[09/17 08:30:50 visual_prompt]: Rank of current process: 0. World size: 1
[09/17 08:30:50 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 08:30:50 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-clevr(task="count_all")', 'DATA.NUMBER_CLASSES', '8', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/17 08:30:50 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 08:30:50 visual_prompt]: Training with config:
[09/17 08:30:50 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-clevr(task="count_all")',
          'NO_TEST': False,
          'NUMBER_CLASSES': 8,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-clevr(task="count_all")/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 08:30:50 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-17 08:30:50.591092: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-17 08:30:50.763790: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-17 08:30:55.665317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 08:30:55.665437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 08:30:55.665453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-17 08:31:04.234291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 08:31:04.234433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 08:31:04.234450: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/17 08:31:04 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
2023-09-17 08:31:04.352423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[:800]+train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 08:31:09 visual_prompt]: Number of images: 1000
[09/17 08:31:09 visual_prompt]: Number of classes: 8 / 8
[09/17 08:31:09 visual_prompt]: Loading validation data...
[09/17 08:31:09 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 08:31:11 visual_prompt]: Number of images: 200
[09/17 08:31:11 visual_prompt]: Number of classes: 8 / 8
[09/17 08:31:11 visual_prompt]: Loading test data...
[09/17 08:31:11 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split validation, from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 08:32:27 visual_prompt]: Number of images: 15000
[09/17 08:32:27 visual_prompt]: Number of classes: 8 / 8
[09/17 08:32:27 visual_prompt]: Constructing models...
[09/17 08:32:30 visual_prompt]: Total Parameters: 86726408	 Gradient Parameters: 927752
[09/17 08:32:30 visual_prompt]: tuned percent:1.070
[09/17 08:32:33 visual_prompt]: Device used for model: 0
[09/17 08:32:33 visual_prompt]: Setting up Evalutator...
[09/17 08:32:33 visual_prompt]: Setting up Trainer...
[09/17 08:32:33 visual_prompt]: 	Setting up the optimizer...
[09/17 08:32:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/17 08:32:43 visual_prompt]: Epoch 1 / 100: avg data time: 1.25e-01, avg batch time: 0.5990, average train loss: 2.6462
[09/17 08:32:47 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1422, average loss: 2.6757
[09/17 08:32:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 62.50	
[09/17 08:33:08 visual_prompt]: 	Test 100/235. loss: 2.740, 0.1871 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 08:33:27 visual_prompt]: 	Test 200/235. loss: 2.793, 0.2079 s / batch. (data: 2.59e-02)max mem: 17.22447 GB 
[09/17 08:33:35 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1922, average loss: 2.6816
[09/17 08:33:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.63	top5: 63.21	
[09/17 08:33:35 visual_prompt]: Best epoch 1: best metric: 0.160
[09/17 08:33:35 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/17 08:33:44 visual_prompt]: Epoch 2 / 100: avg data time: 1.16e-01, avg batch time: 0.5171, average train loss: 4.8814
[09/17 08:33:48 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1428, average loss: 2.6172
[09/17 08:33:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 12.00	top5: 64.50	
[09/17 08:34:09 visual_prompt]: 	Test 100/235. loss: 2.440, 0.2076 s / batch. (data: 2.51e-02)max mem: 17.22447 GB 
[09/17 08:34:28 visual_prompt]: 	Test 200/235. loss: 2.290, 0.1861 s / batch. (data: 1.14e-04)max mem: 17.22447 GB 
[09/17 08:34:36 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1934, average loss: 2.4920
[09/17 08:34:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.89	top5: 64.03	
[09/17 08:34:36 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/17 08:34:46 visual_prompt]: Epoch 3 / 100: avg data time: 1.14e-01, avg batch time: 0.5151, average train loss: 2.7412
[09/17 08:34:49 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1432, average loss: 2.3514
[09/17 08:34:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 63.50	
[09/17 08:35:10 visual_prompt]: 	Test 100/235. loss: 2.292, 0.1837 s / batch. (data: 1.62e-04)max mem: 17.22447 GB 
[09/17 08:35:30 visual_prompt]: 	Test 200/235. loss: 2.316, 0.1841 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 08:35:38 visual_prompt]: Inference (test):avg data time: 6.33e-03, avg batch time: 0.1930, average loss: 2.3551
[09/17 08:35:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 62.29	
[09/17 08:35:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/17 08:35:47 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e-01, avg batch time: 0.5117, average train loss: 2.3899
[09/17 08:35:50 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1433, average loss: 2.0928
[09/17 08:35:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 69.50	
[09/17 08:36:11 visual_prompt]: 	Test 100/235. loss: 2.092, 0.1977 s / batch. (data: 1.48e-02)max mem: 17.22447 GB 
[09/17 08:36:30 visual_prompt]: 	Test 200/235. loss: 2.092, 0.1834 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 08:36:38 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1926, average loss: 2.0855
[09/17 08:36:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 14.39	top5: 73.89	
[09/17 08:36:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/17 08:36:48 visual_prompt]: Epoch 5 / 100: avg data time: 1.09e-01, avg batch time: 0.5134, average train loss: 2.4198
[09/17 08:36:51 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1433, average loss: 2.2562
[09/17 08:36:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 69.50	
[09/17 08:37:12 visual_prompt]: 	Test 100/235. loss: 2.445, 0.2210 s / batch. (data: 2.71e-02)max mem: 17.22447 GB 
[09/17 08:37:32 visual_prompt]: 	Test 200/235. loss: 2.408, 0.1959 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 08:37:40 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1945, average loss: 2.3343
[09/17 08:37:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 13.37	top5: 66.76	
[09/17 08:37:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/17 08:37:49 visual_prompt]: Epoch 6 / 100: avg data time: 9.62e-02, avg batch time: 0.5013, average train loss: 2.8181
[09/17 08:37:52 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1431, average loss: 2.5883
[09/17 08:37:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 69.00	
[09/17 08:38:13 visual_prompt]: 	Test 100/235. loss: 2.715, 0.1888 s / batch. (data: 5.22e-03)max mem: 17.22447 GB 
[09/17 08:38:33 visual_prompt]: 	Test 200/235. loss: 2.662, 0.1973 s / batch. (data: 1.41e-02)max mem: 17.22447 GB 
[09/17 08:38:41 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1940, average loss: 2.7156
[09/17 08:38:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 63.29	
[09/17 08:38:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/17 08:38:50 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e-01, avg batch time: 0.5081, average train loss: 4.8782
[09/17 08:38:53 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1432, average loss: 6.8423
[09/17 08:38:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 62.00	
[09/17 08:39:15 visual_prompt]: 	Test 100/235. loss: 6.422, 0.1954 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 08:39:34 visual_prompt]: 	Test 200/235. loss: 6.424, 0.1925 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 08:39:42 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1931, average loss: 6.9643
[09/17 08:39:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 62.55	
[09/17 08:39:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/17 08:39:51 visual_prompt]: Epoch 8 / 100: avg data time: 9.92e-02, avg batch time: 0.5024, average train loss: 5.8955
[09/17 08:39:54 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1433, average loss: 3.9326
[09/17 08:39:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 61.50	
[09/17 08:40:15 visual_prompt]: 	Test 100/235. loss: 3.893, 0.1836 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 08:40:35 visual_prompt]: 	Test 200/235. loss: 3.942, 0.1835 s / batch. (data: 1.57e-04)max mem: 17.22447 GB 
[09/17 08:40:42 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1927, average loss: 3.8481
[09/17 08:40:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.20	
[09/17 08:40:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/17 08:40:52 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e-01, avg batch time: 0.5118, average train loss: 3.9643
[09/17 08:40:55 visual_prompt]: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1444, average loss: 3.1246
[09/17 08:40:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.00	top5: 65.50	
[09/17 08:41:16 visual_prompt]: 	Test 100/235. loss: 3.688, 0.1984 s / batch. (data: 1.57e-02)max mem: 17.22447 GB 
[09/17 08:41:36 visual_prompt]: 	Test 200/235. loss: 3.491, 0.2034 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 08:41:44 visual_prompt]: Inference (test):avg data time: 8.29e-03, avg batch time: 0.1930, average loss: 3.3953
[09/17 08:41:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 19.24	top5: 62.17	
[09/17 08:41:44 visual_prompt]: Best epoch 9: best metric: 0.220
[09/17 08:41:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/17 08:41:53 visual_prompt]: Epoch 10 / 100: avg data time: 1.14e-01, avg batch time: 0.5159, average train loss: 3.5574
[09/17 08:41:56 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1455, average loss: 5.8620
[09/17 08:41:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 59.50	
[09/17 08:42:17 visual_prompt]: 	Test 100/235. loss: 5.879, 0.1973 s / batch. (data: 1.39e-02)max mem: 17.22447 GB 
[09/17 08:42:37 visual_prompt]: 	Test 200/235. loss: 4.971, 0.1840 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 08:42:45 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1935, average loss: 5.4429
[09/17 08:42:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.71	
[09/17 08:42:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/17 08:42:54 visual_prompt]: Epoch 11 / 100: avg data time: 1.15e-01, avg batch time: 0.5187, average train loss: 8.3021
[09/17 08:42:58 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1430, average loss: 11.0756
[09/17 08:42:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 63.00	
[09/17 08:43:19 visual_prompt]: 	Test 100/235. loss: 13.464, 0.1843 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 08:43:38 visual_prompt]: 	Test 200/235. loss: 12.139, 0.2002 s / batch. (data: 1.68e-04)max mem: 17.22447 GB 
[09/17 08:43:46 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1930, average loss: 11.5213
[09/17 08:43:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.34	
[09/17 08:43:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/17 08:43:55 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e-01, avg batch time: 0.5118, average train loss: 15.1368
[09/17 08:43:59 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1431, average loss: 21.6608
[09/17 08:43:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 66.00	
[09/17 08:44:20 visual_prompt]: 	Test 100/235. loss: 23.445, 0.1840 s / batch. (data: 1.48e-04)max mem: 17.22447 GB 
[09/17 08:44:39 visual_prompt]: 	Test 200/235. loss: 21.870, 0.1844 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 08:44:48 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1957, average loss: 22.0553
[09/17 08:44:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 62.99	
[09/17 08:44:48 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/17 08:44:57 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e-01, avg batch time: 0.5141, average train loss: 26.1666
[09/17 08:45:00 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1431, average loss: 43.0572
[09/17 08:45:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 65.50	
[09/17 08:45:22 visual_prompt]: 	Test 100/235. loss: 45.166, 0.1834 s / batch. (data: 9.25e-05)max mem: 17.22447 GB 
[09/17 08:45:41 visual_prompt]: 	Test 200/235. loss: 45.814, 0.2417 s / batch. (data: 2.86e-02)max mem: 17.22447 GB 
[09/17 08:45:49 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1936, average loss: 45.6822
[09/17 08:45:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 62.17	
[09/17 08:45:49 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/17 08:45:59 visual_prompt]: Epoch 14 / 100: avg data time: 1.19e-01, avg batch time: 0.5540, average train loss: 25.2156
[09/17 08:46:02 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1431, average loss: 20.8818
[09/17 08:46:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 64.00	
[09/17 08:46:23 visual_prompt]: 	Test 100/235. loss: 21.087, 0.1852 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 08:46:43 visual_prompt]: 	Test 200/235. loss: 22.753, 0.1987 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 08:46:51 visual_prompt]: Inference (test):avg data time: 7.33e-03, avg batch time: 0.1935, average loss: 21.6161
[09/17 08:46:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.60	
[09/17 08:46:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/17 08:47:00 visual_prompt]: Epoch 15 / 100: avg data time: 1.01e-01, avg batch time: 0.5060, average train loss: 11.8908
[09/17 08:47:03 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1431, average loss: 8.6685
[09/17 08:47:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 65.50	
[09/17 08:47:25 visual_prompt]: 	Test 100/235. loss: 9.467, 0.1900 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 08:47:45 visual_prompt]: 	Test 200/235. loss: 8.715, 0.2169 s / batch. (data: 3.39e-02)max mem: 17.22447 GB 
[09/17 08:47:53 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1982, average loss: 8.9888
[09/17 08:47:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.40	
[09/17 08:47:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/17 08:48:03 visual_prompt]: Epoch 16 / 100: avg data time: 1.15e-01, avg batch time: 0.5160, average train loss: 8.5733
[09/17 08:48:06 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1430, average loss: 11.8513
[09/17 08:48:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 61.50	
[09/17 08:48:27 visual_prompt]: 	Test 100/235. loss: 11.123, 0.1874 s / batch. (data: 1.57e-04)max mem: 17.22447 GB 
[09/17 08:48:46 visual_prompt]: 	Test 200/235. loss: 11.298, 0.2064 s / batch. (data: 2.31e-04)max mem: 17.22447 GB 
[09/17 08:48:54 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1923, average loss: 11.2478
[09/17 08:48:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.29	top5: 62.20	
[09/17 08:48:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/17 08:49:04 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e-01, avg batch time: 0.5331, average train loss: 8.5304
[09/17 08:49:07 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1430, average loss: 9.5227
[09/17 08:49:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 59.00	
[09/17 08:49:28 visual_prompt]: 	Test 100/235. loss: 9.361, 0.1934 s / batch. (data: 1.03e-02)max mem: 17.22447 GB 
[09/17 08:49:48 visual_prompt]: 	Test 200/235. loss: 8.809, 0.1841 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 08:49:56 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1940, average loss: 9.2134
[09/17 08:49:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.12	
[09/17 08:49:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/17 08:50:05 visual_prompt]: Epoch 18 / 100: avg data time: 1.14e-01, avg batch time: 0.5169, average train loss: 8.5144
[09/17 08:50:08 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1430, average loss: 7.6642
[09/17 08:50:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 66.00	
[09/17 08:50:29 visual_prompt]: 	Test 100/235. loss: 9.089, 0.1975 s / batch. (data: 1.43e-02)max mem: 17.22447 GB 
[09/17 08:50:49 visual_prompt]: 	Test 200/235. loss: 8.278, 0.1840 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 08:50:57 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1931, average loss: 7.9804
[09/17 08:50:57 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.99	
[09/17 08:50:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/17 08:51:06 visual_prompt]: Epoch 19 / 100: avg data time: 1.01e-01, avg batch time: 0.5040, average train loss: 7.6657
[09/17 08:51:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1432, average loss: 8.7837
[09/17 08:51:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 61.00	
[09/17 08:51:30 visual_prompt]: 	Test 100/235. loss: 9.364, 0.1966 s / batch. (data: 1.32e-02)max mem: 17.22447 GB 
[09/17 08:51:50 visual_prompt]: 	Test 200/235. loss: 8.918, 0.1844 s / batch. (data: 9.58e-05)max mem: 17.22447 GB 
[09/17 08:51:58 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1935, average loss: 8.7637
[09/17 08:51:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.63	
[09/17 08:51:58 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/17 08:52:07 visual_prompt]: Epoch 20 / 100: avg data time: 9.92e-02, avg batch time: 0.5020, average train loss: 7.2111
[09/17 08:52:10 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1431, average loss: 5.7931
[09/17 08:52:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 61.00	
[09/17 08:52:31 visual_prompt]: 	Test 100/235. loss: 6.187, 0.1963 s / batch. (data: 1.33e-02)max mem: 17.22447 GB 
[09/17 08:52:51 visual_prompt]: 	Test 200/235. loss: 5.882, 0.1954 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 08:52:59 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1937, average loss: 5.7079
[09/17 08:52:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.53	
[09/17 08:52:59 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/17 08:53:08 visual_prompt]: Epoch 21 / 100: avg data time: 1.16e-01, avg batch time: 0.5181, average train loss: 4.9366
[09/17 08:53:11 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1430, average loss: 5.4927
[09/17 08:53:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 64.50	
[09/17 08:53:32 visual_prompt]: 	Test 100/235. loss: 5.199, 0.1838 s / batch. (data: 1.10e-04)max mem: 17.22447 GB 
[09/17 08:53:52 visual_prompt]: 	Test 200/235. loss: 5.348, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 08:54:00 visual_prompt]: Inference (test):avg data time: 7.17e-03, avg batch time: 0.1929, average loss: 5.4758
[09/17 08:54:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.72	
[09/17 08:54:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/17 08:54:09 visual_prompt]: Epoch 22 / 100: avg data time: 1.14e-01, avg batch time: 0.5159, average train loss: 4.0148
[09/17 08:54:12 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1429, average loss: 3.3577
[09/17 08:54:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 63.50	
[09/17 08:54:33 visual_prompt]: 	Test 100/235. loss: 3.562, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 08:54:53 visual_prompt]: 	Test 200/235. loss: 3.456, 0.2091 s / batch. (data: 2.53e-02)max mem: 17.22447 GB 
[09/17 08:55:01 visual_prompt]: Inference (test):avg data time: 8.99e-03, avg batch time: 0.1948, average loss: 3.4258
[09/17 08:55:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.29	top5: 62.46	
[09/17 08:55:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/17 08:55:10 visual_prompt]: Epoch 23 / 100: avg data time: 1.10e-01, avg batch time: 0.5149, average train loss: 3.0681
[09/17 08:55:14 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1431, average loss: 2.2731
[09/17 08:55:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 61.00	
[09/17 08:55:35 visual_prompt]: 	Test 100/235. loss: 2.344, 0.1990 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 08:55:54 visual_prompt]: 	Test 200/235. loss: 2.356, 0.1839 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 08:56:02 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1930, average loss: 2.2766
[09/17 08:56:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.53	
[09/17 08:56:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/17 08:56:12 visual_prompt]: Epoch 24 / 100: avg data time: 1.12e-01, avg batch time: 0.5138, average train loss: 2.5119
[09/17 08:56:15 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1431, average loss: 2.6395
[09/17 08:56:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 59.00	
[09/17 08:56:36 visual_prompt]: 	Test 100/235. loss: 2.507, 0.1987 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 08:56:56 visual_prompt]: 	Test 200/235. loss: 2.449, 0.1839 s / batch. (data: 1.01e-04)max mem: 17.22447 GB 
[09/17 08:57:04 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1942, average loss: 2.5306
[09/17 08:57:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.12	
[09/17 08:57:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/17 08:57:13 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e-01, avg batch time: 0.5103, average train loss: 2.5291
[09/17 08:57:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1432, average loss: 2.7520
[09/17 08:57:16 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 65.00	
[09/17 08:57:37 visual_prompt]: 	Test 100/235. loss: 2.796, 0.2076 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 08:57:58 visual_prompt]: 	Test 200/235. loss: 2.963, 0.2047 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 08:58:05 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1970, average loss: 2.8409
[09/17 08:58:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.28	
[09/17 08:58:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/17 08:58:15 visual_prompt]: Epoch 26 / 100: avg data time: 1.17e-01, avg batch time: 0.5208, average train loss: 2.5390
[09/17 08:58:18 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1431, average loss: 2.3543
[09/17 08:58:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 59.50	
[09/17 08:58:40 visual_prompt]: 	Test 100/235. loss: 2.405, 0.1969 s / batch. (data: 1.39e-02)max mem: 17.22447 GB 
[09/17 08:59:00 visual_prompt]: 	Test 200/235. loss: 2.289, 0.1995 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 08:59:07 visual_prompt]: Inference (test):avg data time: 6.53e-03, avg batch time: 0.1959, average loss: 2.2956
[09/17 08:59:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 63.21	
[09/17 08:59:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/17 08:59:17 visual_prompt]: Epoch 27 / 100: avg data time: 1.23e-01, avg batch time: 0.5245, average train loss: 2.3707
[09/17 08:59:20 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1430, average loss: 2.1247
[09/17 08:59:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 15.50	top5: 69.00	
[09/17 08:59:41 visual_prompt]: 	Test 100/235. loss: 2.281, 0.1836 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 09:00:01 visual_prompt]: 	Test 200/235. loss: 2.143, 0.1834 s / batch. (data: 4.60e-05)max mem: 17.22447 GB 
[09/17 09:00:09 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1937, average loss: 2.1393
[09/17 09:00:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 13.60	top5: 68.57	
[09/17 09:00:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/17 09:00:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.19e-01, avg batch time: 0.5231, average train loss: 2.1691
[09/17 09:00:21 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1431, average loss: 2.3535
[09/17 09:00:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 18.00	top5: 67.00	
[09/17 09:00:43 visual_prompt]: 	Test 100/235. loss: 2.281, 0.1962 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 09:01:02 visual_prompt]: 	Test 200/235. loss: 2.116, 0.1963 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 09:01:10 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1936, average loss: 2.2395
[09/17 09:01:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.01	top5: 69.72	
[09/17 09:01:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/17 09:01:19 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e-01, avg batch time: 0.5082, average train loss: 2.2765
[09/17 09:01:23 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1431, average loss: 2.2768
[09/17 09:01:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.00	top5: 86.00	
[09/17 09:01:44 visual_prompt]: 	Test 100/235. loss: 2.496, 0.2083 s / batch. (data: 2.51e-02)max mem: 17.22447 GB 
[09/17 09:02:03 visual_prompt]: 	Test 200/235. loss: 2.231, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 09:02:11 visual_prompt]: Inference (test):avg data time: 6.47e-03, avg batch time: 0.1933, average loss: 2.3579
[09/17 09:02:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.27	top5: 82.97	
[09/17 09:02:11 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/17 09:02:21 visual_prompt]: Epoch 30 / 100: avg data time: 1.19e-01, avg batch time: 0.5221, average train loss: 2.3284
[09/17 09:02:24 visual_prompt]: Inference (val):avg data time: 5.37e-04, avg batch time: 0.2383, average loss: 1.7859
[09/17 09:02:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.00	top5: 92.50	
[09/17 09:02:46 visual_prompt]: 	Test 100/235. loss: 2.037, 0.1855 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 09:03:05 visual_prompt]: 	Test 200/235. loss: 1.846, 0.1953 s / batch. (data: 9.39e-05)max mem: 17.22447 GB 
[09/17 09:03:13 visual_prompt]: Inference (test):avg data time: 6.41e-03, avg batch time: 0.1937, average loss: 1.8988
[09/17 09:03:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.79	top5: 88.55	
[09/17 09:03:13 visual_prompt]: Best epoch 30: best metric: 0.250
[09/17 09:03:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/17 09:03:23 visual_prompt]: Epoch 31 / 100: avg data time: 1.19e-01, avg batch time: 0.5206, average train loss: 1.9066
[09/17 09:03:26 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.1430, average loss: 2.8452
[09/17 09:03:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.50	top5: 78.50	
[09/17 09:03:48 visual_prompt]: 	Test 100/235. loss: 2.807, 0.1976 s / batch. (data: 1.54e-04)max mem: 17.22447 GB 
[09/17 09:04:07 visual_prompt]: 	Test 200/235. loss: 2.740, 0.1838 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 09:04:15 visual_prompt]: Inference (test):avg data time: 8.51e-03, avg batch time: 0.1971, average loss: 2.7439
[09/17 09:04:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 20.16	top5: 79.49	
[09/17 09:04:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/17 09:04:25 visual_prompt]: Epoch 32 / 100: avg data time: 1.17e-01, avg batch time: 0.5183, average train loss: 2.3008
[09/17 09:04:28 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1432, average loss: 2.1359
[09/17 09:04:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.50	top5: 86.50	
[09/17 09:04:49 visual_prompt]: 	Test 100/235. loss: 2.323, 0.1979 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 09:05:09 visual_prompt]: 	Test 200/235. loss: 2.239, 0.1970 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 09:05:17 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1940, average loss: 2.2193
[09/17 09:05:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.83	top5: 84.21	
[09/17 09:05:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/17 09:05:26 visual_prompt]: Epoch 33 / 100: avg data time: 1.12e-01, avg batch time: 0.5139, average train loss: 2.0725
[09/17 09:05:30 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.1430, average loss: 1.6580
[09/17 09:05:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 29.00	top5: 92.00	
[09/17 09:05:51 visual_prompt]: 	Test 100/235. loss: 1.953, 0.2081 s / batch. (data: 2.50e-02)max mem: 17.22447 GB 
[09/17 09:06:11 visual_prompt]: 	Test 200/235. loss: 1.682, 0.2007 s / batch. (data: 1.50e-02)max mem: 17.22447 GB 
[09/17 09:06:18 visual_prompt]: Inference (test):avg data time: 6.74e-03, avg batch time: 0.1945, average loss: 1.7347
[09/17 09:06:19 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.75	top5: 89.87	
[09/17 09:06:19 visual_prompt]: Best epoch 33: best metric: 0.290
[09/17 09:06:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/17 09:06:28 visual_prompt]: Epoch 34 / 100: avg data time: 1.11e-01, avg batch time: 0.5146, average train loss: 1.8401
[09/17 09:06:31 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1441, average loss: 1.9363
[09/17 09:06:31 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.50	top5: 89.50	
[09/17 09:06:52 visual_prompt]: 	Test 100/235. loss: 2.125, 0.1839 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 09:07:12 visual_prompt]: 	Test 200/235. loss: 1.947, 0.1837 s / batch. (data: 1.18e-04)max mem: 17.22447 GB 
[09/17 09:07:20 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1930, average loss: 1.9229
[09/17 09:07:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 25.37	top5: 86.56	
[09/17 09:07:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/17 09:07:29 visual_prompt]: Epoch 35 / 100: avg data time: 1.20e-01, avg batch time: 0.5470, average train loss: 1.9060
[09/17 09:07:33 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1431, average loss: 1.8341
[09/17 09:07:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.50	top5: 85.50	
[09/17 09:07:54 visual_prompt]: 	Test 100/235. loss: 2.008, 0.1838 s / batch. (data: 1.96e-04)max mem: 17.22447 GB 
[09/17 09:08:14 visual_prompt]: 	Test 200/235. loss: 1.875, 0.1921 s / batch. (data: 8.85e-03)max mem: 17.22447 GB 
[09/17 09:08:22 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1951, average loss: 1.8685
[09/17 09:08:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.64	top5: 86.47	
[09/17 09:08:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/17 09:08:31 visual_prompt]: Epoch 36 / 100: avg data time: 1.12e-01, avg batch time: 0.5165, average train loss: 1.8817
[09/17 09:08:34 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1430, average loss: 1.6862
[09/17 09:08:34 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 29.50	top5: 97.50	
[09/17 09:08:56 visual_prompt]: 	Test 100/235. loss: 1.768, 0.1999 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 09:09:15 visual_prompt]: 	Test 200/235. loss: 1.552, 0.2132 s / batch. (data: 3.01e-02)max mem: 17.22447 GB 
[09/17 09:09:23 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1934, average loss: 1.6882
[09/17 09:09:23 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.25	top5: 97.61	
[09/17 09:09:23 visual_prompt]: Best epoch 36: best metric: 0.295
[09/17 09:09:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/17 09:09:33 visual_prompt]: Epoch 37 / 100: avg data time: 1.16e-01, avg batch time: 0.5190, average train loss: 1.7160
[09/17 09:09:36 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1432, average loss: 1.4846
[09/17 09:09:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.50	top5: 96.50	
[09/17 09:09:57 visual_prompt]: 	Test 100/235. loss: 1.599, 0.1904 s / batch. (data: 1.77e-04)max mem: 17.22447 GB 
[09/17 09:10:16 visual_prompt]: 	Test 200/235. loss: 1.465, 0.2079 s / batch. (data: 2.47e-02)max mem: 17.22447 GB 
[09/17 09:10:24 visual_prompt]: Inference (test):avg data time: 7.15e-03, avg batch time: 0.1929, average loss: 1.4775
[09/17 09:10:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.69	top5: 97.02	
[09/17 09:10:24 visual_prompt]: Best epoch 37: best metric: 0.355
[09/17 09:10:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/17 09:10:34 visual_prompt]: Epoch 38 / 100: avg data time: 1.19e-01, avg batch time: 0.5205, average train loss: 1.7115
[09/17 09:10:37 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1432, average loss: 1.7835
[09/17 09:10:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.50	top5: 89.00	
[09/17 09:10:58 visual_prompt]: 	Test 100/235. loss: 2.095, 0.1981 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 09:11:17 visual_prompt]: 	Test 200/235. loss: 1.810, 0.1989 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 09:11:25 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1932, average loss: 1.8486
[09/17 09:11:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.50	top5: 87.23	
[09/17 09:11:25 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/17 09:11:35 visual_prompt]: Epoch 39 / 100: avg data time: 1.19e-01, avg batch time: 0.5246, average train loss: 1.8924
[09/17 09:11:38 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1432, average loss: 1.6897
[09/17 09:11:38 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.50	top5: 91.00	
[09/17 09:11:59 visual_prompt]: 	Test 100/235. loss: 1.733, 0.2537 s / batch. (data: 2.32e-02)max mem: 17.22447 GB 
[09/17 09:12:19 visual_prompt]: 	Test 200/235. loss: 1.701, 0.2056 s / batch. (data: 1.99e-02)max mem: 17.22447 GB 
[09/17 09:12:27 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1940, average loss: 1.6298
[09/17 09:12:27 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.06	top5: 90.03	
[09/17 09:12:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/17 09:12:36 visual_prompt]: Epoch 40 / 100: avg data time: 1.12e-01, avg batch time: 0.5370, average train loss: 1.7618
[09/17 09:12:40 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1431, average loss: 2.0632
[09/17 09:12:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.00	top5: 94.00	
[09/17 09:13:01 visual_prompt]: 	Test 100/235. loss: 2.452, 0.1886 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 09:13:21 visual_prompt]: 	Test 200/235. loss: 2.260, 0.1961 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 09:13:29 visual_prompt]: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1939, average loss: 2.1834
[09/17 09:13:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.77	top5: 90.41	
[09/17 09:13:29 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/17 09:13:38 visual_prompt]: Epoch 41 / 100: avg data time: 1.15e-01, avg batch time: 0.5351, average train loss: 2.1197
[09/17 09:13:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1430, average loss: 1.7901
[09/17 09:13:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.50	top5: 86.50	
[09/17 09:14:03 visual_prompt]: 	Test 100/235. loss: 1.795, 0.1957 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 09:14:22 visual_prompt]: 	Test 200/235. loss: 1.724, 0.1978 s / batch. (data: 1.46e-02)max mem: 17.22447 GB 
[09/17 09:14:30 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1937, average loss: 1.7715
[09/17 09:14:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.83	top5: 87.71	
[09/17 09:14:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/17 09:14:39 visual_prompt]: Epoch 42 / 100: avg data time: 1.08e-01, avg batch time: 0.5094, average train loss: 1.7110
[09/17 09:14:43 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1431, average loss: 1.4456
[09/17 09:14:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.00	top5: 96.50	
[09/17 09:15:04 visual_prompt]: 	Test 100/235. loss: 1.643, 0.2432 s / batch. (data: 1.34e-02)max mem: 17.22447 GB 
[09/17 09:15:24 visual_prompt]: 	Test 200/235. loss: 1.465, 0.1843 s / batch. (data: 1.59e-04)max mem: 17.22447 GB 
[09/17 09:15:32 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1951, average loss: 1.5127
[09/17 09:15:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.53	top5: 95.98	
[09/17 09:15:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/17 09:15:41 visual_prompt]: Epoch 43 / 100: avg data time: 1.12e-01, avg batch time: 0.5145, average train loss: 1.7735
[09/17 09:15:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1432, average loss: 1.4672
[09/17 09:15:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.00	top5: 97.50	
[09/17 09:16:06 visual_prompt]: 	Test 100/235. loss: 1.664, 0.1887 s / batch. (data: 1.03e-04)max mem: 17.22447 GB 
[09/17 09:16:25 visual_prompt]: 	Test 200/235. loss: 1.509, 0.1835 s / batch. (data: 1.60e-04)max mem: 17.22447 GB 
[09/17 09:16:33 visual_prompt]: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1947, average loss: 1.5169
[09/17 09:16:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.95	top5: 98.04	
[09/17 09:16:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/17 09:16:43 visual_prompt]: Epoch 44 / 100: avg data time: 1.15e-01, avg batch time: 0.5164, average train loss: 1.8431
[09/17 09:16:46 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1431, average loss: 2.4728
[09/17 09:16:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 84.00	
[09/17 09:17:07 visual_prompt]: 	Test 100/235. loss: 2.470, 0.1834 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 09:17:27 visual_prompt]: 	Test 200/235. loss: 2.390, 0.1837 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 09:17:35 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1937, average loss: 2.4636
[09/17 09:17:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 16.76	top5: 82.17	
[09/17 09:17:35 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/17 09:17:44 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e-01, avg batch time: 0.5132, average train loss: 1.8963
[09/17 09:17:47 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1433, average loss: 2.9856
[09/17 09:17:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.50	top5: 88.50	
[09/17 09:18:09 visual_prompt]: 	Test 100/235. loss: 2.869, 0.1834 s / batch. (data: 4.17e-05)max mem: 17.22447 GB 
[09/17 09:18:28 visual_prompt]: 	Test 200/235. loss: 2.739, 0.2079 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 09:18:36 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1947, average loss: 2.9020
[09/17 09:18:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 13.14	top5: 86.51	
[09/17 09:18:36 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/17 09:18:46 visual_prompt]: Epoch 46 / 100: avg data time: 1.15e-01, avg batch time: 0.5176, average train loss: 2.0216
[09/17 09:18:49 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1430, average loss: 2.6603
[09/17 09:18:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.00	top5: 92.50	
[09/17 09:19:10 visual_prompt]: 	Test 100/235. loss: 3.023, 0.1986 s / batch. (data: 1.56e-02)max mem: 17.22447 GB 
[09/17 09:19:30 visual_prompt]: 	Test 200/235. loss: 2.834, 0.1967 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 09:19:38 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1953, average loss: 2.8882
[09/17 09:19:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.75	top5: 87.83	
[09/17 09:19:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/17 09:19:48 visual_prompt]: Epoch 47 / 100: avg data time: 1.18e-01, avg batch time: 0.5219, average train loss: 1.9697
[09/17 09:19:51 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1430, average loss: 1.5829
[09/17 09:19:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.50	top5: 99.00	
[09/17 09:20:12 visual_prompt]: 	Test 100/235. loss: 1.803, 0.1960 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 09:20:32 visual_prompt]: 	Test 200/235. loss: 1.715, 0.1993 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 09:20:40 visual_prompt]: Inference (test):avg data time: 7.31e-03, avg batch time: 0.1959, average loss: 1.6354
[09/17 09:20:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.07	top5: 95.67	
[09/17 09:20:40 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/17 09:20:49 visual_prompt]: Epoch 48 / 100: avg data time: 1.15e-01, avg batch time: 0.5182, average train loss: 1.6806
[09/17 09:20:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1430, average loss: 1.5807
[09/17 09:20:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.00	top5: 98.00	
[09/17 09:21:14 visual_prompt]: 	Test 100/235. loss: 1.768, 0.2080 s / batch. (data: 2.51e-02)max mem: 17.22447 GB 
[09/17 09:21:34 visual_prompt]: 	Test 200/235. loss: 1.698, 0.1865 s / batch. (data: 2.71e-03)max mem: 17.22447 GB 
[09/17 09:21:42 visual_prompt]: Inference (test):avg data time: 9.16e-03, avg batch time: 0.1950, average loss: 1.6822
[09/17 09:21:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.85	top5: 96.85	
[09/17 09:21:42 visual_prompt]: Best epoch 48: best metric: 0.360
[09/17 09:21:42 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/17 09:21:51 visual_prompt]: Epoch 49 / 100: avg data time: 1.14e-01, avg batch time: 0.5206, average train loss: 1.7474
[09/17 09:21:54 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1430, average loss: 2.2363
[09/17 09:21:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.50	top5: 92.00	
[09/17 09:22:16 visual_prompt]: 	Test 100/235. loss: 2.137, 0.1956 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 09:22:35 visual_prompt]: 	Test 200/235. loss: 2.028, 0.1991 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 09:22:43 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1940, average loss: 2.1118
[09/17 09:22:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.31	top5: 93.69	
[09/17 09:22:43 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/17 09:22:52 visual_prompt]: Epoch 50 / 100: avg data time: 1.10e-01, avg batch time: 0.5146, average train loss: 1.5251
[09/17 09:22:56 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1467, average loss: 1.6211
[09/17 09:22:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.50	top5: 95.50	
[09/17 09:23:17 visual_prompt]: 	Test 100/235. loss: 1.756, 0.1850 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 09:23:36 visual_prompt]: 	Test 200/235. loss: 1.663, 0.2072 s / batch. (data: 1.50e-02)max mem: 17.22447 GB 
[09/17 09:23:44 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1940, average loss: 1.7397
[09/17 09:23:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.63	top5: 94.33	
[09/17 09:23:44 visual_prompt]: Best epoch 50: best metric: 0.395
[09/17 09:23:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/17 09:23:54 visual_prompt]: Epoch 51 / 100: avg data time: 1.18e-01, avg batch time: 0.5216, average train loss: 1.7233
[09/17 09:23:57 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1432, average loss: 1.6765
[09/17 09:23:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.00	top5: 97.50	
[09/17 09:24:18 visual_prompt]: 	Test 100/235. loss: 1.736, 0.1981 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 09:24:38 visual_prompt]: 	Test 200/235. loss: 1.704, 0.1972 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 09:24:46 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1953, average loss: 1.6345
[09/17 09:24:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.86	top5: 97.56	
[09/17 09:24:46 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/17 09:24:55 visual_prompt]: Epoch 52 / 100: avg data time: 1.02e-01, avg batch time: 0.5090, average train loss: 1.5522
[09/17 09:24:59 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1432, average loss: 1.3509
[09/17 09:24:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 40.50	top5: 100.00	
[09/17 09:25:20 visual_prompt]: 	Test 100/235. loss: 1.379, 0.1838 s / batch. (data: 1.48e-04)max mem: 17.22447 GB 
[09/17 09:25:40 visual_prompt]: 	Test 200/235. loss: 1.454, 0.1838 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 09:25:48 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1963, average loss: 1.3925
[09/17 09:25:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 38.97	top5: 99.37	
[09/17 09:25:48 visual_prompt]: Best epoch 52: best metric: 0.405
[09/17 09:25:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/17 09:25:57 visual_prompt]: Epoch 53 / 100: avg data time: 1.18e-01, avg batch time: 0.5203, average train loss: 1.4376
[09/17 09:26:01 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1431, average loss: 1.4891
[09/17 09:26:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.00	top5: 99.00	
[09/17 09:26:22 visual_prompt]: 	Test 100/235. loss: 1.776, 0.1992 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 09:26:41 visual_prompt]: 	Test 200/235. loss: 1.561, 0.1840 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 09:26:49 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1943, average loss: 1.4998
[09/17 09:26:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.80	top5: 98.60	
[09/17 09:26:49 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/17 09:26:59 visual_prompt]: Epoch 54 / 100: avg data time: 1.10e-01, avg batch time: 0.5184, average train loss: 1.5880
[09/17 09:27:02 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1430, average loss: 1.3517
[09/17 09:27:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.00	top5: 100.00	
[09/17 09:27:23 visual_prompt]: 	Test 100/235. loss: 1.516, 0.1838 s / batch. (data: 1.69e-04)max mem: 17.22447 GB 
[09/17 09:27:43 visual_prompt]: 	Test 200/235. loss: 1.495, 0.1852 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 09:27:51 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1945, average loss: 1.4832
[09/17 09:27:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.16	top5: 99.67	
[09/17 09:27:51 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/17 09:28:01 visual_prompt]: Epoch 55 / 100: avg data time: 1.14e-01, avg batch time: 0.5179, average train loss: 1.3602
[09/17 09:28:04 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1432, average loss: 1.1379
[09/17 09:28:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 46.50	top5: 100.00	
[09/17 09:28:25 visual_prompt]: 	Test 100/235. loss: 1.363, 0.1922 s / batch. (data: 8.63e-03)max mem: 17.22447 GB 
[09/17 09:28:45 visual_prompt]: 	Test 200/235. loss: 1.263, 0.1842 s / batch. (data: 9.73e-05)max mem: 17.22447 GB 
[09/17 09:28:52 visual_prompt]: Inference (test):avg data time: 8.74e-03, avg batch time: 0.1940, average loss: 1.2746
[09/17 09:28:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.85	top5: 99.63	
[09/17 09:28:52 visual_prompt]: Best epoch 55: best metric: 0.465
[09/17 09:28:52 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/17 09:29:02 visual_prompt]: Epoch 56 / 100: avg data time: 1.00e-01, avg batch time: 0.5049, average train loss: 1.6290
[09/17 09:29:05 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1431, average loss: 1.6595
[09/17 09:29:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.50	top5: 89.50	
[09/17 09:29:26 visual_prompt]: 	Test 100/235. loss: 1.794, 0.1952 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 09:29:46 visual_prompt]: 	Test 200/235. loss: 1.753, 0.1956 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 09:29:54 visual_prompt]: Inference (test):avg data time: 6.73e-03, avg batch time: 0.1935, average loss: 1.7374
[09/17 09:29:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.88	top5: 87.61	
[09/17 09:29:54 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/17 09:30:03 visual_prompt]: Epoch 57 / 100: avg data time: 1.09e-01, avg batch time: 0.5168, average train loss: 1.7367
[09/17 09:30:06 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1431, average loss: 2.2402
[09/17 09:30:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.00	top5: 93.50	
[09/17 09:30:27 visual_prompt]: 	Test 100/235. loss: 2.430, 0.1972 s / batch. (data: 1.39e-02)max mem: 17.22447 GB 
[09/17 09:30:47 visual_prompt]: 	Test 200/235. loss: 2.386, 0.1837 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 09:30:55 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1939, average loss: 2.3419
[09/17 09:30:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.93	top5: 92.69	
[09/17 09:30:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/17 09:31:04 visual_prompt]: Epoch 58 / 100: avg data time: 1.04e-01, avg batch time: 0.5083, average train loss: 1.8342
[09/17 09:31:08 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1431, average loss: 2.0898
[09/17 09:31:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 20.50	top5: 84.50	
[09/17 09:31:29 visual_prompt]: 	Test 100/235. loss: 2.103, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 09:31:48 visual_prompt]: 	Test 200/235. loss: 2.063, 0.2097 s / batch. (data: 2.62e-02)max mem: 17.22447 GB 
[09/17 09:31:56 visual_prompt]: Inference (test):avg data time: 6.47e-03, avg batch time: 0.1932, average loss: 2.0332
[09/17 09:31:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.39	top5: 85.17	
[09/17 09:31:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/17 09:32:06 visual_prompt]: Epoch 59 / 100: avg data time: 1.19e-01, avg batch time: 0.5207, average train loss: 1.7739
[09/17 09:32:09 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1432, average loss: 1.4514
[09/17 09:32:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 31.00	top5: 98.50	
[09/17 09:32:30 visual_prompt]: 	Test 100/235. loss: 1.565, 0.1916 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 09:32:50 visual_prompt]: 	Test 200/235. loss: 1.512, 0.1982 s / batch. (data: 1.48e-02)max mem: 17.22447 GB 
[09/17 09:32:58 visual_prompt]: Inference (test):avg data time: 6.91e-03, avg batch time: 0.1931, average loss: 1.4820
[09/17 09:32:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.64	top5: 97.00	
[09/17 09:32:58 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/17 09:33:07 visual_prompt]: Epoch 60 / 100: avg data time: 1.12e-01, avg batch time: 0.5169, average train loss: 1.4282
[09/17 09:33:10 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1431, average loss: 1.2921
[09/17 09:33:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.50	top5: 100.00	
[09/17 09:33:32 visual_prompt]: 	Test 100/235. loss: 1.591, 0.1837 s / batch. (data: 1.69e-04)max mem: 17.22447 GB 
[09/17 09:33:51 visual_prompt]: 	Test 200/235. loss: 1.431, 0.1841 s / batch. (data: 1.19e-04)max mem: 17.22447 GB 
[09/17 09:33:59 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1938, average loss: 1.3869
[09/17 09:33:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.69	top5: 99.61	
[09/17 09:33:59 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/17 09:34:09 visual_prompt]: Epoch 61 / 100: avg data time: 1.12e-01, avg batch time: 0.5165, average train loss: 1.4318
[09/17 09:34:12 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1430, average loss: 1.3194
[09/17 09:34:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 41.00	top5: 100.00	
[09/17 09:34:33 visual_prompt]: 	Test 100/235. loss: 1.431, 0.1836 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 09:34:53 visual_prompt]: 	Test 200/235. loss: 1.443, 0.1838 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 09:35:00 visual_prompt]: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1929, average loss: 1.3776
[09/17 09:35:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 38.39	top5: 98.98	
[09/17 09:35:01 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/17 09:35:10 visual_prompt]: Epoch 62 / 100: avg data time: 1.16e-01, avg batch time: 0.5180, average train loss: 1.2312
[09/17 09:35:13 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1434, average loss: 1.7442
[09/17 09:35:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.00	top5: 98.50	
[09/17 09:35:34 visual_prompt]: 	Test 100/235. loss: 2.006, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 09:35:55 visual_prompt]: 	Test 200/235. loss: 2.104, 0.1836 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 09:36:02 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1960, average loss: 1.8575
[09/17 09:36:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.95	top5: 97.11	
[09/17 09:36:02 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/17 09:36:12 visual_prompt]: Epoch 63 / 100: avg data time: 1.11e-01, avg batch time: 0.5150, average train loss: 1.4471
[09/17 09:36:15 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1430, average loss: 1.2629
[09/17 09:36:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.50	top5: 100.00	
[09/17 09:36:36 visual_prompt]: 	Test 100/235. loss: 1.380, 0.1839 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 09:36:56 visual_prompt]: 	Test 200/235. loss: 1.404, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 09:37:04 visual_prompt]: Inference (test):avg data time: 8.58e-03, avg batch time: 0.1941, average loss: 1.3097
[09/17 09:37:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.43	top5: 99.59	
[09/17 09:37:04 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/17 09:37:13 visual_prompt]: Epoch 64 / 100: avg data time: 1.13e-01, avg batch time: 0.5150, average train loss: 1.1515
[09/17 09:37:16 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1441, average loss: 0.9541
[09/17 09:37:16 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 54.50	top5: 100.00	
[09/17 09:37:38 visual_prompt]: 	Test 100/235. loss: 1.253, 0.2163 s / batch. (data: 2.27e-02)max mem: 17.22447 GB 
[09/17 09:37:57 visual_prompt]: 	Test 200/235. loss: 1.180, 0.1896 s / batch. (data: 1.04e-04)max mem: 17.22447 GB 
[09/17 09:38:05 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1942, average loss: 1.1172
[09/17 09:38:05 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.44	top5: 99.93	
[09/17 09:38:05 visual_prompt]: Best epoch 64: best metric: 0.545
[09/17 09:38:05 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/17 09:38:15 visual_prompt]: Epoch 65 / 100: avg data time: 1.13e-01, avg batch time: 0.5165, average train loss: 1.3770
[09/17 09:38:18 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1431, average loss: 1.6588
[09/17 09:38:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 98.50	
[09/17 09:38:39 visual_prompt]: 	Test 100/235. loss: 1.707, 0.2091 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 09:38:59 visual_prompt]: 	Test 200/235. loss: 1.716, 0.1840 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 09:39:06 visual_prompt]: Inference (test):avg data time: 6.47e-03, avg batch time: 0.1929, average loss: 1.7127
[09/17 09:39:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.09	top5: 98.39	
[09/17 09:39:06 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/17 09:39:16 visual_prompt]: Epoch 66 / 100: avg data time: 1.11e-01, avg batch time: 0.5158, average train loss: 1.2626
[09/17 09:39:19 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1431, average loss: 1.2271
[09/17 09:39:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 41.50	top5: 100.00	
[09/17 09:39:40 visual_prompt]: 	Test 100/235. loss: 1.423, 0.2300 s / batch. (data: 4.70e-02)max mem: 17.22447 GB 
[09/17 09:40:00 visual_prompt]: 	Test 200/235. loss: 1.300, 0.2000 s / batch. (data: 1.65e-02)max mem: 17.22447 GB 
[09/17 09:40:07 visual_prompt]: Inference (test):avg data time: 7.02e-03, avg batch time: 0.1928, average loss: 1.2897
[09/17 09:40:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.78	top5: 99.53	
[09/17 09:40:07 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/17 09:40:17 visual_prompt]: Epoch 67 / 100: avg data time: 1.13e-01, avg batch time: 0.5193, average train loss: 1.0891
[09/17 09:40:20 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1432, average loss: 1.1098
[09/17 09:40:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 47.50	top5: 100.00	
[09/17 09:40:41 visual_prompt]: 	Test 100/235. loss: 1.378, 0.1960 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 09:41:01 visual_prompt]: 	Test 200/235. loss: 1.231, 0.1841 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 09:41:09 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1931, average loss: 1.2705
[09/17 09:41:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.23	top5: 99.33	
[09/17 09:41:09 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/17 09:41:18 visual_prompt]: Epoch 68 / 100: avg data time: 1.13e-01, avg batch time: 0.5154, average train loss: 1.1070
[09/17 09:41:21 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1432, average loss: 1.3934
[09/17 09:41:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 100.00	
[09/17 09:41:43 visual_prompt]: 	Test 100/235. loss: 1.646, 0.1837 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 09:42:02 visual_prompt]: 	Test 200/235. loss: 1.785, 0.1940 s / batch. (data: 1.07e-04)max mem: 17.22447 GB 
[09/17 09:42:10 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1946, average loss: 1.5329
[09/17 09:42:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.64	top5: 98.87	
[09/17 09:42:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/17 09:42:20 visual_prompt]: Epoch 69 / 100: avg data time: 1.09e-01, avg batch time: 0.5144, average train loss: 1.2191
[09/17 09:42:23 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1431, average loss: 1.0407
[09/17 09:42:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 52.00	top5: 100.00	
[09/17 09:42:44 visual_prompt]: 	Test 100/235. loss: 1.279, 0.2000 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 09:43:04 visual_prompt]: 	Test 200/235. loss: 1.263, 0.2043 s / batch. (data: 1.16e-02)max mem: 17.22447 GB 
[09/17 09:43:12 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1942, average loss: 1.1726
[09/17 09:43:12 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.21	top5: 99.87	
[09/17 09:43:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/17 09:43:21 visual_prompt]: Epoch 70 / 100: avg data time: 1.22e-01, avg batch time: 0.5245, average train loss: 1.0342
[09/17 09:43:25 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1432, average loss: 1.0390
[09/17 09:43:25 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 52.00	top5: 100.00	
[09/17 09:43:46 visual_prompt]: 	Test 100/235. loss: 1.439, 0.1860 s / batch. (data: 2.52e-04)max mem: 17.22447 GB 
[09/17 09:44:06 visual_prompt]: 	Test 200/235. loss: 1.161, 0.2058 s / batch. (data: 1.54e-02)max mem: 17.22447 GB 
[09/17 09:44:13 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1940, average loss: 1.3083
[09/17 09:44:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.33	top5: 99.54	
[09/17 09:44:14 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/17 09:44:23 visual_prompt]: Epoch 71 / 100: avg data time: 1.16e-01, avg batch time: 0.5195, average train loss: 1.0388
[09/17 09:44:26 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1431, average loss: 1.8533
[09/17 09:44:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 100.00	
[09/17 09:44:47 visual_prompt]: 	Test 100/235. loss: 2.116, 0.2076 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 09:45:07 visual_prompt]: 	Test 200/235. loss: 2.125, 0.1838 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 09:45:15 visual_prompt]: Inference (test):avg data time: 6.94e-03, avg batch time: 0.1932, average loss: 2.0092
[09/17 09:45:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.55	top5: 98.81	
[09/17 09:45:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/17 09:45:24 visual_prompt]: Epoch 72 / 100: avg data time: 9.91e-02, avg batch time: 0.5064, average train loss: 1.2138
[09/17 09:45:27 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1431, average loss: 1.1482
[09/17 09:45:27 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 50.50	top5: 100.00	
[09/17 09:45:49 visual_prompt]: 	Test 100/235. loss: 1.402, 0.1841 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 09:46:08 visual_prompt]: 	Test 200/235. loss: 1.410, 0.2150 s / batch. (data: 1.31e-02)max mem: 17.22447 GB 
[09/17 09:46:16 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1952, average loss: 1.3314
[09/17 09:46:16 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.24	top5: 99.15	
[09/17 09:46:16 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/17 09:46:26 visual_prompt]: Epoch 73 / 100: avg data time: 1.06e-01, avg batch time: 0.5104, average train loss: 0.9639
[09/17 09:46:29 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1429, average loss: 0.7670
[09/17 09:46:29 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 70.00	top5: 100.00	
[09/17 09:46:50 visual_prompt]: 	Test 100/235. loss: 1.083, 0.2078 s / batch. (data: 2.48e-02)max mem: 17.22447 GB 
[09/17 09:47:10 visual_prompt]: 	Test 200/235. loss: 0.997, 0.1963 s / batch. (data: 1.33e-02)max mem: 17.22447 GB 
[09/17 09:47:18 visual_prompt]: Inference (test):avg data time: 6.51e-03, avg batch time: 0.1954, average loss: 1.0090
[09/17 09:47:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 55.31	top5: 99.96	
[09/17 09:47:18 visual_prompt]: Best epoch 73: best metric: 0.700
[09/17 09:47:18 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/17 09:47:27 visual_prompt]: Epoch 74 / 100: avg data time: 1.07e-01, avg batch time: 0.5111, average train loss: 0.8825
[09/17 09:47:30 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1464, average loss: 1.0003
[09/17 09:47:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 51.00	top5: 100.00	
[09/17 09:47:52 visual_prompt]: 	Test 100/235. loss: 1.398, 0.1836 s / batch. (data: 1.81e-04)max mem: 17.22447 GB 
[09/17 09:48:11 visual_prompt]: 	Test 200/235. loss: 1.144, 0.1837 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 09:48:19 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1928, average loss: 1.3132
[09/17 09:48:19 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.67	top5: 99.80	
[09/17 09:48:19 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/17 09:48:28 visual_prompt]: Epoch 75 / 100: avg data time: 1.18e-01, avg batch time: 0.5221, average train loss: 1.0703
[09/17 09:48:32 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1431, average loss: 1.1629
[09/17 09:48:32 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 42.00	top5: 100.00	
[09/17 09:48:53 visual_prompt]: 	Test 100/235. loss: 1.473, 0.2138 s / batch. (data: 2.51e-02)max mem: 17.22447 GB 
[09/17 09:49:12 visual_prompt]: 	Test 200/235. loss: 1.412, 0.1845 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 09:49:20 visual_prompt]: Inference (test):avg data time: 8.73e-03, avg batch time: 0.1938, average loss: 1.4237
[09/17 09:49:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.35	top5: 99.81	
[09/17 09:49:20 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/17 09:49:30 visual_prompt]: Epoch 76 / 100: avg data time: 1.13e-01, avg batch time: 0.5175, average train loss: 1.0693
[09/17 09:49:33 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1431, average loss: 0.7282
[09/17 09:49:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 73.00	top5: 100.00	
[09/17 09:49:54 visual_prompt]: 	Test 100/235. loss: 1.107, 0.1975 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 09:50:14 visual_prompt]: 	Test 200/235. loss: 0.959, 0.1967 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 09:50:22 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1946, average loss: 1.0035
[09/17 09:50:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 54.61	top5: 99.99	
[09/17 09:50:22 visual_prompt]: Best epoch 76: best metric: 0.730
[09/17 09:50:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/17 09:50:31 visual_prompt]: Epoch 77 / 100: avg data time: 1.16e-01, avg batch time: 0.5193, average train loss: 0.9961
[09/17 09:50:35 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1430, average loss: 1.0301
[09/17 09:50:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 51.00	top5: 100.00	
[09/17 09:50:56 visual_prompt]: 	Test 100/235. loss: 1.479, 0.1958 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 09:51:16 visual_prompt]: 	Test 200/235. loss: 1.389, 0.1941 s / batch. (data: 1.11e-02)max mem: 17.22447 GB 
[09/17 09:51:23 visual_prompt]: Inference (test):avg data time: 8.84e-03, avg batch time: 0.1945, average loss: 1.3213
[09/17 09:51:23 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.73	top5: 99.80	
[09/17 09:51:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/17 09:51:33 visual_prompt]: Epoch 78 / 100: avg data time: 1.15e-01, avg batch time: 0.5174, average train loss: 1.0125
[09/17 09:51:36 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1429, average loss: 0.9000
[09/17 09:51:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 56.00	top5: 100.00	
[09/17 09:51:58 visual_prompt]: 	Test 100/235. loss: 1.266, 0.1834 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 09:52:17 visual_prompt]: 	Test 200/235. loss: 1.068, 0.1901 s / batch. (data: 1.82e-04)max mem: 17.22447 GB 
[09/17 09:52:25 visual_prompt]: Inference (test):avg data time: 6.22e-03, avg batch time: 0.1938, average loss: 1.1754
[09/17 09:52:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.61	top5: 99.93	
[09/17 09:52:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/17 09:52:34 visual_prompt]: Epoch 79 / 100: avg data time: 1.16e-01, avg batch time: 0.5196, average train loss: 0.8483
[09/17 09:52:37 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1433, average loss: 0.6821
[09/17 09:52:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.50	top5: 100.00	
[09/17 09:52:59 visual_prompt]: 	Test 100/235. loss: 1.062, 0.1839 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 09:53:19 visual_prompt]: 	Test 200/235. loss: 1.007, 0.1843 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 09:53:27 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1952, average loss: 0.9975
[09/17 09:53:27 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.00	top5: 99.97	
[09/17 09:53:27 visual_prompt]: Best epoch 79: best metric: 0.745
[09/17 09:53:27 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/17 09:53:36 visual_prompt]: Epoch 80 / 100: avg data time: 9.39e-02, avg batch time: 0.5009, average train loss: 0.7506
[09/17 09:53:39 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1432, average loss: 0.6065
[09/17 09:53:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 09:54:01 visual_prompt]: 	Test 100/235. loss: 1.091, 0.1838 s / batch. (data: 1.13e-04)max mem: 17.22447 GB 
[09/17 09:54:20 visual_prompt]: 	Test 200/235. loss: 1.074, 0.1838 s / batch. (data: 1.46e-04)max mem: 17.22447 GB 
[09/17 09:54:28 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1967, average loss: 0.9966
[09/17 09:54:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.92	top5: 99.98	
[09/17 09:54:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/17 09:54:38 visual_prompt]: Epoch 81 / 100: avg data time: 1.14e-01, avg batch time: 0.5183, average train loss: 0.7770
[09/17 09:54:41 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1432, average loss: 0.5957
[09/17 09:54:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 76.50	top5: 100.00	
[09/17 09:55:02 visual_prompt]: 	Test 100/235. loss: 1.107, 0.1961 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 09:55:22 visual_prompt]: 	Test 200/235. loss: 1.065, 0.1880 s / batch. (data: 1.61e-04)max mem: 17.22447 GB 
[09/17 09:55:30 visual_prompt]: Inference (test):avg data time: 6.80e-03, avg batch time: 0.1937, average loss: 1.0091
[09/17 09:55:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 57.63	top5: 99.99	
[09/17 09:55:30 visual_prompt]: Best epoch 81: best metric: 0.765
[09/17 09:55:30 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/17 09:55:39 visual_prompt]: Epoch 82 / 100: avg data time: 1.07e-01, avg batch time: 0.5110, average train loss: 0.6569
[09/17 09:55:43 visual_prompt]: Inference (val):avg data time: 4.74e-05, avg batch time: 0.2876, average loss: 0.5610
[09/17 09:55:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 77.00	top5: 100.00	
[09/17 09:56:04 visual_prompt]: 	Test 100/235. loss: 1.166, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 09:56:24 visual_prompt]: 	Test 200/235. loss: 1.129, 0.1895 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 09:56:32 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1962, average loss: 1.0582
[09/17 09:56:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 55.56	top5: 99.97	
[09/17 09:56:32 visual_prompt]: Best epoch 82: best metric: 0.770
[09/17 09:56:32 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/17 09:56:42 visual_prompt]: Epoch 83 / 100: avg data time: 1.12e-01, avg batch time: 0.5174, average train loss: 0.6507
[09/17 09:56:45 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1431, average loss: 0.7848
[09/17 09:56:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 60.50	top5: 100.00	
[09/17 09:57:06 visual_prompt]: 	Test 100/235. loss: 1.198, 0.1872 s / batch. (data: 1.48e-04)max mem: 17.22447 GB 
[09/17 09:57:26 visual_prompt]: 	Test 200/235. loss: 1.088, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 09:57:34 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1948, average loss: 1.3412
[09/17 09:57:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 50.22	top5: 99.90	
[09/17 09:57:34 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/17 09:57:43 visual_prompt]: Epoch 84 / 100: avg data time: 1.21e-01, avg batch time: 0.5236, average train loss: 0.7466
[09/17 09:57:46 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1448, average loss: 0.6223
[09/17 09:57:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 69.50	top5: 100.00	
[09/17 09:58:08 visual_prompt]: 	Test 100/235. loss: 1.080, 0.1843 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 09:58:27 visual_prompt]: 	Test 200/235. loss: 0.982, 0.2030 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 09:58:35 visual_prompt]: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1939, average loss: 1.0749
[09/17 09:58:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 55.75	top5: 99.97	
[09/17 09:58:35 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/17 09:58:45 visual_prompt]: Epoch 85 / 100: avg data time: 1.19e-01, avg batch time: 0.5216, average train loss: 0.5975
[09/17 09:58:48 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1432, average loss: 0.6189
[09/17 09:58:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 71.00	top5: 100.00	
[09/17 09:59:09 visual_prompt]: 	Test 100/235. loss: 1.328, 0.1833 s / batch. (data: 4.58e-05)max mem: 17.22447 GB 
[09/17 09:59:29 visual_prompt]: 	Test 200/235. loss: 1.298, 0.2094 s / batch. (data: 1.77e-02)max mem: 17.22447 GB 
[09/17 09:59:37 visual_prompt]: Inference (test):avg data time: 7.03e-03, avg batch time: 0.1945, average loss: 1.1818
[09/17 09:59:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 53.93	top5: 99.94	
[09/17 09:59:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 09:59:46 visual_prompt]: Epoch 86 / 100: avg data time: 1.16e-01, avg batch time: 0.5187, average train loss: 0.5581
[09/17 09:59:50 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1432, average loss: 0.4407
[09/17 09:59:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 83.00	top5: 100.00	
[09/17 10:00:11 visual_prompt]: 	Test 100/235. loss: 1.192, 0.1925 s / batch. (data: 9.77e-03)max mem: 17.22447 GB 
[09/17 10:00:30 visual_prompt]: 	Test 200/235. loss: 1.059, 0.1983 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 10:00:38 visual_prompt]: Inference (test):avg data time: 6.63e-03, avg batch time: 0.1933, average loss: 1.0804
[09/17 10:00:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.91	top5: 99.98	
[09/17 10:00:38 visual_prompt]: Best epoch 86: best metric: 0.830
[09/17 10:00:38 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 10:00:48 visual_prompt]: Epoch 87 / 100: avg data time: 1.15e-01, avg batch time: 0.5205, average train loss: 0.4940
[09/17 10:00:51 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1430, average loss: 0.6484
[09/17 10:00:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 10:01:12 visual_prompt]: 	Test 100/235. loss: 1.463, 0.1837 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 10:01:32 visual_prompt]: 	Test 200/235. loss: 1.316, 0.1839 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 10:01:40 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1935, average loss: 1.2830
[09/17 10:01:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 55.41	top5: 99.98	
[09/17 10:01:40 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 10:01:49 visual_prompt]: Epoch 88 / 100: avg data time: 1.23e-01, avg batch time: 0.5269, average train loss: 0.5238
[09/17 10:01:52 visual_prompt]: Inference (val):avg data time: 5.00e-05, avg batch time: 0.1432, average loss: 0.9843
[09/17 10:01:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 60.00	top5: 100.00	
[09/17 10:02:13 visual_prompt]: 	Test 100/235. loss: 1.798, 0.1844 s / batch. (data: 1.08e-04)max mem: 17.22447 GB 
[09/17 10:02:33 visual_prompt]: 	Test 200/235. loss: 1.878, 0.1836 s / batch. (data: 1.19e-04)max mem: 17.22447 GB 
[09/17 10:02:41 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1930, average loss: 1.6071
[09/17 10:02:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.53	top5: 99.89	
[09/17 10:02:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 10:02:50 visual_prompt]: Epoch 89 / 100: avg data time: 1.17e-01, avg batch time: 0.5191, average train loss: 0.6256
[09/17 10:02:54 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1430, average loss: 0.4379
[09/17 10:02:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 81.50	top5: 100.00	
[09/17 10:03:15 visual_prompt]: 	Test 100/235. loss: 1.173, 0.1840 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 10:03:35 visual_prompt]: 	Test 200/235. loss: 1.026, 0.1840 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 10:03:43 visual_prompt]: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1949, average loss: 1.1573
[09/17 10:03:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 57.07	top5: 99.95	
[09/17 10:03:43 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 10:03:52 visual_prompt]: Epoch 90 / 100: avg data time: 1.14e-01, avg batch time: 0.5169, average train loss: 0.4573
[09/17 10:03:56 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1432, average loss: 0.3493
[09/17 10:03:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 86.50	top5: 100.00	
[09/17 10:04:18 visual_prompt]: 	Test 100/235. loss: 1.195, 0.1833 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 10:04:37 visual_prompt]: 	Test 200/235. loss: 1.007, 0.1835 s / batch. (data: 1.79e-04)max mem: 17.22447 GB 
[09/17 10:04:45 visual_prompt]: Inference (test):avg data time: 8.97e-03, avg batch time: 0.1957, average loss: 1.1102
[09/17 10:04:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.11	top5: 99.95	
[09/17 10:04:45 visual_prompt]: Best epoch 90: best metric: 0.865
[09/17 10:04:45 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 10:04:54 visual_prompt]: Epoch 91 / 100: avg data time: 1.10e-01, avg batch time: 0.5118, average train loss: 0.4555
[09/17 10:04:57 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1429, average loss: 0.4030
[09/17 10:04:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 83.00	top5: 100.00	
[09/17 10:05:19 visual_prompt]: 	Test 100/235. loss: 1.174, 0.1961 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 10:05:38 visual_prompt]: 	Test 200/235. loss: 1.114, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 10:05:46 visual_prompt]: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1932, average loss: 1.2007
[09/17 10:05:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 57.90	top5: 99.93	
[09/17 10:05:46 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 10:05:56 visual_prompt]: Epoch 92 / 100: avg data time: 1.11e-01, avg batch time: 0.5188, average train loss: 0.4578
[09/17 10:05:59 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1436, average loss: 0.4016
[09/17 10:05:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 85.50	top5: 100.00	
[09/17 10:06:20 visual_prompt]: 	Test 100/235. loss: 1.307, 0.1977 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 10:06:40 visual_prompt]: 	Test 200/235. loss: 1.234, 0.2011 s / batch. (data: 1.79e-02)max mem: 17.22447 GB 
[09/17 10:06:48 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1937, average loss: 1.2107
[09/17 10:06:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 58.08	top5: 99.98	
[09/17 10:06:48 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 10:06:57 visual_prompt]: Epoch 93 / 100: avg data time: 9.81e-02, avg batch time: 0.5056, average train loss: 0.3564
[09/17 10:07:00 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1435, average loss: 0.2795
[09/17 10:07:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.00	top5: 100.00	
[09/17 10:07:21 visual_prompt]: 	Test 100/235. loss: 1.204, 0.1928 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 10:07:40 visual_prompt]: 	Test 200/235. loss: 1.125, 0.1993 s / batch. (data: 1.54e-04)max mem: 17.22447 GB 
[09/17 10:07:48 visual_prompt]: Inference (test):avg data time: 6.21e-03, avg batch time: 0.1928, average loss: 1.1452
[09/17 10:07:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.89	top5: 99.98	
[09/17 10:07:48 visual_prompt]: Best epoch 93: best metric: 0.920
[09/17 10:07:48 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 10:07:58 visual_prompt]: Epoch 94 / 100: avg data time: 1.12e-01, avg batch time: 0.5141, average train loss: 0.3243
[09/17 10:08:01 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.1466, average loss: 0.2653
[09/17 10:08:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.50	top5: 100.00	
[09/17 10:08:22 visual_prompt]: 	Test 100/235. loss: 1.209, 0.2003 s / batch. (data: 1.65e-02)max mem: 17.22447 GB 
[09/17 10:08:42 visual_prompt]: 	Test 200/235. loss: 1.110, 0.2233 s / batch. (data: 4.02e-02)max mem: 17.22447 GB 
[09/17 10:08:50 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1946, average loss: 1.1769
[09/17 10:08:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.60	top5: 99.97	
[09/17 10:08:50 visual_prompt]: Best epoch 94: best metric: 0.925
[09/17 10:08:50 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 10:08:59 visual_prompt]: Epoch 95 / 100: avg data time: 1.15e-01, avg batch time: 0.5176, average train loss: 0.3182
[09/17 10:09:02 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1432, average loss: 0.2629
[09/17 10:09:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 93.00	top5: 100.00	
[09/17 10:09:24 visual_prompt]: 	Test 100/235. loss: 1.245, 0.1894 s / batch. (data: 1.09e-04)max mem: 17.22447 GB 
[09/17 10:09:43 visual_prompt]: 	Test 200/235. loss: 1.110, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 10:09:51 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1947, average loss: 1.2169
[09/17 10:09:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.14	top5: 99.95	
[09/17 10:09:51 visual_prompt]: Best epoch 95: best metric: 0.930
[09/17 10:09:51 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 10:10:01 visual_prompt]: Epoch 96 / 100: avg data time: 1.14e-01, avg batch time: 0.5179, average train loss: 0.3080
[09/17 10:10:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1439, average loss: 0.2498
[09/17 10:10:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 93.00	top5: 100.00	
[09/17 10:10:25 visual_prompt]: 	Test 100/235. loss: 1.248, 0.1835 s / batch. (data: 1.08e-04)max mem: 17.22447 GB 
[09/17 10:10:45 visual_prompt]: 	Test 200/235. loss: 1.184, 0.1996 s / batch. (data: 1.08e-02)max mem: 17.22447 GB 
[09/17 10:10:53 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1938, average loss: 1.2083
[09/17 10:10:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.07	top5: 99.98	
[09/17 10:10:53 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 10:11:02 visual_prompt]: Epoch 97 / 100: avg data time: 1.12e-01, avg batch time: 0.5168, average train loss: 0.2961
[09/17 10:11:05 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1430, average loss: 0.2194
[09/17 10:11:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 96.00	top5: 100.00	
[09/17 10:11:27 visual_prompt]: 	Test 100/235. loss: 1.222, 0.1975 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 10:11:46 visual_prompt]: 	Test 200/235. loss: 1.135, 0.1985 s / batch. (data: 9.82e-05)max mem: 17.22447 GB 
[09/17 10:11:54 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1930, average loss: 1.2091
[09/17 10:11:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.08	top5: 99.97	
[09/17 10:11:54 visual_prompt]: Best epoch 97: best metric: 0.960
[09/17 10:11:54 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 10:12:04 visual_prompt]: Epoch 98 / 100: avg data time: 1.13e-01, avg batch time: 0.5511, average train loss: 0.2892
[09/17 10:12:07 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1430, average loss: 0.2272
[09/17 10:12:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 94.00	top5: 100.00	
[09/17 10:12:28 visual_prompt]: 	Test 100/235. loss: 1.224, 0.1973 s / batch. (data: 1.54e-04)max mem: 17.22447 GB 
[09/17 10:12:48 visual_prompt]: 	Test 200/235. loss: 1.179, 0.1836 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 10:12:55 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1932, average loss: 1.2214
[09/17 10:12:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.97	top5: 99.97	
[09/17 10:12:56 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 10:13:05 visual_prompt]: Epoch 99 / 100: avg data time: 1.14e-01, avg batch time: 0.5150, average train loss: 0.2756
[09/17 10:13:08 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1432, average loss: 0.2253
[09/17 10:13:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 93.50	top5: 100.00	
[09/17 10:13:29 visual_prompt]: 	Test 100/235. loss: 1.233, 0.2115 s / batch. (data: 2.80e-02)max mem: 17.22447 GB 
[09/17 10:13:49 visual_prompt]: 	Test 200/235. loss: 1.207, 0.2548 s / batch. (data: 7.18e-02)max mem: 17.22447 GB 
[09/17 10:13:56 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1929, average loss: 1.2189
[09/17 10:13:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.33	top5: 99.98	
[09/17 10:13:56 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 10:14:06 visual_prompt]: Epoch 100 / 100: avg data time: 1.08e-01, avg batch time: 0.5104, average train loss: 0.2718
[09/17 10:14:09 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1432, average loss: 0.2207
[09/17 10:14:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 93.50	top5: 100.00	
[09/17 10:14:30 visual_prompt]: 	Test 100/235. loss: 1.230, 0.2002 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 10:14:50 visual_prompt]: 	Test 200/235. loss: 1.198, 0.1956 s / batch. (data: 6.20e-03)max mem: 17.22447 GB 
[09/17 10:14:57 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1932, average loss: 1.2180
[09/17 10:14:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.28	top5: 99.98	
[09/17 10:15:13 visual_prompt]: Rank of current process: 0. World size: 1
[09/17 10:15:13 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 10:15:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-clevr(task="count_all")', 'DATA.NUMBER_CLASSES', '8', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/17 10:15:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 10:15:13 visual_prompt]: Training with config:
[09/17 10:15:13 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-clevr(task="count_all")',
          'NO_TEST': False,
          'NUMBER_CLASSES': 8,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-clevr(task="count_all")/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 10:15:13 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-17 10:15:13.161192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-17 10:15:13.327891: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-17 10:15:14.254875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 10:15:14.254958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 10:15:14.254968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-17 10:15:16.327235: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 10:15:16.327355: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 10:15:16.327373: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/17 10:15:16 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
2023-09-17 10:15:16.353343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[:800]+train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 10:15:21 visual_prompt]: Number of images: 1000
[09/17 10:15:21 visual_prompt]: Number of classes: 8 / 8
[09/17 10:15:21 visual_prompt]: Loading validation data...
[09/17 10:15:21 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 10:15:23 visual_prompt]: Number of images: 200
[09/17 10:15:23 visual_prompt]: Number of classes: 8 / 8
[09/17 10:15:23 visual_prompt]: Loading test data...
[09/17 10:15:23 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split validation, from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 10:16:39 visual_prompt]: Number of images: 15000
[09/17 10:16:39 visual_prompt]: Number of classes: 8 / 8
[09/17 10:16:39 visual_prompt]: Constructing models...
[09/17 10:16:42 visual_prompt]: Total Parameters: 86726408	 Gradient Parameters: 927752
[09/17 10:16:42 visual_prompt]: tuned percent:1.070
[09/17 10:16:44 visual_prompt]: Device used for model: 0
[09/17 10:16:44 visual_prompt]: Setting up Evalutator...
[09/17 10:16:44 visual_prompt]: Setting up Trainer...
[09/17 10:16:44 visual_prompt]: 	Setting up the optimizer...
[09/17 10:16:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/17 10:16:55 visual_prompt]: Epoch 1 / 100: avg data time: 1.26e-01, avg batch time: 0.5975, average train loss: 2.3526
[09/17 10:16:58 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1422, average loss: 2.3642
[09/17 10:16:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 57.50	
[09/17 10:17:19 visual_prompt]: 	Test 100/235. loss: 2.264, 0.1826 s / batch. (data: 1.63e-04)max mem: 17.22447 GB 
[09/17 10:17:39 visual_prompt]: 	Test 200/235. loss: 2.321, 0.1962 s / batch. (data: 1.38e-02)max mem: 17.22447 GB 
[09/17 10:17:47 visual_prompt]: Inference (test):avg data time: 6.76e-03, avg batch time: 0.1923, average loss: 2.3257
[09/17 10:17:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 13.31	top5: 61.60	
[09/17 10:17:47 visual_prompt]: Best epoch 1: best metric: 0.140
[09/17 10:17:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/17 10:17:56 visual_prompt]: Epoch 2 / 100: avg data time: 1.12e-01, avg batch time: 0.5193, average train loss: 3.1198
[09/17 10:17:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1428, average loss: 2.1941
[09/17 10:17:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 66.00	
[09/17 10:18:21 visual_prompt]: 	Test 100/235. loss: 2.333, 0.1832 s / batch. (data: 1.37e-04)max mem: 17.22447 GB 
[09/17 10:18:40 visual_prompt]: 	Test 200/235. loss: 2.246, 0.2076 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 10:18:48 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1939, average loss: 2.1968
[09/17 10:18:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.97	
[09/17 10:18:48 visual_prompt]: Best epoch 2: best metric: 0.145
[09/17 10:18:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/17 10:18:57 visual_prompt]: Epoch 3 / 100: avg data time: 1.13e-01, avg batch time: 0.5147, average train loss: 2.2117
[09/17 10:19:01 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1429, average loss: 2.1542
[09/17 10:19:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.50	top5: 65.50	
[09/17 10:19:22 visual_prompt]: 	Test 100/235. loss: 2.149, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 10:19:41 visual_prompt]: 	Test 200/235. loss: 2.226, 0.1841 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 10:19:49 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1942, average loss: 2.1708
[09/17 10:19:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.16	top5: 62.90	
[09/17 10:19:50 visual_prompt]: Best epoch 3: best metric: 0.245
[09/17 10:19:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/17 10:19:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e-01, avg batch time: 0.5306, average train loss: 2.3503
[09/17 10:20:02 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1434, average loss: 2.3588
[09/17 10:20:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.00	top5: 69.50	
[09/17 10:20:24 visual_prompt]: 	Test 100/235. loss: 2.471, 0.1833 s / batch. (data: 1.17e-04)max mem: 17.22447 GB 
[09/17 10:20:43 visual_prompt]: 	Test 200/235. loss: 2.273, 0.2076 s / batch. (data: 2.43e-02)max mem: 17.22447 GB 
[09/17 10:20:51 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1939, average loss: 2.3814
[09/17 10:20:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.78	top5: 65.79	
[09/17 10:20:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/17 10:21:01 visual_prompt]: Epoch 5 / 100: avg data time: 1.15e-01, avg batch time: 0.5198, average train loss: 2.4684
[09/17 10:21:04 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1433, average loss: 2.1798
[09/17 10:21:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.50	top5: 73.00	
[09/17 10:21:25 visual_prompt]: 	Test 100/235. loss: 2.464, 0.1841 s / batch. (data: 4.03e-05)max mem: 17.22447 GB 
[09/17 10:21:45 visual_prompt]: 	Test 200/235. loss: 2.264, 0.1913 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 10:21:53 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1971, average loss: 2.2534
[09/17 10:21:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.38	top5: 67.57	
[09/17 10:21:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/17 10:22:02 visual_prompt]: Epoch 6 / 100: avg data time: 9.76e-02, avg batch time: 0.5026, average train loss: 3.8574
[09/17 10:22:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1433, average loss: 3.0801
[09/17 10:22:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 75.50	
[09/17 10:22:27 visual_prompt]: 	Test 100/235. loss: 2.990, 0.1836 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 10:22:46 visual_prompt]: 	Test 200/235. loss: 3.089, 0.1838 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 10:22:54 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1933, average loss: 3.1347
[09/17 10:22:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 74.45	
[09/17 10:22:54 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/17 10:23:03 visual_prompt]: Epoch 7 / 100: avg data time: 9.44e-02, avg batch time: 0.4989, average train loss: 3.5049
[09/17 10:23:07 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1432, average loss: 3.2051
[09/17 10:23:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 69.00	
[09/17 10:23:28 visual_prompt]: 	Test 100/235. loss: 3.734, 0.1833 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 10:23:47 visual_prompt]: 	Test 200/235. loss: 3.562, 0.1840 s / batch. (data: 1.55e-04)max mem: 17.22447 GB 
[09/17 10:23:55 visual_prompt]: Inference (test):avg data time: 7.18e-03, avg batch time: 0.1929, average loss: 3.4742
[09/17 10:23:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.84	top5: 63.07	
[09/17 10:23:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/17 10:24:04 visual_prompt]: Epoch 8 / 100: avg data time: 1.13e-01, avg batch time: 0.5190, average train loss: 6.8319
[09/17 10:24:08 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1461, average loss: 13.6904
[09/17 10:24:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 63.50	
[09/17 10:24:29 visual_prompt]: 	Test 100/235. loss: 12.989, 0.1833 s / batch. (data: 1.13e-04)max mem: 17.22447 GB 
[09/17 10:24:49 visual_prompt]: 	Test 200/235. loss: 13.555, 0.2179 s / batch. (data: 1.65e-02)max mem: 17.22447 GB 
[09/17 10:24:57 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1946, average loss: 13.8506
[09/17 10:24:57 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.37	
[09/17 10:24:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/17 10:25:06 visual_prompt]: Epoch 9 / 100: avg data time: 1.11e-01, avg batch time: 0.5142, average train loss: 10.3143
[09/17 10:25:09 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1433, average loss: 8.9839
[09/17 10:25:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 61.50	
[09/17 10:25:30 visual_prompt]: 	Test 100/235. loss: 9.249, 0.1962 s / batch. (data: 1.31e-02)max mem: 17.22447 GB 
[09/17 10:25:50 visual_prompt]: 	Test 200/235. loss: 9.094, 0.1999 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 10:25:58 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1933, average loss: 8.9280
[09/17 10:25:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.77	
[09/17 10:25:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/17 10:26:07 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e-01, avg batch time: 0.5209, average train loss: 11.7120
[09/17 10:26:11 visual_prompt]: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1524, average loss: 9.3116
[09/17 10:26:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 64.00	
[09/17 10:26:32 visual_prompt]: 	Test 100/235. loss: 8.629, 0.1987 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 10:26:51 visual_prompt]: 	Test 200/235. loss: 9.785, 0.2242 s / batch. (data: 1.67e-02)max mem: 17.22447 GB 
[09/17 10:26:59 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1933, average loss: 9.5925
[09/17 10:26:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.60	
[09/17 10:26:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/17 10:27:09 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e-01, avg batch time: 0.5074, average train loss: 8.5113
[09/17 10:27:12 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1433, average loss: 10.3923
[09/17 10:27:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 62.00	
[09/17 10:27:33 visual_prompt]: 	Test 100/235. loss: 10.680, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 10:27:52 visual_prompt]: 	Test 200/235. loss: 11.036, 0.1841 s / batch. (data: 1.83e-04)max mem: 17.22447 GB 
[09/17 10:28:00 visual_prompt]: Inference (test):avg data time: 7.07e-03, avg batch time: 0.1932, average loss: 10.7126
[09/17 10:28:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 61.85	
[09/17 10:28:00 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/17 10:28:10 visual_prompt]: Epoch 12 / 100: avg data time: 9.94e-02, avg batch time: 0.5061, average train loss: 10.6958
[09/17 10:28:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1434, average loss: 4.9331
[09/17 10:28:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 63.50	
[09/17 10:28:34 visual_prompt]: 	Test 100/235. loss: 4.789, 0.1837 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 10:28:53 visual_prompt]: 	Test 200/235. loss: 5.164, 0.1838 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 10:29:01 visual_prompt]: Inference (test):avg data time: 6.56e-03, avg batch time: 0.1927, average loss: 5.1618
[09/17 10:29:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.37	
[09/17 10:29:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/17 10:29:11 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e-01, avg batch time: 0.5118, average train loss: 7.7195
[09/17 10:29:14 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 10.7605
[09/17 10:29:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 62.50	
[09/17 10:29:35 visual_prompt]: 	Test 100/235. loss: 10.433, 0.1828 s / batch. (data: 9.23e-05)max mem: 17.22447 GB 
[09/17 10:29:55 visual_prompt]: 	Test 200/235. loss: 11.030, 0.1871 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 10:30:03 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1948, average loss: 10.3576
[09/17 10:30:03 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.29	top5: 62.45	
[09/17 10:30:03 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/17 10:30:12 visual_prompt]: Epoch 14 / 100: avg data time: 1.15e-01, avg batch time: 0.5205, average train loss: 10.3226
[09/17 10:30:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1432, average loss: 16.3548
[09/17 10:30:16 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 61.00	
[09/17 10:30:37 visual_prompt]: 	Test 100/235. loss: 16.265, 0.1832 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 10:30:56 visual_prompt]: 	Test 200/235. loss: 16.782, 0.1841 s / batch. (data: 1.58e-04)max mem: 17.22447 GB 
[09/17 10:31:04 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1923, average loss: 15.8541
[09/17 10:31:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.53	
[09/17 10:31:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/17 10:31:13 visual_prompt]: Epoch 15 / 100: avg data time: 1.12e-01, avg batch time: 0.5139, average train loss: 14.0096
[09/17 10:31:17 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1435, average loss: 14.9302
[09/17 10:31:17 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 64.50	
[09/17 10:31:38 visual_prompt]: 	Test 100/235. loss: 15.687, 0.1833 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 10:31:57 visual_prompt]: 	Test 200/235. loss: 15.668, 0.1981 s / batch. (data: 1.39e-02)max mem: 17.22447 GB 
[09/17 10:32:05 visual_prompt]: Inference (test):avg data time: 8.42e-03, avg batch time: 0.1939, average loss: 15.3579
[09/17 10:32:05 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.49	
[09/17 10:32:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/17 10:32:15 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e-01, avg batch time: 0.5116, average train loss: 11.6854
[09/17 10:32:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1432, average loss: 8.9871
[09/17 10:32:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 60.50	
[09/17 10:32:39 visual_prompt]: 	Test 100/235. loss: 8.334, 0.1998 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 10:32:58 visual_prompt]: 	Test 200/235. loss: 9.542, 0.1838 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 10:33:06 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1929, average loss: 9.2302
[09/17 10:33:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 61.71	
[09/17 10:33:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/17 10:33:15 visual_prompt]: Epoch 17 / 100: avg data time: 1.14e-01, avg batch time: 0.5166, average train loss: 9.0746
[09/17 10:33:19 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1431, average loss: 15.2314
[09/17 10:33:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 66.00	
[09/17 10:33:40 visual_prompt]: 	Test 100/235. loss: 16.862, 0.1954 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 10:33:59 visual_prompt]: 	Test 200/235. loss: 16.718, 0.2021 s / batch. (data: 1.09e-04)max mem: 17.22447 GB 
[09/17 10:34:07 visual_prompt]: Inference (test):avg data time: 6.50e-03, avg batch time: 0.1922, average loss: 15.6356
[09/17 10:34:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.29	top5: 62.77	
[09/17 10:34:07 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/17 10:34:16 visual_prompt]: Epoch 18 / 100: avg data time: 1.13e-01, avg batch time: 0.5142, average train loss: 11.7536
[09/17 10:34:20 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1435, average loss: 10.6368
[09/17 10:34:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 67.50	
[09/17 10:34:41 visual_prompt]: 	Test 100/235. loss: 8.629, 0.1841 s / batch. (data: 1.14e-04)max mem: 17.22447 GB 
[09/17 10:35:00 visual_prompt]: 	Test 200/235. loss: 10.500, 0.1997 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 10:35:08 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1926, average loss: 10.3865
[09/17 10:35:08 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 63.15	
[09/17 10:35:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/17 10:35:17 visual_prompt]: Epoch 19 / 100: avg data time: 9.54e-02, avg batch time: 0.5048, average train loss: 6.7396
[09/17 10:35:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1430, average loss: 4.6045
[09/17 10:35:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 68.50	
[09/17 10:35:42 visual_prompt]: 	Test 100/235. loss: 5.113, 0.2073 s / batch. (data: 3.26e-04)max mem: 17.22447 GB 
[09/17 10:36:01 visual_prompt]: 	Test 200/235. loss: 5.112, 0.1971 s / batch. (data: 1.39e-02)max mem: 17.22447 GB 
[09/17 10:36:09 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1934, average loss: 5.0623
[09/17 10:36:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.83	
[09/17 10:36:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/17 10:36:19 visual_prompt]: Epoch 20 / 100: avg data time: 9.92e-02, avg batch time: 0.5047, average train loss: 4.4815
[09/17 10:36:22 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1430, average loss: 5.3125
[09/17 10:36:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 69.00	
[09/17 10:36:43 visual_prompt]: 	Test 100/235. loss: 5.956, 0.2092 s / batch. (data: 2.67e-02)max mem: 17.22447 GB 
[09/17 10:37:03 visual_prompt]: 	Test 200/235. loss: 5.894, 0.1942 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 10:37:11 visual_prompt]: Inference (test):avg data time: 9.53e-03, avg batch time: 0.1949, average loss: 5.8303
[09/17 10:37:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 63.06	
[09/17 10:37:11 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/17 10:37:20 visual_prompt]: Epoch 21 / 100: avg data time: 1.09e-01, avg batch time: 0.5122, average train loss: 4.7017
[09/17 10:37:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1436, average loss: 4.4510
[09/17 10:37:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 61.00	
[09/17 10:37:44 visual_prompt]: 	Test 100/235. loss: 5.321, 0.1839 s / batch. (data: 1.47e-04)max mem: 17.22447 GB 
[09/17 10:38:04 visual_prompt]: 	Test 200/235. loss: 4.633, 0.2140 s / batch. (data: 1.12e-02)max mem: 17.22447 GB 
[09/17 10:38:12 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1934, average loss: 4.4765
[09/17 10:38:12 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.63	
[09/17 10:38:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/17 10:38:21 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e-01, avg batch time: 0.5101, average train loss: 3.5982
[09/17 10:38:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1432, average loss: 3.1177
[09/17 10:38:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 65.50	
[09/17 10:38:45 visual_prompt]: 	Test 100/235. loss: 3.405, 0.1836 s / batch. (data: 1.05e-04)max mem: 17.22447 GB 
[09/17 10:39:05 visual_prompt]: 	Test 200/235. loss: 3.352, 0.1963 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 10:39:13 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1940, average loss: 3.3219
[09/17 10:39:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.17	
[09/17 10:39:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/17 10:39:22 visual_prompt]: Epoch 23 / 100: avg data time: 1.20e-01, avg batch time: 0.5215, average train loss: 2.8617
[09/17 10:39:26 visual_prompt]: Inference (val):avg data time: 4.83e-04, avg batch time: 0.2694, average loss: 3.0240
[09/17 10:39:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 67.50	
[09/17 10:39:47 visual_prompt]: 	Test 100/235. loss: 3.274, 0.1837 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 10:40:07 visual_prompt]: 	Test 200/235. loss: 3.262, 0.1996 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 10:40:15 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1966, average loss: 3.2469
[09/17 10:40:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 14.39	top5: 63.15	
[09/17 10:40:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/17 10:40:25 visual_prompt]: Epoch 24 / 100: avg data time: 1.11e-01, avg batch time: 0.5132, average train loss: 2.5772
[09/17 10:40:28 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1431, average loss: 2.6762
[09/17 10:40:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.00	top5: 76.50	
[09/17 10:40:49 visual_prompt]: 	Test 100/235. loss: 2.660, 0.1848 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 10:41:09 visual_prompt]: 	Test 200/235. loss: 2.763, 0.1840 s / batch. (data: 1.74e-04)max mem: 17.22447 GB 
[09/17 10:41:17 visual_prompt]: Inference (test):avg data time: 8.60e-03, avg batch time: 0.1947, average loss: 2.7761
[09/17 10:41:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.06	top5: 77.01	
[09/17 10:41:17 visual_prompt]: Best epoch 24: best metric: 0.270
[09/17 10:41:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/17 10:41:26 visual_prompt]: Epoch 25 / 100: avg data time: 1.13e-01, avg batch time: 0.5193, average train loss: 2.8043
[09/17 10:41:29 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1430, average loss: 1.6624
[09/17 10:41:29 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.00	top5: 92.00	
[09/17 10:41:51 visual_prompt]: 	Test 100/235. loss: 1.800, 0.1986 s / batch. (data: 1.54e-02)max mem: 17.22447 GB 
[09/17 10:42:10 visual_prompt]: 	Test 200/235. loss: 1.735, 0.2068 s / batch. (data: 2.09e-02)max mem: 17.22447 GB 
[09/17 10:42:18 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1939, average loss: 1.6938
[09/17 10:42:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.98	top5: 88.26	
[09/17 10:42:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/17 10:42:28 visual_prompt]: Epoch 26 / 100: avg data time: 1.22e-01, avg batch time: 0.5288, average train loss: 2.2371
[09/17 10:42:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1431, average loss: 2.0428
[09/17 10:42:31 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 31.00	top5: 86.00	
[09/17 10:42:52 visual_prompt]: 	Test 100/235. loss: 2.225, 0.1958 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 10:43:12 visual_prompt]: 	Test 200/235. loss: 2.244, 0.1988 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 10:43:20 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1954, average loss: 2.1321
[09/17 10:43:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.64	top5: 83.13	
[09/17 10:43:20 visual_prompt]: Best epoch 26: best metric: 0.310
[09/17 10:43:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/17 10:43:29 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e-01, avg batch time: 0.5080, average train loss: 2.0131
[09/17 10:43:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1432, average loss: 2.1365
[09/17 10:43:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.50	top5: 86.50	
[09/17 10:43:54 visual_prompt]: 	Test 100/235. loss: 2.086, 0.2004 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 10:44:14 visual_prompt]: 	Test 200/235. loss: 2.281, 0.1845 s / batch. (data: 1.68e-04)max mem: 17.22447 GB 
[09/17 10:44:22 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1949, average loss: 2.1561
[09/17 10:44:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.73	top5: 86.19	
[09/17 10:44:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/17 10:44:31 visual_prompt]: Epoch 28 / 100: avg data time: 1.21e-01, avg batch time: 0.5249, average train loss: 2.1051
[09/17 10:44:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1431, average loss: 2.2743
[09/17 10:44:34 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.00	top5: 86.50	
[09/17 10:44:55 visual_prompt]: 	Test 100/235. loss: 2.251, 0.1843 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 10:45:15 visual_prompt]: 	Test 200/235. loss: 2.230, 0.2038 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 10:45:23 visual_prompt]: Inference (test):avg data time: 6.58e-03, avg batch time: 0.1927, average loss: 2.3343
[09/17 10:45:23 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.95	top5: 88.49	
[09/17 10:45:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/17 10:45:32 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e-01, avg batch time: 0.5100, average train loss: 1.9069
[09/17 10:45:35 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1432, average loss: 1.4739
[09/17 10:45:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.00	top5: 100.00	
[09/17 10:45:56 visual_prompt]: 	Test 100/235. loss: 1.712, 0.2084 s / batch. (data: 2.50e-02)max mem: 17.22447 GB 
[09/17 10:46:16 visual_prompt]: 	Test 200/235. loss: 1.556, 0.1842 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 10:46:24 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1932, average loss: 1.5037
[09/17 10:46:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.25	top5: 98.51	
[09/17 10:46:24 visual_prompt]: Best epoch 29: best metric: 0.320
[09/17 10:46:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/17 10:46:33 visual_prompt]: Epoch 30 / 100: avg data time: 1.02e-01, avg batch time: 0.5077, average train loss: 1.5473
[09/17 10:46:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1431, average loss: 2.2515
[09/17 10:46:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.50	top5: 91.00	
[09/17 10:46:57 visual_prompt]: 	Test 100/235. loss: 2.680, 0.1851 s / batch. (data: 4.41e-05)max mem: 17.22447 GB 
[09/17 10:47:17 visual_prompt]: 	Test 200/235. loss: 2.317, 0.1900 s / batch. (data: 1.30e-04)max mem: 17.22447 GB 
[09/17 10:47:25 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1938, average loss: 2.3547
[09/17 10:47:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.10	top5: 90.19	
[09/17 10:47:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/17 10:47:34 visual_prompt]: Epoch 31 / 100: avg data time: 1.24e-01, avg batch time: 0.5275, average train loss: 1.7523
[09/17 10:47:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1430, average loss: 1.4974
[09/17 10:47:38 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 45.50	top5: 91.50	
[09/17 10:47:59 visual_prompt]: 	Test 100/235. loss: 1.683, 0.1944 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 10:48:18 visual_prompt]: 	Test 200/235. loss: 1.535, 0.1844 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 10:48:26 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1932, average loss: 1.5081
[09/17 10:48:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.89	top5: 91.98	
[09/17 10:48:26 visual_prompt]: Best epoch 31: best metric: 0.455
[09/17 10:48:26 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/17 10:48:36 visual_prompt]: Epoch 32 / 100: avg data time: 1.17e-01, avg batch time: 0.5204, average train loss: 1.8918
[09/17 10:48:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1430, average loss: 2.0999
[09/17 10:48:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.50	top5: 85.50	
[09/17 10:49:00 visual_prompt]: 	Test 100/235. loss: 2.307, 0.1836 s / batch. (data: 1.57e-04)max mem: 17.22447 GB 
[09/17 10:49:20 visual_prompt]: 	Test 200/235. loss: 1.960, 0.2066 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 10:49:27 visual_prompt]: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1934, average loss: 2.1670
[09/17 10:49:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.54	top5: 83.81	
[09/17 10:49:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/17 10:49:37 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e-01, avg batch time: 0.5088, average train loss: 2.6836
[09/17 10:49:40 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1430, average loss: 1.8955
[09/17 10:49:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.50	top5: 89.50	
[09/17 10:50:01 visual_prompt]: 	Test 100/235. loss: 2.138, 0.1880 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 10:50:21 visual_prompt]: 	Test 200/235. loss: 1.950, 0.1996 s / batch. (data: 1.57e-02)max mem: 17.22447 GB 
[09/17 10:50:29 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1944, average loss: 2.0045
[09/17 10:50:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.19	top5: 89.09	
[09/17 10:50:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/17 10:50:38 visual_prompt]: Epoch 34 / 100: avg data time: 1.09e-01, avg batch time: 0.5132, average train loss: 2.1823
[09/17 10:50:41 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1431, average loss: 2.0102
[09/17 10:50:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.50	top5: 89.00	
[09/17 10:51:03 visual_prompt]: 	Test 100/235. loss: 2.348, 0.2045 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 10:51:22 visual_prompt]: 	Test 200/235. loss: 2.218, 0.1962 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 10:51:30 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1937, average loss: 2.1004
[09/17 10:51:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.17	top5: 85.40	
[09/17 10:51:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/17 10:51:39 visual_prompt]: Epoch 35 / 100: avg data time: 1.12e-01, avg batch time: 0.5168, average train loss: 1.6241
[09/17 10:51:42 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.1430, average loss: 1.6506
[09/17 10:51:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.50	top5: 99.00	
[09/17 10:52:04 visual_prompt]: 	Test 100/235. loss: 1.793, 0.1878 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 10:52:23 visual_prompt]: 	Test 200/235. loss: 1.776, 0.1837 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 10:52:31 visual_prompt]: Inference (test):avg data time: 6.77e-03, avg batch time: 0.1927, average loss: 1.7226
[09/17 10:52:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.47	top5: 98.66	
[09/17 10:52:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/17 10:52:40 visual_prompt]: Epoch 36 / 100: avg data time: 1.14e-01, avg batch time: 0.5217, average train loss: 1.6544
[09/17 10:52:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1430, average loss: 1.5084
[09/17 10:52:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 43.00	top5: 97.00	
[09/17 10:53:05 visual_prompt]: 	Test 100/235. loss: 1.671, 0.1974 s / batch. (data: 1.38e-02)max mem: 17.22447 GB 
[09/17 10:53:24 visual_prompt]: 	Test 200/235. loss: 1.681, 0.1839 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 10:53:32 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1931, average loss: 1.5903
[09/17 10:53:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.53	top5: 97.15	
[09/17 10:53:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/17 10:53:41 visual_prompt]: Epoch 37 / 100: avg data time: 1.13e-01, avg batch time: 0.5151, average train loss: 1.5389
[09/17 10:53:45 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1432, average loss: 1.4969
[09/17 10:53:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 100.00	
[09/17 10:54:06 visual_prompt]: 	Test 100/235. loss: 1.630, 0.2064 s / batch. (data: 2.30e-02)max mem: 17.22447 GB 
[09/17 10:54:25 visual_prompt]: 	Test 200/235. loss: 1.609, 0.1834 s / batch. (data: 1.63e-04)max mem: 17.22447 GB 
[09/17 10:54:33 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1937, average loss: 1.5110
[09/17 10:54:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.60	top5: 99.14	
[09/17 10:54:33 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/17 10:54:43 visual_prompt]: Epoch 38 / 100: avg data time: 1.17e-01, avg batch time: 0.5185, average train loss: 1.6184
[09/17 10:54:46 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1432, average loss: 1.5955
[09/17 10:54:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.50	top5: 99.00	
[09/17 10:55:07 visual_prompt]: 	Test 100/235. loss: 1.898, 0.1998 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 10:55:26 visual_prompt]: 	Test 200/235. loss: 1.798, 0.1850 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 10:55:34 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1933, average loss: 1.7501
[09/17 10:55:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.60	top5: 98.37	
[09/17 10:55:34 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/17 10:55:44 visual_prompt]: Epoch 39 / 100: avg data time: 1.19e-01, avg batch time: 0.5214, average train loss: 1.4851
[09/17 10:55:47 visual_prompt]: Inference (val):avg data time: 9.97e-05, avg batch time: 0.1446, average loss: 1.6281
[09/17 10:55:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.00	top5: 98.00	
[09/17 10:56:08 visual_prompt]: 	Test 100/235. loss: 2.066, 0.1962 s / batch. (data: 1.32e-02)max mem: 17.22447 GB 
[09/17 10:56:28 visual_prompt]: 	Test 200/235. loss: 1.699, 0.2137 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 10:56:36 visual_prompt]: Inference (test):avg data time: 8.84e-03, avg batch time: 0.1959, average loss: 1.7682
[09/17 10:56:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.37	top5: 96.10	
[09/17 10:56:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/17 10:56:45 visual_prompt]: Epoch 40 / 100: avg data time: 1.13e-01, avg batch time: 0.5161, average train loss: 1.7584
[09/17 10:56:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1430, average loss: 2.8579
[09/17 10:56:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.50	top5: 79.50	
[09/17 10:57:10 visual_prompt]: 	Test 100/235. loss: 3.389, 0.1893 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 10:57:29 visual_prompt]: 	Test 200/235. loss: 3.224, 0.1980 s / batch. (data: 1.45e-02)max mem: 17.22447 GB 
[09/17 10:57:37 visual_prompt]: Inference (test):avg data time: 6.54e-03, avg batch time: 0.1926, average loss: 3.2053
[09/17 10:57:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.49	top5: 73.91	
[09/17 10:57:37 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/17 10:57:46 visual_prompt]: Epoch 41 / 100: avg data time: 9.26e-02, avg batch time: 0.4977, average train loss: 3.2959
[09/17 10:57:49 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1433, average loss: 2.7937
[09/17 10:57:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.00	top5: 73.00	
[09/17 10:58:11 visual_prompt]: 	Test 100/235. loss: 2.921, 0.1836 s / batch. (data: 1.66e-04)max mem: 17.22447 GB 
[09/17 10:58:30 visual_prompt]: 	Test 200/235. loss: 2.990, 0.2041 s / batch. (data: 1.57e-02)max mem: 17.22447 GB 
[09/17 10:58:38 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1936, average loss: 2.9632
[09/17 10:58:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.70	top5: 73.22	
[09/17 10:58:38 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/17 10:58:47 visual_prompt]: Epoch 42 / 100: avg data time: 1.11e-01, avg batch time: 0.5145, average train loss: 2.0139
[09/17 10:58:50 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1431, average loss: 1.4244
[09/17 10:58:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.00	top5: 100.00	
[09/17 10:59:12 visual_prompt]: 	Test 100/235. loss: 1.625, 0.1975 s / batch. (data: 1.36e-02)max mem: 17.22447 GB 
[09/17 10:59:31 visual_prompt]: 	Test 200/235. loss: 1.546, 0.1841 s / batch. (data: 1.17e-04)max mem: 17.22447 GB 
[09/17 10:59:39 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1949, average loss: 1.5233
[09/17 10:59:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.66	top5: 99.32	
[09/17 10:59:39 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/17 10:59:49 visual_prompt]: Epoch 43 / 100: avg data time: 1.24e-01, avg batch time: 0.5349, average train loss: 1.5185
[09/17 10:59:52 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1431, average loss: 1.9335
[09/17 10:59:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 31.00	top5: 99.00	
[09/17 11:00:13 visual_prompt]: 	Test 100/235. loss: 2.613, 0.1958 s / batch. (data: 1.32e-02)max mem: 17.22447 GB 
[09/17 11:00:33 visual_prompt]: 	Test 200/235. loss: 2.000, 0.1943 s / batch. (data: 1.11e-02)max mem: 17.22447 GB 
[09/17 11:00:41 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1951, average loss: 2.0589
[09/17 11:00:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.63	top5: 98.69	
[09/17 11:00:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/17 11:00:51 visual_prompt]: Epoch 44 / 100: avg data time: 1.10e-01, avg batch time: 0.5148, average train loss: 1.6975
[09/17 11:00:54 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1431, average loss: 1.5319
[09/17 11:00:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 98.50	
[09/17 11:01:15 visual_prompt]: 	Test 100/235. loss: 1.861, 0.1839 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 11:01:35 visual_prompt]: 	Test 200/235. loss: 1.648, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 11:01:43 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1956, average loss: 1.6379
[09/17 11:01:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.67	top5: 94.79	
[09/17 11:01:43 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/17 11:01:52 visual_prompt]: Epoch 45 / 100: avg data time: 9.97e-02, avg batch time: 0.5041, average train loss: 1.2967
[09/17 11:01:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1432, average loss: 1.7755
[09/17 11:01:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.00	top5: 96.50	
[09/17 11:02:16 visual_prompt]: 	Test 100/235. loss: 2.361, 0.1938 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 11:02:36 visual_prompt]: 	Test 200/235. loss: 1.892, 0.2077 s / batch. (data: 1.38e-02)max mem: 17.22447 GB 
[09/17 11:02:44 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1936, average loss: 1.9458
[09/17 11:02:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.23	top5: 94.09	
[09/17 11:02:44 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/17 11:02:53 visual_prompt]: Epoch 46 / 100: avg data time: 1.10e-01, avg batch time: 0.5126, average train loss: 1.4828
[09/17 11:02:56 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1433, average loss: 1.5676
[09/17 11:02:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.50	top5: 99.00	
[09/17 11:03:17 visual_prompt]: 	Test 100/235. loss: 1.922, 0.1920 s / batch. (data: 8.80e-03)max mem: 17.22447 GB 
[09/17 11:03:37 visual_prompt]: 	Test 200/235. loss: 1.665, 0.1835 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 11:03:45 visual_prompt]: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1938, average loss: 1.6707
[09/17 11:03:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.33	top5: 97.01	
[09/17 11:03:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/17 11:03:54 visual_prompt]: Epoch 47 / 100: avg data time: 1.19e-01, avg batch time: 0.5230, average train loss: 2.2578
[09/17 11:03:57 visual_prompt]: Inference (val):avg data time: 4.93e-05, avg batch time: 0.1450, average loss: 3.2524
[09/17 11:03:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 12.50	top5: 68.50	
[09/17 11:04:19 visual_prompt]: 	Test 100/235. loss: 3.084, 0.2210 s / batch. (data: 2.43e-02)max mem: 17.22447 GB 
[09/17 11:04:38 visual_prompt]: 	Test 200/235. loss: 3.116, 0.1841 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 11:04:46 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1931, average loss: 3.1345
[09/17 11:04:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 13.30	top5: 70.28	
[09/17 11:04:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/17 11:04:55 visual_prompt]: Epoch 48 / 100: avg data time: 1.14e-01, avg batch time: 0.5194, average train loss: 2.3477
[09/17 11:04:59 visual_prompt]: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1431, average loss: 2.3739
[09/17 11:04:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.00	top5: 82.00	
[09/17 11:05:20 visual_prompt]: 	Test 100/235. loss: 2.489, 0.1965 s / batch. (data: 1.34e-02)max mem: 17.22447 GB 
[09/17 11:05:39 visual_prompt]: 	Test 200/235. loss: 2.480, 0.1838 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 11:05:47 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1928, average loss: 2.4112
[09/17 11:05:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 19.15	top5: 82.58	
[09/17 11:05:47 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/17 11:05:56 visual_prompt]: Epoch 49 / 100: avg data time: 1.14e-01, avg batch time: 0.5160, average train loss: 1.8241
[09/17 11:06:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1458, average loss: 2.0542
[09/17 11:06:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.00	top5: 88.00	
[09/17 11:06:21 visual_prompt]: 	Test 100/235. loss: 2.534, 0.2034 s / batch. (data: 2.05e-02)max mem: 17.22447 GB 
[09/17 11:06:41 visual_prompt]: 	Test 200/235. loss: 2.205, 0.1844 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 11:06:49 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1958, average loss: 2.2052
[09/17 11:06:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.90	top5: 83.10	
[09/17 11:06:49 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/17 11:06:58 visual_prompt]: Epoch 50 / 100: avg data time: 1.06e-01, avg batch time: 0.5098, average train loss: 1.7168
[09/17 11:07:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1430, average loss: 1.4709
[09/17 11:07:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.00	top5: 100.00	
[09/17 11:07:22 visual_prompt]: 	Test 100/235. loss: 1.631, 0.1989 s / batch. (data: 1.55e-02)max mem: 17.22447 GB 
[09/17 11:07:42 visual_prompt]: 	Test 200/235. loss: 1.553, 0.1994 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 11:07:50 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1936, average loss: 1.5195
[09/17 11:07:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.34	top5: 98.81	
[09/17 11:07:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/17 11:07:59 visual_prompt]: Epoch 51 / 100: avg data time: 1.08e-01, avg batch time: 0.5115, average train loss: 1.4608
[09/17 11:08:02 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1443, average loss: 1.2338
[09/17 11:08:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 44.50	top5: 100.00	
[09/17 11:08:24 visual_prompt]: 	Test 100/235. loss: 1.366, 0.1955 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 11:08:43 visual_prompt]: 	Test 200/235. loss: 1.384, 0.2004 s / batch. (data: 1.69e-02)max mem: 17.22447 GB 
[09/17 11:08:51 visual_prompt]: Inference (test):avg data time: 6.35e-03, avg batch time: 0.1932, average loss: 1.2475
[09/17 11:08:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.72	top5: 99.71	
[09/17 11:08:51 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/17 11:09:00 visual_prompt]: Epoch 52 / 100: avg data time: 1.09e-01, avg batch time: 0.5126, average train loss: 1.3016
[09/17 11:09:03 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1431, average loss: 1.1180
[09/17 11:09:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 42.00	top5: 100.00	
[09/17 11:09:25 visual_prompt]: 	Test 100/235. loss: 1.362, 0.1837 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 11:09:45 visual_prompt]: 	Test 200/235. loss: 1.242, 0.1997 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 11:09:52 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1954, average loss: 1.2189
[09/17 11:09:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.17	top5: 99.81	
[09/17 11:09:52 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/17 11:10:02 visual_prompt]: Epoch 53 / 100: avg data time: 1.15e-01, avg batch time: 0.5152, average train loss: 1.1967
[09/17 11:10:05 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1432, average loss: 1.2343
[09/17 11:10:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 46.00	top5: 100.00	
[09/17 11:10:26 visual_prompt]: 	Test 100/235. loss: 1.549, 0.2089 s / batch. (data: 2.56e-02)max mem: 17.22447 GB 
[09/17 11:10:46 visual_prompt]: 	Test 200/235. loss: 1.305, 0.1930 s / batch. (data: 1.30e-04)max mem: 17.22447 GB 
[09/17 11:10:54 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1938, average loss: 1.3283
[09/17 11:10:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.01	top5: 99.62	
[09/17 11:10:54 visual_prompt]: Best epoch 53: best metric: 0.460
[09/17 11:10:54 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/17 11:11:03 visual_prompt]: Epoch 54 / 100: avg data time: 1.20e-01, avg batch time: 0.5224, average train loss: 2.2311
[09/17 11:11:07 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1431, average loss: 2.5132
[09/17 11:11:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.50	top5: 79.50	
[09/17 11:11:28 visual_prompt]: 	Test 100/235. loss: 2.369, 0.1949 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 11:11:48 visual_prompt]: 	Test 200/235. loss: 2.618, 0.1954 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 11:11:56 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1949, average loss: 2.4989
[09/17 11:11:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 25.82	top5: 73.95	
[09/17 11:11:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/17 11:12:05 visual_prompt]: Epoch 55 / 100: avg data time: 1.15e-01, avg batch time: 0.5266, average train loss: 2.2399
[09/17 11:12:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1430, average loss: 1.8943
[09/17 11:12:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.00	top5: 95.00	
[09/17 11:12:30 visual_prompt]: 	Test 100/235. loss: 2.131, 0.1839 s / batch. (data: 1.83e-04)max mem: 17.22447 GB 
[09/17 11:12:50 visual_prompt]: 	Test 200/235. loss: 1.958, 0.1891 s / batch. (data: 1.03e-04)max mem: 17.22447 GB 
[09/17 11:12:58 visual_prompt]: Inference (test):avg data time: 8.65e-03, avg batch time: 0.1972, average loss: 1.9400
[09/17 11:12:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.35	top5: 93.67	
[09/17 11:12:58 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/17 11:13:07 visual_prompt]: Epoch 56 / 100: avg data time: 1.08e-01, avg batch time: 0.5108, average train loss: 1.4883
[09/17 11:13:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1432, average loss: 1.2722
[09/17 11:13:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 41.00	top5: 100.00	
[09/17 11:13:32 visual_prompt]: 	Test 100/235. loss: 1.499, 0.1952 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 11:13:51 visual_prompt]: 	Test 200/235. loss: 1.380, 0.1908 s / batch. (data: 9.78e-05)max mem: 17.22447 GB 
[09/17 11:13:59 visual_prompt]: Inference (test):avg data time: 7.18e-03, avg batch time: 0.1936, average loss: 1.3961
[09/17 11:13:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.48	top5: 99.25	
[09/17 11:13:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/17 11:14:08 visual_prompt]: Epoch 57 / 100: avg data time: 1.10e-01, avg batch time: 0.5141, average train loss: 1.6036
[09/17 11:14:12 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1431, average loss: 2.0798
[09/17 11:14:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.50	top5: 87.00	
[09/17 11:14:33 visual_prompt]: 	Test 100/235. loss: 2.421, 0.2082 s / batch. (data: 2.52e-02)max mem: 17.22447 GB 
[09/17 11:14:52 visual_prompt]: 	Test 200/235. loss: 2.229, 0.1835 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 11:15:00 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1935, average loss: 2.2626
[09/17 11:15:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.25	top5: 80.91	
[09/17 11:15:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/17 11:15:10 visual_prompt]: Epoch 58 / 100: avg data time: 1.04e-01, avg batch time: 0.5415, average train loss: 1.5105
[09/17 11:15:13 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1430, average loss: 1.1846
[09/17 11:15:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 45.00	top5: 99.50	
[09/17 11:15:35 visual_prompt]: 	Test 100/235. loss: 1.371, 0.1990 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 11:15:54 visual_prompt]: 	Test 200/235. loss: 1.334, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 11:16:02 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1935, average loss: 1.2907
[09/17 11:16:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.43	top5: 99.45	
[09/17 11:16:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/17 11:16:11 visual_prompt]: Epoch 59 / 100: avg data time: 1.11e-01, avg batch time: 0.5153, average train loss: 1.2287
[09/17 11:16:15 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1432, average loss: 1.4322
[09/17 11:16:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 43.00	top5: 100.00	
[09/17 11:16:36 visual_prompt]: 	Test 100/235. loss: 1.786, 0.2002 s / batch. (data: 1.69e-02)max mem: 17.22447 GB 
[09/17 11:16:56 visual_prompt]: 	Test 200/235. loss: 1.595, 0.1918 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 11:17:04 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1955, average loss: 1.6934
[09/17 11:17:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.65	top5: 99.66	
[09/17 11:17:04 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/17 11:17:13 visual_prompt]: Epoch 60 / 100: avg data time: 1.13e-01, avg batch time: 0.5220, average train loss: 1.4785
[09/17 11:17:17 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1431, average loss: 1.1732
[09/17 11:17:17 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 47.50	top5: 99.50	
[09/17 11:17:38 visual_prompt]: 	Test 100/235. loss: 1.464, 0.2102 s / batch. (data: 1.35e-02)max mem: 17.22447 GB 
[09/17 11:17:58 visual_prompt]: 	Test 200/235. loss: 1.246, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 11:18:06 visual_prompt]: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1950, average loss: 1.3111
[09/17 11:18:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.17	top5: 99.70	
[09/17 11:18:06 visual_prompt]: Best epoch 60: best metric: 0.475
[09/17 11:18:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/17 11:18:15 visual_prompt]: Epoch 61 / 100: avg data time: 1.07e-01, avg batch time: 0.5092, average train loss: 1.1955
[09/17 11:18:18 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1431, average loss: 1.5777
[09/17 11:18:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 99.50	
[09/17 11:18:39 visual_prompt]: 	Test 100/235. loss: 2.142, 0.1945 s / batch. (data: 1.37e-04)max mem: 17.22447 GB 
[09/17 11:18:59 visual_prompt]: 	Test 200/235. loss: 1.713, 0.2000 s / batch. (data: 1.31e-02)max mem: 17.22447 GB 
[09/17 11:19:06 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1927, average loss: 1.8618
[09/17 11:19:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.40	top5: 97.12	
[09/17 11:19:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/17 11:19:16 visual_prompt]: Epoch 62 / 100: avg data time: 1.09e-01, avg batch time: 0.5129, average train loss: 1.0437
[09/17 11:19:19 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1431, average loss: 0.9845
[09/17 11:19:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 58.00	top5: 100.00	
[09/17 11:19:40 visual_prompt]: 	Test 100/235. loss: 1.149, 0.1836 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 11:20:00 visual_prompt]: 	Test 200/235. loss: 1.253, 0.1839 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 11:20:08 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1935, average loss: 1.2016
[09/17 11:20:08 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.67	top5: 99.98	
[09/17 11:20:08 visual_prompt]: Best epoch 62: best metric: 0.580
[09/17 11:20:08 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/17 11:20:17 visual_prompt]: Epoch 63 / 100: avg data time: 1.06e-01, avg batch time: 0.5101, average train loss: 1.0116
[09/17 11:20:20 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1432, average loss: 0.8300
[09/17 11:20:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 61.50	top5: 100.00	
[09/17 11:20:41 visual_prompt]: 	Test 100/235. loss: 1.271, 0.1838 s / batch. (data: 1.14e-04)max mem: 17.22447 GB 
[09/17 11:21:01 visual_prompt]: 	Test 200/235. loss: 1.221, 0.1990 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 11:21:09 visual_prompt]: Inference (test):avg data time: 8.66e-03, avg batch time: 0.1944, average loss: 1.0890
[09/17 11:21:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 50.89	top5: 99.97	
[09/17 11:21:09 visual_prompt]: Best epoch 63: best metric: 0.615
[09/17 11:21:09 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/17 11:21:18 visual_prompt]: Epoch 64 / 100: avg data time: 1.15e-01, avg batch time: 0.5179, average train loss: 1.2396
[09/17 11:21:22 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.1432, average loss: 1.0953
[09/17 11:21:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.00	top5: 100.00	
[09/17 11:21:43 visual_prompt]: 	Test 100/235. loss: 1.313, 0.1895 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 11:22:02 visual_prompt]: 	Test 200/235. loss: 1.269, 0.1878 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 11:22:10 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1935, average loss: 1.2869
[09/17 11:22:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.05	top5: 99.84	
[09/17 11:22:10 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/17 11:22:20 visual_prompt]: Epoch 65 / 100: avg data time: 1.11e-01, avg batch time: 0.5136, average train loss: 1.1637
[09/17 11:22:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1429, average loss: 0.9673
[09/17 11:22:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 54.00	top5: 100.00	
[09/17 11:22:44 visual_prompt]: 	Test 100/235. loss: 1.279, 0.1846 s / batch. (data: 1.48e-04)max mem: 17.22447 GB 
[09/17 11:23:03 visual_prompt]: 	Test 200/235. loss: 1.184, 0.1835 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 11:23:11 visual_prompt]: Inference (test):avg data time: 6.64e-03, avg batch time: 0.1926, average loss: 1.1571
[09/17 11:23:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.49	top5: 99.85	
[09/17 11:23:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/17 11:23:20 visual_prompt]: Epoch 66 / 100: avg data time: 1.04e-01, avg batch time: 0.5072, average train loss: 0.8767
[09/17 11:23:24 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1429, average loss: 1.2127
[09/17 11:23:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 52.50	top5: 100.00	
[09/17 11:23:45 visual_prompt]: 	Test 100/235. loss: 1.842, 0.1982 s / batch. (data: 3.96e-05)max mem: 17.22447 GB 
[09/17 11:24:05 visual_prompt]: 	Test 200/235. loss: 1.693, 0.1847 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 11:24:13 visual_prompt]: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1943, average loss: 1.5325
[09/17 11:24:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.43	top5: 99.90	
[09/17 11:24:13 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/17 11:24:22 visual_prompt]: Epoch 67 / 100: avg data time: 9.45e-02, avg batch time: 0.5020, average train loss: 1.5056
[09/17 11:24:25 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1434, average loss: 1.3946
[09/17 11:24:25 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.50	top5: 99.50	
[09/17 11:24:46 visual_prompt]: 	Test 100/235. loss: 1.774, 0.1974 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 11:25:06 visual_prompt]: 	Test 200/235. loss: 1.691, 0.1844 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 11:25:13 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1925, average loss: 1.6751
[09/17 11:25:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.47	top5: 95.78	
[09/17 11:25:14 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/17 11:25:23 visual_prompt]: Epoch 68 / 100: avg data time: 1.11e-01, avg batch time: 0.5144, average train loss: 1.0879
[09/17 11:25:26 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1431, average loss: 0.9306
[09/17 11:25:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 68.00	top5: 100.00	
[09/17 11:25:48 visual_prompt]: 	Test 100/235. loss: 1.236, 0.1997 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 11:26:07 visual_prompt]: 	Test 200/235. loss: 1.236, 0.2115 s / batch. (data: 2.81e-02)max mem: 17.22447 GB 
[09/17 11:26:15 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1957, average loss: 1.2034
[09/17 11:26:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 55.49	top5: 99.75	
[09/17 11:26:15 visual_prompt]: Best epoch 68: best metric: 0.680
[09/17 11:26:15 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/17 11:26:25 visual_prompt]: Epoch 69 / 100: avg data time: 1.17e-01, avg batch time: 0.5192, average train loss: 0.8097
[09/17 11:26:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1438, average loss: 0.8242
[09/17 11:26:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 63.50	top5: 100.00	
[09/17 11:26:49 visual_prompt]: 	Test 100/235. loss: 1.357, 0.1840 s / batch. (data: 1.47e-04)max mem: 17.22447 GB 
[09/17 11:27:09 visual_prompt]: 	Test 200/235. loss: 1.184, 0.1962 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 11:27:16 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1930, average loss: 1.1600
[09/17 11:27:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 51.70	top5: 99.76	
[09/17 11:27:17 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/17 11:27:26 visual_prompt]: Epoch 70 / 100: avg data time: 1.17e-01, avg batch time: 0.5237, average train loss: 0.8240
[09/17 11:27:29 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1431, average loss: 1.1670
[09/17 11:27:29 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 53.00	top5: 100.00	
[09/17 11:27:50 visual_prompt]: 	Test 100/235. loss: 1.394, 0.1845 s / batch. (data: 1.69e-04)max mem: 17.22447 GB 
[09/17 11:28:10 visual_prompt]: 	Test 200/235. loss: 1.422, 0.1979 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 11:28:18 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1934, average loss: 1.5314
[09/17 11:28:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.10	top5: 99.86	
[09/17 11:28:18 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/17 11:28:28 visual_prompt]: Epoch 71 / 100: avg data time: 1.14e-01, avg batch time: 0.5444, average train loss: 0.7650
[09/17 11:28:31 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1430, average loss: 0.8586
[09/17 11:28:31 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 62.00	top5: 100.00	
[09/17 11:28:52 visual_prompt]: 	Test 100/235. loss: 1.415, 0.1982 s / batch. (data: 1.44e-02)max mem: 17.22447 GB 
[09/17 11:29:11 visual_prompt]: 	Test 200/235. loss: 1.209, 0.1958 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 11:29:20 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1948, average loss: 1.2778
[09/17 11:29:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.41	top5: 99.83	
[09/17 11:29:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/17 11:29:29 visual_prompt]: Epoch 72 / 100: avg data time: 1.18e-01, avg batch time: 0.5208, average train loss: 0.7150
[09/17 11:29:32 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1431, average loss: 0.9402
[09/17 11:29:32 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 53.50	top5: 100.00	
[09/17 11:29:54 visual_prompt]: 	Test 100/235. loss: 1.571, 0.1995 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 11:30:13 visual_prompt]: 	Test 200/235. loss: 1.496, 0.2016 s / batch. (data: 6.88e-03)max mem: 17.22447 GB 
[09/17 11:30:21 visual_prompt]: Inference (test):avg data time: 6.65e-03, avg batch time: 0.1941, average loss: 1.3197
[09/17 11:30:21 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.43	top5: 99.98	
[09/17 11:30:21 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/17 11:30:30 visual_prompt]: Epoch 73 / 100: avg data time: 9.70e-02, avg batch time: 0.5016, average train loss: 0.8914
[09/17 11:30:34 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1502, average loss: 1.0732
[09/17 11:30:34 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 50.50	top5: 100.00	
[09/17 11:30:55 visual_prompt]: 	Test 100/235. loss: 1.323, 0.1937 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 11:31:15 visual_prompt]: 	Test 200/235. loss: 1.314, 0.1927 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 11:31:22 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1939, average loss: 1.3809
[09/17 11:31:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.09	top5: 99.74	
[09/17 11:31:22 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/17 11:31:32 visual_prompt]: Epoch 74 / 100: avg data time: 1.07e-01, avg batch time: 0.5106, average train loss: 0.6274
[09/17 11:31:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1432, average loss: 0.8284
[09/17 11:31:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 63.50	top5: 100.00	
[09/17 11:31:56 visual_prompt]: 	Test 100/235. loss: 1.382, 0.2007 s / batch. (data: 1.73e-02)max mem: 17.22447 GB 
[09/17 11:32:16 visual_prompt]: 	Test 200/235. loss: 1.260, 0.2182 s / batch. (data: 1.56e-02)max mem: 17.22447 GB 
[09/17 11:32:24 visual_prompt]: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1932, average loss: 1.3690
[09/17 11:32:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.73	top5: 99.82	
[09/17 11:32:24 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/17 11:32:33 visual_prompt]: Epoch 75 / 100: avg data time: 9.78e-02, avg batch time: 0.5000, average train loss: 0.5523
[09/17 11:32:36 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1433, average loss: 0.9968
[09/17 11:32:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 63.50	top5: 100.00	
[09/17 11:32:57 visual_prompt]: 	Test 100/235. loss: 1.652, 0.1963 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 11:33:17 visual_prompt]: 	Test 200/235. loss: 1.616, 0.1991 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 11:33:25 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1942, average loss: 1.6240
[09/17 11:33:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 50.02	top5: 99.71	
[09/17 11:33:25 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/17 11:33:34 visual_prompt]: Epoch 76 / 100: avg data time: 1.11e-01, avg batch time: 0.5136, average train loss: 0.5106
[09/17 11:33:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1432, average loss: 0.6169
[09/17 11:33:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 11:33:58 visual_prompt]: 	Test 100/235. loss: 1.291, 0.1991 s / batch. (data: 1.57e-02)max mem: 17.22447 GB 
[09/17 11:34:18 visual_prompt]: 	Test 200/235. loss: 1.315, 0.2137 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 11:34:26 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1932, average loss: 1.2554
[09/17 11:34:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.83	top5: 99.96	
[09/17 11:34:26 visual_prompt]: Best epoch 76: best metric: 0.740
[09/17 11:34:26 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/17 11:34:36 visual_prompt]: Epoch 77 / 100: avg data time: 1.10e-01, avg batch time: 0.5486, average train loss: 0.6334
[09/17 11:34:39 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1430, average loss: 1.1215
[09/17 11:34:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 54.00	top5: 100.00	
[09/17 11:35:01 visual_prompt]: 	Test 100/235. loss: 1.899, 0.2475 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 11:35:21 visual_prompt]: 	Test 200/235. loss: 1.656, 0.1943 s / batch. (data: 4.67e-05)max mem: 17.22447 GB 
[09/17 11:35:29 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1963, average loss: 1.7099
[09/17 11:35:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.87	top5: 99.75	
[09/17 11:35:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/17 11:35:38 visual_prompt]: Epoch 78 / 100: avg data time: 9.93e-02, avg batch time: 0.5062, average train loss: 0.7697
[09/17 11:35:41 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1429, average loss: 0.5710
[09/17 11:35:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.50	top5: 100.00	
[09/17 11:36:02 visual_prompt]: 	Test 100/235. loss: 1.212, 0.1964 s / batch. (data: 1.32e-02)max mem: 17.22447 GB 
[09/17 11:36:22 visual_prompt]: 	Test 200/235. loss: 1.080, 0.2251 s / batch. (data: 2.49e-02)max mem: 17.22447 GB 
[09/17 11:36:29 visual_prompt]: Inference (test):avg data time: 6.82e-03, avg batch time: 0.1928, average loss: 0.9297
[09/17 11:36:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.93	top5: 99.99	
[09/17 11:36:29 visual_prompt]: Best epoch 78: best metric: 0.745
[09/17 11:36:29 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/17 11:36:39 visual_prompt]: Epoch 79 / 100: avg data time: 1.11e-01, avg batch time: 0.5227, average train loss: 0.5599
[09/17 11:36:42 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1430, average loss: 0.4861
[09/17 11:36:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 83.00	top5: 100.00	
[09/17 11:37:03 visual_prompt]: 	Test 100/235. loss: 1.306, 0.1883 s / batch. (data: 4.50e-03)max mem: 17.22447 GB 
[09/17 11:37:23 visual_prompt]: 	Test 200/235. loss: 1.133, 0.1923 s / batch. (data: 8.76e-03)max mem: 17.22447 GB 
[09/17 11:37:31 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1932, average loss: 1.0310
[09/17 11:37:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 58.75	top5: 99.93	
[09/17 11:37:31 visual_prompt]: Best epoch 79: best metric: 0.830
[09/17 11:37:31 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/17 11:37:40 visual_prompt]: Epoch 80 / 100: avg data time: 1.12e-01, avg batch time: 0.5137, average train loss: 0.3793
[09/17 11:37:43 visual_prompt]: Inference (val):avg data time: 5.05e-05, avg batch time: 0.1431, average loss: 0.3683
[09/17 11:37:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 87.00	top5: 100.00	
[09/17 11:38:04 visual_prompt]: 	Test 100/235. loss: 1.377, 0.1979 s / batch. (data: 1.47e-02)max mem: 17.22447 GB 
[09/17 11:38:24 visual_prompt]: 	Test 200/235. loss: 1.196, 0.1958 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 11:38:32 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1939, average loss: 1.1299
[09/17 11:38:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.91	top5: 99.95	
[09/17 11:38:32 visual_prompt]: Best epoch 80: best metric: 0.870
[09/17 11:38:32 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/17 11:38:41 visual_prompt]: Epoch 81 / 100: avg data time: 1.16e-01, avg batch time: 0.5214, average train loss: 0.3935
[09/17 11:38:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1432, average loss: 1.3284
[09/17 11:38:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 56.00	top5: 100.00	
[09/17 11:39:06 visual_prompt]: 	Test 100/235. loss: 2.293, 0.1982 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 11:39:26 visual_prompt]: 	Test 200/235. loss: 2.141, 0.1994 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 11:39:34 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1950, average loss: 2.1970
[09/17 11:39:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.81	top5: 99.90	
[09/17 11:39:34 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/17 11:39:43 visual_prompt]: Epoch 82 / 100: avg data time: 1.09e-01, avg batch time: 0.5113, average train loss: 0.5048
[09/17 11:39:46 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1431, average loss: 0.8217
[09/17 11:39:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 59.50	top5: 100.00	
[09/17 11:40:07 visual_prompt]: 	Test 100/235. loss: 1.673, 0.1893 s / batch. (data: 5.23e-03)max mem: 17.22447 GB 
[09/17 11:40:27 visual_prompt]: 	Test 200/235. loss: 1.743, 0.1998 s / batch. (data: 1.42e-02)max mem: 17.22447 GB 
[09/17 11:40:35 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1944, average loss: 1.6451
[09/17 11:40:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.97	top5: 99.85	
[09/17 11:40:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/17 11:40:44 visual_prompt]: Epoch 83 / 100: avg data time: 1.06e-01, avg batch time: 0.5097, average train loss: 0.3072
[09/17 11:40:47 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1432, average loss: 0.3607
[09/17 11:40:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 83.50	top5: 100.00	
[09/17 11:41:09 visual_prompt]: 	Test 100/235. loss: 1.261, 0.1839 s / batch. (data: 1.46e-04)max mem: 17.22447 GB 
[09/17 11:41:28 visual_prompt]: 	Test 200/235. loss: 1.204, 0.2165 s / batch. (data: 2.79e-02)max mem: 17.22447 GB 
[09/17 11:41:36 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1935, average loss: 1.1914
[09/17 11:41:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.73	top5: 99.96	
[09/17 11:41:36 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/17 11:41:46 visual_prompt]: Epoch 84 / 100: avg data time: 1.07e-01, avg batch time: 0.5422, average train loss: 0.2737
[09/17 11:41:49 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1432, average loss: 0.2584
[09/17 11:41:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 90.50	top5: 100.00	
[09/17 11:42:10 visual_prompt]: 	Test 100/235. loss: 1.540, 0.1839 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 11:42:29 visual_prompt]: 	Test 200/235. loss: 1.384, 0.1837 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 11:42:37 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1926, average loss: 1.3547
[09/17 11:42:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.03	top5: 99.93	
[09/17 11:42:37 visual_prompt]: Best epoch 84: best metric: 0.905
[09/17 11:42:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/17 11:42:47 visual_prompt]: Epoch 85 / 100: avg data time: 1.10e-01, avg batch time: 0.5121, average train loss: 0.3735
[09/17 11:42:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1431, average loss: 1.3396
[09/17 11:42:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.00	top5: 100.00	
[09/17 11:43:11 visual_prompt]: 	Test 100/235. loss: 2.395, 0.1941 s / batch. (data: 1.06e-02)max mem: 17.22447 GB 
[09/17 11:43:30 visual_prompt]: 	Test 200/235. loss: 2.140, 0.1835 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 11:43:38 visual_prompt]: Inference (test):avg data time: 6.93e-03, avg batch time: 0.1923, average loss: 2.2613
[09/17 11:43:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.99	top5: 99.77	
[09/17 11:43:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 11:43:47 visual_prompt]: Epoch 86 / 100: avg data time: 1.16e-01, avg batch time: 0.5193, average train loss: 0.3244
[09/17 11:43:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1430, average loss: 0.5500
[09/17 11:43:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 78.00	top5: 100.00	
[09/17 11:44:12 visual_prompt]: 	Test 100/235. loss: 1.779, 0.1891 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 11:44:31 visual_prompt]: 	Test 200/235. loss: 1.620, 0.2038 s / batch. (data: 2.06e-02)max mem: 17.22447 GB 
[09/17 11:44:39 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1937, average loss: 1.5688
[09/17 11:44:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 58.01	top5: 99.87	
[09/17 11:44:39 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 11:44:49 visual_prompt]: Epoch 87 / 100: avg data time: 1.20e-01, avg batch time: 0.5228, average train loss: 0.2305
[09/17 11:44:52 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1432, average loss: 0.2832
[09/17 11:44:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 88.50	top5: 100.00	
[09/17 11:45:13 visual_prompt]: 	Test 100/235. loss: 1.557, 0.1836 s / batch. (data: 1.18e-04)max mem: 17.22447 GB 
[09/17 11:45:34 visual_prompt]: 	Test 200/235. loss: 1.491, 0.1840 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 11:45:41 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1952, average loss: 1.4597
[09/17 11:45:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.99	top5: 99.95	
[09/17 11:45:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 11:45:51 visual_prompt]: Epoch 88 / 100: avg data time: 1.07e-01, avg batch time: 0.5085, average train loss: 0.1259
[09/17 11:45:54 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.1431, average loss: 1.0456
[09/17 11:45:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 71.00	top5: 100.00	
[09/17 11:46:15 visual_prompt]: 	Test 100/235. loss: 2.714, 0.1836 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 11:46:35 visual_prompt]: 	Test 200/235. loss: 2.372, 0.1991 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 11:46:42 visual_prompt]: Inference (test):avg data time: 8.67e-03, avg batch time: 0.1941, average loss: 2.6666
[09/17 11:46:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 55.07	top5: 99.83	
[09/17 11:46:43 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 11:46:52 visual_prompt]: Epoch 89 / 100: avg data time: 1.16e-01, avg batch time: 0.5185, average train loss: 0.1305
[09/17 11:46:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1430, average loss: 0.9184
[09/17 11:46:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 73.00	top5: 100.00	
[09/17 11:47:17 visual_prompt]: 	Test 100/235. loss: 2.098, 0.2108 s / batch. (data: 2.76e-02)max mem: 17.22447 GB 
[09/17 11:47:36 visual_prompt]: 	Test 200/235. loss: 2.270, 0.1975 s / batch. (data: 1.41e-02)max mem: 17.22447 GB 
[09/17 11:47:45 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1987, average loss: 2.3775
[09/17 11:47:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.64	top5: 99.88	
[09/17 11:47:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 11:47:54 visual_prompt]: Epoch 90 / 100: avg data time: 1.17e-01, avg batch time: 0.5193, average train loss: 0.1385
[09/17 11:47:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1432, average loss: 0.4940
[09/17 11:47:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 81.50	top5: 100.00	
[09/17 11:48:19 visual_prompt]: 	Test 100/235. loss: 2.297, 0.2007 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 11:48:38 visual_prompt]: 	Test 200/235. loss: 1.975, 0.1962 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 11:48:46 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1936, average loss: 2.0513
[09/17 11:48:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.80	top5: 99.91	
[09/17 11:48:46 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 11:48:56 visual_prompt]: Epoch 91 / 100: avg data time: 1.19e-01, avg batch time: 0.5219, average train loss: 0.1009
[09/17 11:48:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1431, average loss: 0.8194
[09/17 11:48:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 73.00	top5: 100.00	
[09/17 11:49:20 visual_prompt]: 	Test 100/235. loss: 2.611, 0.1840 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 11:49:40 visual_prompt]: 	Test 200/235. loss: 2.293, 0.2404 s / batch. (data: 2.30e-02)max mem: 17.22447 GB 
[09/17 11:49:48 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1941, average loss: 2.5192
[09/17 11:49:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.11	top5: 99.88	
[09/17 11:49:48 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 11:49:57 visual_prompt]: Epoch 92 / 100: avg data time: 1.19e-01, avg batch time: 0.5239, average train loss: 0.0690
[09/17 11:50:00 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1431, average loss: 0.2219
[09/17 11:50:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.50	top5: 100.00	
[09/17 11:50:22 visual_prompt]: 	Test 100/235. loss: 2.251, 0.1982 s / batch. (data: 1.46e-02)max mem: 17.22447 GB 
[09/17 11:50:41 visual_prompt]: 	Test 200/235. loss: 1.958, 0.1835 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 11:50:49 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1929, average loss: 2.0254
[09/17 11:50:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.65	top5: 99.94	
[09/17 11:50:49 visual_prompt]: Best epoch 92: best metric: 0.925
[09/17 11:50:49 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 11:50:58 visual_prompt]: Epoch 93 / 100: avg data time: 1.08e-01, avg batch time: 0.5154, average train loss: 0.0603
[09/17 11:51:02 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1431, average loss: 0.1046
[09/17 11:51:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 95.50	top5: 100.00	
[09/17 11:51:23 visual_prompt]: 	Test 100/235. loss: 2.250, 0.1995 s / batch. (data: 1.37e-04)max mem: 17.22447 GB 
[09/17 11:51:42 visual_prompt]: 	Test 200/235. loss: 2.060, 0.2096 s / batch. (data: 1.53e-02)max mem: 17.22447 GB 
[09/17 11:51:50 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1932, average loss: 1.9441
[09/17 11:51:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 63.57	top5: 99.95	
[09/17 11:51:50 visual_prompt]: Best epoch 93: best metric: 0.955
[09/17 11:51:50 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 11:51:59 visual_prompt]: Epoch 94 / 100: avg data time: 1.09e-01, avg batch time: 0.5129, average train loss: 0.0435
[09/17 11:52:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1430, average loss: 0.1213
[09/17 11:52:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 93.00	top5: 100.00	
[09/17 11:52:24 visual_prompt]: 	Test 100/235. loss: 2.335, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 11:52:43 visual_prompt]: 	Test 200/235. loss: 2.139, 0.1832 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 11:52:51 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1929, average loss: 2.0535
[09/17 11:52:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 62.47	top5: 99.95	
[09/17 11:52:51 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 11:53:00 visual_prompt]: Epoch 95 / 100: avg data time: 1.15e-01, avg batch time: 0.5178, average train loss: 0.0367
[09/17 11:53:04 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1431, average loss: 0.1087
[09/17 11:53:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 96.00	top5: 100.00	
[09/17 11:53:25 visual_prompt]: 	Test 100/235. loss: 2.336, 0.1828 s / batch. (data: 1.09e-04)max mem: 17.22447 GB 
[09/17 11:53:45 visual_prompt]: 	Test 200/235. loss: 2.273, 0.1963 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 11:53:53 visual_prompt]: Inference (test):avg data time: 6.90e-03, avg batch time: 0.1961, average loss: 2.0710
[09/17 11:53:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 63.21	top5: 99.93	
[09/17 11:53:53 visual_prompt]: Best epoch 95: best metric: 0.960
[09/17 11:53:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 11:54:02 visual_prompt]: Epoch 96 / 100: avg data time: 1.20e-01, avg batch time: 0.5231, average train loss: 0.0408
[09/17 11:54:06 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1432, average loss: 0.2249
[09/17 11:54:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 91.00	top5: 100.00	
[09/17 11:54:27 visual_prompt]: 	Test 100/235. loss: 2.862, 0.1844 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 11:54:46 visual_prompt]: 	Test 200/235. loss: 2.553, 0.2028 s / batch. (data: 1.96e-02)max mem: 17.22447 GB 
[09/17 11:54:54 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1931, average loss: 2.4999
[09/17 11:54:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.93	top5: 99.93	
[09/17 11:54:54 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 11:55:03 visual_prompt]: Epoch 97 / 100: avg data time: 1.15e-01, avg batch time: 0.5162, average train loss: 0.0204
[09/17 11:55:07 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1432, average loss: 0.1647
[09/17 11:55:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 93.00	top5: 100.00	
[09/17 11:55:28 visual_prompt]: 	Test 100/235. loss: 2.797, 0.2131 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 11:55:47 visual_prompt]: 	Test 200/235. loss: 2.657, 0.1835 s / batch. (data: 1.79e-04)max mem: 17.22447 GB 
[09/17 11:55:55 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1933, average loss: 2.4419
[09/17 11:55:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 62.72	top5: 99.95	
[09/17 11:55:55 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 11:56:05 visual_prompt]: Epoch 98 / 100: avg data time: 1.12e-01, avg batch time: 0.5165, average train loss: 0.0193
[09/17 11:56:08 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1431, average loss: 0.2300
[09/17 11:56:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 89.50	top5: 100.00	
[09/17 11:56:29 visual_prompt]: 	Test 100/235. loss: 2.893, 0.2023 s / batch. (data: 1.39e-02)max mem: 17.22447 GB 
[09/17 11:56:49 visual_prompt]: 	Test 200/235. loss: 2.709, 0.1842 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 11:56:57 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1932, average loss: 2.5415
[09/17 11:56:57 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.45	top5: 99.94	
[09/17 11:56:57 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 11:57:06 visual_prompt]: Epoch 99 / 100: avg data time: 1.03e-01, avg batch time: 0.5094, average train loss: 0.0166
[09/17 11:57:09 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1432, average loss: 0.2019
[09/17 11:57:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 91.50	top5: 100.00	
[09/17 11:57:30 visual_prompt]: 	Test 100/235. loss: 2.878, 0.1956 s / batch. (data: 4.10e-05)max mem: 17.22447 GB 
[09/17 11:57:50 visual_prompt]: 	Test 200/235. loss: 2.636, 0.1836 s / batch. (data: 1.68e-04)max mem: 17.22447 GB 
[09/17 11:57:58 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1929, average loss: 2.4982
[09/17 11:57:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.79	top5: 99.94	
[09/17 11:57:58 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 11:58:07 visual_prompt]: Epoch 100 / 100: avg data time: 1.06e-01, avg batch time: 0.5076, average train loss: 0.0197
[09/17 11:58:10 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1437, average loss: 0.2069
[09/17 11:58:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 91.50	top5: 100.00	
[09/17 11:58:32 visual_prompt]: 	Test 100/235. loss: 2.887, 0.1958 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 11:58:51 visual_prompt]: 	Test 200/235. loss: 2.635, 0.1837 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 11:58:59 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1941, average loss: 2.5028
[09/17 11:58:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.73	top5: 99.94	
[09/17 11:59:43 visual_prompt]: Rank of current process: 0. World size: 1
[09/17 11:59:43 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 11:59:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-clevr(task="count_all")', 'DATA.NUMBER_CLASSES', '8', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/17 11:59:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 11:59:43 visual_prompt]: Training with config:
[09/17 11:59:43 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-clevr(task="count_all")',
          'NO_TEST': False,
          'NUMBER_CLASSES': 8,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-clevr(task="count_all")/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 11:59:43 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-17 11:59:43.509974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-17 11:59:43.681196: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-17 11:59:48.567666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 11:59:48.567761: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 11:59:48.567779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-17 11:59:57.686028: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 11:59:57.686352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 11:59:57.686392: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/17 11:59:57 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
2023-09-17 11:59:57.852716: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[:800]+train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 12:00:03 visual_prompt]: Number of images: 1000
[09/17 12:00:03 visual_prompt]: Number of classes: 8 / 8
[09/17 12:00:03 visual_prompt]: Loading validation data...
[09/17 12:00:03 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 12:00:04 visual_prompt]: Number of images: 200
[09/17 12:00:04 visual_prompt]: Number of classes: 8 / 8
[09/17 12:00:04 visual_prompt]: Loading test data...
[09/17 12:00:04 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split validation, from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 12:01:21 visual_prompt]: Number of images: 15000
[09/17 12:01:21 visual_prompt]: Number of classes: 8 / 8
[09/17 12:01:21 visual_prompt]: Constructing models...
[09/17 12:01:24 visual_prompt]: Total Parameters: 86726408	 Gradient Parameters: 927752
[09/17 12:01:24 visual_prompt]: tuned percent:1.070
[09/17 12:01:27 visual_prompt]: Device used for model: 0
[09/17 12:01:27 visual_prompt]: Setting up Evalutator...
[09/17 12:01:27 visual_prompt]: Setting up Trainer...
[09/17 12:01:27 visual_prompt]: 	Setting up the optimizer...
[09/17 12:01:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/17 12:01:37 visual_prompt]: Epoch 1 / 100: avg data time: 1.16e-01, avg batch time: 0.5936, average train loss: 2.4382
[09/17 12:01:40 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1421, average loss: 2.4755
[09/17 12:01:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.00	top5: 62.50	
[09/17 12:02:01 visual_prompt]: 	Test 100/235. loss: 2.736, 0.1822 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 12:02:20 visual_prompt]: 	Test 200/235. loss: 2.591, 0.2185 s / batch. (data: 3.63e-02)max mem: 17.22447 GB 
[09/17 12:02:28 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1924, average loss: 2.4578
[09/17 12:02:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 8.47	top5: 62.77	
[09/17 12:02:28 visual_prompt]: Best epoch 1: best metric: 0.100
[09/17 12:02:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/17 12:02:37 visual_prompt]: Epoch 2 / 100: avg data time: 9.93e-02, avg batch time: 0.5006, average train loss: 2.3209
[09/17 12:02:40 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1429, average loss: 2.1794
[09/17 12:02:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 66.00	
[09/17 12:03:02 visual_prompt]: 	Test 100/235. loss: 2.311, 0.1956 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 12:03:21 visual_prompt]: 	Test 200/235. loss: 2.262, 0.2006 s / batch. (data: 1.80e-02)max mem: 17.22447 GB 
[09/17 12:03:29 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1948, average loss: 2.2283
[09/17 12:03:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 62.77	
[09/17 12:03:29 visual_prompt]: Best epoch 2: best metric: 0.105
[09/17 12:03:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/17 12:03:38 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e-01, avg batch time: 0.5072, average train loss: 2.1714
[09/17 12:03:41 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1431, average loss: 2.0498
[09/17 12:03:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.00	top5: 74.00	
[09/17 12:04:03 visual_prompt]: 	Test 100/235. loss: 2.073, 0.1834 s / batch. (data: 1.37e-04)max mem: 17.22447 GB 
[09/17 12:04:22 visual_prompt]: 	Test 200/235. loss: 2.005, 0.2035 s / batch. (data: 2.02e-02)max mem: 17.22447 GB 
[09/17 12:04:30 visual_prompt]: Inference (test):avg data time: 8.76e-03, avg batch time: 0.1950, average loss: 2.0528
[09/17 12:04:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.09	top5: 76.63	
[09/17 12:04:30 visual_prompt]: Best epoch 3: best metric: 0.190
[09/17 12:04:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/17 12:04:39 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e-01, avg batch time: 0.5137, average train loss: 2.2857
[09/17 12:04:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1432, average loss: 2.3470
[09/17 12:04:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 69.00	
[09/17 12:05:03 visual_prompt]: 	Test 100/235. loss: 2.561, 0.1956 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 12:05:23 visual_prompt]: 	Test 200/235. loss: 2.474, 0.1870 s / batch. (data: 1.09e-04)max mem: 17.22447 GB 
[09/17 12:05:31 visual_prompt]: Inference (test):avg data time: 6.65e-03, avg batch time: 0.1933, average loss: 2.4709
[09/17 12:05:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 63.06	
[09/17 12:05:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/17 12:05:40 visual_prompt]: Epoch 5 / 100: avg data time: 1.10e-01, avg batch time: 0.5152, average train loss: 2.3729
[09/17 12:05:43 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1441, average loss: 2.1853
[09/17 12:05:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 15.00	top5: 64.50	
[09/17 12:06:04 visual_prompt]: 	Test 100/235. loss: 2.181, 0.1915 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 12:06:24 visual_prompt]: 	Test 200/235. loss: 2.119, 0.1832 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 12:06:31 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1936, average loss: 2.1545
[09/17 12:06:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 13.16	top5: 67.57	
[09/17 12:06:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/17 12:06:41 visual_prompt]: Epoch 6 / 100: avg data time: 9.73e-02, avg batch time: 0.5042, average train loss: 3.0125
[09/17 12:06:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1432, average loss: 6.9332
[09/17 12:06:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 76.00	
[09/17 12:07:05 visual_prompt]: 	Test 100/235. loss: 7.576, 0.1834 s / batch. (data: 1.07e-04)max mem: 17.22447 GB 
[09/17 12:07:24 visual_prompt]: 	Test 200/235. loss: 7.255, 0.2077 s / batch. (data: 2.43e-02)max mem: 17.22447 GB 
[09/17 12:07:32 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1954, average loss: 6.9768
[09/17 12:07:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 74.96	
[09/17 12:07:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/17 12:07:42 visual_prompt]: Epoch 7 / 100: avg data time: 1.11e-01, avg batch time: 0.5405, average train loss: 6.6108
[09/17 12:07:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1431, average loss: 4.9874
[09/17 12:07:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 68.50	
[09/17 12:08:06 visual_prompt]: 	Test 100/235. loss: 5.457, 0.2005 s / batch. (data: 1.34e-02)max mem: 17.22447 GB 
[09/17 12:08:26 visual_prompt]: 	Test 200/235. loss: 5.469, 0.1843 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 12:08:34 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1949, average loss: 5.2994
[09/17 12:08:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 62.83	
[09/17 12:08:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/17 12:08:43 visual_prompt]: Epoch 8 / 100: avg data time: 9.34e-02, avg batch time: 0.4957, average train loss: 5.4758
[09/17 12:08:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1435, average loss: 4.3386
[09/17 12:08:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 60.00	
[09/17 12:09:07 visual_prompt]: 	Test 100/235. loss: 4.451, 0.1962 s / batch. (data: 1.31e-02)max mem: 17.22447 GB 
[09/17 12:09:27 visual_prompt]: 	Test 200/235. loss: 4.272, 0.1841 s / batch. (data: 1.46e-04)max mem: 17.22447 GB 
[09/17 12:09:35 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1942, average loss: 4.4667
[09/17 12:09:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 62.14	
[09/17 12:09:35 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/17 12:09:44 visual_prompt]: Epoch 9 / 100: avg data time: 1.12e-01, avg batch time: 0.5140, average train loss: 3.8599
[09/17 12:09:47 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1433, average loss: 3.5605
[09/17 12:09:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 60.50	
[09/17 12:10:08 visual_prompt]: 	Test 100/235. loss: 3.237, 0.1839 s / batch. (data: 1.01e-04)max mem: 17.22447 GB 
[09/17 12:10:28 visual_prompt]: 	Test 200/235. loss: 3.553, 0.2090 s / batch. (data: 2.59e-02)max mem: 17.22447 GB 
[09/17 12:10:36 visual_prompt]: Inference (test):avg data time: 8.61e-03, avg batch time: 0.1944, average loss: 3.5593
[09/17 12:10:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 61.71	
[09/17 12:10:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/17 12:10:45 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e-01, avg batch time: 0.5166, average train loss: 6.4956
[09/17 12:10:48 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1432, average loss: 5.7787
[09/17 12:10:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 75.50	
[09/17 12:11:09 visual_prompt]: 	Test 100/235. loss: 6.141, 0.1838 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 12:11:28 visual_prompt]: 	Test 200/235. loss: 6.270, 0.2089 s / batch. (data: 2.53e-02)max mem: 17.22447 GB 
[09/17 12:11:36 visual_prompt]: Inference (test):avg data time: 6.40e-03, avg batch time: 0.1925, average loss: 6.1225
[09/17 12:11:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.68	top5: 74.02	
[09/17 12:11:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/17 12:11:45 visual_prompt]: Epoch 11 / 100: avg data time: 1.10e-01, avg batch time: 0.5137, average train loss: 8.6317
[09/17 12:11:48 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1430, average loss: 19.6025
[09/17 12:11:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 64.00	
[09/17 12:12:10 visual_prompt]: 	Test 100/235. loss: 19.183, 0.1829 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 12:12:29 visual_prompt]: 	Test 200/235. loss: 21.075, 0.1844 s / batch. (data: 1.48e-04)max mem: 17.22447 GB 
[09/17 12:12:37 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1955, average loss: 19.6552
[09/17 12:12:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.60	
[09/17 12:12:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/17 12:12:46 visual_prompt]: Epoch 12 / 100: avg data time: 1.01e-01, avg batch time: 0.5062, average train loss: 17.8962
[09/17 12:12:49 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1430, average loss: 13.2421
[09/17 12:12:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 67.50	
[09/17 12:13:10 visual_prompt]: 	Test 100/235. loss: 14.199, 0.1837 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 12:13:29 visual_prompt]: 	Test 200/235. loss: 14.670, 0.1963 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 12:13:37 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1926, average loss: 14.1321
[09/17 12:13:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 63.15	
[09/17 12:13:37 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/17 12:13:46 visual_prompt]: Epoch 13 / 100: avg data time: 9.93e-02, avg batch time: 0.5025, average train loss: 22.4894
[09/17 12:13:49 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1431, average loss: 23.3380
[09/17 12:13:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 61.50	
[09/17 12:14:11 visual_prompt]: 	Test 100/235. loss: 27.371, 0.1970 s / batch. (data: 1.40e-02)max mem: 17.22447 GB 
[09/17 12:14:30 visual_prompt]: 	Test 200/235. loss: 24.570, 0.1843 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 12:14:38 visual_prompt]: Inference (test):avg data time: 6.33e-03, avg batch time: 0.1929, average loss: 23.7054
[09/17 12:14:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.43	
[09/17 12:14:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/17 12:14:47 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e-01, avg batch time: 0.5081, average train loss: 17.0380
[09/17 12:14:50 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1431, average loss: 13.5172
[09/17 12:14:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 58.00	
[09/17 12:15:11 visual_prompt]: 	Test 100/235. loss: 12.129, 0.1963 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 12:15:30 visual_prompt]: 	Test 200/235. loss: 13.966, 0.1955 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 12:15:38 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1931, average loss: 12.9493
[09/17 12:15:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 61.88	
[09/17 12:15:38 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/17 12:15:47 visual_prompt]: Epoch 15 / 100: avg data time: 1.12e-01, avg batch time: 0.5145, average train loss: 7.5046
[09/17 12:15:50 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1431, average loss: 4.9478
[09/17 12:15:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 62.50	
[09/17 12:16:12 visual_prompt]: 	Test 100/235. loss: 4.522, 0.1976 s / batch. (data: 1.47e-02)max mem: 17.22447 GB 
[09/17 12:16:31 visual_prompt]: 	Test 200/235. loss: 4.490, 0.1955 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 12:16:39 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1937, average loss: 4.8629
[09/17 12:16:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 63.01	
[09/17 12:16:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/17 12:16:48 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e-01, avg batch time: 0.5091, average train loss: 6.1929
[09/17 12:16:51 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1432, average loss: 5.6413
[09/17 12:16:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 64.00	
[09/17 12:17:12 visual_prompt]: 	Test 100/235. loss: 5.649, 0.1965 s / batch. (data: 1.31e-02)max mem: 17.22447 GB 
[09/17 12:17:32 visual_prompt]: 	Test 200/235. loss: 6.283, 0.2058 s / batch. (data: 3.18e-04)max mem: 17.22447 GB 
[09/17 12:17:40 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1944, average loss: 6.0284
[09/17 12:17:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.60	
[09/17 12:17:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/17 12:17:49 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e-01, avg batch time: 0.5143, average train loss: 5.1211
[09/17 12:17:52 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1431, average loss: 6.1568
[09/17 12:17:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 66.50	
[09/17 12:18:13 visual_prompt]: 	Test 100/235. loss: 7.132, 0.1835 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 12:18:32 visual_prompt]: 	Test 200/235. loss: 6.622, 0.1860 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 12:18:40 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1930, average loss: 6.5248
[09/17 12:18:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 63.23	
[09/17 12:18:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/17 12:18:49 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e-01, avg batch time: 0.5091, average train loss: 4.3024
[09/17 12:18:52 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1431, average loss: 3.9602
[09/17 12:18:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 66.00	
[09/17 12:19:14 visual_prompt]: 	Test 100/235. loss: 4.624, 0.1998 s / batch. (data: 1.58e-04)max mem: 17.22447 GB 
[09/17 12:19:33 visual_prompt]: 	Test 200/235. loss: 4.273, 0.1836 s / batch. (data: 1.59e-04)max mem: 17.22447 GB 
[09/17 12:19:41 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1940, average loss: 4.2672
[09/17 12:19:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.63	
[09/17 12:19:41 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/17 12:19:50 visual_prompt]: Epoch 19 / 100: avg data time: 9.65e-02, avg batch time: 0.5021, average train loss: 3.7266
[09/17 12:19:53 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1431, average loss: 2.8264
[09/17 12:19:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.00	top5: 71.00	
[09/17 12:20:14 visual_prompt]: 	Test 100/235. loss: 2.982, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 12:20:33 visual_prompt]: 	Test 200/235. loss: 2.919, 0.1834 s / batch. (data: 4.34e-05)max mem: 17.22447 GB 
[09/17 12:20:41 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1927, average loss: 2.8923
[09/17 12:20:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 15.04	top5: 66.05	
[09/17 12:20:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/17 12:20:51 visual_prompt]: Epoch 20 / 100: avg data time: 1.11e-01, avg batch time: 0.5175, average train loss: 2.5738
[09/17 12:20:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1429, average loss: 2.3738
[09/17 12:20:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.50	top5: 68.50	
[09/17 12:21:15 visual_prompt]: 	Test 100/235. loss: 2.393, 0.1965 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 12:21:34 visual_prompt]: 	Test 200/235. loss: 2.341, 0.2084 s / batch. (data: 2.56e-02)max mem: 17.22447 GB 
[09/17 12:21:42 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1939, average loss: 2.3110
[09/17 12:21:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 19.99	top5: 71.21	
[09/17 12:21:42 visual_prompt]: Best epoch 20: best metric: 0.195
[09/17 12:21:42 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/17 12:21:51 visual_prompt]: Epoch 21 / 100: avg data time: 9.61e-02, avg batch time: 0.5011, average train loss: 2.2123
[09/17 12:21:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1430, average loss: 2.1075
[09/17 12:21:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.00	top5: 74.00	
[09/17 12:22:15 visual_prompt]: 	Test 100/235. loss: 2.172, 0.2036 s / batch. (data: 2.00e-02)max mem: 17.22447 GB 
[09/17 12:22:35 visual_prompt]: 	Test 200/235. loss: 2.185, 0.1837 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 12:22:42 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1929, average loss: 2.1204
[09/17 12:22:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.57	top5: 75.17	
[09/17 12:22:42 visual_prompt]: Best epoch 21: best metric: 0.230
[09/17 12:22:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/17 12:22:51 visual_prompt]: Epoch 22 / 100: avg data time: 1.04e-01, avg batch time: 0.5068, average train loss: 2.1705
[09/17 12:22:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1430, average loss: 2.4629
[09/17 12:22:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 84.50	
[09/17 12:23:16 visual_prompt]: 	Test 100/235. loss: 2.440, 0.2083 s / batch. (data: 1.55e-02)max mem: 17.22447 GB 
[09/17 12:23:35 visual_prompt]: 	Test 200/235. loss: 2.384, 0.1837 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 12:23:43 visual_prompt]: Inference (test):avg data time: 7.18e-03, avg batch time: 0.1929, average loss: 2.4357
[09/17 12:23:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.17	top5: 85.92	
[09/17 12:23:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/17 12:23:52 visual_prompt]: Epoch 23 / 100: avg data time: 9.85e-02, avg batch time: 0.5077, average train loss: 2.7245
[09/17 12:23:55 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1432, average loss: 2.2249
[09/17 12:23:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 71.00	
[09/17 12:24:16 visual_prompt]: 	Test 100/235. loss: 2.345, 0.2035 s / batch. (data: 2.07e-02)max mem: 17.22447 GB 
[09/17 12:24:36 visual_prompt]: 	Test 200/235. loss: 2.257, 0.1842 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 12:24:43 visual_prompt]: Inference (test):avg data time: 8.72e-03, avg batch time: 0.1935, average loss: 2.2507
[09/17 12:24:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 15.15	top5: 67.12	
[09/17 12:24:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/17 12:24:53 visual_prompt]: Epoch 24 / 100: avg data time: 1.02e-01, avg batch time: 0.5083, average train loss: 2.4604
[09/17 12:24:56 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1431, average loss: 2.6465
[09/17 12:24:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 76.50	
[09/17 12:25:17 visual_prompt]: 	Test 100/235. loss: 2.828, 0.1985 s / batch. (data: 1.50e-02)max mem: 17.22447 GB 
[09/17 12:25:36 visual_prompt]: 	Test 200/235. loss: 2.622, 0.1841 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 12:25:44 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1932, average loss: 2.7066
[09/17 12:25:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 76.85	
[09/17 12:25:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/17 12:25:53 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e-01, avg batch time: 0.5063, average train loss: 2.5277
[09/17 12:25:56 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1434, average loss: 2.0236
[09/17 12:25:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.50	top5: 79.00	
[09/17 12:26:18 visual_prompt]: 	Test 100/235. loss: 1.992, 0.1833 s / batch. (data: 4.27e-05)max mem: 17.22447 GB 
[09/17 12:26:37 visual_prompt]: 	Test 200/235. loss: 2.053, 0.1853 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 12:26:45 visual_prompt]: Inference (test):avg data time: 7.30e-03, avg batch time: 0.1943, average loss: 2.0350
[09/17 12:26:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.43	top5: 78.74	
[09/17 12:26:45 visual_prompt]: Best epoch 25: best metric: 0.235
[09/17 12:26:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/17 12:26:54 visual_prompt]: Epoch 26 / 100: avg data time: 1.11e-01, avg batch time: 0.5165, average train loss: 2.3617
[09/17 12:26:57 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1431, average loss: 2.0820
[09/17 12:26:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.00	top5: 83.00	
[09/17 12:27:19 visual_prompt]: 	Test 100/235. loss: 2.403, 0.1982 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 12:27:38 visual_prompt]: 	Test 200/235. loss: 2.143, 0.1842 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 12:27:46 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1938, average loss: 2.1113
[09/17 12:27:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 25.53	top5: 83.42	
[09/17 12:27:46 visual_prompt]: Best epoch 26: best metric: 0.240
[09/17 12:27:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/17 12:27:55 visual_prompt]: Epoch 27 / 100: avg data time: 1.04e-01, avg batch time: 0.5091, average train loss: 2.3122
[09/17 12:27:58 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1432, average loss: 1.9493
[09/17 12:27:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.50	top5: 89.50	
[09/17 12:28:19 visual_prompt]: 	Test 100/235. loss: 2.063, 0.1884 s / batch. (data: 5.28e-03)max mem: 17.22447 GB 
[09/17 12:28:39 visual_prompt]: 	Test 200/235. loss: 1.998, 0.1975 s / batch. (data: 1.45e-02)max mem: 17.22447 GB 
[09/17 12:28:46 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1932, average loss: 2.0388
[09/17 12:28:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.05	top5: 87.05	
[09/17 12:28:47 visual_prompt]: Best epoch 27: best metric: 0.305
[09/17 12:28:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/17 12:28:56 visual_prompt]: Epoch 28 / 100: avg data time: 1.10e-01, avg batch time: 0.5170, average train loss: 1.9216
[09/17 12:28:59 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1432, average loss: 2.2656
[09/17 12:28:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.50	top5: 82.00	
[09/17 12:29:20 visual_prompt]: 	Test 100/235. loss: 2.435, 0.1982 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 12:29:39 visual_prompt]: 	Test 200/235. loss: 2.182, 0.1958 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 12:29:47 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1929, average loss: 2.3699
[09/17 12:29:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 19.66	top5: 80.46	
[09/17 12:29:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/17 12:29:56 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e-01, avg batch time: 0.5091, average train loss: 2.2090
[09/17 12:29:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1432, average loss: 2.3048
[09/17 12:29:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.50	top5: 76.50	
[09/17 12:30:21 visual_prompt]: 	Test 100/235. loss: 2.460, 0.1961 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 12:30:40 visual_prompt]: 	Test 200/235. loss: 2.259, 0.1838 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 12:30:48 visual_prompt]: Inference (test):avg data time: 9.35e-03, avg batch time: 0.1955, average loss: 2.2902
[09/17 12:30:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.41	top5: 76.07	
[09/17 12:30:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/17 12:30:57 visual_prompt]: Epoch 30 / 100: avg data time: 1.02e-01, avg batch time: 0.5073, average train loss: 2.1438
[09/17 12:31:00 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1432, average loss: 2.1877
[09/17 12:31:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.50	top5: 85.00	
[09/17 12:31:21 visual_prompt]: 	Test 100/235. loss: 2.515, 0.1946 s / batch. (data: 1.14e-02)max mem: 17.22447 GB 
[09/17 12:31:41 visual_prompt]: 	Test 200/235. loss: 2.205, 0.2009 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 12:31:49 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1931, average loss: 2.2314
[09/17 12:31:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.99	top5: 82.03	
[09/17 12:31:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/17 12:31:58 visual_prompt]: Epoch 31 / 100: avg data time: 1.08e-01, avg batch time: 0.5102, average train loss: 2.1046
[09/17 12:32:01 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1431, average loss: 1.8601
[09/17 12:32:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 89.50	
[09/17 12:32:22 visual_prompt]: 	Test 100/235. loss: 2.117, 0.2107 s / batch. (data: 1.41e-02)max mem: 17.22447 GB 
[09/17 12:32:41 visual_prompt]: 	Test 200/235. loss: 1.930, 0.2120 s / batch. (data: 2.89e-02)max mem: 17.22447 GB 
[09/17 12:32:49 visual_prompt]: Inference (test):avg data time: 6.92e-03, avg batch time: 0.1925, average loss: 1.9590
[09/17 12:32:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 16.99	top5: 85.03	
[09/17 12:32:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/17 12:32:58 visual_prompt]: Epoch 32 / 100: avg data time: 1.10e-01, avg batch time: 0.5121, average train loss: 2.5021
[09/17 12:33:01 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1434, average loss: 2.2783
[09/17 12:33:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.00	top5: 74.50	
[09/17 12:33:22 visual_prompt]: 	Test 100/235. loss: 2.765, 0.1928 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 12:33:42 visual_prompt]: 	Test 200/235. loss: 2.433, 0.1880 s / batch. (data: 1.57e-04)max mem: 17.22447 GB 
[09/17 12:33:50 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1938, average loss: 2.4192
[09/17 12:33:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.54	top5: 73.87	
[09/17 12:33:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/17 12:33:59 visual_prompt]: Epoch 33 / 100: avg data time: 1.08e-01, avg batch time: 0.5104, average train loss: 2.0845
[09/17 12:34:02 visual_prompt]: Inference (val):avg data time: 1.38e-04, avg batch time: 0.2269, average loss: 1.9144
[09/17 12:34:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.00	top5: 82.50	
[09/17 12:34:23 visual_prompt]: 	Test 100/235. loss: 2.201, 0.1956 s / batch. (data: 1.67e-04)max mem: 17.22447 GB 
[09/17 12:34:43 visual_prompt]: 	Test 200/235. loss: 1.964, 0.2083 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 12:34:50 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1926, average loss: 1.9128
[09/17 12:34:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.42	top5: 83.93	
[09/17 12:34:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/17 12:35:00 visual_prompt]: Epoch 34 / 100: avg data time: 1.14e-01, avg batch time: 0.5177, average train loss: 1.8905
[09/17 12:35:03 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1442, average loss: 2.4127
[09/17 12:35:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.50	top5: 80.50	
[09/17 12:35:24 visual_prompt]: 	Test 100/235. loss: 2.612, 0.1998 s / batch. (data: 1.55e-02)max mem: 17.22447 GB 
[09/17 12:35:44 visual_prompt]: 	Test 200/235. loss: 2.369, 0.1961 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 12:35:52 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1947, average loss: 2.3785
[09/17 12:35:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.47	top5: 83.27	
[09/17 12:35:52 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/17 12:36:01 visual_prompt]: Epoch 35 / 100: avg data time: 1.08e-01, avg batch time: 0.5120, average train loss: 1.8569
[09/17 12:36:04 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1432, average loss: 1.6963
[09/17 12:36:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.50	top5: 92.00	
[09/17 12:36:25 visual_prompt]: 	Test 100/235. loss: 1.724, 0.2004 s / batch. (data: 1.70e-02)max mem: 17.22447 GB 
[09/17 12:36:44 visual_prompt]: 	Test 200/235. loss: 1.671, 0.1958 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 12:36:52 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1935, average loss: 1.6761
[09/17 12:36:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.34	top5: 92.86	
[09/17 12:36:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/17 12:37:02 visual_prompt]: Epoch 36 / 100: avg data time: 1.03e-01, avg batch time: 0.5260, average train loss: 1.6683
[09/17 12:37:05 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1430, average loss: 1.5359
[09/17 12:37:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.00	top5: 95.50	
[09/17 12:37:26 visual_prompt]: 	Test 100/235. loss: 1.704, 0.1885 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 12:37:45 visual_prompt]: 	Test 200/235. loss: 1.545, 0.1842 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 12:37:53 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1934, average loss: 1.5696
[09/17 12:37:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.67	top5: 94.05	
[09/17 12:37:53 visual_prompt]: Best epoch 36: best metric: 0.320
[09/17 12:37:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/17 12:38:02 visual_prompt]: Epoch 37 / 100: avg data time: 8.74e-02, avg batch time: 0.4987, average train loss: 2.1115
[09/17 12:38:05 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1432, average loss: 3.9344
[09/17 12:38:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.50	top5: 68.50	
[09/17 12:38:26 visual_prompt]: 	Test 100/235. loss: 3.814, 0.2123 s / batch. (data: 2.91e-02)max mem: 17.22447 GB 
[09/17 12:38:46 visual_prompt]: 	Test 200/235. loss: 3.201, 0.1839 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 12:38:53 visual_prompt]: Inference (test):avg data time: 8.55e-03, avg batch time: 0.1938, average loss: 3.6401
[09/17 12:38:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.78	top5: 71.65	
[09/17 12:38:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/17 12:39:03 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e-01, avg batch time: 0.5077, average train loss: 3.3070
[09/17 12:39:06 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1434, average loss: 1.8909
[09/17 12:39:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.00	top5: 85.50	
[09/17 12:39:27 visual_prompt]: 	Test 100/235. loss: 1.990, 0.1886 s / batch. (data: 5.22e-03)max mem: 17.22447 GB 
[09/17 12:39:46 visual_prompt]: 	Test 200/235. loss: 1.972, 0.2325 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 12:39:54 visual_prompt]: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1935, average loss: 1.9671
[09/17 12:39:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.03	top5: 81.37	
[09/17 12:39:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/17 12:40:03 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e-01, avg batch time: 0.5074, average train loss: 2.2194
[09/17 12:40:06 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1430, average loss: 1.7260
[09/17 12:40:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.00	top5: 90.00	
[09/17 12:40:27 visual_prompt]: 	Test 100/235. loss: 2.049, 0.1978 s / batch. (data: 1.49e-02)max mem: 17.22447 GB 
[09/17 12:40:47 visual_prompt]: 	Test 200/235. loss: 1.826, 0.1983 s / batch. (data: 1.49e-02)max mem: 17.22447 GB 
[09/17 12:40:54 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1934, average loss: 1.7565
[09/17 12:40:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 26.07	top5: 89.62	
[09/17 12:40:54 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/17 12:41:04 visual_prompt]: Epoch 40 / 100: avg data time: 1.04e-01, avg batch time: 0.5078, average train loss: 1.9684
[09/17 12:41:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1431, average loss: 1.9612
[09/17 12:41:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.50	top5: 86.00	
[09/17 12:41:28 visual_prompt]: 	Test 100/235. loss: 2.067, 0.2066 s / batch. (data: 2.35e-02)max mem: 17.22447 GB 
[09/17 12:41:47 visual_prompt]: 	Test 200/235. loss: 2.000, 0.1845 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 12:41:55 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1927, average loss: 1.9182
[09/17 12:41:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.03	top5: 86.95	
[09/17 12:41:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/17 12:42:04 visual_prompt]: Epoch 41 / 100: avg data time: 9.70e-02, avg batch time: 0.5014, average train loss: 1.9458
[09/17 12:42:07 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1430, average loss: 1.9289
[09/17 12:42:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 88.00	
[09/17 12:42:28 visual_prompt]: 	Test 100/235. loss: 2.121, 0.1955 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 12:42:47 visual_prompt]: 	Test 200/235. loss: 1.893, 0.2035 s / batch. (data: 9.95e-03)max mem: 17.22447 GB 
[09/17 12:42:55 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1925, average loss: 1.9962
[09/17 12:42:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.66	top5: 85.93	
[09/17 12:42:55 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/17 12:43:04 visual_prompt]: Epoch 42 / 100: avg data time: 9.99e-02, avg batch time: 0.5024, average train loss: 1.7696
[09/17 12:43:07 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1433, average loss: 1.5326
[09/17 12:43:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.00	top5: 95.00	
[09/17 12:43:28 visual_prompt]: 	Test 100/235. loss: 1.675, 0.1958 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 12:43:48 visual_prompt]: 	Test 200/235. loss: 1.518, 0.1973 s / batch. (data: 9.82e-05)max mem: 17.22447 GB 
[09/17 12:43:55 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1932, average loss: 1.5726
[09/17 12:43:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.92	top5: 94.97	
[09/17 12:43:55 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/17 12:44:05 visual_prompt]: Epoch 43 / 100: avg data time: 1.00e-01, avg batch time: 0.5408, average train loss: 1.5698
[09/17 12:44:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1431, average loss: 1.5927
[09/17 12:44:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.50	top5: 95.50	
[09/17 12:44:29 visual_prompt]: 	Test 100/235. loss: 1.856, 0.1957 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 12:44:49 visual_prompt]: 	Test 200/235. loss: 1.710, 0.2021 s / batch. (data: 1.89e-02)max mem: 17.22447 GB 
[09/17 12:44:56 visual_prompt]: Inference (test):avg data time: 8.84e-03, avg batch time: 0.1942, average loss: 1.6867
[09/17 12:44:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.81	top5: 93.11	
[09/17 12:44:56 visual_prompt]: Best epoch 43: best metric: 0.325
[09/17 12:44:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/17 12:45:06 visual_prompt]: Epoch 44 / 100: avg data time: 1.01e-01, avg batch time: 0.5037, average train loss: 1.8294
[09/17 12:45:08 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1431, average loss: 1.8314
[09/17 12:45:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 89.50	
[09/17 12:45:30 visual_prompt]: 	Test 100/235. loss: 1.942, 0.1956 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 12:45:49 visual_prompt]: 	Test 200/235. loss: 1.961, 0.1961 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 12:45:57 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1928, average loss: 1.8825
[09/17 12:45:57 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.55	top5: 87.74	
[09/17 12:45:57 visual_prompt]: Best epoch 44: best metric: 0.350
[09/17 12:45:57 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/17 12:46:06 visual_prompt]: Epoch 45 / 100: avg data time: 1.13e-01, avg batch time: 0.5166, average train loss: 1.6438
[09/17 12:46:09 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1429, average loss: 1.5349
[09/17 12:46:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.00	top5: 97.00	
[09/17 12:46:30 visual_prompt]: 	Test 100/235. loss: 1.739, 0.2084 s / batch. (data: 2.51e-02)max mem: 17.22447 GB 
[09/17 12:46:50 visual_prompt]: 	Test 200/235. loss: 1.579, 0.1977 s / batch. (data: 1.46e-02)max mem: 17.22447 GB 
[09/17 12:46:58 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1941, average loss: 1.6151
[09/17 12:46:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.19	top5: 97.15	
[09/17 12:46:58 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/17 12:47:07 visual_prompt]: Epoch 46 / 100: avg data time: 9.70e-02, avg batch time: 0.5016, average train loss: 1.7026
[09/17 12:47:10 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1433, average loss: 1.8433
[09/17 12:47:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.50	top5: 93.00	
[09/17 12:47:31 visual_prompt]: 	Test 100/235. loss: 2.117, 0.1995 s / batch. (data: 1.37e-02)max mem: 17.22447 GB 
[09/17 12:47:50 visual_prompt]: 	Test 200/235. loss: 1.773, 0.1838 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 12:47:58 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1928, average loss: 1.9229
[09/17 12:47:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.53	top5: 91.57	
[09/17 12:47:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/17 12:48:07 visual_prompt]: Epoch 47 / 100: avg data time: 1.08e-01, avg batch time: 0.5106, average train loss: 1.6097
[09/17 12:48:10 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1430, average loss: 1.4995
[09/17 12:48:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 96.50	
[09/17 12:48:31 visual_prompt]: 	Test 100/235. loss: 1.609, 0.1838 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 12:48:51 visual_prompt]: 	Test 200/235. loss: 1.482, 0.1984 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 12:48:58 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1929, average loss: 1.5317
[09/17 12:48:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.25	top5: 97.09	
[09/17 12:48:58 visual_prompt]: Best epoch 47: best metric: 0.375
[09/17 12:48:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/17 12:49:07 visual_prompt]: Epoch 48 / 100: avg data time: 1.06e-01, avg batch time: 0.5099, average train loss: 1.5073
[09/17 12:49:11 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1432, average loss: 1.6346
[09/17 12:49:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.50	top5: 95.50	
[09/17 12:49:32 visual_prompt]: 	Test 100/235. loss: 1.894, 0.1838 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 12:49:52 visual_prompt]: 	Test 200/235. loss: 1.661, 0.2152 s / batch. (data: 1.69e-02)max mem: 17.22447 GB 
[09/17 12:50:00 visual_prompt]: Inference (test):avg data time: 7.01e-03, avg batch time: 0.1955, average loss: 1.7348
[09/17 12:50:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.49	top5: 95.43	
[09/17 12:50:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/17 12:50:09 visual_prompt]: Epoch 49 / 100: avg data time: 1.11e-01, avg batch time: 0.5127, average train loss: 2.3114
[09/17 12:50:12 visual_prompt]: Inference (val):avg data time: 4.14e-04, avg batch time: 0.1980, average loss: 2.4336
[09/17 12:50:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 76.00	
[09/17 12:50:33 visual_prompt]: 	Test 100/235. loss: 2.357, 0.1839 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 12:50:52 visual_prompt]: 	Test 200/235. loss: 2.408, 0.1840 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 12:51:00 visual_prompt]: Inference (test):avg data time: 6.93e-03, avg batch time: 0.1923, average loss: 2.3809
[09/17 12:51:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 15.59	top5: 76.75	
[09/17 12:51:00 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/17 12:51:09 visual_prompt]: Epoch 50 / 100: avg data time: 1.06e-01, avg batch time: 0.5112, average train loss: 2.2608
[09/17 12:51:12 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1433, average loss: 2.1092
[09/17 12:51:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.50	top5: 82.00	
[09/17 12:51:34 visual_prompt]: 	Test 100/235. loss: 2.485, 0.1968 s / batch. (data: 1.40e-02)max mem: 17.22447 GB 
[09/17 12:51:53 visual_prompt]: 	Test 200/235. loss: 2.302, 0.1841 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 12:52:01 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1948, average loss: 2.3290
[09/17 12:52:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 20.32	top5: 76.47	
[09/17 12:52:01 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/17 12:52:10 visual_prompt]: Epoch 51 / 100: avg data time: 1.09e-01, avg batch time: 0.5130, average train loss: 1.9495
[09/17 12:52:13 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1431, average loss: 2.0470
[09/17 12:52:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 87.00	
[09/17 12:52:34 visual_prompt]: 	Test 100/235. loss: 2.018, 0.1883 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 12:52:54 visual_prompt]: 	Test 200/235. loss: 2.170, 0.2106 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 12:53:02 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1943, average loss: 2.1510
[09/17 12:53:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.16	top5: 82.61	
[09/17 12:53:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/17 12:53:11 visual_prompt]: Epoch 52 / 100: avg data time: 1.14e-01, avg batch time: 0.5172, average train loss: 2.0559
[09/17 12:53:14 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1430, average loss: 1.7873
[09/17 12:53:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.50	top5: 83.00	
[09/17 12:53:35 visual_prompt]: 	Test 100/235. loss: 1.959, 0.2118 s / batch. (data: 2.89e-02)max mem: 17.22447 GB 
[09/17 12:53:55 visual_prompt]: 	Test 200/235. loss: 1.910, 0.2020 s / batch. (data: 1.34e-02)max mem: 17.22447 GB 
[09/17 12:54:02 visual_prompt]: Inference (test):avg data time: 6.49e-03, avg batch time: 0.1922, average loss: 1.8652
[09/17 12:54:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.24	top5: 80.97	
[09/17 12:54:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/17 12:54:12 visual_prompt]: Epoch 53 / 100: avg data time: 1.07e-01, avg batch time: 0.5137, average train loss: 1.8864
[09/17 12:54:15 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1430, average loss: 1.6877
[09/17 12:54:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.00	top5: 92.50	
[09/17 12:54:36 visual_prompt]: 	Test 100/235. loss: 1.854, 0.1832 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 12:54:55 visual_prompt]: 	Test 200/235. loss: 1.781, 0.2184 s / batch. (data: 2.87e-02)max mem: 17.22447 GB 
[09/17 12:55:03 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1927, average loss: 1.7779
[09/17 12:55:03 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.82	top5: 90.00	
[09/17 12:55:03 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/17 12:55:12 visual_prompt]: Epoch 54 / 100: avg data time: 1.09e-01, avg batch time: 0.5127, average train loss: 1.7403
[09/17 12:55:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1431, average loss: 1.5316
[09/17 12:55:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 95.50	
[09/17 12:55:36 visual_prompt]: 	Test 100/235. loss: 1.683, 0.1962 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 12:55:56 visual_prompt]: 	Test 200/235. loss: 1.584, 0.1940 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 12:56:04 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1942, average loss: 1.5968
[09/17 12:56:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.51	top5: 93.80	
[09/17 12:56:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/17 12:56:13 visual_prompt]: Epoch 55 / 100: avg data time: 1.06e-01, avg batch time: 0.5108, average train loss: 1.6341
[09/17 12:56:16 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1433, average loss: 1.5168
[09/17 12:56:16 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.50	top5: 98.50	
[09/17 12:56:38 visual_prompt]: 	Test 100/235. loss: 1.680, 0.1838 s / batch. (data: 1.62e-04)max mem: 17.22447 GB 
[09/17 12:56:57 visual_prompt]: 	Test 200/235. loss: 1.576, 0.1834 s / batch. (data: 1.54e-04)max mem: 17.22447 GB 
[09/17 12:57:05 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1945, average loss: 1.5804
[09/17 12:57:05 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.34	top5: 96.39	
[09/17 12:57:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/17 12:57:14 visual_prompt]: Epoch 56 / 100: avg data time: 1.06e-01, avg batch time: 0.5112, average train loss: 1.6745
[09/17 12:57:17 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1439, average loss: 1.5645
[09/17 12:57:17 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 98.00	
[09/17 12:57:38 visual_prompt]: 	Test 100/235. loss: 1.919, 0.2198 s / batch. (data: 2.02e-02)max mem: 17.22447 GB 
[09/17 12:57:58 visual_prompt]: 	Test 200/235. loss: 1.662, 0.1930 s / batch. (data: 4.03e-05)max mem: 17.22447 GB 
[09/17 12:58:06 visual_prompt]: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1932, average loss: 1.7014
[09/17 12:58:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.86	top5: 94.61	
[09/17 12:58:06 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/17 12:58:15 visual_prompt]: Epoch 57 / 100: avg data time: 1.02e-01, avg batch time: 0.5056, average train loss: 1.6348
[09/17 12:58:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1432, average loss: 1.4655
[09/17 12:58:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.00	top5: 98.00	
[09/17 12:58:39 visual_prompt]: 	Test 100/235. loss: 1.615, 0.1830 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 12:58:59 visual_prompt]: 	Test 200/235. loss: 1.509, 0.1842 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 12:59:07 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1953, average loss: 1.5006
[09/17 12:59:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.15	top5: 96.95	
[09/17 12:59:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/17 12:59:16 visual_prompt]: Epoch 58 / 100: avg data time: 9.96e-02, avg batch time: 0.5044, average train loss: 1.5786
[09/17 12:59:19 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1431, average loss: 1.4767
[09/17 12:59:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.00	top5: 94.50	
[09/17 12:59:40 visual_prompt]: 	Test 100/235. loss: 1.571, 0.1828 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 12:59:59 visual_prompt]: 	Test 200/235. loss: 1.502, 0.1842 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 13:00:07 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1948, average loss: 1.5259
[09/17 13:00:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.61	top5: 96.33	
[09/17 13:00:07 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/17 13:00:16 visual_prompt]: Epoch 59 / 100: avg data time: 9.54e-02, avg batch time: 0.5007, average train loss: 1.5222
[09/17 13:00:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1431, average loss: 1.5152
[09/17 13:00:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 98.50	
[09/17 13:00:41 visual_prompt]: 	Test 100/235. loss: 1.795, 0.2096 s / batch. (data: 2.69e-02)max mem: 17.22447 GB 
[09/17 13:01:00 visual_prompt]: 	Test 200/235. loss: 1.654, 0.1839 s / batch. (data: 1.07e-04)max mem: 17.22447 GB 
[09/17 13:01:08 visual_prompt]: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1942, average loss: 1.6005
[09/17 13:01:08 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.32	top5: 97.78	
[09/17 13:01:08 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/17 13:01:17 visual_prompt]: Epoch 60 / 100: avg data time: 1.04e-01, avg batch time: 0.5091, average train loss: 1.6802
[09/17 13:01:20 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1464, average loss: 1.7417
[09/17 13:01:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 97.00	
[09/17 13:01:41 visual_prompt]: 	Test 100/235. loss: 1.886, 0.1960 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 13:02:01 visual_prompt]: 	Test 200/235. loss: 1.814, 0.1980 s / batch. (data: 1.46e-02)max mem: 17.22447 GB 
[09/17 13:02:09 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1935, average loss: 1.8646
[09/17 13:02:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.87	top5: 95.84	
[09/17 13:02:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/17 13:02:18 visual_prompt]: Epoch 61 / 100: avg data time: 1.09e-01, avg batch time: 0.5110, average train loss: 1.5361
[09/17 13:02:21 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1431, average loss: 1.4735
[09/17 13:02:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.00	top5: 96.50	
[09/17 13:02:42 visual_prompt]: 	Test 100/235. loss: 1.656, 0.1943 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 13:03:02 visual_prompt]: 	Test 200/235. loss: 1.523, 0.2019 s / batch. (data: 1.86e-02)max mem: 17.22447 GB 
[09/17 13:03:09 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1938, average loss: 1.5150
[09/17 13:03:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.31	top5: 97.13	
[09/17 13:03:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/17 13:03:19 visual_prompt]: Epoch 62 / 100: avg data time: 1.09e-01, avg batch time: 0.5125, average train loss: 1.4287
[09/17 13:03:22 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1432, average loss: 1.5682
[09/17 13:03:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.00	top5: 97.00	
[09/17 13:03:43 visual_prompt]: 	Test 100/235. loss: 1.685, 0.1958 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 13:04:02 visual_prompt]: 	Test 200/235. loss: 1.614, 0.1837 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 13:04:10 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1926, average loss: 1.6636
[09/17 13:04:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.53	top5: 96.75	
[09/17 13:04:10 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/17 13:04:19 visual_prompt]: Epoch 63 / 100: avg data time: 9.43e-02, avg batch time: 0.4999, average train loss: 1.5058
[09/17 13:04:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1430, average loss: 1.3811
[09/17 13:04:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 99.00	
[09/17 13:04:43 visual_prompt]: 	Test 100/235. loss: 1.656, 0.1956 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 13:05:03 visual_prompt]: 	Test 200/235. loss: 1.422, 0.1841 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 13:05:10 visual_prompt]: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1928, average loss: 1.4494
[09/17 13:05:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.63	top5: 98.23	
[09/17 13:05:10 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/17 13:05:20 visual_prompt]: Epoch 64 / 100: avg data time: 1.14e-01, avg batch time: 0.5177, average train loss: 1.4258
[09/17 13:05:23 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1432, average loss: 1.3305
[09/17 13:05:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 41.00	top5: 98.50	
[09/17 13:05:44 visual_prompt]: 	Test 100/235. loss: 1.639, 0.1837 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 13:06:03 visual_prompt]: 	Test 200/235. loss: 1.380, 0.1836 s / batch. (data: 1.62e-04)max mem: 17.22447 GB 
[09/17 13:06:11 visual_prompt]: Inference (test):avg data time: 7.17e-03, avg batch time: 0.1924, average loss: 1.4254
[09/17 13:06:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.19	top5: 97.90	
[09/17 13:06:11 visual_prompt]: Best epoch 64: best metric: 0.410
[09/17 13:06:11 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/17 13:06:20 visual_prompt]: Epoch 65 / 100: avg data time: 1.03e-01, avg batch time: 0.5073, average train loss: 1.3828
[09/17 13:06:23 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1432, average loss: 1.3441
[09/17 13:06:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 42.50	top5: 99.50	
[09/17 13:06:44 visual_prompt]: 	Test 100/235. loss: 1.604, 0.2078 s / batch. (data: 2.48e-02)max mem: 17.22447 GB 
[09/17 13:07:03 visual_prompt]: 	Test 200/235. loss: 1.395, 0.2005 s / batch. (data: 7.96e-03)max mem: 17.22447 GB 
[09/17 13:07:11 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1923, average loss: 1.4558
[09/17 13:07:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.38	top5: 98.38	
[09/17 13:07:11 visual_prompt]: Best epoch 65: best metric: 0.425
[09/17 13:07:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/17 13:07:20 visual_prompt]: Epoch 66 / 100: avg data time: 1.11e-01, avg batch time: 0.5144, average train loss: 1.3423
[09/17 13:07:23 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1430, average loss: 1.6247
[09/17 13:07:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.50	top5: 97.50	
[09/17 13:07:45 visual_prompt]: 	Test 100/235. loss: 1.788, 0.1994 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 13:08:04 visual_prompt]: 	Test 200/235. loss: 1.628, 0.1976 s / batch. (data: 1.40e-02)max mem: 17.22447 GB 
[09/17 13:08:12 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1946, average loss: 1.7147
[09/17 13:08:12 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.28	top5: 97.99	
[09/17 13:08:12 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/17 13:08:22 visual_prompt]: Epoch 67 / 100: avg data time: 1.07e-01, avg batch time: 0.5114, average train loss: 1.3116
[09/17 13:08:25 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1462, average loss: 1.3478
[09/17 13:08:25 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 40.50	top5: 99.50	
[09/17 13:08:46 visual_prompt]: 	Test 100/235. loss: 1.543, 0.2040 s / batch. (data: 2.10e-02)max mem: 17.22447 GB 
[09/17 13:09:05 visual_prompt]: 	Test 200/235. loss: 1.360, 0.2023 s / batch. (data: 1.89e-02)max mem: 17.22447 GB 
[09/17 13:09:13 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1931, average loss: 1.4554
[09/17 13:09:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.21	top5: 98.54	
[09/17 13:09:13 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/17 13:09:22 visual_prompt]: Epoch 68 / 100: avg data time: 1.02e-01, avg batch time: 0.5142, average train loss: 1.2898
[09/17 13:09:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1431, average loss: 1.4937
[09/17 13:09:25 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.50	top5: 97.00	
[09/17 13:09:46 visual_prompt]: 	Test 100/235. loss: 1.698, 0.1836 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 13:10:06 visual_prompt]: 	Test 200/235. loss: 1.589, 0.1961 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 13:10:14 visual_prompt]: Inference (test):avg data time: 6.89e-03, avg batch time: 0.1938, average loss: 1.5970
[09/17 13:10:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.23	top5: 96.31	
[09/17 13:10:14 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/17 13:10:23 visual_prompt]: Epoch 69 / 100: avg data time: 9.84e-02, avg batch time: 0.5029, average train loss: 1.2969
[09/17 13:10:26 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1431, average loss: 1.4232
[09/17 13:10:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.00	top5: 99.00	
[09/17 13:10:47 visual_prompt]: 	Test 100/235. loss: 1.627, 0.1840 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 13:11:07 visual_prompt]: 	Test 200/235. loss: 1.485, 0.1981 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 13:11:14 visual_prompt]: Inference (test):avg data time: 6.88e-03, avg batch time: 0.1930, average loss: 1.5252
[09/17 13:11:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.76	top5: 98.70	
[09/17 13:11:14 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/17 13:11:23 visual_prompt]: Epoch 70 / 100: avg data time: 1.04e-01, avg batch time: 0.5085, average train loss: 1.2798
[09/17 13:11:26 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1434, average loss: 1.2575
[09/17 13:11:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 48.50	top5: 100.00	
[09/17 13:11:47 visual_prompt]: 	Test 100/235. loss: 1.472, 0.1973 s / batch. (data: 1.43e-02)max mem: 17.22447 GB 
[09/17 13:12:07 visual_prompt]: 	Test 200/235. loss: 1.421, 0.1843 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 13:12:15 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1934, average loss: 1.3982
[09/17 13:12:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.16	top5: 98.87	
[09/17 13:12:15 visual_prompt]: Best epoch 70: best metric: 0.485
[09/17 13:12:15 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/17 13:12:24 visual_prompt]: Epoch 71 / 100: avg data time: 1.05e-01, avg batch time: 0.5250, average train loss: 1.2678
[09/17 13:12:27 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1430, average loss: 1.1787
[09/17 13:12:27 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 47.00	top5: 99.50	
[09/17 13:12:49 visual_prompt]: 	Test 100/235. loss: 1.543, 0.1879 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 13:13:08 visual_prompt]: 	Test 200/235. loss: 1.383, 0.1836 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 13:13:16 visual_prompt]: Inference (test):avg data time: 7.10e-03, avg batch time: 0.1955, average loss: 1.3875
[09/17 13:13:16 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.89	top5: 98.51	
[09/17 13:13:16 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/17 13:13:25 visual_prompt]: Epoch 72 / 100: avg data time: 9.82e-02, avg batch time: 0.5031, average train loss: 1.2662
[09/17 13:13:28 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1431, average loss: 1.3106
[09/17 13:13:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.00	top5: 100.00	
[09/17 13:13:49 visual_prompt]: 	Test 100/235. loss: 1.623, 0.1835 s / batch. (data: 3.84e-05)max mem: 17.22447 GB 
[09/17 13:14:09 visual_prompt]: 	Test 200/235. loss: 1.531, 0.1841 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 13:14:17 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1958, average loss: 1.4957
[09/17 13:14:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.41	top5: 97.91	
[09/17 13:14:17 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/17 13:14:26 visual_prompt]: Epoch 73 / 100: avg data time: 1.06e-01, avg batch time: 0.5115, average train loss: 1.2635
[09/17 13:14:30 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1431, average loss: 1.2210
[09/17 13:14:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 45.00	top5: 100.00	
[09/17 13:14:51 visual_prompt]: 	Test 100/235. loss: 1.440, 0.2002 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 13:15:10 visual_prompt]: 	Test 200/235. loss: 1.414, 0.1979 s / batch. (data: 1.43e-02)max mem: 17.22447 GB 
[09/17 13:15:18 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1932, average loss: 1.3901
[09/17 13:15:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.79	top5: 99.16	
[09/17 13:15:18 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/17 13:15:27 visual_prompt]: Epoch 74 / 100: avg data time: 1.02e-01, avg batch time: 0.5072, average train loss: 1.2414
[09/17 13:15:30 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1431, average loss: 1.4273
[09/17 13:15:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 40.00	top5: 97.50	
[09/17 13:15:53 visual_prompt]: 	Test 100/235. loss: 1.533, 0.1844 s / batch. (data: 1.14e-04)max mem: 17.22447 GB 
[09/17 13:16:12 visual_prompt]: 	Test 200/235. loss: 1.504, 0.1970 s / batch. (data: 1.32e-02)max mem: 17.22447 GB 
[09/17 13:16:20 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1997, average loss: 1.5448
[09/17 13:16:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.06	top5: 97.51	
[09/17 13:16:20 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/17 13:16:29 visual_prompt]: Epoch 75 / 100: avg data time: 1.05e-01, avg batch time: 0.5090, average train loss: 1.2505
[09/17 13:16:32 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1432, average loss: 1.1920
[09/17 13:16:32 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 49.50	top5: 100.00	
[09/17 13:16:53 visual_prompt]: 	Test 100/235. loss: 1.454, 0.1837 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 13:17:13 visual_prompt]: 	Test 200/235. loss: 1.294, 0.1960 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 13:17:21 visual_prompt]: Inference (test):avg data time: 8.54e-03, avg batch time: 0.1945, average loss: 1.3588
[09/17 13:17:21 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.33	top5: 98.81	
[09/17 13:17:21 visual_prompt]: Best epoch 75: best metric: 0.495
[09/17 13:17:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/17 13:17:30 visual_prompt]: Epoch 76 / 100: avg data time: 1.06e-01, avg batch time: 0.5264, average train loss: 1.1643
[09/17 13:17:33 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1431, average loss: 1.2348
[09/17 13:17:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 44.00	top5: 100.00	
[09/17 13:17:55 visual_prompt]: 	Test 100/235. loss: 1.508, 0.1831 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 13:18:14 visual_prompt]: 	Test 200/235. loss: 1.386, 0.1966 s / batch. (data: 1.33e-02)max mem: 17.22447 GB 
[09/17 13:18:22 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1933, average loss: 1.4415
[09/17 13:18:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.74	top5: 99.05	
[09/17 13:18:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/17 13:18:31 visual_prompt]: Epoch 77 / 100: avg data time: 1.17e-01, avg batch time: 0.5189, average train loss: 1.1622
[09/17 13:18:34 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1430, average loss: 1.0743
[09/17 13:18:34 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 54.00	top5: 100.00	
[09/17 13:18:55 visual_prompt]: 	Test 100/235. loss: 1.450, 0.1841 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 13:19:15 visual_prompt]: 	Test 200/235. loss: 1.321, 0.1879 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 13:19:23 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1941, average loss: 1.3205
[09/17 13:19:23 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.17	top5: 98.98	
[09/17 13:19:23 visual_prompt]: Best epoch 77: best metric: 0.540
[09/17 13:19:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/17 13:19:32 visual_prompt]: Epoch 78 / 100: avg data time: 1.05e-01, avg batch time: 0.5127, average train loss: 1.0887
[09/17 13:19:35 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1432, average loss: 1.2974
[09/17 13:19:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 45.50	top5: 100.00	
[09/17 13:19:56 visual_prompt]: 	Test 100/235. loss: 1.485, 0.1839 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 13:20:16 visual_prompt]: 	Test 200/235. loss: 1.361, 0.1842 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 13:20:24 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1936, average loss: 1.5033
[09/17 13:20:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.85	top5: 98.97	
[09/17 13:20:24 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/17 13:20:33 visual_prompt]: Epoch 79 / 100: avg data time: 1.07e-01, avg batch time: 0.5097, average train loss: 0.9930
[09/17 13:20:36 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1430, average loss: 1.1215
[09/17 13:20:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 49.00	top5: 100.00	
[09/17 13:20:57 visual_prompt]: 	Test 100/235. loss: 1.464, 0.1979 s / batch. (data: 1.50e-02)max mem: 17.22447 GB 
[09/17 13:21:17 visual_prompt]: 	Test 200/235. loss: 1.379, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 13:21:24 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1938, average loss: 1.4091
[09/17 13:21:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.61	top5: 99.23	
[09/17 13:21:24 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/17 13:21:33 visual_prompt]: Epoch 80 / 100: avg data time: 9.96e-02, avg batch time: 0.5030, average train loss: 0.9855
[09/17 13:21:36 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1431, average loss: 1.7259
[09/17 13:21:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.00	top5: 99.00	
[09/17 13:21:57 visual_prompt]: 	Test 100/235. loss: 1.983, 0.1959 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 13:22:17 visual_prompt]: 	Test 200/235. loss: 1.777, 0.1991 s / batch. (data: 2.17e-04)max mem: 17.22447 GB 
[09/17 13:22:25 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1941, average loss: 1.9196
[09/17 13:22:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.09	top5: 97.73	
[09/17 13:22:25 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/17 13:22:34 visual_prompt]: Epoch 81 / 100: avg data time: 1.09e-01, avg batch time: 0.5122, average train loss: 0.9566
[09/17 13:22:37 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1430, average loss: 0.9737
[09/17 13:22:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.50	top5: 100.00	
[09/17 13:22:58 visual_prompt]: 	Test 100/235. loss: 1.447, 0.2130 s / batch. (data: 1.34e-02)max mem: 17.22447 GB 
[09/17 13:23:18 visual_prompt]: 	Test 200/235. loss: 1.273, 0.1838 s / batch. (data: 3.81e-05)max mem: 17.22447 GB 
[09/17 13:23:25 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1932, average loss: 1.3675
[09/17 13:23:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.14	top5: 99.11	
[09/17 13:23:26 visual_prompt]: Best epoch 81: best metric: 0.575
[09/17 13:23:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/17 13:23:35 visual_prompt]: Epoch 82 / 100: avg data time: 1.01e-01, avg batch time: 0.5052, average train loss: 1.0438
[09/17 13:23:38 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1431, average loss: 1.1654
[09/17 13:23:38 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 46.50	top5: 100.00	
[09/17 13:23:59 visual_prompt]: 	Test 100/235. loss: 1.559, 0.3762 s / batch. (data: 2.64e-02)max mem: 17.22447 GB 
[09/17 13:24:18 visual_prompt]: 	Test 200/235. loss: 1.434, 0.2078 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 13:24:26 visual_prompt]: Inference (test):avg data time: 6.83e-03, avg batch time: 0.1937, average loss: 1.4554
[09/17 13:24:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.17	top5: 99.19	
[09/17 13:24:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/17 13:24:35 visual_prompt]: Epoch 83 / 100: avg data time: 1.08e-01, avg batch time: 0.5128, average train loss: 1.0423
[09/17 13:24:38 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1431, average loss: 1.1599
[09/17 13:24:38 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 48.00	top5: 100.00	
[09/17 13:25:00 visual_prompt]: 	Test 100/235. loss: 1.479, 0.1893 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 13:25:19 visual_prompt]: 	Test 200/235. loss: 1.440, 0.1966 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 13:25:27 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1934, average loss: 1.4186
[09/17 13:25:27 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.11	top5: 98.64	
[09/17 13:25:27 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/17 13:25:36 visual_prompt]: Epoch 84 / 100: avg data time: 1.13e-01, avg batch time: 0.5153, average train loss: 0.8901
[09/17 13:25:39 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1431, average loss: 0.9441
[09/17 13:25:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 59.00	top5: 100.00	
[09/17 13:26:00 visual_prompt]: 	Test 100/235. loss: 1.406, 0.2019 s / batch. (data: 1.44e-02)max mem: 17.22447 GB 
[09/17 13:26:20 visual_prompt]: 	Test 200/235. loss: 1.278, 0.1840 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 13:26:27 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1928, average loss: 1.3361
[09/17 13:26:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.11	top5: 99.47	
[09/17 13:26:28 visual_prompt]: Best epoch 84: best metric: 0.590
[09/17 13:26:28 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/17 13:26:37 visual_prompt]: Epoch 85 / 100: avg data time: 1.05e-01, avg batch time: 0.5102, average train loss: 0.7933
[09/17 13:26:40 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1434, average loss: 0.9901
[09/17 13:26:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 53.00	top5: 100.00	
[09/17 13:27:02 visual_prompt]: 	Test 100/235. loss: 1.574, 0.1964 s / batch. (data: 1.46e-04)max mem: 17.22447 GB 
[09/17 13:27:21 visual_prompt]: 	Test 200/235. loss: 1.409, 0.1965 s / batch. (data: 1.32e-02)max mem: 17.22447 GB 
[09/17 13:27:29 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1963, average loss: 1.5245
[09/17 13:27:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.90	top5: 99.36	
[09/17 13:27:29 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 13:27:39 visual_prompt]: Epoch 86 / 100: avg data time: 1.12e-01, avg batch time: 0.5612, average train loss: 0.7662
[09/17 13:27:42 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1433, average loss: 0.9444
[09/17 13:27:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 61.00	top5: 100.00	
[09/17 13:28:03 visual_prompt]: 	Test 100/235. loss: 1.619, 0.1844 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 13:28:23 visual_prompt]: 	Test 200/235. loss: 1.363, 0.1886 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 13:28:31 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1940, average loss: 1.5072
[09/17 13:28:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.00	top5: 99.53	
[09/17 13:28:31 visual_prompt]: Best epoch 86: best metric: 0.610
[09/17 13:28:31 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 13:28:40 visual_prompt]: Epoch 87 / 100: avg data time: 9.98e-02, avg batch time: 0.5031, average train loss: 0.7728
[09/17 13:28:43 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 1.0311
[09/17 13:28:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.00	top5: 100.00	
[09/17 13:29:04 visual_prompt]: 	Test 100/235. loss: 1.629, 0.1918 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 13:29:23 visual_prompt]: 	Test 200/235. loss: 1.549, 0.1839 s / batch. (data: 1.58e-04)max mem: 17.22447 GB 
[09/17 13:29:31 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1939, average loss: 1.5936
[09/17 13:29:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.87	top5: 99.29	
[09/17 13:29:31 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 13:29:40 visual_prompt]: Epoch 88 / 100: avg data time: 1.05e-01, avg batch time: 0.5115, average train loss: 0.8161
[09/17 13:29:43 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1431, average loss: 1.5672
[09/17 13:29:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.50	top5: 100.00	
[09/17 13:30:04 visual_prompt]: 	Test 100/235. loss: 1.951, 0.2100 s / batch. (data: 1.50e-02)max mem: 17.22447 GB 
[09/17 13:30:24 visual_prompt]: 	Test 200/235. loss: 1.929, 0.1836 s / batch. (data: 1.54e-04)max mem: 17.22447 GB 
[09/17 13:30:31 visual_prompt]: Inference (test):avg data time: 6.89e-03, avg batch time: 0.1920, average loss: 1.9434
[09/17 13:30:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.21	top5: 98.53	
[09/17 13:30:31 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 13:30:41 visual_prompt]: Epoch 89 / 100: avg data time: 1.03e-01, avg batch time: 0.5065, average train loss: 0.7322
[09/17 13:30:44 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1431, average loss: 1.3541
[09/17 13:30:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.00	top5: 100.00	
[09/17 13:31:05 visual_prompt]: 	Test 100/235. loss: 1.912, 0.1840 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 13:31:25 visual_prompt]: 	Test 200/235. loss: 1.830, 0.2066 s / batch. (data: 9.89e-03)max mem: 17.22447 GB 
[09/17 13:31:33 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1982, average loss: 1.8310
[09/17 13:31:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.17	top5: 99.07	
[09/17 13:31:33 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 13:31:42 visual_prompt]: Epoch 90 / 100: avg data time: 9.88e-02, avg batch time: 0.5028, average train loss: 0.7537
[09/17 13:31:45 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1432, average loss: 0.9993
[09/17 13:31:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 54.00	top5: 100.00	
[09/17 13:32:06 visual_prompt]: 	Test 100/235. loss: 1.678, 0.2026 s / batch. (data: 1.48e-02)max mem: 17.22447 GB 
[09/17 13:32:26 visual_prompt]: 	Test 200/235. loss: 1.593, 0.2080 s / batch. (data: 2.49e-02)max mem: 17.22447 GB 
[09/17 13:32:33 visual_prompt]: Inference (test):avg data time: 6.84e-03, avg batch time: 0.1933, average loss: 1.6190
[09/17 13:32:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.44	top5: 99.41	
[09/17 13:32:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 13:32:43 visual_prompt]: Epoch 91 / 100: avg data time: 1.02e-01, avg batch time: 0.5051, average train loss: 0.6858
[09/17 13:32:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1431, average loss: 0.7786
[09/17 13:32:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 67.00	top5: 100.00	
[09/17 13:33:07 visual_prompt]: 	Test 100/235. loss: 1.566, 0.2422 s / batch. (data: 3.36e-02)max mem: 17.22447 GB 
[09/17 13:33:27 visual_prompt]: 	Test 200/235. loss: 1.430, 0.1890 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 13:33:35 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1956, average loss: 1.5261
[09/17 13:33:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.47	top5: 99.37	
[09/17 13:33:35 visual_prompt]: Best epoch 91: best metric: 0.670
[09/17 13:33:35 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 13:33:44 visual_prompt]: Epoch 92 / 100: avg data time: 1.04e-01, avg batch time: 0.5091, average train loss: 0.6803
[09/17 13:33:47 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1432, average loss: 0.8737
[09/17 13:33:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 59.50	top5: 100.00	
[09/17 13:34:08 visual_prompt]: 	Test 100/235. loss: 1.636, 0.1967 s / batch. (data: 1.33e-02)max mem: 17.22447 GB 
[09/17 13:34:27 visual_prompt]: 	Test 200/235. loss: 1.564, 0.1959 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 13:34:35 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1926, average loss: 1.5969
[09/17 13:34:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.66	top5: 99.44	
[09/17 13:34:35 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 13:34:44 visual_prompt]: Epoch 93 / 100: avg data time: 1.02e-01, avg batch time: 0.5064, average train loss: 0.6162
[09/17 13:34:47 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1437, average loss: 1.0177
[09/17 13:34:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.00	top5: 100.00	
[09/17 13:35:08 visual_prompt]: 	Test 100/235. loss: 1.730, 0.2025 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 13:35:28 visual_prompt]: 	Test 200/235. loss: 1.696, 0.2144 s / batch. (data: 3.12e-02)max mem: 17.22447 GB 
[09/17 13:35:36 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1933, average loss: 1.7217
[09/17 13:35:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.63	top5: 99.41	
[09/17 13:35:36 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 13:35:45 visual_prompt]: Epoch 94 / 100: avg data time: 9.64e-02, avg batch time: 0.5019, average train loss: 0.5572
[09/17 13:35:48 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1431, average loss: 0.8343
[09/17 13:35:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 63.00	top5: 100.00	
[09/17 13:36:09 visual_prompt]: 	Test 100/235. loss: 1.696, 0.1955 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 13:36:29 visual_prompt]: 	Test 200/235. loss: 1.643, 0.1842 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 13:36:36 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1949, average loss: 1.6599
[09/17 13:36:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.45	top5: 99.47	
[09/17 13:36:36 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 13:36:45 visual_prompt]: Epoch 95 / 100: avg data time: 9.17e-02, avg batch time: 0.4978, average train loss: 0.5282
[09/17 13:36:49 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1431, average loss: 0.9821
[09/17 13:36:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 58.50	top5: 100.00	
[09/17 13:37:10 visual_prompt]: 	Test 100/235. loss: 1.778, 0.1940 s / batch. (data: 1.10e-02)max mem: 17.22447 GB 
[09/17 13:37:30 visual_prompt]: 	Test 200/235. loss: 1.774, 0.2099 s / batch. (data: 2.72e-02)max mem: 17.22447 GB 
[09/17 13:37:38 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1967, average loss: 1.7875
[09/17 13:37:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.90	top5: 99.43	
[09/17 13:37:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 13:37:47 visual_prompt]: Epoch 96 / 100: avg data time: 1.01e-01, avg batch time: 0.5042, average train loss: 0.5008
[09/17 13:37:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1431, average loss: 0.9428
[09/17 13:37:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 55.00	top5: 100.00	
[09/17 13:38:11 visual_prompt]: 	Test 100/235. loss: 1.745, 0.1966 s / batch. (data: 1.33e-02)max mem: 17.22447 GB 
[09/17 13:38:31 visual_prompt]: 	Test 200/235. loss: 1.740, 0.1865 s / batch. (data: 1.78e-04)max mem: 17.22447 GB 
[09/17 13:38:39 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1938, average loss: 1.7719
[09/17 13:38:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.85	top5: 99.48	
[09/17 13:38:39 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 13:38:48 visual_prompt]: Epoch 97 / 100: avg data time: 1.00e-01, avg batch time: 0.5046, average train loss: 0.5097
[09/17 13:38:51 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1432, average loss: 0.9368
[09/17 13:38:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 58.50	top5: 100.00	
[09/17 13:39:12 visual_prompt]: 	Test 100/235. loss: 1.749, 0.1952 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 13:39:31 visual_prompt]: 	Test 200/235. loss: 1.735, 0.1887 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 13:39:39 visual_prompt]: Inference (test):avg data time: 6.77e-03, avg batch time: 0.1927, average loss: 1.7866
[09/17 13:39:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.02	top5: 99.47	
[09/17 13:39:39 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 13:39:48 visual_prompt]: Epoch 98 / 100: avg data time: 1.03e-01, avg batch time: 0.5108, average train loss: 0.5018
[09/17 13:39:51 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1431, average loss: 0.8613
[09/17 13:39:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 61.00	top5: 100.00	
[09/17 13:40:12 visual_prompt]: 	Test 100/235. loss: 1.724, 0.1837 s / batch. (data: 1.91e-04)max mem: 17.22447 GB 
[09/17 13:40:32 visual_prompt]: 	Test 200/235. loss: 1.697, 0.1839 s / batch. (data: 9.85e-05)max mem: 17.22447 GB 
[09/17 13:40:40 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1967, average loss: 1.7594
[09/17 13:40:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.47	top5: 99.48	
[09/17 13:40:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 13:40:49 visual_prompt]: Epoch 99 / 100: avg data time: 1.11e-01, avg batch time: 0.5128, average train loss: 0.4835
[09/17 13:40:52 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1433, average loss: 1.0297
[09/17 13:40:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 55.00	top5: 100.00	
[09/17 13:41:14 visual_prompt]: 	Test 100/235. loss: 1.822, 0.1991 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 13:41:33 visual_prompt]: 	Test 200/235. loss: 1.820, 0.2100 s / batch. (data: 2.73e-02)max mem: 17.22447 GB 
[09/17 13:41:41 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1941, average loss: 1.8567
[09/17 13:41:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.09	top5: 99.43	
[09/17 13:41:41 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 13:41:50 visual_prompt]: Epoch 100 / 100: avg data time: 1.10e-01, avg batch time: 0.5143, average train loss: 0.4823
[09/17 13:41:53 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1432, average loss: 0.9689
[09/17 13:41:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.50	top5: 100.00	
[09/17 13:42:14 visual_prompt]: 	Test 100/235. loss: 1.791, 0.2123 s / batch. (data: 2.94e-02)max mem: 17.22447 GB 
[09/17 13:42:34 visual_prompt]: 	Test 200/235. loss: 1.778, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 13:42:42 visual_prompt]: Inference (test):avg data time: 7.18e-03, avg batch time: 0.1935, average loss: 1.8238
[09/17 13:42:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.56	top5: 99.43	
[09/17 13:43:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/17 13:43:14 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 13:43:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-clevr(task="count_all")', 'DATA.NUMBER_CLASSES', '8', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/17 13:43:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 13:43:14 visual_prompt]: Training with config:
[09/17 13:43:14 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-clevr(task="count_all")',
          'NO_TEST': False,
          'NUMBER_CLASSES': 8,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-clevr(task="count_all")/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 13:43:14 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-17 13:43:14.971903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-17 13:43:15.149686: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-17 13:43:19.870515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 13:43:19.870629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 13:43:19.870644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-17 13:43:28.401864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 13:43:28.402196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 13:43:28.402237: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/17 13:43:28 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
2023-09-17 13:43:28.557945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[:800]+train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 13:43:34 visual_prompt]: Number of images: 1000
[09/17 13:43:34 visual_prompt]: Number of classes: 8 / 8
[09/17 13:43:34 visual_prompt]: Loading validation data...
[09/17 13:43:34 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 13:43:35 visual_prompt]: Number of images: 200
[09/17 13:43:35 visual_prompt]: Number of classes: 8 / 8
[09/17 13:43:35 visual_prompt]: Loading test data...
[09/17 13:43:35 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split validation, from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 13:44:51 visual_prompt]: Number of images: 15000
[09/17 13:44:51 visual_prompt]: Number of classes: 8 / 8
[09/17 13:44:51 visual_prompt]: Constructing models...
[09/17 13:44:54 visual_prompt]: Total Parameters: 86726408	 Gradient Parameters: 927752
[09/17 13:44:54 visual_prompt]: tuned percent:1.070
[09/17 13:44:57 visual_prompt]: Device used for model: 0
[09/17 13:44:57 visual_prompt]: Setting up Evalutator...
[09/17 13:44:57 visual_prompt]: Setting up Trainer...
[09/17 13:44:57 visual_prompt]: 	Setting up the optimizer...
[09/17 13:44:57 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/17 13:45:07 visual_prompt]: Epoch 1 / 100: avg data time: 1.23e-01, avg batch time: 0.5986, average train loss: 2.4600
[09/17 13:45:11 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1422, average loss: 2.5080
[09/17 13:45:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 57.50	
[09/17 13:45:32 visual_prompt]: 	Test 100/235. loss: 2.374, 0.1817 s / batch. (data: 1.60e-04)max mem: 17.22447 GB 
[09/17 13:45:51 visual_prompt]: 	Test 200/235. loss: 2.457, 0.1848 s / batch. (data: 3.43e-05)max mem: 17.22447 GB 
[09/17 13:45:59 visual_prompt]: Inference (test):avg data time: 6.92e-03, avg batch time: 0.1922, average loss: 2.4398
[09/17 13:45:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 63.27	
[09/17 13:45:59 visual_prompt]: Best epoch 1: best metric: 0.105
[09/17 13:45:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/17 13:46:08 visual_prompt]: Epoch 2 / 100: avg data time: 1.00e-01, avg batch time: 0.5078, average train loss: 3.9145
[09/17 13:46:11 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1428, average loss: 3.3655
[09/17 13:46:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 65.00	
[09/17 13:46:32 visual_prompt]: 	Test 100/235. loss: 3.806, 0.1956 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 13:46:52 visual_prompt]: 	Test 200/235. loss: 3.718, 0.1858 s / batch. (data: 1.12e-04)max mem: 17.22447 GB 
[09/17 13:46:59 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1929, average loss: 3.6142
[09/17 13:46:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 63.09	
[09/17 13:46:59 visual_prompt]: Best epoch 2: best metric: 0.145
[09/17 13:46:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/17 13:47:09 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e-01, avg batch time: 0.5072, average train loss: 2.7410
[09/17 13:47:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1431, average loss: 2.3192
[09/17 13:47:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 63.50	
[09/17 13:47:33 visual_prompt]: 	Test 100/235. loss: 2.403, 0.1841 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 13:47:52 visual_prompt]: 	Test 200/235. loss: 2.305, 0.1839 s / batch. (data: 1.47e-04)max mem: 17.22447 GB 
[09/17 13:48:00 visual_prompt]: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1932, average loss: 2.3542
[09/17 13:48:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 62.69	
[09/17 13:48:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/17 13:48:09 visual_prompt]: Epoch 4 / 100: avg data time: 1.13e-01, avg batch time: 0.5227, average train loss: 2.3584
[09/17 13:48:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1431, average loss: 2.3399
[09/17 13:48:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 71.00	
[09/17 13:48:34 visual_prompt]: 	Test 100/235. loss: 2.528, 0.1838 s / batch. (data: 1.36e-04)max mem: 17.22447 GB 
[09/17 13:48:53 visual_prompt]: 	Test 200/235. loss: 2.344, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 13:49:01 visual_prompt]: Inference (test):avg data time: 8.55e-03, avg batch time: 0.1948, average loss: 2.3941
[09/17 13:49:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 71.33	
[09/17 13:49:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/17 13:49:11 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e-01, avg batch time: 0.5230, average train loss: 2.5267
[09/17 13:49:14 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1498, average loss: 2.7928
[09/17 13:49:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 61.50	
[09/17 13:49:35 visual_prompt]: 	Test 100/235. loss: 2.830, 0.1936 s / batch. (data: 1.06e-02)max mem: 17.22447 GB 
[09/17 13:49:54 visual_prompt]: 	Test 200/235. loss: 2.935, 0.1838 s / batch. (data: 6.99e-05)max mem: 17.22447 GB 
[09/17 13:50:02 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1942, average loss: 2.8169
[09/17 13:50:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 62.20	
[09/17 13:50:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/17 13:50:11 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e-01, avg batch time: 0.5092, average train loss: 3.1646
[09/17 13:50:14 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1435, average loss: 5.0270
[09/17 13:50:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 59.50	
[09/17 13:50:36 visual_prompt]: 	Test 100/235. loss: 5.289, 0.1840 s / batch. (data: 1.46e-04)max mem: 17.22447 GB 
[09/17 13:50:55 visual_prompt]: 	Test 200/235. loss: 5.069, 0.1994 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 13:51:03 visual_prompt]: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1935, average loss: 4.8787
[09/17 13:51:03 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.49	top5: 62.49	
[09/17 13:51:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/17 13:51:12 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e-02, avg batch time: 0.5044, average train loss: 4.9469
[09/17 13:51:15 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1432, average loss: 4.7467
[09/17 13:51:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 65.00	
[09/17 13:51:36 visual_prompt]: 	Test 100/235. loss: 4.776, 0.1959 s / batch. (data: 3.74e-05)max mem: 17.22447 GB 
[09/17 13:51:56 visual_prompt]: 	Test 200/235. loss: 4.719, 0.1838 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 13:52:04 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1937, average loss: 4.6322
[09/17 13:52:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 63.31	
[09/17 13:52:04 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/17 13:52:13 visual_prompt]: Epoch 8 / 100: avg data time: 1.10e-01, avg batch time: 0.5138, average train loss: 6.2370
[09/17 13:52:16 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1433, average loss: 7.0046
[09/17 13:52:16 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 63.50	
[09/17 13:52:37 visual_prompt]: 	Test 100/235. loss: 6.798, 0.2113 s / batch. (data: 2.60e-02)max mem: 17.22447 GB 
[09/17 13:52:57 visual_prompt]: 	Test 200/235. loss: 7.071, 0.2050 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 13:53:05 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1933, average loss: 6.9535
[09/17 13:53:05 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 63.73	
[09/17 13:53:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/17 13:53:14 visual_prompt]: Epoch 9 / 100: avg data time: 1.14e-01, avg batch time: 0.5197, average train loss: 4.5909
[09/17 13:53:17 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1431, average loss: 4.9888
[09/17 13:53:17 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 63.50	
[09/17 13:53:38 visual_prompt]: 	Test 100/235. loss: 4.793, 0.1847 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 13:53:58 visual_prompt]: 	Test 200/235. loss: 4.425, 0.2052 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 13:54:06 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1938, average loss: 4.9412
[09/17 13:54:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 62.46	
[09/17 13:54:06 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/17 13:54:15 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e-01, avg batch time: 0.5095, average train loss: 6.6800
[09/17 13:54:18 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1431, average loss: 6.3190
[09/17 13:54:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 60.50	
[09/17 13:54:39 visual_prompt]: 	Test 100/235. loss: 5.517, 0.2100 s / batch. (data: 2.69e-02)max mem: 17.22447 GB 
[09/17 13:54:59 visual_prompt]: 	Test 200/235. loss: 6.580, 0.2051 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 13:55:06 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1936, average loss: 6.1854
[09/17 13:55:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 61.71	
[09/17 13:55:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/17 13:55:16 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e-01, avg batch time: 0.5113, average train loss: 8.1533
[09/17 13:55:19 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1432, average loss: 8.2929
[09/17 13:55:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 65.00	
[09/17 13:55:40 visual_prompt]: 	Test 100/235. loss: 7.799, 0.1836 s / batch. (data: 3.77e-05)max mem: 17.22447 GB 
[09/17 13:56:00 visual_prompt]: 	Test 200/235. loss: 8.286, 0.1848 s / batch. (data: 1.17e-04)max mem: 17.22447 GB 
[09/17 13:56:07 visual_prompt]: Inference (test):avg data time: 7.17e-03, avg batch time: 0.1945, average loss: 8.3038
[09/17 13:56:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.51	
[09/17 13:56:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/17 13:56:17 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e-01, avg batch time: 0.5088, average train loss: 11.5404
[09/17 13:56:20 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1430, average loss: 10.8095
[09/17 13:56:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 64.50	
[09/17 13:56:41 visual_prompt]: 	Test 100/235. loss: 10.889, 0.1998 s / batch. (data: 1.67e-02)max mem: 17.22447 GB 
[09/17 13:57:00 visual_prompt]: 	Test 200/235. loss: 11.296, 0.2047 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 13:57:08 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1935, average loss: 11.0464
[09/17 13:57:08 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.85	
[09/17 13:57:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/17 13:57:17 visual_prompt]: Epoch 13 / 100: avg data time: 1.12e-01, avg batch time: 0.5129, average train loss: 10.8365
[09/17 13:57:20 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1443, average loss: 9.1086
[09/17 13:57:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 64.00	
[09/17 13:57:42 visual_prompt]: 	Test 100/235. loss: 10.433, 0.1839 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 13:58:01 visual_prompt]: 	Test 200/235. loss: 9.289, 0.1857 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 13:58:09 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1929, average loss: 9.3913
[09/17 13:58:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.92	
[09/17 13:58:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/17 13:58:18 visual_prompt]: Epoch 14 / 100: avg data time: 9.51e-02, avg batch time: 0.4990, average train loss: 8.8403
[09/17 13:58:21 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1432, average loss: 8.2352
[09/17 13:58:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 63.50	
[09/17 13:58:42 visual_prompt]: 	Test 100/235. loss: 8.865, 0.1963 s / batch. (data: 1.30e-04)max mem: 17.22447 GB 
[09/17 13:59:02 visual_prompt]: 	Test 200/235. loss: 7.918, 0.2006 s / batch. (data: 1.72e-02)max mem: 17.22447 GB 
[09/17 13:59:10 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1967, average loss: 8.5278
[09/17 13:59:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.69	
[09/17 13:59:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/17 13:59:19 visual_prompt]: Epoch 15 / 100: avg data time: 9.73e-02, avg batch time: 0.5019, average train loss: 6.7852
[09/17 13:59:22 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1432, average loss: 8.4026
[09/17 13:59:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 62.00	
[09/17 13:59:43 visual_prompt]: 	Test 100/235. loss: 9.250, 0.2040 s / batch. (data: 2.08e-02)max mem: 17.22447 GB 
[09/17 14:00:03 visual_prompt]: 	Test 200/235. loss: 8.787, 0.1988 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 14:00:10 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1923, average loss: 8.1698
[09/17 14:00:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.29	top5: 62.66	
[09/17 14:00:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/17 14:00:20 visual_prompt]: Epoch 16 / 100: avg data time: 1.08e-01, avg batch time: 0.5098, average train loss: 6.3504
[09/17 14:00:23 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 8.1253
[09/17 14:00:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 58.00	
[09/17 14:00:44 visual_prompt]: 	Test 100/235. loss: 8.516, 0.1838 s / batch. (data: 1.63e-04)max mem: 17.22447 GB 
[09/17 14:01:03 visual_prompt]: 	Test 200/235. loss: 8.490, 0.1990 s / batch. (data: 1.54e-02)max mem: 17.22447 GB 
[09/17 14:01:11 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1936, average loss: 7.7768
[09/17 14:01:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 61.88	
[09/17 14:01:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/17 14:01:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.10e-01, avg batch time: 0.5128, average train loss: 6.5301
[09/17 14:01:24 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1432, average loss: 8.1914
[09/17 14:01:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 11.00	top5: 65.50	
[09/17 14:01:45 visual_prompt]: 	Test 100/235. loss: 8.777, 0.2122 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 14:02:04 visual_prompt]: 	Test 200/235. loss: 8.370, 0.1964 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 14:02:12 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1941, average loss: 8.6354
[09/17 14:02:12 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.51	top5: 62.40	
[09/17 14:02:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/17 14:02:21 visual_prompt]: Epoch 18 / 100: avg data time: 9.55e-02, avg batch time: 0.5011, average train loss: 6.6701
[09/17 14:02:24 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1432, average loss: 8.9376
[09/17 14:02:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 67.50	
[09/17 14:02:46 visual_prompt]: 	Test 100/235. loss: 8.971, 0.1847 s / batch. (data: 2.74e-04)max mem: 17.22447 GB 
[09/17 14:03:05 visual_prompt]: 	Test 200/235. loss: 9.276, 0.1982 s / batch. (data: 1.47e-02)max mem: 17.22447 GB 
[09/17 14:03:13 visual_prompt]: Inference (test):avg data time: 6.78e-03, avg batch time: 0.1929, average loss: 9.1894
[09/17 14:03:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 63.15	
[09/17 14:03:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/17 14:03:22 visual_prompt]: Epoch 19 / 100: avg data time: 1.00e-01, avg batch time: 0.5046, average train loss: 7.0925
[09/17 14:03:25 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1463, average loss: 5.1372
[09/17 14:03:25 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 65.50	
[09/17 14:03:46 visual_prompt]: 	Test 100/235. loss: 5.234, 0.1997 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 14:04:06 visual_prompt]: 	Test 200/235. loss: 5.624, 0.1835 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 14:04:14 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1936, average loss: 5.3496
[09/17 14:04:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.74	
[09/17 14:04:14 visual_prompt]: Best epoch 19: best metric: 0.160
[09/17 14:04:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/17 14:04:23 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e-01, avg batch time: 0.5113, average train loss: 4.1803
[09/17 14:04:26 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 3.5082
[09/17 14:04:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 18.00	top5: 66.00	
[09/17 14:04:47 visual_prompt]: 	Test 100/235. loss: 4.184, 0.1832 s / batch. (data: 1.11e-04)max mem: 17.22447 GB 
[09/17 14:05:07 visual_prompt]: 	Test 200/235. loss: 3.878, 0.1994 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 14:05:14 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1931, average loss: 3.6873
[09/17 14:05:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 17.41	top5: 62.91	
[09/17 14:05:14 visual_prompt]: Best epoch 20: best metric: 0.180
[09/17 14:05:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/17 14:05:24 visual_prompt]: Epoch 21 / 100: avg data time: 1.10e-01, avg batch time: 0.5170, average train loss: 4.5780
[09/17 14:05:27 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1432, average loss: 3.6941
[09/17 14:05:27 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 69.50	
[09/17 14:05:48 visual_prompt]: 	Test 100/235. loss: 3.865, 0.1941 s / batch. (data: 1.80e-03)max mem: 17.22447 GB 
[09/17 14:06:07 visual_prompt]: 	Test 200/235. loss: 3.720, 0.1840 s / batch. (data: 1.79e-04)max mem: 17.22447 GB 
[09/17 14:06:15 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1934, average loss: 3.5807
[09/17 14:06:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 70.71	
[09/17 14:06:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/17 14:06:24 visual_prompt]: Epoch 22 / 100: avg data time: 1.01e-01, avg batch time: 0.5040, average train loss: 2.9517
[09/17 14:06:27 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1433, average loss: 3.0339
[09/17 14:06:27 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.50	top5: 73.50	
[09/17 14:06:49 visual_prompt]: 	Test 100/235. loss: 3.657, 0.2099 s / batch. (data: 2.74e-02)max mem: 17.22447 GB 
[09/17 14:07:08 visual_prompt]: 	Test 200/235. loss: 3.366, 0.1970 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 14:07:16 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1936, average loss: 3.2821
[09/17 14:07:16 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.14	top5: 69.63	
[09/17 14:07:16 visual_prompt]: Best epoch 22: best metric: 0.215
[09/17 14:07:16 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/17 14:07:25 visual_prompt]: Epoch 23 / 100: avg data time: 1.02e-01, avg batch time: 0.5087, average train loss: 2.4117
[09/17 14:07:28 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1432, average loss: 2.4189
[09/17 14:07:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.50	top5: 80.50	
[09/17 14:07:50 visual_prompt]: 	Test 100/235. loss: 2.785, 0.1869 s / batch. (data: 3.86e-05)max mem: 17.22447 GB 
[09/17 14:08:09 visual_prompt]: 	Test 200/235. loss: 2.624, 0.1956 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 14:08:17 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1952, average loss: 2.4554
[09/17 14:08:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 17.40	top5: 76.99	
[09/17 14:08:17 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/17 14:08:27 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e-01, avg batch time: 0.5068, average train loss: 1.9976
[09/17 14:08:29 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1432, average loss: 1.5998
[09/17 14:08:29 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.50	top5: 97.50	
[09/17 14:08:51 visual_prompt]: 	Test 100/235. loss: 1.708, 0.2096 s / batch. (data: 2.64e-02)max mem: 17.22447 GB 
[09/17 14:09:10 visual_prompt]: 	Test 200/235. loss: 1.555, 0.2013 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 14:09:18 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1948, average loss: 1.6163
[09/17 14:09:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.61	top5: 97.03	
[09/17 14:09:18 visual_prompt]: Best epoch 24: best metric: 0.265
[09/17 14:09:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/17 14:09:27 visual_prompt]: Epoch 25 / 100: avg data time: 1.02e-01, avg batch time: 0.5045, average train loss: 1.9310
[09/17 14:09:30 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1431, average loss: 2.2269
[09/17 14:09:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 31.50	top5: 91.50	
[09/17 14:09:52 visual_prompt]: 	Test 100/235. loss: 2.214, 0.1894 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 14:10:11 visual_prompt]: 	Test 200/235. loss: 2.350, 0.1840 s / batch. (data: 1.69e-04)max mem: 17.22447 GB 
[09/17 14:10:19 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1938, average loss: 2.2808
[09/17 14:10:19 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.83	top5: 88.87	
[09/17 14:10:19 visual_prompt]: Best epoch 25: best metric: 0.315
[09/17 14:10:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/17 14:10:28 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e-01, avg batch time: 0.5086, average train loss: 2.1627
[09/17 14:10:31 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1434, average loss: 2.8597
[09/17 14:10:31 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.00	top5: 79.50	
[09/17 14:10:53 visual_prompt]: 	Test 100/235. loss: 3.272, 0.1844 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 14:11:12 visual_prompt]: 	Test 200/235. loss: 3.079, 0.1946 s / batch. (data: 1.12e-02)max mem: 17.22447 GB 
[09/17 14:11:20 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1937, average loss: 3.0402
[09/17 14:11:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 20.51	top5: 74.51	
[09/17 14:11:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/17 14:11:29 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e-01, avg batch time: 0.5119, average train loss: 2.3560
[09/17 14:11:32 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1460, average loss: 2.2725
[09/17 14:11:32 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.00	top5: 81.00	
[09/17 14:11:54 visual_prompt]: 	Test 100/235. loss: 2.190, 0.1981 s / batch. (data: 1.11e-02)max mem: 17.22447 GB 
[09/17 14:12:13 visual_prompt]: 	Test 200/235. loss: 2.120, 0.1874 s / batch. (data: 1.60e-04)max mem: 17.22447 GB 
[09/17 14:12:21 visual_prompt]: Inference (test):avg data time: 7.31e-03, avg batch time: 0.1938, average loss: 2.1899
[09/17 14:12:21 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.39	top5: 82.93	
[09/17 14:12:21 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/17 14:12:30 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e-01, avg batch time: 0.5096, average train loss: 2.0947
[09/17 14:12:33 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1432, average loss: 2.4110
[09/17 14:12:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.50	top5: 79.50	
[09/17 14:12:55 visual_prompt]: 	Test 100/235. loss: 2.770, 0.2125 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 14:13:14 visual_prompt]: 	Test 200/235. loss: 2.524, 0.1844 s / batch. (data: 1.16e-04)max mem: 17.22447 GB 
[09/17 14:13:22 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1938, average loss: 2.5715
[09/17 14:13:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.97	top5: 77.31	
[09/17 14:13:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/17 14:13:31 visual_prompt]: Epoch 29 / 100: avg data time: 1.13e-01, avg batch time: 0.5169, average train loss: 2.0458
[09/17 14:13:34 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1433, average loss: 2.0492
[09/17 14:13:34 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 95.00	
[09/17 14:13:55 visual_prompt]: 	Test 100/235. loss: 2.193, 0.2080 s / batch. (data: 2.47e-02)max mem: 17.22447 GB 
[09/17 14:14:15 visual_prompt]: 	Test 200/235. loss: 2.135, 0.1840 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 14:14:23 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1937, average loss: 2.1384
[09/17 14:14:23 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.39	top5: 94.61	
[09/17 14:14:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/17 14:14:32 visual_prompt]: Epoch 30 / 100: avg data time: 1.14e-01, avg batch time: 0.5155, average train loss: 1.9097
[09/17 14:14:35 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1432, average loss: 1.7940
[09/17 14:14:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.50	top5: 97.00	
[09/17 14:14:57 visual_prompt]: 	Test 100/235. loss: 1.889, 0.1912 s / batch. (data: 7.63e-03)max mem: 17.22447 GB 
[09/17 14:15:16 visual_prompt]: 	Test 200/235. loss: 1.843, 0.2132 s / batch. (data: 2.82e-02)max mem: 17.22447 GB 
[09/17 14:15:24 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1949, average loss: 1.8107
[09/17 14:15:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.67	top5: 95.09	
[09/17 14:15:24 visual_prompt]: Best epoch 30: best metric: 0.325
[09/17 14:15:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/17 14:15:33 visual_prompt]: Epoch 31 / 100: avg data time: 1.13e-01, avg batch time: 0.5173, average train loss: 1.7330
[09/17 14:15:36 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1433, average loss: 1.6504
[09/17 14:15:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.50	top5: 97.00	
[09/17 14:15:57 visual_prompt]: 	Test 100/235. loss: 1.830, 0.2042 s / batch. (data: 3.18e-04)max mem: 17.22447 GB 
[09/17 14:16:17 visual_prompt]: 	Test 200/235. loss: 1.787, 0.1991 s / batch. (data: 1.57e-02)max mem: 17.22447 GB 
[09/17 14:16:25 visual_prompt]: Inference (test):avg data time: 7.30e-03, avg batch time: 0.1934, average loss: 1.7331
[09/17 14:16:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.39	top5: 95.33	
[09/17 14:16:25 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/17 14:16:34 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e-01, avg batch time: 0.5122, average train loss: 2.0450
[09/17 14:16:37 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1433, average loss: 1.8572
[09/17 14:16:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.50	top5: 91.50	
[09/17 14:16:58 visual_prompt]: 	Test 100/235. loss: 2.098, 0.1981 s / batch. (data: 1.03e-02)max mem: 17.22447 GB 
[09/17 14:17:18 visual_prompt]: 	Test 200/235. loss: 1.999, 0.1836 s / batch. (data: 1.50e-04)max mem: 17.22447 GB 
[09/17 14:17:26 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1935, average loss: 1.9507
[09/17 14:17:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.14	top5: 89.76	
[09/17 14:17:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/17 14:17:35 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e-01, avg batch time: 0.5113, average train loss: 1.8308
[09/17 14:17:38 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1435, average loss: 1.6975
[09/17 14:17:38 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 96.50	
[09/17 14:17:59 visual_prompt]: 	Test 100/235. loss: 1.898, 0.1844 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 14:18:18 visual_prompt]: 	Test 200/235. loss: 1.725, 0.2079 s / batch. (data: 2.45e-02)max mem: 17.22447 GB 
[09/17 14:18:26 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1930, average loss: 1.7341
[09/17 14:18:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.44	top5: 94.68	
[09/17 14:18:26 visual_prompt]: Best epoch 33: best metric: 0.375
[09/17 14:18:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/17 14:18:36 visual_prompt]: Epoch 34 / 100: avg data time: 1.09e-01, avg batch time: 0.5134, average train loss: 1.7423
[09/17 14:18:39 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1432, average loss: 1.5551
[09/17 14:18:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.00	top5: 92.50	
[09/17 14:19:00 visual_prompt]: 	Test 100/235. loss: 1.783, 0.1958 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 14:19:19 visual_prompt]: 	Test 200/235. loss: 1.687, 0.1857 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 14:19:27 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1926, average loss: 1.5563
[09/17 14:19:27 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 38.28	top5: 92.22	
[09/17 14:19:27 visual_prompt]: Best epoch 34: best metric: 0.380
[09/17 14:19:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/17 14:19:36 visual_prompt]: Epoch 35 / 100: avg data time: 1.17e-01, avg batch time: 0.5189, average train loss: 1.7025
[09/17 14:19:39 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1432, average loss: 2.2601
[09/17 14:19:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 24.00	top5: 87.50	
[09/17 14:20:00 visual_prompt]: 	Test 100/235. loss: 2.934, 0.1842 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 14:20:20 visual_prompt]: 	Test 200/235. loss: 2.508, 0.1836 s / batch. (data: 1.11e-04)max mem: 17.22447 GB 
[09/17 14:20:28 visual_prompt]: Inference (test):avg data time: 6.76e-03, avg batch time: 0.1931, average loss: 2.4958
[09/17 14:20:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 20.51	top5: 83.98	
[09/17 14:20:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/17 14:20:37 visual_prompt]: Epoch 36 / 100: avg data time: 9.27e-02, avg batch time: 0.4968, average train loss: 1.6949
[09/17 14:20:40 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1432, average loss: 1.8814
[09/17 14:20:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.00	top5: 96.00	
[09/17 14:21:01 visual_prompt]: 	Test 100/235. loss: 2.187, 0.1990 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 14:21:20 visual_prompt]: 	Test 200/235. loss: 2.046, 0.1836 s / batch. (data: 1.18e-04)max mem: 17.22447 GB 
[09/17 14:21:28 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1929, average loss: 1.9838
[09/17 14:21:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 26.83	top5: 94.27	
[09/17 14:21:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/17 14:21:37 visual_prompt]: Epoch 37 / 100: avg data time: 9.99e-02, avg batch time: 0.5021, average train loss: 1.6777
[09/17 14:21:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1430, average loss: 1.5385
[09/17 14:21:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.50	top5: 99.00	
[09/17 14:22:01 visual_prompt]: 	Test 100/235. loss: 1.646, 0.1839 s / batch. (data: 1.16e-04)max mem: 17.22447 GB 
[09/17 14:22:21 visual_prompt]: 	Test 200/235. loss: 1.586, 0.2031 s / batch. (data: 2.01e-02)max mem: 17.22447 GB 
[09/17 14:22:29 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1935, average loss: 1.5949
[09/17 14:22:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.87	top5: 97.85	
[09/17 14:22:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/17 14:22:38 visual_prompt]: Epoch 38 / 100: avg data time: 1.09e-01, avg batch time: 0.5115, average train loss: 1.6428
[09/17 14:22:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1432, average loss: 1.6761
[09/17 14:22:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.50	top5: 97.50	
[09/17 14:23:02 visual_prompt]: 	Test 100/235. loss: 2.241, 0.1915 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 14:23:22 visual_prompt]: 	Test 200/235. loss: 1.934, 0.1843 s / batch. (data: 9.70e-05)max mem: 17.22447 GB 
[09/17 14:23:30 visual_prompt]: Inference (test):avg data time: 8.64e-03, avg batch time: 0.1942, average loss: 1.8850
[09/17 14:23:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.87	top5: 95.03	
[09/17 14:23:30 visual_prompt]: Best epoch 38: best metric: 0.385
[09/17 14:23:30 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/17 14:23:39 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e-01, avg batch time: 0.5092, average train loss: 1.6240
[09/17 14:23:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1433, average loss: 1.6247
[09/17 14:23:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.50	top5: 99.50	
[09/17 14:24:03 visual_prompt]: 	Test 100/235. loss: 1.937, 0.1988 s / batch. (data: 1.55e-02)max mem: 17.22447 GB 
[09/17 14:24:22 visual_prompt]: 	Test 200/235. loss: 1.726, 0.1963 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 14:24:30 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1935, average loss: 1.6332
[09/17 14:24:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.47	top5: 99.13	
[09/17 14:24:30 visual_prompt]: Best epoch 39: best metric: 0.395
[09/17 14:24:30 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/17 14:24:39 visual_prompt]: Epoch 40 / 100: avg data time: 1.12e-01, avg batch time: 0.5151, average train loss: 1.7024
[09/17 14:24:43 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1433, average loss: 2.4077
[09/17 14:24:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.00	top5: 79.50	
[09/17 14:25:03 visual_prompt]: 	Test 100/235. loss: 2.855, 0.1836 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 14:25:23 visual_prompt]: 	Test 200/235. loss: 2.642, 0.2069 s / batch. (data: 2.22e-02)max mem: 17.22447 GB 
[09/17 14:25:31 visual_prompt]: Inference (test):avg data time: 9.08e-03, avg batch time: 0.1938, average loss: 2.6433
[09/17 14:25:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 15.25	top5: 72.15	
[09/17 14:25:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/17 14:25:40 visual_prompt]: Epoch 41 / 100: avg data time: 1.08e-01, avg batch time: 0.5139, average train loss: 1.8589
[09/17 14:25:43 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1433, average loss: 1.8746
[09/17 14:25:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.00	top5: 92.50	
[09/17 14:26:04 visual_prompt]: 	Test 100/235. loss: 2.180, 0.1836 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 14:26:24 visual_prompt]: 	Test 200/235. loss: 1.999, 0.2009 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 14:26:31 visual_prompt]: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1929, average loss: 2.0154
[09/17 14:26:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.61	top5: 89.96	
[09/17 14:26:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/17 14:26:41 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e-01, avg batch time: 0.5077, average train loss: 1.5884
[09/17 14:26:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1433, average loss: 1.1489
[09/17 14:26:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 48.00	top5: 100.00	
[09/17 14:27:05 visual_prompt]: 	Test 100/235. loss: 1.279, 0.1835 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 14:27:24 visual_prompt]: 	Test 200/235. loss: 1.465, 0.2003 s / batch. (data: 1.69e-02)max mem: 17.22447 GB 
[09/17 14:27:32 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1940, average loss: 1.2739
[09/17 14:27:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.11	top5: 99.87	
[09/17 14:27:32 visual_prompt]: Best epoch 42: best metric: 0.480
[09/17 14:27:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/17 14:27:41 visual_prompt]: Epoch 43 / 100: avg data time: 1.05e-01, avg batch time: 0.5087, average train loss: 1.4222
[09/17 14:27:44 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1432, average loss: 1.3940
[09/17 14:27:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.00	top5: 100.00	
[09/17 14:28:05 visual_prompt]: 	Test 100/235. loss: 1.696, 0.1957 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 14:28:25 visual_prompt]: 	Test 200/235. loss: 1.381, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 14:28:32 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1931, average loss: 1.4998
[09/17 14:28:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.61	top5: 99.91	
[09/17 14:28:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/17 14:28:42 visual_prompt]: Epoch 44 / 100: avg data time: 1.03e-01, avg batch time: 0.5068, average train loss: 1.3833
[09/17 14:28:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1436, average loss: 1.6155
[09/17 14:28:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.00	top5: 92.00	
[09/17 14:29:06 visual_prompt]: 	Test 100/235. loss: 1.853, 0.1985 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 14:29:25 visual_prompt]: 	Test 200/235. loss: 1.829, 0.2071 s / batch. (data: 2.03e-02)max mem: 17.22447 GB 
[09/17 14:29:33 visual_prompt]: Inference (test):avg data time: 8.13e-03, avg batch time: 0.1929, average loss: 1.7811
[09/17 14:29:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.85	top5: 90.28	
[09/17 14:29:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/17 14:29:42 visual_prompt]: Epoch 45 / 100: avg data time: 9.14e-02, avg batch time: 0.4985, average train loss: 1.5368
[09/17 14:29:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1434, average loss: 1.3190
[09/17 14:29:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 43.50	top5: 100.00	
[09/17 14:30:06 visual_prompt]: 	Test 100/235. loss: 1.653, 0.1836 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 14:30:26 visual_prompt]: 	Test 200/235. loss: 1.385, 0.1839 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 14:30:33 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1933, average loss: 1.4008
[09/17 14:30:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 41.34	top5: 99.87	
[09/17 14:30:34 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/17 14:30:42 visual_prompt]: Epoch 46 / 100: avg data time: 9.50e-02, avg batch time: 0.4989, average train loss: 1.4733
[09/17 14:30:46 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1433, average loss: 1.4019
[09/17 14:30:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 42.50	top5: 100.00	
[09/17 14:31:07 visual_prompt]: 	Test 100/235. loss: 1.485, 0.1836 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 14:31:26 visual_prompt]: 	Test 200/235. loss: 1.644, 0.1846 s / batch. (data: 1.18e-04)max mem: 17.22447 GB 
[09/17 14:31:34 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1927, average loss: 1.5893
[09/17 14:31:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.53	top5: 99.99	
[09/17 14:31:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/17 14:31:43 visual_prompt]: Epoch 47 / 100: avg data time: 9.23e-02, avg batch time: 0.4971, average train loss: 1.4067
[09/17 14:31:46 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1434, average loss: 1.6173
[09/17 14:31:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 46.00	top5: 98.00	
[09/17 14:32:07 visual_prompt]: 	Test 100/235. loss: 2.001, 0.1871 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 14:32:26 visual_prompt]: 	Test 200/235. loss: 1.882, 0.2020 s / batch. (data: 1.84e-02)max mem: 17.22447 GB 
[09/17 14:32:34 visual_prompt]: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1924, average loss: 1.7864
[09/17 14:32:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 38.63	top5: 96.39	
[09/17 14:32:34 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/17 14:32:43 visual_prompt]: Epoch 48 / 100: avg data time: 1.09e-01, avg batch time: 0.5125, average train loss: 1.5712
[09/17 14:32:46 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1433, average loss: 1.9820
[09/17 14:32:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.50	top5: 97.50	
[09/17 14:33:08 visual_prompt]: 	Test 100/235. loss: 2.265, 0.1967 s / batch. (data: 5.89e-05)max mem: 17.22447 GB 
[09/17 14:33:27 visual_prompt]: 	Test 200/235. loss: 2.198, 0.1942 s / batch. (data: 6.69e-03)max mem: 17.22447 GB 
[09/17 14:33:35 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1927, average loss: 2.2333
[09/17 14:33:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.30	top5: 95.07	
[09/17 14:33:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/17 14:33:44 visual_prompt]: Epoch 49 / 100: avg data time: 1.07e-01, avg batch time: 0.5095, average train loss: 1.1934
[09/17 14:33:47 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1431, average loss: 1.1002
[09/17 14:33:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 47.00	top5: 100.00	
[09/17 14:34:08 visual_prompt]: 	Test 100/235. loss: 1.144, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 14:34:28 visual_prompt]: 	Test 200/235. loss: 1.264, 0.2008 s / batch. (data: 1.56e-04)max mem: 17.22447 GB 
[09/17 14:34:35 visual_prompt]: Inference (test):avg data time: 7.30e-03, avg batch time: 0.1929, average loss: 1.2368
[09/17 14:34:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.35	top5: 99.95	
[09/17 14:34:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/17 14:34:44 visual_prompt]: Epoch 50 / 100: avg data time: 9.41e-02, avg batch time: 0.4972, average train loss: 1.4704
[09/17 14:34:47 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1433, average loss: 1.9627
[09/17 14:34:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 47.50	top5: 94.50	
[09/17 14:35:08 visual_prompt]: 	Test 100/235. loss: 2.384, 0.1841 s / batch. (data: 1.30e-04)max mem: 17.22447 GB 
[09/17 14:35:28 visual_prompt]: 	Test 200/235. loss: 2.188, 0.1842 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 14:35:36 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1936, average loss: 2.2660
[09/17 14:35:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.79	top5: 91.75	
[09/17 14:35:36 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/17 14:35:45 visual_prompt]: Epoch 51 / 100: avg data time: 9.99e-02, avg batch time: 0.5040, average train loss: 1.4531
[09/17 14:35:48 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1431, average loss: 1.2954
[09/17 14:35:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 48.00	top5: 100.00	
[09/17 14:36:09 visual_prompt]: 	Test 100/235. loss: 1.661, 0.1878 s / batch. (data: 1.32e-04)max mem: 17.22447 GB 
[09/17 14:36:29 visual_prompt]: 	Test 200/235. loss: 1.523, 0.1845 s / batch. (data: 1.44e-04)max mem: 17.22447 GB 
[09/17 14:36:36 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1938, average loss: 1.5355
[09/17 14:36:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.99	top5: 99.93	
[09/17 14:36:36 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/17 14:36:45 visual_prompt]: Epoch 52 / 100: avg data time: 9.72e-02, avg batch time: 0.5020, average train loss: 1.3459
[09/17 14:36:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 1.1564
[09/17 14:36:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 50.50	top5: 100.00	
[09/17 14:37:09 visual_prompt]: 	Test 100/235. loss: 1.505, 0.1838 s / batch. (data: 1.17e-04)max mem: 17.22447 GB 
[09/17 14:37:29 visual_prompt]: 	Test 200/235. loss: 1.331, 0.1998 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 14:37:37 visual_prompt]: Inference (test):avg data time: 6.27e-03, avg batch time: 0.1926, average loss: 1.3846
[09/17 14:37:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.72	top5: 99.95	
[09/17 14:37:37 visual_prompt]: Best epoch 52: best metric: 0.505
[09/17 14:37:37 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/17 14:37:46 visual_prompt]: Epoch 53 / 100: avg data time: 9.59e-02, avg batch time: 0.5011, average train loss: 1.3097
[09/17 14:37:49 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1472, average loss: 1.3349
[09/17 14:37:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 48.00	top5: 100.00	
[09/17 14:38:10 visual_prompt]: 	Test 100/235. loss: 1.780, 0.1849 s / batch. (data: 1.30e-04)max mem: 17.22447 GB 
[09/17 14:38:29 visual_prompt]: 	Test 200/235. loss: 1.696, 0.1965 s / batch. (data: 1.66e-04)max mem: 17.22447 GB 
[09/17 14:38:37 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1926, average loss: 1.5704
[09/17 14:38:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.15	top5: 99.76	
[09/17 14:38:37 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/17 14:38:46 visual_prompt]: Epoch 54 / 100: avg data time: 1.06e-01, avg batch time: 0.5104, average train loss: 1.4263
[09/17 14:38:49 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1432, average loss: 1.0727
[09/17 14:38:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 52.50	top5: 100.00	
[09/17 14:39:11 visual_prompt]: 	Test 100/235. loss: 1.502, 0.1842 s / batch. (data: 1.59e-04)max mem: 17.22447 GB 
[09/17 14:39:30 visual_prompt]: 	Test 200/235. loss: 1.233, 0.2003 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 14:39:38 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1935, average loss: 1.2646
[09/17 14:39:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.15	top5: 99.83	
[09/17 14:39:38 visual_prompt]: Best epoch 54: best metric: 0.525
[09/17 14:39:38 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/17 14:39:47 visual_prompt]: Epoch 55 / 100: avg data time: 1.00e-01, avg batch time: 0.5056, average train loss: 1.1787
[09/17 14:39:50 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1434, average loss: 1.1282
[09/17 14:39:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 49.00	top5: 100.00	
[09/17 14:40:11 visual_prompt]: 	Test 100/235. loss: 1.287, 0.1841 s / batch. (data: 1.16e-04)max mem: 17.22447 GB 
[09/17 14:40:30 visual_prompt]: 	Test 200/235. loss: 1.229, 0.1982 s / batch. (data: 1.43e-02)max mem: 17.22447 GB 
[09/17 14:40:38 visual_prompt]: Inference (test):avg data time: 6.08e-03, avg batch time: 0.1923, average loss: 1.2842
[09/17 14:40:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.87	top5: 99.75	
[09/17 14:40:38 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/17 14:40:47 visual_prompt]: Epoch 56 / 100: avg data time: 1.07e-01, avg batch time: 0.5107, average train loss: 1.3952
[09/17 14:40:50 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1433, average loss: 1.2501
[09/17 14:40:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 41.50	top5: 100.00	
[09/17 14:41:11 visual_prompt]: 	Test 100/235. loss: 1.477, 0.1936 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 14:41:31 visual_prompt]: 	Test 200/235. loss: 1.351, 0.2001 s / batch. (data: 1.67e-02)max mem: 17.22447 GB 
[09/17 14:41:39 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1937, average loss: 1.3977
[09/17 14:41:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.64	top5: 99.99	
[09/17 14:41:39 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/17 14:41:48 visual_prompt]: Epoch 57 / 100: avg data time: 1.06e-01, avg batch time: 0.5100, average train loss: 1.0312
[09/17 14:41:51 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1433, average loss: 0.9724
[09/17 14:41:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 54.00	top5: 100.00	
[09/17 14:42:12 visual_prompt]: 	Test 100/235. loss: 1.329, 0.1971 s / batch. (data: 1.37e-02)max mem: 17.22447 GB 
[09/17 14:42:32 visual_prompt]: 	Test 200/235. loss: 1.070, 0.2042 s / batch. (data: 1.77e-04)max mem: 17.22447 GB 
[09/17 14:42:39 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1937, average loss: 1.1278
[09/17 14:42:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 52.05	top5: 99.86	
[09/17 14:42:39 visual_prompt]: Best epoch 57: best metric: 0.540
[09/17 14:42:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/17 14:42:48 visual_prompt]: Epoch 58 / 100: avg data time: 9.73e-02, avg batch time: 0.5037, average train loss: 1.0654
[09/17 14:42:51 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1441, average loss: 1.4845
[09/17 14:42:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 41.50	top5: 100.00	
[09/17 14:43:12 visual_prompt]: 	Test 100/235. loss: 1.898, 0.1963 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 14:43:32 visual_prompt]: 	Test 200/235. loss: 1.598, 0.1838 s / batch. (data: 1.47e-04)max mem: 17.22447 GB 
[09/17 14:43:40 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1926, average loss: 1.7398
[09/17 14:43:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.65	top5: 99.61	
[09/17 14:43:40 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/17 14:43:49 visual_prompt]: Epoch 59 / 100: avg data time: 1.08e-01, avg batch time: 0.5110, average train loss: 1.0124
[09/17 14:43:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1433, average loss: 0.6526
[09/17 14:43:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 14:44:13 visual_prompt]: 	Test 100/235. loss: 0.943, 0.1959 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 14:44:32 visual_prompt]: 	Test 200/235. loss: 0.864, 0.1838 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 14:44:40 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1932, average loss: 0.8706
[09/17 14:44:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.79	top5: 99.97	
[09/17 14:44:40 visual_prompt]: Best epoch 59: best metric: 0.740
[09/17 14:44:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/17 14:44:49 visual_prompt]: Epoch 60 / 100: avg data time: 9.85e-02, avg batch time: 0.5041, average train loss: 1.5067
[09/17 14:44:53 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1434, average loss: 1.4635
[09/17 14:44:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 42.00	top5: 98.50	
[09/17 14:45:14 visual_prompt]: 	Test 100/235. loss: 1.607, 0.2066 s / batch. (data: 2.31e-02)max mem: 17.22447 GB 
[09/17 14:45:33 visual_prompt]: 	Test 200/235. loss: 1.713, 0.1842 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 14:45:41 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1935, average loss: 1.5437
[09/17 14:45:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 38.42	top5: 98.35	
[09/17 14:45:41 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/17 14:45:50 visual_prompt]: Epoch 61 / 100: avg data time: 9.32e-02, avg batch time: 0.4982, average train loss: 1.5384
[09/17 14:45:53 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1433, average loss: 1.2945
[09/17 14:45:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 42.00	top5: 100.00	
[09/17 14:46:14 visual_prompt]: 	Test 100/235. loss: 1.561, 0.2078 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 14:46:34 visual_prompt]: 	Test 200/235. loss: 1.431, 0.1995 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 14:46:42 visual_prompt]: Inference (test):avg data time: 9.89e-03, avg batch time: 0.1948, average loss: 1.4365
[09/17 14:46:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.85	top5: 99.03	
[09/17 14:46:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/17 14:46:51 visual_prompt]: Epoch 62 / 100: avg data time: 9.99e-02, avg batch time: 0.5030, average train loss: 1.1253
[09/17 14:46:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1434, average loss: 1.1406
[09/17 14:46:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 49.00	top5: 100.00	
[09/17 14:47:15 visual_prompt]: 	Test 100/235. loss: 1.419, 0.1944 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 14:47:34 visual_prompt]: 	Test 200/235. loss: 1.339, 0.1838 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 14:47:42 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1932, average loss: 1.3601
[09/17 14:47:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.45	top5: 99.50	
[09/17 14:47:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/17 14:47:51 visual_prompt]: Epoch 63 / 100: avg data time: 1.02e-01, avg batch time: 0.5052, average train loss: 1.7174
[09/17 14:47:54 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1432, average loss: 1.7804
[09/17 14:47:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.00	top5: 86.50	
[09/17 14:48:15 visual_prompt]: 	Test 100/235. loss: 1.972, 0.2109 s / batch. (data: 2.79e-02)max mem: 17.22447 GB 
[09/17 14:48:35 visual_prompt]: 	Test 200/235. loss: 1.851, 0.1843 s / batch. (data: 1.11e-04)max mem: 17.22447 GB 
[09/17 14:48:42 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1928, average loss: 1.8433
[09/17 14:48:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.03	top5: 87.27	
[09/17 14:48:42 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/17 14:48:52 visual_prompt]: Epoch 64 / 100: avg data time: 1.02e-01, avg batch time: 0.5071, average train loss: 1.8048
[09/17 14:48:54 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1432, average loss: 1.4813
[09/17 14:48:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.00	top5: 99.50	
[09/17 14:49:16 visual_prompt]: 	Test 100/235. loss: 1.585, 0.1986 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 14:49:35 visual_prompt]: 	Test 200/235. loss: 1.570, 0.1918 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 14:49:43 visual_prompt]: Inference (test):avg data time: 8.86e-03, avg batch time: 0.1941, average loss: 1.5379
[09/17 14:49:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.25	top5: 99.39	
[09/17 14:49:43 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/17 14:49:52 visual_prompt]: Epoch 65 / 100: avg data time: 9.45e-02, avg batch time: 0.5004, average train loss: 2.3705
[09/17 14:49:55 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1433, average loss: 1.7700
[09/17 14:49:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.50	top5: 88.00	
[09/17 14:50:16 visual_prompt]: 	Test 100/235. loss: 1.888, 0.1919 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 14:50:36 visual_prompt]: 	Test 200/235. loss: 1.915, 0.1840 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 14:50:43 visual_prompt]: Inference (test):avg data time: 6.87e-03, avg batch time: 0.1926, average loss: 1.8363
[09/17 14:50:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 25.93	top5: 82.58	
[09/17 14:50:44 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/17 14:50:52 visual_prompt]: Epoch 66 / 100: avg data time: 9.40e-02, avg batch time: 0.4990, average train loss: 1.9969
[09/17 14:50:56 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1432, average loss: 1.5565
[09/17 14:50:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.50	top5: 94.00	
[09/17 14:51:17 visual_prompt]: 	Test 100/235. loss: 1.719, 0.1954 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 14:51:36 visual_prompt]: 	Test 200/235. loss: 1.601, 0.1838 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 14:51:44 visual_prompt]: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1925, average loss: 1.6022
[09/17 14:51:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.27	top5: 92.21	
[09/17 14:51:44 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/17 14:51:53 visual_prompt]: Epoch 67 / 100: avg data time: 9.25e-02, avg batch time: 0.4963, average train loss: 1.7588
[09/17 14:51:56 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1434, average loss: 1.6094
[09/17 14:51:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.00	top5: 95.50	
[09/17 14:52:17 visual_prompt]: 	Test 100/235. loss: 1.715, 0.1957 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 14:52:36 visual_prompt]: 	Test 200/235. loss: 1.598, 0.1850 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 14:52:44 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1935, average loss: 1.6200
[09/17 14:52:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.10	top5: 95.60	
[09/17 14:52:44 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/17 14:52:53 visual_prompt]: Epoch 68 / 100: avg data time: 9.23e-02, avg batch time: 0.4982, average train loss: 1.6789
[09/17 14:52:56 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1434, average loss: 1.4824
[09/17 14:52:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 99.00	
[09/17 14:53:17 visual_prompt]: 	Test 100/235. loss: 1.665, 0.1844 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 14:53:36 visual_prompt]: 	Test 200/235. loss: 1.536, 0.2038 s / batch. (data: 2.04e-02)max mem: 17.22447 GB 
[09/17 14:53:44 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1935, average loss: 1.5457
[09/17 14:53:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.59	top5: 97.56	
[09/17 14:53:44 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/17 14:53:53 visual_prompt]: Epoch 69 / 100: avg data time: 9.62e-02, avg batch time: 0.5007, average train loss: 1.5167
[09/17 14:53:56 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1433, average loss: 1.5836
[09/17 14:53:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.00	top5: 99.00	
[09/17 14:54:18 visual_prompt]: 	Test 100/235. loss: 1.664, 0.1841 s / batch. (data: 1.42e-04)max mem: 17.22447 GB 
[09/17 14:54:37 visual_prompt]: 	Test 200/235. loss: 1.675, 0.2075 s / batch. (data: 2.43e-02)max mem: 17.22447 GB 
[09/17 14:54:45 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1935, average loss: 1.6143
[09/17 14:54:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.76	top5: 98.32	
[09/17 14:54:45 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/17 14:54:54 visual_prompt]: Epoch 70 / 100: avg data time: 9.19e-02, avg batch time: 0.4956, average train loss: 1.4042
[09/17 14:54:57 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1434, average loss: 1.5438
[09/17 14:54:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 97.00	
[09/17 14:55:18 visual_prompt]: 	Test 100/235. loss: 1.813, 0.1984 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 14:55:38 visual_prompt]: 	Test 200/235. loss: 1.674, 0.1995 s / batch. (data: 1.48e-02)max mem: 17.22447 GB 
[09/17 14:55:45 visual_prompt]: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1943, average loss: 1.6509
[09/17 14:55:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.79	top5: 95.27	
[09/17 14:55:45 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/17 14:55:54 visual_prompt]: Epoch 71 / 100: avg data time: 9.23e-02, avg batch time: 0.4957, average train loss: 1.2566
[09/17 14:55:58 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1431, average loss: 1.1308
[09/17 14:55:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 45.00	top5: 100.00	
[09/17 14:56:19 visual_prompt]: 	Test 100/235. loss: 1.352, 0.1884 s / batch. (data: 4.98e-03)max mem: 17.22447 GB 
[09/17 14:56:38 visual_prompt]: 	Test 200/235. loss: 1.318, 0.1847 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 14:56:46 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1934, average loss: 1.2268
[09/17 14:56:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.75	top5: 99.76	
[09/17 14:56:46 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/17 14:56:55 visual_prompt]: Epoch 72 / 100: avg data time: 9.30e-02, avg batch time: 0.4983, average train loss: 1.2248
[09/17 14:56:58 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 1.0863
[09/17 14:56:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 49.50	top5: 100.00	
[09/17 14:57:19 visual_prompt]: 	Test 100/235. loss: 1.406, 0.1986 s / batch. (data: 1.43e-02)max mem: 17.22447 GB 
[09/17 14:57:39 visual_prompt]: 	Test 200/235. loss: 1.195, 0.2223 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 14:57:47 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1930, average loss: 1.2063
[09/17 14:57:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.31	top5: 99.71	
[09/17 14:57:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/17 14:57:56 visual_prompt]: Epoch 73 / 100: avg data time: 9.73e-02, avg batch time: 0.5029, average train loss: 1.0650
[09/17 14:57:59 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1434, average loss: 1.0132
[09/17 14:57:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 56.00	top5: 100.00	
[09/17 14:58:20 visual_prompt]: 	Test 100/235. loss: 1.306, 0.1962 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 14:58:39 visual_prompt]: 	Test 200/235. loss: 1.234, 0.1841 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 14:58:47 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1932, average loss: 1.1365
[09/17 14:58:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.57	top5: 99.91	
[09/17 14:58:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/17 14:58:56 visual_prompt]: Epoch 74 / 100: avg data time: 9.89e-02, avg batch time: 0.5041, average train loss: 1.0017
[09/17 14:58:59 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1432, average loss: 0.9999
[09/17 14:58:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 58.50	top5: 100.00	
[09/17 14:59:20 visual_prompt]: 	Test 100/235. loss: 1.329, 0.2001 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 14:59:40 visual_prompt]: 	Test 200/235. loss: 1.215, 0.1861 s / batch. (data: 1.35e-04)max mem: 17.22447 GB 
[09/17 14:59:48 visual_prompt]: Inference (test):avg data time: 7.09e-03, avg batch time: 0.1926, average loss: 1.1200
[09/17 14:59:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 51.52	top5: 99.97	
[09/17 14:59:48 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/17 14:59:57 visual_prompt]: Epoch 75 / 100: avg data time: 9.96e-02, avg batch time: 0.5040, average train loss: 0.9597
[09/17 15:00:00 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1434, average loss: 1.1825
[09/17 15:00:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 43.50	top5: 100.00	
[09/17 15:00:21 visual_prompt]: 	Test 100/235. loss: 1.536, 0.1839 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 15:00:40 visual_prompt]: 	Test 200/235. loss: 1.504, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 15:00:48 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1933, average loss: 1.3354
[09/17 15:00:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.60	top5: 99.75	
[09/17 15:00:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/17 15:00:58 visual_prompt]: Epoch 76 / 100: avg data time: 1.06e-01, avg batch time: 0.5113, average train loss: 1.0476
[09/17 15:01:01 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1434, average loss: 0.9234
[09/17 15:01:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 55.00	top5: 100.00	
[09/17 15:01:22 visual_prompt]: 	Test 100/235. loss: 1.199, 0.1840 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 15:01:41 visual_prompt]: 	Test 200/235. loss: 1.089, 0.1875 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 15:01:49 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1932, average loss: 1.0927
[09/17 15:01:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 50.18	top5: 99.88	
[09/17 15:01:49 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/17 15:01:58 visual_prompt]: Epoch 77 / 100: avg data time: 1.05e-01, avg batch time: 0.5092, average train loss: 0.8766
[09/17 15:02:01 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1434, average loss: 0.7671
[09/17 15:02:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 66.50	top5: 100.00	
[09/17 15:02:22 visual_prompt]: 	Test 100/235. loss: 1.192, 0.1988 s / batch. (data: 1.55e-02)max mem: 17.22447 GB 
[09/17 15:02:42 visual_prompt]: 	Test 200/235. loss: 0.989, 0.2230 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 15:02:50 visual_prompt]: Inference (test):avg data time: 6.99e-03, avg batch time: 0.1931, average loss: 0.9502
[09/17 15:02:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.82	top5: 99.97	
[09/17 15:02:50 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/17 15:02:59 visual_prompt]: Epoch 78 / 100: avg data time: 9.96e-02, avg batch time: 0.5019, average train loss: 0.8001
[09/17 15:03:02 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1456, average loss: 0.7211
[09/17 15:03:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 66.00	top5: 100.00	
[09/17 15:03:23 visual_prompt]: 	Test 100/235. loss: 1.243, 0.1841 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 15:03:42 visual_prompt]: 	Test 200/235. loss: 0.972, 0.1969 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 15:03:50 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1937, average loss: 0.9758
[09/17 15:03:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.49	top5: 99.91	
[09/17 15:03:50 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/17 15:03:59 visual_prompt]: Epoch 79 / 100: avg data time: 1.04e-01, avg batch time: 0.5081, average train loss: 0.8981
[09/17 15:04:02 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1432, average loss: 0.7764
[09/17 15:04:02 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 65.50	top5: 100.00	
[09/17 15:04:24 visual_prompt]: 	Test 100/235. loss: 1.314, 0.1999 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 15:04:43 visual_prompt]: 	Test 200/235. loss: 1.037, 0.2075 s / batch. (data: 2.45e-02)max mem: 17.22447 GB 
[09/17 15:04:51 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1927, average loss: 1.0957
[09/17 15:04:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 51.95	top5: 99.94	
[09/17 15:04:51 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/17 15:05:00 visual_prompt]: Epoch 80 / 100: avg data time: 1.00e-01, avg batch time: 0.5032, average train loss: 0.7361
[09/17 15:05:03 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1430, average loss: 0.8045
[09/17 15:05:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 60.50	top5: 100.00	
[09/17 15:05:24 visual_prompt]: 	Test 100/235. loss: 1.366, 0.2080 s / batch. (data: 2.48e-02)max mem: 17.22447 GB 
[09/17 15:05:43 visual_prompt]: 	Test 200/235. loss: 1.200, 0.2078 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 15:05:51 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1930, average loss: 1.0744
[09/17 15:05:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 54.51	top5: 99.97	
[09/17 15:05:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/17 15:06:00 visual_prompt]: Epoch 81 / 100: avg data time: 9.32e-02, avg batch time: 0.4990, average train loss: 0.6672
[09/17 15:06:03 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1446, average loss: 0.5635
[09/17 15:06:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 15:06:25 visual_prompt]: 	Test 100/235. loss: 1.213, 0.2080 s / batch. (data: 2.46e-02)max mem: 17.22447 GB 
[09/17 15:06:44 visual_prompt]: 	Test 200/235. loss: 0.847, 0.1840 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 15:06:52 visual_prompt]: Inference (test):avg data time: 8.80e-03, avg batch time: 0.1942, average loss: 0.9296
[09/17 15:06:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.97	top5: 99.97	
[09/17 15:06:52 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/17 15:07:01 visual_prompt]: Epoch 82 / 100: avg data time: 1.02e-01, avg batch time: 0.5066, average train loss: 0.6837
[09/17 15:07:04 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1447, average loss: 0.5860
[09/17 15:07:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 75.50	top5: 100.00	
[09/17 15:07:25 visual_prompt]: 	Test 100/235. loss: 1.214, 0.1844 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 15:07:44 visual_prompt]: 	Test 200/235. loss: 0.891, 0.1846 s / batch. (data: 1.17e-04)max mem: 17.22447 GB 
[09/17 15:07:52 visual_prompt]: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1926, average loss: 0.9334
[09/17 15:07:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 60.90	top5: 99.99	
[09/17 15:07:52 visual_prompt]: Best epoch 82: best metric: 0.755
[09/17 15:07:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/17 15:08:01 visual_prompt]: Epoch 83 / 100: avg data time: 1.08e-01, avg batch time: 0.5111, average train loss: 0.6989
[09/17 15:08:04 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 0.5515
[09/17 15:08:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 76.50	top5: 100.00	
[09/17 15:08:25 visual_prompt]: 	Test 100/235. loss: 1.310, 0.1989 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 15:08:45 visual_prompt]: 	Test 200/235. loss: 0.960, 0.1962 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 15:08:53 visual_prompt]: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1931, average loss: 1.0427
[09/17 15:08:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 57.15	top5: 99.96	
[09/17 15:08:53 visual_prompt]: Best epoch 83: best metric: 0.765
[09/17 15:08:53 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/17 15:09:02 visual_prompt]: Epoch 84 / 100: avg data time: 1.01e-01, avg batch time: 0.5059, average train loss: 0.7606
[09/17 15:09:05 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1431, average loss: 0.6771
[09/17 15:09:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 68.50	top5: 100.00	
[09/17 15:09:26 visual_prompt]: 	Test 100/235. loss: 1.379, 0.1843 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 15:09:45 visual_prompt]: 	Test 200/235. loss: 1.096, 0.1850 s / batch. (data: 3.91e-05)max mem: 17.22447 GB 
[09/17 15:09:53 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1937, average loss: 1.0563
[09/17 15:09:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 56.98	top5: 99.99	
[09/17 15:09:53 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/17 15:10:03 visual_prompt]: Epoch 85 / 100: avg data time: 1.13e-01, avg batch time: 0.5149, average train loss: 0.6134
[09/17 15:10:06 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1433, average loss: 0.4398
[09/17 15:10:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 83.00	top5: 100.00	
[09/17 15:10:27 visual_prompt]: 	Test 100/235. loss: 1.160, 0.1841 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 15:10:46 visual_prompt]: 	Test 200/235. loss: 0.901, 0.1842 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 15:10:54 visual_prompt]: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1921, average loss: 0.8804
[09/17 15:10:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 61.92	top5: 99.99	
[09/17 15:10:54 visual_prompt]: Best epoch 85: best metric: 0.830
[09/17 15:10:54 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 15:11:03 visual_prompt]: Epoch 86 / 100: avg data time: 1.09e-01, avg batch time: 0.5131, average train loss: 0.5659
[09/17 15:11:06 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1443, average loss: 0.5634
[09/17 15:11:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 15:11:27 visual_prompt]: 	Test 100/235. loss: 1.392, 0.1954 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 15:11:46 visual_prompt]: 	Test 200/235. loss: 1.082, 0.1991 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 15:11:54 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1933, average loss: 1.0161
[09/17 15:11:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.59	top5: 99.99	
[09/17 15:11:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 15:12:03 visual_prompt]: Epoch 87 / 100: avg data time: 1.04e-01, avg batch time: 0.5054, average train loss: 0.4430
[09/17 15:12:06 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1432, average loss: 0.3168
[09/17 15:12:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 89.00	top5: 100.00	
[09/17 15:12:27 visual_prompt]: 	Test 100/235. loss: 1.209, 0.2204 s / batch. (data: 3.72e-02)max mem: 17.22447 GB 
[09/17 15:12:47 visual_prompt]: 	Test 200/235. loss: 0.866, 0.2011 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 15:12:55 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1935, average loss: 0.8894
[09/17 15:12:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 65.11	top5: 99.98	
[09/17 15:12:55 visual_prompt]: Best epoch 87: best metric: 0.890
[09/17 15:12:55 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 15:13:04 visual_prompt]: Epoch 88 / 100: avg data time: 1.07e-01, avg batch time: 0.5097, average train loss: 0.4366
[09/17 15:13:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1433, average loss: 0.2876
[09/17 15:13:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 88.50	top5: 100.00	
[09/17 15:13:28 visual_prompt]: 	Test 100/235. loss: 1.263, 0.2302 s / batch. (data: 4.70e-02)max mem: 17.22447 GB 
[09/17 15:13:47 visual_prompt]: 	Test 200/235. loss: 0.903, 0.1845 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 15:13:55 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1934, average loss: 0.9491
[09/17 15:13:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.31	top5: 99.98	
[09/17 15:13:55 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 15:14:04 visual_prompt]: Epoch 89 / 100: avg data time: 9.66e-02, avg batch time: 0.5024, average train loss: 0.3638
[09/17 15:14:07 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1436, average loss: 0.2977
[09/17 15:14:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 87.00	top5: 100.00	
[09/17 15:14:28 visual_prompt]: 	Test 100/235. loss: 1.434, 0.1955 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 15:14:48 visual_prompt]: 	Test 200/235. loss: 1.022, 0.2212 s / batch. (data: 3.77e-02)max mem: 17.22447 GB 
[09/17 15:14:55 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1930, average loss: 1.0338
[09/17 15:14:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 63.63	top5: 99.99	
[09/17 15:14:55 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 15:15:04 visual_prompt]: Epoch 90 / 100: avg data time: 9.94e-02, avg batch time: 0.5014, average train loss: 0.3379
[09/17 15:15:07 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1432, average loss: 0.6053
[09/17 15:15:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 69.50	top5: 100.00	
[09/17 15:15:29 visual_prompt]: 	Test 100/235. loss: 1.742, 0.1845 s / batch. (data: 1.37e-04)max mem: 17.22447 GB 
[09/17 15:15:48 visual_prompt]: 	Test 200/235. loss: 1.285, 0.1994 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 15:15:56 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1936, average loss: 1.3131
[09/17 15:15:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 58.55	top5: 99.99	
[09/17 15:15:56 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 15:16:05 visual_prompt]: Epoch 91 / 100: avg data time: 1.12e-01, avg batch time: 0.5151, average train loss: 0.3613
[09/17 15:16:08 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1434, average loss: 0.3887
[09/17 15:16:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 83.50	top5: 100.00	
[09/17 15:16:29 visual_prompt]: 	Test 100/235. loss: 1.585, 0.1841 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 15:16:49 visual_prompt]: 	Test 200/235. loss: 1.016, 0.1983 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 15:16:56 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1929, average loss: 1.1648
[09/17 15:16:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 62.45	top5: 99.99	
[09/17 15:16:56 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 15:17:06 visual_prompt]: Epoch 92 / 100: avg data time: 1.03e-01, avg batch time: 0.5048, average train loss: 0.4087
[09/17 15:17:09 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1431, average loss: 0.2582
[09/17 15:17:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.00	top5: 100.00	
[09/17 15:17:30 visual_prompt]: 	Test 100/235. loss: 1.252, 0.1838 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 15:17:49 visual_prompt]: 	Test 200/235. loss: 0.860, 0.1847 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 15:17:57 visual_prompt]: Inference (test):avg data time: 7.15e-03, avg batch time: 0.1931, average loss: 0.9271
[09/17 15:17:57 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.48	top5: 99.97	
[09/17 15:17:57 visual_prompt]: Best epoch 92: best metric: 0.920
[09/17 15:17:57 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 15:18:06 visual_prompt]: Epoch 93 / 100: avg data time: 1.11e-01, avg batch time: 0.5140, average train loss: 0.3794
[09/17 15:18:09 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1434, average loss: 0.2851
[09/17 15:18:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 88.00	top5: 100.00	
[09/17 15:18:30 visual_prompt]: 	Test 100/235. loss: 1.369, 0.1836 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 15:18:50 visual_prompt]: 	Test 200/235. loss: 1.000, 0.2036 s / batch. (data: 2.78e-04)max mem: 17.22447 GB 
[09/17 15:18:58 visual_prompt]: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1936, average loss: 1.0176
[09/17 15:18:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 63.59	top5: 99.98	
[09/17 15:18:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 15:19:07 visual_prompt]: Epoch 94 / 100: avg data time: 1.04e-01, avg batch time: 0.5061, average train loss: 0.3033
[09/17 15:19:10 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1434, average loss: 0.5261
[09/17 15:19:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 78.50	top5: 100.00	
[09/17 15:19:31 visual_prompt]: 	Test 100/235. loss: 2.004, 0.1981 s / batch. (data: 1.51e-04)max mem: 17.22447 GB 
[09/17 15:19:50 visual_prompt]: 	Test 200/235. loss: 1.327, 0.1953 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 15:19:58 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1929, average loss: 1.4627
[09/17 15:19:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 59.83	top5: 99.99	
[09/17 15:19:58 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 15:20:07 visual_prompt]: Epoch 95 / 100: avg data time: 1.06e-01, avg batch time: 0.5082, average train loss: 0.3018
[09/17 15:20:10 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1454, average loss: 0.3042
[09/17 15:20:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 88.00	top5: 100.00	
[09/17 15:20:31 visual_prompt]: 	Test 100/235. loss: 1.738, 0.1998 s / batch. (data: 1.68e-02)max mem: 17.22447 GB 
[09/17 15:20:51 visual_prompt]: 	Test 200/235. loss: 1.114, 0.1997 s / batch. (data: 1.62e-02)max mem: 17.22447 GB 
[09/17 15:20:58 visual_prompt]: Inference (test):avg data time: 8.65e-03, avg batch time: 0.1936, average loss: 1.2466
[09/17 15:20:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 63.15	top5: 99.99	
[09/17 15:20:59 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 15:21:08 visual_prompt]: Epoch 96 / 100: avg data time: 1.09e-01, avg batch time: 0.5118, average train loss: 0.2568
[09/17 15:21:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1434, average loss: 0.1538
[09/17 15:21:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 94.00	top5: 100.00	
[09/17 15:21:32 visual_prompt]: 	Test 100/235. loss: 1.682, 0.1846 s / batch. (data: 1.34e-04)max mem: 17.22447 GB 
[09/17 15:21:51 visual_prompt]: 	Test 200/235. loss: 1.121, 0.1877 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 15:21:59 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1929, average loss: 1.2070
[09/17 15:21:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.72	top5: 99.98	
[09/17 15:21:59 visual_prompt]: Best epoch 96: best metric: 0.940
[09/17 15:21:59 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 15:22:08 visual_prompt]: Epoch 97 / 100: avg data time: 9.33e-02, avg batch time: 0.4987, average train loss: 0.2208
[09/17 15:22:11 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1433, average loss: 0.1642
[09/17 15:22:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 94.50	top5: 100.00	
[09/17 15:22:32 visual_prompt]: 	Test 100/235. loss: 1.749, 0.1901 s / batch. (data: 1.00e-04)max mem: 17.22447 GB 
[09/17 15:22:52 visual_prompt]: 	Test 200/235. loss: 1.162, 0.1992 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 15:22:59 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1934, average loss: 1.2600
[09/17 15:22:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.29	top5: 99.97	
[09/17 15:22:59 visual_prompt]: Best epoch 97: best metric: 0.945
[09/17 15:22:59 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 15:23:08 visual_prompt]: Epoch 98 / 100: avg data time: 9.74e-02, avg batch time: 0.5023, average train loss: 0.2114
[09/17 15:23:12 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1431, average loss: 0.1998
[09/17 15:23:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.50	top5: 100.00	
[09/17 15:23:33 visual_prompt]: 	Test 100/235. loss: 1.804, 0.1959 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 15:23:52 visual_prompt]: 	Test 200/235. loss: 1.176, 0.1840 s / batch. (data: 1.05e-04)max mem: 17.22447 GB 
[09/17 15:24:00 visual_prompt]: Inference (test):avg data time: 6.98e-03, avg batch time: 0.1927, average loss: 1.2766
[09/17 15:24:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.27	top5: 99.99	
[09/17 15:24:00 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 15:24:09 visual_prompt]: Epoch 99 / 100: avg data time: 1.04e-01, avg batch time: 0.5069, average train loss: 0.1925
[09/17 15:24:12 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1432, average loss: 0.2067
[09/17 15:24:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.00	top5: 100.00	
[09/17 15:24:33 visual_prompt]: 	Test 100/235. loss: 1.812, 0.1837 s / batch. (data: 1.41e-04)max mem: 17.22447 GB 
[09/17 15:24:53 visual_prompt]: 	Test 200/235. loss: 1.167, 0.1844 s / batch. (data: 1.55e-04)max mem: 17.22447 GB 
[09/17 15:25:00 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1928, average loss: 1.2837
[09/17 15:25:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.19	top5: 99.99	
[09/17 15:25:00 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 15:25:09 visual_prompt]: Epoch 100 / 100: avg data time: 8.90e-02, avg batch time: 0.4932, average train loss: 0.1897
[09/17 15:25:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1432, average loss: 0.2004
[09/17 15:25:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 92.00	top5: 100.00	
[09/17 15:25:33 visual_prompt]: 	Test 100/235. loss: 1.809, 0.2009 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 15:25:53 visual_prompt]: 	Test 200/235. loss: 1.166, 0.1841 s / batch. (data: 1.07e-04)max mem: 17.22447 GB 
[09/17 15:26:01 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1937, average loss: 1.2827
[09/17 15:26:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 64.23	top5: 99.99	
[09/17 15:26:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/17 15:26:14 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 15:26:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-clevr(task="count_all")', 'DATA.NUMBER_CLASSES', '8', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/17 15:26:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 15:26:14 visual_prompt]: Training with config:
[09/17 15:26:14 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-clevr(task="count_all")',
          'NO_TEST': False,
          'NUMBER_CLASSES': 8,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-clevr(task="count_all")/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 15:26:14 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-17 15:26:14.118194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-17 15:26:14.291560: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-17 15:26:15.203900: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 15:26:15.203983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 15:26:15.203992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-17 15:26:17.238368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 15:26:17.238482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-17 15:26:17.238497: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/17 15:26:17 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: dtype_utils.py:   50]: You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
2023-09-17 15:26:17.261484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[:800]+train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 15:26:22 visual_prompt]: Number of images: 1000
[09/17 15:26:22 visual_prompt]: Number of classes: 8 / 8
[09/17 15:26:22 visual_prompt]: Loading validation data...
[09/17 15:26:22 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[WARNING: feature.py:   71]: `TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split train[63000:63200], from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 15:26:23 visual_prompt]: Number of images: 200
[09/17 15:26:23 visual_prompt]: Number of classes: 8 / 8
[09/17 15:26:23 visual_prompt]: Loading test data...
[09/17 15:26:23 visual_prompt]: Constructing vtab-clevr(task="count_all") dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/clevr/3.1.0
[INFO: dataset_builder.py:  510]: Reusing dataset clevr (visual_prompt_tuning/data_path/clevr/3.1.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset clevr for split validation, from visual_prompt_tuning/data_path/clevr/3.1.0
[09/17 15:27:40 visual_prompt]: Number of images: 15000
[09/17 15:27:40 visual_prompt]: Number of classes: 8 / 8
[09/17 15:27:40 visual_prompt]: Constructing models...
[09/17 15:27:42 visual_prompt]: Total Parameters: 86726408	 Gradient Parameters: 927752
[09/17 15:27:42 visual_prompt]: tuned percent:1.070
[09/17 15:27:45 visual_prompt]: Device used for model: 0
[09/17 15:27:45 visual_prompt]: Setting up Evalutator...
[09/17 15:27:45 visual_prompt]: Setting up Trainer...
[09/17 15:27:45 visual_prompt]: 	Setting up the optimizer...
[09/17 15:27:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/17 15:27:55 visual_prompt]: Epoch 1 / 100: avg data time: 1.02e-01, avg batch time: 0.5935, average train loss: 2.3617
[09/17 15:27:59 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1422, average loss: 2.3812
[09/17 15:27:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 62.00	
[09/17 15:28:20 visual_prompt]: 	Test 100/235. loss: 2.464, 0.1967 s / batch. (data: 1.50e-02)max mem: 17.22447 GB 
[09/17 15:28:39 visual_prompt]: 	Test 200/235. loss: 2.500, 0.1826 s / batch. (data: 1.76e-04)max mem: 17.22447 GB 
[09/17 15:28:47 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1915, average loss: 2.4145
[09/17 15:28:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.03	top5: 59.55	
[09/17 15:28:47 visual_prompt]: Best epoch 1: best metric: 0.105
[09/17 15:28:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/17 15:28:56 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e-01, avg batch time: 0.5077, average train loss: 3.7444
[09/17 15:28:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1431, average loss: 2.5899
[09/17 15:28:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 65.00	
[09/17 15:29:20 visual_prompt]: 	Test 100/235. loss: 2.551, 0.1961 s / batch. (data: 1.12e-02)max mem: 17.22447 GB 
[09/17 15:29:39 visual_prompt]: 	Test 200/235. loss: 2.606, 0.2081 s / batch. (data: 2.49e-02)max mem: 17.22447 GB 
[09/17 15:29:47 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1924, average loss: 2.5669
[09/17 15:29:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 64.30	
[09/17 15:29:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/17 15:29:57 visual_prompt]: Epoch 3 / 100: avg data time: 1.17e-01, avg batch time: 0.5189, average train loss: 2.2623
[09/17 15:30:00 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1430, average loss: 2.2582
[09/17 15:30:00 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 64.00	
[09/17 15:30:21 visual_prompt]: 	Test 100/235. loss: 2.375, 0.1839 s / batch. (data: 1.55e-04)max mem: 17.22447 GB 
[09/17 15:30:40 visual_prompt]: 	Test 200/235. loss: 2.317, 0.1971 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 15:30:48 visual_prompt]: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1934, average loss: 2.2653
[09/17 15:30:48 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 64.09	
[09/17 15:30:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/17 15:30:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e-01, avg batch time: 0.5122, average train loss: 2.4044
[09/17 15:31:01 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1433, average loss: 2.2833
[09/17 15:31:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 22.50	top5: 66.50	
[09/17 15:31:22 visual_prompt]: 	Test 100/235. loss: 2.509, 0.1845 s / batch. (data: 1.55e-04)max mem: 17.22447 GB 
[09/17 15:31:41 visual_prompt]: 	Test 200/235. loss: 2.427, 0.1856 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 15:31:49 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1934, average loss: 2.3423
[09/17 15:31:49 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 20.31	top5: 64.55	
[09/17 15:31:49 visual_prompt]: Best epoch 4: best metric: 0.225
[09/17 15:31:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/17 15:31:58 visual_prompt]: Epoch 5 / 100: avg data time: 1.13e-01, avg batch time: 0.5158, average train loss: 2.2489
[09/17 15:32:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1431, average loss: 2.0843
[09/17 15:32:01 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.50	top5: 89.00	
[09/17 15:32:23 visual_prompt]: 	Test 100/235. loss: 2.076, 0.1954 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 15:32:42 visual_prompt]: 	Test 200/235. loss: 2.159, 0.1964 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 15:32:50 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1941, average loss: 2.1618
[09/17 15:32:50 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.43	top5: 86.78	
[09/17 15:32:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/17 15:32:59 visual_prompt]: Epoch 6 / 100: avg data time: 9.86e-02, avg batch time: 0.5023, average train loss: 2.6582
[09/17 15:33:03 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1432, average loss: 3.2508
[09/17 15:33:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 62.50	
[09/17 15:33:23 visual_prompt]: 	Test 100/235. loss: 3.355, 0.1864 s / batch. (data: 1.19e-04)max mem: 17.22447 GB 
[09/17 15:33:43 visual_prompt]: 	Test 200/235. loss: 3.463, 0.1919 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 15:33:51 visual_prompt]: Inference (test):avg data time: 6.63e-03, avg batch time: 0.1922, average loss: 3.3670
[09/17 15:33:51 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.69	
[09/17 15:33:51 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/17 15:34:00 visual_prompt]: Epoch 7 / 100: avg data time: 1.16e-01, avg batch time: 0.5195, average train loss: 4.4630
[09/17 15:34:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1431, average loss: 4.8107
[09/17 15:34:03 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 65.50	
[09/17 15:34:24 visual_prompt]: 	Test 100/235. loss: 4.756, 0.2111 s / batch. (data: 1.36e-02)max mem: 17.22447 GB 
[09/17 15:34:44 visual_prompt]: 	Test 200/235. loss: 5.180, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 15:34:52 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1932, average loss: 4.9044
[09/17 15:34:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.74	
[09/17 15:34:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/17 15:35:01 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e-01, avg batch time: 0.5053, average train loss: 5.1518
[09/17 15:35:04 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1432, average loss: 18.5447
[09/17 15:35:04 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.50	top5: 62.50	
[09/17 15:35:25 visual_prompt]: 	Test 100/235. loss: 17.052, 0.1850 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 15:35:44 visual_prompt]: 	Test 200/235. loss: 17.013, 0.1999 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 15:35:52 visual_prompt]: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1929, average loss: 18.5147
[09/17 15:35:52 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.35	top5: 63.01	
[09/17 15:35:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/17 15:36:01 visual_prompt]: Epoch 9 / 100: avg data time: 1.14e-01, avg batch time: 0.5185, average train loss: 14.9483
[09/17 15:36:05 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1432, average loss: 20.0198
[09/17 15:36:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 10.50	top5: 65.50	
[09/17 15:36:26 visual_prompt]: 	Test 100/235. loss: 20.894, 0.1885 s / batch. (data: 5.23e-03)max mem: 17.22447 GB 
[09/17 15:36:45 visual_prompt]: 	Test 200/235. loss: 20.347, 0.1839 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 15:36:53 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1929, average loss: 20.4807
[09/17 15:36:53 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.05	top5: 62.40	
[09/17 15:36:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/17 15:37:02 visual_prompt]: Epoch 10 / 100: avg data time: 1.12e-01, avg batch time: 0.5147, average train loss: 16.4897
[09/17 15:37:05 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1430, average loss: 10.6982
[09/17 15:37:05 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.50	top5: 61.50	
[09/17 15:37:27 visual_prompt]: 	Test 100/235. loss: 11.158, 0.2053 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 15:37:46 visual_prompt]: 	Test 200/235. loss: 10.203, 0.2088 s / batch. (data: 4.03e-05)max mem: 17.22447 GB 
[09/17 15:37:54 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1937, average loss: 10.6644
[09/17 15:37:54 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.83	top5: 62.43	
[09/17 15:37:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/17 15:38:03 visual_prompt]: Epoch 11 / 100: avg data time: 1.12e-01, avg batch time: 0.5181, average train loss: 12.4661
[09/17 15:38:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1451, average loss: 8.6519
[09/17 15:38:06 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 65.00	
[09/17 15:38:27 visual_prompt]: 	Test 100/235. loss: 9.104, 0.1835 s / batch. (data: 1.09e-04)max mem: 17.22447 GB 
[09/17 15:38:47 visual_prompt]: 	Test 200/235. loss: 9.689, 0.1841 s / batch. (data: 1.07e-04)max mem: 17.22447 GB 
[09/17 15:38:55 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1933, average loss: 9.1624
[09/17 15:38:55 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.28	
[09/17 15:38:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/17 15:39:04 visual_prompt]: Epoch 12 / 100: avg data time: 9.51e-02, avg batch time: 0.4994, average train loss: 7.7494
[09/17 15:39:07 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1432, average loss: 9.2610
[09/17 15:39:07 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 61.50	
[09/17 15:39:28 visual_prompt]: 	Test 100/235. loss: 9.048, 0.1840 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 15:39:48 visual_prompt]: 	Test 200/235. loss: 9.642, 0.1838 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 15:39:56 visual_prompt]: Inference (test):avg data time: 8.61e-03, avg batch time: 0.1941, average loss: 9.2047
[09/17 15:39:56 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.20	
[09/17 15:39:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/17 15:40:05 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e-01, avg batch time: 0.5119, average train loss: 9.7276
[09/17 15:40:08 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1430, average loss: 4.5914
[09/17 15:40:08 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 59.50	
[09/17 15:40:29 visual_prompt]: 	Test 100/235. loss: 4.291, 0.1960 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 15:40:49 visual_prompt]: 	Test 200/235. loss: 4.459, 0.1900 s / batch. (data: 6.64e-03)max mem: 17.22447 GB 
[09/17 15:40:57 visual_prompt]: Inference (test):avg data time: 9.21e-03, avg batch time: 0.1941, average loss: 4.3723
[09/17 15:40:57 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.49	
[09/17 15:40:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/17 15:41:06 visual_prompt]: Epoch 14 / 100: avg data time: 1.13e-01, avg batch time: 0.5167, average train loss: 7.2690
[09/17 15:41:09 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1431, average loss: 6.8789
[09/17 15:41:09 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 16.00	top5: 61.50	
[09/17 15:41:31 visual_prompt]: 	Test 100/235. loss: 7.404, 0.1852 s / batch. (data: 1.19e-04)max mem: 17.22447 GB 
[09/17 15:41:50 visual_prompt]: 	Test 200/235. loss: 7.628, 0.2075 s / batch. (data: 2.39e-02)max mem: 17.22447 GB 
[09/17 15:41:58 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1941, average loss: 7.1974
[09/17 15:41:58 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.65	top5: 62.77	
[09/17 15:41:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/17 15:42:07 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e-01, avg batch time: 0.5086, average train loss: 6.3910
[09/17 15:42:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1431, average loss: 6.4717
[09/17 15:42:10 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 62.00	
[09/17 15:42:31 visual_prompt]: 	Test 100/235. loss: 5.640, 0.1839 s / batch. (data: 1.87e-04)max mem: 17.22447 GB 
[09/17 15:42:51 visual_prompt]: 	Test 200/235. loss: 5.916, 0.1854 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 15:42:59 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1930, average loss: 6.2456
[09/17 15:42:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 62.55	
[09/17 15:42:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/17 15:43:08 visual_prompt]: Epoch 16 / 100: avg data time: 9.90e-02, avg batch time: 0.5019, average train loss: 3.7105
[09/17 15:43:11 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1430, average loss: 2.7101
[09/17 15:43:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 18.50	top5: 66.00	
[09/17 15:43:32 visual_prompt]: 	Test 100/235. loss: 2.958, 0.1833 s / batch. (data: 1.40e-04)max mem: 17.22447 GB 
[09/17 15:43:52 visual_prompt]: 	Test 200/235. loss: 2.818, 0.1889 s / batch. (data: 1.58e-04)max mem: 17.22447 GB 
[09/17 15:43:59 visual_prompt]: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1932, average loss: 2.7676
[09/17 15:43:59 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.49	top5: 62.99	
[09/17 15:43:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/17 15:44:08 visual_prompt]: Epoch 17 / 100: avg data time: 9.58e-02, avg batch time: 0.5001, average train loss: 2.5803
[09/17 15:44:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1430, average loss: 2.3151
[09/17 15:44:11 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 14.00	top5: 59.00	
[09/17 15:44:33 visual_prompt]: 	Test 100/235. loss: 2.167, 0.1960 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 15:44:52 visual_prompt]: 	Test 200/235. loss: 2.259, 0.1839 s / batch. (data: 1.18e-04)max mem: 17.22447 GB 
[09/17 15:45:00 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1929, average loss: 2.2874
[09/17 15:45:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.94	top5: 62.47	
[09/17 15:45:00 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/17 15:45:09 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e-01, avg batch time: 0.5082, average train loss: 2.1698
[09/17 15:45:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1428, average loss: 2.0412
[09/17 15:45:12 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 84.00	
[09/17 15:45:33 visual_prompt]: 	Test 100/235. loss: 2.126, 0.1954 s / batch. (data: 1.23e-02)max mem: 17.22447 GB 
[09/17 15:45:52 visual_prompt]: 	Test 200/235. loss: 2.121, 0.1842 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 15:46:00 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1927, average loss: 2.1079
[09/17 15:46:00 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.84	top5: 83.67	
[09/17 15:46:00 visual_prompt]: Best epoch 18: best metric: 0.255
[09/17 15:46:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/17 15:46:10 visual_prompt]: Epoch 19 / 100: avg data time: 9.53e-02, avg batch time: 0.5005, average train loss: 2.3688
[09/17 15:46:13 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1428, average loss: 2.3895
[09/17 15:46:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 73.50	
[09/17 15:46:34 visual_prompt]: 	Test 100/235. loss: 2.927, 0.2005 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 15:46:53 visual_prompt]: 	Test 200/235. loss: 2.576, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 15:47:01 visual_prompt]: Inference (test):avg data time: 6.58e-03, avg batch time: 0.1923, average loss: 2.4930
[09/17 15:47:01 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.21	top5: 73.15	
[09/17 15:47:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/17 15:47:10 visual_prompt]: Epoch 20 / 100: avg data time: 9.63e-02, avg batch time: 0.4992, average train loss: 2.2751
[09/17 15:47:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1432, average loss: 2.2532
[09/17 15:47:13 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 29.00	top5: 87.50	
[09/17 15:47:34 visual_prompt]: 	Test 100/235. loss: 2.512, 0.2131 s / batch. (data: 1.48e-02)max mem: 17.22447 GB 
[09/17 15:47:54 visual_prompt]: 	Test 200/235. loss: 2.372, 0.1833 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 15:48:02 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1929, average loss: 2.2856
[09/17 15:48:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.41	top5: 89.33	
[09/17 15:48:02 visual_prompt]: Best epoch 20: best metric: 0.290
[09/17 15:48:02 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/17 15:48:11 visual_prompt]: Epoch 21 / 100: avg data time: 1.02e-01, avg batch time: 0.5050, average train loss: 2.0092
[09/17 15:48:14 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1472, average loss: 2.1721
[09/17 15:48:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.00	top5: 90.00	
[09/17 15:48:35 visual_prompt]: 	Test 100/235. loss: 2.261, 0.1862 s / batch. (data: 9.68e-05)max mem: 17.22447 GB 
[09/17 15:48:54 visual_prompt]: 	Test 200/235. loss: 2.159, 0.1959 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 15:49:02 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1924, average loss: 2.1513
[09/17 15:49:02 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.20	top5: 89.03	
[09/17 15:49:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/17 15:49:11 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e-01, avg batch time: 0.5074, average train loss: 2.0032
[09/17 15:49:14 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1431, average loss: 2.1483
[09/17 15:49:14 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.00	top5: 82.50	
[09/17 15:49:36 visual_prompt]: 	Test 100/235. loss: 2.615, 0.1836 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 15:49:55 visual_prompt]: 	Test 200/235. loss: 2.252, 0.1974 s / batch. (data: 1.42e-02)max mem: 17.22447 GB 
[09/17 15:50:03 visual_prompt]: Inference (test):avg data time: 8.71e-03, avg batch time: 0.1933, average loss: 2.2729
[09/17 15:50:03 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 22.28	top5: 78.23	
[09/17 15:50:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/17 15:50:12 visual_prompt]: Epoch 23 / 100: avg data time: 9.19e-02, avg batch time: 0.4991, average train loss: 1.8069
[09/17 15:50:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1430, average loss: 1.6904
[09/17 15:50:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.50	top5: 96.00	
[09/17 15:50:36 visual_prompt]: 	Test 100/235. loss: 1.889, 0.1832 s / batch. (data: 1.49e-04)max mem: 17.22447 GB 
[09/17 15:50:56 visual_prompt]: 	Test 200/235. loss: 1.621, 0.1835 s / batch. (data: 1.13e-04)max mem: 17.22447 GB 
[09/17 15:51:03 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1932, average loss: 1.7529
[09/17 15:51:03 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 26.62	top5: 94.41	
[09/17 15:51:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/17 15:51:12 visual_prompt]: Epoch 24 / 100: avg data time: 1.00e-01, avg batch time: 0.5035, average train loss: 1.8759
[09/17 15:51:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1445, average loss: 2.2263
[09/17 15:51:15 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 17.00	top5: 91.00	
[09/17 15:51:37 visual_prompt]: 	Test 100/235. loss: 2.346, 0.1899 s / batch. (data: 5.20e-03)max mem: 17.22447 GB 
[09/17 15:51:56 visual_prompt]: 	Test 200/235. loss: 2.127, 0.1958 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 15:52:04 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1935, average loss: 2.2166
[09/17 15:52:04 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 17.56	top5: 88.83	
[09/17 15:52:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/17 15:52:13 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e-01, avg batch time: 0.5097, average train loss: 4.7979
[09/17 15:52:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1430, average loss: 5.4369
[09/17 15:52:16 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 9.50	top5: 75.00	
[09/17 15:52:37 visual_prompt]: 	Test 100/235. loss: 5.073, 0.1839 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 15:52:57 visual_prompt]: 	Test 200/235. loss: 5.481, 0.1955 s / batch. (data: 1.22e-02)max mem: 17.22447 GB 
[09/17 15:53:05 visual_prompt]: Inference (test):avg data time: 8.47e-03, avg batch time: 0.1935, average loss: 5.3537
[09/17 15:53:05 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 12.37	top5: 73.18	
[09/17 15:53:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/17 15:53:14 visual_prompt]: Epoch 26 / 100: avg data time: 1.10e-01, avg batch time: 0.5121, average train loss: 4.3576
[09/17 15:53:17 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1429, average loss: 3.3942
[09/17 15:53:17 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 13.00	top5: 73.50	
[09/17 15:53:38 visual_prompt]: 	Test 100/235. loss: 3.558, 0.1952 s / batch. (data: 1.21e-02)max mem: 17.22447 GB 
[09/17 15:53:57 visual_prompt]: 	Test 200/235. loss: 3.530, 0.2088 s / batch. (data: 2.60e-02)max mem: 17.22447 GB 
[09/17 15:54:05 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1917, average loss: 3.5124
[09/17 15:54:05 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 14.37	top5: 72.75	
[09/17 15:54:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/17 15:54:14 visual_prompt]: Epoch 27 / 100: avg data time: 1.00e-01, avg batch time: 0.5071, average train loss: 3.2606
[09/17 15:54:18 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1431, average loss: 2.7965
[09/17 15:54:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.50	top5: 65.50	
[09/17 15:54:39 visual_prompt]: 	Test 100/235. loss: 2.835, 0.1861 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 15:54:58 visual_prompt]: 	Test 200/235. loss: 2.912, 0.1971 s / batch. (data: 1.37e-02)max mem: 17.22447 GB 
[09/17 15:55:06 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1931, average loss: 2.8910
[09/17 15:55:06 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 19.95	top5: 63.17	
[09/17 15:55:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/17 15:55:15 visual_prompt]: Epoch 28 / 100: avg data time: 9.37e-02, avg batch time: 0.5004, average train loss: 2.7047
[09/17 15:55:18 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1429, average loss: 2.3359
[09/17 15:55:18 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 20.50	top5: 84.50	
[09/17 15:55:39 visual_prompt]: 	Test 100/235. loss: 2.525, 0.1959 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 15:55:59 visual_prompt]: 	Test 200/235. loss: 2.309, 0.1925 s / batch. (data: 9.31e-03)max mem: 17.22447 GB 
[09/17 15:56:07 visual_prompt]: Inference (test):avg data time: 8.79e-03, avg batch time: 0.1939, average loss: 2.4625
[09/17 15:56:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 18.42	top5: 83.64	
[09/17 15:56:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/17 15:56:16 visual_prompt]: Epoch 29 / 100: avg data time: 9.23e-02, avg batch time: 0.5007, average train loss: 2.1041
[09/17 15:56:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1428, average loss: 2.1393
[09/17 15:56:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 23.00	top5: 86.50	
[09/17 15:56:40 visual_prompt]: 	Test 100/235. loss: 2.586, 0.1834 s / batch. (data: 1.05e-04)max mem: 17.22447 GB 
[09/17 15:56:59 visual_prompt]: 	Test 200/235. loss: 2.267, 0.1841 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 15:57:07 visual_prompt]: Inference (test):avg data time: 7.15e-03, avg batch time: 0.1924, average loss: 2.3314
[09/17 15:57:07 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.94	top5: 83.41	
[09/17 15:57:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/17 15:57:16 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e-01, avg batch time: 0.5075, average train loss: 2.1405
[09/17 15:57:19 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1429, average loss: 2.7318
[09/17 15:57:19 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 19.00	top5: 90.50	
[09/17 15:57:41 visual_prompt]: 	Test 100/235. loss: 2.837, 0.1844 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 15:58:00 visual_prompt]: 	Test 200/235. loss: 2.903, 0.2044 s / batch. (data: 1.47e-02)max mem: 17.22447 GB 
[09/17 15:58:08 visual_prompt]: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1925, average loss: 2.8334
[09/17 15:58:08 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 17.27	top5: 90.54	
[09/17 15:58:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/17 15:58:17 visual_prompt]: Epoch 31 / 100: avg data time: 9.92e-02, avg batch time: 0.5062, average train loss: 1.9929
[09/17 15:58:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1429, average loss: 2.1536
[09/17 15:58:20 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.00	top5: 88.00	
[09/17 15:58:41 visual_prompt]: 	Test 100/235. loss: 2.587, 0.2118 s / batch. (data: 1.95e-02)max mem: 17.22447 GB 
[09/17 15:59:01 visual_prompt]: 	Test 200/235. loss: 2.399, 0.2017 s / batch. (data: 1.51e-02)max mem: 17.22447 GB 
[09/17 15:59:08 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1933, average loss: 2.3612
[09/17 15:59:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.59	top5: 80.35	
[09/17 15:59:09 visual_prompt]: Best epoch 31: best metric: 0.320
[09/17 15:59:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/17 15:59:17 visual_prompt]: Epoch 32 / 100: avg data time: 9.13e-02, avg batch time: 0.4971, average train loss: 1.9716
[09/17 15:59:21 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1429, average loss: 1.9353
[09/17 15:59:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.50	top5: 93.00	
[09/17 15:59:42 visual_prompt]: 	Test 100/235. loss: 1.970, 0.2077 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 16:00:01 visual_prompt]: 	Test 200/235. loss: 1.903, 0.1988 s / batch. (data: 1.53e-02)max mem: 17.22447 GB 
[09/17 16:00:09 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1932, average loss: 1.9242
[09/17 16:00:09 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 25.15	top5: 91.77	
[09/17 16:00:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/17 16:00:18 visual_prompt]: Epoch 33 / 100: avg data time: 9.96e-02, avg batch time: 0.5022, average train loss: 1.7893
[09/17 16:00:21 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1432, average loss: 1.7155
[09/17 16:00:21 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.50	top5: 96.00	
[09/17 16:00:42 visual_prompt]: 	Test 100/235. loss: 2.046, 0.1841 s / batch. (data: 1.17e-04)max mem: 17.22447 GB 
[09/17 16:01:02 visual_prompt]: 	Test 200/235. loss: 1.658, 0.1979 s / batch. (data: 1.43e-02)max mem: 17.22447 GB 
[09/17 16:01:10 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1932, average loss: 1.7717
[09/17 16:01:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.71	top5: 95.29	
[09/17 16:01:10 visual_prompt]: Best epoch 33: best metric: 0.325
[09/17 16:01:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/17 16:01:19 visual_prompt]: Epoch 34 / 100: avg data time: 9.31e-02, avg batch time: 0.4958, average train loss: 1.9531
[09/17 16:01:22 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1450, average loss: 1.7033
[09/17 16:01:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.50	top5: 94.00	
[09/17 16:01:43 visual_prompt]: 	Test 100/235. loss: 1.972, 0.2019 s / batch. (data: 1.92e-02)max mem: 17.22447 GB 
[09/17 16:02:02 visual_prompt]: 	Test 200/235. loss: 1.759, 0.1840 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 16:02:10 visual_prompt]: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1925, average loss: 1.8079
[09/17 16:02:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.43	top5: 94.08	
[09/17 16:02:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/17 16:02:19 visual_prompt]: Epoch 35 / 100: avg data time: 9.93e-02, avg batch time: 0.5028, average train loss: 1.6705
[09/17 16:02:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1427, average loss: 1.9539
[09/17 16:02:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 26.00	top5: 92.50	
[09/17 16:02:43 visual_prompt]: 	Test 100/235. loss: 2.260, 0.2101 s / batch. (data: 2.73e-02)max mem: 17.22447 GB 
[09/17 16:03:02 visual_prompt]: 	Test 200/235. loss: 1.809, 0.1838 s / batch. (data: 1.65e-04)max mem: 17.22447 GB 
[09/17 16:03:10 visual_prompt]: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1924, average loss: 1.9412
[09/17 16:03:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.84	top5: 93.17	
[09/17 16:03:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/17 16:03:19 visual_prompt]: Epoch 36 / 100: avg data time: 9.14e-02, avg batch time: 0.4955, average train loss: 1.9327
[09/17 16:03:22 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1430, average loss: 2.0779
[09/17 16:03:22 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 29.50	top5: 87.50	
[09/17 16:03:43 visual_prompt]: 	Test 100/235. loss: 2.273, 0.1984 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 16:04:02 visual_prompt]: 	Test 200/235. loss: 2.282, 0.1857 s / batch. (data: 1.13e-04)max mem: 17.22447 GB 
[09/17 16:04:10 visual_prompt]: Inference (test):avg data time: 6.57e-03, avg batch time: 0.1920, average loss: 2.1849
[09/17 16:04:10 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.61	top5: 85.81	
[09/17 16:04:10 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/17 16:04:19 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e-01, avg batch time: 0.5102, average train loss: 1.8653
[09/17 16:04:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1428, average loss: 1.5931
[09/17 16:04:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.00	top5: 95.50	
[09/17 16:04:44 visual_prompt]: 	Test 100/235. loss: 1.674, 0.1878 s / batch. (data: 9.75e-05)max mem: 17.22447 GB 
[09/17 16:05:03 visual_prompt]: 	Test 200/235. loss: 1.593, 0.1842 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 16:05:11 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1934, average loss: 1.6252
[09/17 16:05:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.97	top5: 96.02	
[09/17 16:05:11 visual_prompt]: Best epoch 37: best metric: 0.370
[09/17 16:05:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/17 16:05:20 visual_prompt]: Epoch 38 / 100: avg data time: 1.03e-01, avg batch time: 0.5070, average train loss: 1.6720
[09/17 16:05:23 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1431, average loss: 1.4279
[09/17 16:05:23 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.50	top5: 98.00	
[09/17 16:05:44 visual_prompt]: 	Test 100/235. loss: 1.688, 0.1847 s / batch. (data: 1.38e-04)max mem: 17.22447 GB 
[09/17 16:06:04 visual_prompt]: 	Test 200/235. loss: 1.443, 0.2075 s / batch. (data: 2.43e-02)max mem: 17.22447 GB 
[09/17 16:06:11 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1933, average loss: 1.4525
[09/17 16:06:11 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.76	top5: 97.88	
[09/17 16:06:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/17 16:06:21 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e-01, avg batch time: 0.5061, average train loss: 1.7750
[09/17 16:06:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1427, average loss: 2.1622
[09/17 16:06:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.00	top5: 88.50	
[09/17 16:06:45 visual_prompt]: 	Test 100/235. loss: 2.173, 0.1833 s / batch. (data: 1.67e-04)max mem: 17.22447 GB 
[09/17 16:07:04 visual_prompt]: 	Test 200/235. loss: 2.213, 0.1836 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 16:07:12 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1934, average loss: 2.1755
[09/17 16:07:12 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 31.23	top5: 88.11	
[09/17 16:07:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/17 16:07:21 visual_prompt]: Epoch 40 / 100: avg data time: 1.08e-01, avg batch time: 0.5100, average train loss: 1.9386
[09/17 16:07:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1429, average loss: 1.6842
[09/17 16:07:24 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 32.00	top5: 96.00	
[09/17 16:07:45 visual_prompt]: 	Test 100/235. loss: 1.711, 0.1841 s / batch. (data: 1.14e-04)max mem: 17.22447 GB 
[09/17 16:08:05 visual_prompt]: 	Test 200/235. loss: 1.696, 0.1934 s / batch. (data: 1.52e-04)max mem: 17.22447 GB 
[09/17 16:08:13 visual_prompt]: Inference (test):avg data time: 6.98e-03, avg batch time: 0.1925, average loss: 1.6564
[09/17 16:08:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.31	top5: 96.92	
[09/17 16:08:13 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/17 16:08:22 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e-01, avg batch time: 0.5093, average train loss: 1.6684
[09/17 16:08:25 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1431, average loss: 1.5692
[09/17 16:08:25 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 95.50	
[09/17 16:08:46 visual_prompt]: 	Test 100/235. loss: 1.714, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 16:09:06 visual_prompt]: 	Test 200/235. loss: 1.650, 0.1985 s / batch. (data: 1.54e-02)max mem: 17.22447 GB 
[09/17 16:09:13 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1930, average loss: 1.6060
[09/17 16:09:13 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.77	top5: 95.95	
[09/17 16:09:13 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/17 16:09:23 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e-01, avg batch time: 0.5074, average train loss: 1.6671
[09/17 16:09:26 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1430, average loss: 1.7545
[09/17 16:09:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.00	top5: 91.00	
[09/17 16:09:47 visual_prompt]: 	Test 100/235. loss: 1.952, 0.1841 s / batch. (data: 1.66e-04)max mem: 17.22447 GB 
[09/17 16:10:06 visual_prompt]: 	Test 200/235. loss: 1.898, 0.1962 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 16:10:14 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1927, average loss: 1.8589
[09/17 16:10:14 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 32.23	top5: 87.84	
[09/17 16:10:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/17 16:10:23 visual_prompt]: Epoch 43 / 100: avg data time: 9.11e-02, avg batch time: 0.4992, average train loss: 1.8105
[09/17 16:10:26 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1429, average loss: 1.7869
[09/17 16:10:26 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.50	top5: 94.00	
[09/17 16:10:47 visual_prompt]: 	Test 100/235. loss: 1.991, 0.1834 s / batch. (data: 1.26e-04)max mem: 17.22447 GB 
[09/17 16:11:07 visual_prompt]: 	Test 200/235. loss: 1.818, 0.2077 s / batch. (data: 2.45e-02)max mem: 17.22447 GB 
[09/17 16:11:15 visual_prompt]: Inference (test):avg data time: 8.63e-03, avg batch time: 0.1939, average loss: 1.8101
[09/17 16:11:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.84	top5: 93.29	
[09/17 16:11:15 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/17 16:11:24 visual_prompt]: Epoch 44 / 100: avg data time: 1.00e-01, avg batch time: 0.5053, average train loss: 1.9222
[09/17 16:11:27 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1467, average loss: 2.2488
[09/17 16:11:27 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 18.50	top5: 88.50	
[09/17 16:11:48 visual_prompt]: 	Test 100/235. loss: 2.344, 0.2057 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 16:12:07 visual_prompt]: 	Test 200/235. loss: 2.142, 0.1841 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 16:12:15 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1928, average loss: 2.2353
[09/17 16:12:15 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 17.99	top5: 90.18	
[09/17 16:12:15 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/17 16:12:24 visual_prompt]: Epoch 45 / 100: avg data time: 1.00e-01, avg batch time: 0.5051, average train loss: 1.8427
[09/17 16:12:27 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1430, average loss: 1.7025
[09/17 16:12:27 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.00	top5: 93.50	
[09/17 16:12:49 visual_prompt]: 	Test 100/235. loss: 1.880, 0.1857 s / batch. (data: 1.01e-04)max mem: 17.22447 GB 
[09/17 16:13:08 visual_prompt]: 	Test 200/235. loss: 1.780, 0.1983 s / batch. (data: 1.47e-02)max mem: 17.22447 GB 
[09/17 16:13:16 visual_prompt]: Inference (test):avg data time: 8.76e-03, avg batch time: 0.1940, average loss: 1.7989
[09/17 16:13:16 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 24.28	top5: 92.16	
[09/17 16:13:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/17 16:13:25 visual_prompt]: Epoch 46 / 100: avg data time: 1.02e-01, avg batch time: 0.5055, average train loss: 1.6843
[09/17 16:13:28 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1460, average loss: 1.6198
[09/17 16:13:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.00	top5: 94.50	
[09/17 16:13:49 visual_prompt]: 	Test 100/235. loss: 1.615, 0.1835 s / batch. (data: 9.58e-05)max mem: 17.22447 GB 
[09/17 16:14:09 visual_prompt]: 	Test 200/235. loss: 1.655, 0.1959 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 16:14:16 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1927, average loss: 1.6230
[09/17 16:14:16 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.41	top5: 93.99	
[09/17 16:14:16 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/17 16:14:25 visual_prompt]: Epoch 47 / 100: avg data time: 1.03e-01, avg batch time: 0.5064, average train loss: 1.6262
[09/17 16:14:28 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1439, average loss: 1.6109
[09/17 16:14:28 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.00	top5: 97.00	
[09/17 16:14:50 visual_prompt]: 	Test 100/235. loss: 1.581, 0.2069 s / batch. (data: 1.61e-02)max mem: 17.22447 GB 
[09/17 16:15:09 visual_prompt]: 	Test 200/235. loss: 1.620, 0.1921 s / batch. (data: 8.87e-03)max mem: 17.22447 GB 
[09/17 16:15:17 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1930, average loss: 1.6190
[09/17 16:15:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.98	top5: 96.57	
[09/17 16:15:17 visual_prompt]: Best epoch 47: best metric: 0.380
[09/17 16:15:17 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/17 16:15:26 visual_prompt]: Epoch 48 / 100: avg data time: 9.57e-02, avg batch time: 0.4981, average train loss: 1.6809
[09/17 16:15:29 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1428, average loss: 1.7307
[09/17 16:15:29 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 34.00	top5: 93.00	
[09/17 16:15:50 visual_prompt]: 	Test 100/235. loss: 1.922, 0.1967 s / batch. (data: 1.36e-02)max mem: 17.22447 GB 
[09/17 16:16:09 visual_prompt]: 	Test 200/235. loss: 1.798, 0.1960 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 16:16:17 visual_prompt]: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1928, average loss: 1.7494
[09/17 16:16:17 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.27	top5: 94.07	
[09/17 16:16:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/17 16:16:27 visual_prompt]: Epoch 49 / 100: avg data time: 1.07e-01, avg batch time: 0.5108, average train loss: 1.9900
[09/17 16:16:30 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.1428, average loss: 1.8764
[09/17 16:16:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 21.00	top5: 82.00	
[09/17 16:16:51 visual_prompt]: 	Test 100/235. loss: 2.159, 0.2080 s / batch. (data: 2.52e-02)max mem: 17.22447 GB 
[09/17 16:17:10 visual_prompt]: 	Test 200/235. loss: 2.021, 0.1844 s / batch. (data: 1.02e-04)max mem: 17.22447 GB 
[09/17 16:17:18 visual_prompt]: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1930, average loss: 2.0070
[09/17 16:17:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 23.16	top5: 77.90	
[09/17 16:17:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/17 16:17:27 visual_prompt]: Epoch 50 / 100: avg data time: 1.03e-01, avg batch time: 0.5052, average train loss: 1.6880
[09/17 16:17:30 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1436, average loss: 1.7259
[09/17 16:17:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 35.00	top5: 97.00	
[09/17 16:17:51 visual_prompt]: 	Test 100/235. loss: 1.816, 0.1840 s / batch. (data: 1.16e-04)max mem: 17.22447 GB 
[09/17 16:18:10 visual_prompt]: 	Test 200/235. loss: 1.632, 0.1842 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 16:18:18 visual_prompt]: Inference (test):avg data time: 6.78e-03, avg batch time: 0.1922, average loss: 1.7377
[09/17 16:18:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 33.93	top5: 95.15	
[09/17 16:18:18 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/17 16:18:27 visual_prompt]: Epoch 51 / 100: avg data time: 9.56e-02, avg batch time: 0.4984, average train loss: 1.5824
[09/17 16:18:30 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1430, average loss: 1.6287
[09/17 16:18:30 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 31.50	top5: 94.50	
[09/17 16:18:51 visual_prompt]: 	Test 100/235. loss: 1.837, 0.1838 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 16:19:11 visual_prompt]: 	Test 200/235. loss: 1.629, 0.1918 s / batch. (data: 8.85e-03)max mem: 17.22447 GB 
[09/17 16:19:18 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1929, average loss: 1.7324
[09/17 16:19:18 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.23	top5: 94.25	
[09/17 16:19:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/17 16:19:28 visual_prompt]: Epoch 52 / 100: avg data time: 1.10e-01, avg batch time: 0.5121, average train loss: 1.5956
[09/17 16:19:31 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1429, average loss: 1.6326
[09/17 16:19:31 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 25.50	top5: 98.50	
[09/17 16:19:52 visual_prompt]: 	Test 100/235. loss: 1.982, 0.1832 s / batch. (data: 1.09e-04)max mem: 17.22447 GB 
[09/17 16:20:12 visual_prompt]: 	Test 200/235. loss: 1.764, 0.2084 s / batch. (data: 2.53e-02)max mem: 17.22447 GB 
[09/17 16:20:19 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1941, average loss: 1.7539
[09/17 16:20:19 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 27.55	top5: 98.41	
[09/17 16:20:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/17 16:20:29 visual_prompt]: Epoch 53 / 100: avg data time: 1.01e-01, avg batch time: 0.5045, average train loss: 1.5101
[09/17 16:20:32 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1433, average loss: 1.4004
[09/17 16:20:32 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 99.00	
[09/17 16:20:53 visual_prompt]: 	Test 100/235. loss: 1.511, 0.1990 s / batch. (data: 1.58e-02)max mem: 17.22447 GB 
[09/17 16:21:12 visual_prompt]: 	Test 200/235. loss: 1.394, 0.1968 s / batch. (data: 1.38e-02)max mem: 17.22447 GB 
[09/17 16:21:20 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1923, average loss: 1.4295
[09/17 16:21:20 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.05	top5: 98.21	
[09/17 16:21:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/17 16:21:29 visual_prompt]: Epoch 54 / 100: avg data time: 1.00e-01, avg batch time: 0.5039, average train loss: 1.5530
[09/17 16:21:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1430, average loss: 1.4822
[09/17 16:21:32 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 36.50	top5: 97.50	
[09/17 16:21:53 visual_prompt]: 	Test 100/235. loss: 1.596, 0.1833 s / batch. (data: 1.13e-04)max mem: 17.22447 GB 
[09/17 16:22:13 visual_prompt]: 	Test 200/235. loss: 1.527, 0.2103 s / batch. (data: 2.75e-02)max mem: 17.22447 GB 
[09/17 16:22:20 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1936, average loss: 1.5510
[09/17 16:22:21 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.71	top5: 97.52	
[09/17 16:22:21 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/17 16:22:30 visual_prompt]: Epoch 55 / 100: avg data time: 1.09e-01, avg batch time: 0.5111, average train loss: 1.4694
[09/17 16:22:33 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1430, average loss: 1.5075
[09/17 16:22:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.00	top5: 94.00	
[09/17 16:22:54 visual_prompt]: 	Test 100/235. loss: 1.800, 0.2024 s / batch. (data: 1.95e-02)max mem: 17.22447 GB 
[09/17 16:23:13 visual_prompt]: 	Test 200/235. loss: 1.604, 0.1897 s / batch. (data: 1.22e-04)max mem: 17.22447 GB 
[09/17 16:23:21 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1929, average loss: 1.6385
[09/17 16:23:21 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.25	top5: 91.26	
[09/17 16:23:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/17 16:23:30 visual_prompt]: Epoch 56 / 100: avg data time: 1.03e-01, avg batch time: 0.5079, average train loss: 1.3293
[09/17 16:23:33 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1429, average loss: 1.4665
[09/17 16:23:33 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 33.50	top5: 99.50	
[09/17 16:23:55 visual_prompt]: 	Test 100/235. loss: 1.648, 0.1837 s / batch. (data: 1.43e-04)max mem: 17.22447 GB 
[09/17 16:24:14 visual_prompt]: 	Test 200/235. loss: 1.557, 0.1838 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 16:24:22 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1924, average loss: 1.6036
[09/17 16:24:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 30.54	top5: 99.47	
[09/17 16:24:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/17 16:24:31 visual_prompt]: Epoch 57 / 100: avg data time: 9.98e-02, avg batch time: 0.5032, average train loss: 1.3746
[09/17 16:24:34 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1430, average loss: 1.5000
[09/17 16:24:34 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 28.00	top5: 98.00	
[09/17 16:24:55 visual_prompt]: 	Test 100/235. loss: 1.640, 0.2516 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 16:25:14 visual_prompt]: 	Test 200/235. loss: 1.458, 0.1836 s / batch. (data: 1.53e-04)max mem: 17.22447 GB 
[09/17 16:25:22 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1925, average loss: 1.5245
[09/17 16:25:22 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.64	top5: 98.05	
[09/17 16:25:22 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/17 16:25:32 visual_prompt]: Epoch 58 / 100: avg data time: 1.05e-01, avg batch time: 0.5062, average train loss: 1.4220
[09/17 16:25:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1459, average loss: 2.0758
[09/17 16:25:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 20.00	top5: 92.00	
[09/17 16:25:56 visual_prompt]: 	Test 100/235. loss: 2.068, 0.1836 s / batch. (data: 1.06e-04)max mem: 17.22447 GB 
[09/17 16:26:15 visual_prompt]: 	Test 200/235. loss: 2.109, 0.2246 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 16:26:23 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1935, average loss: 2.0920
[09/17 16:26:23 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 21.38	top5: 91.67	
[09/17 16:26:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/17 16:26:32 visual_prompt]: Epoch 59 / 100: avg data time: 9.73e-02, avg batch time: 0.5003, average train loss: 1.5782
[09/17 16:26:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1431, average loss: 1.5745
[09/17 16:26:35 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.00	top5: 96.00	
[09/17 16:26:57 visual_prompt]: 	Test 100/235. loss: 1.737, 0.1835 s / batch. (data: 1.20e-04)max mem: 17.22447 GB 
[09/17 16:27:16 visual_prompt]: 	Test 200/235. loss: 1.535, 0.2061 s / batch. (data: 2.12e-02)max mem: 17.22447 GB 
[09/17 16:27:24 visual_prompt]: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1936, average loss: 1.5795
[09/17 16:27:24 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.81	top5: 94.33	
[09/17 16:27:24 visual_prompt]: Best epoch 59: best metric: 0.390
[09/17 16:27:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/17 16:27:33 visual_prompt]: Epoch 60 / 100: avg data time: 9.72e-02, avg batch time: 0.5006, average train loss: 1.3856
[09/17 16:27:36 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1428, average loss: 1.2842
[09/17 16:27:36 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 44.00	top5: 98.50	
[09/17 16:27:57 visual_prompt]: 	Test 100/235. loss: 1.567, 0.1895 s / batch. (data: 1.45e-04)max mem: 17.22447 GB 
[09/17 16:28:17 visual_prompt]: 	Test 200/235. loss: 1.367, 0.2051 s / batch. (data: 2.21e-02)max mem: 17.22447 GB 
[09/17 16:28:25 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1931, average loss: 1.4346
[09/17 16:28:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.22	top5: 98.18	
[09/17 16:28:25 visual_prompt]: Best epoch 60: best metric: 0.440
[09/17 16:28:25 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/17 16:28:34 visual_prompt]: Epoch 61 / 100: avg data time: 9.74e-02, avg batch time: 0.5039, average train loss: 1.3232
[09/17 16:28:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1474, average loss: 1.0753
[09/17 16:28:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 53.00	top5: 100.00	
[09/17 16:28:58 visual_prompt]: 	Test 100/235. loss: 1.320, 0.1836 s / batch. (data: 1.14e-04)max mem: 17.22447 GB 
[09/17 16:29:17 visual_prompt]: 	Test 200/235. loss: 1.190, 0.1842 s / batch. (data: 1.03e-04)max mem: 17.22447 GB 
[09/17 16:29:25 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1929, average loss: 1.2051
[09/17 16:29:25 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.73	top5: 99.67	
[09/17 16:29:25 visual_prompt]: Best epoch 61: best metric: 0.530
[09/17 16:29:25 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/17 16:29:34 visual_prompt]: Epoch 62 / 100: avg data time: 1.01e-01, avg batch time: 0.5032, average train loss: 1.1893
[09/17 16:29:37 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1432, average loss: 1.6596
[09/17 16:29:37 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 31.50	top5: 97.00	
[09/17 16:29:59 visual_prompt]: 	Test 100/235. loss: 1.746, 0.1932 s / batch. (data: 1.48e-04)max mem: 17.22447 GB 
[09/17 16:30:18 visual_prompt]: 	Test 200/235. loss: 1.745, 0.1960 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 16:30:26 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1931, average loss: 1.7466
[09/17 16:30:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.38	top5: 97.25	
[09/17 16:30:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/17 16:30:35 visual_prompt]: Epoch 63 / 100: avg data time: 1.07e-01, avg batch time: 0.5090, average train loss: 1.1989
[09/17 16:30:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1430, average loss: 1.5658
[09/17 16:30:38 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 37.50	top5: 99.00	
[09/17 16:30:59 visual_prompt]: 	Test 100/235. loss: 1.896, 0.1838 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 16:31:19 visual_prompt]: 	Test 200/235. loss: 1.788, 0.1965 s / batch. (data: 1.29e-02)max mem: 17.22447 GB 
[09/17 16:31:26 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1933, average loss: 1.6877
[09/17 16:31:26 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 34.06	top5: 98.91	
[09/17 16:31:26 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/17 16:31:36 visual_prompt]: Epoch 64 / 100: avg data time: 1.06e-01, avg batch time: 0.5105, average train loss: 1.3238
[09/17 16:31:39 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1432, average loss: 1.1170
[09/17 16:31:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 50.00	top5: 100.00	
[09/17 16:32:00 visual_prompt]: 	Test 100/235. loss: 1.357, 0.1892 s / batch. (data: 1.15e-04)max mem: 17.22447 GB 
[09/17 16:32:19 visual_prompt]: 	Test 200/235. loss: 1.249, 0.1985 s / batch. (data: 6.91e-05)max mem: 17.22447 GB 
[09/17 16:32:27 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1930, average loss: 1.2525
[09/17 16:32:27 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 43.16	top5: 99.45	
[09/17 16:32:27 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/17 16:32:36 visual_prompt]: Epoch 65 / 100: avg data time: 9.40e-02, avg batch time: 0.4999, average train loss: 1.2117
[09/17 16:32:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1437, average loss: 1.6068
[09/17 16:32:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 27.00	top5: 97.00	
[09/17 16:33:00 visual_prompt]: 	Test 100/235. loss: 1.649, 0.1991 s / batch. (data: 1.56e-02)max mem: 17.22447 GB 
[09/17 16:33:19 visual_prompt]: 	Test 200/235. loss: 1.763, 0.2078 s / batch. (data: 2.47e-02)max mem: 17.22447 GB 
[09/17 16:33:27 visual_prompt]: Inference (test):avg data time: 7.33e-03, avg batch time: 0.1927, average loss: 1.7101
[09/17 16:33:27 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 28.44	top5: 96.94	
[09/17 16:33:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/17 16:33:36 visual_prompt]: Epoch 66 / 100: avg data time: 9.51e-02, avg batch time: 0.5020, average train loss: 1.2540
[09/17 16:33:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1431, average loss: 1.1749
[09/17 16:33:39 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 46.00	top5: 100.00	
[09/17 16:34:00 visual_prompt]: 	Test 100/235. loss: 1.353, 0.1838 s / batch. (data: 1.03e-04)max mem: 17.22447 GB 
[09/17 16:34:20 visual_prompt]: 	Test 200/235. loss: 1.397, 0.2010 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 16:34:28 visual_prompt]: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1934, average loss: 1.3450
[09/17 16:34:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.89	top5: 99.27	
[09/17 16:34:28 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/17 16:34:37 visual_prompt]: Epoch 67 / 100: avg data time: 1.00e-01, avg batch time: 0.5061, average train loss: 1.2092
[09/17 16:34:40 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1432, average loss: 1.7222
[09/17 16:34:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 30.00	top5: 95.00	
[09/17 16:35:01 visual_prompt]: 	Test 100/235. loss: 2.106, 0.1855 s / batch. (data: 1.07e-04)max mem: 17.22447 GB 
[09/17 16:35:20 visual_prompt]: 	Test 200/235. loss: 1.888, 0.1840 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 16:35:28 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1925, average loss: 1.9428
[09/17 16:35:28 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 29.67	top5: 92.59	
[09/17 16:35:28 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/17 16:35:37 visual_prompt]: Epoch 68 / 100: avg data time: 1.01e-01, avg batch time: 0.5042, average train loss: 1.3304
[09/17 16:35:40 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1435, average loss: 1.2381
[09/17 16:35:40 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 39.50	top5: 100.00	
[09/17 16:36:01 visual_prompt]: 	Test 100/235. loss: 1.500, 0.1839 s / batch. (data: 1.61e-04)max mem: 17.22447 GB 
[09/17 16:36:21 visual_prompt]: 	Test 200/235. loss: 1.289, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 16:36:29 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1922, average loss: 1.3390
[09/17 16:36:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 37.17	top5: 99.61	
[09/17 16:36:29 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/17 16:36:38 visual_prompt]: Epoch 69 / 100: avg data time: 9.93e-02, avg batch time: 0.5034, average train loss: 1.1196
[09/17 16:36:41 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1440, average loss: 0.9971
[09/17 16:36:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 50.50	top5: 100.00	
[09/17 16:37:02 visual_prompt]: 	Test 100/235. loss: 1.208, 0.1965 s / batch. (data: 1.31e-02)max mem: 17.22447 GB 
[09/17 16:37:21 visual_prompt]: 	Test 200/235. loss: 1.239, 0.1840 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 16:37:29 visual_prompt]: Inference (test):avg data time: 8.86e-03, avg batch time: 0.1937, average loss: 1.2138
[09/17 16:37:29 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 42.07	top5: 99.75	
[09/17 16:37:29 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/17 16:37:38 visual_prompt]: Epoch 70 / 100: avg data time: 9.76e-02, avg batch time: 0.5029, average train loss: 1.0445
[09/17 16:37:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1432, average loss: 0.8036
[09/17 16:37:41 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 65.00	top5: 100.00	
[09/17 16:38:02 visual_prompt]: 	Test 100/235. loss: 1.217, 0.2195 s / batch. (data: 1.74e-02)max mem: 17.22447 GB 
[09/17 16:38:22 visual_prompt]: 	Test 200/235. loss: 1.141, 0.1840 s / batch. (data: 1.16e-04)max mem: 17.22447 GB 
[09/17 16:38:30 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1923, average loss: 1.0681
[09/17 16:38:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 52.89	top5: 99.90	
[09/17 16:38:30 visual_prompt]: Best epoch 70: best metric: 0.650
[09/17 16:38:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/17 16:38:39 visual_prompt]: Epoch 71 / 100: avg data time: 9.27e-02, avg batch time: 0.4977, average train loss: 1.0066
[09/17 16:38:42 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1430, average loss: 1.2122
[09/17 16:38:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 47.00	top5: 99.50	
[09/17 16:39:03 visual_prompt]: 	Test 100/235. loss: 1.419, 0.1836 s / batch. (data: 1.60e-04)max mem: 17.22447 GB 
[09/17 16:39:22 visual_prompt]: 	Test 200/235. loss: 1.438, 0.2094 s / batch. (data: 2.64e-02)max mem: 17.22447 GB 
[09/17 16:39:30 visual_prompt]: Inference (test):avg data time: 6.68e-03, avg batch time: 0.1923, average loss: 1.4028
[09/17 16:39:30 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.35	top5: 99.41	
[09/17 16:39:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/17 16:39:39 visual_prompt]: Epoch 72 / 100: avg data time: 1.00e-01, avg batch time: 0.5071, average train loss: 1.0182
[09/17 16:39:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1432, average loss: 1.3128
[09/17 16:39:42 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 38.50	top5: 100.00	
[09/17 16:40:03 visual_prompt]: 	Test 100/235. loss: 1.551, 0.1869 s / batch. (data: 2.08e-03)max mem: 17.22447 GB 
[09/17 16:40:23 visual_prompt]: 	Test 200/235. loss: 1.680, 0.1838 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 16:40:30 visual_prompt]: Inference (test):avg data time: 7.33e-03, avg batch time: 0.1933, average loss: 1.5445
[09/17 16:40:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 35.49	top5: 98.64	
[09/17 16:40:31 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/17 16:40:40 visual_prompt]: Epoch 73 / 100: avg data time: 1.09e-01, avg batch time: 0.5117, average train loss: 1.1145
[09/17 16:40:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1434, average loss: 1.0457
[09/17 16:40:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 49.00	top5: 100.00	
[09/17 16:41:04 visual_prompt]: 	Test 100/235. loss: 1.321, 0.2132 s / batch. (data: 3.06e-02)max mem: 17.22447 GB 
[09/17 16:41:23 visual_prompt]: 	Test 200/235. loss: 1.290, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22447 GB 
[09/17 16:41:31 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1934, average loss: 1.2642
[09/17 16:41:31 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.69	top5: 99.73	
[09/17 16:41:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/17 16:41:40 visual_prompt]: Epoch 74 / 100: avg data time: 1.05e-01, avg batch time: 0.5085, average train loss: 0.9190
[09/17 16:41:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1432, average loss: 0.8416
[09/17 16:41:43 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 64.50	top5: 100.00	
[09/17 16:42:05 visual_prompt]: 	Test 100/235. loss: 1.242, 0.1967 s / batch. (data: 1.36e-02)max mem: 17.22447 GB 
[09/17 16:42:24 visual_prompt]: 	Test 200/235. loss: 1.187, 0.1843 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 16:42:32 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1930, average loss: 1.1485
[09/17 16:42:32 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.43	top5: 99.85	
[09/17 16:42:32 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/17 16:42:41 visual_prompt]: Epoch 75 / 100: avg data time: 1.12e-01, avg batch time: 0.5166, average train loss: 0.9825
[09/17 16:42:44 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1431, average loss: 0.9755
[09/17 16:42:44 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 57.50	top5: 100.00	
[09/17 16:43:05 visual_prompt]: 	Test 100/235. loss: 1.393, 0.2370 s / batch. (data: 5.36e-02)max mem: 17.22447 GB 
[09/17 16:43:25 visual_prompt]: 	Test 200/235. loss: 1.263, 0.1838 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 16:43:33 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1935, average loss: 1.2648
[09/17 16:43:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.15	top5: 99.80	
[09/17 16:43:33 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/17 16:43:42 visual_prompt]: Epoch 76 / 100: avg data time: 9.78e-02, avg batch time: 0.5023, average train loss: 0.9799
[09/17 16:43:45 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1430, average loss: 0.8728
[09/17 16:43:45 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 64.50	top5: 100.00	
[09/17 16:44:06 visual_prompt]: 	Test 100/235. loss: 1.260, 0.2304 s / batch. (data: 3.41e-02)max mem: 17.22447 GB 
[09/17 16:44:25 visual_prompt]: 	Test 200/235. loss: 1.153, 0.1999 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 16:44:33 visual_prompt]: Inference (test):avg data time: 6.08e-03, avg batch time: 0.1922, average loss: 1.1679
[09/17 16:44:33 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.53	top5: 99.72	
[09/17 16:44:33 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/17 16:44:42 visual_prompt]: Epoch 77 / 100: avg data time: 1.05e-01, avg batch time: 0.5094, average train loss: 0.8348
[09/17 16:44:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1430, average loss: 0.7271
[09/17 16:44:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 69.50	top5: 100.00	
[09/17 16:45:07 visual_prompt]: 	Test 100/235. loss: 1.266, 0.2019 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 16:45:26 visual_prompt]: 	Test 200/235. loss: 1.180, 0.1839 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 16:45:34 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1934, average loss: 1.1395
[09/17 16:45:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 51.57	top5: 99.88	
[09/17 16:45:34 visual_prompt]: Best epoch 77: best metric: 0.695
[09/17 16:45:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/17 16:45:43 visual_prompt]: Epoch 78 / 100: avg data time: 9.83e-02, avg batch time: 0.4996, average train loss: 0.7648
[09/17 16:45:46 visual_prompt]: Inference (val):avg data time: 4.10e-05, avg batch time: 0.1431, average loss: 0.8470
[09/17 16:45:46 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 62.50	top5: 100.00	
[09/17 16:46:07 visual_prompt]: 	Test 100/235. loss: 1.471, 0.2251 s / batch. (data: 4.24e-02)max mem: 17.22447 GB 
[09/17 16:46:27 visual_prompt]: 	Test 200/235. loss: 1.397, 0.1847 s / batch. (data: 1.24e-04)max mem: 17.22447 GB 
[09/17 16:46:34 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1927, average loss: 1.3569
[09/17 16:46:34 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.79	top5: 99.79	
[09/17 16:46:34 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/17 16:46:43 visual_prompt]: Epoch 79 / 100: avg data time: 9.33e-02, avg batch time: 0.5003, average train loss: 0.7445
[09/17 16:46:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1430, average loss: 0.8270
[09/17 16:46:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 64.00	top5: 100.00	
[09/17 16:47:08 visual_prompt]: 	Test 100/235. loss: 1.389, 0.2109 s / batch. (data: 2.47e-02)max mem: 17.22447 GB 
[09/17 16:47:27 visual_prompt]: 	Test 200/235. loss: 1.507, 0.1839 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 16:47:35 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1931, average loss: 1.3202
[09/17 16:47:35 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.21	top5: 99.77	
[09/17 16:47:35 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/17 16:47:44 visual_prompt]: Epoch 80 / 100: avg data time: 1.04e-01, avg batch time: 0.5061, average train loss: 0.7177
[09/17 16:47:47 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1429, average loss: 1.0940
[09/17 16:47:47 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 51.00	top5: 100.00	
[09/17 16:48:08 visual_prompt]: 	Test 100/235. loss: 1.583, 0.2056 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 16:48:28 visual_prompt]: 	Test 200/235. loss: 1.749, 0.1837 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 16:48:36 visual_prompt]: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1932, average loss: 1.5832
[09/17 16:48:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 39.41	top5: 99.70	
[09/17 16:48:36 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/17 16:48:45 visual_prompt]: Epoch 81 / 100: avg data time: 1.06e-01, avg batch time: 0.5103, average train loss: 0.7778
[09/17 16:48:48 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1428, average loss: 0.8347
[09/17 16:48:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 63.50	top5: 100.00	
[09/17 16:49:09 visual_prompt]: 	Test 100/235. loss: 1.454, 0.2053 s / batch. (data: 1.25e-02)max mem: 17.22447 GB 
[09/17 16:49:28 visual_prompt]: 	Test 200/235. loss: 1.368, 0.1991 s / batch. (data: 1.59e-02)max mem: 17.22447 GB 
[09/17 16:49:36 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1926, average loss: 1.3143
[09/17 16:49:36 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.96	top5: 99.80	
[09/17 16:49:36 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/17 16:49:45 visual_prompt]: Epoch 82 / 100: avg data time: 1.05e-01, avg batch time: 0.5071, average train loss: 0.6619
[09/17 16:49:48 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1457, average loss: 0.6217
[09/17 16:49:48 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 72.00	top5: 100.00	
[09/17 16:50:10 visual_prompt]: 	Test 100/235. loss: 1.415, 0.1979 s / batch. (data: 1.47e-02)max mem: 17.22447 GB 
[09/17 16:50:29 visual_prompt]: 	Test 200/235. loss: 1.277, 0.1963 s / batch. (data: 1.30e-02)max mem: 17.22447 GB 
[09/17 16:50:37 visual_prompt]: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1932, average loss: 1.2770
[09/17 16:50:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 50.53	top5: 99.81	
[09/17 16:50:37 visual_prompt]: Best epoch 82: best metric: 0.720
[09/17 16:50:37 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/17 16:50:46 visual_prompt]: Epoch 83 / 100: avg data time: 9.98e-02, avg batch time: 0.5033, average train loss: 0.7913
[09/17 16:50:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1431, average loss: 1.2037
[09/17 16:50:49 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 43.50	top5: 100.00	
[09/17 16:51:10 visual_prompt]: 	Test 100/235. loss: 1.685, 0.1830 s / batch. (data: 4.36e-05)max mem: 17.22447 GB 
[09/17 16:51:29 visual_prompt]: 	Test 200/235. loss: 1.794, 0.1873 s / batch. (data: 1.10e-04)max mem: 17.22447 GB 
[09/17 16:51:37 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1929, average loss: 1.6733
[09/17 16:51:37 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 36.69	top5: 99.47	
[09/17 16:51:37 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/17 16:51:47 visual_prompt]: Epoch 84 / 100: avg data time: 9.91e-02, avg batch time: 0.5043, average train loss: 0.5651
[09/17 16:51:50 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1430, average loss: 0.7076
[09/17 16:51:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 70.00	top5: 100.00	
[09/17 16:52:11 visual_prompt]: 	Test 100/235. loss: 1.503, 0.1837 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 16:52:30 visual_prompt]: 	Test 200/235. loss: 1.508, 0.1958 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 16:52:38 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1929, average loss: 1.3507
[09/17 16:52:38 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 46.06	top5: 99.88	
[09/17 16:52:38 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/17 16:52:47 visual_prompt]: Epoch 85 / 100: avg data time: 1.10e-01, avg batch time: 0.5142, average train loss: 0.4734
[09/17 16:52:50 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1432, average loss: 1.1422
[09/17 16:52:50 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 56.50	top5: 100.00	
[09/17 16:53:12 visual_prompt]: 	Test 100/235. loss: 2.010, 0.2082 s / batch. (data: 2.51e-02)max mem: 17.22447 GB 
[09/17 16:53:31 visual_prompt]: 	Test 200/235. loss: 2.314, 0.1837 s / batch. (data: 1.60e-04)max mem: 17.22447 GB 
[09/17 16:53:39 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1932, average loss: 1.8983
[09/17 16:53:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 40.59	top5: 99.71	
[09/17 16:53:39 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 16:53:48 visual_prompt]: Epoch 86 / 100: avg data time: 9.68e-02, avg batch time: 0.5010, average train loss: 0.5903
[09/17 16:53:51 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1430, average loss: 0.8460
[09/17 16:53:51 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 62.50	top5: 100.00	
[09/17 16:54:12 visual_prompt]: 	Test 100/235. loss: 1.698, 0.1842 s / batch. (data: 1.19e-04)max mem: 17.22447 GB 
[09/17 16:54:32 visual_prompt]: 	Test 200/235. loss: 1.839, 0.1841 s / batch. (data: 1.29e-04)max mem: 17.22447 GB 
[09/17 16:54:39 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1924, average loss: 1.5841
[09/17 16:54:39 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.64	top5: 99.81	
[09/17 16:54:39 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 16:54:49 visual_prompt]: Epoch 87 / 100: avg data time: 1.10e-01, avg batch time: 0.5140, average train loss: 0.4893
[09/17 16:54:52 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1434, average loss: 0.5019
[09/17 16:54:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 77.00	top5: 100.00	
[09/17 16:55:13 visual_prompt]: 	Test 100/235. loss: 1.513, 0.1841 s / batch. (data: 1.23e-04)max mem: 17.22447 GB 
[09/17 16:55:32 visual_prompt]: 	Test 200/235. loss: 1.536, 0.1840 s / batch. (data: 1.28e-04)max mem: 17.22447 GB 
[09/17 16:55:40 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1927, average loss: 1.3894
[09/17 16:55:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.98	top5: 99.89	
[09/17 16:55:40 visual_prompt]: Best epoch 87: best metric: 0.770
[09/17 16:55:40 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 16:55:49 visual_prompt]: Epoch 88 / 100: avg data time: 9.82e-02, avg batch time: 0.5001, average train loss: 0.4272
[09/17 16:55:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1428, average loss: 0.4456
[09/17 16:55:52 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 82.50	top5: 100.00	
[09/17 16:56:13 visual_prompt]: 	Test 100/235. loss: 1.702, 0.1985 s / batch. (data: 1.54e-02)max mem: 17.22447 GB 
[09/17 16:56:32 visual_prompt]: 	Test 200/235. loss: 1.887, 0.1999 s / batch. (data: 1.60e-02)max mem: 17.22447 GB 
[09/17 16:56:40 visual_prompt]: Inference (test):avg data time: 8.51e-03, avg batch time: 0.1936, average loss: 1.4776
[09/17 16:56:40 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 51.67	top5: 99.93	
[09/17 16:56:40 visual_prompt]: Best epoch 88: best metric: 0.825
[09/17 16:56:40 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 16:56:50 visual_prompt]: Epoch 89 / 100: avg data time: 1.15e-01, avg batch time: 0.5176, average train loss: 0.3846
[09/17 16:56:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1429, average loss: 0.8665
[09/17 16:56:53 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 64.50	top5: 100.00	
[09/17 16:57:14 visual_prompt]: 	Test 100/235. loss: 2.138, 0.1971 s / batch. (data: 9.68e-05)max mem: 17.22447 GB 
[09/17 16:57:33 visual_prompt]: 	Test 200/235. loss: 2.345, 0.1971 s / batch. (data: 1.40e-02)max mem: 17.22447 GB 
[09/17 16:57:41 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1936, average loss: 1.8919
[09/17 16:57:41 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 44.76	top5: 99.87	
[09/17 16:57:41 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 16:57:51 visual_prompt]: Epoch 90 / 100: avg data time: 1.14e-01, avg batch time: 0.5151, average train loss: 0.4641
[09/17 16:57:54 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1428, average loss: 0.5728
[09/17 16:57:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 79.00	top5: 100.00	
[09/17 16:58:15 visual_prompt]: 	Test 100/235. loss: 2.028, 0.2095 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 16:58:34 visual_prompt]: 	Test 200/235. loss: 1.846, 0.2001 s / batch. (data: 1.14e-02)max mem: 17.22447 GB 
[09/17 16:58:42 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1930, average loss: 1.7634
[09/17 16:58:42 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 48.77	top5: 99.82	
[09/17 16:58:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 16:58:51 visual_prompt]: Epoch 91 / 100: avg data time: 1.03e-01, avg batch time: 0.5102, average train loss: 0.5134
[09/17 16:58:54 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1431, average loss: 0.7702
[09/17 16:58:54 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 68.00	top5: 100.00	
[09/17 16:59:15 visual_prompt]: 	Test 100/235. loss: 1.883, 0.1830 s / batch. (data: 1.64e-04)max mem: 17.22447 GB 
[09/17 16:59:35 visual_prompt]: 	Test 200/235. loss: 2.127, 0.1991 s / batch. (data: 1.31e-04)max mem: 17.22447 GB 
[09/17 16:59:43 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1926, average loss: 1.7470
[09/17 16:59:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.32	top5: 99.82	
[09/17 16:59:43 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 16:59:52 visual_prompt]: Epoch 92 / 100: avg data time: 1.03e-01, avg batch time: 0.5082, average train loss: 0.3201
[09/17 16:59:55 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1429, average loss: 0.4476
[09/17 16:59:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 81.00	top5: 100.00	
[09/17 17:00:16 visual_prompt]: 	Test 100/235. loss: 1.836, 0.1969 s / batch. (data: 1.35e-02)max mem: 17.22447 GB 
[09/17 17:00:35 visual_prompt]: 	Test 200/235. loss: 1.872, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22447 GB 
[09/17 17:00:43 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1931, average loss: 1.5858
[09/17 17:00:43 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 50.46	top5: 99.89	
[09/17 17:00:43 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 17:00:52 visual_prompt]: Epoch 93 / 100: avg data time: 1.05e-01, avg batch time: 0.5084, average train loss: 0.2756
[09/17 17:00:55 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1443, average loss: 0.4843
[09/17 17:00:55 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 80.50	top5: 100.00	
[09/17 17:01:16 visual_prompt]: 	Test 100/235. loss: 1.933, 0.1837 s / batch. (data: 1.13e-04)max mem: 17.22447 GB 
[09/17 17:01:36 visual_prompt]: 	Test 200/235. loss: 2.109, 0.1962 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 17:01:44 visual_prompt]: Inference (test):avg data time: 6.88e-03, avg batch time: 0.1925, average loss: 1.7233
[09/17 17:01:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.57	top5: 99.87	
[09/17 17:01:44 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 17:01:53 visual_prompt]: Epoch 94 / 100: avg data time: 9.88e-02, avg batch time: 0.5019, average train loss: 0.2529
[09/17 17:01:56 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1427, average loss: 0.8197
[09/17 17:01:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 69.50	top5: 100.00	
[09/17 17:02:17 visual_prompt]: 	Test 100/235. loss: 2.252, 0.1834 s / batch. (data: 9.99e-05)max mem: 17.22447 GB 
[09/17 17:02:36 visual_prompt]: 	Test 200/235. loss: 2.534, 0.1840 s / batch. (data: 1.33e-04)max mem: 17.22447 GB 
[09/17 17:02:44 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1932, average loss: 2.0534
[09/17 17:02:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 45.32	top5: 99.84	
[09/17 17:02:44 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 17:02:53 visual_prompt]: Epoch 95 / 100: avg data time: 1.03e-01, avg batch time: 0.5057, average train loss: 0.2434
[09/17 17:02:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1430, average loss: 0.5169
[09/17 17:02:56 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 77.50	top5: 100.00	
[09/17 17:03:17 visual_prompt]: 	Test 100/235. loss: 2.132, 0.2271 s / batch. (data: 1.28e-02)max mem: 17.22447 GB 
[09/17 17:03:37 visual_prompt]: 	Test 200/235. loss: 2.215, 0.2077 s / batch. (data: 2.47e-02)max mem: 17.22447 GB 
[09/17 17:03:44 visual_prompt]: Inference (test):avg data time: 6.17e-03, avg batch time: 0.1918, average loss: 1.8819
[09/17 17:03:44 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 49.01	top5: 99.89	
[09/17 17:03:44 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 17:03:54 visual_prompt]: Epoch 96 / 100: avg data time: 1.01e-01, avg batch time: 0.5051, average train loss: 0.2062
[09/17 17:03:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1430, average loss: 0.6460
[09/17 17:03:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 17:04:18 visual_prompt]: 	Test 100/235. loss: 2.342, 0.2078 s / batch. (data: 2.49e-02)max mem: 17.22447 GB 
[09/17 17:04:37 visual_prompt]: 	Test 200/235. loss: 2.461, 0.1837 s / batch. (data: 1.27e-04)max mem: 17.22447 GB 
[09/17 17:04:45 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1935, average loss: 2.0565
[09/17 17:04:45 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.15	top5: 99.87	
[09/17 17:04:45 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 17:04:54 visual_prompt]: Epoch 97 / 100: avg data time: 9.12e-02, avg batch time: 0.4973, average train loss: 0.1886
[09/17 17:04:57 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1429, average loss: 0.6648
[09/17 17:04:57 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 74.00	top5: 100.00	
[09/17 17:05:18 visual_prompt]: 	Test 100/235. loss: 2.374, 0.1841 s / batch. (data: 1.25e-04)max mem: 17.22447 GB 
[09/17 17:05:38 visual_prompt]: 	Test 200/235. loss: 2.513, 0.2074 s / batch. (data: 2.44e-02)max mem: 17.22447 GB 
[09/17 17:05:45 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1923, average loss: 2.0990
[09/17 17:05:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.13	top5: 99.86	
[09/17 17:05:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 17:05:55 visual_prompt]: Epoch 98 / 100: avg data time: 9.99e-02, avg batch time: 0.5033, average train loss: 0.1993
[09/17 17:05:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1430, average loss: 0.6770
[09/17 17:05:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 75.00	top5: 100.00	
[09/17 17:06:19 visual_prompt]: 	Test 100/235. loss: 2.417, 0.1959 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 17:06:38 visual_prompt]: 	Test 200/235. loss: 2.557, 0.1835 s / batch. (data: 1.80e-04)max mem: 17.22447 GB 
[09/17 17:06:46 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1931, average loss: 2.1176
[09/17 17:06:46 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.11	top5: 99.87	
[09/17 17:06:46 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 17:06:55 visual_prompt]: Epoch 99 / 100: avg data time: 1.01e-01, avg batch time: 0.5037, average train loss: 0.1758
[09/17 17:06:58 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1432, average loss: 0.6021
[09/17 17:06:58 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 76.00	top5: 100.00	
[09/17 17:07:20 visual_prompt]: 	Test 100/235. loss: 2.336, 0.1836 s / batch. (data: 1.39e-04)max mem: 17.22447 GB 
[09/17 17:07:39 visual_prompt]: 	Test 200/235. loss: 2.468, 0.1955 s / batch. (data: 1.24e-02)max mem: 17.22447 GB 
[09/17 17:07:47 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1928, average loss: 2.0497
[09/17 17:07:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.74	top5: 99.88	
[09/17 17:07:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 17:07:56 visual_prompt]: Epoch 100 / 100: avg data time: 1.04e-01, avg batch time: 0.5091, average train loss: 0.1832
[09/17 17:07:59 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1431, average loss: 0.5861
[09/17 17:07:59 visual_prompt]: Classification results with val_vtab-clevr(task="count_all"): top1: 77.00	top5: 100.00	
[09/17 17:08:20 visual_prompt]: 	Test 100/235. loss: 2.355, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22447 GB 
[09/17 17:08:39 visual_prompt]: 	Test 200/235. loss: 2.463, 0.1835 s / batch. (data: 1.21e-04)max mem: 17.22447 GB 
[09/17 17:08:47 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1921, average loss: 2.0586
[09/17 17:08:47 visual_prompt]: Classification results with test_vtab-clevr(task="count_all"): top1: 47.77	top5: 99.88	
