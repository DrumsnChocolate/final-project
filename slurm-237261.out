/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 21:37:01 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 21:37:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 21:37:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 21:37:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 21:37:02 visual_prompt]: Training with config:
[09/25 21:37:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 21:37:02 visual_prompt]: Loading training data...
2023-09-25 21:37:02.755782: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-25 21:37:02.807786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-25 21:37:23.032723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/25 21:37:53 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 21:37:55 visual_prompt]: Number of images: 800
[09/25 21:37:55 visual_prompt]: Number of classes: 102 / 102
[09/25 21:37:55 visual_prompt]: Loading validation data...
[09/25 21:37:55 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 21:37:55 visual_prompt]: Number of images: 200
[09/25 21:37:55 visual_prompt]: Number of classes: 91 / 102
[09/25 21:37:55 visual_prompt]: Constructing models...
[09/25 21:37:58 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 21:37:58 visual_prompt]: tuned percent:0.625
[09/25 21:38:00 visual_prompt]: Device used for model: 0
[09/25 21:38:00 visual_prompt]: Setting up Evaluator...
[09/25 21:38:00 visual_prompt]: Setting up Trainer...
[09/25 21:38:00 visual_prompt]: 	Setting up the optimizer...
[09/25 21:38:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 21:38:11 visual_prompt]: Epoch 1 / 100: avg data time: 1.94e-01, avg batch time: 0.7876, average train loss: 4.6718
[09/25 21:38:12 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1578, average loss: 4.6780
[09/25 21:38:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:38:12 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 21:38:12 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 21:38:19 visual_prompt]: Epoch 2 / 100: avg data time: 6.08e-02, avg batch time: 0.4701, average train loss: 5.0082
[09/25 21:38:20 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1575, average loss: 5.4050
[09/25 21:38:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 3.00	
[09/25 21:38:20 visual_prompt]: Best epoch 2: best metric: 0.020
[09/25 21:38:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 21:38:27 visual_prompt]: Epoch 3 / 100: avg data time: 5.84e-02, avg batch time: 0.4680, average train loss: 6.4803
[09/25 21:38:28 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1582, average loss: 7.7159
[09/25 21:38:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 21:38:28 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 21:38:34 visual_prompt]: Epoch 4 / 100: avg data time: 4.32e-02, avg batch time: 0.4566, average train loss: 12.8774
[09/25 21:38:36 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1582, average loss: 11.2561
[09/25 21:38:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:38:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 21:38:42 visual_prompt]: Epoch 5 / 100: avg data time: 4.27e-02, avg batch time: 0.4574, average train loss: 26.5068
[09/25 21:38:43 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1582, average loss: 34.6122
[09/25 21:38:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.00	
[09/25 21:38:43 visual_prompt]: Best epoch 5: best metric: 0.025
[09/25 21:38:43 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 21:38:50 visual_prompt]: Epoch 6 / 100: avg data time: 5.88e-02, avg batch time: 0.4734, average train loss: 40.1588
[09/25 21:38:51 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1587, average loss: 51.8585
[09/25 21:38:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 21:38:51 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 21:38:57 visual_prompt]: Epoch 7 / 100: avg data time: 4.70e-02, avg batch time: 0.4617, average train loss: 73.2164
[09/25 21:38:59 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1595, average loss: 66.4576
[09/25 21:38:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:38:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 21:39:05 visual_prompt]: Epoch 8 / 100: avg data time: 4.35e-02, avg batch time: 0.4612, average train loss: 83.4749
[09/25 21:39:06 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1596, average loss: 97.8995
[09/25 21:39:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.50	
[09/25 21:39:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 21:39:13 visual_prompt]: Epoch 9 / 100: avg data time: 4.78e-02, avg batch time: 0.4664, average train loss: 138.8791
[09/25 21:39:14 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1598, average loss: 128.4067
[09/25 21:39:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 21:39:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 21:39:21 visual_prompt]: Epoch 10 / 100: avg data time: 5.86e-02, avg batch time: 0.4783, average train loss: 165.7658
[09/25 21:39:22 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1605, average loss: 154.3991
[09/25 21:39:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:39:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 21:39:29 visual_prompt]: Epoch 11 / 100: avg data time: 6.05e-02, avg batch time: 0.4783, average train loss: 182.8344
[09/25 21:39:30 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1610, average loss: 213.5628
[09/25 21:39:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 21:39:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 21:39:37 visual_prompt]: Epoch 12 / 100: avg data time: 6.14e-02, avg batch time: 0.4823, average train loss: 210.9633
[09/25 21:39:38 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1606, average loss: 201.6480
[09/25 21:39:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:39:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 21:39:44 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e-02, avg batch time: 0.4687, average train loss: 219.4873
[09/25 21:39:46 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1610, average loss: 221.4198
[09/25 21:39:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:39:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 21:39:52 visual_prompt]: Epoch 14 / 100: avg data time: 6.01e-02, avg batch time: 0.4790, average train loss: 212.1496
[09/25 21:39:54 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1612, average loss: 223.4091
[09/25 21:39:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:39:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 21:40:00 visual_prompt]: Epoch 15 / 100: avg data time: 4.77e-02, avg batch time: 0.4677, average train loss: 224.8954
[09/25 21:40:01 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1616, average loss: 205.7178
[09/25 21:40:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/25 21:40:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 21:40:08 visual_prompt]: Epoch 16 / 100: avg data time: 4.05e-02, avg batch time: 0.4650, average train loss: 217.4015
[09/25 21:40:09 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1612, average loss: 224.5676
[09/25 21:40:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:40:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 21:40:16 visual_prompt]: Epoch 17 / 100: avg data time: 5.51e-02, avg batch time: 0.4756, average train loss: 209.8273
[09/25 21:40:17 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1612, average loss: 213.4726
[09/25 21:40:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 21:40:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 21:40:24 visual_prompt]: Epoch 18 / 100: avg data time: 5.57e-02, avg batch time: 0.4757, average train loss: 194.1894
[09/25 21:40:25 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1612, average loss: 173.7425
[09/25 21:40:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:40:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 21:40:32 visual_prompt]: Epoch 19 / 100: avg data time: 5.95e-02, avg batch time: 0.4785, average train loss: 187.3746
[09/25 21:40:33 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1610, average loss: 202.4420
[09/25 21:40:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:40:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 21:40:40 visual_prompt]: Epoch 20 / 100: avg data time: 5.59e-02, avg batch time: 0.4760, average train loss: 214.7813
[09/25 21:40:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1611, average loss: 198.3066
[09/25 21:40:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 21:40:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 21:40:47 visual_prompt]: Epoch 21 / 100: avg data time: 5.41e-02, avg batch time: 0.4735, average train loss: 216.4864
[09/25 21:40:49 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1610, average loss: 200.6632
[09/25 21:40:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.00	
[09/25 21:40:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 21:40:55 visual_prompt]: Epoch 22 / 100: avg data time: 5.29e-02, avg batch time: 0.4718, average train loss: 229.4846
[09/25 21:40:57 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1607, average loss: 257.2174
[09/25 21:40:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:40:57 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 21:41:03 visual_prompt]: Epoch 23 / 100: avg data time: 4.87e-02, avg batch time: 0.4670, average train loss: 238.9902
[09/25 21:41:05 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1602, average loss: 309.2088
[09/25 21:41:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/25 21:41:05 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 21:41:11 visual_prompt]: Epoch 24 / 100: avg data time: 4.20e-02, avg batch time: 0.4623, average train loss: 232.6333
[09/25 21:41:12 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1601, average loss: 241.9807
[09/25 21:41:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:41:12 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 21:41:19 visual_prompt]: Epoch 25 / 100: avg data time: 5.67e-02, avg batch time: 0.4735, average train loss: 232.2697
[09/25 21:41:20 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1603, average loss: 231.1181
[09/25 21:41:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 21:41:20 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 21:41:26 visual_prompt]: Epoch 26 / 100: avg data time: 4.46e-02, avg batch time: 0.4624, average train loss: 240.4584
[09/25 21:41:28 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1597, average loss: 207.9326
[09/25 21:41:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 21:41:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 21:41:34 visual_prompt]: Epoch 27 / 100: avg data time: 4.54e-02, avg batch time: 0.4644, average train loss: 231.0636
[09/25 21:41:36 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1598, average loss: 218.2485
[09/25 21:41:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 21:41:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 21:41:42 visual_prompt]: Epoch 28 / 100: avg data time: 4.94e-02, avg batch time: 0.4660, average train loss: 213.9659
[09/25 21:41:43 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1596, average loss: 167.5292
[09/25 21:41:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:41:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 21:41:50 visual_prompt]: Epoch 29 / 100: avg data time: 4.97e-02, avg batch time: 0.4663, average train loss: 187.4764
[09/25 21:41:51 visual_prompt]: Inference (val):avg data time: 1.71e-05, avg batch time: 0.1596, average loss: 181.6885
[09/25 21:41:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 21:41:51 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 21:41:57 visual_prompt]: Epoch 30 / 100: avg data time: 4.57e-02, avg batch time: 0.4611, average train loss: 205.0936
[09/25 21:41:59 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1593, average loss: 179.4166
[09/25 21:41:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:41:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 21:42:05 visual_prompt]: Epoch 31 / 100: avg data time: 5.41e-02, avg batch time: 0.4706, average train loss: 173.3378
[09/25 21:42:07 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1595, average loss: 149.1405
[09/25 21:42:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 21:42:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 21:42:13 visual_prompt]: Epoch 32 / 100: avg data time: 5.45e-02, avg batch time: 0.4692, average train loss: 175.5946
[09/25 21:42:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1597, average loss: 176.1480
[09/25 21:42:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:42:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 21:42:21 visual_prompt]: Epoch 33 / 100: avg data time: 5.24e-02, avg batch time: 0.4685, average train loss: 182.6557
[09/25 21:42:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1595, average loss: 173.4678
[09/25 21:42:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:42:22 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 21:42:29 visual_prompt]: Epoch 34 / 100: avg data time: 5.19e-02, avg batch time: 0.4665, average train loss: 199.3277
[09/25 21:42:30 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1588, average loss: 211.4659
[09/25 21:42:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:42:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 21:42:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.02e-02, avg batch time: 0.4648, average train loss: 198.2741
[09/25 21:42:38 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1586, average loss: 168.6018
[09/25 21:42:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 21:42:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 21:42:44 visual_prompt]: Epoch 36 / 100: avg data time: 4.94e-02, avg batch time: 0.4640, average train loss: 210.1675
[09/25 21:42:45 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1587, average loss: 183.6818
[09/25 21:42:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:42:45 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 21:42:52 visual_prompt]: Epoch 37 / 100: avg data time: 5.67e-02, avg batch time: 0.4702, average train loss: 199.4469
[09/25 21:42:53 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1588, average loss: 158.4351
[09/25 21:42:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:42:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 21:42:59 visual_prompt]: Epoch 38 / 100: avg data time: 4.56e-02, avg batch time: 0.4596, average train loss: 185.9789
[09/25 21:43:01 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1587, average loss: 183.2246
[09/25 21:43:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 21:43:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 21:43:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.60e-02, avg batch time: 0.4718, average train loss: 211.4677
[09/25 21:43:09 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1584, average loss: 164.6980
[09/25 21:43:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 21:43:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 21:43:15 visual_prompt]: Epoch 40 / 100: avg data time: 5.47e-02, avg batch time: 0.4686, average train loss: 197.9766
[09/25 21:43:17 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1585, average loss: 138.7020
[09/25 21:43:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 21:43:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 21:43:23 visual_prompt]: Epoch 41 / 100: avg data time: 5.43e-02, avg batch time: 0.4701, average train loss: 174.6238
[09/25 21:43:24 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1588, average loss: 164.0412
[09/25 21:43:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 21:43:24 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 21:43:31 visual_prompt]: Epoch 42 / 100: avg data time: 5.21e-02, avg batch time: 0.4664, average train loss: 180.7888
[09/25 21:43:32 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1582, average loss: 197.9301
[09/25 21:43:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 21:43:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 21:43:39 visual_prompt]: Epoch 43 / 100: avg data time: 5.44e-02, avg batch time: 0.4667, average train loss: 204.5869
[09/25 21:43:40 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1581, average loss: 186.0496
[09/25 21:43:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:43:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 21:43:46 visual_prompt]: Epoch 44 / 100: avg data time: 5.54e-02, avg batch time: 0.4687, average train loss: 180.0981
[09/25 21:43:48 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1584, average loss: 166.1113
[09/25 21:43:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 21:43:48 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 21:43:54 visual_prompt]: Epoch 45 / 100: avg data time: 5.04e-02, avg batch time: 0.4655, average train loss: 161.8235
[09/25 21:43:56 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1584, average loss: 150.3629
[09/25 21:43:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 21:43:56 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 21:44:02 visual_prompt]: Epoch 46 / 100: avg data time: 5.56e-02, avg batch time: 0.4700, average train loss: 155.9297
[09/25 21:44:04 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1578, average loss: 153.7109
[09/25 21:44:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 21:44:04 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 21:44:10 visual_prompt]: Epoch 47 / 100: avg data time: 4.20e-02, avg batch time: 0.4553, average train loss: 155.3383
[09/25 21:44:11 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1583, average loss: 167.1579
[09/25 21:44:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/25 21:44:11 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 21:44:17 visual_prompt]: Epoch 48 / 100: avg data time: 4.13e-02, avg batch time: 0.4552, average train loss: 146.2236
[09/25 21:44:19 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1582, average loss: 171.9387
[09/25 21:44:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:44:19 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 21:44:25 visual_prompt]: Epoch 49 / 100: avg data time: 4.81e-02, avg batch time: 0.4613, average train loss: 131.9891
[09/25 21:44:26 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1582, average loss: 160.6557
[09/25 21:44:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 1.50	
[09/25 21:44:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 21:44:33 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e-02, avg batch time: 0.4602, average train loss: 148.1263
[09/25 21:44:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1587, average loss: 160.5123
[09/25 21:44:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:44:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 21:44:41 visual_prompt]: Epoch 51 / 100: avg data time: 6.39e-02, avg batch time: 0.4758, average train loss: 133.7305
[09/25 21:44:42 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1582, average loss: 150.8821
[09/25 21:44:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 21:44:42 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 21:44:48 visual_prompt]: Epoch 52 / 100: avg data time: 4.86e-02, avg batch time: 0.4615, average train loss: 123.1517
[09/25 21:44:50 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1583, average loss: 137.2989
[09/25 21:44:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 21:44:50 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 21:44:56 visual_prompt]: Epoch 53 / 100: avg data time: 5.51e-02, avg batch time: 0.4666, average train loss: 105.8396
[09/25 21:44:57 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1581, average loss: 117.8231
[09/25 21:44:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:44:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 21:45:04 visual_prompt]: Epoch 54 / 100: avg data time: 6.39e-02, avg batch time: 0.4748, average train loss: 116.8826
[09/25 21:45:05 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1582, average loss: 125.8356
[09/25 21:45:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 21:45:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 21:45:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.19e-02, avg batch time: 0.4727, average train loss: 131.9794
[09/25 21:45:13 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1575, average loss: 125.4723
[09/25 21:45:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 21:45:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 21:45:20 visual_prompt]: Epoch 56 / 100: avg data time: 5.31e-02, avg batch time: 0.4650, average train loss: 128.7738
[09/25 21:45:21 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1580, average loss: 117.6933
[09/25 21:45:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:45:21 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 21:45:27 visual_prompt]: Epoch 57 / 100: avg data time: 4.28e-02, avg batch time: 0.4555, average train loss: 121.4016
[09/25 21:45:29 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1580, average loss: 107.7007
[09/25 21:45:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:45:29 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 21:45:35 visual_prompt]: Epoch 58 / 100: avg data time: 5.55e-02, avg batch time: 0.4679, average train loss: 96.2702
[09/25 21:45:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1576, average loss: 104.0496
[09/25 21:45:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 21:45:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 21:45:43 visual_prompt]: Epoch 59 / 100: avg data time: 4.99e-02, avg batch time: 0.4632, average train loss: 102.8665
[09/25 21:45:44 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1578, average loss: 95.9635
[09/25 21:45:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 21:45:44 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 21:45:51 visual_prompt]: Epoch 60 / 100: avg data time: 5.00e-02, avg batch time: 0.4620, average train loss: 125.5138
[09/25 21:45:52 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1582, average loss: 90.3850
[09/25 21:45:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:45:52 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 21:45:58 visual_prompt]: Epoch 61 / 100: avg data time: 5.53e-02, avg batch time: 0.4674, average train loss: 85.0905
[09/25 21:46:00 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1573, average loss: 93.0638
[09/25 21:46:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:46:00 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 21:46:06 visual_prompt]: Epoch 62 / 100: avg data time: 4.52e-02, avg batch time: 0.4588, average train loss: 77.5317
[09/25 21:46:07 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1582, average loss: 78.3708
[09/25 21:46:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 21:46:07 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 21:46:14 visual_prompt]: Epoch 63 / 100: avg data time: 5.68e-02, avg batch time: 0.4685, average train loss: 72.6601
[09/25 21:46:15 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1581, average loss: 70.7025
[09/25 21:46:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 21:46:15 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 21:46:22 visual_prompt]: Epoch 64 / 100: avg data time: 5.65e-02, avg batch time: 0.4685, average train loss: 69.7905
[09/25 21:46:23 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 72.7479
[09/25 21:46:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 21:46:23 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 21:46:29 visual_prompt]: Epoch 65 / 100: avg data time: 6.02e-02, avg batch time: 0.4710, average train loss: 70.4916
[09/25 21:46:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1580, average loss: 87.2695
[09/25 21:46:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 21:46:31 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 21:46:37 visual_prompt]: Epoch 66 / 100: avg data time: 5.95e-02, avg batch time: 0.4703, average train loss: 61.7054
[09/25 21:46:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1578, average loss: 73.4023
[09/25 21:46:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 21:46:39 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 21:46:45 visual_prompt]: Epoch 67 / 100: avg data time: 5.73e-02, avg batch time: 0.4693, average train loss: 58.1647
[09/25 21:46:47 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1579, average loss: 55.8102
[09/25 21:46:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:46:47 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 21:46:53 visual_prompt]: Epoch 68 / 100: avg data time: 4.46e-02, avg batch time: 0.4557, average train loss: 51.0967
[09/25 21:46:54 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1583, average loss: 46.8383
[09/25 21:46:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:46:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 21:47:00 visual_prompt]: Epoch 69 / 100: avg data time: 5.39e-02, avg batch time: 0.4652, average train loss: 51.9333
[09/25 21:47:02 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1578, average loss: 58.9738
[09/25 21:47:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:47:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 21:47:08 visual_prompt]: Epoch 70 / 100: avg data time: 4.58e-02, avg batch time: 0.4567, average train loss: 68.7044
[09/25 21:47:09 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1579, average loss: 64.2128
[09/25 21:47:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 21:47:09 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 21:47:16 visual_prompt]: Epoch 71 / 100: avg data time: 4.61e-02, avg batch time: 0.4586, average train loss: 61.6550
[09/25 21:47:17 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1579, average loss: 52.3684
[09/25 21:47:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 21:47:17 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 21:47:23 visual_prompt]: Epoch 72 / 100: avg data time: 4.24e-02, avg batch time: 0.4569, average train loss: 46.9779
[09/25 21:47:25 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1581, average loss: 39.7277
[09/25 21:47:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 21:47:25 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 21:47:31 visual_prompt]: Epoch 73 / 100: avg data time: 5.64e-02, avg batch time: 0.4672, average train loss: 35.3856
[09/25 21:47:33 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1579, average loss: 38.1247
[09/25 21:47:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:47:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 21:47:39 visual_prompt]: Epoch 74 / 100: avg data time: 5.20e-02, avg batch time: 0.4630, average train loss: 32.4028
[09/25 21:47:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 31.7461
[09/25 21:47:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.00	
[09/25 21:47:40 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 21:47:47 visual_prompt]: Epoch 75 / 100: avg data time: 4.35e-02, avg batch time: 0.4561, average train loss: 28.6364
[09/25 21:47:48 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1579, average loss: 27.0214
[09/25 21:47:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.00	
[09/25 21:47:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 21:47:54 visual_prompt]: Epoch 76 / 100: avg data time: 5.70e-02, avg batch time: 0.4678, average train loss: 22.2177
[09/25 21:47:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1572, average loss: 23.8647
[09/25 21:47:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 21:47:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 21:48:02 visual_prompt]: Epoch 77 / 100: avg data time: 5.93e-02, avg batch time: 0.4717, average train loss: 19.5688
[09/25 21:48:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 22.2079
[09/25 21:48:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/25 21:48:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 21:48:10 visual_prompt]: Epoch 78 / 100: avg data time: 4.37e-02, avg batch time: 0.4577, average train loss: 16.8984
[09/25 21:48:11 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1584, average loss: 18.1655
[09/25 21:48:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:48:11 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 21:48:18 visual_prompt]: Epoch 79 / 100: avg data time: 4.61e-02, avg batch time: 0.4578, average train loss: 14.0783
[09/25 21:48:19 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1583, average loss: 13.2597
[09/25 21:48:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 21:48:19 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 21:48:25 visual_prompt]: Epoch 80 / 100: avg data time: 5.14e-02, avg batch time: 0.4627, average train loss: 11.1471
[09/25 21:48:27 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1580, average loss: 11.0293
[09/25 21:48:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:48:27 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 21:48:33 visual_prompt]: Epoch 81 / 100: avg data time: 5.40e-02, avg batch time: 0.4674, average train loss: 9.3160
[09/25 21:48:34 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1576, average loss: 10.5785
[09/25 21:48:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:48:34 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 21:48:41 visual_prompt]: Epoch 82 / 100: avg data time: 6.19e-02, avg batch time: 0.4737, average train loss: 9.3441
[09/25 21:48:42 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1575, average loss: 9.3134
[09/25 21:48:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 21:48:42 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 21:48:48 visual_prompt]: Epoch 83 / 100: avg data time: 4.56e-02, avg batch time: 0.4592, average train loss: 7.8927
[09/25 21:48:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1582, average loss: 8.0698
[09/25 21:48:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:48:50 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 21:48:56 visual_prompt]: Epoch 84 / 100: avg data time: 4.55e-02, avg batch time: 0.4575, average train loss: 6.7928
[09/25 21:48:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1575, average loss: 7.6299
[09/25 21:48:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 21:48:58 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 21:49:04 visual_prompt]: Epoch 85 / 100: avg data time: 4.41e-02, avg batch time: 0.4579, average train loss: 6.4858
[09/25 21:49:05 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1582, average loss: 7.5669
[09/25 21:49:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:49:05 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 21:49:12 visual_prompt]: Epoch 86 / 100: avg data time: 5.59e-02, avg batch time: 0.4680, average train loss: 6.2220
[09/25 21:49:13 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1583, average loss: 6.8306
[09/25 21:49:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:49:13 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 21:49:20 visual_prompt]: Epoch 87 / 100: avg data time: 6.09e-02, avg batch time: 0.4732, average train loss: 5.9734
[09/25 21:49:21 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1582, average loss: 6.9416
[09/25 21:49:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 21:49:21 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 21:49:27 visual_prompt]: Epoch 88 / 100: avg data time: 5.33e-02, avg batch time: 0.4643, average train loss: 5.9818
[09/25 21:49:29 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1583, average loss: 6.3288
[09/25 21:49:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 21:49:29 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 21:49:35 visual_prompt]: Epoch 89 / 100: avg data time: 5.23e-02, avg batch time: 0.4659, average train loss: 5.6638
[09/25 21:49:37 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1585, average loss: 5.9673
[09/25 21:49:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 21:49:37 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 21:49:43 visual_prompt]: Epoch 90 / 100: avg data time: 4.80e-02, avg batch time: 0.4617, average train loss: 5.4164
[09/25 21:49:44 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1584, average loss: 5.6324
[09/25 21:49:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 21:49:44 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 21:49:50 visual_prompt]: Epoch 91 / 100: avg data time: 4.73e-02, avg batch time: 0.4608, average train loss: 5.3265
[09/25 21:49:52 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1578, average loss: 5.3617
[09/25 21:49:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 21:49:52 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 21:49:58 visual_prompt]: Epoch 92 / 100: avg data time: 5.86e-02, avg batch time: 0.4708, average train loss: 5.2818
[09/25 21:50:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 5.2998
[09/25 21:50:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.00	
[09/25 21:50:00 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 21:50:06 visual_prompt]: Epoch 93 / 100: avg data time: 5.70e-02, avg batch time: 0.4690, average train loss: 5.1888
[09/25 21:50:08 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1577, average loss: 5.1840
[09/25 21:50:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:50:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 21:50:14 visual_prompt]: Epoch 94 / 100: avg data time: 5.51e-02, avg batch time: 0.4667, average train loss: 5.0104
[09/25 21:50:15 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1578, average loss: 5.1429
[09/25 21:50:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 21:50:15 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 21:50:22 visual_prompt]: Epoch 95 / 100: avg data time: 4.98e-02, avg batch time: 0.4637, average train loss: 4.8389
[09/25 21:50:23 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1584, average loss: 4.6364
[09/25 21:50:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.50	
[09/25 21:50:23 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 21:50:29 visual_prompt]: Epoch 96 / 100: avg data time: 4.74e-02, avg batch time: 0.4603, average train loss: 4.6333
[09/25 21:50:31 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1581, average loss: 4.6096
[09/25 21:50:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 11.00	
[09/25 21:50:31 visual_prompt]: Best epoch 96: best metric: 0.035
[09/25 21:50:31 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 21:50:37 visual_prompt]: Epoch 97 / 100: avg data time: 5.52e-02, avg batch time: 0.4677, average train loss: 4.4992
[09/25 21:50:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1579, average loss: 4.6228
[09/25 21:50:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/25 21:50:38 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 21:50:45 visual_prompt]: Epoch 98 / 100: avg data time: 5.61e-02, avg batch time: 0.4701, average train loss: 4.3342
[09/25 21:50:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 4.4914
[09/25 21:50:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 14.00	
[09/25 21:50:46 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 21:50:53 visual_prompt]: Epoch 99 / 100: avg data time: 5.94e-02, avg batch time: 0.4722, average train loss: 4.1812
[09/25 21:50:54 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1575, average loss: 4.3508
[09/25 21:50:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 16.00	
[09/25 21:50:54 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 21:51:01 visual_prompt]: Epoch 100 / 100: avg data time: 5.58e-02, avg batch time: 0.4694, average train loss: 4.0948
[09/25 21:51:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1584, average loss: 4.3594
[09/25 21:51:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 17.00	
[09/25 21:51:02 visual_prompt]: Best epoch 100: best metric: 0.040
[09/25 21:51:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 21:51:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 21:51:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 21:51:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 21:51:02 visual_prompt]: Training with config:
[09/25 21:51:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 21:51:02 visual_prompt]: Loading training data...
[09/25 21:51:02 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 21:51:03 visual_prompt]: Number of images: 800
[09/25 21:51:03 visual_prompt]: Number of classes: 102 / 102
[09/25 21:51:03 visual_prompt]: Loading validation data...
[09/25 21:51:03 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 21:51:04 visual_prompt]: Number of images: 200
[09/25 21:51:04 visual_prompt]: Number of classes: 91 / 102
[09/25 21:51:04 visual_prompt]: Constructing models...
[09/25 21:51:06 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 21:51:06 visual_prompt]: tuned percent:0.625
[09/25 21:51:06 visual_prompt]: Device used for model: 0
[09/25 21:51:06 visual_prompt]: Setting up Evaluator...
[09/25 21:51:06 visual_prompt]: Setting up Trainer...
[09/25 21:51:06 visual_prompt]: 	Setting up the optimizer...
[09/25 21:51:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 21:51:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.70e-02, avg batch time: 0.4739, average train loss: 4.6686
[09/25 21:51:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1579, average loss: 4.6780
[09/25 21:51:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:51:14 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 21:51:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 21:51:21 visual_prompt]: Epoch 2 / 100: avg data time: 5.77e-02, avg batch time: 0.4710, average train loss: 5.1761
[09/25 21:51:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 5.0716
[09/25 21:51:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:51:22 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 21:51:29 visual_prompt]: Epoch 3 / 100: avg data time: 5.75e-02, avg batch time: 0.4699, average train loss: 5.6288
[09/25 21:51:30 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1577, average loss: 6.1145
[09/25 21:51:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.50	
[09/25 21:51:30 visual_prompt]: Best epoch 3: best metric: 0.020
[09/25 21:51:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 21:51:36 visual_prompt]: Epoch 4 / 100: avg data time: 5.46e-02, avg batch time: 0.4690, average train loss: 6.8048
[09/25 21:51:38 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1582, average loss: 7.4773
[09/25 21:51:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.50	
[09/25 21:51:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 21:51:45 visual_prompt]: Epoch 5 / 100: avg data time: 5.89e-02, avg batch time: 0.4715, average train loss: 9.7973
[09/25 21:51:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 11.9543
[09/25 21:51:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 6.00	
[09/25 21:51:46 visual_prompt]: Best epoch 5: best metric: 0.035
[09/25 21:51:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 21:51:52 visual_prompt]: Epoch 6 / 100: avg data time: 4.69e-02, avg batch time: 0.4612, average train loss: 22.8739
[09/25 21:51:54 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1584, average loss: 32.7193
[09/25 21:51:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/25 21:51:54 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 21:52:00 visual_prompt]: Epoch 7 / 100: avg data time: 5.43e-02, avg batch time: 0.4685, average train loss: 48.6704
[09/25 21:52:02 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1586, average loss: 45.6692
[09/25 21:52:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:52:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 21:52:08 visual_prompt]: Epoch 8 / 100: avg data time: 5.64e-02, avg batch time: 0.4699, average train loss: 95.8389
[09/25 21:52:10 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1584, average loss: 90.4550
[09/25 21:52:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 21:52:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 21:52:16 visual_prompt]: Epoch 9 / 100: avg data time: 5.82e-02, avg batch time: 0.4713, average train loss: 110.1609
[09/25 21:52:18 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1585, average loss: 108.9315
[09/25 21:52:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:52:18 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 21:52:24 visual_prompt]: Epoch 10 / 100: avg data time: 6.27e-02, avg batch time: 0.4773, average train loss: 132.1613
[09/25 21:52:26 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1585, average loss: 142.4962
[09/25 21:52:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 21:52:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 21:52:32 visual_prompt]: Epoch 11 / 100: avg data time: 5.18e-02, avg batch time: 0.4658, average train loss: 156.1042
[09/25 21:52:34 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1584, average loss: 262.3374
[09/25 21:52:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 21:52:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 21:52:40 visual_prompt]: Epoch 12 / 100: avg data time: 5.74e-02, avg batch time: 0.4714, average train loss: 293.1591
[09/25 21:52:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1586, average loss: 262.2113
[09/25 21:52:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 21:52:42 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 21:52:48 visual_prompt]: Epoch 13 / 100: avg data time: 6.08e-02, avg batch time: 0.4743, average train loss: 377.0550
[09/25 21:52:50 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1581, average loss: 266.0157
[09/25 21:52:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:52:50 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 21:52:56 visual_prompt]: Epoch 14 / 100: avg data time: 5.38e-02, avg batch time: 0.4686, average train loss: 248.3328
[09/25 21:52:58 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1588, average loss: 229.9022
[09/25 21:52:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:52:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 21:53:04 visual_prompt]: Epoch 15 / 100: avg data time: 5.25e-02, avg batch time: 0.4666, average train loss: 279.9287
[09/25 21:53:06 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1588, average loss: 310.4522
[09/25 21:53:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:53:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 21:53:12 visual_prompt]: Epoch 16 / 100: avg data time: 5.18e-02, avg batch time: 0.4660, average train loss: 290.3757
[09/25 21:53:14 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1587, average loss: 253.5216
[09/25 21:53:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:53:14 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 21:53:20 visual_prompt]: Epoch 17 / 100: avg data time: 4.40e-02, avg batch time: 0.4596, average train loss: 301.4881
[09/25 21:53:21 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1584, average loss: 277.8725
[09/25 21:53:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:53:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 21:53:28 visual_prompt]: Epoch 18 / 100: avg data time: 5.67e-02, avg batch time: 0.4712, average train loss: 279.3470
[09/25 21:53:29 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 281.6789
[09/25 21:53:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.50	
[09/25 21:53:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 21:53:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.86e-02, avg batch time: 0.4714, average train loss: 280.2616
[09/25 21:53:37 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1584, average loss: 302.7162
[09/25 21:53:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:53:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 21:53:44 visual_prompt]: Epoch 20 / 100: avg data time: 5.60e-02, avg batch time: 0.4695, average train loss: 273.9910
[09/25 21:53:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1588, average loss: 298.8483
[09/25 21:53:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:53:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 21:53:52 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e-02, avg batch time: 0.4707, average train loss: 297.4340
[09/25 21:53:53 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1582, average loss: 254.7148
[09/25 21:53:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:53:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 21:54:00 visual_prompt]: Epoch 22 / 100: avg data time: 4.82e-02, avg batch time: 0.4616, average train loss: 239.9514
[09/25 21:54:01 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1580, average loss: 282.3016
[09/25 21:54:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 21:54:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 21:54:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.18e-02, avg batch time: 0.4660, average train loss: 328.9808
[09/25 21:54:09 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1580, average loss: 308.2248
[09/25 21:54:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:54:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 21:54:15 visual_prompt]: Epoch 24 / 100: avg data time: 5.39e-02, avg batch time: 0.4680, average train loss: 379.2993
[09/25 21:54:17 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1583, average loss: 404.8799
[09/25 21:54:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 21:54:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 21:54:23 visual_prompt]: Epoch 25 / 100: avg data time: 5.14e-02, avg batch time: 0.4653, average train loss: 455.2292
[09/25 21:54:25 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1587, average loss: 405.1552
[09/25 21:54:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 21:54:25 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 21:54:31 visual_prompt]: Epoch 26 / 100: avg data time: 5.55e-02, avg batch time: 0.4687, average train loss: 384.9828
[09/25 21:54:33 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1577, average loss: 355.3075
[09/25 21:54:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 6.50	
[09/25 21:54:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 21:54:39 visual_prompt]: Epoch 27 / 100: avg data time: 4.68e-02, avg batch time: 0.4617, average train loss: 365.3201
[09/25 21:54:41 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1584, average loss: 319.0510
[09/25 21:54:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.00	
[09/25 21:54:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 21:54:47 visual_prompt]: Epoch 28 / 100: avg data time: 5.66e-02, avg batch time: 0.4694, average train loss: 352.0037
[09/25 21:54:49 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1585, average loss: 340.5301
[09/25 21:54:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 21:54:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 21:54:55 visual_prompt]: Epoch 29 / 100: avg data time: 5.89e-02, avg batch time: 0.4719, average train loss: 265.3600
[09/25 21:54:57 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1581, average loss: 186.1016
[09/25 21:54:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 21:54:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 21:55:03 visual_prompt]: Epoch 30 / 100: avg data time: 4.86e-02, avg batch time: 0.4637, average train loss: 209.8432
[09/25 21:55:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1584, average loss: 261.8670
[09/25 21:55:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 21:55:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 21:55:11 visual_prompt]: Epoch 31 / 100: avg data time: 5.38e-02, avg batch time: 0.4674, average train loss: 271.3216
[09/25 21:55:12 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1583, average loss: 261.6142
[09/25 21:55:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 21:55:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 21:55:19 visual_prompt]: Epoch 32 / 100: avg data time: 5.53e-02, avg batch time: 0.4682, average train loss: 304.5026
[09/25 21:55:20 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1584, average loss: 300.3414
[09/25 21:55:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 21:55:20 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 21:55:27 visual_prompt]: Epoch 33 / 100: avg data time: 4.55e-02, avg batch time: 0.4581, average train loss: 281.3354
[09/25 21:55:28 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1577, average loss: 296.6799
[09/25 21:55:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:55:28 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 21:55:34 visual_prompt]: Epoch 34 / 100: avg data time: 5.15e-02, avg batch time: 0.4651, average train loss: 272.6128
[09/25 21:55:36 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1578, average loss: 228.4461
[09/25 21:55:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 21:55:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 21:55:42 visual_prompt]: Epoch 35 / 100: avg data time: 6.20e-02, avg batch time: 0.4737, average train loss: 213.5922
[09/25 21:55:44 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1587, average loss: 280.8658
[09/25 21:55:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/25 21:55:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 21:55:50 visual_prompt]: Epoch 36 / 100: avg data time: 5.41e-02, avg batch time: 0.4665, average train loss: 270.9323
[09/25 21:55:52 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1587, average loss: 302.1024
[09/25 21:55:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:55:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 21:55:58 visual_prompt]: Epoch 37 / 100: avg data time: 6.63e-02, avg batch time: 0.4792, average train loss: 237.5382
[09/25 21:56:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 206.7502
[09/25 21:56:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 6.00	
[09/25 21:56:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 21:56:06 visual_prompt]: Epoch 38 / 100: avg data time: 5.89e-02, avg batch time: 0.4719, average train loss: 218.1178
[09/25 21:56:08 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1585, average loss: 208.7786
[09/25 21:56:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 21:56:08 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 21:56:14 visual_prompt]: Epoch 39 / 100: avg data time: 5.77e-02, avg batch time: 0.4707, average train loss: 229.4961
[09/25 21:56:16 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1581, average loss: 251.8221
[09/25 21:56:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:56:16 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 21:56:22 visual_prompt]: Epoch 40 / 100: avg data time: 5.89e-02, avg batch time: 0.4716, average train loss: 234.0175
[09/25 21:56:24 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1582, average loss: 216.8957
[09/25 21:56:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 1.50	
[09/25 21:56:24 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 21:56:30 visual_prompt]: Epoch 41 / 100: avg data time: 5.83e-02, avg batch time: 0.4698, average train loss: 194.8448
[09/25 21:56:32 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1581, average loss: 210.3829
[09/25 21:56:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 21:56:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 21:56:38 visual_prompt]: Epoch 42 / 100: avg data time: 5.77e-02, avg batch time: 0.4704, average train loss: 214.0665
[09/25 21:56:40 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1586, average loss: 267.2016
[09/25 21:56:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 21:56:40 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 21:56:46 visual_prompt]: Epoch 43 / 100: avg data time: 6.54e-02, avg batch time: 0.4770, average train loss: 223.4523
[09/25 21:56:48 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1581, average loss: 169.4115
[09/25 21:56:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 21:56:48 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 21:56:54 visual_prompt]: Epoch 44 / 100: avg data time: 5.60e-02, avg batch time: 0.4682, average train loss: 178.7056
[09/25 21:56:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 167.3882
[09/25 21:56:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/25 21:56:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 21:57:02 visual_prompt]: Epoch 45 / 100: avg data time: 6.45e-02, avg batch time: 0.4759, average train loss: 183.1259
[09/25 21:57:04 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 181.0846
[09/25 21:57:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:57:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 21:57:10 visual_prompt]: Epoch 46 / 100: avg data time: 5.50e-02, avg batch time: 0.4668, average train loss: 188.2153
[09/25 21:57:12 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 182.6654
[09/25 21:57:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/25 21:57:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 21:57:18 visual_prompt]: Epoch 47 / 100: avg data time: 5.59e-02, avg batch time: 0.4699, average train loss: 172.6849
[09/25 21:57:20 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1584, average loss: 156.1107
[09/25 21:57:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 21:57:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 21:57:26 visual_prompt]: Epoch 48 / 100: avg data time: 4.56e-02, avg batch time: 0.4586, average train loss: 136.0941
[09/25 21:57:28 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1581, average loss: 149.5013
[09/25 21:57:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:57:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 21:57:34 visual_prompt]: Epoch 49 / 100: avg data time: 6.16e-02, avg batch time: 0.4739, average train loss: 127.7816
[09/25 21:57:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1576, average loss: 119.6001
[09/25 21:57:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:57:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 21:57:42 visual_prompt]: Epoch 50 / 100: avg data time: 5.37e-02, avg batch time: 0.4662, average train loss: 138.9804
[09/25 21:57:43 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1583, average loss: 147.7683
[09/25 21:57:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 21:57:43 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 21:57:50 visual_prompt]: Epoch 51 / 100: avg data time: 4.93e-02, avg batch time: 0.4624, average train loss: 142.3976
[09/25 21:57:51 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1582, average loss: 143.5971
[09/25 21:57:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 21:57:51 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 21:57:58 visual_prompt]: Epoch 52 / 100: avg data time: 5.82e-02, avg batch time: 0.4715, average train loss: 118.9144
[09/25 21:57:59 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1586, average loss: 119.1363
[09/25 21:57:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 21:57:59 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 21:58:06 visual_prompt]: Epoch 53 / 100: avg data time: 5.88e-02, avg batch time: 0.4709, average train loss: 146.0422
[09/25 21:58:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1580, average loss: 132.1137
[09/25 21:58:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:58:07 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 21:58:14 visual_prompt]: Epoch 54 / 100: avg data time: 5.66e-02, avg batch time: 0.4695, average train loss: 123.2613
[09/25 21:58:15 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1584, average loss: 123.6273
[09/25 21:58:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 21:58:15 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 21:58:22 visual_prompt]: Epoch 55 / 100: avg data time: 5.04e-02, avg batch time: 0.4623, average train loss: 117.2638
[09/25 21:58:23 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1582, average loss: 100.6710
[09/25 21:58:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 21:58:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 21:58:30 visual_prompt]: Epoch 56 / 100: avg data time: 5.24e-02, avg batch time: 0.4650, average train loss: 106.8408
[09/25 21:58:31 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 100.7340
[09/25 21:58:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 21:58:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 21:58:38 visual_prompt]: Epoch 57 / 100: avg data time: 6.14e-02, avg batch time: 0.4733, average train loss: 102.3419
[09/25 21:58:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 100.4846
[09/25 21:58:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:58:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 21:58:46 visual_prompt]: Epoch 58 / 100: avg data time: 5.94e-02, avg batch time: 0.4713, average train loss: 113.0236
[09/25 21:58:47 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1579, average loss: 136.4790
[09/25 21:58:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 21:58:47 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 21:58:53 visual_prompt]: Epoch 59 / 100: avg data time: 4.70e-02, avg batch time: 0.4613, average train loss: 128.6555
[09/25 21:58:55 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1578, average loss: 112.1837
[09/25 21:58:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 21:58:55 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 21:59:01 visual_prompt]: Epoch 60 / 100: avg data time: 5.24e-02, avg batch time: 0.4657, average train loss: 107.9931
[09/25 21:59:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1579, average loss: 93.8399
[09/25 21:59:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/25 21:59:03 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 21:59:09 visual_prompt]: Epoch 61 / 100: avg data time: 4.96e-02, avg batch time: 0.4619, average train loss: 92.4643
[09/25 21:59:10 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1583, average loss: 110.0959
[09/25 21:59:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:59:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 21:59:17 visual_prompt]: Epoch 62 / 100: avg data time: 5.54e-02, avg batch time: 0.4692, average train loss: 107.4921
[09/25 21:59:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1581, average loss: 95.6599
[09/25 21:59:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.50	
[09/25 21:59:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 21:59:25 visual_prompt]: Epoch 63 / 100: avg data time: 6.38e-02, avg batch time: 0.4760, average train loss: 98.1647
[09/25 21:59:26 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1583, average loss: 107.1387
[09/25 21:59:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.50	
[09/25 21:59:26 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 21:59:33 visual_prompt]: Epoch 64 / 100: avg data time: 5.32e-02, avg batch time: 0.4663, average train loss: 94.8758
[09/25 21:59:34 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1582, average loss: 86.6265
[09/25 21:59:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 21:59:34 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 21:59:41 visual_prompt]: Epoch 65 / 100: avg data time: 4.56e-02, avg batch time: 0.4599, average train loss: 81.1957
[09/25 21:59:42 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1579, average loss: 65.7116
[09/25 21:59:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.00	
[09/25 21:59:42 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 21:59:49 visual_prompt]: Epoch 66 / 100: avg data time: 5.42e-02, avg batch time: 0.4682, average train loss: 73.2711
[09/25 21:59:50 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1582, average loss: 77.1310
[09/25 21:59:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 21:59:50 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 21:59:57 visual_prompt]: Epoch 67 / 100: avg data time: 4.86e-02, avg batch time: 0.4620, average train loss: 74.1566
[09/25 21:59:58 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1581, average loss: 64.5628
[09/25 21:59:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 21:59:58 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 22:00:05 visual_prompt]: Epoch 68 / 100: avg data time: 6.12e-02, avg batch time: 0.4739, average train loss: 71.3674
[09/25 22:00:06 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1580, average loss: 50.2263
[09/25 22:00:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:00:06 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 22:00:13 visual_prompt]: Epoch 69 / 100: avg data time: 5.50e-02, avg batch time: 0.4707, average train loss: 52.8837
[09/25 22:00:14 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1583, average loss: 47.9463
[09/25 22:00:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 8.00	
[09/25 22:00:14 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 22:00:20 visual_prompt]: Epoch 70 / 100: avg data time: 4.91e-02, avg batch time: 0.4630, average train loss: 45.0978
[09/25 22:00:22 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1583, average loss: 44.3013
[09/25 22:00:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:00:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 22:00:28 visual_prompt]: Epoch 71 / 100: avg data time: 5.50e-02, avg batch time: 0.4676, average train loss: 32.2521
[09/25 22:00:30 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1581, average loss: 25.4327
[09/25 22:00:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:00:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 22:00:36 visual_prompt]: Epoch 72 / 100: avg data time: 6.17e-02, avg batch time: 0.4745, average train loss: 25.6278
[09/25 22:00:38 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1581, average loss: 18.3465
[09/25 22:00:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:00:38 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 22:00:44 visual_prompt]: Epoch 73 / 100: avg data time: 6.24e-02, avg batch time: 0.4748, average train loss: 21.2751
[09/25 22:00:46 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1584, average loss: 17.3886
[09/25 22:00:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:00:46 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 22:00:52 visual_prompt]: Epoch 74 / 100: avg data time: 5.37e-02, avg batch time: 0.4658, average train loss: 15.6284
[09/25 22:00:54 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1584, average loss: 12.8656
[09/25 22:00:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:00:54 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 22:01:00 visual_prompt]: Epoch 75 / 100: avg data time: 5.94e-02, avg batch time: 0.4712, average train loss: 12.6754
[09/25 22:01:02 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1578, average loss: 11.8755
[09/25 22:01:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:01:02 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 22:01:08 visual_prompt]: Epoch 76 / 100: avg data time: 4.83e-02, avg batch time: 0.4627, average train loss: 10.5698
[09/25 22:01:10 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1577, average loss: 10.4253
[09/25 22:01:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:01:10 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 22:01:16 visual_prompt]: Epoch 77 / 100: avg data time: 5.82e-02, avg batch time: 0.4724, average train loss: 8.0917
[09/25 22:01:18 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1580, average loss: 7.2770
[09/25 22:01:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:01:18 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 22:01:24 visual_prompt]: Epoch 78 / 100: avg data time: 5.65e-02, avg batch time: 0.4703, average train loss: 6.2075
[09/25 22:01:26 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1578, average loss: 6.5824
[09/25 22:01:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/25 22:01:26 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 22:01:32 visual_prompt]: Epoch 79 / 100: avg data time: 6.26e-02, avg batch time: 0.4749, average train loss: 5.5445
[09/25 22:01:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 5.1243
[09/25 22:01:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 10.50	
[09/25 22:01:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 22:01:40 visual_prompt]: Epoch 80 / 100: avg data time: 5.39e-02, avg batch time: 0.4666, average train loss: 5.0156
[09/25 22:01:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 5.2481
[09/25 22:01:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 13.50	
[09/25 22:01:41 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 22:01:48 visual_prompt]: Epoch 81 / 100: avg data time: 4.81e-02, avg batch time: 0.4605, average train loss: 4.9111
[09/25 22:01:49 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1578, average loss: 4.8791
[09/25 22:01:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 12.00	
[09/25 22:01:49 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 22:01:56 visual_prompt]: Epoch 82 / 100: avg data time: 5.93e-02, avg batch time: 0.4722, average train loss: 4.7463
[09/25 22:01:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1581, average loss: 4.7318
[09/25 22:01:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 14.00	
[09/25 22:01:57 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 22:02:04 visual_prompt]: Epoch 83 / 100: avg data time: 5.81e-02, avg batch time: 0.4702, average train loss: 4.5895
[09/25 22:02:05 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1582, average loss: 4.7263
[09/25 22:02:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 14.00	
[09/25 22:02:05 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 22:02:12 visual_prompt]: Epoch 84 / 100: avg data time: 6.06e-02, avg batch time: 0.4728, average train loss: 4.4658
[09/25 22:02:13 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1580, average loss: 4.5597
[09/25 22:02:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 14.00	
[09/25 22:02:13 visual_prompt]: Best epoch 84: best metric: 0.045
[09/25 22:02:13 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 22:02:20 visual_prompt]: Epoch 85 / 100: avg data time: 5.55e-02, avg batch time: 0.4689, average train loss: 4.2915
[09/25 22:02:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 4.4724
[09/25 22:02:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 18.00	
[09/25 22:02:21 visual_prompt]: Best epoch 85: best metric: 0.080
[09/25 22:02:21 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 22:02:28 visual_prompt]: Epoch 86 / 100: avg data time: 6.57e-02, avg batch time: 0.4787, average train loss: 4.1176
[09/25 22:02:29 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1582, average loss: 4.4422
[09/25 22:02:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.00	top5: 18.50	
[09/25 22:02:29 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 22:02:36 visual_prompt]: Epoch 87 / 100: avg data time: 4.93e-02, avg batch time: 0.4625, average train loss: 3.9400
[09/25 22:02:37 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1578, average loss: 4.2565
[09/25 22:02:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.00	top5: 21.50	
[09/25 22:02:37 visual_prompt]: Best epoch 87: best metric: 0.100
[09/25 22:02:37 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 22:02:43 visual_prompt]: Epoch 88 / 100: avg data time: 5.20e-02, avg batch time: 0.4643, average train loss: 3.8485
[09/25 22:02:45 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1578, average loss: 4.3988
[09/25 22:02:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 20.00	
[09/25 22:02:45 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 22:02:51 visual_prompt]: Epoch 89 / 100: avg data time: 5.99e-02, avg batch time: 0.4728, average train loss: 3.7497
[09/25 22:02:53 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1582, average loss: 4.0434
[09/25 22:02:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 13.00	top5: 29.50	
[09/25 22:02:53 visual_prompt]: Best epoch 89: best metric: 0.130
[09/25 22:02:53 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 22:02:59 visual_prompt]: Epoch 90 / 100: avg data time: 6.02e-02, avg batch time: 0.4732, average train loss: 3.4908
[09/25 22:03:01 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1581, average loss: 4.1277
[09/25 22:03:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.50	top5: 28.00	
[09/25 22:03:01 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 22:03:07 visual_prompt]: Epoch 91 / 100: avg data time: 5.92e-02, avg batch time: 0.4727, average train loss: 3.2821
[09/25 22:03:09 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 3.8848
[09/25 22:03:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 15.00	top5: 28.50	
[09/25 22:03:09 visual_prompt]: Best epoch 91: best metric: 0.150
[09/25 22:03:09 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 22:03:15 visual_prompt]: Epoch 92 / 100: avg data time: 6.19e-02, avg batch time: 0.4758, average train loss: 3.2010
[09/25 22:03:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 3.8895
[09/25 22:03:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 14.00	top5: 37.00	
[09/25 22:03:17 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 22:03:23 visual_prompt]: Epoch 93 / 100: avg data time: 5.90e-02, avg batch time: 0.4710, average train loss: 2.8874
[09/25 22:03:25 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1580, average loss: 3.9392
[09/25 22:03:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 16.00	top5: 34.00	
[09/25 22:03:25 visual_prompt]: Best epoch 93: best metric: 0.160
[09/25 22:03:25 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 22:03:31 visual_prompt]: Epoch 94 / 100: avg data time: 5.36e-02, avg batch time: 0.4681, average train loss: 2.5834
[09/25 22:03:33 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 3.7868
[09/25 22:03:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 18.00	top5: 38.50	
[09/25 22:03:33 visual_prompt]: Best epoch 94: best metric: 0.180
[09/25 22:03:33 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 22:03:39 visual_prompt]: Epoch 95 / 100: avg data time: 5.91e-02, avg batch time: 0.4722, average train loss: 2.3178
[09/25 22:03:41 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1577, average loss: 3.7529
[09/25 22:03:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 22.50	top5: 46.00	
[09/25 22:03:41 visual_prompt]: Best epoch 95: best metric: 0.225
[09/25 22:03:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 22:03:47 visual_prompt]: Epoch 96 / 100: avg data time: 5.91e-02, avg batch time: 0.4718, average train loss: 1.9004
[09/25 22:03:49 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1586, average loss: 3.9768
[09/25 22:03:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 23.50	top5: 43.00	
[09/25 22:03:49 visual_prompt]: Best epoch 96: best metric: 0.235
[09/25 22:03:49 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 22:03:55 visual_prompt]: Epoch 97 / 100: avg data time: 6.26e-02, avg batch time: 0.4753, average train loss: 1.6573
[09/25 22:03:57 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1584, average loss: 3.7747
[09/25 22:03:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 26.00	top5: 45.50	
[09/25 22:03:57 visual_prompt]: Best epoch 97: best metric: 0.260
[09/25 22:03:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 22:04:03 visual_prompt]: Epoch 98 / 100: avg data time: 6.29e-02, avg batch time: 0.4768, average train loss: 1.4291
[09/25 22:04:05 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1582, average loss: 3.8508
[09/25 22:04:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 26.50	top5: 47.50	
[09/25 22:04:05 visual_prompt]: Best epoch 98: best metric: 0.265
[09/25 22:04:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 22:04:11 visual_prompt]: Epoch 99 / 100: avg data time: 5.29e-02, avg batch time: 0.4662, average train loss: 1.2372
[09/25 22:04:13 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1590, average loss: 3.6418
[09/25 22:04:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 29.00	top5: 50.50	
[09/25 22:04:13 visual_prompt]: Best epoch 99: best metric: 0.290
[09/25 22:04:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 22:04:19 visual_prompt]: Epoch 100 / 100: avg data time: 5.47e-02, avg batch time: 0.4678, average train loss: 1.1543
[09/25 22:04:20 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 3.8378
[09/25 22:04:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 27.50	top5: 48.50	
[09/25 22:04:21 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:04:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:04:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:04:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:04:21 visual_prompt]: Training with config:
[09/25 22:04:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:04:21 visual_prompt]: Loading training data...
[09/25 22:04:21 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:04:22 visual_prompt]: Number of images: 800
[09/25 22:04:22 visual_prompt]: Number of classes: 102 / 102
[09/25 22:04:22 visual_prompt]: Loading validation data...
[09/25 22:04:22 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:04:22 visual_prompt]: Number of images: 200
[09/25 22:04:22 visual_prompt]: Number of classes: 91 / 102
[09/25 22:04:22 visual_prompt]: Constructing models...
[09/25 22:04:24 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 22:04:24 visual_prompt]: tuned percent:0.625
[09/25 22:04:24 visual_prompt]: Device used for model: 0
[09/25 22:04:24 visual_prompt]: Setting up Evaluator...
[09/25 22:04:24 visual_prompt]: Setting up Trainer...
[09/25 22:04:24 visual_prompt]: 	Setting up the optimizer...
[09/25 22:04:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:04:31 visual_prompt]: Epoch 1 / 100: avg data time: 6.18e-02, avg batch time: 0.4795, average train loss: 4.6690
[09/25 22:04:33 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1579, average loss: 4.6780
[09/25 22:04:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:04:33 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:04:33 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 22:04:39 visual_prompt]: Epoch 2 / 100: avg data time: 6.30e-02, avg batch time: 0.4755, average train loss: 5.0744
[09/25 22:04:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 5.2742
[09/25 22:04:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 22:04:41 visual_prompt]: Best epoch 2: best metric: 0.020
[09/25 22:04:41 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 22:04:47 visual_prompt]: Epoch 3 / 100: avg data time: 5.82e-02, avg batch time: 0.4695, average train loss: 9.0748
[09/25 22:04:49 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1583, average loss: 12.2084
[09/25 22:04:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:04:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 22:04:55 visual_prompt]: Epoch 4 / 100: avg data time: 5.75e-02, avg batch time: 0.4685, average train loss: 23.9360
[09/25 22:04:57 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1582, average loss: 30.4922
[09/25 22:04:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:04:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 22:05:03 visual_prompt]: Epoch 5 / 100: avg data time: 6.33e-02, avg batch time: 0.4747, average train loss: 50.3537
[09/25 22:05:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1580, average loss: 49.5918
[09/25 22:05:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:05:05 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 22:05:11 visual_prompt]: Epoch 6 / 100: avg data time: 4.93e-02, avg batch time: 0.4613, average train loss: 105.0408
[09/25 22:05:13 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1582, average loss: 108.3668
[09/25 22:05:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:05:13 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 22:05:19 visual_prompt]: Epoch 7 / 100: avg data time: 5.73e-02, avg batch time: 0.4703, average train loss: 99.1066
[09/25 22:05:20 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1575, average loss: 85.7533
[09/25 22:05:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:05:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 22:05:27 visual_prompt]: Epoch 8 / 100: avg data time: 5.43e-02, avg batch time: 0.4676, average train loss: 156.8493
[09/25 22:05:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1582, average loss: 171.0594
[09/25 22:05:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:05:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 22:05:35 visual_prompt]: Epoch 9 / 100: avg data time: 6.09e-02, avg batch time: 0.4728, average train loss: 229.0826
[09/25 22:05:36 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 432.8078
[09/25 22:05:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/25 22:05:36 visual_prompt]: Best epoch 9: best metric: 0.025
[09/25 22:05:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 22:05:43 visual_prompt]: Epoch 10 / 100: avg data time: 5.70e-02, avg batch time: 0.4687, average train loss: 303.7239
[09/25 22:05:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 265.4291
[09/25 22:05:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.00	
[09/25 22:05:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 22:05:51 visual_prompt]: Epoch 11 / 100: avg data time: 5.03e-02, avg batch time: 0.4641, average train loss: 372.3835
[09/25 22:05:52 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1574, average loss: 389.8879
[09/25 22:05:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:05:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 22:05:59 visual_prompt]: Epoch 12 / 100: avg data time: 6.19e-02, avg batch time: 0.4731, average train loss: 417.8529
[09/25 22:06:00 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1575, average loss: 427.2633
[09/25 22:06:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 22:06:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 22:06:07 visual_prompt]: Epoch 13 / 100: avg data time: 6.11e-02, avg batch time: 0.4735, average train loss: 470.1210
[09/25 22:06:08 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1575, average loss: 610.5320
[09/25 22:06:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:06:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 22:06:15 visual_prompt]: Epoch 14 / 100: avg data time: 5.53e-02, avg batch time: 0.4665, average train loss: 561.5266
[09/25 22:06:16 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1581, average loss: 529.7908
[09/25 22:06:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:06:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 22:06:23 visual_prompt]: Epoch 15 / 100: avg data time: 5.61e-02, avg batch time: 0.4674, average train loss: 602.3073
[09/25 22:06:24 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1579, average loss: 638.3694
[09/25 22:06:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.50	
[09/25 22:06:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 22:06:31 visual_prompt]: Epoch 16 / 100: avg data time: 5.85e-02, avg batch time: 0.4708, average train loss: 666.2937
[09/25 22:06:32 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1582, average loss: 636.4093
[09/25 22:06:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:06:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 22:06:39 visual_prompt]: Epoch 17 / 100: avg data time: 4.86e-02, avg batch time: 0.4614, average train loss: 572.0218
[09/25 22:06:40 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 417.8805
[09/25 22:06:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:06:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 22:06:47 visual_prompt]: Epoch 18 / 100: avg data time: 6.24e-02, avg batch time: 0.4739, average train loss: 435.7114
[09/25 22:06:48 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1584, average loss: 396.7482
[09/25 22:06:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 22:06:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 22:06:55 visual_prompt]: Epoch 19 / 100: avg data time: 5.82e-02, avg batch time: 0.4710, average train loss: 436.2842
[09/25 22:06:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1579, average loss: 405.6975
[09/25 22:06:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 22:06:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 22:07:03 visual_prompt]: Epoch 20 / 100: avg data time: 5.70e-02, avg batch time: 0.4693, average train loss: 396.0159
[09/25 22:07:04 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1588, average loss: 332.7810
[09/25 22:07:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.00	
[09/25 22:07:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 22:07:11 visual_prompt]: Epoch 21 / 100: avg data time: 5.90e-02, avg batch time: 0.4707, average train loss: 335.0064
[09/25 22:07:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 301.5288
[09/25 22:07:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:07:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 22:07:19 visual_prompt]: Epoch 22 / 100: avg data time: 6.25e-02, avg batch time: 0.4741, average train loss: 278.9776
[09/25 22:07:20 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1581, average loss: 268.8053
[09/25 22:07:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:07:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 22:07:27 visual_prompt]: Epoch 23 / 100: avg data time: 5.96e-02, avg batch time: 0.4714, average train loss: 265.3991
[09/25 22:07:28 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1584, average loss: 227.3427
[09/25 22:07:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 22:07:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 22:07:35 visual_prompt]: Epoch 24 / 100: avg data time: 6.19e-02, avg batch time: 0.4755, average train loss: 243.1877
[09/25 22:07:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1579, average loss: 221.5650
[09/25 22:07:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:07:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 22:07:43 visual_prompt]: Epoch 25 / 100: avg data time: 5.50e-02, avg batch time: 0.4677, average train loss: 225.3945
[09/25 22:07:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1578, average loss: 212.7017
[09/25 22:07:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.00	
[09/25 22:07:44 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 22:07:51 visual_prompt]: Epoch 26 / 100: avg data time: 5.77e-02, avg batch time: 0.4709, average train loss: 203.5111
[09/25 22:07:52 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 187.8595
[09/25 22:07:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 7.00	
[09/25 22:07:52 visual_prompt]: Best epoch 26: best metric: 0.040
[09/25 22:07:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 22:07:59 visual_prompt]: Epoch 27 / 100: avg data time: 6.30e-02, avg batch time: 0.4748, average train loss: 201.9389
[09/25 22:08:00 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1583, average loss: 194.0247
[09/25 22:08:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 5.00	
[09/25 22:08:00 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 22:08:07 visual_prompt]: Epoch 28 / 100: avg data time: 5.35e-02, avg batch time: 0.4664, average train loss: 190.6164
[09/25 22:08:08 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1581, average loss: 168.9427
[09/25 22:08:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:08:08 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 22:08:15 visual_prompt]: Epoch 29 / 100: avg data time: 5.13e-02, avg batch time: 0.4654, average train loss: 172.7360
[09/25 22:08:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 155.7114
[09/25 22:08:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:08:16 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 22:08:23 visual_prompt]: Epoch 30 / 100: avg data time: 5.75e-02, avg batch time: 0.4693, average train loss: 174.9859
[09/25 22:08:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1582, average loss: 153.3551
[09/25 22:08:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 9.00	
[09/25 22:08:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 22:08:31 visual_prompt]: Epoch 31 / 100: avg data time: 5.84e-02, avg batch time: 0.4707, average train loss: 155.3489
[09/25 22:08:32 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1579, average loss: 133.9719
[09/25 22:08:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 8.50	
[09/25 22:08:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 22:08:39 visual_prompt]: Epoch 32 / 100: avg data time: 5.78e-02, avg batch time: 0.4699, average train loss: 136.8480
[09/25 22:08:40 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1580, average loss: 107.7589
[09/25 22:08:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:08:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 22:08:47 visual_prompt]: Epoch 33 / 100: avg data time: 5.79e-02, avg batch time: 0.4713, average train loss: 108.3489
[09/25 22:08:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1584, average loss: 76.2211
[09/25 22:08:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.00	
[09/25 22:08:48 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 22:08:55 visual_prompt]: Epoch 34 / 100: avg data time: 6.14e-02, avg batch time: 0.4738, average train loss: 78.6777
[09/25 22:08:56 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1580, average loss: 75.2355
[09/25 22:08:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 9.50	
[09/25 22:08:56 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 22:09:02 visual_prompt]: Epoch 35 / 100: avg data time: 4.40e-02, avg batch time: 0.4591, average train loss: 76.5020
[09/25 22:09:04 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1577, average loss: 75.2420
[09/25 22:09:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 22:09:04 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 22:09:11 visual_prompt]: Epoch 36 / 100: avg data time: 6.25e-02, avg batch time: 0.4746, average train loss: 81.8545
[09/25 22:09:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 68.9794
[09/25 22:09:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 11.50	
[09/25 22:09:12 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 22:09:19 visual_prompt]: Epoch 37 / 100: avg data time: 6.29e-02, avg batch time: 0.4754, average train loss: 75.4147
[09/25 22:09:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 63.5823
[09/25 22:09:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.00	
[09/25 22:09:20 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 22:09:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.43e-02, avg batch time: 0.4690, average train loss: 63.0252
[09/25 22:09:28 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1582, average loss: 57.3011
[09/25 22:09:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/25 22:09:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 22:09:34 visual_prompt]: Epoch 39 / 100: avg data time: 6.21e-02, avg batch time: 0.4744, average train loss: 65.1195
[09/25 22:09:36 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1581, average loss: 58.5160
[09/25 22:09:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:09:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 22:09:42 visual_prompt]: Epoch 40 / 100: avg data time: 5.76e-02, avg batch time: 0.4706, average train loss: 61.9158
[09/25 22:09:44 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1584, average loss: 61.5835
[09/25 22:09:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:09:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 22:09:50 visual_prompt]: Epoch 41 / 100: avg data time: 6.49e-02, avg batch time: 0.4770, average train loss: 60.2366
[09/25 22:09:52 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1583, average loss: 53.4044
[09/25 22:09:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 10.50	
[09/25 22:09:52 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 22:09:59 visual_prompt]: Epoch 42 / 100: avg data time: 6.10e-02, avg batch time: 0.4730, average train loss: 53.6283
[09/25 22:10:00 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1581, average loss: 48.8404
[09/25 22:10:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 22:10:00 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 22:10:06 visual_prompt]: Epoch 43 / 100: avg data time: 5.19e-02, avg batch time: 0.4644, average train loss: 49.3164
[09/25 22:10:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 51.5806
[09/25 22:10:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:10:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 22:10:14 visual_prompt]: Epoch 44 / 100: avg data time: 6.19e-02, avg batch time: 0.4746, average train loss: 49.4812
[09/25 22:10:16 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 51.9071
[09/25 22:10:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 11.50	
[09/25 22:10:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 22:10:22 visual_prompt]: Epoch 45 / 100: avg data time: 5.70e-02, avg batch time: 0.4688, average train loss: 48.7117
[09/25 22:10:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1583, average loss: 46.2099
[09/25 22:10:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:10:24 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 22:10:30 visual_prompt]: Epoch 46 / 100: avg data time: 5.74e-02, avg batch time: 0.4693, average train loss: 39.5377
[09/25 22:10:32 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1577, average loss: 40.1853
[09/25 22:10:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.00	
[09/25 22:10:32 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 22:10:38 visual_prompt]: Epoch 47 / 100: avg data time: 6.31e-02, avg batch time: 0.4761, average train loss: 40.5822
[09/25 22:10:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 37.8911
[09/25 22:10:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 13.50	
[09/25 22:10:40 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 22:10:46 visual_prompt]: Epoch 48 / 100: avg data time: 4.65e-02, avg batch time: 0.4597, average train loss: 43.3457
[09/25 22:10:48 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1582, average loss: 33.5741
[09/25 22:10:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 12.50	
[09/25 22:10:48 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 22:10:54 visual_prompt]: Epoch 49 / 100: avg data time: 5.81e-02, avg batch time: 0.4720, average train loss: 35.7643
[09/25 22:10:56 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1581, average loss: 23.0206
[09/25 22:10:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 10.00	
[09/25 22:10:56 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 22:11:02 visual_prompt]: Epoch 50 / 100: avg data time: 5.32e-02, avg batch time: 0.4652, average train loss: 29.2498
[09/25 22:11:04 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1580, average loss: 23.4837
[09/25 22:11:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 16.50	
[09/25 22:11:04 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 22:11:10 visual_prompt]: Epoch 51 / 100: avg data time: 5.94e-02, avg batch time: 0.4722, average train loss: 29.3690
[09/25 22:11:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1581, average loss: 27.1783
[09/25 22:11:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 11.50	
[09/25 22:11:12 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 22:11:18 visual_prompt]: Epoch 52 / 100: avg data time: 5.04e-02, avg batch time: 0.4632, average train loss: 32.6592
[09/25 22:11:20 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1581, average loss: 29.9358
[09/25 22:11:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 11.00	
[09/25 22:11:20 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 22:11:26 visual_prompt]: Epoch 53 / 100: avg data time: 5.65e-02, avg batch time: 0.4716, average train loss: 29.5027
[09/25 22:11:28 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1585, average loss: 24.4517
[09/25 22:11:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 10.00	
[09/25 22:11:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 22:11:34 visual_prompt]: Epoch 54 / 100: avg data time: 5.78e-02, avg batch time: 0.4698, average train loss: 27.0287
[09/25 22:11:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 26.0163
[09/25 22:11:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 9.00	
[09/25 22:11:36 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 22:11:42 visual_prompt]: Epoch 55 / 100: avg data time: 5.70e-02, avg batch time: 0.4702, average train loss: 25.3750
[09/25 22:11:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 19.5119
[09/25 22:11:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 10.50	
[09/25 22:11:44 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 22:11:50 visual_prompt]: Epoch 56 / 100: avg data time: 5.94e-02, avg batch time: 0.4717, average train loss: 24.2613
[09/25 22:11:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 17.7068
[09/25 22:11:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.00	top5: 17.00	
[09/25 22:11:52 visual_prompt]: Best epoch 56: best metric: 0.050
[09/25 22:11:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 22:11:58 visual_prompt]: Epoch 57 / 100: avg data time: 5.54e-02, avg batch time: 0.4693, average train loss: 21.3392
[09/25 22:12:00 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1586, average loss: 18.6306
[09/25 22:12:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 10.50	
[09/25 22:12:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 22:12:06 visual_prompt]: Epoch 58 / 100: avg data time: 6.21e-02, avg batch time: 0.4743, average train loss: 20.7041
[09/25 22:12:08 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 19.2405
[09/25 22:12:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 8.50	
[09/25 22:12:08 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 22:12:14 visual_prompt]: Epoch 59 / 100: avg data time: 6.70e-02, avg batch time: 0.4791, average train loss: 20.1516
[09/25 22:12:16 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1579, average loss: 16.7943
[09/25 22:12:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 9.00	
[09/25 22:12:16 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 22:12:22 visual_prompt]: Epoch 60 / 100: avg data time: 6.64e-02, avg batch time: 0.4787, average train loss: 19.9185
[09/25 22:12:24 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 18.5847
[09/25 22:12:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 11.50	
[09/25 22:12:24 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 22:12:30 visual_prompt]: Epoch 61 / 100: avg data time: 6.78e-02, avg batch time: 0.4798, average train loss: 19.4406
[09/25 22:12:32 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1576, average loss: 14.3407
[09/25 22:12:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.50	top5: 19.00	
[09/25 22:12:32 visual_prompt]: Best epoch 61: best metric: 0.085
[09/25 22:12:32 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 22:12:38 visual_prompt]: Epoch 62 / 100: avg data time: 4.45e-02, avg batch time: 0.4597, average train loss: 18.2855
[09/25 22:12:40 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1579, average loss: 14.6096
[09/25 22:12:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 12.50	
[09/25 22:12:40 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 22:12:46 visual_prompt]: Epoch 63 / 100: avg data time: 6.20e-02, avg batch time: 0.4740, average train loss: 17.2441
[09/25 22:12:48 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1584, average loss: 14.0225
[09/25 22:12:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 15.00	
[09/25 22:12:48 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 22:12:54 visual_prompt]: Epoch 64 / 100: avg data time: 5.31e-02, avg batch time: 0.4671, average train loss: 16.4454
[09/25 22:12:56 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1581, average loss: 13.7604
[09/25 22:12:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 11.50	
[09/25 22:12:56 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 22:13:02 visual_prompt]: Epoch 65 / 100: avg data time: 6.14e-02, avg batch time: 0.4752, average train loss: 16.1037
[09/25 22:13:04 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1584, average loss: 12.6644
[09/25 22:13:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.00	top5: 14.50	
[09/25 22:13:04 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 22:13:10 visual_prompt]: Epoch 66 / 100: avg data time: 4.73e-02, avg batch time: 0.4626, average train loss: 14.8976
[09/25 22:13:12 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1579, average loss: 10.9588
[09/25 22:13:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.00	top5: 19.00	
[09/25 22:13:12 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 22:13:18 visual_prompt]: Epoch 67 / 100: avg data time: 5.14e-02, avg batch time: 0.4651, average train loss: 14.7179
[09/25 22:13:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 11.7179
[09/25 22:13:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 19.50	
[09/25 22:13:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 22:13:26 visual_prompt]: Epoch 68 / 100: avg data time: 5.51e-02, avg batch time: 0.4678, average train loss: 13.5522
[09/25 22:13:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 11.5856
[09/25 22:13:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.50	top5: 16.50	
[09/25 22:13:28 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 22:13:34 visual_prompt]: Epoch 69 / 100: avg data time: 5.69e-02, avg batch time: 0.4708, average train loss: 14.6571
[09/25 22:13:36 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1583, average loss: 12.4482
[09/25 22:13:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.00	top5: 13.50	
[09/25 22:13:36 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 22:13:42 visual_prompt]: Epoch 70 / 100: avg data time: 5.17e-02, avg batch time: 0.4659, average train loss: 14.2545
[09/25 22:13:44 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1579, average loss: 10.8353
[09/25 22:13:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.50	top5: 21.00	
[09/25 22:13:44 visual_prompt]: Best epoch 70: best metric: 0.105
[09/25 22:13:44 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 22:13:50 visual_prompt]: Epoch 71 / 100: avg data time: 5.31e-02, avg batch time: 0.4664, average train loss: 13.6650
[09/25 22:13:52 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1580, average loss: 11.4475
[09/25 22:13:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 15.00	
[09/25 22:13:52 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 22:13:58 visual_prompt]: Epoch 72 / 100: avg data time: 6.33e-02, avg batch time: 0.4753, average train loss: 13.6180
[09/25 22:14:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1581, average loss: 10.4575
[09/25 22:14:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.50	top5: 18.50	
[09/25 22:14:00 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 22:14:06 visual_prompt]: Epoch 73 / 100: avg data time: 5.83e-02, avg batch time: 0.4704, average train loss: 12.9086
[09/25 22:14:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1581, average loss: 10.3585
[09/25 22:14:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 22.50	
[09/25 22:14:08 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 22:14:14 visual_prompt]: Epoch 74 / 100: avg data time: 5.18e-02, avg batch time: 0.4644, average train loss: 13.2601
[09/25 22:14:16 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1581, average loss: 9.0172
[09/25 22:14:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.00	top5: 22.00	
[09/25 22:14:16 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 22:14:22 visual_prompt]: Epoch 75 / 100: avg data time: 5.19e-02, avg batch time: 0.4654, average train loss: 12.6437
[09/25 22:14:24 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1584, average loss: 10.2206
[09/25 22:14:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 14.50	
[09/25 22:14:24 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 22:14:30 visual_prompt]: Epoch 76 / 100: avg data time: 4.94e-02, avg batch time: 0.4647, average train loss: 12.6999
[09/25 22:14:32 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1584, average loss: 8.8686
[09/25 22:14:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 23.00	
[09/25 22:14:32 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 22:14:38 visual_prompt]: Epoch 77 / 100: avg data time: 7.00e-02, avg batch time: 0.4828, average train loss: 12.4683
[09/25 22:14:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 9.3760
[09/25 22:14:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.50	top5: 20.00	
[09/25 22:14:40 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 22:14:46 visual_prompt]: Epoch 78 / 100: avg data time: 5.42e-02, avg batch time: 0.4665, average train loss: 11.9715
[09/25 22:14:48 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1577, average loss: 8.8733
[09/25 22:14:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.00	top5: 21.50	
[09/25 22:14:48 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 22:14:54 visual_prompt]: Epoch 79 / 100: avg data time: 6.29e-02, avg batch time: 0.4754, average train loss: 11.4731
[09/25 22:14:56 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 9.2905
[09/25 22:14:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 23.00	
[09/25 22:14:56 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 22:15:02 visual_prompt]: Epoch 80 / 100: avg data time: 6.28e-02, avg batch time: 0.4766, average train loss: 11.7429
[09/25 22:15:04 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 9.0322
[09/25 22:15:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 23.00	
[09/25 22:15:04 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 22:15:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.31e-02, avg batch time: 0.4662, average train loss: 11.4283
[09/25 22:15:12 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1583, average loss: 8.4276
[09/25 22:15:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.50	top5: 21.00	
[09/25 22:15:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 22:15:18 visual_prompt]: Epoch 82 / 100: avg data time: 5.76e-02, avg batch time: 0.4708, average train loss: 10.6914
[09/25 22:15:20 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1581, average loss: 8.9920
[09/25 22:15:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 20.00	
[09/25 22:15:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 22:15:26 visual_prompt]: Epoch 83 / 100: avg data time: 4.99e-02, avg batch time: 0.4644, average train loss: 10.5595
[09/25 22:15:28 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1586, average loss: 8.2184
[09/25 22:15:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.00	top5: 21.50	
[09/25 22:15:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 22:15:34 visual_prompt]: Epoch 84 / 100: avg data time: 5.71e-02, avg batch time: 0.4713, average train loss: 10.1022
[09/25 22:15:36 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1577, average loss: 7.4880
[09/25 22:15:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.00	top5: 26.50	
[09/25 22:15:36 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 22:15:42 visual_prompt]: Epoch 85 / 100: avg data time: 6.58e-02, avg batch time: 0.4790, average train loss: 9.9904
[09/25 22:15:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1577, average loss: 8.0439
[09/25 22:15:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.50	top5: 25.50	
[09/25 22:15:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 22:15:50 visual_prompt]: Epoch 86 / 100: avg data time: 5.67e-02, avg batch time: 0.4696, average train loss: 10.1084
[09/25 22:15:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1586, average loss: 7.6231
[09/25 22:15:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.00	top5: 22.50	
[09/25 22:15:52 visual_prompt]: Best epoch 86: best metric: 0.110
[09/25 22:15:52 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 22:15:58 visual_prompt]: Epoch 87 / 100: avg data time: 5.56e-02, avg batch time: 0.4688, average train loss: 9.9215
[09/25 22:16:00 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 7.4149
[09/25 22:16:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 25.50	
[09/25 22:16:00 visual_prompt]: Best epoch 87: best metric: 0.120
[09/25 22:16:00 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 22:16:06 visual_prompt]: Epoch 88 / 100: avg data time: 6.69e-02, avg batch time: 0.4796, average train loss: 10.2884
[09/25 22:16:08 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 7.5858
[09/25 22:16:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.00	top5: 23.00	
[09/25 22:16:08 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 22:16:14 visual_prompt]: Epoch 89 / 100: avg data time: 4.56e-02, avg batch time: 0.4608, average train loss: 10.0269
[09/25 22:16:16 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1584, average loss: 7.0575
[09/25 22:16:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 13.50	top5: 28.00	
[09/25 22:16:16 visual_prompt]: Best epoch 89: best metric: 0.135
[09/25 22:16:16 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 22:16:22 visual_prompt]: Epoch 90 / 100: avg data time: 4.71e-02, avg batch time: 0.4608, average train loss: 10.1509
[09/25 22:16:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1585, average loss: 7.4495
[09/25 22:16:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.50	top5: 26.50	
[09/25 22:16:24 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 22:16:30 visual_prompt]: Epoch 91 / 100: avg data time: 6.09e-02, avg batch time: 0.4743, average train loss: 9.6868
[09/25 22:16:32 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1581, average loss: 7.2356
[09/25 22:16:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 27.50	
[09/25 22:16:32 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 22:16:38 visual_prompt]: Epoch 92 / 100: avg data time: 6.54e-02, avg batch time: 0.4788, average train loss: 9.6980
[09/25 22:16:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1585, average loss: 7.0871
[09/25 22:16:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.00	top5: 27.50	
[09/25 22:16:40 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 22:16:46 visual_prompt]: Epoch 93 / 100: avg data time: 5.88e-02, avg batch time: 0.4712, average train loss: 9.4703
[09/25 22:16:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 7.3179
[09/25 22:16:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.50	top5: 23.50	
[09/25 22:16:48 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 22:16:54 visual_prompt]: Epoch 94 / 100: avg data time: 5.75e-02, avg batch time: 0.4700, average train loss: 9.6608
[09/25 22:16:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 7.2927
[09/25 22:16:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.50	top5: 24.50	
[09/25 22:16:56 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 22:17:02 visual_prompt]: Epoch 95 / 100: avg data time: 5.98e-02, avg batch time: 0.4733, average train loss: 9.5333
[09/25 22:17:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 7.0241
[09/25 22:17:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 27.00	
[09/25 22:17:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 22:17:11 visual_prompt]: Epoch 96 / 100: avg data time: 6.80e-02, avg batch time: 0.4814, average train loss: 9.5637
[09/25 22:17:12 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 7.1195
[09/25 22:17:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 26.00	
[09/25 22:17:12 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 22:17:18 visual_prompt]: Epoch 97 / 100: avg data time: 4.72e-02, avg batch time: 0.4601, average train loss: 9.7460
[09/25 22:17:20 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1581, average loss: 7.1029
[09/25 22:17:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 26.00	
[09/25 22:17:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 22:17:27 visual_prompt]: Epoch 98 / 100: avg data time: 5.95e-02, avg batch time: 0.4721, average train loss: 9.3488
[09/25 22:17:28 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 7.0716
[09/25 22:17:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 13.00	top5: 27.00	
[09/25 22:17:28 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 22:17:34 visual_prompt]: Epoch 99 / 100: avg data time: 5.36e-02, avg batch time: 0.4664, average train loss: 10.0065
[09/25 22:17:36 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1583, average loss: 7.0888
[09/25 22:17:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.50	top5: 26.00	
[09/25 22:17:36 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 22:17:43 visual_prompt]: Epoch 100 / 100: avg data time: 6.46e-02, avg batch time: 0.4772, average train loss: 9.6062
[09/25 22:17:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1581, average loss: 7.0931
[09/25 22:17:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.50	top5: 26.00	
[09/25 22:17:44 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:17:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:17:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:17:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:17:44 visual_prompt]: Training with config:
[09/25 22:17:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:17:44 visual_prompt]: Loading training data...
[09/25 22:17:44 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:17:45 visual_prompt]: Number of images: 800
[09/25 22:17:45 visual_prompt]: Number of classes: 102 / 102
[09/25 22:17:45 visual_prompt]: Loading validation data...
[09/25 22:17:45 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:17:46 visual_prompt]: Number of images: 200
[09/25 22:17:46 visual_prompt]: Number of classes: 91 / 102
[09/25 22:17:46 visual_prompt]: Constructing models...
[09/25 22:17:48 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 22:17:48 visual_prompt]: tuned percent:0.625
[09/25 22:17:48 visual_prompt]: Device used for model: 0
[09/25 22:17:48 visual_prompt]: Setting up Evaluator...
[09/25 22:17:48 visual_prompt]: Setting up Trainer...
[09/25 22:17:48 visual_prompt]: 	Setting up the optimizer...
[09/25 22:17:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:17:55 visual_prompt]: Epoch 1 / 100: avg data time: 6.21e-02, avg batch time: 0.4821, average train loss: 4.6661
[09/25 22:17:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 4.6780
[09/25 22:17:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:17:56 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:17:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 22:18:03 visual_prompt]: Epoch 2 / 100: avg data time: 6.55e-02, avg batch time: 0.4779, average train loss: 4.7857
[09/25 22:18:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1581, average loss: 4.7300
[09/25 22:18:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 22:18:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 22:18:11 visual_prompt]: Epoch 3 / 100: avg data time: 5.99e-02, avg batch time: 0.4736, average train loss: 4.9694
[09/25 22:18:12 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 5.1540
[09/25 22:18:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:18:12 visual_prompt]: Best epoch 3: best metric: 0.015
[09/25 22:18:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 22:18:19 visual_prompt]: Epoch 4 / 100: avg data time: 4.88e-02, avg batch time: 0.4615, average train loss: 5.2981
[09/25 22:18:20 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.1580, average loss: 5.6234
[09/25 22:18:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 22:18:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 22:18:27 visual_prompt]: Epoch 5 / 100: avg data time: 5.97e-02, avg batch time: 0.4719, average train loss: 6.4782
[09/25 22:18:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 7.1503
[09/25 22:18:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:18:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 22:18:35 visual_prompt]: Epoch 6 / 100: avg data time: 5.07e-02, avg batch time: 0.4624, average train loss: 8.9045
[09/25 22:18:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1585, average loss: 10.3480
[09/25 22:18:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/25 22:18:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 22:18:43 visual_prompt]: Epoch 7 / 100: avg data time: 6.26e-02, avg batch time: 0.4754, average train loss: 10.7471
[09/25 22:18:44 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1577, average loss: 10.7156
[09/25 22:18:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 22:18:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 22:18:51 visual_prompt]: Epoch 8 / 100: avg data time: 5.95e-02, avg batch time: 0.4720, average train loss: 15.2982
[09/25 22:18:52 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 16.6194
[09/25 22:18:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:18:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 22:18:59 visual_prompt]: Epoch 9 / 100: avg data time: 5.93e-02, avg batch time: 0.4711, average train loss: 22.0719
[09/25 22:19:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 22.6057
[09/25 22:19:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:19:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 22:19:07 visual_prompt]: Epoch 10 / 100: avg data time: 6.48e-02, avg batch time: 0.4774, average train loss: 34.5987
[09/25 22:19:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1578, average loss: 30.5204
[09/25 22:19:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:19:08 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 22:19:15 visual_prompt]: Epoch 11 / 100: avg data time: 5.94e-02, avg batch time: 0.4717, average train loss: 43.1291
[09/25 22:19:17 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1583, average loss: 35.2689
[09/25 22:19:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.00	
[09/25 22:19:17 visual_prompt]: Best epoch 11: best metric: 0.020
[09/25 22:19:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 22:19:23 visual_prompt]: Epoch 12 / 100: avg data time: 5.45e-02, avg batch time: 0.4677, average train loss: 53.9129
[09/25 22:19:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 46.8901
[09/25 22:19:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:19:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 22:19:31 visual_prompt]: Epoch 13 / 100: avg data time: 6.59e-02, avg batch time: 0.4777, average train loss: 57.2045
[09/25 22:19:33 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1580, average loss: 57.9515
[09/25 22:19:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:19:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 22:19:39 visual_prompt]: Epoch 14 / 100: avg data time: 5.48e-02, avg batch time: 0.4676, average train loss: 65.4965
[09/25 22:19:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 68.8337
[09/25 22:19:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 22:19:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 22:19:47 visual_prompt]: Epoch 15 / 100: avg data time: 6.22e-02, avg batch time: 0.4735, average train loss: 79.8499
[09/25 22:19:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 64.1065
[09/25 22:19:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 22:19:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 22:19:55 visual_prompt]: Epoch 16 / 100: avg data time: 5.65e-02, avg batch time: 0.4688, average train loss: 79.7212
[09/25 22:19:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 77.0512
[09/25 22:19:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:19:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 22:20:03 visual_prompt]: Epoch 17 / 100: avg data time: 4.82e-02, avg batch time: 0.4602, average train loss: 79.2154
[09/25 22:20:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1585, average loss: 63.4106
[09/25 22:20:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:20:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 22:20:11 visual_prompt]: Epoch 18 / 100: avg data time: 6.02e-02, avg batch time: 0.4726, average train loss: 78.0755
[09/25 22:20:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1580, average loss: 67.9551
[09/25 22:20:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 22:20:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 22:20:19 visual_prompt]: Epoch 19 / 100: avg data time: 5.92e-02, avg batch time: 0.4725, average train loss: 80.6234
[09/25 22:20:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 73.3343
[09/25 22:20:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 22:20:20 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 22:20:27 visual_prompt]: Epoch 20 / 100: avg data time: 4.96e-02, avg batch time: 0.4624, average train loss: 80.7855
[09/25 22:20:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 75.4683
[09/25 22:20:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:20:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 22:20:35 visual_prompt]: Epoch 21 / 100: avg data time: 5.91e-02, avg batch time: 0.4715, average train loss: 80.7507
[09/25 22:20:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 104.1297
[09/25 22:20:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:20:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 22:20:43 visual_prompt]: Epoch 22 / 100: avg data time: 6.31e-02, avg batch time: 0.4751, average train loss: 88.5837
[09/25 22:20:44 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1578, average loss: 88.3683
[09/25 22:20:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:20:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 22:20:51 visual_prompt]: Epoch 23 / 100: avg data time: 5.98e-02, avg batch time: 0.4714, average train loss: 88.6637
[09/25 22:20:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 90.5503
[09/25 22:20:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 22:20:52 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 22:20:58 visual_prompt]: Epoch 24 / 100: avg data time: 5.22e-02, avg batch time: 0.4649, average train loss: 85.5412
[09/25 22:21:00 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1576, average loss: 89.0475
[09/25 22:21:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/25 22:21:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 22:21:07 visual_prompt]: Epoch 25 / 100: avg data time: 6.13e-02, avg batch time: 0.4734, average train loss: 78.1937
[09/25 22:21:08 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 86.1047
[09/25 22:21:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:21:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 22:21:14 visual_prompt]: Epoch 26 / 100: avg data time: 5.78e-02, avg batch time: 0.4695, average train loss: 75.0990
[09/25 22:21:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 82.7984
[09/25 22:21:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 22:21:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 22:21:22 visual_prompt]: Epoch 27 / 100: avg data time: 5.96e-02, avg batch time: 0.4723, average train loss: 71.9964
[09/25 22:21:24 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1585, average loss: 68.2059
[09/25 22:21:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:21:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 22:21:31 visual_prompt]: Epoch 28 / 100: avg data time: 6.04e-02, avg batch time: 0.4727, average train loss: 67.2702
[09/25 22:21:32 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1580, average loss: 70.1717
[09/25 22:21:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:21:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 22:21:39 visual_prompt]: Epoch 29 / 100: avg data time: 5.90e-02, avg batch time: 0.4710, average train loss: 65.5810
[09/25 22:21:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1579, average loss: 68.4302
[09/25 22:21:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:21:40 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 22:21:47 visual_prompt]: Epoch 30 / 100: avg data time: 6.52e-02, avg batch time: 0.4774, average train loss: 61.8205
[09/25 22:21:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1582, average loss: 70.6628
[09/25 22:21:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:21:48 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 22:21:55 visual_prompt]: Epoch 31 / 100: avg data time: 6.43e-02, avg batch time: 0.4770, average train loss: 64.7581
[09/25 22:21:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 57.5902
[09/25 22:21:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:21:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 22:22:03 visual_prompt]: Epoch 32 / 100: avg data time: 6.02e-02, avg batch time: 0.4737, average train loss: 68.3288
[09/25 22:22:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1586, average loss: 55.7136
[09/25 22:22:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:22:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 22:22:11 visual_prompt]: Epoch 33 / 100: avg data time: 6.49e-02, avg batch time: 0.4772, average train loss: 63.8809
[09/25 22:22:12 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 50.7291
[09/25 22:22:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 22:22:12 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 22:22:19 visual_prompt]: Epoch 34 / 100: avg data time: 5.87e-02, avg batch time: 0.4708, average train loss: 63.4139
[09/25 22:22:21 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1583, average loss: 49.8272
[09/25 22:22:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:22:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 22:22:27 visual_prompt]: Epoch 35 / 100: avg data time: 5.73e-02, avg batch time: 0.4698, average train loss: 62.4121
[09/25 22:22:29 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1582, average loss: 50.1365
[09/25 22:22:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:22:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 22:22:35 visual_prompt]: Epoch 36 / 100: avg data time: 5.86e-02, avg batch time: 0.4708, average train loss: 64.6887
[09/25 22:22:37 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1582, average loss: 51.8923
[09/25 22:22:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:22:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 22:22:43 visual_prompt]: Epoch 37 / 100: avg data time: 6.23e-02, avg batch time: 0.4751, average train loss: 65.1309
[09/25 22:22:45 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1582, average loss: 55.2193
[09/25 22:22:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 22:22:45 visual_prompt]: Best epoch 37: best metric: 0.025
[09/25 22:22:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 22:22:51 visual_prompt]: Epoch 38 / 100: avg data time: 6.18e-02, avg batch time: 0.4750, average train loss: 65.3791
[09/25 22:22:53 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1581, average loss: 60.2843
[09/25 22:22:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 22:22:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 22:22:59 visual_prompt]: Epoch 39 / 100: avg data time: 6.87e-02, avg batch time: 0.4815, average train loss: 65.4468
[09/25 22:23:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 65.5038
[09/25 22:23:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:23:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 22:23:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.47e-02, avg batch time: 0.4683, average train loss: 64.1358
[09/25 22:23:09 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 58.5819
[09/25 22:23:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 22:23:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 22:23:15 visual_prompt]: Epoch 41 / 100: avg data time: 5.77e-02, avg batch time: 0.4712, average train loss: 67.2276
[09/25 22:23:17 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1575, average loss: 66.7422
[09/25 22:23:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 22:23:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 22:23:23 visual_prompt]: Epoch 42 / 100: avg data time: 5.67e-02, avg batch time: 0.4713, average train loss: 65.4814
[09/25 22:23:25 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1584, average loss: 60.2556
[09/25 22:23:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:23:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 22:23:31 visual_prompt]: Epoch 43 / 100: avg data time: 5.98e-02, avg batch time: 0.4741, average train loss: 58.8606
[09/25 22:23:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 51.3222
[09/25 22:23:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 4.50	
[09/25 22:23:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 22:23:39 visual_prompt]: Epoch 44 / 100: avg data time: 5.87e-02, avg batch time: 0.4708, average train loss: 51.7298
[09/25 22:23:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1579, average loss: 46.0374
[09/25 22:23:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:23:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 22:23:47 visual_prompt]: Epoch 45 / 100: avg data time: 5.97e-02, avg batch time: 0.4717, average train loss: 47.8883
[09/25 22:23:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 46.8638
[09/25 22:23:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:23:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 22:23:55 visual_prompt]: Epoch 46 / 100: avg data time: 5.70e-02, avg batch time: 0.4689, average train loss: 44.6229
[09/25 22:23:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 40.0799
[09/25 22:23:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 9.50	
[09/25 22:23:57 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 22:24:03 visual_prompt]: Epoch 47 / 100: avg data time: 6.13e-02, avg batch time: 0.4749, average train loss: 44.0067
[09/25 22:24:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1586, average loss: 47.1864
[09/25 22:24:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:24:05 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 22:24:11 visual_prompt]: Epoch 48 / 100: avg data time: 6.02e-02, avg batch time: 0.4731, average train loss: 42.9762
[09/25 22:24:13 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1581, average loss: 45.2356
[09/25 22:24:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:24:13 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 22:24:19 visual_prompt]: Epoch 49 / 100: avg data time: 5.73e-02, avg batch time: 0.4714, average train loss: 37.9852
[09/25 22:24:21 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1580, average loss: 49.2645
[09/25 22:24:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:24:21 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 22:24:27 visual_prompt]: Epoch 50 / 100: avg data time: 6.64e-02, avg batch time: 0.4800, average train loss: 42.6763
[09/25 22:24:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 44.9922
[09/25 22:24:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/25 22:24:29 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 22:24:35 visual_prompt]: Epoch 51 / 100: avg data time: 6.49e-02, avg batch time: 0.4767, average train loss: 39.2946
[09/25 22:24:37 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1584, average loss: 35.2132
[09/25 22:24:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:24:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 22:24:43 visual_prompt]: Epoch 52 / 100: avg data time: 6.23e-02, avg batch time: 0.4745, average train loss: 37.1123
[09/25 22:24:45 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1586, average loss: 36.0600
[09/25 22:24:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:24:45 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 22:24:51 visual_prompt]: Epoch 53 / 100: avg data time: 5.97e-02, avg batch time: 0.4731, average train loss: 41.5329
[09/25 22:24:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1585, average loss: 32.5866
[09/25 22:24:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 22:24:53 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 22:24:59 visual_prompt]: Epoch 54 / 100: avg data time: 5.81e-02, avg batch time: 0.4716, average train loss: 34.8463
[09/25 22:25:01 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 37.6713
[09/25 22:25:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:25:01 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 22:25:07 visual_prompt]: Epoch 55 / 100: avg data time: 6.25e-02, avg batch time: 0.4751, average train loss: 36.0738
[09/25 22:25:09 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1583, average loss: 28.6889
[09/25 22:25:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.50	
[09/25 22:25:09 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 22:25:15 visual_prompt]: Epoch 56 / 100: avg data time: 6.10e-02, avg batch time: 0.4726, average train loss: 34.2470
[09/25 22:25:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1579, average loss: 23.5681
[09/25 22:25:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:25:17 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 22:25:24 visual_prompt]: Epoch 57 / 100: avg data time: 6.21e-02, avg batch time: 0.4752, average train loss: 28.4685
[09/25 22:25:25 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1578, average loss: 24.7202
[09/25 22:25:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:25:25 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 22:25:32 visual_prompt]: Epoch 58 / 100: avg data time: 5.73e-02, avg batch time: 0.4704, average train loss: 24.8896
[09/25 22:25:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 19.1199
[09/25 22:25:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 22:25:33 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 22:25:40 visual_prompt]: Epoch 59 / 100: avg data time: 6.05e-02, avg batch time: 0.4727, average train loss: 22.4577
[09/25 22:25:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 18.0040
[09/25 22:25:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 22:25:41 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 22:25:48 visual_prompt]: Epoch 60 / 100: avg data time: 5.89e-02, avg batch time: 0.4731, average train loss: 19.5844
[09/25 22:25:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1579, average loss: 17.7766
[09/25 22:25:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:25:49 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 22:25:56 visual_prompt]: Epoch 61 / 100: avg data time: 5.84e-02, avg batch time: 0.4724, average train loss: 16.1199
[09/25 22:25:57 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 14.5030
[09/25 22:25:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:25:57 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 22:26:04 visual_prompt]: Epoch 62 / 100: avg data time: 5.50e-02, avg batch time: 0.4683, average train loss: 16.0729
[09/25 22:26:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1585, average loss: 14.0252
[09/25 22:26:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 22:26:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 22:26:12 visual_prompt]: Epoch 63 / 100: avg data time: 6.09e-02, avg batch time: 0.4739, average train loss: 13.8276
[09/25 22:26:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 12.0170
[09/25 22:26:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:26:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 22:26:20 visual_prompt]: Epoch 64 / 100: avg data time: 6.66e-02, avg batch time: 0.4787, average train loss: 12.7190
[09/25 22:26:21 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1581, average loss: 10.9365
[09/25 22:26:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:26:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 22:26:28 visual_prompt]: Epoch 65 / 100: avg data time: 6.44e-02, avg batch time: 0.4766, average train loss: 12.5509
[09/25 22:26:29 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1584, average loss: 9.6277
[09/25 22:26:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.00	
[09/25 22:26:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 22:26:36 visual_prompt]: Epoch 66 / 100: avg data time: 4.89e-02, avg batch time: 0.4608, average train loss: 11.2386
[09/25 22:26:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 78.3304
[09/25 22:26:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:26:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 22:26:44 visual_prompt]: Epoch 67 / 100: avg data time: 6.28e-02, avg batch time: 0.4746, average train loss: 16.7647
[09/25 22:26:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1586, average loss: 7.6488
[09/25 22:26:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.50	
[09/25 22:26:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 22:26:52 visual_prompt]: Epoch 68 / 100: avg data time: 4.92e-02, avg batch time: 0.4634, average train loss: 9.0390
[09/25 22:26:53 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1579, average loss: 7.0504
[09/25 22:26:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.50	
[09/25 22:26:53 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 22:27:00 visual_prompt]: Epoch 69 / 100: avg data time: 5.91e-02, avg batch time: 0.4716, average train loss: 8.4554
[09/25 22:27:01 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1580, average loss: 6.8721
[09/25 22:27:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 22:27:01 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 22:27:08 visual_prompt]: Epoch 70 / 100: avg data time: 5.81e-02, avg batch time: 0.4718, average train loss: 7.8498
[09/25 22:27:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 6.5553
[09/25 22:27:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:27:09 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 22:27:16 visual_prompt]: Epoch 71 / 100: avg data time: 6.47e-02, avg batch time: 0.4765, average train loss: 7.5772
[09/25 22:27:17 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1583, average loss: 6.1453
[09/25 22:27:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.00	
[09/25 22:27:17 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 22:27:24 visual_prompt]: Epoch 72 / 100: avg data time: 6.55e-02, avg batch time: 0.4778, average train loss: 7.3152
[09/25 22:27:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 6.6146
[09/25 22:27:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:27:26 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 22:27:32 visual_prompt]: Epoch 73 / 100: avg data time: 5.09e-02, avg batch time: 0.4626, average train loss: 7.5185
[09/25 22:27:33 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 5.9584
[09/25 22:27:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 22:27:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 22:27:40 visual_prompt]: Epoch 74 / 100: avg data time: 6.09e-02, avg batch time: 0.4731, average train loss: 7.4754
[09/25 22:27:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1575, average loss: 7.2095
[09/25 22:27:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.50	
[09/25 22:27:42 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 22:27:48 visual_prompt]: Epoch 75 / 100: avg data time: 5.86e-02, avg batch time: 0.4701, average train loss: 7.8085
[09/25 22:27:50 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1579, average loss: 6.4278
[09/25 22:27:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:27:50 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 22:27:56 visual_prompt]: Epoch 76 / 100: avg data time: 5.57e-02, avg batch time: 0.4688, average train loss: 7.0745
[09/25 22:27:58 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1582, average loss: 5.8399
[09/25 22:27:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 22:27:58 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 22:28:04 visual_prompt]: Epoch 77 / 100: avg data time: 6.24e-02, avg batch time: 0.4749, average train loss: 6.5169
[09/25 22:28:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1579, average loss: 5.7656
[09/25 22:28:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 22:28:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 22:28:12 visual_prompt]: Epoch 78 / 100: avg data time: 5.92e-02, avg batch time: 0.4711, average train loss: 6.0491
[09/25 22:28:14 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1583, average loss: 5.4915
[09/25 22:28:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/25 22:28:14 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 22:28:20 visual_prompt]: Epoch 79 / 100: avg data time: 5.73e-02, avg batch time: 0.4698, average train loss: 5.7173
[09/25 22:28:22 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 5.7476
[09/25 22:28:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:28:22 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 22:28:28 visual_prompt]: Epoch 80 / 100: avg data time: 6.38e-02, avg batch time: 0.4756, average train loss: 5.5752
[09/25 22:28:30 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1578, average loss: 5.1475
[09/25 22:28:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:28:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 22:28:36 visual_prompt]: Epoch 81 / 100: avg data time: 4.60e-02, avg batch time: 0.4587, average train loss: 5.3220
[09/25 22:28:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 5.1093
[09/25 22:28:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:28:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 22:28:44 visual_prompt]: Epoch 82 / 100: avg data time: 5.74e-02, avg batch time: 0.4704, average train loss: 5.1657
[09/25 22:28:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 4.8518
[09/25 22:28:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.00	
[09/25 22:28:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 22:28:52 visual_prompt]: Epoch 83 / 100: avg data time: 5.79e-02, avg batch time: 0.4704, average train loss: 5.0189
[09/25 22:28:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1582, average loss: 4.8196
[09/25 22:28:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 22:28:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 22:29:00 visual_prompt]: Epoch 84 / 100: avg data time: 6.84e-02, avg batch time: 0.4801, average train loss: 4.9536
[09/25 22:29:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 4.8201
[09/25 22:29:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:29:02 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 22:29:08 visual_prompt]: Epoch 85 / 100: avg data time: 5.91e-02, avg batch time: 0.4735, average train loss: 4.9102
[09/25 22:29:10 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1581, average loss: 4.8129
[09/25 22:29:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:29:10 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 22:29:16 visual_prompt]: Epoch 86 / 100: avg data time: 5.21e-02, avg batch time: 0.4655, average train loss: 4.8532
[09/25 22:29:18 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1583, average loss: 4.7131
[09/25 22:29:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 8.00	
[09/25 22:29:18 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 22:29:24 visual_prompt]: Epoch 87 / 100: avg data time: 5.42e-02, avg batch time: 0.4663, average train loss: 4.7838
[09/25 22:29:26 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1574, average loss: 4.7741
[09/25 22:29:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:29:26 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 22:29:32 visual_prompt]: Epoch 88 / 100: avg data time: 5.70e-02, avg batch time: 0.4698, average train loss: 4.7581
[09/25 22:29:34 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1581, average loss: 4.8208
[09/25 22:29:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:29:34 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 22:29:40 visual_prompt]: Epoch 89 / 100: avg data time: 6.15e-02, avg batch time: 0.4742, average train loss: 4.7417
[09/25 22:29:42 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1579, average loss: 4.6888
[09/25 22:29:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 22:29:42 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 22:29:48 visual_prompt]: Epoch 90 / 100: avg data time: 5.39e-02, avg batch time: 0.4676, average train loss: 4.7034
[09/25 22:29:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1586, average loss: 4.7447
[09/25 22:29:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:29:50 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 22:29:56 visual_prompt]: Epoch 91 / 100: avg data time: 5.53e-02, avg batch time: 0.4688, average train loss: 4.6815
[09/25 22:29:58 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 4.7284
[09/25 22:29:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 22:29:58 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 22:30:04 visual_prompt]: Epoch 92 / 100: avg data time: 5.16e-02, avg batch time: 0.4656, average train loss: 4.6972
[09/25 22:30:05 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1584, average loss: 4.6610
[09/25 22:30:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:30:05 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 22:30:12 visual_prompt]: Epoch 93 / 100: avg data time: 6.31e-02, avg batch time: 0.4773, average train loss: 4.6446
[09/25 22:30:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1586, average loss: 4.6726
[09/25 22:30:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 22:30:14 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 22:30:20 visual_prompt]: Epoch 94 / 100: avg data time: 6.15e-02, avg batch time: 0.4745, average train loss: 4.6321
[09/25 22:30:22 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1583, average loss: 4.6647
[09/25 22:30:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:30:22 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 22:30:28 visual_prompt]: Epoch 95 / 100: avg data time: 6.13e-02, avg batch time: 0.4738, average train loss: 4.6204
[09/25 22:30:30 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1581, average loss: 4.6641
[09/25 22:30:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 22:30:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 22:30:36 visual_prompt]: Epoch 96 / 100: avg data time: 5.78e-02, avg batch time: 0.4699, average train loss: 4.6058
[09/25 22:30:38 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1580, average loss: 4.6601
[09/25 22:30:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:30:38 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 22:30:44 visual_prompt]: Epoch 97 / 100: avg data time: 5.35e-02, avg batch time: 0.4685, average train loss: 4.6005
[09/25 22:30:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1583, average loss: 4.6535
[09/25 22:30:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:30:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 22:30:52 visual_prompt]: Epoch 98 / 100: avg data time: 5.59e-02, avg batch time: 0.4699, average train loss: 4.5940
[09/25 22:30:54 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1579, average loss: 4.6583
[09/25 22:30:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:30:54 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 22:31:00 visual_prompt]: Epoch 99 / 100: avg data time: 5.00e-02, avg batch time: 0.4629, average train loss: 4.5860
[09/25 22:31:01 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1581, average loss: 4.6644
[09/25 22:31:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:31:01 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 22:31:08 visual_prompt]: Epoch 100 / 100: avg data time: 6.18e-02, avg batch time: 0.4751, average train loss: 4.6028
[09/25 22:31:09 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1585, average loss: 4.6488
[09/25 22:31:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:31:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:31:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:31:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:31:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:31:09 visual_prompt]: Training with config:
[09/25 22:31:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:31:09 visual_prompt]: Loading training data...
[09/25 22:31:09 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:31:11 visual_prompt]: Number of images: 800
[09/25 22:31:11 visual_prompt]: Number of classes: 102 / 102
[09/25 22:31:11 visual_prompt]: Loading validation data...
[09/25 22:31:11 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:31:11 visual_prompt]: Number of images: 200
[09/25 22:31:11 visual_prompt]: Number of classes: 91 / 102
[09/25 22:31:11 visual_prompt]: Constructing models...
[09/25 22:31:13 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 22:31:13 visual_prompt]: tuned percent:0.625
[09/25 22:31:13 visual_prompt]: Device used for model: 0
[09/25 22:31:13 visual_prompt]: Setting up Evaluator...
[09/25 22:31:13 visual_prompt]: Setting up Trainer...
[09/25 22:31:13 visual_prompt]: 	Setting up the optimizer...
[09/25 22:31:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:31:20 visual_prompt]: Epoch 1 / 100: avg data time: 5.64e-02, avg batch time: 0.4776, average train loss: 4.6681
[09/25 22:31:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 4.6780
[09/25 22:31:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:31:22 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:31:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 22:31:28 visual_prompt]: Epoch 2 / 100: avg data time: 6.15e-02, avg batch time: 0.4740, average train loss: 4.8276
[09/25 22:31:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 4.9762
[09/25 22:31:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 22:31:30 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 22:31:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 22:31:36 visual_prompt]: Epoch 3 / 100: avg data time: 4.43e-02, avg batch time: 0.4564, average train loss: 5.0825
[09/25 22:31:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 5.0916
[09/25 22:31:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 22:31:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 22:31:44 visual_prompt]: Epoch 4 / 100: avg data time: 5.84e-02, avg batch time: 0.4718, average train loss: 5.5043
[09/25 22:31:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 5.9542
[09/25 22:31:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:31:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 22:31:52 visual_prompt]: Epoch 5 / 100: avg data time: 6.42e-02, avg batch time: 0.4766, average train loss: 5.9606
[09/25 22:31:54 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1583, average loss: 6.0477
[09/25 22:31:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 22:31:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 22:32:00 visual_prompt]: Epoch 6 / 100: avg data time: 6.26e-02, avg batch time: 0.4754, average train loss: 10.5676
[09/25 22:32:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1586, average loss: 10.2631
[09/25 22:32:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 22:32:02 visual_prompt]: Best epoch 6: best metric: 0.020
[09/25 22:32:02 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 22:32:08 visual_prompt]: Epoch 7 / 100: avg data time: 5.90e-02, avg batch time: 0.4720, average train loss: 10.8194
[09/25 22:32:10 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 11.6929
[09/25 22:32:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:32:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 22:32:16 visual_prompt]: Epoch 8 / 100: avg data time: 6.94e-02, avg batch time: 0.4845, average train loss: 15.5876
[09/25 22:32:18 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 23.0697
[09/25 22:32:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.00	
[09/25 22:32:18 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 22:32:25 visual_prompt]: Epoch 9 / 100: avg data time: 6.61e-02, avg batch time: 0.4808, average train loss: 41.3970
[09/25 22:32:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1586, average loss: 54.1493
[09/25 22:32:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.50	
[09/25 22:32:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 22:32:33 visual_prompt]: Epoch 10 / 100: avg data time: 6.15e-02, avg batch time: 0.4746, average train loss: 54.1563
[09/25 22:32:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 59.6237
[09/25 22:32:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/25 22:32:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 22:32:41 visual_prompt]: Epoch 11 / 100: avg data time: 6.58e-02, avg batch time: 0.4799, average train loss: 61.0368
[09/25 22:32:42 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1583, average loss: 51.1533
[09/25 22:32:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:32:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 22:32:49 visual_prompt]: Epoch 12 / 100: avg data time: 5.81e-02, avg batch time: 0.4726, average train loss: 61.9199
[09/25 22:32:50 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 66.8683
[09/25 22:32:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 22:32:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 22:32:57 visual_prompt]: Epoch 13 / 100: avg data time: 6.17e-02, avg batch time: 0.4783, average train loss: 81.8670
[09/25 22:32:58 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1591, average loss: 87.6374
[09/25 22:32:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:32:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 22:33:05 visual_prompt]: Epoch 14 / 100: avg data time: 6.05e-02, avg batch time: 0.4755, average train loss: 91.1192
[09/25 22:33:06 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1589, average loss: 96.5963
[09/25 22:33:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:33:06 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 22:33:13 visual_prompt]: Epoch 15 / 100: avg data time: 6.31e-02, avg batch time: 0.4767, average train loss: 84.1208
[09/25 22:33:15 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.1588, average loss: 87.1365
[09/25 22:33:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 22:33:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 22:33:21 visual_prompt]: Epoch 16 / 100: avg data time: 6.42e-02, avg batch time: 0.4801, average train loss: 89.4351
[09/25 22:33:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1588, average loss: 91.1804
[09/25 22:33:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:33:23 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 22:33:29 visual_prompt]: Epoch 17 / 100: avg data time: 5.84e-02, avg batch time: 0.4732, average train loss: 104.5380
[09/25 22:33:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1587, average loss: 82.6320
[09/25 22:33:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:33:31 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 22:33:37 visual_prompt]: Epoch 18 / 100: avg data time: 5.86e-02, avg batch time: 0.4727, average train loss: 76.5360
[09/25 22:33:39 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1581, average loss: 73.5108
[09/25 22:33:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:33:39 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 22:33:45 visual_prompt]: Epoch 19 / 100: avg data time: 6.41e-02, avg batch time: 0.4782, average train loss: 83.6767
[09/25 22:33:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 82.8207
[09/25 22:33:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 4.50	
[09/25 22:33:47 visual_prompt]: Best epoch 19: best metric: 0.025
[09/25 22:33:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 22:33:53 visual_prompt]: Epoch 20 / 100: avg data time: 6.48e-02, avg batch time: 0.4775, average train loss: 92.1973
[09/25 22:33:55 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1584, average loss: 81.8870
[09/25 22:33:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.50	
[09/25 22:33:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 22:34:01 visual_prompt]: Epoch 21 / 100: avg data time: 5.19e-02, avg batch time: 0.4667, average train loss: 91.6224
[09/25 22:34:03 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 87.9826
[09/25 22:34:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:34:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 22:34:09 visual_prompt]: Epoch 22 / 100: avg data time: 6.19e-02, avg batch time: 0.4748, average train loss: 92.1017
[09/25 22:34:11 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 119.0782
[09/25 22:34:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:34:11 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 22:34:17 visual_prompt]: Epoch 23 / 100: avg data time: 5.58e-02, avg batch time: 0.4701, average train loss: 89.1745
[09/25 22:34:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 95.6690
[09/25 22:34:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:34:19 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 22:34:25 visual_prompt]: Epoch 24 / 100: avg data time: 6.16e-02, avg batch time: 0.4771, average train loss: 85.5970
[09/25 22:34:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 75.8572
[09/25 22:34:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 22:34:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 22:34:33 visual_prompt]: Epoch 25 / 100: avg data time: 5.63e-02, avg batch time: 0.4692, average train loss: 104.6266
[09/25 22:34:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 91.7161
[09/25 22:34:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 10.00	
[09/25 22:34:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 22:34:41 visual_prompt]: Epoch 26 / 100: avg data time: 5.22e-02, avg batch time: 0.4661, average train loss: 118.5033
[09/25 22:34:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 109.1450
[09/25 22:34:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:34:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 22:34:49 visual_prompt]: Epoch 27 / 100: avg data time: 5.13e-02, avg batch time: 0.4671, average train loss: 104.1838
[09/25 22:34:51 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1581, average loss: 82.6715
[09/25 22:34:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:34:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 22:34:57 visual_prompt]: Epoch 28 / 100: avg data time: 5.09e-02, avg batch time: 0.4646, average train loss: 91.0954
[09/25 22:34:59 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1587, average loss: 72.5908
[09/25 22:34:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:34:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 22:35:05 visual_prompt]: Epoch 29 / 100: avg data time: 6.05e-02, avg batch time: 0.4744, average train loss: 94.3270
[09/25 22:35:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 109.3123
[09/25 22:35:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:35:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 22:35:13 visual_prompt]: Epoch 30 / 100: avg data time: 6.41e-02, avg batch time: 0.4774, average train loss: 92.1955
[09/25 22:35:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 85.2189
[09/25 22:35:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:35:15 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 22:35:21 visual_prompt]: Epoch 31 / 100: avg data time: 5.78e-02, avg batch time: 0.4708, average train loss: 102.6903
[09/25 22:35:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 87.3634
[09/25 22:35:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 22:35:23 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 22:35:30 visual_prompt]: Epoch 32 / 100: avg data time: 6.85e-02, avg batch time: 0.4820, average train loss: 97.4941
[09/25 22:35:31 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1579, average loss: 74.8896
[09/25 22:35:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/25 22:35:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 22:35:38 visual_prompt]: Epoch 33 / 100: avg data time: 6.94e-02, avg batch time: 0.4817, average train loss: 98.9258
[09/25 22:35:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1585, average loss: 95.6326
[09/25 22:35:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 22:35:39 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 22:35:46 visual_prompt]: Epoch 34 / 100: avg data time: 6.76e-02, avg batch time: 0.4796, average train loss: 100.5390
[09/25 22:35:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 87.0647
[09/25 22:35:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:35:47 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 22:35:54 visual_prompt]: Epoch 35 / 100: avg data time: 5.99e-02, avg batch time: 0.4732, average train loss: 92.5519
[09/25 22:35:55 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 91.2545
[09/25 22:35:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:35:55 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 22:36:02 visual_prompt]: Epoch 36 / 100: avg data time: 5.58e-02, avg batch time: 0.4681, average train loss: 99.0902
[09/25 22:36:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1583, average loss: 82.0507
[09/25 22:36:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 22:36:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 22:36:10 visual_prompt]: Epoch 37 / 100: avg data time: 5.32e-02, avg batch time: 0.4666, average train loss: 93.4971
[09/25 22:36:11 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 103.8597
[09/25 22:36:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/25 22:36:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 22:36:18 visual_prompt]: Epoch 38 / 100: avg data time: 5.95e-02, avg batch time: 0.4719, average train loss: 83.6326
[09/25 22:36:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1578, average loss: 67.1750
[09/25 22:36:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 22:36:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 22:36:26 visual_prompt]: Epoch 39 / 100: avg data time: 6.03e-02, avg batch time: 0.4731, average train loss: 69.8525
[09/25 22:36:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1587, average loss: 56.0928
[09/25 22:36:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:36:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 22:36:34 visual_prompt]: Epoch 40 / 100: avg data time: 5.81e-02, avg batch time: 0.4714, average train loss: 67.1196
[09/25 22:36:35 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 52.0099
[09/25 22:36:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:36:35 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 22:36:42 visual_prompt]: Epoch 41 / 100: avg data time: 5.92e-02, avg batch time: 0.4714, average train loss: 74.1891
[09/25 22:36:43 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1581, average loss: 55.7429
[09/25 22:36:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:36:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 22:36:50 visual_prompt]: Epoch 42 / 100: avg data time: 5.61e-02, avg batch time: 0.4682, average train loss: 71.0486
[09/25 22:36:51 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1584, average loss: 53.5146
[09/25 22:36:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 22:36:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 22:36:58 visual_prompt]: Epoch 43 / 100: avg data time: 6.10e-02, avg batch time: 0.4736, average train loss: 56.6190
[09/25 22:37:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 45.5234
[09/25 22:37:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 22:37:00 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 22:37:06 visual_prompt]: Epoch 44 / 100: avg data time: 5.51e-02, avg batch time: 0.4679, average train loss: 47.9422
[09/25 22:37:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 45.8070
[09/25 22:37:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/25 22:37:08 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 22:37:14 visual_prompt]: Epoch 45 / 100: avg data time: 6.31e-02, avg batch time: 0.4761, average train loss: 54.7498
[09/25 22:37:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 51.6076
[09/25 22:37:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 22:37:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 22:37:22 visual_prompt]: Epoch 46 / 100: avg data time: 6.02e-02, avg batch time: 0.4741, average train loss: 51.2945
[09/25 22:37:24 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1581, average loss: 53.8129
[09/25 22:37:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:37:24 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 22:37:30 visual_prompt]: Epoch 47 / 100: avg data time: 5.90e-02, avg batch time: 0.4707, average train loss: 48.1695
[09/25 22:37:32 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1577, average loss: 57.3679
[09/25 22:37:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 22:37:32 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 22:37:38 visual_prompt]: Epoch 48 / 100: avg data time: 5.96e-02, avg batch time: 0.4722, average train loss: 53.7918
[09/25 22:37:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 56.9605
[09/25 22:37:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:37:40 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 22:37:46 visual_prompt]: Epoch 49 / 100: avg data time: 6.81e-02, avg batch time: 0.4798, average train loss: 55.4764
[09/25 22:37:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1583, average loss: 52.0215
[09/25 22:37:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:37:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 22:37:54 visual_prompt]: Epoch 50 / 100: avg data time: 6.97e-02, avg batch time: 0.4821, average train loss: 51.3435
[09/25 22:37:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 46.3152
[09/25 22:37:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:37:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 22:38:02 visual_prompt]: Epoch 51 / 100: avg data time: 6.06e-02, avg batch time: 0.4729, average train loss: 47.8275
[09/25 22:38:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 40.8386
[09/25 22:38:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:38:04 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 22:38:10 visual_prompt]: Epoch 52 / 100: avg data time: 5.30e-02, avg batch time: 0.4672, average train loss: 50.0871
[09/25 22:38:12 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1577, average loss: 55.0585
[09/25 22:38:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.00	
[09/25 22:38:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 22:38:18 visual_prompt]: Epoch 53 / 100: avg data time: 5.98e-02, avg batch time: 0.4720, average train loss: 48.1745
[09/25 22:38:20 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 45.5292
[09/25 22:38:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/25 22:38:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 22:38:26 visual_prompt]: Epoch 54 / 100: avg data time: 5.21e-02, avg batch time: 0.4660, average train loss: 35.0559
[09/25 22:38:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 31.2725
[09/25 22:38:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/25 22:38:28 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 22:38:34 visual_prompt]: Epoch 55 / 100: avg data time: 4.54e-02, avg batch time: 0.4569, average train loss: 28.5026
[09/25 22:38:36 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 27.4559
[09/25 22:38:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 22:38:36 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 22:38:42 visual_prompt]: Epoch 56 / 100: avg data time: 6.21e-02, avg batch time: 0.4748, average train loss: 29.9006
[09/25 22:38:44 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 31.1707
[09/25 22:38:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 22:38:44 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 22:38:50 visual_prompt]: Epoch 57 / 100: avg data time: 6.25e-02, avg batch time: 0.4746, average train loss: 29.2253
[09/25 22:38:52 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1581, average loss: 26.6731
[09/25 22:38:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:38:52 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 22:38:58 visual_prompt]: Epoch 58 / 100: avg data time: 6.05e-02, avg batch time: 0.4726, average train loss: 22.6127
[09/25 22:39:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1581, average loss: 26.7095
[09/25 22:39:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:39:00 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 22:39:06 visual_prompt]: Epoch 59 / 100: avg data time: 5.97e-02, avg batch time: 0.4720, average train loss: 20.9861
[09/25 22:39:08 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 19.9920
[09/25 22:39:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/25 22:39:08 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 22:39:14 visual_prompt]: Epoch 60 / 100: avg data time: 5.69e-02, avg batch time: 0.4712, average train loss: 16.6377
[09/25 22:39:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 16.3304
[09/25 22:39:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:39:16 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 22:39:22 visual_prompt]: Epoch 61 / 100: avg data time: 4.65e-02, avg batch time: 0.4590, average train loss: 15.9930
[09/25 22:39:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1580, average loss: 17.6337
[09/25 22:39:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:39:24 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 22:39:30 visual_prompt]: Epoch 62 / 100: avg data time: 5.75e-02, avg batch time: 0.4702, average train loss: 17.0963
[09/25 22:39:32 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1578, average loss: 16.1897
[09/25 22:39:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:39:32 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 22:39:38 visual_prompt]: Epoch 63 / 100: avg data time: 5.64e-02, avg batch time: 0.4684, average train loss: 17.6459
[09/25 22:39:40 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1574, average loss: 18.6424
[09/25 22:39:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 22:39:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 22:39:46 visual_prompt]: Epoch 64 / 100: avg data time: 5.72e-02, avg batch time: 0.4685, average train loss: 19.2859
[09/25 22:39:48 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 16.2504
[09/25 22:39:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:39:48 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 22:39:54 visual_prompt]: Epoch 65 / 100: avg data time: 5.73e-02, avg batch time: 0.4693, average train loss: 16.9373
[09/25 22:39:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1586, average loss: 16.5931
[09/25 22:39:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 22:39:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 22:40:02 visual_prompt]: Epoch 66 / 100: avg data time: 5.42e-02, avg batch time: 0.4668, average train loss: 13.0529
[09/25 22:40:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1584, average loss: 12.1246
[09/25 22:40:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:40:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 22:40:10 visual_prompt]: Epoch 67 / 100: avg data time: 4.37e-02, avg batch time: 0.4579, average train loss: 11.5634
[09/25 22:40:12 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1584, average loss: 13.5964
[09/25 22:40:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:40:12 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 22:40:18 visual_prompt]: Epoch 68 / 100: avg data time: 6.31e-02, avg batch time: 0.4762, average train loss: 10.9416
[09/25 22:40:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 11.4178
[09/25 22:40:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 3.00	
[09/25 22:40:20 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 22:40:26 visual_prompt]: Epoch 69 / 100: avg data time: 4.28e-02, avg batch time: 0.4574, average train loss: 9.4430
[09/25 22:40:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 11.9360
[09/25 22:40:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 22:40:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 22:40:34 visual_prompt]: Epoch 70 / 100: avg data time: 6.39e-02, avg batch time: 0.4774, average train loss: 8.4723
[09/25 22:40:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 8.8495
[09/25 22:40:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:40:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 22:40:42 visual_prompt]: Epoch 71 / 100: avg data time: 6.25e-02, avg batch time: 0.4747, average train loss: 7.0985
[09/25 22:40:44 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1578, average loss: 8.0826
[09/25 22:40:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.50	
[09/25 22:40:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 22:40:50 visual_prompt]: Epoch 72 / 100: avg data time: 6.28e-02, avg batch time: 0.4752, average train loss: 6.6360
[09/25 22:40:52 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1582, average loss: 7.9780
[09/25 22:40:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 22:40:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 22:40:58 visual_prompt]: Epoch 73 / 100: avg data time: 5.98e-02, avg batch time: 0.4722, average train loss: 6.5029
[09/25 22:41:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 7.7095
[09/25 22:41:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:41:00 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 22:41:06 visual_prompt]: Epoch 74 / 100: avg data time: 5.13e-02, avg batch time: 0.4627, average train loss: 6.3354
[09/25 22:41:08 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1578, average loss: 7.2164
[09/25 22:41:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:41:08 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 22:41:14 visual_prompt]: Epoch 75 / 100: avg data time: 6.20e-02, avg batch time: 0.4731, average train loss: 6.1232
[09/25 22:41:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 6.9736
[09/25 22:41:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:41:16 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 22:41:22 visual_prompt]: Epoch 76 / 100: avg data time: 4.97e-02, avg batch time: 0.4635, average train loss: 5.9476
[09/25 22:41:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 6.8069
[09/25 22:41:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 22:41:24 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 22:41:30 visual_prompt]: Epoch 77 / 100: avg data time: 5.87e-02, avg batch time: 0.4701, average train loss: 5.9010
[09/25 22:41:32 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1585, average loss: 6.5554
[09/25 22:41:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:41:32 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 22:41:38 visual_prompt]: Epoch 78 / 100: avg data time: 6.06e-02, avg batch time: 0.4733, average train loss: 5.7106
[09/25 22:41:40 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1575, average loss: 6.5707
[09/25 22:41:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:41:40 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 22:41:46 visual_prompt]: Epoch 79 / 100: avg data time: 5.65e-02, avg batch time: 0.4673, average train loss: 5.6912
[09/25 22:41:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1585, average loss: 6.3039
[09/25 22:41:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.50	
[09/25 22:41:48 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 22:41:54 visual_prompt]: Epoch 80 / 100: avg data time: 5.90e-02, avg batch time: 0.4709, average train loss: 5.5233
[09/25 22:41:56 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1581, average loss: 6.0294
[09/25 22:41:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:41:56 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 22:42:02 visual_prompt]: Epoch 81 / 100: avg data time: 4.78e-02, avg batch time: 0.4601, average train loss: 5.4579
[09/25 22:42:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1577, average loss: 6.1199
[09/25 22:42:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 1.50	
[09/25 22:42:04 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 22:42:10 visual_prompt]: Epoch 82 / 100: avg data time: 5.99e-02, avg batch time: 0.4720, average train loss: 5.4100
[09/25 22:42:12 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 6.0024
[09/25 22:42:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 22:42:12 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 22:42:18 visual_prompt]: Epoch 83 / 100: avg data time: 6.05e-02, avg batch time: 0.4729, average train loss: 5.4178
[09/25 22:42:20 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1578, average loss: 5.7574
[09/25 22:42:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:42:20 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 22:42:26 visual_prompt]: Epoch 84 / 100: avg data time: 6.39e-02, avg batch time: 0.4750, average train loss: 5.2254
[09/25 22:42:28 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1578, average loss: 5.5446
[09/25 22:42:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 22:42:28 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 22:42:34 visual_prompt]: Epoch 85 / 100: avg data time: 6.00e-02, avg batch time: 0.4713, average train loss: 5.1318
[09/25 22:42:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 5.2844
[09/25 22:42:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:42:36 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 22:42:42 visual_prompt]: Epoch 86 / 100: avg data time: 5.89e-02, avg batch time: 0.4713, average train loss: 5.1174
[09/25 22:42:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 5.6179
[09/25 22:42:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 22:42:44 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 22:42:50 visual_prompt]: Epoch 87 / 100: avg data time: 5.54e-02, avg batch time: 0.4697, average train loss: 5.1281
[09/25 22:42:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 5.1700
[09/25 22:42:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/25 22:42:52 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 22:42:58 visual_prompt]: Epoch 88 / 100: avg data time: 6.17e-02, avg batch time: 0.4734, average train loss: 4.9829
[09/25 22:43:00 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1582, average loss: 5.4256
[09/25 22:43:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:43:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 22:43:06 visual_prompt]: Epoch 89 / 100: avg data time: 5.63e-02, avg batch time: 0.4695, average train loss: 5.0397
[09/25 22:43:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 5.3803
[09/25 22:43:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:43:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 22:43:14 visual_prompt]: Epoch 90 / 100: avg data time: 5.05e-02, avg batch time: 0.4625, average train loss: 4.9594
[09/25 22:43:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 5.0950
[09/25 22:43:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:43:16 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 22:43:22 visual_prompt]: Epoch 91 / 100: avg data time: 6.04e-02, avg batch time: 0.4726, average train loss: 4.8305
[09/25 22:43:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1579, average loss: 4.8020
[09/25 22:43:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.50	
[09/25 22:43:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 22:43:30 visual_prompt]: Epoch 92 / 100: avg data time: 6.29e-02, avg batch time: 0.4746, average train loss: 4.7852
[09/25 22:43:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1582, average loss: 4.7419
[09/25 22:43:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.00	
[09/25 22:43:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 22:43:38 visual_prompt]: Epoch 93 / 100: avg data time: 5.25e-02, avg batch time: 0.4651, average train loss: 4.7252
[09/25 22:43:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1578, average loss: 4.7225
[09/25 22:43:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:43:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 22:43:46 visual_prompt]: Epoch 94 / 100: avg data time: 5.26e-02, avg batch time: 0.4654, average train loss: 4.6693
[09/25 22:43:48 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1586, average loss: 4.6847
[09/25 22:43:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:43:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 22:43:54 visual_prompt]: Epoch 95 / 100: avg data time: 6.30e-02, avg batch time: 0.4744, average train loss: 4.6070
[09/25 22:43:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 4.6718
[09/25 22:43:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/25 22:43:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 22:44:02 visual_prompt]: Epoch 96 / 100: avg data time: 5.98e-02, avg batch time: 0.4717, average train loss: 4.5622
[09/25 22:44:04 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 4.5917
[09/25 22:44:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.50	
[09/25 22:44:04 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 22:44:10 visual_prompt]: Epoch 97 / 100: avg data time: 5.19e-02, avg batch time: 0.4655, average train loss: 4.4988
[09/25 22:44:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 4.6063
[09/25 22:44:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.50	
[09/25 22:44:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 22:44:18 visual_prompt]: Epoch 98 / 100: avg data time: 5.16e-02, avg batch time: 0.4652, average train loss: 4.4453
[09/25 22:44:20 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 4.5320
[09/25 22:44:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.00	
[09/25 22:44:20 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 22:44:26 visual_prompt]: Epoch 99 / 100: avg data time: 5.93e-02, avg batch time: 0.4712, average train loss: 4.3996
[09/25 22:44:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1580, average loss: 4.5093
[09/25 22:44:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 10.00	
[09/25 22:44:28 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 22:44:34 visual_prompt]: Epoch 100 / 100: avg data time: 6.57e-02, avg batch time: 0.4774, average train loss: 4.3726
[09/25 22:44:36 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1580, average loss: 4.5280
[09/25 22:44:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.50	
[09/25 22:44:36 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:44:36 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:44:36 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:44:36 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:44:36 visual_prompt]: Training with config:
[09/25 22:44:36 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:44:36 visual_prompt]: Loading training data...
[09/25 22:44:36 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:44:37 visual_prompt]: Number of images: 800
[09/25 22:44:37 visual_prompt]: Number of classes: 102 / 102
[09/25 22:44:37 visual_prompt]: Loading validation data...
[09/25 22:44:37 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:44:37 visual_prompt]: Number of images: 200
[09/25 22:44:37 visual_prompt]: Number of classes: 91 / 102
[09/25 22:44:37 visual_prompt]: Constructing models...
[09/25 22:44:40 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 22:44:40 visual_prompt]: tuned percent:0.625
[09/25 22:44:40 visual_prompt]: Device used for model: 0
[09/25 22:44:40 visual_prompt]: Setting up Evaluator...
[09/25 22:44:40 visual_prompt]: Setting up Trainer...
[09/25 22:44:40 visual_prompt]: 	Setting up the optimizer...
[09/25 22:44:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:44:46 visual_prompt]: Epoch 1 / 100: avg data time: 5.91e-02, avg batch time: 0.4758, average train loss: 4.6716
[09/25 22:44:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1579, average loss: 4.6780
[09/25 22:44:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:44:48 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:44:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 22:44:54 visual_prompt]: Epoch 2 / 100: avg data time: 6.35e-02, avg batch time: 0.4751, average train loss: 4.7695
[09/25 22:44:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1583, average loss: 4.8746
[09/25 22:44:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 22:44:56 visual_prompt]: Best epoch 2: best metric: 0.020
[09/25 22:44:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 22:45:02 visual_prompt]: Epoch 3 / 100: avg data time: 5.56e-02, avg batch time: 0.4673, average train loss: 5.1501
[09/25 22:45:04 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 5.2339
[09/25 22:45:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 22:45:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 22:45:10 visual_prompt]: Epoch 4 / 100: avg data time: 5.74e-02, avg batch time: 0.4706, average train loss: 5.1476
[09/25 22:45:12 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1583, average loss: 4.8549
[09/25 22:45:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 15.00	
[09/25 22:45:12 visual_prompt]: Best epoch 4: best metric: 0.045
[09/25 22:45:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 22:45:18 visual_prompt]: Epoch 5 / 100: avg data time: 4.51e-02, avg batch time: 0.4578, average train loss: 4.9648
[09/25 22:45:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1590, average loss: 3.8463
[09/25 22:45:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 27.50	top5: 47.50	
[09/25 22:45:20 visual_prompt]: Best epoch 5: best metric: 0.275
[09/25 22:45:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 22:45:26 visual_prompt]: Epoch 6 / 100: avg data time: 5.86e-02, avg batch time: 0.4715, average train loss: 7.4234
[09/25 22:45:28 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1581, average loss: 10.0002
[09/25 22:45:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 10.00	
[09/25 22:45:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 22:45:34 visual_prompt]: Epoch 7 / 100: avg data time: 6.45e-02, avg batch time: 0.4775, average train loss: 7.7744
[09/25 22:45:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1579, average loss: 7.6948
[09/25 22:45:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 16.50	top5: 40.00	
[09/25 22:45:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 22:45:42 visual_prompt]: Epoch 8 / 100: avg data time: 5.48e-02, avg batch time: 0.4670, average train loss: 7.5065
[09/25 22:45:44 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 10.4549
[09/25 22:45:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 20.00	top5: 39.00	
[09/25 22:45:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 22:45:50 visual_prompt]: Epoch 9 / 100: avg data time: 5.97e-02, avg batch time: 0.4723, average train loss: 8.5617
[09/25 22:45:52 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1580, average loss: 8.0389
[09/25 22:45:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 45.50	top5: 67.50	
[09/25 22:45:52 visual_prompt]: Best epoch 9: best metric: 0.455
[09/25 22:45:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 22:45:58 visual_prompt]: Epoch 10 / 100: avg data time: 5.02e-02, avg batch time: 0.4632, average train loss: 5.9518
[09/25 22:46:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 5.9961
[09/25 22:46:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 44.50	top5: 68.50	
[09/25 22:46:00 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 22:46:07 visual_prompt]: Epoch 11 / 100: avg data time: 6.48e-02, avg batch time: 0.4781, average train loss: 6.8004
[09/25 22:46:08 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1580, average loss: 8.9534
[09/25 22:46:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 19.50	top5: 45.50	
[09/25 22:46:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 22:46:15 visual_prompt]: Epoch 12 / 100: avg data time: 6.39e-02, avg batch time: 0.4766, average train loss: 7.9684
[09/25 22:46:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 10.2543
[09/25 22:46:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 32.50	top5: 52.00	
[09/25 22:46:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 22:46:23 visual_prompt]: Epoch 13 / 100: avg data time: 4.38e-02, avg batch time: 0.4599, average train loss: 5.7255
[09/25 22:46:24 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 6.9355
[09/25 22:46:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 42.50	top5: 72.50	
[09/25 22:46:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 22:46:31 visual_prompt]: Epoch 14 / 100: avg data time: 5.96e-02, avg batch time: 0.4723, average train loss: 6.3214
[09/25 22:46:32 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1581, average loss: 10.0098
[09/25 22:46:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 37.00	top5: 66.00	
[09/25 22:46:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 22:46:39 visual_prompt]: Epoch 15 / 100: avg data time: 5.96e-02, avg batch time: 0.4724, average train loss: 4.5955
[09/25 22:46:40 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1582, average loss: 13.5772
[09/25 22:46:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 37.50	top5: 64.50	
[09/25 22:46:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 22:46:47 visual_prompt]: Epoch 16 / 100: avg data time: 6.25e-02, avg batch time: 0.4761, average train loss: 3.2566
[09/25 22:46:48 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1584, average loss: 6.9337
[09/25 22:46:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 53.00	top5: 80.00	
[09/25 22:46:48 visual_prompt]: Best epoch 16: best metric: 0.530
[09/25 22:46:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 22:46:55 visual_prompt]: Epoch 17 / 100: avg data time: 4.52e-02, avg batch time: 0.4601, average train loss: 1.9458
[09/25 22:46:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1587, average loss: 4.4067
[09/25 22:46:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 50.50	top5: 73.00	
[09/25 22:46:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 22:47:03 visual_prompt]: Epoch 18 / 100: avg data time: 6.03e-02, avg batch time: 0.4729, average train loss: 1.3174
[09/25 22:47:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1585, average loss: 3.8997
[09/25 22:47:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.00	top5: 86.00	
[09/25 22:47:04 visual_prompt]: Best epoch 18: best metric: 0.640
[09/25 22:47:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 22:47:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.86e-02, avg batch time: 0.4726, average train loss: 1.5906
[09/25 22:47:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 1.9668
[09/25 22:47:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.50	top5: 86.00	
[09/25 22:47:12 visual_prompt]: Best epoch 19: best metric: 0.715
[09/25 22:47:12 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 22:47:19 visual_prompt]: Epoch 20 / 100: avg data time: 5.77e-02, avg batch time: 0.4713, average train loss: 1.3347
[09/25 22:47:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1581, average loss: 3.6910
[09/25 22:47:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 81.50	
[09/25 22:47:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 22:47:27 visual_prompt]: Epoch 21 / 100: avg data time: 6.52e-02, avg batch time: 0.4794, average train loss: 5.3341
[09/25 22:47:29 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 12.0474
[09/25 22:47:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.50	top5: 28.00	
[09/25 22:47:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 22:47:35 visual_prompt]: Epoch 22 / 100: avg data time: 5.55e-02, avg batch time: 0.4682, average train loss: 26.8383
[09/25 22:47:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 37.8337
[09/25 22:47:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 22:47:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 22:47:43 visual_prompt]: Epoch 23 / 100: avg data time: 6.16e-02, avg batch time: 0.4746, average train loss: 61.2808
[09/25 22:47:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1583, average loss: 56.3160
[09/25 22:47:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:47:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 22:47:51 visual_prompt]: Epoch 24 / 100: avg data time: 5.24e-02, avg batch time: 0.4662, average train loss: 78.4093
[09/25 22:47:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1583, average loss: 142.3486
[09/25 22:47:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:47:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 22:47:59 visual_prompt]: Epoch 25 / 100: avg data time: 5.60e-02, avg batch time: 0.4698, average train loss: 116.7565
[09/25 22:48:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 104.0512
[09/25 22:48:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:48:01 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 22:48:07 visual_prompt]: Epoch 26 / 100: avg data time: 5.80e-02, avg batch time: 0.4707, average train loss: 121.4583
[09/25 22:48:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1585, average loss: 150.6647
[09/25 22:48:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:48:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 22:48:15 visual_prompt]: Epoch 27 / 100: avg data time: 4.54e-02, avg batch time: 0.4605, average train loss: 135.6519
[09/25 22:48:17 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1583, average loss: 139.4959
[09/25 22:48:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 22:48:17 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 22:48:23 visual_prompt]: Epoch 28 / 100: avg data time: 5.59e-02, avg batch time: 0.4686, average train loss: 121.8616
[09/25 22:48:25 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1578, average loss: 105.3808
[09/25 22:48:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:48:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 22:48:31 visual_prompt]: Epoch 29 / 100: avg data time: 4.85e-02, avg batch time: 0.4618, average train loss: 103.4585
[09/25 22:48:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1576, average loss: 99.6171
[09/25 22:48:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/25 22:48:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 22:48:39 visual_prompt]: Epoch 30 / 100: avg data time: 6.53e-02, avg batch time: 0.4777, average train loss: 117.8283
[09/25 22:48:41 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1578, average loss: 96.9731
[09/25 22:48:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:48:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 22:48:47 visual_prompt]: Epoch 31 / 100: avg data time: 5.72e-02, avg batch time: 0.4702, average train loss: 111.9434
[09/25 22:48:49 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1585, average loss: 122.4209
[09/25 22:48:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:48:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 22:48:55 visual_prompt]: Epoch 32 / 100: avg data time: 6.22e-02, avg batch time: 0.4750, average train loss: 89.9803
[09/25 22:48:57 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1581, average loss: 81.9581
[09/25 22:48:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/25 22:48:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 22:49:03 visual_prompt]: Epoch 33 / 100: avg data time: 5.62e-02, avg batch time: 0.4682, average train loss: 112.8942
[09/25 22:49:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 127.4767
[09/25 22:49:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:49:05 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 22:49:11 visual_prompt]: Epoch 34 / 100: avg data time: 6.04e-02, avg batch time: 0.4738, average train loss: 114.0025
[09/25 22:49:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1584, average loss: 97.0179
[09/25 22:49:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:49:13 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 22:49:19 visual_prompt]: Epoch 35 / 100: avg data time: 5.63e-02, avg batch time: 0.4693, average train loss: 109.6462
[09/25 22:49:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1578, average loss: 104.3822
[09/25 22:49:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:49:21 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 22:49:27 visual_prompt]: Epoch 36 / 100: avg data time: 5.40e-02, avg batch time: 0.4670, average train loss: 110.7145
[09/25 22:49:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 91.8845
[09/25 22:49:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 22:49:29 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 22:49:35 visual_prompt]: Epoch 37 / 100: avg data time: 5.87e-02, avg batch time: 0.4714, average train loss: 90.0759
[09/25 22:49:37 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1591, average loss: 86.7796
[09/25 22:49:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:49:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 22:49:43 visual_prompt]: Epoch 38 / 100: avg data time: 5.45e-02, avg batch time: 0.4680, average train loss: 86.7280
[09/25 22:49:45 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1578, average loss: 75.1681
[09/25 22:49:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:49:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 22:49:51 visual_prompt]: Epoch 39 / 100: avg data time: 6.00e-02, avg batch time: 0.4722, average train loss: 78.8465
[09/25 22:49:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 70.8841
[09/25 22:49:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 22:49:53 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 22:49:59 visual_prompt]: Epoch 40 / 100: avg data time: 5.84e-02, avg batch time: 0.4707, average train loss: 78.0971
[09/25 22:50:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 88.1512
[09/25 22:50:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 22:50:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 22:50:08 visual_prompt]: Epoch 41 / 100: avg data time: 5.94e-02, avg batch time: 0.4724, average train loss: 89.2684
[09/25 22:50:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1585, average loss: 79.3591
[09/25 22:50:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 22:50:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 22:50:16 visual_prompt]: Epoch 42 / 100: avg data time: 6.25e-02, avg batch time: 0.4746, average train loss: 76.5000
[09/25 22:50:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 81.8384
[09/25 22:50:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:50:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 22:50:24 visual_prompt]: Epoch 43 / 100: avg data time: 5.89e-02, avg batch time: 0.4719, average train loss: 71.2788
[09/25 22:50:25 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1582, average loss: 63.9232
[09/25 22:50:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:50:25 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 22:50:32 visual_prompt]: Epoch 44 / 100: avg data time: 5.02e-02, avg batch time: 0.4633, average train loss: 65.7381
[09/25 22:50:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 65.3146
[09/25 22:50:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 22:50:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 22:50:40 visual_prompt]: Epoch 45 / 100: avg data time: 6.21e-02, avg batch time: 0.4758, average train loss: 64.8866
[09/25 22:50:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 60.3241
[09/25 22:50:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 22:50:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 22:50:48 visual_prompt]: Epoch 46 / 100: avg data time: 5.56e-02, avg batch time: 0.4678, average train loss: 69.8105
[09/25 22:50:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1589, average loss: 71.8121
[09/25 22:50:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/25 22:50:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 22:50:56 visual_prompt]: Epoch 47 / 100: avg data time: 5.77e-02, avg batch time: 0.4728, average train loss: 82.9003
[09/25 22:50:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 81.6453
[09/25 22:50:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 22:50:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 22:51:03 visual_prompt]: Epoch 48 / 100: avg data time: 4.30e-02, avg batch time: 0.4583, average train loss: 89.6683
[09/25 22:51:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 75.1494
[09/25 22:51:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 22:51:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 22:51:12 visual_prompt]: Epoch 49 / 100: avg data time: 6.35e-02, avg batch time: 0.4766, average train loss: 70.0674
[09/25 22:51:13 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 54.0756
[09/25 22:51:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 22:51:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 22:51:20 visual_prompt]: Epoch 50 / 100: avg data time: 5.89e-02, avg batch time: 0.4709, average train loss: 51.9805
[09/25 22:51:21 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1581, average loss: 43.5503
[09/25 22:51:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:51:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 22:51:28 visual_prompt]: Epoch 51 / 100: avg data time: 6.25e-02, avg batch time: 0.4752, average train loss: 46.5281
[09/25 22:51:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 41.9364
[09/25 22:51:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/25 22:51:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 22:51:36 visual_prompt]: Epoch 52 / 100: avg data time: 6.20e-02, avg batch time: 0.4741, average train loss: 43.8152
[09/25 22:51:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1575, average loss: 35.4372
[09/25 22:51:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 22:51:37 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 22:51:44 visual_prompt]: Epoch 53 / 100: avg data time: 4.56e-02, avg batch time: 0.4605, average train loss: 33.2287
[09/25 22:51:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 31.9917
[09/25 22:51:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 22:51:45 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 22:51:52 visual_prompt]: Epoch 54 / 100: avg data time: 5.58e-02, avg batch time: 0.4693, average train loss: 28.3383
[09/25 22:51:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 22.8533
[09/25 22:51:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 22:51:53 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 22:52:00 visual_prompt]: Epoch 55 / 100: avg data time: 4.88e-02, avg batch time: 0.4628, average train loss: 22.3352
[09/25 22:52:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 16.6945
[09/25 22:52:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 1.50	
[09/25 22:52:01 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 22:52:08 visual_prompt]: Epoch 56 / 100: avg data time: 5.90e-02, avg batch time: 0.4715, average train loss: 14.4168
[09/25 22:52:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1584, average loss: 11.1929
[09/25 22:52:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 22:52:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 22:52:16 visual_prompt]: Epoch 57 / 100: avg data time: 6.60e-02, avg batch time: 0.4785, average train loss: 10.9189
[09/25 22:52:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1580, average loss: 9.4623
[09/25 22:52:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 22:52:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 22:52:24 visual_prompt]: Epoch 58 / 100: avg data time: 6.36e-02, avg batch time: 0.4769, average train loss: 8.6184
[09/25 22:52:25 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1580, average loss: 7.5721
[09/25 22:52:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/25 22:52:25 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 22:52:32 visual_prompt]: Epoch 59 / 100: avg data time: 6.96e-02, avg batch time: 0.4824, average train loss: 6.9109
[09/25 22:52:34 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1581, average loss: 6.1136
[09/25 22:52:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 22:52:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 22:52:40 visual_prompt]: Epoch 60 / 100: avg data time: 5.93e-02, avg batch time: 0.4720, average train loss: 6.1936
[09/25 22:52:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1583, average loss: 5.8198
[09/25 22:52:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:52:42 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 22:52:48 visual_prompt]: Epoch 61 / 100: avg data time: 5.75e-02, avg batch time: 0.4707, average train loss: 5.8001
[09/25 22:52:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1581, average loss: 5.7907
[09/25 22:52:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.00	
[09/25 22:52:50 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 22:52:56 visual_prompt]: Epoch 62 / 100: avg data time: 6.18e-02, avg batch time: 0.4746, average train loss: 5.7721
[09/25 22:52:58 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 6.0461
[09/25 22:52:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 22:52:58 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 22:53:04 visual_prompt]: Epoch 63 / 100: avg data time: 5.88e-02, avg batch time: 0.4716, average train loss: 6.0228
[09/25 22:53:06 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1580, average loss: 5.8757
[09/25 22:53:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 9.50	
[09/25 22:53:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 22:53:12 visual_prompt]: Epoch 64 / 100: avg data time: 5.66e-02, avg batch time: 0.4688, average train loss: 5.6612
[09/25 22:53:14 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 5.3946
[09/25 22:53:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 22:53:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 22:53:20 visual_prompt]: Epoch 65 / 100: avg data time: 4.48e-02, avg batch time: 0.4592, average train loss: 5.5497
[09/25 22:53:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 5.2917
[09/25 22:53:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 22:53:22 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 22:53:28 visual_prompt]: Epoch 66 / 100: avg data time: 6.44e-02, avg batch time: 0.4771, average train loss: 5.3070
[09/25 22:53:30 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1579, average loss: 5.1565
[09/25 22:53:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 9.00	
[09/25 22:53:30 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 22:53:36 visual_prompt]: Epoch 67 / 100: avg data time: 6.08e-02, avg batch time: 0.4733, average train loss: 5.1008
[09/25 22:53:38 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 5.0815
[09/25 22:53:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 9.00	
[09/25 22:53:38 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 22:53:44 visual_prompt]: Epoch 68 / 100: avg data time: 6.71e-02, avg batch time: 0.4791, average train loss: 5.0497
[09/25 22:53:46 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1578, average loss: 5.4012
[09/25 22:53:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 8.50	
[09/25 22:53:46 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 22:53:53 visual_prompt]: Epoch 69 / 100: avg data time: 6.04e-02, avg batch time: 0.4727, average train loss: 5.1337
[09/25 22:53:54 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 5.2209
[09/25 22:53:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 10.00	
[09/25 22:53:54 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 22:54:01 visual_prompt]: Epoch 70 / 100: avg data time: 5.57e-02, avg batch time: 0.4687, average train loss: 4.8705
[09/25 22:54:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 5.1868
[09/25 22:54:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 11.50	
[09/25 22:54:02 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 22:54:09 visual_prompt]: Epoch 71 / 100: avg data time: 6.21e-02, avg batch time: 0.4739, average train loss: 4.7173
[09/25 22:54:10 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1574, average loss: 4.9035
[09/25 22:54:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 20.00	
[09/25 22:54:10 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 22:54:17 visual_prompt]: Epoch 72 / 100: avg data time: 5.24e-02, avg batch time: 0.4642, average train loss: 4.4950
[09/25 22:54:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 5.3652
[09/25 22:54:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 15.00	
[09/25 22:54:18 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 22:54:25 visual_prompt]: Epoch 73 / 100: avg data time: 5.70e-02, avg batch time: 0.4713, average train loss: 4.4288
[09/25 22:54:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 4.9963
[09/25 22:54:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 11.00	
[09/25 22:54:26 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 22:54:33 visual_prompt]: Epoch 74 / 100: avg data time: 6.16e-02, avg batch time: 0.4740, average train loss: 4.2639
[09/25 22:54:34 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1576, average loss: 4.3903
[09/25 22:54:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.50	top5: 23.50	
[09/25 22:54:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 22:54:41 visual_prompt]: Epoch 75 / 100: avg data time: 6.55e-02, avg batch time: 0.4777, average train loss: 3.7099
[09/25 22:54:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1582, average loss: 4.3436
[09/25 22:54:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.00	top5: 27.50	
[09/25 22:54:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 22:54:49 visual_prompt]: Epoch 76 / 100: avg data time: 6.44e-02, avg batch time: 0.4773, average train loss: 3.2116
[09/25 22:54:50 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1575, average loss: 4.1978
[09/25 22:54:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 16.50	top5: 39.00	
[09/25 22:54:50 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 22:54:57 visual_prompt]: Epoch 77 / 100: avg data time: 6.12e-02, avg batch time: 0.4748, average train loss: 3.2321
[09/25 22:54:58 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1576, average loss: 4.0011
[09/25 22:54:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 20.50	top5: 46.00	
[09/25 22:54:58 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 22:55:05 visual_prompt]: Epoch 78 / 100: avg data time: 5.88e-02, avg batch time: 0.4708, average train loss: 2.3107
[09/25 22:55:06 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1578, average loss: 3.5439
[09/25 22:55:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 27.50	top5: 55.50	
[09/25 22:55:06 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 22:55:13 visual_prompt]: Epoch 79 / 100: avg data time: 6.07e-02, avg batch time: 0.4753, average train loss: 1.4258
[09/25 22:55:15 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1581, average loss: 3.5998
[09/25 22:55:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 35.50	top5: 58.50	
[09/25 22:55:15 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 22:55:21 visual_prompt]: Epoch 80 / 100: avg data time: 6.79e-02, avg batch time: 0.4800, average train loss: 0.9819
[09/25 22:55:23 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1579, average loss: 2.9403
[09/25 22:55:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 39.00	top5: 72.50	
[09/25 22:55:23 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 22:55:29 visual_prompt]: Epoch 81 / 100: avg data time: 4.68e-02, avg batch time: 0.4619, average train loss: 0.5577
[09/25 22:55:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 2.9807
[09/25 22:55:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 46.50	top5: 76.50	
[09/25 22:55:31 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 22:55:37 visual_prompt]: Epoch 82 / 100: avg data time: 6.16e-02, avg batch time: 0.4736, average train loss: 0.2912
[09/25 22:55:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 2.5736
[09/25 22:55:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 55.00	top5: 79.00	
[09/25 22:55:39 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 22:55:45 visual_prompt]: Epoch 83 / 100: avg data time: 6.11e-02, avg batch time: 0.4746, average train loss: 0.1524
[09/25 22:55:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1582, average loss: 2.1471
[09/25 22:55:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 55.00	top5: 79.00	
[09/25 22:55:47 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 22:55:53 visual_prompt]: Epoch 84 / 100: avg data time: 6.40e-02, avg batch time: 0.4759, average train loss: 0.0825
[09/25 22:55:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 1.9945
[09/25 22:55:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.50	top5: 83.00	
[09/25 22:55:55 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 22:56:01 visual_prompt]: Epoch 85 / 100: avg data time: 6.38e-02, avg batch time: 0.4771, average train loss: 0.0378
[09/25 22:56:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1581, average loss: 2.1571
[09/25 22:56:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.00	top5: 82.50	
[09/25 22:56:03 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 22:56:09 visual_prompt]: Epoch 86 / 100: avg data time: 6.03e-02, avg batch time: 0.4728, average train loss: 0.0213
[09/25 22:56:11 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1578, average loss: 2.0632
[09/25 22:56:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.50	top5: 83.50	
[09/25 22:56:11 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 22:56:17 visual_prompt]: Epoch 87 / 100: avg data time: 4.88e-02, avg batch time: 0.4651, average train loss: 0.0132
[09/25 22:56:19 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 2.0681
[09/25 22:56:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 82.50	
[09/25 22:56:19 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 22:56:25 visual_prompt]: Epoch 88 / 100: avg data time: 6.00e-02, avg batch time: 0.4722, average train loss: 0.0139
[09/25 22:56:27 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1584, average loss: 1.9809
[09/25 22:56:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.50	top5: 83.00	
[09/25 22:56:27 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 22:56:34 visual_prompt]: Epoch 89 / 100: avg data time: 6.20e-02, avg batch time: 0.4739, average train loss: 0.0052
[09/25 22:56:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1579, average loss: 1.9038
[09/25 22:56:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 84.00	
[09/25 22:56:35 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 22:56:42 visual_prompt]: Epoch 90 / 100: avg data time: 5.97e-02, avg batch time: 0.4732, average train loss: 0.0067
[09/25 22:56:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 1.8868
[09/25 22:56:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.00	top5: 84.50	
[09/25 22:56:43 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 22:56:50 visual_prompt]: Epoch 91 / 100: avg data time: 6.27e-02, avg batch time: 0.4769, average train loss: 0.0042
[09/25 22:56:51 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1586, average loss: 1.8938
[09/25 22:56:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 84.00	
[09/25 22:56:51 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 22:56:58 visual_prompt]: Epoch 92 / 100: avg data time: 6.40e-02, avg batch time: 0.4762, average train loss: 0.0036
[09/25 22:56:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1577, average loss: 1.8766
[09/25 22:56:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 84.00	
[09/25 22:56:59 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 22:57:06 visual_prompt]: Epoch 93 / 100: avg data time: 5.70e-02, avg batch time: 0.4704, average train loss: 0.0039
[09/25 22:57:07 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1582, average loss: 1.8638
[09/25 22:57:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 84.00	
[09/25 22:57:07 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 22:57:14 visual_prompt]: Epoch 94 / 100: avg data time: 5.76e-02, avg batch time: 0.4711, average train loss: 0.0035
[09/25 22:57:15 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1576, average loss: 1.8568
[09/25 22:57:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:57:15 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 22:57:22 visual_prompt]: Epoch 95 / 100: avg data time: 6.31e-02, avg batch time: 0.4754, average train loss: 0.0036
[09/25 22:57:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 1.8512
[09/25 22:57:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:57:24 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 22:57:30 visual_prompt]: Epoch 96 / 100: avg data time: 4.87e-02, avg batch time: 0.4650, average train loss: 0.0039
[09/25 22:57:32 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1583, average loss: 1.8482
[09/25 22:57:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:57:32 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 22:57:38 visual_prompt]: Epoch 97 / 100: avg data time: 5.32e-02, avg batch time: 0.4688, average train loss: 0.0041
[09/25 22:57:40 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 1.8458
[09/25 22:57:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:57:40 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 22:57:46 visual_prompt]: Epoch 98 / 100: avg data time: 4.80e-02, avg batch time: 0.4608, average train loss: 0.0042
[09/25 22:57:48 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1577, average loss: 1.8413
[09/25 22:57:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:57:48 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 22:57:54 visual_prompt]: Epoch 99 / 100: avg data time: 6.01e-02, avg batch time: 0.4737, average train loss: 0.0038
[09/25 22:57:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 1.8402
[09/25 22:57:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:57:56 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 22:58:02 visual_prompt]: Epoch 100 / 100: avg data time: 6.04e-02, avg batch time: 0.4733, average train loss: 0.0036
[09/25 22:58:04 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 1.8401
[09/25 22:58:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 83.50	
[09/25 22:58:04 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:58:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:58:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:58:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:58:04 visual_prompt]: Training with config:
[09/25 22:58:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:58:04 visual_prompt]: Loading training data...
[09/25 22:58:04 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:58:05 visual_prompt]: Number of images: 800
[09/25 22:58:05 visual_prompt]: Number of classes: 102 / 102
[09/25 22:58:05 visual_prompt]: Loading validation data...
[09/25 22:58:05 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 22:58:05 visual_prompt]: Number of images: 200
[09/25 22:58:05 visual_prompt]: Number of classes: 91 / 102
[09/25 22:58:05 visual_prompt]: Constructing models...
[09/25 22:58:08 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 22:58:08 visual_prompt]: tuned percent:0.625
[09/25 22:58:08 visual_prompt]: Device used for model: 0
[09/25 22:58:08 visual_prompt]: Setting up Evaluator...
[09/25 22:58:08 visual_prompt]: Setting up Trainer...
[09/25 22:58:08 visual_prompt]: 	Setting up the optimizer...
[09/25 22:58:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:58:14 visual_prompt]: Epoch 1 / 100: avg data time: 5.39e-02, avg batch time: 0.4708, average train loss: 4.6718
[09/25 22:58:16 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1574, average loss: 4.6780
[09/25 22:58:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 22:58:16 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:58:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 22:58:22 visual_prompt]: Epoch 2 / 100: avg data time: 5.34e-02, avg batch time: 0.4661, average train loss: 4.7754
[09/25 22:58:24 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1581, average loss: 4.8340
[09/25 22:58:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.00	
[09/25 22:58:24 visual_prompt]: Best epoch 2: best metric: 0.020
[09/25 22:58:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 22:58:30 visual_prompt]: Epoch 3 / 100: avg data time: 6.15e-02, avg batch time: 0.4736, average train loss: 5.0646
[09/25 22:58:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 5.1057
[09/25 22:58:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 10.00	
[09/25 22:58:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 22:58:38 visual_prompt]: Epoch 4 / 100: avg data time: 5.23e-02, avg batch time: 0.4638, average train loss: 4.9067
[09/25 22:58:40 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 5.1270
[09/25 22:58:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.00	top5: 31.50	
[09/25 22:58:40 visual_prompt]: Best epoch 4: best metric: 0.110
[09/25 22:58:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 22:58:46 visual_prompt]: Epoch 5 / 100: avg data time: 4.43e-02, avg batch time: 0.4587, average train loss: 6.2949
[09/25 22:58:48 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1579, average loss: 9.1045
[09/25 22:58:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 14.50	top5: 31.50	
[09/25 22:58:48 visual_prompt]: Best epoch 5: best metric: 0.145
[09/25 22:58:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 22:58:54 visual_prompt]: Epoch 6 / 100: avg data time: 5.15e-02, avg batch time: 0.4661, average train loss: 15.5401
[09/25 22:58:56 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1579, average loss: 21.4693
[09/25 22:58:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 22:58:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 22:59:02 visual_prompt]: Epoch 7 / 100: avg data time: 6.16e-02, avg batch time: 0.4738, average train loss: 33.3592
[09/25 22:59:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 32.5496
[09/25 22:59:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.00	top5: 13.00	
[09/25 22:59:04 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 22:59:10 visual_prompt]: Epoch 8 / 100: avg data time: 6.57e-02, avg batch time: 0.4777, average train loss: 57.1940
[09/25 22:59:12 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1584, average loss: 74.9315
[09/25 22:59:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 22:59:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 22:59:18 visual_prompt]: Epoch 9 / 100: avg data time: 6.81e-02, avg batch time: 0.4801, average train loss: 87.7603
[09/25 22:59:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1580, average loss: 92.9407
[09/25 22:59:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 6.00	
[09/25 22:59:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 22:59:27 visual_prompt]: Epoch 10 / 100: avg data time: 6.13e-02, avg batch time: 0.4748, average train loss: 108.8172
[09/25 22:59:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 110.5835
[09/25 22:59:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 11.00	
[09/25 22:59:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 22:59:35 visual_prompt]: Epoch 11 / 100: avg data time: 6.26e-02, avg batch time: 0.4742, average train loss: 141.9298
[09/25 22:59:36 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1574, average loss: 149.7064
[09/25 22:59:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.50	
[09/25 22:59:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 22:59:43 visual_prompt]: Epoch 12 / 100: avg data time: 5.34e-02, avg batch time: 0.4664, average train loss: 187.0211
[09/25 22:59:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1581, average loss: 187.5925
[09/25 22:59:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 7.50	
[09/25 22:59:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 22:59:51 visual_prompt]: Epoch 13 / 100: avg data time: 5.36e-02, avg batch time: 0.4683, average train loss: 195.9999
[09/25 22:59:52 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 171.6702
[09/25 22:59:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/25 22:59:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 22:59:59 visual_prompt]: Epoch 14 / 100: avg data time: 6.16e-02, avg batch time: 0.4734, average train loss: 198.3253
[09/25 23:00:00 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1582, average loss: 213.9147
[09/25 23:00:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:00:00 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 23:00:07 visual_prompt]: Epoch 15 / 100: avg data time: 6.12e-02, avg batch time: 0.4734, average train loss: 205.6687
[09/25 23:00:08 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 180.5734
[09/25 23:00:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:00:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 23:00:15 visual_prompt]: Epoch 16 / 100: avg data time: 5.07e-02, avg batch time: 0.4636, average train loss: 189.2083
[09/25 23:00:16 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1584, average loss: 153.3195
[09/25 23:00:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.00	
[09/25 23:00:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 23:00:23 visual_prompt]: Epoch 17 / 100: avg data time: 5.91e-02, avg batch time: 0.4725, average train loss: 163.7011
[09/25 23:00:24 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1578, average loss: 156.5661
[09/25 23:00:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 13.00	
[09/25 23:00:24 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 23:00:31 visual_prompt]: Epoch 18 / 100: avg data time: 6.27e-02, avg batch time: 0.4759, average train loss: 151.2809
[09/25 23:00:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 125.1706
[09/25 23:00:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.00	top5: 13.50	
[09/25 23:00:32 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 23:00:39 visual_prompt]: Epoch 19 / 100: avg data time: 5.92e-02, avg batch time: 0.4725, average train loss: 115.8280
[09/25 23:00:41 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1581, average loss: 102.8364
[09/25 23:00:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.00	top5: 15.00	
[09/25 23:00:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 23:00:47 visual_prompt]: Epoch 20 / 100: avg data time: 5.57e-02, avg batch time: 0.4688, average train loss: 80.8814
[09/25 23:00:49 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1588, average loss: 64.0932
[09/25 23:00:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.50	top5: 19.00	
[09/25 23:00:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 23:00:55 visual_prompt]: Epoch 21 / 100: avg data time: 5.25e-02, avg batch time: 0.4660, average train loss: 50.0515
[09/25 23:00:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1580, average loss: 45.6137
[09/25 23:00:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 17.00	top5: 27.00	
[09/25 23:00:57 visual_prompt]: Best epoch 21: best metric: 0.170
[09/25 23:00:57 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 23:01:03 visual_prompt]: Epoch 22 / 100: avg data time: 6.10e-02, avg batch time: 0.4743, average train loss: 33.4484
[09/25 23:01:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1578, average loss: 33.6576
[09/25 23:01:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 20.50	top5: 36.00	
[09/25 23:01:05 visual_prompt]: Best epoch 22: best metric: 0.205
[09/25 23:01:05 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 23:01:11 visual_prompt]: Epoch 23 / 100: avg data time: 5.67e-02, avg batch time: 0.4702, average train loss: 21.6973
[09/25 23:01:13 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 22.3336
[09/25 23:01:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 23.50	top5: 39.50	
[09/25 23:01:13 visual_prompt]: Best epoch 23: best metric: 0.235
[09/25 23:01:13 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 23:01:19 visual_prompt]: Epoch 24 / 100: avg data time: 5.96e-02, avg batch time: 0.4726, average train loss: 14.5102
[09/25 23:01:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1579, average loss: 14.3891
[09/25 23:01:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 29.00	top5: 47.50	
[09/25 23:01:21 visual_prompt]: Best epoch 24: best metric: 0.290
[09/25 23:01:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 23:01:27 visual_prompt]: Epoch 25 / 100: avg data time: 5.90e-02, avg batch time: 0.4713, average train loss: 9.6758
[09/25 23:01:29 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 14.9601
[09/25 23:01:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 29.50	top5: 50.50	
[09/25 23:01:29 visual_prompt]: Best epoch 25: best metric: 0.295
[09/25 23:01:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 23:01:35 visual_prompt]: Epoch 26 / 100: avg data time: 6.63e-02, avg batch time: 0.4808, average train loss: 8.3062
[09/25 23:01:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1579, average loss: 11.1543
[09/25 23:01:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 36.00	top5: 60.00	
[09/25 23:01:37 visual_prompt]: Best epoch 26: best metric: 0.360
[09/25 23:01:37 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 23:01:44 visual_prompt]: Epoch 27 / 100: avg data time: 6.40e-02, avg batch time: 0.4770, average train loss: 7.4725
[09/25 23:01:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 9.5760
[09/25 23:01:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 39.50	top5: 65.50	
[09/25 23:01:45 visual_prompt]: Best epoch 27: best metric: 0.395
[09/25 23:01:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 23:01:52 visual_prompt]: Epoch 28 / 100: avg data time: 6.11e-02, avg batch time: 0.4744, average train loss: 4.9776
[09/25 23:01:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 7.4655
[09/25 23:01:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 43.50	top5: 73.00	
[09/25 23:01:53 visual_prompt]: Best epoch 28: best metric: 0.435
[09/25 23:01:53 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 23:02:00 visual_prompt]: Epoch 29 / 100: avg data time: 5.23e-02, avg batch time: 0.4663, average train loss: 3.3743
[09/25 23:02:01 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1581, average loss: 6.7495
[09/25 23:02:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 48.00	top5: 70.50	
[09/25 23:02:01 visual_prompt]: Best epoch 29: best metric: 0.480
[09/25 23:02:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 23:02:08 visual_prompt]: Epoch 30 / 100: avg data time: 4.95e-02, avg batch time: 0.4634, average train loss: 2.3599
[09/25 23:02:09 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1582, average loss: 6.1537
[09/25 23:02:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 48.00	top5: 76.00	
[09/25 23:02:09 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 23:02:16 visual_prompt]: Epoch 31 / 100: avg data time: 5.11e-02, avg batch time: 0.4653, average train loss: 1.9752
[09/25 23:02:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 5.7401
[09/25 23:02:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 50.50	top5: 73.00	
[09/25 23:02:17 visual_prompt]: Best epoch 31: best metric: 0.505
[09/25 23:02:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 23:02:24 visual_prompt]: Epoch 32 / 100: avg data time: 6.59e-02, avg batch time: 0.4782, average train loss: 1.5878
[09/25 23:02:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1583, average loss: 4.8688
[09/25 23:02:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 54.00	top5: 79.50	
[09/25 23:02:26 visual_prompt]: Best epoch 32: best metric: 0.540
[09/25 23:02:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 23:02:32 visual_prompt]: Epoch 33 / 100: avg data time: 5.63e-02, avg batch time: 0.4701, average train loss: 0.9894
[09/25 23:02:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 6.0305
[09/25 23:02:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 53.00	top5: 74.50	
[09/25 23:02:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 23:02:40 visual_prompt]: Epoch 34 / 100: avg data time: 6.54e-02, avg batch time: 0.4787, average train loss: 0.9918
[09/25 23:02:42 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1580, average loss: 4.6587
[09/25 23:02:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 61.00	top5: 79.50	
[09/25 23:02:42 visual_prompt]: Best epoch 34: best metric: 0.610
[09/25 23:02:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 23:02:48 visual_prompt]: Epoch 35 / 100: avg data time: 5.67e-02, avg batch time: 0.4698, average train loss: 0.6468
[09/25 23:02:50 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1586, average loss: 4.3536
[09/25 23:02:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 62.50	top5: 80.00	
[09/25 23:02:50 visual_prompt]: Best epoch 35: best metric: 0.625
[09/25 23:02:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 23:02:56 visual_prompt]: Epoch 36 / 100: avg data time: 5.04e-02, avg batch time: 0.4648, average train loss: 0.4509
[09/25 23:02:58 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1581, average loss: 4.6941
[09/25 23:02:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.50	top5: 81.50	
[09/25 23:02:58 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 23:03:04 visual_prompt]: Epoch 37 / 100: avg data time: 5.95e-02, avg batch time: 0.4725, average train loss: 0.6148
[09/25 23:03:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 4.3944
[09/25 23:03:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.50	top5: 81.00	
[09/25 23:03:06 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 23:03:12 visual_prompt]: Epoch 38 / 100: avg data time: 6.29e-02, avg batch time: 0.4755, average train loss: 0.5747
[09/25 23:03:14 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1582, average loss: 4.7271
[09/25 23:03:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 61.00	top5: 81.00	
[09/25 23:03:14 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 23:03:20 visual_prompt]: Epoch 39 / 100: avg data time: 5.07e-02, avg batch time: 0.4640, average train loss: 0.5901
[09/25 23:03:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1579, average loss: 4.8182
[09/25 23:03:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.00	top5: 80.00	
[09/25 23:03:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 23:03:28 visual_prompt]: Epoch 40 / 100: avg data time: 4.88e-02, avg batch time: 0.4632, average train loss: 0.4290
[09/25 23:03:30 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1584, average loss: 4.6513
[09/25 23:03:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 81.50	
[09/25 23:03:30 visual_prompt]: Best epoch 40: best metric: 0.635
[09/25 23:03:30 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 23:03:36 visual_prompt]: Epoch 41 / 100: avg data time: 6.14e-02, avg batch time: 0.4750, average train loss: 0.3188
[09/25 23:03:38 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1577, average loss: 3.6876
[09/25 23:03:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.00	top5: 84.00	
[09/25 23:03:38 visual_prompt]: Best epoch 41: best metric: 0.640
[09/25 23:03:38 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 23:03:44 visual_prompt]: Epoch 42 / 100: avg data time: 5.60e-02, avg batch time: 0.4693, average train loss: 0.3123
[09/25 23:03:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 4.1131
[09/25 23:03:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.50	top5: 85.50	
[09/25 23:03:46 visual_prompt]: Best epoch 42: best metric: 0.675
[09/25 23:03:46 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 23:03:52 visual_prompt]: Epoch 43 / 100: avg data time: 5.24e-02, avg batch time: 0.4675, average train loss: 0.1961
[09/25 23:03:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1580, average loss: 3.7493
[09/25 23:03:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 84.50	
[09/25 23:03:54 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 23:04:00 visual_prompt]: Epoch 44 / 100: avg data time: 5.19e-02, avg batch time: 0.4657, average train loss: 0.2909
[09/25 23:04:02 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1585, average loss: 4.0934
[09/25 23:04:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 84.50	
[09/25 23:04:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 23:04:08 visual_prompt]: Epoch 45 / 100: avg data time: 5.41e-02, avg batch time: 0.4674, average train loss: 0.1974
[09/25 23:04:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 4.1476
[09/25 23:04:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 61.50	top5: 87.00	
[09/25 23:04:10 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 23:04:16 visual_prompt]: Epoch 46 / 100: avg data time: 5.65e-02, avg batch time: 0.4713, average train loss: 0.2126
[09/25 23:04:18 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 4.8510
[09/25 23:04:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.50	top5: 83.50	
[09/25 23:04:18 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 23:04:24 visual_prompt]: Epoch 47 / 100: avg data time: 5.11e-02, avg batch time: 0.4663, average train loss: 0.2020
[09/25 23:04:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 3.8753
[09/25 23:04:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.00	top5: 84.00	
[09/25 23:04:26 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 23:04:32 visual_prompt]: Epoch 48 / 100: avg data time: 5.98e-02, avg batch time: 0.4745, average train loss: 0.1338
[09/25 23:04:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1586, average loss: 3.6737
[09/25 23:04:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 87.50	
[09/25 23:04:34 visual_prompt]: Best epoch 48: best metric: 0.690
[09/25 23:04:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 23:04:40 visual_prompt]: Epoch 49 / 100: avg data time: 4.95e-02, avg batch time: 0.4642, average train loss: 0.1431
[09/25 23:04:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1583, average loss: 3.4407
[09/25 23:04:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 86.00	
[09/25 23:04:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 23:04:48 visual_prompt]: Epoch 50 / 100: avg data time: 6.07e-02, avg batch time: 0.4732, average train loss: 0.1619
[09/25 23:04:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1575, average loss: 3.4468
[09/25 23:04:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 87.50	
[09/25 23:04:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 23:04:56 visual_prompt]: Epoch 51 / 100: avg data time: 5.35e-02, avg batch time: 0.4691, average train loss: 0.0905
[09/25 23:04:58 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1579, average loss: 4.1965
[09/25 23:04:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 85.00	
[09/25 23:04:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 23:05:04 visual_prompt]: Epoch 52 / 100: avg data time: 6.23e-02, avg batch time: 0.4748, average train loss: 0.0823
[09/25 23:05:06 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1580, average loss: 4.1841
[09/25 23:05:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 62.50	top5: 84.50	
[09/25 23:05:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 23:05:12 visual_prompt]: Epoch 53 / 100: avg data time: 5.09e-02, avg batch time: 0.4648, average train loss: 0.0845
[09/25 23:05:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 3.8692
[09/25 23:05:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 88.00	
[09/25 23:05:14 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 23:05:21 visual_prompt]: Epoch 54 / 100: avg data time: 5.89e-02, avg batch time: 0.4721, average train loss: 0.1154
[09/25 23:05:22 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1575, average loss: 4.4033
[09/25 23:05:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.00	top5: 87.50	
[09/25 23:05:22 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 23:05:29 visual_prompt]: Epoch 55 / 100: avg data time: 5.68e-02, avg batch time: 0.4701, average train loss: 0.1002
[09/25 23:05:30 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1579, average loss: 4.1790
[09/25 23:05:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.00	top5: 86.00	
[09/25 23:05:30 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 23:05:37 visual_prompt]: Epoch 56 / 100: avg data time: 5.28e-02, avg batch time: 0.4669, average train loss: 0.0688
[09/25 23:05:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 4.4628
[09/25 23:05:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.00	top5: 84.50	
[09/25 23:05:38 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 23:05:45 visual_prompt]: Epoch 57 / 100: avg data time: 6.74e-02, avg batch time: 0.4798, average train loss: 0.0645
[09/25 23:05:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 4.0603
[09/25 23:05:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 87.50	
[09/25 23:05:46 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 23:05:53 visual_prompt]: Epoch 58 / 100: avg data time: 6.36e-02, avg batch time: 0.4762, average train loss: 0.0359
[09/25 23:05:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 4.1533
[09/25 23:05:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 85.00	
[09/25 23:05:54 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 23:06:01 visual_prompt]: Epoch 59 / 100: avg data time: 6.33e-02, avg batch time: 0.4752, average train loss: 0.0223
[09/25 23:06:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 4.1710
[09/25 23:06:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.00	top5: 85.50	
[09/25 23:06:02 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 23:06:09 visual_prompt]: Epoch 60 / 100: avg data time: 5.38e-02, avg batch time: 0.4674, average train loss: 0.0629
[09/25 23:06:10 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1580, average loss: 3.9205
[09/25 23:06:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 85.00	
[09/25 23:06:10 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 23:06:17 visual_prompt]: Epoch 61 / 100: avg data time: 5.89e-02, avg batch time: 0.4711, average train loss: 0.0504
[09/25 23:06:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 3.9093
[09/25 23:06:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.50	top5: 86.00	
[09/25 23:06:18 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 23:06:25 visual_prompt]: Epoch 62 / 100: avg data time: 6.09e-02, avg batch time: 0.4734, average train loss: 0.0065
[09/25 23:06:27 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1580, average loss: 3.9833
[09/25 23:06:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.00	top5: 85.00	
[09/25 23:06:27 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 23:06:33 visual_prompt]: Epoch 63 / 100: avg data time: 6.11e-02, avg batch time: 0.4741, average train loss: 0.0205
[09/25 23:06:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 3.9256
[09/25 23:06:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.00	top5: 85.50	
[09/25 23:06:35 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 23:06:41 visual_prompt]: Epoch 64 / 100: avg data time: 6.27e-02, avg batch time: 0.4746, average train loss: 0.0131
[09/25 23:06:43 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1579, average loss: 3.9037
[09/25 23:06:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.50	top5: 87.00	
[09/25 23:06:43 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 23:06:49 visual_prompt]: Epoch 65 / 100: avg data time: 6.05e-02, avg batch time: 0.4723, average train loss: 0.0147
[09/25 23:06:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 3.8310
[09/25 23:06:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.00	top5: 86.50	
[09/25 23:06:51 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 23:06:57 visual_prompt]: Epoch 66 / 100: avg data time: 6.28e-02, avg batch time: 0.4745, average train loss: 0.0119
[09/25 23:06:59 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 3.8074
[09/25 23:06:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.00	top5: 87.00	
[09/25 23:06:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 23:07:05 visual_prompt]: Epoch 67 / 100: avg data time: 5.30e-02, avg batch time: 0.4656, average train loss: 0.0053
[09/25 23:07:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 3.8943
[09/25 23:07:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.00	top5: 87.00	
[09/25 23:07:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 23:07:13 visual_prompt]: Epoch 68 / 100: avg data time: 5.89e-02, avg batch time: 0.4710, average train loss: 0.0151
[09/25 23:07:15 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 3.8576
[09/25 23:07:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 87.00	
[09/25 23:07:15 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 23:07:21 visual_prompt]: Epoch 69 / 100: avg data time: 6.14e-02, avg batch time: 0.4747, average train loss: 0.0143
[09/25 23:07:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1583, average loss: 3.7626
[09/25 23:07:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.00	top5: 87.00	
[09/25 23:07:23 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 23:07:29 visual_prompt]: Epoch 70 / 100: avg data time: 5.75e-02, avg batch time: 0.4710, average train loss: 0.0057
[09/25 23:07:31 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1578, average loss: 3.7187
[09/25 23:07:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 86.50	
[09/25 23:07:31 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 23:07:37 visual_prompt]: Epoch 71 / 100: avg data time: 5.92e-02, avg batch time: 0.4726, average train loss: 0.0112
[09/25 23:07:39 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1584, average loss: 3.7087
[09/25 23:07:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 86.50	
[09/25 23:07:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 23:07:45 visual_prompt]: Epoch 72 / 100: avg data time: 5.65e-02, avg batch time: 0.4696, average train loss: 0.0084
[09/25 23:07:47 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1580, average loss: 3.6977
[09/25 23:07:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 87.00	
[09/25 23:07:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 23:07:53 visual_prompt]: Epoch 73 / 100: avg data time: 5.47e-02, avg batch time: 0.4674, average train loss: 0.0173
[09/25 23:07:55 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1582, average loss: 3.6829
[09/25 23:07:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 86.50	
[09/25 23:07:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 23:08:02 visual_prompt]: Epoch 74 / 100: avg data time: 5.83e-02, avg batch time: 0.4713, average train loss: 0.0011
[09/25 23:08:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 3.7056
[09/25 23:08:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 86.00	
[09/25 23:08:03 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 23:08:10 visual_prompt]: Epoch 75 / 100: avg data time: 5.83e-02, avg batch time: 0.4705, average train loss: 0.0181
[09/25 23:08:11 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1578, average loss: 3.6416
[09/25 23:08:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.50	top5: 86.00	
[09/25 23:08:11 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 23:08:18 visual_prompt]: Epoch 76 / 100: avg data time: 5.81e-02, avg batch time: 0.4713, average train loss: 0.0179
[09/25 23:08:19 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1580, average loss: 3.6388
[09/25 23:08:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.50	top5: 86.00	
[09/25 23:08:19 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 23:08:26 visual_prompt]: Epoch 77 / 100: avg data time: 6.30e-02, avg batch time: 0.4748, average train loss: 0.0211
[09/25 23:08:27 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1575, average loss: 3.5619
[09/25 23:08:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.50	top5: 86.00	
[09/25 23:08:27 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 23:08:34 visual_prompt]: Epoch 78 / 100: avg data time: 4.62e-02, avg batch time: 0.4605, average train loss: 0.0090
[09/25 23:08:35 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1586, average loss: 3.6094
[09/25 23:08:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 67.50	top5: 85.50	
[09/25 23:08:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 23:08:42 visual_prompt]: Epoch 79 / 100: avg data time: 6.27e-02, avg batch time: 0.4757, average train loss: 0.0161
[09/25 23:08:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 3.5977
[09/25 23:08:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 85.50	
[09/25 23:08:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 23:08:50 visual_prompt]: Epoch 80 / 100: avg data time: 5.99e-02, avg batch time: 0.4730, average train loss: 0.0019
[09/25 23:08:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 3.5827
[09/25 23:08:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.50	top5: 85.50	
[09/25 23:08:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 23:08:58 visual_prompt]: Epoch 81 / 100: avg data time: 6.65e-02, avg batch time: 0.4791, average train loss: 0.0014
[09/25 23:09:00 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1578, average loss: 3.5526
[09/25 23:09:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.50	
[09/25 23:09:00 visual_prompt]: Best epoch 81: best metric: 0.695
[09/25 23:09:00 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 23:09:06 visual_prompt]: Epoch 82 / 100: avg data time: 6.69e-02, avg batch time: 0.4796, average train loss: 0.0171
[09/25 23:09:08 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1577, average loss: 3.5541
[09/25 23:09:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.50	
[09/25 23:09:08 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 23:09:14 visual_prompt]: Epoch 83 / 100: avg data time: 5.60e-02, avg batch time: 0.4692, average train loss: 0.0056
[09/25 23:09:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1577, average loss: 3.6038
[09/25 23:09:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 86.00	
[09/25 23:09:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 23:09:22 visual_prompt]: Epoch 84 / 100: avg data time: 5.89e-02, avg batch time: 0.4724, average train loss: 0.0031
[09/25 23:09:24 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1587, average loss: 3.6128
[09/25 23:09:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.50	top5: 86.00	
[09/25 23:09:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 23:09:30 visual_prompt]: Epoch 85 / 100: avg data time: 6.13e-02, avg batch time: 0.4736, average train loss: 0.0020
[09/25 23:09:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 3.6107
[09/25 23:09:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 86.00	
[09/25 23:09:32 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 23:09:39 visual_prompt]: Epoch 86 / 100: avg data time: 5.62e-02, avg batch time: 0.4689, average train loss: 0.0081
[09/25 23:09:40 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 3.5860
[09/25 23:09:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 85.50	
[09/25 23:09:40 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 23:09:47 visual_prompt]: Epoch 87 / 100: avg data time: 6.41e-02, avg batch time: 0.4766, average train loss: 0.0069
[09/25 23:09:48 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1584, average loss: 3.5697
[09/25 23:09:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 85.50	
[09/25 23:09:48 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 23:09:55 visual_prompt]: Epoch 88 / 100: avg data time: 5.82e-02, avg batch time: 0.4708, average train loss: 0.0061
[09/25 23:09:56 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1579, average loss: 3.5454
[09/25 23:09:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 85.50	
[09/25 23:09:56 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 23:10:03 visual_prompt]: Epoch 89 / 100: avg data time: 4.99e-02, avg batch time: 0.4653, average train loss: 0.0091
[09/25 23:10:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 3.5292
[09/25 23:10:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:10:04 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 23:10:11 visual_prompt]: Epoch 90 / 100: avg data time: 6.58e-02, avg batch time: 0.4804, average train loss: 0.0158
[09/25 23:10:12 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1584, average loss: 3.5176
[09/25 23:10:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:10:12 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 23:10:19 visual_prompt]: Epoch 91 / 100: avg data time: 6.00e-02, avg batch time: 0.4739, average train loss: 0.0085
[09/25 23:10:21 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 3.5160
[09/25 23:10:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 85.50	
[09/25 23:10:21 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 23:10:27 visual_prompt]: Epoch 92 / 100: avg data time: 5.75e-02, avg batch time: 0.4709, average train loss: 0.0096
[09/25 23:10:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1578, average loss: 3.5194
[09/25 23:10:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 86.50	
[09/25 23:10:29 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 23:10:35 visual_prompt]: Epoch 93 / 100: avg data time: 6.40e-02, avg batch time: 0.4767, average train loss: 0.0065
[09/25 23:10:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 3.5119
[09/25 23:10:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 86.00	
[09/25 23:10:37 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 23:10:43 visual_prompt]: Epoch 94 / 100: avg data time: 5.90e-02, avg batch time: 0.4721, average train loss: 0.0060
[09/25 23:10:45 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1581, average loss: 3.5074
[09/25 23:10:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.50	
[09/25 23:10:45 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 23:10:51 visual_prompt]: Epoch 95 / 100: avg data time: 5.01e-02, avg batch time: 0.4641, average train loss: 0.0212
[09/25 23:10:53 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1578, average loss: 3.5056
[09/25 23:10:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:10:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 23:10:59 visual_prompt]: Epoch 96 / 100: avg data time: 5.57e-02, avg batch time: 0.4689, average train loss: 0.0050
[09/25 23:11:01 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1577, average loss: 3.5066
[09/25 23:11:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:11:01 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 23:11:07 visual_prompt]: Epoch 97 / 100: avg data time: 6.14e-02, avg batch time: 0.4745, average train loss: 0.0099
[09/25 23:11:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 3.5061
[09/25 23:11:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:11:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 23:11:15 visual_prompt]: Epoch 98 / 100: avg data time: 5.92e-02, avg batch time: 0.4719, average train loss: 0.0002
[09/25 23:11:17 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1580, average loss: 3.5061
[09/25 23:11:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:11:17 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 23:11:23 visual_prompt]: Epoch 99 / 100: avg data time: 5.93e-02, avg batch time: 0.4720, average train loss: 0.0006
[09/25 23:11:25 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1582, average loss: 3.5061
[09/25 23:11:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:11:25 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 23:11:31 visual_prompt]: Epoch 100 / 100: avg data time: 4.88e-02, avg batch time: 0.4662, average train loss: 0.0029
[09/25 23:11:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 3.5060
[09/25 23:11:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 86.00	
[09/25 23:11:33 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:11:33 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:11:33 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:11:33 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:11:33 visual_prompt]: Training with config:
[09/25 23:11:33 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:11:33 visual_prompt]: Loading training data...
[09/25 23:11:33 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:11:34 visual_prompt]: Number of images: 800
[09/25 23:11:34 visual_prompt]: Number of classes: 102 / 102
[09/25 23:11:34 visual_prompt]: Loading validation data...
[09/25 23:11:34 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:11:35 visual_prompt]: Number of images: 200
[09/25 23:11:35 visual_prompt]: Number of classes: 91 / 102
[09/25 23:11:35 visual_prompt]: Constructing models...
[09/25 23:11:37 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 23:11:37 visual_prompt]: tuned percent:0.625
[09/25 23:11:37 visual_prompt]: Device used for model: 0
[09/25 23:11:37 visual_prompt]: Setting up Evaluator...
[09/25 23:11:37 visual_prompt]: Setting up Trainer...
[09/25 23:11:37 visual_prompt]: 	Setting up the optimizer...
[09/25 23:11:37 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:11:44 visual_prompt]: Epoch 1 / 100: avg data time: 5.83e-02, avg batch time: 0.4763, average train loss: 4.6676
[09/25 23:11:45 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1574, average loss: 4.6780
[09/25 23:11:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:11:45 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:11:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:11:52 visual_prompt]: Epoch 2 / 100: avg data time: 4.97e-02, avg batch time: 0.4645, average train loss: 4.6951
[09/25 23:11:53 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1580, average loss: 4.6438
[09/25 23:11:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:11:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:12:00 visual_prompt]: Epoch 3 / 100: avg data time: 5.86e-02, avg batch time: 0.4711, average train loss: 4.7577
[09/25 23:12:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 4.7860
[09/25 23:12:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 23:12:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:12:08 visual_prompt]: Epoch 4 / 100: avg data time: 5.64e-02, avg batch time: 0.4691, average train loss: 4.8438
[09/25 23:12:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 4.7543
[09/25 23:12:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:12:10 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:12:16 visual_prompt]: Epoch 5 / 100: avg data time: 5.83e-02, avg batch time: 0.4712, average train loss: 4.8312
[09/25 23:12:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 4.7334
[09/25 23:12:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:12:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:12:24 visual_prompt]: Epoch 6 / 100: avg data time: 6.39e-02, avg batch time: 0.4781, average train loss: 4.9656
[09/25 23:12:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 5.1548
[09/25 23:12:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 23:12:26 visual_prompt]: Best epoch 6: best metric: 0.015
[09/25 23:12:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:12:32 visual_prompt]: Epoch 7 / 100: avg data time: 5.61e-02, avg batch time: 0.4683, average train loss: 5.2989
[09/25 23:12:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1582, average loss: 5.7753
[09/25 23:12:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 23:12:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:12:40 visual_prompt]: Epoch 8 / 100: avg data time: 6.73e-02, avg batch time: 0.4796, average train loss: 7.5767
[09/25 23:12:42 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1577, average loss: 12.5699
[09/25 23:12:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:12:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:12:49 visual_prompt]: Epoch 9 / 100: avg data time: 6.04e-02, avg batch time: 0.4727, average train loss: 8.9813
[09/25 23:12:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 7.4820
[09/25 23:12:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:12:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:12:57 visual_prompt]: Epoch 10 / 100: avg data time: 5.82e-02, avg batch time: 0.4707, average train loss: 8.8959
[09/25 23:12:58 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1576, average loss: 7.6455
[09/25 23:12:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/25 23:12:58 visual_prompt]: Best epoch 10: best metric: 0.020
[09/25 23:12:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:13:05 visual_prompt]: Epoch 11 / 100: avg data time: 5.81e-02, avg batch time: 0.4714, average train loss: 10.1378
[09/25 23:13:06 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 8.4671
[09/25 23:13:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/25 23:13:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:13:13 visual_prompt]: Epoch 12 / 100: avg data time: 6.24e-02, avg batch time: 0.4755, average train loss: 9.7434
[09/25 23:13:14 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1582, average loss: 9.1628
[09/25 23:13:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:13:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:13:21 visual_prompt]: Epoch 13 / 100: avg data time: 5.93e-02, avg batch time: 0.4735, average train loss: 10.0562
[09/25 23:13:22 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 8.3098
[09/25 23:13:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 23:13:22 visual_prompt]: Best epoch 13: best metric: 0.025
[09/25 23:13:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:13:29 visual_prompt]: Epoch 14 / 100: avg data time: 6.22e-02, avg batch time: 0.4765, average train loss: 9.8602
[09/25 23:13:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 7.5027
[09/25 23:13:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.00	
[09/25 23:13:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:13:37 visual_prompt]: Epoch 15 / 100: avg data time: 6.34e-02, avg batch time: 0.4771, average train loss: 9.8241
[09/25 23:13:39 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 7.6682
[09/25 23:13:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:13:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:13:45 visual_prompt]: Epoch 16 / 100: avg data time: 5.93e-02, avg batch time: 0.4733, average train loss: 8.9365
[09/25 23:13:47 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 36.0367
[09/25 23:13:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:13:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:13:53 visual_prompt]: Epoch 17 / 100: avg data time: 6.10e-02, avg batch time: 0.4753, average train loss: 13.8537
[09/25 23:13:55 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1581, average loss: 8.8271
[09/25 23:13:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 23:13:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:14:01 visual_prompt]: Epoch 18 / 100: avg data time: 5.56e-02, avg batch time: 0.4693, average train loss: 11.6290
[09/25 23:14:03 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1579, average loss: 9.4694
[09/25 23:14:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/25 23:14:03 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:14:09 visual_prompt]: Epoch 19 / 100: avg data time: 6.21e-02, avg batch time: 0.4762, average train loss: 11.8933
[09/25 23:14:11 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1580, average loss: 8.9526
[09/25 23:14:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 23:14:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:14:17 visual_prompt]: Epoch 20 / 100: avg data time: 5.10e-02, avg batch time: 0.4651, average train loss: 12.0940
[09/25 23:14:19 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1586, average loss: 9.1478
[09/25 23:14:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.50	
[09/25 23:14:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:14:25 visual_prompt]: Epoch 21 / 100: avg data time: 4.75e-02, avg batch time: 0.4621, average train loss: 14.7792
[09/25 23:14:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1578, average loss: 9.9979
[09/25 23:14:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.00	
[09/25 23:14:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:14:33 visual_prompt]: Epoch 22 / 100: avg data time: 5.34e-02, avg batch time: 0.4674, average train loss: 12.5430
[09/25 23:14:35 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1586, average loss: 9.0218
[09/25 23:14:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/25 23:14:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:14:42 visual_prompt]: Epoch 23 / 100: avg data time: 6.45e-02, avg batch time: 0.4777, average train loss: 13.2731
[09/25 23:14:43 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 11.0782
[09/25 23:14:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:14:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:14:50 visual_prompt]: Epoch 24 / 100: avg data time: 5.83e-02, avg batch time: 0.4718, average train loss: 12.5354
[09/25 23:14:51 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1582, average loss: 8.9693
[09/25 23:14:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 23:14:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:14:58 visual_prompt]: Epoch 25 / 100: avg data time: 5.91e-02, avg batch time: 0.4723, average train loss: 13.3889
[09/25 23:14:59 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 9.4035
[09/25 23:14:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 23:14:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:15:06 visual_prompt]: Epoch 26 / 100: avg data time: 5.02e-02, avg batch time: 0.4671, average train loss: 15.2125
[09/25 23:15:07 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 12.3748
[09/25 23:15:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:15:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:15:14 visual_prompt]: Epoch 27 / 100: avg data time: 5.25e-02, avg batch time: 0.4676, average train loss: 11.8954
[09/25 23:15:15 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1583, average loss: 12.5916
[09/25 23:15:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.00	
[09/25 23:15:15 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:15:22 visual_prompt]: Epoch 28 / 100: avg data time: 5.99e-02, avg batch time: 0.4728, average train loss: 13.6303
[09/25 23:15:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 14.9110
[09/25 23:15:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 7.00	
[09/25 23:15:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:15:30 visual_prompt]: Epoch 29 / 100: avg data time: 5.67e-02, avg batch time: 0.4706, average train loss: 15.0195
[09/25 23:15:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 14.1424
[09/25 23:15:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:15:31 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:15:38 visual_prompt]: Epoch 30 / 100: avg data time: 5.16e-02, avg batch time: 0.4661, average train loss: 13.9493
[09/25 23:15:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1584, average loss: 15.0692
[09/25 23:15:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:15:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:15:46 visual_prompt]: Epoch 31 / 100: avg data time: 6.03e-02, avg batch time: 0.4732, average train loss: 14.0798
[09/25 23:15:47 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1583, average loss: 12.8460
[09/25 23:15:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/25 23:15:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:15:54 visual_prompt]: Epoch 32 / 100: avg data time: 5.75e-02, avg batch time: 0.4711, average train loss: 13.2324
[09/25 23:15:56 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1584, average loss: 12.0233
[09/25 23:15:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 1.50	
[09/25 23:15:56 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:16:02 visual_prompt]: Epoch 33 / 100: avg data time: 6.41e-02, avg batch time: 0.4779, average train loss: 12.5647
[09/25 23:16:04 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 11.2201
[09/25 23:16:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:16:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:16:10 visual_prompt]: Epoch 34 / 100: avg data time: 6.22e-02, avg batch time: 0.4760, average train loss: 11.3664
[09/25 23:16:12 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1579, average loss: 9.9308
[09/25 23:16:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:16:12 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/25 23:16:18 visual_prompt]: Epoch 35 / 100: avg data time: 6.06e-02, avg batch time: 0.4730, average train loss: 11.1308
[09/25 23:16:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1576, average loss: 12.8906
[09/25 23:16:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:16:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/25 23:16:27 visual_prompt]: Epoch 36 / 100: avg data time: 6.26e-02, avg batch time: 0.4747, average train loss: 11.2467
[09/25 23:16:28 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1572, average loss: 9.3360
[09/25 23:16:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.50	
[09/25 23:16:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/25 23:16:35 visual_prompt]: Epoch 37 / 100: avg data time: 5.91e-02, avg batch time: 0.4721, average train loss: 9.4739
[09/25 23:16:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 9.7570
[09/25 23:16:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 23:16:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/25 23:16:43 visual_prompt]: Epoch 38 / 100: avg data time: 5.73e-02, avg batch time: 0.4702, average train loss: 8.8833
[09/25 23:16:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 8.3581
[09/25 23:16:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 23:16:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/25 23:16:51 visual_prompt]: Epoch 39 / 100: avg data time: 6.47e-02, avg batch time: 0.4770, average train loss: 8.4903
[09/25 23:16:52 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1578, average loss: 9.1169
[09/25 23:16:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:16:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/25 23:16:59 visual_prompt]: Epoch 40 / 100: avg data time: 5.15e-02, avg batch time: 0.4676, average train loss: 8.4342
[09/25 23:17:00 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1579, average loss: 7.4252
[09/25 23:17:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:17:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/25 23:17:07 visual_prompt]: Epoch 41 / 100: avg data time: 6.17e-02, avg batch time: 0.4742, average train loss: 7.8579
[09/25 23:17:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 7.2120
[09/25 23:17:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:17:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/25 23:17:15 visual_prompt]: Epoch 42 / 100: avg data time: 6.48e-02, avg batch time: 0.4767, average train loss: 7.4000
[09/25 23:17:17 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1585, average loss: 7.0799
[09/25 23:17:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:17:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/25 23:17:23 visual_prompt]: Epoch 43 / 100: avg data time: 6.00e-02, avg batch time: 0.4720, average train loss: 7.2114
[09/25 23:17:25 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1585, average loss: 7.0914
[09/25 23:17:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 23:17:25 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/25 23:17:31 visual_prompt]: Epoch 44 / 100: avg data time: 4.61e-02, avg batch time: 0.4609, average train loss: 7.1489
[09/25 23:17:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 5.8673
[09/25 23:17:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:17:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/25 23:17:39 visual_prompt]: Epoch 45 / 100: avg data time: 6.24e-02, avg batch time: 0.4752, average train loss: 6.6445
[09/25 23:17:41 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1582, average loss: 5.9122
[09/25 23:17:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 23:17:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/25 23:17:47 visual_prompt]: Epoch 46 / 100: avg data time: 6.16e-02, avg batch time: 0.4744, average train loss: 6.4561
[09/25 23:17:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1577, average loss: 5.5018
[09/25 23:17:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 23:17:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/25 23:17:55 visual_prompt]: Epoch 47 / 100: avg data time: 5.36e-02, avg batch time: 0.4659, average train loss: 6.0563
[09/25 23:17:57 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1581, average loss: 5.7387
[09/25 23:17:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 23:17:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/25 23:18:03 visual_prompt]: Epoch 48 / 100: avg data time: 5.52e-02, avg batch time: 0.4679, average train loss: 6.1864
[09/25 23:18:05 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1577, average loss: 6.7332
[09/25 23:18:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:18:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/25 23:18:12 visual_prompt]: Epoch 49 / 100: avg data time: 6.15e-02, avg batch time: 0.4737, average train loss: 6.1292
[09/25 23:18:13 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1580, average loss: 5.2927
[09/25 23:18:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:18:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/25 23:18:20 visual_prompt]: Epoch 50 / 100: avg data time: 6.32e-02, avg batch time: 0.4749, average train loss: 5.2901
[09/25 23:18:21 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1583, average loss: 5.5496
[09/25 23:18:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:18:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/25 23:18:28 visual_prompt]: Epoch 51 / 100: avg data time: 6.03e-02, avg batch time: 0.4719, average train loss: 5.7118
[09/25 23:18:29 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1580, average loss: 5.1524
[09/25 23:18:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 23:18:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/25 23:18:36 visual_prompt]: Epoch 52 / 100: avg data time: 6.25e-02, avg batch time: 0.4748, average train loss: 6.6723
[09/25 23:18:37 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1576, average loss: 5.9109
[09/25 23:18:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 23:18:37 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/25 23:18:44 visual_prompt]: Epoch 53 / 100: avg data time: 5.77e-02, avg batch time: 0.4706, average train loss: 6.0444
[09/25 23:18:45 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1584, average loss: 5.6953
[09/25 23:18:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 23:18:45 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/25 23:18:52 visual_prompt]: Epoch 54 / 100: avg data time: 6.27e-02, avg batch time: 0.4763, average train loss: 6.2079
[09/25 23:18:54 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1577, average loss: 5.5203
[09/25 23:18:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:18:54 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/25 23:19:00 visual_prompt]: Epoch 55 / 100: avg data time: 6.14e-02, avg batch time: 0.4734, average train loss: 6.0104
[09/25 23:19:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 5.6852
[09/25 23:19:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:19:02 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/25 23:19:08 visual_prompt]: Epoch 56 / 100: avg data time: 5.92e-02, avg batch time: 0.4716, average train loss: 5.8550
[09/25 23:19:10 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1585, average loss: 5.0961
[09/25 23:19:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 6.50	
[09/25 23:19:10 visual_prompt]: Best epoch 56: best metric: 0.035
[09/25 23:19:10 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/25 23:19:16 visual_prompt]: Epoch 57 / 100: avg data time: 6.09e-02, avg batch time: 0.4741, average train loss: 5.6640
[09/25 23:19:18 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1581, average loss: 5.8375
[09/25 23:19:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:19:18 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/25 23:19:24 visual_prompt]: Epoch 58 / 100: avg data time: 5.98e-02, avg batch time: 0.4731, average train loss: 5.5043
[09/25 23:19:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1583, average loss: 4.9081
[09/25 23:19:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:19:26 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/25 23:19:33 visual_prompt]: Epoch 59 / 100: avg data time: 6.24e-02, avg batch time: 0.4758, average train loss: 5.2697
[09/25 23:19:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 5.8605
[09/25 23:19:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 23:19:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/25 23:19:41 visual_prompt]: Epoch 60 / 100: avg data time: 6.12e-02, avg batch time: 0.4741, average train loss: 5.3774
[09/25 23:19:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 5.0474
[09/25 23:19:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:19:42 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/25 23:19:49 visual_prompt]: Epoch 61 / 100: avg data time: 5.96e-02, avg batch time: 0.4721, average train loss: 5.3347
[09/25 23:19:50 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 5.0380
[09/25 23:19:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 6.00	
[09/25 23:19:50 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/25 23:19:57 visual_prompt]: Epoch 62 / 100: avg data time: 6.39e-02, avg batch time: 0.4762, average train loss: 5.1381
[09/25 23:19:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 5.0655
[09/25 23:19:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 23:19:58 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/25 23:20:05 visual_prompt]: Epoch 63 / 100: avg data time: 5.94e-02, avg batch time: 0.4714, average train loss: 5.2482
[09/25 23:20:06 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1581, average loss: 4.8972
[09/25 23:20:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:20:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/25 23:20:13 visual_prompt]: Epoch 64 / 100: avg data time: 6.07e-02, avg batch time: 0.4729, average train loss: 5.3002
[09/25 23:20:15 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1576, average loss: 5.1039
[09/25 23:20:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 23:20:15 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/25 23:20:21 visual_prompt]: Epoch 65 / 100: avg data time: 6.27e-02, avg batch time: 0.4756, average train loss: 5.2880
[09/25 23:20:23 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 5.0462
[09/25 23:20:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:20:23 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/25 23:20:29 visual_prompt]: Epoch 66 / 100: avg data time: 5.88e-02, avg batch time: 0.4713, average train loss: 5.2206
[09/25 23:20:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 4.9046
[09/25 23:20:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:20:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/25 23:20:37 visual_prompt]: Epoch 67 / 100: avg data time: 5.48e-02, avg batch time: 0.4674, average train loss: 5.1703
[09/25 23:20:39 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1576, average loss: 4.8497
[09/25 23:20:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 23:20:39 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/25 23:20:45 visual_prompt]: Epoch 68 / 100: avg data time: 5.71e-02, avg batch time: 0.4693, average train loss: 5.1385
[09/25 23:20:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1578, average loss: 4.8745
[09/25 23:20:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:20:47 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/25 23:20:53 visual_prompt]: Epoch 69 / 100: avg data time: 5.44e-02, avg batch time: 0.4664, average train loss: 5.0783
[09/25 23:20:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 4.8048
[09/25 23:20:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:20:55 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/25 23:21:01 visual_prompt]: Epoch 70 / 100: avg data time: 5.13e-02, avg batch time: 0.4655, average train loss: 4.9585
[09/25 23:21:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1575, average loss: 4.8008
[09/25 23:21:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 23:21:03 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/25 23:21:09 visual_prompt]: Epoch 71 / 100: avg data time: 5.54e-02, avg batch time: 0.4677, average train loss: 4.9479
[09/25 23:21:11 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 4.9046
[09/25 23:21:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:21:11 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/25 23:21:17 visual_prompt]: Epoch 72 / 100: avg data time: 6.09e-02, avg batch time: 0.4724, average train loss: 4.9332
[09/25 23:21:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1579, average loss: 4.7793
[09/25 23:21:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:21:19 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/25 23:21:25 visual_prompt]: Epoch 73 / 100: avg data time: 6.13e-02, avg batch time: 0.4741, average train loss: 4.7955
[09/25 23:21:27 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 4.6957
[09/25 23:21:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:21:27 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/25 23:21:33 visual_prompt]: Epoch 74 / 100: avg data time: 5.30e-02, avg batch time: 0.4650, average train loss: 4.7706
[09/25 23:21:35 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1579, average loss: 4.7865
[09/25 23:21:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:21:35 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/25 23:21:41 visual_prompt]: Epoch 75 / 100: avg data time: 5.52e-02, avg batch time: 0.4691, average train loss: 4.7357
[09/25 23:21:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1578, average loss: 4.8127
[09/25 23:21:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:21:43 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/25 23:21:49 visual_prompt]: Epoch 76 / 100: avg data time: 6.26e-02, avg batch time: 0.4748, average train loss: 4.7161
[09/25 23:21:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1578, average loss: 4.6739
[09/25 23:21:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:21:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/25 23:21:58 visual_prompt]: Epoch 77 / 100: avg data time: 6.09e-02, avg batch time: 0.4734, average train loss: 4.7551
[09/25 23:21:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 4.7641
[09/25 23:21:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 23:21:59 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/25 23:22:06 visual_prompt]: Epoch 78 / 100: avg data time: 5.47e-02, avg batch time: 0.4678, average train loss: 4.7207
[09/25 23:22:07 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 4.6981
[09/25 23:22:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:22:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/25 23:22:14 visual_prompt]: Epoch 79 / 100: avg data time: 5.73e-02, avg batch time: 0.4697, average train loss: 4.7077
[09/25 23:22:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1576, average loss: 4.6802
[09/25 23:22:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/25 23:22:15 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/25 23:22:22 visual_prompt]: Epoch 80 / 100: avg data time: 6.18e-02, avg batch time: 0.4732, average train loss: 4.6913
[09/25 23:22:23 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1580, average loss: 4.7085
[09/25 23:22:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:22:23 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/25 23:22:30 visual_prompt]: Epoch 81 / 100: avg data time: 6.55e-02, avg batch time: 0.4766, average train loss: 4.6444
[09/25 23:22:31 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1578, average loss: 4.8139
[09/25 23:22:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 23:22:31 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/25 23:22:38 visual_prompt]: Epoch 82 / 100: avg data time: 6.32e-02, avg batch time: 0.4742, average train loss: 4.6728
[09/25 23:22:40 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 4.7027
[09/25 23:22:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:22:40 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/25 23:22:46 visual_prompt]: Epoch 83 / 100: avg data time: 6.36e-02, avg batch time: 0.4765, average train loss: 4.6506
[09/25 23:22:48 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1580, average loss: 4.7497
[09/25 23:22:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:22:48 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/25 23:22:54 visual_prompt]: Epoch 84 / 100: avg data time: 6.32e-02, avg batch time: 0.4744, average train loss: 4.6900
[09/25 23:22:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 4.7010
[09/25 23:22:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 23:22:56 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/25 23:23:02 visual_prompt]: Epoch 85 / 100: avg data time: 5.54e-02, avg batch time: 0.4665, average train loss: 4.6760
[09/25 23:23:04 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 4.6867
[09/25 23:23:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:23:04 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/25 23:23:10 visual_prompt]: Epoch 86 / 100: avg data time: 5.85e-02, avg batch time: 0.4694, average train loss: 4.6542
[09/25 23:23:12 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1577, average loss: 4.6815
[09/25 23:23:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:23:12 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/25 23:23:18 visual_prompt]: Epoch 87 / 100: avg data time: 6.01e-02, avg batch time: 0.4733, average train loss: 4.6318
[09/25 23:23:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1579, average loss: 4.6760
[09/25 23:23:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:23:20 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/25 23:23:26 visual_prompt]: Epoch 88 / 100: avg data time: 5.51e-02, avg batch time: 0.4689, average train loss: 4.6354
[09/25 23:23:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 4.6658
[09/25 23:23:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 7.00	
[09/25 23:23:28 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/25 23:23:35 visual_prompt]: Epoch 89 / 100: avg data time: 6.04e-02, avg batch time: 0.4741, average train loss: 4.6202
[09/25 23:23:36 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 4.6678
[09/25 23:23:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:23:36 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/25 23:23:43 visual_prompt]: Epoch 90 / 100: avg data time: 6.12e-02, avg batch time: 0.4728, average train loss: 4.6143
[09/25 23:23:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1581, average loss: 4.6628
[09/25 23:23:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.00	
[09/25 23:23:44 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/25 23:23:51 visual_prompt]: Epoch 91 / 100: avg data time: 5.87e-02, avg batch time: 0.4709, average train loss: 4.6053
[09/25 23:23:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1575, average loss: 4.6673
[09/25 23:23:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/25 23:23:52 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/25 23:23:59 visual_prompt]: Epoch 92 / 100: avg data time: 5.71e-02, avg batch time: 0.4696, average train loss: 4.6023
[09/25 23:24:00 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1579, average loss: 4.6689
[09/25 23:24:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:24:00 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/25 23:24:07 visual_prompt]: Epoch 93 / 100: avg data time: 5.12e-02, avg batch time: 0.4648, average train loss: 4.5964
[09/25 23:24:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1578, average loss: 4.6596
[09/25 23:24:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:24:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/25 23:24:15 visual_prompt]: Epoch 94 / 100: avg data time: 6.40e-02, avg batch time: 0.4758, average train loss: 4.6020
[09/25 23:24:17 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1582, average loss: 4.6706
[09/25 23:24:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:24:17 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/25 23:24:23 visual_prompt]: Epoch 95 / 100: avg data time: 5.53e-02, avg batch time: 0.4670, average train loss: 4.5965
[09/25 23:24:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 4.6604
[09/25 23:24:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:24:25 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/25 23:24:31 visual_prompt]: Epoch 96 / 100: avg data time: 6.56e-02, avg batch time: 0.4775, average train loss: 4.5901
[09/25 23:24:33 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 4.6559
[09/25 23:24:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:24:33 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/25 23:24:39 visual_prompt]: Epoch 97 / 100: avg data time: 6.25e-02, avg batch time: 0.4748, average train loss: 4.5768
[09/25 23:24:41 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 4.6538
[09/25 23:24:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:24:41 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/25 23:24:47 visual_prompt]: Epoch 98 / 100: avg data time: 5.84e-02, avg batch time: 0.4711, average train loss: 4.5322
[09/25 23:24:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1579, average loss: 4.6303
[09/25 23:24:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 23:24:49 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/25 23:24:55 visual_prompt]: Epoch 99 / 100: avg data time: 5.43e-02, avg batch time: 0.4668, average train loss: 4.4687
[09/25 23:24:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1576, average loss: 4.5604
[09/25 23:24:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 23:24:57 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/25 23:25:03 visual_prompt]: Epoch 100 / 100: avg data time: 5.37e-02, avg batch time: 0.4678, average train loss: 4.4070
[09/25 23:25:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 4.5395
[09/25 23:25:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 10.00	
[09/25 23:25:05 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:25:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:25:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:25:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:25:05 visual_prompt]: Training with config:
[09/25 23:25:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:25:05 visual_prompt]: Loading training data...
[09/25 23:25:05 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:25:06 visual_prompt]: Number of images: 800
[09/25 23:25:06 visual_prompt]: Number of classes: 102 / 102
[09/25 23:25:06 visual_prompt]: Loading validation data...
[09/25 23:25:06 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:25:07 visual_prompt]: Number of images: 200
[09/25 23:25:07 visual_prompt]: Number of classes: 91 / 102
[09/25 23:25:07 visual_prompt]: Constructing models...
[09/25 23:25:09 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 23:25:09 visual_prompt]: tuned percent:0.625
[09/25 23:25:09 visual_prompt]: Device used for model: 0
[09/25 23:25:09 visual_prompt]: Setting up Evaluator...
[09/25 23:25:09 visual_prompt]: Setting up Trainer...
[09/25 23:25:09 visual_prompt]: 	Setting up the optimizer...
[09/25 23:25:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:25:16 visual_prompt]: Epoch 1 / 100: avg data time: 4.95e-02, avg batch time: 0.4694, average train loss: 4.6677
[09/25 23:25:17 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1578, average loss: 4.6780
[09/25 23:25:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:25:17 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:25:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:25:24 visual_prompt]: Epoch 2 / 100: avg data time: 5.92e-02, avg batch time: 0.4748, average train loss: 4.7164
[09/25 23:25:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1577, average loss: 4.6835
[09/25 23:25:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:25:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:25:32 visual_prompt]: Epoch 3 / 100: avg data time: 6.26e-02, avg batch time: 0.4749, average train loss: 4.7376
[09/25 23:25:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1575, average loss: 4.6286
[09/25 23:25:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 23:25:33 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:25:40 visual_prompt]: Epoch 4 / 100: avg data time: 5.93e-02, avg batch time: 0.4710, average train loss: 4.7596
[09/25 23:25:41 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1576, average loss: 5.0590
[09/25 23:25:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 23:25:41 visual_prompt]: Best epoch 4: best metric: 0.015
[09/25 23:25:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:25:48 visual_prompt]: Epoch 5 / 100: avg data time: 5.90e-02, avg batch time: 0.4710, average train loss: 4.8563
[09/25 23:25:49 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1579, average loss: 4.6806
[09/25 23:25:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 23:25:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:25:56 visual_prompt]: Epoch 6 / 100: avg data time: 5.58e-02, avg batch time: 0.4692, average train loss: 4.8851
[09/25 23:25:57 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1581, average loss: 4.9587
[09/25 23:25:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/25 23:25:57 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:26:04 visual_prompt]: Epoch 7 / 100: avg data time: 6.66e-02, avg batch time: 0.4789, average train loss: 5.0975
[09/25 23:26:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1581, average loss: 5.3249
[09/25 23:26:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 23:26:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:26:12 visual_prompt]: Epoch 8 / 100: avg data time: 6.71e-02, avg batch time: 0.4790, average train loss: 5.3677
[09/25 23:26:14 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1579, average loss: 6.2496
[09/25 23:26:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:26:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:26:20 visual_prompt]: Epoch 9 / 100: avg data time: 4.97e-02, avg batch time: 0.4649, average train loss: 5.6679
[09/25 23:26:22 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1581, average loss: 5.7951
[09/25 23:26:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.00	
[09/25 23:26:22 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:26:28 visual_prompt]: Epoch 10 / 100: avg data time: 6.14e-02, avg batch time: 0.4746, average train loss: 7.4337
[09/25 23:26:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 6.7888
[09/25 23:26:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:26:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:26:37 visual_prompt]: Epoch 11 / 100: avg data time: 6.99e-02, avg batch time: 0.4814, average train loss: 7.5896
[09/25 23:26:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1581, average loss: 6.6281
[09/25 23:26:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:26:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:26:45 visual_prompt]: Epoch 12 / 100: avg data time: 6.60e-02, avg batch time: 0.4780, average train loss: 7.9863
[09/25 23:26:46 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 8.4203
[09/25 23:26:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:26:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:26:53 visual_prompt]: Epoch 13 / 100: avg data time: 5.18e-02, avg batch time: 0.4654, average train loss: 9.1696
[09/25 23:26:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 7.9108
[09/25 23:26:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 23:26:54 visual_prompt]: Best epoch 13: best metric: 0.020
[09/25 23:26:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:27:01 visual_prompt]: Epoch 14 / 100: avg data time: 6.26e-02, avg batch time: 0.4755, average train loss: 8.0561
[09/25 23:27:02 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1576, average loss: 6.7698
[09/25 23:27:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:27:02 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:27:09 visual_prompt]: Epoch 15 / 100: avg data time: 5.82e-02, avg batch time: 0.4713, average train loss: 8.1913
[09/25 23:27:11 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1582, average loss: 9.0851
[09/25 23:27:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/25 23:27:11 visual_prompt]: Best epoch 15: best metric: 0.025
[09/25 23:27:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:27:17 visual_prompt]: Epoch 16 / 100: avg data time: 6.04e-02, avg batch time: 0.4738, average train loss: 13.5784
[09/25 23:27:19 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1586, average loss: 16.7626
[09/25 23:27:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 23:27:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:27:25 visual_prompt]: Epoch 17 / 100: avg data time: 5.17e-02, avg batch time: 0.4647, average train loss: 19.4361
[09/25 23:27:27 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1579, average loss: 30.3511
[09/25 23:27:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/25 23:27:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:27:33 visual_prompt]: Epoch 18 / 100: avg data time: 6.37e-02, avg batch time: 0.4767, average train loss: 26.8554
[09/25 23:27:35 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 20.9666
[09/25 23:27:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:27:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:27:41 visual_prompt]: Epoch 19 / 100: avg data time: 6.61e-02, avg batch time: 0.4782, average train loss: 23.3055
[09/25 23:27:43 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1582, average loss: 13.4524
[09/25 23:27:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/25 23:27:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:27:50 visual_prompt]: Epoch 20 / 100: avg data time: 5.85e-02, avg batch time: 0.4723, average train loss: 20.9673
[09/25 23:27:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 17.2836
[09/25 23:27:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/25 23:27:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:27:58 visual_prompt]: Epoch 21 / 100: avg data time: 6.61e-02, avg batch time: 0.4785, average train loss: 19.0870
[09/25 23:27:59 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1582, average loss: 12.5173
[09/25 23:27:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 1.00	
[09/25 23:27:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:28:06 visual_prompt]: Epoch 22 / 100: avg data time: 4.83e-02, avg batch time: 0.4623, average train loss: 17.2535
[09/25 23:28:07 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 14.5482
[09/25 23:28:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.50	
[09/25 23:28:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:28:14 visual_prompt]: Epoch 23 / 100: avg data time: 6.52e-02, avg batch time: 0.4768, average train loss: 16.9966
[09/25 23:28:16 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1579, average loss: 12.1763
[09/25 23:28:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 23:28:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:28:22 visual_prompt]: Epoch 24 / 100: avg data time: 5.80e-02, avg batch time: 0.4703, average train loss: 13.4413
[09/25 23:28:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 14.4534
[09/25 23:28:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 23:28:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:28:30 visual_prompt]: Epoch 25 / 100: avg data time: 5.93e-02, avg batch time: 0.4714, average train loss: 11.9736
[09/25 23:28:32 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1583, average loss: 11.5149
[09/25 23:28:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 23:28:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:28:38 visual_prompt]: Epoch 26 / 100: avg data time: 6.29e-02, avg batch time: 0.4773, average train loss: 13.6279
[09/25 23:28:40 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1577, average loss: 19.5543
[09/25 23:28:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/25 23:28:40 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:28:46 visual_prompt]: Epoch 27 / 100: avg data time: 5.62e-02, avg batch time: 0.4705, average train loss: 15.0418
[09/25 23:28:48 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1586, average loss: 13.2455
[09/25 23:28:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:28:48 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:28:54 visual_prompt]: Epoch 28 / 100: avg data time: 4.74e-02, avg batch time: 0.4607, average train loss: 11.6235
[09/25 23:28:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 9.7177
[09/25 23:28:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.00	
[09/25 23:28:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:29:02 visual_prompt]: Epoch 29 / 100: avg data time: 6.33e-02, avg batch time: 0.4754, average train loss: 10.7700
[09/25 23:29:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 10.6490
[09/25 23:29:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:29:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:29:10 visual_prompt]: Epoch 30 / 100: avg data time: 5.55e-02, avg batch time: 0.4689, average train loss: 15.2450
[09/25 23:29:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 14.2337
[09/25 23:29:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/25 23:29:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:29:18 visual_prompt]: Epoch 31 / 100: avg data time: 5.56e-02, avg batch time: 0.4693, average train loss: 14.7089
[09/25 23:29:20 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 12.7912
[09/25 23:29:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 23:29:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:29:26 visual_prompt]: Epoch 32 / 100: avg data time: 5.76e-02, avg batch time: 0.4702, average train loss: 13.0991
[09/25 23:29:28 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1577, average loss: 11.5069
[09/25 23:29:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:29:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:29:35 visual_prompt]: Epoch 33 / 100: avg data time: 6.01e-02, avg batch time: 0.4731, average train loss: 12.4984
[09/25 23:29:36 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1575, average loss: 9.2795
[09/25 23:29:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:29:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:29:43 visual_prompt]: Epoch 34 / 100: avg data time: 5.10e-02, avg batch time: 0.4664, average train loss: 10.3396
[09/25 23:29:44 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1581, average loss: 7.6720
[09/25 23:29:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/25 23:29:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/25 23:29:51 visual_prompt]: Epoch 35 / 100: avg data time: 5.15e-02, avg batch time: 0.4644, average train loss: 8.3926
[09/25 23:29:52 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 6.7172
[09/25 23:29:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/25 23:29:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/25 23:29:58 visual_prompt]: Epoch 36 / 100: avg data time: 4.76e-02, avg batch time: 0.4607, average train loss: 6.9971
[09/25 23:30:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 6.7743
[09/25 23:30:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 23:30:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/25 23:30:06 visual_prompt]: Epoch 37 / 100: avg data time: 5.75e-02, avg batch time: 0.4697, average train loss: 6.3405
[09/25 23:30:08 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1580, average loss: 6.4408
[09/25 23:30:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:30:08 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/25 23:30:15 visual_prompt]: Epoch 38 / 100: avg data time: 6.17e-02, avg batch time: 0.4750, average train loss: 6.6069
[09/25 23:30:16 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1577, average loss: 7.8127
[09/25 23:30:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:30:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/25 23:30:23 visual_prompt]: Epoch 39 / 100: avg data time: 5.80e-02, avg batch time: 0.4714, average train loss: 7.2263
[09/25 23:30:24 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1585, average loss: 6.6396
[09/25 23:30:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/25 23:30:24 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/25 23:30:31 visual_prompt]: Epoch 40 / 100: avg data time: 5.41e-02, avg batch time: 0.4684, average train loss: 5.9099
[09/25 23:30:32 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 5.6214
[09/25 23:30:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:30:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/25 23:30:39 visual_prompt]: Epoch 41 / 100: avg data time: 6.06e-02, avg batch time: 0.4727, average train loss: 5.6830
[09/25 23:30:40 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1578, average loss: 6.7191
[09/25 23:30:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/25 23:30:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/25 23:30:47 visual_prompt]: Epoch 42 / 100: avg data time: 6.37e-02, avg batch time: 0.4767, average train loss: 5.7682
[09/25 23:30:49 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 6.2159
[09/25 23:30:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:30:49 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/25 23:30:55 visual_prompt]: Epoch 43 / 100: avg data time: 5.68e-02, avg batch time: 0.4693, average train loss: 5.4663
[09/25 23:30:57 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 5.4561
[09/25 23:30:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 23:30:57 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/25 23:31:03 visual_prompt]: Epoch 44 / 100: avg data time: 6.03e-02, avg batch time: 0.4727, average train loss: 5.3494
[09/25 23:31:05 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1577, average loss: 5.3582
[09/25 23:31:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/25 23:31:05 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/25 23:31:11 visual_prompt]: Epoch 45 / 100: avg data time: 6.35e-02, avg batch time: 0.4759, average train loss: 5.8675
[09/25 23:31:13 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 5.8289
[09/25 23:31:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:31:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/25 23:31:19 visual_prompt]: Epoch 46 / 100: avg data time: 4.98e-02, avg batch time: 0.4646, average train loss: 5.7111
[09/25 23:31:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1573, average loss: 5.3100
[09/25 23:31:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 23:31:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/25 23:31:27 visual_prompt]: Epoch 47 / 100: avg data time: 6.31e-02, avg batch time: 0.4762, average train loss: 5.6312
[09/25 23:31:29 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 5.4885
[09/25 23:31:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 23:31:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/25 23:31:36 visual_prompt]: Epoch 48 / 100: avg data time: 6.23e-02, avg batch time: 0.4747, average train loss: 5.3904
[09/25 23:31:37 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1577, average loss: 5.4796
[09/25 23:31:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/25 23:31:37 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/25 23:31:44 visual_prompt]: Epoch 49 / 100: avg data time: 6.35e-02, avg batch time: 0.4761, average train loss: 5.2488
[09/25 23:31:45 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 5.3335
[09/25 23:31:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/25 23:31:45 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/25 23:31:52 visual_prompt]: Epoch 50 / 100: avg data time: 6.03e-02, avg batch time: 0.4725, average train loss: 5.1660
[09/25 23:31:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 5.1067
[09/25 23:31:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 23:31:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/25 23:32:00 visual_prompt]: Epoch 51 / 100: avg data time: 5.55e-02, avg batch time: 0.4693, average train loss: 5.0495
[09/25 23:32:02 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1579, average loss: 4.8894
[09/25 23:32:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:32:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/25 23:32:08 visual_prompt]: Epoch 52 / 100: avg data time: 6.73e-02, avg batch time: 0.4800, average train loss: 5.0073
[09/25 23:32:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 5.1245
[09/25 23:32:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/25 23:32:10 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/25 23:32:16 visual_prompt]: Epoch 53 / 100: avg data time: 6.28e-02, avg batch time: 0.4752, average train loss: 4.9639
[09/25 23:32:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1584, average loss: 5.0088
[09/25 23:32:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:32:18 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/25 23:32:24 visual_prompt]: Epoch 54 / 100: avg data time: 5.52e-02, avg batch time: 0.4693, average train loss: 4.9742
[09/25 23:32:26 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1580, average loss: 5.3132
[09/25 23:32:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.50	
[09/25 23:32:26 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/25 23:32:33 visual_prompt]: Epoch 55 / 100: avg data time: 6.26e-02, avg batch time: 0.4745, average train loss: 5.3075
[09/25 23:32:34 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1582, average loss: 5.2255
[09/25 23:32:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:32:34 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/25 23:32:41 visual_prompt]: Epoch 56 / 100: avg data time: 5.62e-02, avg batch time: 0.4681, average train loss: 5.0370
[09/25 23:32:42 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 4.9671
[09/25 23:32:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/25 23:32:42 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/25 23:32:49 visual_prompt]: Epoch 57 / 100: avg data time: 5.90e-02, avg batch time: 0.4705, average train loss: 4.9550
[09/25 23:32:50 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1582, average loss: 4.8746
[09/25 23:32:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:32:50 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/25 23:32:57 visual_prompt]: Epoch 58 / 100: avg data time: 6.17e-02, avg batch time: 0.4737, average train loss: 4.8649
[09/25 23:32:58 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1580, average loss: 5.1494
[09/25 23:32:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:32:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/25 23:33:05 visual_prompt]: Epoch 59 / 100: avg data time: 6.36e-02, avg batch time: 0.4760, average train loss: 4.9508
[09/25 23:33:07 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 4.9136
[09/25 23:33:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/25 23:33:07 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/25 23:33:13 visual_prompt]: Epoch 60 / 100: avg data time: 6.32e-02, avg batch time: 0.4756, average train loss: 4.9761
[09/25 23:33:15 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 4.9732
[09/25 23:33:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/25 23:33:15 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/25 23:33:21 visual_prompt]: Epoch 61 / 100: avg data time: 6.62e-02, avg batch time: 0.4784, average train loss: 4.9246
[09/25 23:33:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1575, average loss: 4.9122
[09/25 23:33:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:33:23 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/25 23:33:29 visual_prompt]: Epoch 62 / 100: avg data time: 6.67e-02, avg batch time: 0.4799, average train loss: 4.8859
[09/25 23:33:31 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1580, average loss: 4.8681
[09/25 23:33:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 23:33:31 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/25 23:33:38 visual_prompt]: Epoch 63 / 100: avg data time: 5.76e-02, avg batch time: 0.4708, average train loss: 4.7935
[09/25 23:33:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 4.8240
[09/25 23:33:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/25 23:33:39 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/25 23:33:46 visual_prompt]: Epoch 64 / 100: avg data time: 6.50e-02, avg batch time: 0.4762, average train loss: 4.7624
[09/25 23:33:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 4.7381
[09/25 23:33:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.50	
[09/25 23:33:47 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/25 23:33:54 visual_prompt]: Epoch 65 / 100: avg data time: 5.02e-02, avg batch time: 0.4616, average train loss: 4.7787
[09/25 23:33:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 4.7138
[09/25 23:33:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 8.50	
[09/25 23:33:55 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/25 23:34:02 visual_prompt]: Epoch 66 / 100: avg data time: 6.22e-02, avg batch time: 0.4743, average train loss: 4.7430
[09/25 23:34:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1580, average loss: 4.7291
[09/25 23:34:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/25 23:34:03 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/25 23:34:10 visual_prompt]: Epoch 67 / 100: avg data time: 6.09e-02, avg batch time: 0.4727, average train loss: 4.7515
[09/25 23:34:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 4.7421
[09/25 23:34:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/25 23:34:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/25 23:34:18 visual_prompt]: Epoch 68 / 100: avg data time: 6.04e-02, avg batch time: 0.4722, average train loss: 4.7418
[09/25 23:34:20 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1581, average loss: 4.7066
[09/25 23:34:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:34:20 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/25 23:34:26 visual_prompt]: Epoch 69 / 100: avg data time: 6.02e-02, avg batch time: 0.4727, average train loss: 4.7097
[09/25 23:34:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1580, average loss: 4.6732
[09/25 23:34:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/25 23:34:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/25 23:34:34 visual_prompt]: Epoch 70 / 100: avg data time: 6.43e-02, avg batch time: 0.4763, average train loss: 4.6895
[09/25 23:34:36 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1585, average loss: 4.6238
[09/25 23:34:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/25 23:34:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/25 23:34:42 visual_prompt]: Epoch 71 / 100: avg data time: 6.36e-02, avg batch time: 0.4753, average train loss: 4.7089
[09/25 23:34:44 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1583, average loss: 4.6612
[09/25 23:34:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/25 23:34:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/25 23:34:51 visual_prompt]: Epoch 72 / 100: avg data time: 6.37e-02, avg batch time: 0.4752, average train loss: 4.8426
[09/25 23:34:52 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 4.9039
[09/25 23:34:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/25 23:34:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/25 23:34:59 visual_prompt]: Epoch 73 / 100: avg data time: 6.22e-02, avg batch time: 0.4739, average train loss: 4.7490
[09/25 23:35:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 4.6907
[09/25 23:35:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/25 23:35:00 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/25 23:35:07 visual_prompt]: Epoch 74 / 100: avg data time: 5.78e-02, avg batch time: 0.4704, average train loss: 4.7300
[09/25 23:35:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 4.6341
[09/25 23:35:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.00	
[09/25 23:35:08 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/25 23:35:15 visual_prompt]: Epoch 75 / 100: avg data time: 6.46e-02, avg batch time: 0.4778, average train loss: 4.6457
[09/25 23:35:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1576, average loss: 4.6623
[09/25 23:35:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/25 23:35:17 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/25 23:35:23 visual_prompt]: Epoch 76 / 100: avg data time: 6.01e-02, avg batch time: 0.4735, average train loss: 4.6128
[09/25 23:35:25 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1583, average loss: 4.5753
[09/25 23:35:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 11.00	
[09/25 23:35:25 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/25 23:35:31 visual_prompt]: Epoch 77 / 100: avg data time: 5.77e-02, avg batch time: 0.4707, average train loss: 4.5105
[09/25 23:35:33 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1580, average loss: 4.6386
[09/25 23:35:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/25 23:35:33 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/25 23:35:39 visual_prompt]: Epoch 78 / 100: avg data time: 6.28e-02, avg batch time: 0.4763, average train loss: 4.4446
[09/25 23:35:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1581, average loss: 4.6293
[09/25 23:35:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/25 23:35:41 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/25 23:35:47 visual_prompt]: Epoch 79 / 100: avg data time: 6.05e-02, avg batch time: 0.4734, average train loss: 4.5774
[09/25 23:35:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1578, average loss: 4.6852
[09/25 23:35:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.00	
[09/25 23:35:49 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/25 23:35:56 visual_prompt]: Epoch 80 / 100: avg data time: 6.02e-02, avg batch time: 0.4732, average train loss: 4.6521
[09/25 23:35:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1584, average loss: 4.6497
[09/25 23:35:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.00	
[09/25 23:35:57 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/25 23:36:04 visual_prompt]: Epoch 81 / 100: avg data time: 6.00e-02, avg batch time: 0.4739, average train loss: 4.4708
[09/25 23:36:05 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 4.5808
[09/25 23:36:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 8.00	
[09/25 23:36:05 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/25 23:36:12 visual_prompt]: Epoch 82 / 100: avg data time: 5.95e-02, avg batch time: 0.4724, average train loss: 4.4069
[09/25 23:36:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1578, average loss: 4.5070
[09/25 23:36:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 11.50	
[09/25 23:36:13 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/25 23:36:20 visual_prompt]: Epoch 83 / 100: avg data time: 6.18e-02, avg batch time: 0.4750, average train loss: 4.2711
[09/25 23:36:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1577, average loss: 4.4881
[09/25 23:36:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 14.50	
[09/25 23:36:21 visual_prompt]: Best epoch 83: best metric: 0.045
[09/25 23:36:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/25 23:36:28 visual_prompt]: Epoch 84 / 100: avg data time: 5.05e-02, avg batch time: 0.4641, average train loss: 3.9170
[09/25 23:36:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 4.2378
[09/25 23:36:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.50	top5: 26.00	
[09/25 23:36:29 visual_prompt]: Best epoch 84: best metric: 0.105
[09/25 23:36:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/25 23:36:36 visual_prompt]: Epoch 85 / 100: avg data time: 6.26e-02, avg batch time: 0.4752, average train loss: 3.4252
[09/25 23:36:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1578, average loss: 3.7219
[09/25 23:36:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 19.00	top5: 38.00	
[09/25 23:36:38 visual_prompt]: Best epoch 85: best metric: 0.190
[09/25 23:36:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/25 23:36:44 visual_prompt]: Epoch 86 / 100: avg data time: 6.07e-02, avg batch time: 0.4752, average train loss: 2.4191
[09/25 23:36:46 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 3.4425
[09/25 23:36:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 27.00	top5: 50.50	
[09/25 23:36:46 visual_prompt]: Best epoch 86: best metric: 0.270
[09/25 23:36:46 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/25 23:36:52 visual_prompt]: Epoch 87 / 100: avg data time: 5.99e-02, avg batch time: 0.4738, average train loss: 1.5293
[09/25 23:36:54 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1584, average loss: 2.5755
[09/25 23:36:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 38.00	top5: 66.00	
[09/25 23:36:54 visual_prompt]: Best epoch 87: best metric: 0.380
[09/25 23:36:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/25 23:37:00 visual_prompt]: Epoch 88 / 100: avg data time: 5.76e-02, avg batch time: 0.4721, average train loss: 0.7971
[09/25 23:37:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 2.1408
[09/25 23:37:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 50.00	top5: 76.00	
[09/25 23:37:02 visual_prompt]: Best epoch 88: best metric: 0.500
[09/25 23:37:02 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/25 23:37:08 visual_prompt]: Epoch 89 / 100: avg data time: 5.97e-02, avg batch time: 0.4727, average train loss: 0.3634
[09/25 23:37:10 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1582, average loss: 1.8496
[09/25 23:37:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 55.00	top5: 80.00	
[09/25 23:37:10 visual_prompt]: Best epoch 89: best metric: 0.550
[09/25 23:37:10 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/25 23:37:16 visual_prompt]: Epoch 90 / 100: avg data time: 5.51e-02, avg batch time: 0.4692, average train loss: 0.1946
[09/25 23:37:18 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1575, average loss: 1.7499
[09/25 23:37:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.00	top5: 81.50	
[09/25 23:37:18 visual_prompt]: Best epoch 90: best metric: 0.580
[09/25 23:37:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/25 23:37:25 visual_prompt]: Epoch 91 / 100: avg data time: 6.16e-02, avg batch time: 0.4758, average train loss: 0.1298
[09/25 23:37:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1585, average loss: 1.7732
[09/25 23:37:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.00	top5: 81.50	
[09/25 23:37:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/25 23:37:33 visual_prompt]: Epoch 92 / 100: avg data time: 5.84e-02, avg batch time: 0.4723, average train loss: 0.1077
[09/25 23:37:34 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1577, average loss: 1.7023
[09/25 23:37:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.00	top5: 83.50	
[09/25 23:37:34 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/25 23:37:41 visual_prompt]: Epoch 93 / 100: avg data time: 5.42e-02, avg batch time: 0.4691, average train loss: 0.0958
[09/25 23:37:42 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1583, average loss: 1.7089
[09/25 23:37:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 82.50	
[09/25 23:37:42 visual_prompt]: Best epoch 93: best metric: 0.595
[09/25 23:37:42 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/25 23:37:49 visual_prompt]: Epoch 94 / 100: avg data time: 6.44e-02, avg batch time: 0.4774, average train loss: 0.0889
[09/25 23:37:50 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 1.6693
[09/25 23:37:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.50	top5: 83.50	
[09/25 23:37:51 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/25 23:37:57 visual_prompt]: Epoch 95 / 100: avg data time: 6.83e-02, avg batch time: 0.4820, average train loss: 0.0868
[09/25 23:37:59 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1586, average loss: 1.6821
[09/25 23:37:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.00	top5: 83.50	
[09/25 23:37:59 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/25 23:38:05 visual_prompt]: Epoch 96 / 100: avg data time: 6.11e-02, avg batch time: 0.4752, average train loss: 0.0834
[09/25 23:38:07 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 1.6692
[09/25 23:38:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 83.50	
[09/25 23:38:07 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/25 23:38:13 visual_prompt]: Epoch 97 / 100: avg data time: 6.46e-02, avg batch time: 0.4776, average train loss: 0.0827
[09/25 23:38:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 1.6677
[09/25 23:38:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 83.50	
[09/25 23:38:15 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/25 23:38:22 visual_prompt]: Epoch 98 / 100: avg data time: 5.38e-02, avg batch time: 0.4690, average train loss: 0.0807
[09/25 23:38:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 1.6693
[09/25 23:38:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 83.50	
[09/25 23:38:23 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/25 23:38:30 visual_prompt]: Epoch 99 / 100: avg data time: 5.97e-02, avg batch time: 0.4733, average train loss: 0.0804
[09/25 23:38:31 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1583, average loss: 1.6674
[09/25 23:38:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 83.50	
[09/25 23:38:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/25 23:38:38 visual_prompt]: Epoch 100 / 100: avg data time: 6.28e-02, avg batch time: 0.4768, average train loss: 0.0816
[09/25 23:38:39 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1585, average loss: 1.6668
[09/25 23:38:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 84.00	
[09/25 23:38:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:38:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:38:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:38:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:38:39 visual_prompt]: Training with config:
[09/25 23:38:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:38:39 visual_prompt]: Loading training data...
[09/25 23:38:39 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:38:41 visual_prompt]: Number of images: 800
[09/25 23:38:41 visual_prompt]: Number of classes: 102 / 102
[09/25 23:38:41 visual_prompt]: Loading validation data...
[09/25 23:38:41 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:38:41 visual_prompt]: Number of images: 200
[09/25 23:38:41 visual_prompt]: Number of classes: 91 / 102
[09/25 23:38:41 visual_prompt]: Constructing models...
[09/25 23:38:44 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 23:38:44 visual_prompt]: tuned percent:0.625
[09/25 23:38:44 visual_prompt]: Device used for model: 0
[09/25 23:38:44 visual_prompt]: Setting up Evaluator...
[09/25 23:38:44 visual_prompt]: Setting up Trainer...
[09/25 23:38:44 visual_prompt]: 	Setting up the optimizer...
[09/25 23:38:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:38:50 visual_prompt]: Epoch 1 / 100: avg data time: 6.63e-02, avg batch time: 0.4839, average train loss: 4.6651
[09/25 23:38:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 4.6780
[09/25 23:38:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:38:52 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:38:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:38:58 visual_prompt]: Epoch 2 / 100: avg data time: 5.67e-02, avg batch time: 0.4703, average train loss: 4.6824
[09/25 23:39:00 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 4.5434
[09/25 23:39:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 12.50	
[09/25 23:39:00 visual_prompt]: Best epoch 2: best metric: 0.035
[09/25 23:39:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:39:06 visual_prompt]: Epoch 3 / 100: avg data time: 5.90e-02, avg batch time: 0.4723, average train loss: 4.7010
[09/25 23:39:08 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 4.6023
[09/25 23:39:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/25 23:39:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:39:15 visual_prompt]: Epoch 4 / 100: avg data time: 6.47e-02, avg batch time: 0.4786, average train loss: 4.9539
[09/25 23:39:16 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1587, average loss: 5.0558
[09/25 23:39:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/25 23:39:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:39:23 visual_prompt]: Epoch 5 / 100: avg data time: 6.04e-02, avg batch time: 0.4735, average train loss: 5.0592
[09/25 23:39:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 5.0764
[09/25 23:39:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 9.50	
[09/25 23:39:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:39:31 visual_prompt]: Epoch 6 / 100: avg data time: 6.22e-02, avg batch time: 0.4774, average train loss: 5.0064
[09/25 23:39:33 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 5.1135
[09/25 23:39:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 10.50	
[09/25 23:39:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:39:39 visual_prompt]: Epoch 7 / 100: avg data time: 6.03e-02, avg batch time: 0.4737, average train loss: 4.8814
[09/25 23:39:41 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1582, average loss: 4.6360
[09/25 23:39:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.50	top5: 18.00	
[09/25 23:39:41 visual_prompt]: Best epoch 7: best metric: 0.115
[09/25 23:39:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:39:47 visual_prompt]: Epoch 8 / 100: avg data time: 6.27e-02, avg batch time: 0.4770, average train loss: 4.3449
[09/25 23:39:49 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1587, average loss: 4.6463
[09/25 23:39:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 14.50	top5: 30.50	
[09/25 23:39:49 visual_prompt]: Best epoch 8: best metric: 0.145
[09/25 23:39:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:39:55 visual_prompt]: Epoch 9 / 100: avg data time: 6.24e-02, avg batch time: 0.4777, average train loss: 3.7272
[09/25 23:39:57 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1585, average loss: 2.5126
[09/25 23:39:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 48.00	top5: 70.50	
[09/25 23:39:57 visual_prompt]: Best epoch 9: best metric: 0.480
[09/25 23:39:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:40:04 visual_prompt]: Epoch 10 / 100: avg data time: 5.78e-02, avg batch time: 0.4735, average train loss: 2.3320
[09/25 23:40:05 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1586, average loss: 4.9715
[09/25 23:40:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 16.00	top5: 35.50	
[09/25 23:40:05 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:40:12 visual_prompt]: Epoch 11 / 100: avg data time: 6.55e-02, avg batch time: 0.4808, average train loss: 2.7300
[09/25 23:40:13 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1588, average loss: 4.2363
[09/25 23:40:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 35.50	top5: 58.50	
[09/25 23:40:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:40:20 visual_prompt]: Epoch 12 / 100: avg data time: 6.15e-02, avg batch time: 0.4755, average train loss: 2.2512
[09/25 23:40:22 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1581, average loss: 2.0805
[09/25 23:40:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.00	top5: 86.00	
[09/25 23:40:22 visual_prompt]: Best epoch 12: best metric: 0.630
[09/25 23:40:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:40:28 visual_prompt]: Epoch 13 / 100: avg data time: 6.57e-02, avg batch time: 0.4801, average train loss: 0.6712
[09/25 23:40:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1583, average loss: 1.3119
[09/25 23:40:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 89.00	
[09/25 23:40:30 visual_prompt]: Best epoch 13: best metric: 0.755
[09/25 23:40:30 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:40:36 visual_prompt]: Epoch 14 / 100: avg data time: 6.15e-02, avg batch time: 0.4766, average train loss: 0.4359
[09/25 23:40:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1587, average loss: 1.5082
[09/25 23:40:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.00	top5: 91.50	
[09/25 23:40:38 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:40:44 visual_prompt]: Epoch 15 / 100: avg data time: 5.92e-02, avg batch time: 0.4745, average train loss: 0.3766
[09/25 23:40:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 0.9100
[09/25 23:40:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 95.00	
[09/25 23:40:46 visual_prompt]: Best epoch 15: best metric: 0.815
[09/25 23:40:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:40:53 visual_prompt]: Epoch 16 / 100: avg data time: 6.00e-02, avg batch time: 0.4757, average train loss: 0.2923
[09/25 23:40:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1589, average loss: 0.8567
[09/25 23:40:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/25 23:40:54 visual_prompt]: Best epoch 16: best metric: 0.830
[09/25 23:40:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:41:01 visual_prompt]: Epoch 17 / 100: avg data time: 6.40e-02, avg batch time: 0.4789, average train loss: 0.2969
[09/25 23:41:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1582, average loss: 1.0069
[09/25 23:41:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 91.50	
[09/25 23:41:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:41:09 visual_prompt]: Epoch 18 / 100: avg data time: 7.02e-02, avg batch time: 0.4848, average train loss: 0.2437
[09/25 23:41:11 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1578, average loss: 1.2113
[09/25 23:41:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 92.00	
[09/25 23:41:11 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:41:17 visual_prompt]: Epoch 19 / 100: avg data time: 6.26e-02, avg batch time: 0.4773, average train loss: 0.1920
[09/25 23:41:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1587, average loss: 1.1829
[09/25 23:41:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.00	top5: 94.00	
[09/25 23:41:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:41:25 visual_prompt]: Epoch 20 / 100: avg data time: 5.98e-02, avg batch time: 0.4738, average train loss: 0.2546
[09/25 23:41:27 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1588, average loss: 1.6834
[09/25 23:41:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.00	top5: 87.50	
[09/25 23:41:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:41:34 visual_prompt]: Epoch 21 / 100: avg data time: 5.83e-02, avg batch time: 0.4720, average train loss: 0.3004
[09/25 23:41:35 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1587, average loss: 1.7589
[09/25 23:41:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 90.50	
[09/25 23:41:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:41:42 visual_prompt]: Epoch 22 / 100: avg data time: 6.09e-02, avg batch time: 0.4745, average train loss: 0.3243
[09/25 23:41:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1579, average loss: 0.8783
[09/25 23:41:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 92.00	
[09/25 23:41:43 visual_prompt]: Best epoch 22: best metric: 0.845
[09/25 23:41:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:41:50 visual_prompt]: Epoch 23 / 100: avg data time: 5.32e-02, avg batch time: 0.4679, average train loss: 0.1663
[09/25 23:41:51 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1587, average loss: 1.4211
[09/25 23:41:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 92.00	
[09/25 23:41:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:41:58 visual_prompt]: Epoch 24 / 100: avg data time: 7.40e-02, avg batch time: 0.4872, average train loss: 0.2355
[09/25 23:42:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1583, average loss: 1.3048
[09/25 23:42:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.50	top5: 91.00	
[09/25 23:42:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:42:06 visual_prompt]: Epoch 25 / 100: avg data time: 6.15e-02, avg batch time: 0.4759, average train loss: 0.2691
[09/25 23:42:08 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1586, average loss: 1.0436
[09/25 23:42:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 91.50	
[09/25 23:42:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:42:14 visual_prompt]: Epoch 26 / 100: avg data time: 6.14e-02, avg batch time: 0.4750, average train loss: 0.2382
[09/25 23:42:16 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 0.8347
[09/25 23:42:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.00	
[09/25 23:42:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:42:22 visual_prompt]: Epoch 27 / 100: avg data time: 5.90e-02, avg batch time: 0.4719, average train loss: 0.4767
[09/25 23:42:24 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1582, average loss: 1.3396
[09/25 23:42:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.00	top5: 90.50	
[09/25 23:42:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:42:31 visual_prompt]: Epoch 28 / 100: avg data time: 5.61e-02, avg batch time: 0.4699, average train loss: 0.3230
[09/25 23:42:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 0.8907
[09/25 23:42:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.00	
[09/25 23:42:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:42:39 visual_prompt]: Epoch 29 / 100: avg data time: 6.26e-02, avg batch time: 0.4766, average train loss: 0.1232
[09/25 23:42:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 1.1135
[09/25 23:42:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 92.50	
[09/25 23:42:40 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:42:47 visual_prompt]: Epoch 30 / 100: avg data time: 6.14e-02, avg batch time: 0.4750, average train loss: 0.2347
[09/25 23:42:48 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1584, average loss: 1.6431
[09/25 23:42:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.00	top5: 88.00	
[09/25 23:42:48 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:42:55 visual_prompt]: Epoch 31 / 100: avg data time: 6.48e-02, avg batch time: 0.4778, average train loss: 0.2735
[09/25 23:42:57 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.9952
[09/25 23:42:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.00	
[09/25 23:42:57 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:43:03 visual_prompt]: Epoch 32 / 100: avg data time: 6.21e-02, avg batch time: 0.4750, average train loss: 0.1882
[09/25 23:43:05 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1583, average loss: 1.8271
[09/25 23:43:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.00	top5: 84.00	
[09/25 23:43:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:43:11 visual_prompt]: Epoch 33 / 100: avg data time: 5.88e-02, avg batch time: 0.4717, average train loss: 0.2264
[09/25 23:43:13 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1581, average loss: 0.7233
[09/25 23:43:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.00	
[09/25 23:43:13 visual_prompt]: Best epoch 33: best metric: 0.860
[09/25 23:43:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:43:19 visual_prompt]: Epoch 34 / 100: avg data time: 6.41e-02, avg batch time: 0.4770, average train loss: 0.1355
[09/25 23:43:21 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1580, average loss: 0.8240
[09/25 23:43:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.50	
[09/25 23:43:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/25 23:43:27 visual_prompt]: Epoch 35 / 100: avg data time: 5.37e-02, avg batch time: 0.4681, average train loss: 0.0609
[09/25 23:43:29 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.8418
[09/25 23:43:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/25 23:43:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/25 23:43:36 visual_prompt]: Epoch 36 / 100: avg data time: 5.95e-02, avg batch time: 0.4724, average train loss: 0.0679
[09/25 23:43:37 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1579, average loss: 0.7194
[09/25 23:43:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 94.00	
[09/25 23:43:37 visual_prompt]: Best epoch 36: best metric: 0.875
[09/25 23:43:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/25 23:43:44 visual_prompt]: Epoch 37 / 100: avg data time: 6.58e-02, avg batch time: 0.4792, average train loss: 0.0486
[09/25 23:43:45 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1581, average loss: 0.7614
[09/25 23:43:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/25 23:43:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/25 23:43:52 visual_prompt]: Epoch 38 / 100: avg data time: 6.19e-02, avg batch time: 0.4743, average train loss: 0.0444
[09/25 23:43:53 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.6614
[09/25 23:43:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 95.50	
[09/25 23:43:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/25 23:44:00 visual_prompt]: Epoch 39 / 100: avg data time: 6.19e-02, avg batch time: 0.4743, average train loss: 0.0301
[09/25 23:44:02 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.5800
[09/25 23:44:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 95.00	
[09/25 23:44:02 visual_prompt]: Best epoch 39: best metric: 0.890
[09/25 23:44:02 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/25 23:44:08 visual_prompt]: Epoch 40 / 100: avg data time: 5.33e-02, avg batch time: 0.4676, average train loss: 0.0306
[09/25 23:44:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1582, average loss: 0.5726
[09/25 23:44:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.00	
[09/25 23:44:10 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/25 23:44:16 visual_prompt]: Epoch 41 / 100: avg data time: 5.22e-02, avg batch time: 0.4672, average train loss: 0.0148
[09/25 23:44:18 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1581, average loss: 0.4509
[09/25 23:44:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.00	
[09/25 23:44:18 visual_prompt]: Best epoch 41: best metric: 0.930
[09/25 23:44:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/25 23:44:24 visual_prompt]: Epoch 42 / 100: avg data time: 6.40e-02, avg batch time: 0.4764, average train loss: 0.0399
[09/25 23:44:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 0.4585
[09/25 23:44:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/25 23:44:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/25 23:44:32 visual_prompt]: Epoch 43 / 100: avg data time: 6.52e-02, avg batch time: 0.4784, average train loss: 0.0387
[09/25 23:44:34 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1577, average loss: 0.5601
[09/25 23:44:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/25 23:44:34 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/25 23:44:41 visual_prompt]: Epoch 44 / 100: avg data time: 6.16e-02, avg batch time: 0.4741, average train loss: 0.0359
[09/25 23:44:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1573, average loss: 0.4780
[09/25 23:44:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/25 23:44:42 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/25 23:44:49 visual_prompt]: Epoch 45 / 100: avg data time: 5.53e-02, avg batch time: 0.4687, average train loss: 0.0411
[09/25 23:44:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1578, average loss: 0.3872
[09/25 23:44:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/25 23:44:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/25 23:44:57 visual_prompt]: Epoch 46 / 100: avg data time: 6.05e-02, avg batch time: 0.4735, average train loss: 0.0138
[09/25 23:44:58 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1580, average loss: 0.4607
[09/25 23:44:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/25 23:44:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/25 23:45:05 visual_prompt]: Epoch 47 / 100: avg data time: 6.30e-02, avg batch time: 0.4760, average train loss: 0.0253
[09/25 23:45:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 0.4283
[09/25 23:45:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/25 23:45:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/25 23:45:13 visual_prompt]: Epoch 48 / 100: avg data time: 6.37e-02, avg batch time: 0.4765, average train loss: 0.0132
[09/25 23:45:15 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1583, average loss: 0.4667
[09/25 23:45:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/25 23:45:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/25 23:45:21 visual_prompt]: Epoch 49 / 100: avg data time: 6.06e-02, avg batch time: 0.4729, average train loss: 0.0178
[09/25 23:45:23 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1583, average loss: 0.4284
[09/25 23:45:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/25 23:45:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/25 23:45:29 visual_prompt]: Epoch 50 / 100: avg data time: 6.24e-02, avg batch time: 0.4749, average train loss: 0.0414
[09/25 23:45:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1584, average loss: 0.4644
[09/25 23:45:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/25 23:45:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/25 23:45:37 visual_prompt]: Epoch 51 / 100: avg data time: 5.72e-02, avg batch time: 0.4727, average train loss: 0.0342
[09/25 23:45:39 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1582, average loss: 0.4445
[09/25 23:45:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/25 23:45:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/25 23:45:46 visual_prompt]: Epoch 52 / 100: avg data time: 6.28e-02, avg batch time: 0.4760, average train loss: 0.0390
[09/25 23:45:47 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1586, average loss: 0.6330
[09/25 23:45:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 93.50	
[09/25 23:45:47 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/25 23:45:54 visual_prompt]: Epoch 53 / 100: avg data time: 6.18e-02, avg batch time: 0.4743, average train loss: 0.0377
[09/25 23:45:55 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1583, average loss: 0.3878
[09/25 23:45:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/25 23:45:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/25 23:46:02 visual_prompt]: Epoch 54 / 100: avg data time: 6.33e-02, avg batch time: 0.4763, average train loss: 0.0166
[09/25 23:46:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1582, average loss: 0.4594
[09/25 23:46:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.00	
[09/25 23:46:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/25 23:46:10 visual_prompt]: Epoch 55 / 100: avg data time: 6.36e-02, avg batch time: 0.4765, average train loss: 0.0092
[09/25 23:46:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1584, average loss: 0.3245
[09/25 23:46:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.50	
[09/25 23:46:12 visual_prompt]: Best epoch 55: best metric: 0.940
[09/25 23:46:12 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/25 23:46:18 visual_prompt]: Epoch 56 / 100: avg data time: 5.46e-02, avg batch time: 0.4707, average train loss: 0.2127
[09/25 23:46:20 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1579, average loss: 0.6282
[09/25 23:46:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 93.00	
[09/25 23:46:20 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/25 23:46:26 visual_prompt]: Epoch 57 / 100: avg data time: 5.98e-02, avg batch time: 0.4736, average train loss: 0.0838
[09/25 23:46:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.7345
[09/25 23:46:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 94.50	
[09/25 23:46:28 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/25 23:46:35 visual_prompt]: Epoch 58 / 100: avg data time: 6.37e-02, avg batch time: 0.4765, average train loss: 0.0562
[09/25 23:46:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1587, average loss: 0.4702
[09/25 23:46:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/25 23:46:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/25 23:46:43 visual_prompt]: Epoch 59 / 100: avg data time: 6.16e-02, avg batch time: 0.4747, average train loss: 0.0215
[09/25 23:46:44 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1585, average loss: 0.4620
[09/25 23:46:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/25 23:46:44 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/25 23:46:51 visual_prompt]: Epoch 60 / 100: avg data time: 5.44e-02, avg batch time: 0.4686, average train loss: 0.0112
[09/25 23:46:52 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 0.4658
[09/25 23:46:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/25 23:46:52 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/25 23:46:59 visual_prompt]: Epoch 61 / 100: avg data time: 6.10e-02, avg batch time: 0.4749, average train loss: 0.3262
[09/25 23:47:01 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1586, average loss: 0.4572
[09/25 23:47:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/25 23:47:01 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/25 23:47:07 visual_prompt]: Epoch 62 / 100: avg data time: 6.37e-02, avg batch time: 0.4773, average train loss: 0.0250
[09/25 23:47:09 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 0.4531
[09/25 23:47:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/25 23:47:09 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/25 23:47:15 visual_prompt]: Epoch 63 / 100: avg data time: 5.63e-02, avg batch time: 0.4699, average train loss: 0.0093
[09/25 23:47:17 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1585, average loss: 0.5265
[09/25 23:47:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/25 23:47:17 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/25 23:47:23 visual_prompt]: Epoch 64 / 100: avg data time: 6.14e-02, avg batch time: 0.4746, average train loss: 0.0070
[09/25 23:47:25 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1585, average loss: 0.3669
[09/25 23:47:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/25 23:47:25 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/25 23:47:32 visual_prompt]: Epoch 65 / 100: avg data time: 6.54e-02, avg batch time: 0.4783, average train loss: 0.0051
[09/25 23:47:33 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1582, average loss: 0.4953
[09/25 23:47:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 96.50	
[09/25 23:47:33 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/25 23:47:40 visual_prompt]: Epoch 66 / 100: avg data time: 5.99e-02, avg batch time: 0.4736, average train loss: 0.0057
[09/25 23:47:41 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1581, average loss: 0.3264
[09/25 23:47:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/25 23:47:41 visual_prompt]: Best epoch 66: best metric: 0.945
[09/25 23:47:41 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/25 23:47:48 visual_prompt]: Epoch 67 / 100: avg data time: 5.85e-02, avg batch time: 0.4728, average train loss: 0.0049
[09/25 23:47:49 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.3802
[09/25 23:47:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/25 23:47:49 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/25 23:47:56 visual_prompt]: Epoch 68 / 100: avg data time: 6.42e-02, avg batch time: 0.4774, average train loss: 0.0061
[09/25 23:47:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 0.3754
[09/25 23:47:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/25 23:47:58 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/25 23:48:04 visual_prompt]: Epoch 69 / 100: avg data time: 6.47e-02, avg batch time: 0.4781, average train loss: 0.0130
[09/25 23:48:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1579, average loss: 0.3840
[09/25 23:48:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/25 23:48:06 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/25 23:48:12 visual_prompt]: Epoch 70 / 100: avg data time: 5.22e-02, avg batch time: 0.4676, average train loss: 0.0064
[09/25 23:48:14 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.3696
[09/25 23:48:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:48:14 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/25 23:48:20 visual_prompt]: Epoch 71 / 100: avg data time: 5.98e-02, avg batch time: 0.4748, average train loss: 0.0056
[09/25 23:48:22 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1582, average loss: 0.3560
[09/25 23:48:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:48:22 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/25 23:48:29 visual_prompt]: Epoch 72 / 100: avg data time: 6.22e-02, avg batch time: 0.4754, average train loss: 0.0050
[09/25 23:48:30 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1587, average loss: 0.3257
[09/25 23:48:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:48:30 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/25 23:48:37 visual_prompt]: Epoch 73 / 100: avg data time: 5.90e-02, avg batch time: 0.4722, average train loss: 0.0047
[09/25 23:48:38 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.3128
[09/25 23:48:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:48:38 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/25 23:48:45 visual_prompt]: Epoch 74 / 100: avg data time: 5.89e-02, avg batch time: 0.4730, average train loss: 0.0048
[09/25 23:48:46 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1587, average loss: 0.3235
[09/25 23:48:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:48:46 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/25 23:48:53 visual_prompt]: Epoch 75 / 100: avg data time: 6.35e-02, avg batch time: 0.4766, average train loss: 0.0048
[09/25 23:48:54 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.3097
[09/25 23:48:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:48:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/25 23:49:01 visual_prompt]: Epoch 76 / 100: avg data time: 6.26e-02, avg batch time: 0.4753, average train loss: 0.0049
[09/25 23:49:03 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1579, average loss: 0.3110
[09/25 23:49:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:49:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/25 23:49:09 visual_prompt]: Epoch 77 / 100: avg data time: 5.88e-02, avg batch time: 0.4723, average train loss: 0.0049
[09/25 23:49:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 0.3114
[09/25 23:49:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/25 23:49:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/25 23:49:17 visual_prompt]: Epoch 78 / 100: avg data time: 5.81e-02, avg batch time: 0.4709, average train loss: 0.0049
[09/25 23:49:19 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1584, average loss: 0.3105
[09/25 23:49:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/25 23:49:19 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/25 23:49:25 visual_prompt]: Epoch 79 / 100: avg data time: 6.54e-02, avg batch time: 0.4790, average train loss: 0.0049
[09/25 23:49:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1587, average loss: 0.3006
[09/25 23:49:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/25 23:49:27 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/25 23:49:33 visual_prompt]: Epoch 80 / 100: avg data time: 4.86e-02, avg batch time: 0.4624, average train loss: 0.0050
[09/25 23:49:35 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1581, average loss: 0.3020
[09/25 23:49:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/25 23:49:35 visual_prompt]: Best epoch 80: best metric: 0.950
[09/25 23:49:35 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/25 23:49:42 visual_prompt]: Epoch 81 / 100: avg data time: 6.64e-02, avg batch time: 0.4788, average train loss: 0.0051
[09/25 23:49:43 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 0.3029
[09/25 23:49:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:49:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/25 23:49:50 visual_prompt]: Epoch 82 / 100: avg data time: 4.89e-02, avg batch time: 0.4634, average train loss: 0.0051
[09/25 23:49:51 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1578, average loss: 0.3043
[09/25 23:49:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/25 23:49:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/25 23:49:58 visual_prompt]: Epoch 83 / 100: avg data time: 7.02e-02, avg batch time: 0.4843, average train loss: 0.0050
[09/25 23:50:00 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1583, average loss: 0.2984
[09/25 23:50:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:50:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/25 23:50:06 visual_prompt]: Epoch 84 / 100: avg data time: 6.28e-02, avg batch time: 0.4747, average train loss: 0.0049
[09/25 23:50:08 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1578, average loss: 0.2966
[09/25 23:50:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/25 23:50:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/25 23:50:14 visual_prompt]: Epoch 85 / 100: avg data time: 6.84e-02, avg batch time: 0.4812, average train loss: 0.0049
[09/25 23:50:16 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1591, average loss: 0.2967
[09/25 23:50:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/25 23:50:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/25 23:50:22 visual_prompt]: Epoch 86 / 100: avg data time: 6.23e-02, avg batch time: 0.4749, average train loss: 0.0048
[09/25 23:50:24 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1580, average loss: 0.2966
[09/25 23:50:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/25 23:50:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/25 23:50:30 visual_prompt]: Epoch 87 / 100: avg data time: 5.48e-02, avg batch time: 0.4699, average train loss: 0.0049
[09/25 23:50:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.2961
[09/25 23:50:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:50:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/25 23:50:38 visual_prompt]: Epoch 88 / 100: avg data time: 4.57e-02, avg batch time: 0.4578, average train loss: 0.0049
[09/25 23:50:40 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1577, average loss: 0.2957
[09/25 23:50:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/25 23:50:40 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/25 23:50:46 visual_prompt]: Epoch 89 / 100: avg data time: 6.26e-02, avg batch time: 0.4756, average train loss: 0.0049
[09/25 23:50:48 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1579, average loss: 0.2948
[09/25 23:50:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/25 23:50:48 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/25 23:50:55 visual_prompt]: Epoch 90 / 100: avg data time: 6.46e-02, avg batch time: 0.4778, average train loss: 0.0048
[09/25 23:50:56 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1578, average loss: 0.3000
[09/25 23:50:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:50:56 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/25 23:51:03 visual_prompt]: Epoch 91 / 100: avg data time: 5.79e-02, avg batch time: 0.4714, average train loss: 0.0048
[09/25 23:51:04 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 0.2971
[09/25 23:51:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/25 23:51:04 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/25 23:51:11 visual_prompt]: Epoch 92 / 100: avg data time: 6.09e-02, avg batch time: 0.4731, average train loss: 0.0048
[09/25 23:51:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 0.2946
[09/25 23:51:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/25 23:51:12 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/25 23:51:19 visual_prompt]: Epoch 93 / 100: avg data time: 6.09e-02, avg batch time: 0.4733, average train loss: 0.0048
[09/25 23:51:20 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 0.2949
[09/25 23:51:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/25 23:51:20 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/25 23:51:27 visual_prompt]: Epoch 94 / 100: avg data time: 6.91e-02, avg batch time: 0.4815, average train loss: 0.0048
[09/25 23:51:29 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1586, average loss: 0.2953
[09/25 23:51:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:51:29 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/25 23:51:35 visual_prompt]: Epoch 95 / 100: avg data time: 6.27e-02, avg batch time: 0.4757, average train loss: 0.0048
[09/25 23:51:37 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1575, average loss: 0.2944
[09/25 23:51:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:51:37 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/25 23:51:43 visual_prompt]: Epoch 96 / 100: avg data time: 5.91e-02, avg batch time: 0.4720, average train loss: 0.0047
[09/25 23:51:45 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.2946
[09/25 23:51:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:51:45 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/25 23:51:52 visual_prompt]: Epoch 97 / 100: avg data time: 6.37e-02, avg batch time: 0.4767, average train loss: 0.0048
[09/25 23:51:53 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1584, average loss: 0.2945
[09/25 23:51:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:51:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/25 23:52:00 visual_prompt]: Epoch 98 / 100: avg data time: 6.37e-02, avg batch time: 0.4767, average train loss: 0.0048
[09/25 23:52:01 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1582, average loss: 0.2943
[09/25 23:52:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:52:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/25 23:52:08 visual_prompt]: Epoch 99 / 100: avg data time: 6.15e-02, avg batch time: 0.4750, average train loss: 0.0047
[09/25 23:52:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 0.2942
[09/25 23:52:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:52:10 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/25 23:52:16 visual_prompt]: Epoch 100 / 100: avg data time: 6.52e-02, avg batch time: 0.4781, average train loss: 0.0048
[09/25 23:52:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1584, average loss: 0.2943
[09/25 23:52:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/25 23:52:18 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:52:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:52:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:52:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:52:18 visual_prompt]: Training with config:
[09/25 23:52:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:52:18 visual_prompt]: Loading training data...
[09/25 23:52:18 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:52:19 visual_prompt]: Number of images: 800
[09/25 23:52:19 visual_prompt]: Number of classes: 102 / 102
[09/25 23:52:19 visual_prompt]: Loading validation data...
[09/25 23:52:19 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/25 23:52:19 visual_prompt]: Number of images: 200
[09/25 23:52:19 visual_prompt]: Number of classes: 91 / 102
[09/25 23:52:19 visual_prompt]: Constructing models...
[09/25 23:52:22 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/25 23:52:22 visual_prompt]: tuned percent:0.625
[09/25 23:52:22 visual_prompt]: Device used for model: 0
[09/25 23:52:22 visual_prompt]: Setting up Evaluator...
[09/25 23:52:22 visual_prompt]: Setting up Trainer...
[09/25 23:52:22 visual_prompt]: 	Setting up the optimizer...
[09/25 23:52:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:52:28 visual_prompt]: Epoch 1 / 100: avg data time: 6.41e-02, avg batch time: 0.4863, average train loss: 4.6701
[09/25 23:52:30 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 4.6780
[09/25 23:52:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/25 23:52:30 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:52:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:52:37 visual_prompt]: Epoch 2 / 100: avg data time: 6.33e-02, avg batch time: 0.4758, average train loss: 4.7107
[09/25 23:52:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 5.1275
[09/25 23:52:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/25 23:52:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:52:45 visual_prompt]: Epoch 3 / 100: avg data time: 6.21e-02, avg batch time: 0.4741, average train loss: 4.8624
[09/25 23:52:46 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1579, average loss: 4.7612
[09/25 23:52:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.50	
[09/25 23:52:46 visual_prompt]: Best epoch 3: best metric: 0.020
[09/25 23:52:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:52:53 visual_prompt]: Epoch 4 / 100: avg data time: 6.30e-02, avg batch time: 0.4755, average train loss: 4.6792
[09/25 23:52:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1584, average loss: 4.5473
[09/25 23:52:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 17.00	
[09/25 23:52:55 visual_prompt]: Best epoch 4: best metric: 0.025
[09/25 23:52:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:53:01 visual_prompt]: Epoch 5 / 100: avg data time: 5.99e-02, avg batch time: 0.4742, average train loss: 4.5974
[09/25 23:53:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 4.5390
[09/25 23:53:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 15.50	
[09/25 23:53:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:53:09 visual_prompt]: Epoch 6 / 100: avg data time: 5.44e-02, avg batch time: 0.4711, average train loss: 4.3037
[09/25 23:53:11 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1584, average loss: 4.2003
[09/25 23:53:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 26.00	
[09/25 23:53:11 visual_prompt]: Best epoch 6: best metric: 0.080
[09/25 23:53:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:53:18 visual_prompt]: Epoch 7 / 100: avg data time: 6.77e-02, avg batch time: 0.4812, average train loss: 3.5176
[09/25 23:53:19 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 4.0464
[09/25 23:53:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 17.50	top5: 45.00	
[09/25 23:53:19 visual_prompt]: Best epoch 7: best metric: 0.175
[09/25 23:53:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:53:26 visual_prompt]: Epoch 8 / 100: avg data time: 6.31e-02, avg batch time: 0.4768, average train loss: 3.4979
[09/25 23:53:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 2.5997
[09/25 23:53:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 50.00	top5: 68.50	
[09/25 23:53:27 visual_prompt]: Best epoch 8: best metric: 0.500
[09/25 23:53:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:53:34 visual_prompt]: Epoch 9 / 100: avg data time: 6.15e-02, avg batch time: 0.4755, average train loss: 2.0796
[09/25 23:53:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1586, average loss: 2.7917
[09/25 23:53:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 51.00	top5: 76.50	
[09/25 23:53:36 visual_prompt]: Best epoch 9: best metric: 0.510
[09/25 23:53:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:53:42 visual_prompt]: Epoch 10 / 100: avg data time: 6.19e-02, avg batch time: 0.4755, average train loss: 1.2922
[09/25 23:53:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 1.0749
[09/25 23:53:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.50	top5: 92.50	
[09/25 23:53:44 visual_prompt]: Best epoch 10: best metric: 0.735
[09/25 23:53:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:53:50 visual_prompt]: Epoch 11 / 100: avg data time: 5.48e-02, avg batch time: 0.4684, average train loss: 0.6354
[09/25 23:53:52 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 1.2238
[09/25 23:53:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 92.50	
[09/25 23:53:52 visual_prompt]: Best epoch 11: best metric: 0.755
[09/25 23:53:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:53:58 visual_prompt]: Epoch 12 / 100: avg data time: 6.41e-02, avg batch time: 0.4770, average train loss: 0.5662
[09/25 23:54:00 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 1.6636
[09/25 23:54:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 91.00	
[09/25 23:54:00 visual_prompt]: Best epoch 12: best metric: 0.785
[09/25 23:54:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:54:06 visual_prompt]: Epoch 13 / 100: avg data time: 6.38e-02, avg batch time: 0.4787, average train loss: 0.2709
[09/25 23:54:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.7353
[09/25 23:54:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:54:08 visual_prompt]: Best epoch 13: best metric: 0.880
[09/25 23:54:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:54:15 visual_prompt]: Epoch 14 / 100: avg data time: 6.32e-02, avg batch time: 0.4760, average train loss: 0.1714
[09/25 23:54:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1587, average loss: 0.8739
[09/25 23:54:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/25 23:54:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:54:23 visual_prompt]: Epoch 15 / 100: avg data time: 4.73e-02, avg batch time: 0.4636, average train loss: 0.2169
[09/25 23:54:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 1.0006
[09/25 23:54:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.00	
[09/25 23:54:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:54:31 visual_prompt]: Epoch 16 / 100: avg data time: 6.23e-02, avg batch time: 0.4748, average train loss: 0.1216
[09/25 23:54:32 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1577, average loss: 0.7541
[09/25 23:54:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/25 23:54:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:54:39 visual_prompt]: Epoch 17 / 100: avg data time: 6.06e-02, avg batch time: 0.4739, average train loss: 0.0348
[09/25 23:54:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 0.7078
[09/25 23:54:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.00	
[09/25 23:54:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:54:47 visual_prompt]: Epoch 18 / 100: avg data time: 6.09e-02, avg batch time: 0.4773, average train loss: 0.0517
[09/25 23:54:49 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1578, average loss: 0.7142
[09/25 23:54:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/25 23:54:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:54:55 visual_prompt]: Epoch 19 / 100: avg data time: 6.67e-02, avg batch time: 0.4803, average train loss: 0.0365
[09/25 23:54:57 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1581, average loss: 0.7324
[09/25 23:54:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/25 23:54:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:55:03 visual_prompt]: Epoch 20 / 100: avg data time: 6.72e-02, avg batch time: 0.4796, average train loss: 0.0043
[09/25 23:55:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.7341
[09/25 23:55:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/25 23:55:05 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:55:12 visual_prompt]: Epoch 21 / 100: avg data time: 7.09e-02, avg batch time: 0.4834, average train loss: 0.0018
[09/25 23:55:13 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1578, average loss: 0.7278
[09/25 23:55:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/25 23:55:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:55:20 visual_prompt]: Epoch 22 / 100: avg data time: 5.63e-02, avg batch time: 0.4694, average train loss: 0.0009
[09/25 23:55:21 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1586, average loss: 0.7429
[09/25 23:55:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/25 23:55:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:55:28 visual_prompt]: Epoch 23 / 100: avg data time: 6.70e-02, avg batch time: 0.4794, average train loss: 0.0009
[09/25 23:55:30 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1584, average loss: 0.7264
[09/25 23:55:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/25 23:55:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:55:36 visual_prompt]: Epoch 24 / 100: avg data time: 5.94e-02, avg batch time: 0.4724, average train loss: 0.0008
[09/25 23:55:38 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.7219
[09/25 23:55:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:55:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:55:44 visual_prompt]: Epoch 25 / 100: avg data time: 6.52e-02, avg batch time: 0.4775, average train loss: 0.0001
[09/25 23:55:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1585, average loss: 0.7190
[09/25 23:55:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/25 23:55:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:55:53 visual_prompt]: Epoch 26 / 100: avg data time: 5.97e-02, avg batch time: 0.4728, average train loss: 0.0002
[09/25 23:55:54 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1581, average loss: 0.7148
[09/25 23:55:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/25 23:55:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:56:01 visual_prompt]: Epoch 27 / 100: avg data time: 6.35e-02, avg batch time: 0.4764, average train loss: 0.0002
[09/25 23:56:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.7122
[09/25 23:56:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:56:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:56:09 visual_prompt]: Epoch 28 / 100: avg data time: 5.88e-02, avg batch time: 0.4712, average train loss: 0.0001
[09/25 23:56:10 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1583, average loss: 0.7108
[09/25 23:56:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:56:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:56:17 visual_prompt]: Epoch 29 / 100: avg data time: 5.27e-02, avg batch time: 0.4681, average train loss: 0.0001
[09/25 23:56:19 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1582, average loss: 0.7091
[09/25 23:56:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:56:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:56:25 visual_prompt]: Epoch 30 / 100: avg data time: 6.34e-02, avg batch time: 0.4770, average train loss: 0.0001
[09/25 23:56:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1577, average loss: 0.7073
[09/25 23:56:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/25 23:56:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:56:33 visual_prompt]: Epoch 31 / 100: avg data time: 6.83e-02, avg batch time: 0.4805, average train loss: 0.0002
[09/25 23:56:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 0.7081
[09/25 23:56:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/25 23:56:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:56:42 visual_prompt]: Epoch 32 / 100: avg data time: 6.05e-02, avg batch time: 0.4735, average train loss: 0.0001
[09/25 23:56:43 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1584, average loss: 0.7088
[09/25 23:56:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:56:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:56:50 visual_prompt]: Epoch 33 / 100: avg data time: 6.27e-02, avg batch time: 0.4765, average train loss: 0.0001
[09/25 23:56:51 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.7080
[09/25 23:56:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:56:51 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:56:58 visual_prompt]: Epoch 34 / 100: avg data time: 6.45e-02, avg batch time: 0.4769, average train loss: 0.0001
[09/25 23:57:00 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 0.7065
[09/25 23:57:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/25 23:57:06 visual_prompt]: Epoch 35 / 100: avg data time: 6.06e-02, avg batch time: 0.4742, average train loss: 0.0001
[09/25 23:57:08 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1586, average loss: 0.7054
[09/25 23:57:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:08 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/25 23:57:14 visual_prompt]: Epoch 36 / 100: avg data time: 6.79e-02, avg batch time: 0.4809, average train loss: 0.0001
[09/25 23:57:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.7039
[09/25 23:57:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/25 23:57:22 visual_prompt]: Epoch 37 / 100: avg data time: 5.32e-02, avg batch time: 0.4676, average train loss: 0.0001
[09/25 23:57:24 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1579, average loss: 0.7023
[09/25 23:57:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/25 23:57:31 visual_prompt]: Epoch 38 / 100: avg data time: 6.08e-02, avg batch time: 0.4753, average train loss: 0.0001
[09/25 23:57:32 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 0.7009
[09/25 23:57:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:32 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/25 23:57:39 visual_prompt]: Epoch 39 / 100: avg data time: 6.16e-02, avg batch time: 0.4748, average train loss: 0.0001
[09/25 23:57:40 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1580, average loss: 0.6999
[09/25 23:57:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/25 23:57:47 visual_prompt]: Epoch 40 / 100: avg data time: 6.38e-02, avg batch time: 0.4778, average train loss: 0.0001
[09/25 23:57:48 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 0.6993
[09/25 23:57:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/25 23:57:55 visual_prompt]: Epoch 41 / 100: avg data time: 6.02e-02, avg batch time: 0.4739, average train loss: 0.0001
[09/25 23:57:57 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.6990
[09/25 23:57:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:57:57 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/25 23:58:03 visual_prompt]: Epoch 42 / 100: avg data time: 6.56e-02, avg batch time: 0.4782, average train loss: 0.0001
[09/25 23:58:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 0.6986
[09/25 23:58:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:05 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/25 23:58:11 visual_prompt]: Epoch 43 / 100: avg data time: 6.76e-02, avg batch time: 0.4814, average train loss: 0.0001
[09/25 23:58:13 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1585, average loss: 0.6978
[09/25 23:58:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/25 23:58:20 visual_prompt]: Epoch 44 / 100: avg data time: 6.20e-02, avg batch time: 0.4754, average train loss: 0.0001
[09/25 23:58:21 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1584, average loss: 0.6971
[09/25 23:58:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/25 23:58:28 visual_prompt]: Epoch 45 / 100: avg data time: 6.28e-02, avg batch time: 0.4767, average train loss: 0.0001
[09/25 23:58:29 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1584, average loss: 0.6964
[09/25 23:58:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/25 23:58:36 visual_prompt]: Epoch 46 / 100: avg data time: 6.22e-02, avg batch time: 0.4749, average train loss: 0.0001
[09/25 23:58:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 0.6958
[09/25 23:58:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/25 23:58:44 visual_prompt]: Epoch 47 / 100: avg data time: 5.73e-02, avg batch time: 0.4719, average train loss: 0.0001
[09/25 23:58:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1577, average loss: 0.6952
[09/25 23:58:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/25 23:58:52 visual_prompt]: Epoch 48 / 100: avg data time: 6.68e-02, avg batch time: 0.4796, average train loss: 0.0001
[09/25 23:58:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.6946
[09/25 23:58:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:58:54 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/25 23:59:00 visual_prompt]: Epoch 49 / 100: avg data time: 7.07e-02, avg batch time: 0.4841, average train loss: 0.0001
[09/25 23:59:02 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.6942
[09/25 23:59:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:02 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/25 23:59:09 visual_prompt]: Epoch 50 / 100: avg data time: 6.31e-02, avg batch time: 0.4764, average train loss: 0.0000
[09/25 23:59:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.6938
[09/25 23:59:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:10 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/25 23:59:17 visual_prompt]: Epoch 51 / 100: avg data time: 5.78e-02, avg batch time: 0.4724, average train loss: 0.0000
[09/25 23:59:18 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 0.6932
[09/25 23:59:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/25 23:59:25 visual_prompt]: Epoch 52 / 100: avg data time: 6.74e-02, avg batch time: 0.4799, average train loss: 0.0001
[09/25 23:59:27 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1579, average loss: 0.6927
[09/25 23:59:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/25 23:59:33 visual_prompt]: Epoch 53 / 100: avg data time: 6.07e-02, avg batch time: 0.4746, average train loss: 0.0000
[09/25 23:59:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1582, average loss: 0.6922
[09/25 23:59:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/25 23:59:41 visual_prompt]: Epoch 54 / 100: avg data time: 6.15e-02, avg batch time: 0.4749, average train loss: 0.0000
[09/25 23:59:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.6918
[09/25 23:59:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/25 23:59:49 visual_prompt]: Epoch 55 / 100: avg data time: 6.02e-02, avg batch time: 0.4738, average train loss: 0.0001
[09/25 23:59:51 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 0.6915
[09/25 23:59:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/25 23:59:58 visual_prompt]: Epoch 56 / 100: avg data time: 6.29e-02, avg batch time: 0.4758, average train loss: 0.0001
[09/25 23:59:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1578, average loss: 0.6912
[09/25 23:59:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/25 23:59:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 00:00:06 visual_prompt]: Epoch 57 / 100: avg data time: 6.26e-02, avg batch time: 0.4766, average train loss: 0.0000
[09/26 00:00:07 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1578, average loss: 0.6910
[09/26 00:00:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 00:00:14 visual_prompt]: Epoch 58 / 100: avg data time: 6.62e-02, avg batch time: 0.4784, average train loss: 0.0000
[09/26 00:00:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 0.6909
[09/26 00:00:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 00:00:22 visual_prompt]: Epoch 59 / 100: avg data time: 5.40e-02, avg batch time: 0.4673, average train loss: 0.0001
[09/26 00:00:24 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 0.6907
[09/26 00:00:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 00:00:30 visual_prompt]: Epoch 60 / 100: avg data time: 6.08e-02, avg batch time: 0.4733, average train loss: 0.0000
[09/26 00:00:32 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1579, average loss: 0.6905
[09/26 00:00:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:32 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 00:00:38 visual_prompt]: Epoch 61 / 100: avg data time: 6.60e-02, avg batch time: 0.4793, average train loss: 0.0000
[09/26 00:00:40 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.6902
[09/26 00:00:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:40 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 00:00:46 visual_prompt]: Epoch 62 / 100: avg data time: 5.77e-02, avg batch time: 0.4707, average train loss: 0.0000
[09/26 00:00:48 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1580, average loss: 0.6900
[09/26 00:00:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:48 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 00:00:55 visual_prompt]: Epoch 63 / 100: avg data time: 6.25e-02, avg batch time: 0.4747, average train loss: 0.0001
[09/26 00:00:56 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1581, average loss: 0.6897
[09/26 00:00:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:00:56 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 00:01:03 visual_prompt]: Epoch 64 / 100: avg data time: 5.96e-02, avg batch time: 0.4737, average train loss: 0.0000
[09/26 00:01:04 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 0.6896
[09/26 00:01:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:04 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 00:01:11 visual_prompt]: Epoch 65 / 100: avg data time: 6.13e-02, avg batch time: 0.4739, average train loss: 0.0000
[09/26 00:01:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 0.6895
[09/26 00:01:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:13 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 00:01:19 visual_prompt]: Epoch 66 / 100: avg data time: 6.41e-02, avg batch time: 0.4766, average train loss: 0.0001
[09/26 00:01:21 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1581, average loss: 0.6894
[09/26 00:01:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:21 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 00:01:27 visual_prompt]: Epoch 67 / 100: avg data time: 6.46e-02, avg batch time: 0.4770, average train loss: 0.0000
[09/26 00:01:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1582, average loss: 0.6892
[09/26 00:01:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:29 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 00:01:35 visual_prompt]: Epoch 68 / 100: avg data time: 6.46e-02, avg batch time: 0.4771, average train loss: 0.0003
[09/26 00:01:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.6890
[09/26 00:01:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:37 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 00:01:44 visual_prompt]: Epoch 69 / 100: avg data time: 6.45e-02, avg batch time: 0.4787, average train loss: 0.0000
[09/26 00:01:45 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.6888
[09/26 00:01:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:45 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 00:01:52 visual_prompt]: Epoch 70 / 100: avg data time: 5.95e-02, avg batch time: 0.4723, average train loss: 0.0000
[09/26 00:01:53 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1581, average loss: 0.6887
[09/26 00:01:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:01:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 00:02:00 visual_prompt]: Epoch 71 / 100: avg data time: 5.46e-02, avg batch time: 0.4672, average train loss: 0.0001
[09/26 00:02:01 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 0.6885
[09/26 00:02:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:01 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 00:02:08 visual_prompt]: Epoch 72 / 100: avg data time: 6.51e-02, avg batch time: 0.4781, average train loss: 0.0000
[09/26 00:02:10 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1582, average loss: 0.6883
[09/26 00:02:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:10 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 00:02:16 visual_prompt]: Epoch 73 / 100: avg data time: 5.64e-02, avg batch time: 0.4697, average train loss: 0.0000
[09/26 00:02:18 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1581, average loss: 0.6881
[09/26 00:02:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:18 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 00:02:24 visual_prompt]: Epoch 74 / 100: avg data time: 6.52e-02, avg batch time: 0.4789, average train loss: 0.0001
[09/26 00:02:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.6880
[09/26 00:02:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:26 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 00:02:32 visual_prompt]: Epoch 75 / 100: avg data time: 5.47e-02, avg batch time: 0.4692, average train loss: 0.0000
[09/26 00:02:34 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1585, average loss: 0.6878
[09/26 00:02:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:34 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 00:02:41 visual_prompt]: Epoch 76 / 100: avg data time: 7.10e-02, avg batch time: 0.4837, average train loss: 0.0001
[09/26 00:02:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1581, average loss: 0.6878
[09/26 00:02:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:42 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 00:02:49 visual_prompt]: Epoch 77 / 100: avg data time: 6.55e-02, avg batch time: 0.4784, average train loss: 0.0000
[09/26 00:02:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 0.6877
[09/26 00:02:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:50 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 00:02:57 visual_prompt]: Epoch 78 / 100: avg data time: 4.90e-02, avg batch time: 0.4656, average train loss: 0.0001
[09/26 00:02:58 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1584, average loss: 0.6876
[09/26 00:02:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:02:58 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 00:03:05 visual_prompt]: Epoch 79 / 100: avg data time: 6.13e-02, avg batch time: 0.4756, average train loss: 0.0001
[09/26 00:03:07 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1579, average loss: 0.6875
[09/26 00:03:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:07 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 00:03:13 visual_prompt]: Epoch 80 / 100: avg data time: 6.32e-02, avg batch time: 0.4783, average train loss: 0.0000
[09/26 00:03:15 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 0.6874
[09/26 00:03:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:15 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 00:03:21 visual_prompt]: Epoch 81 / 100: avg data time: 6.45e-02, avg batch time: 0.4787, average train loss: 0.0000
[09/26 00:03:23 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1587, average loss: 0.6874
[09/26 00:03:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:23 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 00:03:30 visual_prompt]: Epoch 82 / 100: avg data time: 6.33e-02, avg batch time: 0.4768, average train loss: 0.0000
[09/26 00:03:31 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1587, average loss: 0.6873
[09/26 00:03:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:31 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 00:03:38 visual_prompt]: Epoch 83 / 100: avg data time: 6.35e-02, avg batch time: 0.4783, average train loss: 0.0001
[09/26 00:03:39 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.6873
[09/26 00:03:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:39 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 00:03:46 visual_prompt]: Epoch 84 / 100: avg data time: 5.79e-02, avg batch time: 0.4734, average train loss: 0.0000
[09/26 00:03:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.6872
[09/26 00:03:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:47 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 00:03:54 visual_prompt]: Epoch 85 / 100: avg data time: 6.10e-02, avg batch time: 0.4751, average train loss: 0.0000
[09/26 00:03:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1579, average loss: 0.6872
[09/26 00:03:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:03:56 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 00:04:02 visual_prompt]: Epoch 86 / 100: avg data time: 6.46e-02, avg batch time: 0.4788, average train loss: 0.0001
[09/26 00:04:04 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1586, average loss: 0.6872
[09/26 00:04:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:04 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 00:04:10 visual_prompt]: Epoch 87 / 100: avg data time: 5.95e-02, avg batch time: 0.4746, average train loss: 0.0001
[09/26 00:04:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 0.6872
[09/26 00:04:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:12 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 00:04:18 visual_prompt]: Epoch 88 / 100: avg data time: 6.45e-02, avg batch time: 0.4812, average train loss: 0.0000
[09/26 00:04:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1585, average loss: 0.6871
[09/26 00:04:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:20 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 00:04:27 visual_prompt]: Epoch 89 / 100: avg data time: 6.06e-02, avg batch time: 0.4749, average train loss: 0.0000
[09/26 00:04:28 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1588, average loss: 0.6871
[09/26 00:04:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:28 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 00:04:35 visual_prompt]: Epoch 90 / 100: avg data time: 6.77e-02, avg batch time: 0.4812, average train loss: 0.0000
[09/26 00:04:36 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1586, average loss: 0.6871
[09/26 00:04:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:36 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 00:04:43 visual_prompt]: Epoch 91 / 100: avg data time: 6.30e-02, avg batch time: 0.4768, average train loss: 0.0001
[09/26 00:04:45 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1582, average loss: 0.6871
[09/26 00:04:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:45 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 00:04:51 visual_prompt]: Epoch 92 / 100: avg data time: 6.28e-02, avg batch time: 0.4778, average train loss: 0.0000
[09/26 00:04:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1585, average loss: 0.6871
[09/26 00:04:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:04:53 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 00:04:59 visual_prompt]: Epoch 93 / 100: avg data time: 5.57e-02, avg batch time: 0.4699, average train loss: 0.0001
[09/26 00:05:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.6871
[09/26 00:05:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:01 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 00:05:07 visual_prompt]: Epoch 94 / 100: avg data time: 5.42e-02, avg batch time: 0.4691, average train loss: 0.0000
[09/26 00:05:09 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1580, average loss: 0.6871
[09/26 00:05:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:09 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 00:05:15 visual_prompt]: Epoch 95 / 100: avg data time: 6.18e-02, avg batch time: 0.4766, average train loss: 0.0000
[09/26 00:05:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1584, average loss: 0.6870
[09/26 00:05:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:17 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 00:05:24 visual_prompt]: Epoch 96 / 100: avg data time: 6.55e-02, avg batch time: 0.4785, average train loss: 0.0001
[09/26 00:05:25 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1585, average loss: 0.6870
[09/26 00:05:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:25 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 00:05:32 visual_prompt]: Epoch 97 / 100: avg data time: 6.49e-02, avg batch time: 0.4780, average train loss: 0.0001
[09/26 00:05:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 0.6870
[09/26 00:05:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:34 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 00:05:40 visual_prompt]: Epoch 98 / 100: avg data time: 6.27e-02, avg batch time: 0.4758, average train loss: 0.0001
[09/26 00:05:42 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1583, average loss: 0.6870
[09/26 00:05:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:42 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 00:05:48 visual_prompt]: Epoch 99 / 100: avg data time: 5.50e-02, avg batch time: 0.4679, average train loss: 0.0000
[09/26 00:05:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1586, average loss: 0.6870
[09/26 00:05:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:50 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 00:05:56 visual_prompt]: Epoch 100 / 100: avg data time: 4.93e-02, avg batch time: 0.4635, average train loss: 0.0000
[09/26 00:05:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1591, average loss: 0.6870
[09/26 00:05:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:05:58 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:05:58 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:05:58 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:05:58 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:05:58 visual_prompt]: Training with config:
[09/26 00:05:58 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:05:58 visual_prompt]: Loading training data...
[09/26 00:05:58 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:05:59 visual_prompt]: Number of images: 800
[09/26 00:05:59 visual_prompt]: Number of classes: 102 / 102
[09/26 00:05:59 visual_prompt]: Loading validation data...
[09/26 00:05:59 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:05:59 visual_prompt]: Number of images: 200
[09/26 00:05:59 visual_prompt]: Number of classes: 91 / 102
[09/26 00:05:59 visual_prompt]: Constructing models...
[09/26 00:06:02 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 00:06:02 visual_prompt]: tuned percent:0.625
[09/26 00:06:02 visual_prompt]: Device used for model: 0
[09/26 00:06:02 visual_prompt]: Setting up Evaluator...
[09/26 00:06:02 visual_prompt]: Setting up Trainer...
[09/26 00:06:02 visual_prompt]: 	Setting up the optimizer...
[09/26 00:06:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:06:08 visual_prompt]: Epoch 1 / 100: avg data time: 6.44e-02, avg batch time: 0.4837, average train loss: 4.6660
[09/26 00:06:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 4.6780
[09/26 00:06:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:06:10 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:06:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:06:17 visual_prompt]: Epoch 2 / 100: avg data time: 5.41e-02, avg batch time: 0.4686, average train loss: 4.6217
[09/26 00:06:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1579, average loss: 4.6062
[09/26 00:06:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/26 00:06:18 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 00:06:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:06:25 visual_prompt]: Epoch 3 / 100: avg data time: 6.61e-02, avg batch time: 0.4784, average train loss: 4.6602
[09/26 00:06:26 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1580, average loss: 4.6124
[09/26 00:06:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.50	
[09/26 00:06:26 visual_prompt]: Best epoch 3: best metric: 0.025
[09/26 00:06:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:06:33 visual_prompt]: Epoch 4 / 100: avg data time: 6.94e-02, avg batch time: 0.4822, average train loss: 4.6713
[09/26 00:06:35 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 4.7255
[09/26 00:06:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 00:06:35 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:06:41 visual_prompt]: Epoch 5 / 100: avg data time: 6.23e-02, avg batch time: 0.4745, average train loss: 4.7349
[09/26 00:06:43 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 4.7078
[09/26 00:06:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:06:43 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:06:49 visual_prompt]: Epoch 6 / 100: avg data time: 6.21e-02, avg batch time: 0.4741, average train loss: 4.7332
[09/26 00:06:51 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 4.8083
[09/26 00:06:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 00:06:51 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:06:58 visual_prompt]: Epoch 7 / 100: avg data time: 6.59e-02, avg batch time: 0.4778, average train loss: 4.7664
[09/26 00:06:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 4.8171
[09/26 00:06:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 00:06:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:07:06 visual_prompt]: Epoch 8 / 100: avg data time: 6.34e-02, avg batch time: 0.4755, average train loss: 4.8820
[09/26 00:07:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 4.8618
[09/26 00:07:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:07:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:07:14 visual_prompt]: Epoch 9 / 100: avg data time: 5.92e-02, avg batch time: 0.4713, average train loss: 4.9461
[09/26 00:07:16 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1583, average loss: 5.0308
[09/26 00:07:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/26 00:07:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:07:22 visual_prompt]: Epoch 10 / 100: avg data time: 6.26e-02, avg batch time: 0.4751, average train loss: 4.9881
[09/26 00:07:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1581, average loss: 5.0487
[09/26 00:07:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 00:07:24 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:07:30 visual_prompt]: Epoch 11 / 100: avg data time: 5.84e-02, avg batch time: 0.4719, average train loss: 5.1220
[09/26 00:07:32 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 4.9744
[09/26 00:07:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 00:07:32 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:07:38 visual_prompt]: Epoch 12 / 100: avg data time: 6.20e-02, avg batch time: 0.4738, average train loss: 4.9203
[09/26 00:07:40 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1580, average loss: 4.9201
[09/26 00:07:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:07:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:07:46 visual_prompt]: Epoch 13 / 100: avg data time: 6.41e-02, avg batch time: 0.4763, average train loss: 4.9659
[09/26 00:07:48 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1580, average loss: 4.9516
[09/26 00:07:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:07:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:07:55 visual_prompt]: Epoch 14 / 100: avg data time: 6.14e-02, avg batch time: 0.4741, average train loss: 4.9132
[09/26 00:07:56 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1579, average loss: 5.5583
[09/26 00:07:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 00:07:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:08:03 visual_prompt]: Epoch 15 / 100: avg data time: 6.06e-02, avg batch time: 0.4720, average train loss: 5.2611
[09/26 00:08:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1580, average loss: 4.8478
[09/26 00:08:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 00:08:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:08:11 visual_prompt]: Epoch 16 / 100: avg data time: 6.42e-02, avg batch time: 0.4761, average train loss: 4.9977
[09/26 00:08:13 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1577, average loss: 5.0569
[09/26 00:08:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/26 00:08:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:08:19 visual_prompt]: Epoch 17 / 100: avg data time: 7.12e-02, avg batch time: 0.4832, average train loss: 5.1663
[09/26 00:08:21 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1583, average loss: 5.0661
[09/26 00:08:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 00:08:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:08:27 visual_prompt]: Epoch 18 / 100: avg data time: 7.18e-02, avg batch time: 0.4834, average train loss: 5.1511
[09/26 00:08:29 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1581, average loss: 5.7062
[09/26 00:08:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/26 00:08:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:08:35 visual_prompt]: Epoch 19 / 100: avg data time: 4.98e-02, avg batch time: 0.4632, average train loss: 5.4276
[09/26 00:08:37 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 5.0626
[09/26 00:08:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/26 00:08:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:08:44 visual_prompt]: Epoch 20 / 100: avg data time: 5.11e-02, avg batch time: 0.4642, average train loss: 5.2126
[09/26 00:08:45 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1584, average loss: 5.6272
[09/26 00:08:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 00:08:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:08:51 visual_prompt]: Epoch 21 / 100: avg data time: 5.74e-02, avg batch time: 0.4702, average train loss: 5.3565
[09/26 00:08:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 5.1218
[09/26 00:08:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/26 00:08:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:09:00 visual_prompt]: Epoch 22 / 100: avg data time: 6.06e-02, avg batch time: 0.4737, average train loss: 4.9799
[09/26 00:09:01 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 4.9481
[09/26 00:09:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/26 00:09:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:09:08 visual_prompt]: Epoch 23 / 100: avg data time: 6.17e-02, avg batch time: 0.4731, average train loss: 4.9987
[09/26 00:09:09 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 4.9888
[09/26 00:09:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.00	
[09/26 00:09:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:09:16 visual_prompt]: Epoch 24 / 100: avg data time: 6.16e-02, avg batch time: 0.4758, average train loss: 4.9575
[09/26 00:09:17 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1586, average loss: 4.9441
[09/26 00:09:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/26 00:09:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:09:24 visual_prompt]: Epoch 25 / 100: avg data time: 6.01e-02, avg batch time: 0.4738, average train loss: 5.0924
[09/26 00:09:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1582, average loss: 5.0547
[09/26 00:09:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 00:09:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:09:32 visual_prompt]: Epoch 26 / 100: avg data time: 7.09e-02, avg batch time: 0.4826, average train loss: 5.0763
[09/26 00:09:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1579, average loss: 5.0351
[09/26 00:09:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 00:09:34 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:09:40 visual_prompt]: Epoch 27 / 100: avg data time: 5.86e-02, avg batch time: 0.4718, average train loss: 5.0150
[09/26 00:09:42 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1579, average loss: 4.8897
[09/26 00:09:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 00:09:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:09:49 visual_prompt]: Epoch 28 / 100: avg data time: 6.72e-02, avg batch time: 0.4789, average train loss: 5.1505
[09/26 00:09:50 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 4.9325
[09/26 00:09:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/26 00:09:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:09:57 visual_prompt]: Epoch 29 / 100: avg data time: 6.80e-02, avg batch time: 0.4807, average train loss: 5.0113
[09/26 00:09:58 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1582, average loss: 4.9577
[09/26 00:09:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 00:09:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:10:05 visual_prompt]: Epoch 30 / 100: avg data time: 6.12e-02, avg batch time: 0.4746, average train loss: 4.9569
[09/26 00:10:07 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 4.8756
[09/26 00:10:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/26 00:10:07 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:10:13 visual_prompt]: Epoch 31 / 100: avg data time: 6.25e-02, avg batch time: 0.4742, average train loss: 4.9594
[09/26 00:10:15 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1580, average loss: 4.8508
[09/26 00:10:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/26 00:10:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:10:21 visual_prompt]: Epoch 32 / 100: avg data time: 6.09e-02, avg batch time: 0.4737, average train loss: 4.9361
[09/26 00:10:23 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1578, average loss: 5.0523
[09/26 00:10:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:10:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:10:29 visual_prompt]: Epoch 33 / 100: avg data time: 6.23e-02, avg batch time: 0.4745, average train loss: 4.9520
[09/26 00:10:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 4.9080
[09/26 00:10:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/26 00:10:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:10:38 visual_prompt]: Epoch 34 / 100: avg data time: 6.27e-02, avg batch time: 0.4754, average train loss: 4.8339
[09/26 00:10:39 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1578, average loss: 4.7933
[09/26 00:10:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/26 00:10:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:10:46 visual_prompt]: Epoch 35 / 100: avg data time: 6.31e-02, avg batch time: 0.4749, average train loss: 4.9481
[09/26 00:10:47 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1582, average loss: 5.0228
[09/26 00:10:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:10:47 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:10:54 visual_prompt]: Epoch 36 / 100: avg data time: 6.63e-02, avg batch time: 0.4791, average train loss: 5.2523
[09/26 00:10:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1577, average loss: 4.8953
[09/26 00:10:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:10:56 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:11:02 visual_prompt]: Epoch 37 / 100: avg data time: 6.33e-02, avg batch time: 0.4761, average train loss: 5.1569
[09/26 00:11:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 5.0857
[09/26 00:11:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 00:11:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:11:10 visual_prompt]: Epoch 38 / 100: avg data time: 6.51e-02, avg batch time: 0.4783, average train loss: 5.4281
[09/26 00:11:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 5.7901
[09/26 00:11:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 00:11:12 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:11:19 visual_prompt]: Epoch 39 / 100: avg data time: 6.82e-02, avg batch time: 0.4800, average train loss: 5.3845
[09/26 00:11:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1574, average loss: 4.9286
[09/26 00:11:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/26 00:11:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:11:27 visual_prompt]: Epoch 40 / 100: avg data time: 6.26e-02, avg batch time: 0.4756, average train loss: 5.2271
[09/26 00:11:28 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1585, average loss: 5.6403
[09/26 00:11:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/26 00:11:28 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:11:35 visual_prompt]: Epoch 41 / 100: avg data time: 5.45e-02, avg batch time: 0.4681, average train loss: 5.0967
[09/26 00:11:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 4.8610
[09/26 00:11:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:11:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:11:43 visual_prompt]: Epoch 42 / 100: avg data time: 5.36e-02, avg batch time: 0.4661, average train loss: 5.1228
[09/26 00:11:44 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1578, average loss: 5.0120
[09/26 00:11:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 00:11:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:11:51 visual_prompt]: Epoch 43 / 100: avg data time: 6.25e-02, avg batch time: 0.4754, average train loss: 5.0685
[09/26 00:11:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1574, average loss: 4.8983
[09/26 00:11:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/26 00:11:53 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:11:59 visual_prompt]: Epoch 44 / 100: avg data time: 6.56e-02, avg batch time: 0.4781, average train loss: 6.2064
[09/26 00:12:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 5.2147
[09/26 00:12:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:12:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:12:07 visual_prompt]: Epoch 45 / 100: avg data time: 5.85e-02, avg batch time: 0.4708, average train loss: 5.7501
[09/26 00:12:09 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1576, average loss: 5.2571
[09/26 00:12:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/26 00:12:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:12:15 visual_prompt]: Epoch 46 / 100: avg data time: 6.00e-02, avg batch time: 0.4713, average train loss: 5.5977
[09/26 00:12:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1578, average loss: 5.2493
[09/26 00:12:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 00:12:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:12:23 visual_prompt]: Epoch 47 / 100: avg data time: 5.25e-02, avg batch time: 0.4665, average train loss: 5.5385
[09/26 00:12:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 5.0455
[09/26 00:12:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/26 00:12:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:12:31 visual_prompt]: Epoch 48 / 100: avg data time: 6.15e-02, avg batch time: 0.4750, average train loss: 5.3350
[09/26 00:12:33 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 4.9823
[09/26 00:12:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:12:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:12:40 visual_prompt]: Epoch 49 / 100: avg data time: 6.23e-02, avg batch time: 0.4755, average train loss: 5.3102
[09/26 00:12:41 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1578, average loss: 4.9253
[09/26 00:12:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 6.50	
[09/26 00:12:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:12:48 visual_prompt]: Epoch 50 / 100: avg data time: 5.96e-02, avg batch time: 0.4728, average train loss: 5.0389
[09/26 00:12:49 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1578, average loss: 4.8996
[09/26 00:12:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:12:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:12:56 visual_prompt]: Epoch 51 / 100: avg data time: 5.94e-02, avg batch time: 0.4723, average train loss: 4.9925
[09/26 00:12:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 4.8890
[09/26 00:12:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:12:57 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:13:04 visual_prompt]: Epoch 52 / 100: avg data time: 6.60e-02, avg batch time: 0.4786, average train loss: 4.8060
[09/26 00:13:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1587, average loss: 4.7904
[09/26 00:13:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:13:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:13:12 visual_prompt]: Epoch 53 / 100: avg data time: 6.14e-02, avg batch time: 0.4742, average train loss: 4.7464
[09/26 00:13:14 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1580, average loss: 4.7267
[09/26 00:13:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 00:13:14 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:13:20 visual_prompt]: Epoch 54 / 100: avg data time: 6.12e-02, avg batch time: 0.4741, average train loss: 4.8450
[09/26 00:13:22 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1583, average loss: 4.7855
[09/26 00:13:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:13:22 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:13:29 visual_prompt]: Epoch 55 / 100: avg data time: 6.62e-02, avg batch time: 0.4799, average train loss: 4.7907
[09/26 00:13:30 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 4.7704
[09/26 00:13:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 4.50	
[09/26 00:13:30 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:13:37 visual_prompt]: Epoch 56 / 100: avg data time: 6.58e-02, avg batch time: 0.4785, average train loss: 4.7532
[09/26 00:13:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 4.7710
[09/26 00:13:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:13:38 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:13:45 visual_prompt]: Epoch 57 / 100: avg data time: 6.06e-02, avg batch time: 0.4741, average train loss: 4.8158
[09/26 00:13:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1584, average loss: 4.7736
[09/26 00:13:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:13:47 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:13:53 visual_prompt]: Epoch 58 / 100: avg data time: 5.29e-02, avg batch time: 0.4671, average train loss: 4.7352
[09/26 00:13:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1581, average loss: 4.6861
[09/26 00:13:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/26 00:13:55 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:14:01 visual_prompt]: Epoch 59 / 100: avg data time: 6.06e-02, avg batch time: 0.4742, average train loss: 4.7693
[09/26 00:14:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 4.6923
[09/26 00:14:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 00:14:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:14:09 visual_prompt]: Epoch 60 / 100: avg data time: 6.63e-02, avg batch time: 0.4793, average train loss: 4.7222
[09/26 00:14:11 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1580, average loss: 4.7429
[09/26 00:14:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 00:14:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:14:17 visual_prompt]: Epoch 61 / 100: avg data time: 5.95e-02, avg batch time: 0.4724, average train loss: 4.7204
[09/26 00:14:19 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1580, average loss: 4.7721
[09/26 00:14:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:14:19 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:14:26 visual_prompt]: Epoch 62 / 100: avg data time: 6.29e-02, avg batch time: 0.4769, average train loss: 4.7494
[09/26 00:14:27 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1579, average loss: 4.7296
[09/26 00:14:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 00:14:27 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:14:34 visual_prompt]: Epoch 63 / 100: avg data time: 6.11e-02, avg batch time: 0.4738, average train loss: 4.7235
[09/26 00:14:35 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1578, average loss: 4.7085
[09/26 00:14:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 00:14:35 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:14:42 visual_prompt]: Epoch 64 / 100: avg data time: 6.28e-02, avg batch time: 0.4759, average train loss: 4.6899
[09/26 00:14:44 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1582, average loss: 4.6815
[09/26 00:14:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 00:14:44 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:14:50 visual_prompt]: Epoch 65 / 100: avg data time: 6.22e-02, avg batch time: 0.4757, average train loss: 4.7036
[09/26 00:14:52 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1585, average loss: 4.6688
[09/26 00:14:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.00	
[09/26 00:14:52 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:14:58 visual_prompt]: Epoch 66 / 100: avg data time: 5.94e-02, avg batch time: 0.4727, average train loss: 4.6924
[09/26 00:15:00 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 4.7552
[09/26 00:15:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:15:00 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:15:06 visual_prompt]: Epoch 67 / 100: avg data time: 6.30e-02, avg batch time: 0.4758, average train loss: 4.7271
[09/26 00:15:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 4.7219
[09/26 00:15:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 3.50	
[09/26 00:15:08 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:15:15 visual_prompt]: Epoch 68 / 100: avg data time: 6.52e-02, avg batch time: 0.4773, average train loss: 4.6949
[09/26 00:15:16 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1582, average loss: 4.8627
[09/26 00:15:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 00:15:16 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:15:23 visual_prompt]: Epoch 69 / 100: avg data time: 5.93e-02, avg batch time: 0.4714, average train loss: 4.6736
[09/26 00:15:24 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1578, average loss: 4.8021
[09/26 00:15:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:15:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:15:31 visual_prompt]: Epoch 70 / 100: avg data time: 6.29e-02, avg batch time: 0.4750, average train loss: 4.6740
[09/26 00:15:33 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1578, average loss: 4.6881
[09/26 00:15:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:15:33 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 00:15:39 visual_prompt]: Epoch 71 / 100: avg data time: 5.56e-02, avg batch time: 0.4681, average train loss: 4.6726
[09/26 00:15:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1586, average loss: 4.7161
[09/26 00:15:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 00:15:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 00:15:47 visual_prompt]: Epoch 72 / 100: avg data time: 6.62e-02, avg batch time: 0.4793, average train loss: 4.6704
[09/26 00:15:49 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1575, average loss: 4.7273
[09/26 00:15:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:15:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 00:15:55 visual_prompt]: Epoch 73 / 100: avg data time: 5.64e-02, avg batch time: 0.4695, average train loss: 4.6754
[09/26 00:15:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 4.6599
[09/26 00:15:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:15:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 00:16:04 visual_prompt]: Epoch 74 / 100: avg data time: 6.63e-02, avg batch time: 0.4780, average train loss: 4.6830
[09/26 00:16:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 4.6951
[09/26 00:16:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/26 00:16:05 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 00:16:12 visual_prompt]: Epoch 75 / 100: avg data time: 5.80e-02, avg batch time: 0.4708, average train loss: 4.6445
[09/26 00:16:13 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1579, average loss: 4.6769
[09/26 00:16:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.00	
[09/26 00:16:13 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 00:16:20 visual_prompt]: Epoch 76 / 100: avg data time: 5.99e-02, avg batch time: 0.4727, average train loss: 4.6622
[09/26 00:16:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1581, average loss: 4.6740
[09/26 00:16:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 00:16:21 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 00:16:28 visual_prompt]: Epoch 77 / 100: avg data time: 6.37e-02, avg batch time: 0.4770, average train loss: 4.6813
[09/26 00:16:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 4.6770
[09/26 00:16:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 00:16:30 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 00:16:36 visual_prompt]: Epoch 78 / 100: avg data time: 6.27e-02, avg batch time: 0.4756, average train loss: 4.6632
[09/26 00:16:38 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1575, average loss: 4.6696
[09/26 00:16:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 00:16:38 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 00:16:44 visual_prompt]: Epoch 79 / 100: avg data time: 6.24e-02, avg batch time: 0.4765, average train loss: 4.6514
[09/26 00:16:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 4.6693
[09/26 00:16:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/26 00:16:46 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 00:16:52 visual_prompt]: Epoch 80 / 100: avg data time: 5.58e-02, avg batch time: 0.4687, average train loss: 4.6399
[09/26 00:16:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 4.6608
[09/26 00:16:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:16:54 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 00:17:00 visual_prompt]: Epoch 81 / 100: avg data time: 4.88e-02, avg batch time: 0.4626, average train loss: 4.6444
[09/26 00:17:02 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1581, average loss: 4.6823
[09/26 00:17:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 00:17:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 00:17:09 visual_prompt]: Epoch 82 / 100: avg data time: 6.00e-02, avg batch time: 0.4722, average train loss: 4.6241
[09/26 00:17:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1580, average loss: 4.7095
[09/26 00:17:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/26 00:17:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 00:17:17 visual_prompt]: Epoch 83 / 100: avg data time: 6.24e-02, avg batch time: 0.4749, average train loss: 4.6265
[09/26 00:17:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1584, average loss: 4.6728
[09/26 00:17:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 00:17:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 00:17:25 visual_prompt]: Epoch 84 / 100: avg data time: 6.92e-02, avg batch time: 0.4815, average train loss: 4.6243
[09/26 00:17:27 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1584, average loss: 4.6619
[09/26 00:17:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 00:17:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 00:17:33 visual_prompt]: Epoch 85 / 100: avg data time: 6.36e-02, avg batch time: 0.4756, average train loss: 4.6135
[09/26 00:17:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1578, average loss: 4.6755
[09/26 00:17:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/26 00:17:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 00:17:41 visual_prompt]: Epoch 86 / 100: avg data time: 6.41e-02, avg batch time: 0.4765, average train loss: 4.6200
[09/26 00:17:43 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1584, average loss: 4.6650
[09/26 00:17:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 00:17:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 00:17:49 visual_prompt]: Epoch 87 / 100: avg data time: 6.18e-02, avg batch time: 0.4738, average train loss: 4.6236
[09/26 00:17:51 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1584, average loss: 4.6607
[09/26 00:17:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 00:17:51 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 00:17:58 visual_prompt]: Epoch 88 / 100: avg data time: 6.33e-02, avg batch time: 0.4775, average train loss: 4.6105
[09/26 00:17:59 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 4.6638
[09/26 00:17:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/26 00:17:59 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 00:18:06 visual_prompt]: Epoch 89 / 100: avg data time: 6.10e-02, avg batch time: 0.4741, average train loss: 4.6071
[09/26 00:18:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1580, average loss: 4.6801
[09/26 00:18:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.00	
[09/26 00:18:07 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 00:18:14 visual_prompt]: Epoch 90 / 100: avg data time: 6.36e-02, avg batch time: 0.4766, average train loss: 4.6072
[09/26 00:18:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1578, average loss: 4.6659
[09/26 00:18:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:18:16 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 00:18:22 visual_prompt]: Epoch 91 / 100: avg data time: 6.47e-02, avg batch time: 0.4773, average train loss: 4.5952
[09/26 00:18:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1579, average loss: 4.6620
[09/26 00:18:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 00:18:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 00:18:30 visual_prompt]: Epoch 92 / 100: avg data time: 6.06e-02, avg batch time: 0.4739, average train loss: 4.5871
[09/26 00:18:32 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1580, average loss: 4.6460
[09/26 00:18:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 00:18:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 00:18:38 visual_prompt]: Epoch 93 / 100: avg data time: 6.41e-02, avg batch time: 0.4764, average train loss: 4.5726
[09/26 00:18:40 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 4.7057
[09/26 00:18:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:18:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 00:18:47 visual_prompt]: Epoch 94 / 100: avg data time: 6.42e-02, avg batch time: 0.4773, average train loss: 4.5943
[09/26 00:18:48 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 4.6494
[09/26 00:18:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/26 00:18:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 00:18:55 visual_prompt]: Epoch 95 / 100: avg data time: 6.70e-02, avg batch time: 0.4798, average train loss: 4.5518
[09/26 00:18:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 4.6571
[09/26 00:18:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:18:57 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 00:19:03 visual_prompt]: Epoch 96 / 100: avg data time: 6.89e-02, avg batch time: 0.4819, average train loss: 4.5904
[09/26 00:19:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 4.6586
[09/26 00:19:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:19:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 00:19:11 visual_prompt]: Epoch 97 / 100: avg data time: 5.88e-02, avg batch time: 0.4718, average train loss: 4.5792
[09/26 00:19:13 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1582, average loss: 4.6594
[09/26 00:19:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:19:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 00:19:19 visual_prompt]: Epoch 98 / 100: avg data time: 5.10e-02, avg batch time: 0.4658, average train loss: 4.5887
[09/26 00:19:21 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1578, average loss: 4.6578
[09/26 00:19:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:19:21 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 00:19:27 visual_prompt]: Epoch 99 / 100: avg data time: 5.91e-02, avg batch time: 0.4716, average train loss: 4.5833
[09/26 00:19:29 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1577, average loss: 4.7044
[09/26 00:19:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:19:29 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 00:19:36 visual_prompt]: Epoch 100 / 100: avg data time: 5.59e-02, avg batch time: 0.4696, average train loss: 4.5895
[09/26 00:19:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1583, average loss: 4.6589
[09/26 00:19:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/26 00:19:37 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:19:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:19:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:19:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:19:37 visual_prompt]: Training with config:
[09/26 00:19:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:19:37 visual_prompt]: Loading training data...
[09/26 00:19:37 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:19:38 visual_prompt]: Number of images: 800
[09/26 00:19:38 visual_prompt]: Number of classes: 102 / 102
[09/26 00:19:38 visual_prompt]: Loading validation data...
[09/26 00:19:38 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:19:39 visual_prompt]: Number of images: 200
[09/26 00:19:39 visual_prompt]: Number of classes: 91 / 102
[09/26 00:19:39 visual_prompt]: Constructing models...
[09/26 00:19:41 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 00:19:41 visual_prompt]: tuned percent:0.625
[09/26 00:19:41 visual_prompt]: Device used for model: 0
[09/26 00:19:41 visual_prompt]: Setting up Evaluator...
[09/26 00:19:41 visual_prompt]: Setting up Trainer...
[09/26 00:19:41 visual_prompt]: 	Setting up the optimizer...
[09/26 00:19:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:19:48 visual_prompt]: Epoch 1 / 100: avg data time: 6.43e-02, avg batch time: 0.4810, average train loss: 4.6714
[09/26 00:19:50 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1578, average loss: 4.6780
[09/26 00:19:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:19:50 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:19:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:19:56 visual_prompt]: Epoch 2 / 100: avg data time: 6.01e-02, avg batch time: 0.4732, average train loss: 4.6277
[09/26 00:19:58 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1585, average loss: 4.5454
[09/26 00:19:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 13.50	
[09/26 00:19:58 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 00:19:58 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:20:04 visual_prompt]: Epoch 3 / 100: avg data time: 5.24e-02, avg batch time: 0.4648, average train loss: 4.4581
[09/26 00:20:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1577, average loss: 4.4668
[09/26 00:20:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 10.00	
[09/26 00:20:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:20:12 visual_prompt]: Epoch 4 / 100: avg data time: 6.40e-02, avg batch time: 0.4762, average train loss: 4.4176
[09/26 00:20:14 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 4.0524
[09/26 00:20:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 23.00	
[09/26 00:20:14 visual_prompt]: Best epoch 4: best metric: 0.065
[09/26 00:20:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:20:20 visual_prompt]: Epoch 5 / 100: avg data time: 6.04e-02, avg batch time: 0.4729, average train loss: 3.4651
[09/26 00:20:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 2.8842
[09/26 00:20:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 39.50	top5: 62.50	
[09/26 00:20:22 visual_prompt]: Best epoch 5: best metric: 0.395
[09/26 00:20:22 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:20:29 visual_prompt]: Epoch 6 / 100: avg data time: 5.74e-02, avg batch time: 0.4722, average train loss: 2.0680
[09/26 00:20:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 1.2284
[09/26 00:20:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.00	top5: 88.00	
[09/26 00:20:30 visual_prompt]: Best epoch 6: best metric: 0.710
[09/26 00:20:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:20:37 visual_prompt]: Epoch 7 / 100: avg data time: 5.98e-02, avg batch time: 0.4745, average train loss: 0.7818
[09/26 00:20:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 0.6504
[09/26 00:20:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 94.50	
[09/26 00:20:38 visual_prompt]: Best epoch 7: best metric: 0.835
[09/26 00:20:38 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:20:45 visual_prompt]: Epoch 8 / 100: avg data time: 6.08e-02, avg batch time: 0.4749, average train loss: 0.3843
[09/26 00:20:47 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1580, average loss: 0.6031
[09/26 00:20:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 00:20:47 visual_prompt]: Best epoch 8: best metric: 0.865
[09/26 00:20:47 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:20:53 visual_prompt]: Epoch 9 / 100: avg data time: 6.97e-02, avg batch time: 0.4837, average train loss: 0.2926
[09/26 00:20:55 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1578, average loss: 0.7167
[09/26 00:20:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 96.00	
[09/26 00:20:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:21:01 visual_prompt]: Epoch 10 / 100: avg data time: 5.74e-02, avg batch time: 0.4710, average train loss: 0.8521
[09/26 00:21:03 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1578, average loss: 3.7673
[09/26 00:21:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 16.50	top5: 41.00	
[09/26 00:21:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:21:10 visual_prompt]: Epoch 11 / 100: avg data time: 6.50e-02, avg batch time: 0.4784, average train loss: 4.2620
[09/26 00:21:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 5.3386
[09/26 00:21:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 00:21:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:21:18 visual_prompt]: Epoch 12 / 100: avg data time: 7.13e-02, avg batch time: 0.4846, average train loss: 5.2761
[09/26 00:21:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1586, average loss: 5.9169
[09/26 00:21:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:21:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:21:26 visual_prompt]: Epoch 13 / 100: avg data time: 5.08e-02, avg batch time: 0.4658, average train loss: 5.5602
[09/26 00:21:28 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1578, average loss: 5.4636
[09/26 00:21:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/26 00:21:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:21:34 visual_prompt]: Epoch 14 / 100: avg data time: 5.74e-02, avg batch time: 0.4724, average train loss: 5.1237
[09/26 00:21:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1577, average loss: 4.9536
[09/26 00:21:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 00:21:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:21:42 visual_prompt]: Epoch 15 / 100: avg data time: 6.65e-02, avg batch time: 0.4783, average train loss: 4.9628
[09/26 00:21:44 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1582, average loss: 5.1893
[09/26 00:21:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 00:21:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:21:50 visual_prompt]: Epoch 16 / 100: avg data time: 6.18e-02, avg batch time: 0.4746, average train loss: 5.1245
[09/26 00:21:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 4.8807
[09/26 00:21:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 00:21:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:21:59 visual_prompt]: Epoch 17 / 100: avg data time: 6.19e-02, avg batch time: 0.4740, average train loss: 4.9421
[09/26 00:22:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 4.7808
[09/26 00:22:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 00:22:00 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:22:07 visual_prompt]: Epoch 18 / 100: avg data time: 6.06e-02, avg batch time: 0.4739, average train loss: 4.8464
[09/26 00:22:09 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 4.8514
[09/26 00:22:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.50	
[09/26 00:22:09 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:22:15 visual_prompt]: Epoch 19 / 100: avg data time: 6.79e-02, avg batch time: 0.4795, average train loss: 4.9538
[09/26 00:22:17 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1583, average loss: 4.8364
[09/26 00:22:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 00:22:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:22:23 visual_prompt]: Epoch 20 / 100: avg data time: 6.53e-02, avg batch time: 0.4780, average train loss: 4.9719
[09/26 00:22:25 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1579, average loss: 4.9276
[09/26 00:22:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 00:22:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:22:32 visual_prompt]: Epoch 21 / 100: avg data time: 6.10e-02, avg batch time: 0.4746, average train loss: 4.9492
[09/26 00:22:33 visual_prompt]: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1587, average loss: 4.7205
[09/26 00:22:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:22:33 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:22:40 visual_prompt]: Epoch 22 / 100: avg data time: 5.43e-02, avg batch time: 0.4670, average train loss: 4.8418
[09/26 00:22:41 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1581, average loss: 4.8210
[09/26 00:22:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/26 00:22:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:22:48 visual_prompt]: Epoch 23 / 100: avg data time: 5.40e-02, avg batch time: 0.4704, average train loss: 4.8592
[09/26 00:22:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 4.7976
[09/26 00:22:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 4.50	
[09/26 00:22:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:22:56 visual_prompt]: Epoch 24 / 100: avg data time: 6.08e-02, avg batch time: 0.4731, average train loss: 4.9096
[09/26 00:22:57 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1582, average loss: 4.9694
[09/26 00:22:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/26 00:22:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:23:04 visual_prompt]: Epoch 25 / 100: avg data time: 6.69e-02, avg batch time: 0.4798, average train loss: 4.9906
[09/26 00:23:06 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1583, average loss: 4.9355
[09/26 00:23:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:23:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:23:12 visual_prompt]: Epoch 26 / 100: avg data time: 7.22e-02, avg batch time: 0.4842, average train loss: 4.9639
[09/26 00:23:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 4.9304
[09/26 00:23:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:23:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:23:21 visual_prompt]: Epoch 27 / 100: avg data time: 6.43e-02, avg batch time: 0.4767, average train loss: 4.8910
[09/26 00:23:22 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1581, average loss: 4.8065
[09/26 00:23:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:23:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:23:29 visual_prompt]: Epoch 28 / 100: avg data time: 6.50e-02, avg batch time: 0.4770, average train loss: 4.8489
[09/26 00:23:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 4.7814
[09/26 00:23:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.00	
[09/26 00:23:30 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:23:37 visual_prompt]: Epoch 29 / 100: avg data time: 7.13e-02, avg batch time: 0.4849, average train loss: 4.8530
[09/26 00:23:39 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 4.9743
[09/26 00:23:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 00:23:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:23:45 visual_prompt]: Epoch 30 / 100: avg data time: 6.28e-02, avg batch time: 0.4753, average train loss: 4.9268
[09/26 00:23:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 4.9897
[09/26 00:23:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/26 00:23:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:23:53 visual_prompt]: Epoch 31 / 100: avg data time: 6.04e-02, avg batch time: 0.4730, average train loss: 4.9845
[09/26 00:23:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1585, average loss: 4.9271
[09/26 00:23:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/26 00:23:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:24:01 visual_prompt]: Epoch 32 / 100: avg data time: 6.11e-02, avg batch time: 0.4726, average train loss: 4.8727
[09/26 00:24:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1572, average loss: 4.7683
[09/26 00:24:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 7.00	
[09/26 00:24:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:24:10 visual_prompt]: Epoch 33 / 100: avg data time: 6.65e-02, avg batch time: 0.4778, average train loss: 4.8695
[09/26 00:24:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 4.9168
[09/26 00:24:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/26 00:24:11 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:24:18 visual_prompt]: Epoch 34 / 100: avg data time: 6.43e-02, avg batch time: 0.4768, average train loss: 4.9785
[09/26 00:24:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 4.7654
[09/26 00:24:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:24:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:24:26 visual_prompt]: Epoch 35 / 100: avg data time: 6.94e-02, avg batch time: 0.4820, average train loss: 4.9037
[09/26 00:24:28 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 4.9776
[09/26 00:24:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:24:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:24:34 visual_prompt]: Epoch 36 / 100: avg data time: 6.95e-02, avg batch time: 0.4813, average train loss: 4.9546
[09/26 00:24:36 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1582, average loss: 4.8165
[09/26 00:24:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/26 00:24:36 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:24:42 visual_prompt]: Epoch 37 / 100: avg data time: 5.31e-02, avg batch time: 0.4673, average train loss: 4.8189
[09/26 00:24:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 4.7369
[09/26 00:24:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 00:24:44 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:24:51 visual_prompt]: Epoch 38 / 100: avg data time: 6.50e-02, avg batch time: 0.4769, average train loss: 4.8171
[09/26 00:24:52 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1581, average loss: 4.8098
[09/26 00:24:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/26 00:24:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:24:59 visual_prompt]: Epoch 39 / 100: avg data time: 5.84e-02, avg batch time: 0.4724, average train loss: 4.7708
[09/26 00:25:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 4.7919
[09/26 00:25:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 00:25:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:25:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.94e-02, avg batch time: 0.4721, average train loss: 4.7981
[09/26 00:25:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 4.8074
[09/26 00:25:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:25:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:25:15 visual_prompt]: Epoch 41 / 100: avg data time: 6.12e-02, avg batch time: 0.4740, average train loss: 4.8648
[09/26 00:25:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 4.8054
[09/26 00:25:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/26 00:25:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:25:23 visual_prompt]: Epoch 42 / 100: avg data time: 6.90e-02, avg batch time: 0.4817, average train loss: 4.9356
[09/26 00:25:25 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1587, average loss: 4.8324
[09/26 00:25:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 00:25:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:25:32 visual_prompt]: Epoch 43 / 100: avg data time: 6.78e-02, avg batch time: 0.4796, average train loss: 4.9804
[09/26 00:25:33 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 4.7658
[09/26 00:25:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/26 00:25:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:25:40 visual_prompt]: Epoch 44 / 100: avg data time: 6.24e-02, avg batch time: 0.4748, average train loss: 4.8865
[09/26 00:25:41 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1580, average loss: 4.8710
[09/26 00:25:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 00:25:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:25:48 visual_prompt]: Epoch 45 / 100: avg data time: 5.71e-02, avg batch time: 0.4707, average train loss: 4.8441
[09/26 00:25:49 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1580, average loss: 4.7749
[09/26 00:25:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:25:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:25:56 visual_prompt]: Epoch 46 / 100: avg data time: 6.14e-02, avg batch time: 0.4749, average train loss: 4.8316
[09/26 00:25:58 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 4.8353
[09/26 00:25:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.00	
[09/26 00:25:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:26:04 visual_prompt]: Epoch 47 / 100: avg data time: 6.19e-02, avg batch time: 0.4749, average train loss: 4.8305
[09/26 00:26:06 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 4.7098
[09/26 00:26:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 00:26:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:26:12 visual_prompt]: Epoch 48 / 100: avg data time: 6.24e-02, avg batch time: 0.4753, average train loss: 4.8353
[09/26 00:26:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1586, average loss: 4.8885
[09/26 00:26:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:26:14 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:26:20 visual_prompt]: Epoch 49 / 100: avg data time: 5.69e-02, avg batch time: 0.4699, average train loss: 4.9126
[09/26 00:26:22 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1581, average loss: 4.8385
[09/26 00:26:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 00:26:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:26:29 visual_prompt]: Epoch 50 / 100: avg data time: 7.30e-02, avg batch time: 0.4852, average train loss: 4.8405
[09/26 00:26:30 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1580, average loss: 4.7164
[09/26 00:26:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 00:26:30 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:26:37 visual_prompt]: Epoch 51 / 100: avg data time: 6.01e-02, avg batch time: 0.4737, average train loss: 4.7274
[09/26 00:26:39 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 4.7308
[09/26 00:26:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:26:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:26:45 visual_prompt]: Epoch 52 / 100: avg data time: 5.10e-02, avg batch time: 0.4675, average train loss: 4.7461
[09/26 00:26:47 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1584, average loss: 4.6417
[09/26 00:26:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.50	
[09/26 00:26:47 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:26:53 visual_prompt]: Epoch 53 / 100: avg data time: 4.72e-02, avg batch time: 0.4606, average train loss: 4.6914
[09/26 00:26:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 4.7778
[09/26 00:26:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 00:26:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:27:01 visual_prompt]: Epoch 54 / 100: avg data time: 5.93e-02, avg batch time: 0.4726, average train loss: 4.7304
[09/26 00:27:03 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1582, average loss: 4.7648
[09/26 00:27:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 9.50	
[09/26 00:27:03 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:27:09 visual_prompt]: Epoch 55 / 100: avg data time: 6.35e-02, avg batch time: 0.4768, average train loss: 4.7192
[09/26 00:27:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1583, average loss: 4.7576
[09/26 00:27:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:27:11 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:27:18 visual_prompt]: Epoch 56 / 100: avg data time: 6.56e-02, avg batch time: 0.4789, average train loss: 4.8356
[09/26 00:27:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 4.7254
[09/26 00:27:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 00:27:19 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:27:26 visual_prompt]: Epoch 57 / 100: avg data time: 5.85e-02, avg batch time: 0.4712, average train loss: 4.8085
[09/26 00:27:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 4.6716
[09/26 00:27:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 00:27:27 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:27:34 visual_prompt]: Epoch 58 / 100: avg data time: 6.27e-02, avg batch time: 0.4757, average train loss: 4.7733
[09/26 00:27:36 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1583, average loss: 4.7544
[09/26 00:27:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 00:27:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:27:42 visual_prompt]: Epoch 59 / 100: avg data time: 5.97e-02, avg batch time: 0.4736, average train loss: 4.6533
[09/26 00:27:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 4.6683
[09/26 00:27:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 7.00	
[09/26 00:27:44 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:27:50 visual_prompt]: Epoch 60 / 100: avg data time: 5.92e-02, avg batch time: 0.4741, average train loss: 4.5776
[09/26 00:27:52 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1585, average loss: 4.6260
[09/26 00:27:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/26 00:27:52 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:27:59 visual_prompt]: Epoch 61 / 100: avg data time: 6.41e-02, avg batch time: 0.4774, average train loss: 4.5820
[09/26 00:28:00 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1587, average loss: 4.6554
[09/26 00:28:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 00:28:00 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:28:07 visual_prompt]: Epoch 62 / 100: avg data time: 6.29e-02, avg batch time: 0.4774, average train loss: 4.5949
[09/26 00:28:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 4.5993
[09/26 00:28:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/26 00:28:08 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:28:15 visual_prompt]: Epoch 63 / 100: avg data time: 5.64e-02, avg batch time: 0.4706, average train loss: 4.5679
[09/26 00:28:17 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 4.6014
[09/26 00:28:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 5.50	
[09/26 00:28:17 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:28:23 visual_prompt]: Epoch 64 / 100: avg data time: 6.35e-02, avg batch time: 0.4760, average train loss: 4.5400
[09/26 00:28:25 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1581, average loss: 4.5880
[09/26 00:28:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 00:28:25 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:28:31 visual_prompt]: Epoch 65 / 100: avg data time: 6.63e-02, avg batch time: 0.4793, average train loss: 4.4814
[09/26 00:28:33 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1584, average loss: 4.6868
[09/26 00:28:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.00	
[09/26 00:28:33 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:28:40 visual_prompt]: Epoch 66 / 100: avg data time: 7.32e-02, avg batch time: 0.4856, average train loss: 4.4022
[09/26 00:28:41 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1578, average loss: 4.7914
[09/26 00:28:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 00:28:41 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:28:48 visual_prompt]: Epoch 67 / 100: avg data time: 6.05e-02, avg batch time: 0.4733, average train loss: 4.4749
[09/26 00:28:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1580, average loss: 4.5986
[09/26 00:28:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 8.50	
[09/26 00:28:49 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:28:56 visual_prompt]: Epoch 68 / 100: avg data time: 6.85e-02, avg batch time: 0.4805, average train loss: 4.4660
[09/26 00:28:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 4.5249
[09/26 00:28:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 12.00	
[09/26 00:28:58 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:29:04 visual_prompt]: Epoch 69 / 100: avg data time: 6.03e-02, avg batch time: 0.4744, average train loss: 4.4202
[09/26 00:29:06 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1581, average loss: 4.5997
[09/26 00:29:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.00	
[09/26 00:29:06 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:29:12 visual_prompt]: Epoch 70 / 100: avg data time: 6.16e-02, avg batch time: 0.4740, average train loss: 4.4548
[09/26 00:29:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 4.4871
[09/26 00:29:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 12.00	
[09/26 00:29:14 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 00:29:21 visual_prompt]: Epoch 71 / 100: avg data time: 5.84e-02, avg batch time: 0.4714, average train loss: 4.3707
[09/26 00:29:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1582, average loss: 4.5602
[09/26 00:29:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 10.50	
[09/26 00:29:22 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 00:29:29 visual_prompt]: Epoch 72 / 100: avg data time: 6.68e-02, avg batch time: 0.4791, average train loss: 4.2997
[09/26 00:29:30 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 4.5198
[09/26 00:29:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 12.00	
[09/26 00:29:30 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 00:29:37 visual_prompt]: Epoch 73 / 100: avg data time: 6.37e-02, avg batch time: 0.4759, average train loss: 4.2719
[09/26 00:29:39 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 4.5821
[09/26 00:29:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 8.50	
[09/26 00:29:39 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 00:29:45 visual_prompt]: Epoch 74 / 100: avg data time: 6.65e-02, avg batch time: 0.4791, average train loss: 4.2302
[09/26 00:29:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1581, average loss: 4.5947
[09/26 00:29:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 10.50	
[09/26 00:29:47 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 00:29:53 visual_prompt]: Epoch 75 / 100: avg data time: 6.14e-02, avg batch time: 0.4743, average train loss: 4.2442
[09/26 00:29:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 4.4106
[09/26 00:29:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 14.50	
[09/26 00:29:55 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 00:30:02 visual_prompt]: Epoch 76 / 100: avg data time: 6.20e-02, avg batch time: 0.4749, average train loss: 4.1846
[09/26 00:30:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 4.3244
[09/26 00:30:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 21.00	
[09/26 00:30:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 00:30:10 visual_prompt]: Epoch 77 / 100: avg data time: 5.74e-02, avg batch time: 0.4701, average train loss: 3.7759
[09/26 00:30:11 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 3.9097
[09/26 00:30:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 13.00	top5: 33.00	
[09/26 00:30:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 00:30:18 visual_prompt]: Epoch 78 / 100: avg data time: 5.50e-02, avg batch time: 0.4678, average train loss: 3.1053
[09/26 00:30:19 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1584, average loss: 2.9704
[09/26 00:30:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 26.50	top5: 58.50	
[09/26 00:30:19 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 00:30:26 visual_prompt]: Epoch 79 / 100: avg data time: 5.57e-02, avg batch time: 0.4695, average train loss: 1.7407
[09/26 00:30:27 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 2.2180
[09/26 00:30:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 47.50	top5: 72.50	
[09/26 00:30:27 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 00:30:34 visual_prompt]: Epoch 80 / 100: avg data time: 5.81e-02, avg batch time: 0.4706, average train loss: 0.7067
[09/26 00:30:35 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 1.7085
[09/26 00:30:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.50	top5: 84.50	
[09/26 00:30:35 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 00:30:42 visual_prompt]: Epoch 81 / 100: avg data time: 6.11e-02, avg batch time: 0.4742, average train loss: 0.2728
[09/26 00:30:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1579, average loss: 1.4035
[09/26 00:30:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.50	top5: 87.00	
[09/26 00:30:44 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 00:30:50 visual_prompt]: Epoch 82 / 100: avg data time: 6.20e-02, avg batch time: 0.4744, average train loss: 0.1325
[09/26 00:30:52 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1582, average loss: 1.2353
[09/26 00:30:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.00	top5: 90.00	
[09/26 00:30:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 00:30:58 visual_prompt]: Epoch 83 / 100: avg data time: 6.28e-02, avg batch time: 0.4769, average train loss: 0.0848
[09/26 00:31:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1582, average loss: 1.2147
[09/26 00:31:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 89.00	
[09/26 00:31:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 00:31:07 visual_prompt]: Epoch 84 / 100: avg data time: 6.42e-02, avg batch time: 0.4763, average train loss: 0.0713
[09/26 00:31:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 1.2452
[09/26 00:31:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.50	top5: 89.50	
[09/26 00:31:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 00:31:15 visual_prompt]: Epoch 85 / 100: avg data time: 5.97e-02, avg batch time: 0.4726, average train loss: 0.0665
[09/26 00:31:16 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1571, average loss: 1.2114
[09/26 00:31:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.00	top5: 90.50	
[09/26 00:31:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 00:31:23 visual_prompt]: Epoch 86 / 100: avg data time: 6.61e-02, avg batch time: 0.4791, average train loss: 0.0643
[09/26 00:31:25 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 1.2200
[09/26 00:31:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.00	top5: 90.50	
[09/26 00:31:25 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 00:31:31 visual_prompt]: Epoch 87 / 100: avg data time: 6.18e-02, avg batch time: 0.4745, average train loss: 0.0638
[09/26 00:31:33 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1580, average loss: 1.2002
[09/26 00:31:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.50	top5: 90.50	
[09/26 00:31:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 00:31:40 visual_prompt]: Epoch 88 / 100: avg data time: 6.46e-02, avg batch time: 0.4799, average train loss: 0.0631
[09/26 00:31:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 1.2048
[09/26 00:31:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.50	top5: 91.00	
[09/26 00:31:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 00:31:48 visual_prompt]: Epoch 89 / 100: avg data time: 6.18e-02, avg batch time: 0.4741, average train loss: 0.0633
[09/26 00:31:49 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1586, average loss: 1.2130
[09/26 00:31:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 00:31:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 00:31:56 visual_prompt]: Epoch 90 / 100: avg data time: 6.10e-02, avg batch time: 0.4735, average train loss: 0.0619
[09/26 00:31:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 1.2015
[09/26 00:31:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 00:31:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 00:32:04 visual_prompt]: Epoch 91 / 100: avg data time: 6.32e-02, avg batch time: 0.4764, average train loss: 0.0618
[09/26 00:32:06 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1583, average loss: 1.2000
[09/26 00:32:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.00	top5: 90.00	
[09/26 00:32:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 00:32:12 visual_prompt]: Epoch 92 / 100: avg data time: 6.20e-02, avg batch time: 0.4755, average train loss: 0.0619
[09/26 00:32:14 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1589, average loss: 1.1992
[09/26 00:32:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 89.50	
[09/26 00:32:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 00:32:21 visual_prompt]: Epoch 93 / 100: avg data time: 6.63e-02, avg batch time: 0.4801, average train loss: 0.0603
[09/26 00:32:22 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1585, average loss: 1.1947
[09/26 00:32:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.00	top5: 90.50	
[09/26 00:32:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 00:32:29 visual_prompt]: Epoch 94 / 100: avg data time: 5.93e-02, avg batch time: 0.4732, average train loss: 0.0595
[09/26 00:32:30 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1581, average loss: 1.1903
[09/26 00:32:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.00	top5: 90.00	
[09/26 00:32:30 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 00:32:37 visual_prompt]: Epoch 95 / 100: avg data time: 6.59e-02, avg batch time: 0.4787, average train loss: 0.0583
[09/26 00:32:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1581, average loss: 1.1871
[09/26 00:32:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 90.50	
[09/26 00:32:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 00:32:45 visual_prompt]: Epoch 96 / 100: avg data time: 6.17e-02, avg batch time: 0.4760, average train loss: 0.0589
[09/26 00:32:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1583, average loss: 1.1898
[09/26 00:32:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 00:32:47 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 00:32:53 visual_prompt]: Epoch 97 / 100: avg data time: 6.08e-02, avg batch time: 0.4742, average train loss: 0.0581
[09/26 00:32:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 1.1914
[09/26 00:32:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 90.50	
[09/26 00:32:55 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 00:33:01 visual_prompt]: Epoch 98 / 100: avg data time: 6.11e-02, avg batch time: 0.4746, average train loss: 0.0578
[09/26 00:33:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 1.1909
[09/26 00:33:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 00:33:03 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 00:33:09 visual_prompt]: Epoch 99 / 100: avg data time: 6.13e-02, avg batch time: 0.4742, average train loss: 0.0573
[09/26 00:33:11 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 1.1908
[09/26 00:33:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 00:33:11 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 00:33:18 visual_prompt]: Epoch 100 / 100: avg data time: 6.15e-02, avg batch time: 0.4751, average train loss: 0.0577
[09/26 00:33:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1579, average loss: 1.1905
[09/26 00:33:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 00:33:19 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:33:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:33:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:33:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:33:19 visual_prompt]: Training with config:
[09/26 00:33:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:33:19 visual_prompt]: Loading training data...
[09/26 00:33:19 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:33:20 visual_prompt]: Number of images: 800
[09/26 00:33:20 visual_prompt]: Number of classes: 102 / 102
[09/26 00:33:20 visual_prompt]: Loading validation data...
[09/26 00:33:20 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:33:21 visual_prompt]: Number of images: 200
[09/26 00:33:21 visual_prompt]: Number of classes: 91 / 102
[09/26 00:33:21 visual_prompt]: Constructing models...
[09/26 00:33:23 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 00:33:23 visual_prompt]: tuned percent:0.625
[09/26 00:33:23 visual_prompt]: Device used for model: 0
[09/26 00:33:23 visual_prompt]: Setting up Evaluator...
[09/26 00:33:23 visual_prompt]: Setting up Trainer...
[09/26 00:33:23 visual_prompt]: 	Setting up the optimizer...
[09/26 00:33:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:33:30 visual_prompt]: Epoch 1 / 100: avg data time: 5.24e-02, avg batch time: 0.4705, average train loss: 4.6661
[09/26 00:33:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 00:33:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:33:31 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:33:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:33:38 visual_prompt]: Epoch 2 / 100: avg data time: 6.70e-02, avg batch time: 0.4804, average train loss: 4.6278
[09/26 00:33:40 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1582, average loss: 4.6570
[09/26 00:33:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.00	
[09/26 00:33:40 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 00:33:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:33:46 visual_prompt]: Epoch 3 / 100: avg data time: 5.85e-02, avg batch time: 0.4708, average train loss: 4.6916
[09/26 00:33:48 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 4.6231
[09/26 00:33:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 10.50	
[09/26 00:33:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:33:54 visual_prompt]: Epoch 4 / 100: avg data time: 5.05e-02, avg batch time: 0.4676, average train loss: 4.6954
[09/26 00:33:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1581, average loss: 4.5406
[09/26 00:33:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 12.00	
[09/26 00:33:56 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 00:33:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:34:02 visual_prompt]: Epoch 5 / 100: avg data time: 5.13e-02, avg batch time: 0.4666, average train loss: 4.6054
[09/26 00:34:04 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1584, average loss: 4.4406
[09/26 00:34:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 17.50	
[09/26 00:34:04 visual_prompt]: Best epoch 5: best metric: 0.040
[09/26 00:34:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:34:11 visual_prompt]: Epoch 6 / 100: avg data time: 6.14e-02, avg batch time: 0.4747, average train loss: 3.6036
[09/26 00:34:12 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1580, average loss: 4.5688
[09/26 00:34:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 17.00	
[09/26 00:34:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:34:19 visual_prompt]: Epoch 7 / 100: avg data time: 6.34e-02, avg batch time: 0.4766, average train loss: 2.1587
[09/26 00:34:20 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1584, average loss: 1.5249
[09/26 00:34:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 63.50	top5: 85.00	
[09/26 00:34:20 visual_prompt]: Best epoch 7: best metric: 0.635
[09/26 00:34:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:34:27 visual_prompt]: Epoch 8 / 100: avg data time: 7.14e-02, avg batch time: 0.4845, average train loss: 0.9650
[09/26 00:34:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1588, average loss: 0.8640
[09/26 00:34:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 94.00	
[09/26 00:34:29 visual_prompt]: Best epoch 8: best metric: 0.775
[09/26 00:34:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:34:35 visual_prompt]: Epoch 9 / 100: avg data time: 6.48e-02, avg batch time: 0.4782, average train loss: 0.6254
[09/26 00:34:37 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1587, average loss: 1.1525
[09/26 00:34:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 90.50	
[09/26 00:34:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:34:44 visual_prompt]: Epoch 10 / 100: avg data time: 6.83e-02, avg batch time: 0.4812, average train loss: 0.4630
[09/26 00:34:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1582, average loss: 0.9505
[09/26 00:34:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 92.50	
[09/26 00:34:45 visual_prompt]: Best epoch 10: best metric: 0.810
[09/26 00:34:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:34:52 visual_prompt]: Epoch 11 / 100: avg data time: 5.19e-02, avg batch time: 0.4672, average train loss: 0.2969
[09/26 00:34:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.9702
[09/26 00:34:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 93.00	
[09/26 00:34:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:35:00 visual_prompt]: Epoch 12 / 100: avg data time: 6.25e-02, avg batch time: 0.4776, average train loss: 0.4044
[09/26 00:35:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 1.0738
[09/26 00:35:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 93.50	
[09/26 00:35:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:35:08 visual_prompt]: Epoch 13 / 100: avg data time: 6.02e-02, avg batch time: 0.4742, average train loss: 0.1351
[09/26 00:35:10 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 0.9617
[09/26 00:35:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 00:35:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:35:16 visual_prompt]: Epoch 14 / 100: avg data time: 6.19e-02, avg batch time: 0.4756, average train loss: 0.1447
[09/26 00:35:18 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1587, average loss: 0.8435
[09/26 00:35:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 94.00	
[09/26 00:35:18 visual_prompt]: Best epoch 14: best metric: 0.845
[09/26 00:35:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:35:24 visual_prompt]: Epoch 15 / 100: avg data time: 6.21e-02, avg batch time: 0.4766, average train loss: 0.1012
[09/26 00:35:26 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1592, average loss: 0.7421
[09/26 00:35:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 00:35:26 visual_prompt]: Best epoch 15: best metric: 0.865
[09/26 00:35:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:35:33 visual_prompt]: Epoch 16 / 100: avg data time: 6.72e-02, avg batch time: 0.4817, average train loss: 0.0616
[09/26 00:35:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 0.6845
[09/26 00:35:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 00:35:34 visual_prompt]: Best epoch 16: best metric: 0.870
[09/26 00:35:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:35:41 visual_prompt]: Epoch 17 / 100: avg data time: 6.24e-02, avg batch time: 0.4772, average train loss: 0.0728
[09/26 00:35:43 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.9038
[09/26 00:35:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 95.00	
[09/26 00:35:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:35:49 visual_prompt]: Epoch 18 / 100: avg data time: 6.66e-02, avg batch time: 0.4818, average train loss: 0.0551
[09/26 00:35:51 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 0.7513
[09/26 00:35:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 00:35:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:35:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.18e-02, avg batch time: 0.4770, average train loss: 0.0346
[09/26 00:35:59 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1585, average loss: 0.7252
[09/26 00:35:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.00	
[09/26 00:35:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:36:06 visual_prompt]: Epoch 20 / 100: avg data time: 6.89e-02, avg batch time: 0.4831, average train loss: 0.0185
[09/26 00:36:07 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1581, average loss: 0.5040
[09/26 00:36:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 00:36:07 visual_prompt]: Best epoch 20: best metric: 0.900
[09/26 00:36:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:36:14 visual_prompt]: Epoch 21 / 100: avg data time: 5.61e-02, avg batch time: 0.4715, average train loss: 0.0276
[09/26 00:36:15 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1586, average loss: 0.6195
[09/26 00:36:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 00:36:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:36:22 visual_prompt]: Epoch 22 / 100: avg data time: 6.80e-02, avg batch time: 0.4816, average train loss: 0.0219
[09/26 00:36:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 0.5293
[09/26 00:36:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 00:36:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:36:30 visual_prompt]: Epoch 23 / 100: avg data time: 5.37e-02, avg batch time: 0.4690, average train loss: 0.0065
[09/26 00:36:32 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1585, average loss: 0.4753
[09/26 00:36:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 97.50	
[09/26 00:36:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:36:38 visual_prompt]: Epoch 24 / 100: avg data time: 6.58e-02, avg batch time: 0.4817, average train loss: 0.0362
[09/26 00:36:40 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1587, average loss: 0.4693
[09/26 00:36:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 00:36:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:36:47 visual_prompt]: Epoch 25 / 100: avg data time: 6.47e-02, avg batch time: 0.4790, average train loss: 0.0159
[09/26 00:36:48 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1587, average loss: 0.4725
[09/26 00:36:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:36:48 visual_prompt]: Best epoch 25: best metric: 0.905
[09/26 00:36:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:36:55 visual_prompt]: Epoch 26 / 100: avg data time: 5.01e-02, avg batch time: 0.4673, average train loss: 0.0128
[09/26 00:36:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.4025
[09/26 00:36:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 99.00	
[09/26 00:36:56 visual_prompt]: Best epoch 26: best metric: 0.910
[09/26 00:36:56 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:37:03 visual_prompt]: Epoch 27 / 100: avg data time: 6.26e-02, avg batch time: 0.4759, average train loss: 0.0207
[09/26 00:37:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.3728
[09/26 00:37:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 00:37:04 visual_prompt]: Best epoch 27: best metric: 0.925
[09/26 00:37:04 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:37:11 visual_prompt]: Epoch 28 / 100: avg data time: 6.67e-02, avg batch time: 0.4810, average train loss: 0.0062
[09/26 00:37:13 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1587, average loss: 0.3623
[09/26 00:37:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 00:37:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:37:19 visual_prompt]: Epoch 29 / 100: avg data time: 5.81e-02, avg batch time: 0.4720, average train loss: 0.0067
[09/26 00:37:21 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1587, average loss: 0.3447
[09/26 00:37:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 00:37:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:37:27 visual_prompt]: Epoch 30 / 100: avg data time: 5.46e-02, avg batch time: 0.4700, average train loss: 0.0055
[09/26 00:37:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1587, average loss: 0.3411
[09/26 00:37:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 00:37:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:37:36 visual_prompt]: Epoch 31 / 100: avg data time: 6.71e-02, avg batch time: 0.4808, average train loss: 0.0054
[09/26 00:37:37 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1586, average loss: 0.3327
[09/26 00:37:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 00:37:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:37:44 visual_prompt]: Epoch 32 / 100: avg data time: 6.59e-02, avg batch time: 0.4790, average train loss: 0.0055
[09/26 00:37:46 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.3319
[09/26 00:37:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 00:37:46 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:37:52 visual_prompt]: Epoch 33 / 100: avg data time: 6.08e-02, avg batch time: 0.4750, average train loss: 0.0058
[09/26 00:37:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1590, average loss: 0.3249
[09/26 00:37:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 00:37:54 visual_prompt]: Best epoch 33: best metric: 0.930
[09/26 00:37:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:38:00 visual_prompt]: Epoch 34 / 100: avg data time: 6.41e-02, avg batch time: 0.4775, average train loss: 0.0060
[09/26 00:38:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 0.3218
[09/26 00:38:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 00:38:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:38:09 visual_prompt]: Epoch 35 / 100: avg data time: 6.94e-02, avg batch time: 0.4822, average train loss: 0.0062
[09/26 00:38:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 0.3254
[09/26 00:38:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:38:10 visual_prompt]: Best epoch 35: best metric: 0.935
[09/26 00:38:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:38:17 visual_prompt]: Epoch 36 / 100: avg data time: 5.37e-02, avg batch time: 0.4671, average train loss: 0.0062
[09/26 00:38:18 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.3220
[09/26 00:38:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 00:38:18 visual_prompt]: Best epoch 36: best metric: 0.945
[09/26 00:38:18 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:38:25 visual_prompt]: Epoch 37 / 100: avg data time: 6.80e-02, avg batch time: 0.4808, average train loss: 0.0062
[09/26 00:38:27 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1581, average loss: 0.3214
[09/26 00:38:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 00:38:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:38:33 visual_prompt]: Epoch 38 / 100: avg data time: 6.24e-02, avg batch time: 0.4757, average train loss: 0.0064
[09/26 00:38:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1580, average loss: 0.3069
[09/26 00:38:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 00:38:35 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:38:41 visual_prompt]: Epoch 39 / 100: avg data time: 6.86e-02, avg batch time: 0.4813, average train loss: 0.0062
[09/26 00:38:43 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1583, average loss: 0.3107
[09/26 00:38:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 00:38:43 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:38:50 visual_prompt]: Epoch 40 / 100: avg data time: 6.37e-02, avg batch time: 0.4774, average train loss: 0.0061
[09/26 00:38:51 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 0.3082
[09/26 00:38:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 00:38:51 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:38:58 visual_prompt]: Epoch 41 / 100: avg data time: 6.21e-02, avg batch time: 0.4754, average train loss: 0.0060
[09/26 00:38:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1579, average loss: 0.3016
[09/26 00:38:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 99.00	
[09/26 00:38:59 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:39:06 visual_prompt]: Epoch 42 / 100: avg data time: 5.86e-02, avg batch time: 0.4715, average train loss: 0.0060
[09/26 00:39:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1584, average loss: 0.2939
[09/26 00:39:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:39:07 visual_prompt]: Best epoch 42: best metric: 0.950
[09/26 00:39:07 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:39:14 visual_prompt]: Epoch 43 / 100: avg data time: 6.73e-02, avg batch time: 0.4811, average train loss: 0.0059
[09/26 00:39:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1586, average loss: 0.2939
[09/26 00:39:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 00:39:16 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:39:22 visual_prompt]: Epoch 44 / 100: avg data time: 5.89e-02, avg batch time: 0.4729, average train loss: 0.0058
[09/26 00:39:24 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 0.2959
[09/26 00:39:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:39:24 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:39:31 visual_prompt]: Epoch 45 / 100: avg data time: 6.31e-02, avg batch time: 0.4773, average train loss: 0.0056
[09/26 00:39:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 0.3040
[09/26 00:39:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.00	
[09/26 00:39:32 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:39:39 visual_prompt]: Epoch 46 / 100: avg data time: 6.11e-02, avg batch time: 0.4737, average train loss: 0.0054
[09/26 00:39:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.2883
[09/26 00:39:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.50	
[09/26 00:39:40 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:39:47 visual_prompt]: Epoch 47 / 100: avg data time: 6.54e-02, avg batch time: 0.4779, average train loss: 0.0054
[09/26 00:39:48 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.2929
[09/26 00:39:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.50	
[09/26 00:39:48 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:39:55 visual_prompt]: Epoch 48 / 100: avg data time: 4.66e-02, avg batch time: 0.4611, average train loss: 0.0054
[09/26 00:39:56 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1583, average loss: 0.2992
[09/26 00:39:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 00:39:56 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:40:03 visual_prompt]: Epoch 49 / 100: avg data time: 6.09e-02, avg batch time: 0.4736, average train loss: 0.0053
[09/26 00:40:05 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1582, average loss: 0.2799
[09/26 00:40:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:40:05 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:40:11 visual_prompt]: Epoch 50 / 100: avg data time: 6.55e-02, avg batch time: 0.4777, average train loss: 0.0052
[09/26 00:40:13 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1581, average loss: 0.3035
[09/26 00:40:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.00	
[09/26 00:40:13 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:40:19 visual_prompt]: Epoch 51 / 100: avg data time: 6.05e-02, avg batch time: 0.4733, average train loss: 0.0051
[09/26 00:40:21 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1581, average loss: 0.2749
[09/26 00:40:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.00	
[09/26 00:40:21 visual_prompt]: Best epoch 51: best metric: 0.955
[09/26 00:40:21 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:40:28 visual_prompt]: Epoch 52 / 100: avg data time: 6.40e-02, avg batch time: 0.4776, average train loss: 0.0049
[09/26 00:40:29 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1580, average loss: 0.2760
[09/26 00:40:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.50	
[09/26 00:40:29 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:40:36 visual_prompt]: Epoch 53 / 100: avg data time: 6.51e-02, avg batch time: 0.4773, average train loss: 0.0049
[09/26 00:40:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1581, average loss: 0.2880
[09/26 00:40:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 99.00	
[09/26 00:40:38 visual_prompt]: Best epoch 53: best metric: 0.960
[09/26 00:40:38 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:40:44 visual_prompt]: Epoch 54 / 100: avg data time: 6.42e-02, avg batch time: 0.4768, average train loss: 0.0048
[09/26 00:40:46 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1579, average loss: 0.2783
[09/26 00:40:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:40:46 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:40:52 visual_prompt]: Epoch 55 / 100: avg data time: 6.84e-02, avg batch time: 0.4821, average train loss: 0.0048
[09/26 00:40:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1578, average loss: 0.2880
[09/26 00:40:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:40:54 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:41:01 visual_prompt]: Epoch 56 / 100: avg data time: 6.63e-02, avg batch time: 0.4788, average train loss: 0.0048
[09/26 00:41:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 0.2820
[09/26 00:41:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.00	
[09/26 00:41:02 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:41:09 visual_prompt]: Epoch 57 / 100: avg data time: 5.87e-02, avg batch time: 0.4712, average train loss: 0.0046
[09/26 00:41:10 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1587, average loss: 0.2790
[09/26 00:41:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.00	
[09/26 00:41:10 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:41:17 visual_prompt]: Epoch 58 / 100: avg data time: 7.12e-02, avg batch time: 0.4839, average train loss: 0.0045
[09/26 00:41:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1587, average loss: 0.2952
[09/26 00:41:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:41:19 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:41:25 visual_prompt]: Epoch 59 / 100: avg data time: 6.27e-02, avg batch time: 0.4763, average train loss: 0.0044
[09/26 00:41:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1584, average loss: 0.2994
[09/26 00:41:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:41:27 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:41:33 visual_prompt]: Epoch 60 / 100: avg data time: 6.92e-02, avg batch time: 0.4827, average train loss: 0.0043
[09/26 00:41:35 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1580, average loss: 0.2848
[09/26 00:41:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.50	
[09/26 00:41:35 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:41:42 visual_prompt]: Epoch 61 / 100: avg data time: 6.50e-02, avg batch time: 0.4784, average train loss: 0.0043
[09/26 00:41:43 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1579, average loss: 0.2947
[09/26 00:41:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 00:41:43 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:41:50 visual_prompt]: Epoch 62 / 100: avg data time: 6.06e-02, avg batch time: 0.4738, average train loss: 0.0042
[09/26 00:41:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1578, average loss: 0.2872
[09/26 00:41:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 00:41:51 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:41:58 visual_prompt]: Epoch 63 / 100: avg data time: 5.44e-02, avg batch time: 0.4675, average train loss: 0.0042
[09/26 00:41:59 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1587, average loss: 0.2896
[09/26 00:41:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 00:41:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:42:06 visual_prompt]: Epoch 64 / 100: avg data time: 4.97e-02, avg batch time: 0.4644, average train loss: 0.0043
[09/26 00:42:08 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1585, average loss: 0.3036
[09/26 00:42:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 00:42:08 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:42:14 visual_prompt]: Epoch 65 / 100: avg data time: 6.49e-02, avg batch time: 0.4780, average train loss: 0.0043
[09/26 00:42:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1583, average loss: 0.2875
[09/26 00:42:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:42:16 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:42:22 visual_prompt]: Epoch 66 / 100: avg data time: 5.44e-02, avg batch time: 0.4676, average train loss: 0.0042
[09/26 00:42:24 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 0.2762
[09/26 00:42:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 00:42:24 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:42:30 visual_prompt]: Epoch 67 / 100: avg data time: 6.40e-02, avg batch time: 0.4796, average train loss: 0.0041
[09/26 00:42:32 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1580, average loss: 0.3091
[09/26 00:42:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 00:42:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:42:39 visual_prompt]: Epoch 68 / 100: avg data time: 6.57e-02, avg batch time: 0.4797, average train loss: 0.0041
[09/26 00:42:40 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 0.2808
[09/26 00:42:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 00:42:40 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:42:47 visual_prompt]: Epoch 69 / 100: avg data time: 5.91e-02, avg batch time: 0.4728, average train loss: 0.0041
[09/26 00:42:48 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 0.2872
[09/26 00:42:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.00	
[09/26 00:42:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:42:55 visual_prompt]: Epoch 70 / 100: avg data time: 5.81e-02, avg batch time: 0.4728, average train loss: 0.0041
[09/26 00:42:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.2986
[09/26 00:42:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 00:42:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 00:43:03 visual_prompt]: Epoch 71 / 100: avg data time: 7.04e-02, avg batch time: 0.4841, average train loss: 0.0040
[09/26 00:43:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.3353
[09/26 00:43:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.50	
[09/26 00:43:05 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 00:43:11 visual_prompt]: Epoch 72 / 100: avg data time: 6.58e-02, avg batch time: 0.4791, average train loss: 0.2129
[09/26 00:43:13 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1586, average loss: 3.7110
[09/26 00:43:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 32.00	top5: 51.50	
[09/26 00:43:13 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 00:43:20 visual_prompt]: Epoch 73 / 100: avg data time: 6.56e-02, avg batch time: 0.4800, average train loss: 2.8335
[09/26 00:43:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1579, average loss: 1.4506
[09/26 00:43:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 88.50	
[09/26 00:43:21 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 00:43:28 visual_prompt]: Epoch 74 / 100: avg data time: 6.43e-02, avg batch time: 0.4786, average train loss: 0.4893
[09/26 00:43:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1588, average loss: 0.5099
[09/26 00:43:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 00:43:30 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 00:43:36 visual_prompt]: Epoch 75 / 100: avg data time: 6.56e-02, avg batch time: 0.4797, average train loss: 0.1044
[09/26 00:43:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.3465
[09/26 00:43:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 00:43:38 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 00:43:45 visual_prompt]: Epoch 76 / 100: avg data time: 6.39e-02, avg batch time: 0.4789, average train loss: 0.0352
[09/26 00:43:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 0.3349
[09/26 00:43:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:43:46 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 00:43:53 visual_prompt]: Epoch 77 / 100: avg data time: 6.07e-02, avg batch time: 0.4744, average train loss: 0.0203
[09/26 00:43:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.3151
[09/26 00:43:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 00:43:55 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 00:44:01 visual_prompt]: Epoch 78 / 100: avg data time: 5.30e-02, avg batch time: 0.4699, average train loss: 0.0148
[09/26 00:44:03 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1581, average loss: 0.3045
[09/26 00:44:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:44:03 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 00:44:09 visual_prompt]: Epoch 79 / 100: avg data time: 5.54e-02, avg batch time: 0.4713, average train loss: 0.0088
[09/26 00:44:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1588, average loss: 0.3038
[09/26 00:44:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 00:44:11 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 00:44:17 visual_prompt]: Epoch 80 / 100: avg data time: 5.84e-02, avg batch time: 0.4733, average train loss: 0.0094
[09/26 00:44:19 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1584, average loss: 0.2906
[09/26 00:44:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:44:19 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 00:44:25 visual_prompt]: Epoch 81 / 100: avg data time: 5.85e-02, avg batch time: 0.4719, average train loss: 0.0087
[09/26 00:44:27 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 0.2979
[09/26 00:44:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 00:44:27 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 00:44:34 visual_prompt]: Epoch 82 / 100: avg data time: 5.56e-02, avg batch time: 0.4704, average train loss: 0.0067
[09/26 00:44:35 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1587, average loss: 0.3278
[09/26 00:44:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 00:44:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 00:44:42 visual_prompt]: Epoch 83 / 100: avg data time: 4.82e-02, avg batch time: 0.4645, average train loss: 0.0070
[09/26 00:44:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1576, average loss: 0.2882
[09/26 00:44:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:44:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 00:44:50 visual_prompt]: Epoch 84 / 100: avg data time: 6.18e-02, avg batch time: 0.4756, average train loss: 0.0062
[09/26 00:44:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 0.2866
[09/26 00:44:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:44:51 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 00:44:58 visual_prompt]: Epoch 85 / 100: avg data time: 6.55e-02, avg batch time: 0.4803, average train loss: 0.0058
[09/26 00:45:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.2872
[09/26 00:45:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:00 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 00:45:06 visual_prompt]: Epoch 86 / 100: avg data time: 5.15e-02, avg batch time: 0.4694, average train loss: 0.0061
[09/26 00:45:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.2885
[09/26 00:45:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:08 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 00:45:14 visual_prompt]: Epoch 87 / 100: avg data time: 6.15e-02, avg batch time: 0.4750, average train loss: 0.0055
[09/26 00:45:16 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 0.2868
[09/26 00:45:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:16 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 00:45:23 visual_prompt]: Epoch 88 / 100: avg data time: 6.30e-02, avg batch time: 0.4783, average train loss: 0.0056
[09/26 00:45:24 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1584, average loss: 0.2854
[09/26 00:45:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:24 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 00:45:31 visual_prompt]: Epoch 89 / 100: avg data time: 6.42e-02, avg batch time: 0.4776, average train loss: 0.0056
[09/26 00:45:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 0.2844
[09/26 00:45:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:33 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 00:45:39 visual_prompt]: Epoch 90 / 100: avg data time: 6.50e-02, avg batch time: 0.4796, average train loss: 0.0057
[09/26 00:45:41 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1583, average loss: 0.2846
[09/26 00:45:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:41 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 00:45:47 visual_prompt]: Epoch 91 / 100: avg data time: 6.29e-02, avg batch time: 0.4772, average train loss: 0.0055
[09/26 00:45:49 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.2851
[09/26 00:45:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 00:45:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 00:45:56 visual_prompt]: Epoch 92 / 100: avg data time: 5.94e-02, avg batch time: 0.4732, average train loss: 0.0052
[09/26 00:45:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.2854
[09/26 00:45:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:45:57 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 00:46:04 visual_prompt]: Epoch 93 / 100: avg data time: 6.25e-02, avg batch time: 0.4761, average train loss: 0.0052
[09/26 00:46:05 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1588, average loss: 0.2855
[09/26 00:46:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:05 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 00:46:12 visual_prompt]: Epoch 94 / 100: avg data time: 6.07e-02, avg batch time: 0.4755, average train loss: 0.0054
[09/26 00:46:13 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1582, average loss: 0.2860
[09/26 00:46:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:14 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 00:46:20 visual_prompt]: Epoch 95 / 100: avg data time: 6.53e-02, avg batch time: 0.4804, average train loss: 0.0054
[09/26 00:46:22 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1581, average loss: 0.2859
[09/26 00:46:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 00:46:28 visual_prompt]: Epoch 96 / 100: avg data time: 5.23e-02, avg batch time: 0.4671, average train loss: 0.0054
[09/26 00:46:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1592, average loss: 0.2860
[09/26 00:46:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:30 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 00:46:36 visual_prompt]: Epoch 97 / 100: avg data time: 6.00e-02, avg batch time: 0.4741, average train loss: 0.0054
[09/26 00:46:38 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 0.2859
[09/26 00:46:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:38 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 00:46:45 visual_prompt]: Epoch 98 / 100: avg data time: 6.33e-02, avg batch time: 0.4770, average train loss: 0.0055
[09/26 00:46:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1582, average loss: 0.2859
[09/26 00:46:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:46 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 00:46:53 visual_prompt]: Epoch 99 / 100: avg data time: 6.27e-02, avg batch time: 0.4767, average train loss: 0.0054
[09/26 00:46:54 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1583, average loss: 0.2859
[09/26 00:46:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:46:54 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 00:47:01 visual_prompt]: Epoch 100 / 100: avg data time: 6.49e-02, avg batch time: 0.4777, average train loss: 0.0053
[09/26 00:47:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.2859
[09/26 00:47:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 00:47:03 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:47:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:47:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:47:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:47:03 visual_prompt]: Training with config:
[09/26 00:47:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:47:03 visual_prompt]: Loading training data...
[09/26 00:47:03 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:47:04 visual_prompt]: Number of images: 800
[09/26 00:47:04 visual_prompt]: Number of classes: 102 / 102
[09/26 00:47:04 visual_prompt]: Loading validation data...
[09/26 00:47:04 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 00:47:04 visual_prompt]: Number of images: 200
[09/26 00:47:04 visual_prompt]: Number of classes: 91 / 102
[09/26 00:47:04 visual_prompt]: Constructing models...
[09/26 00:47:07 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 00:47:07 visual_prompt]: tuned percent:0.625
[09/26 00:47:07 visual_prompt]: Device used for model: 0
[09/26 00:47:07 visual_prompt]: Setting up Evaluator...
[09/26 00:47:07 visual_prompt]: Setting up Trainer...
[09/26 00:47:07 visual_prompt]: 	Setting up the optimizer...
[09/26 00:47:07 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:47:13 visual_prompt]: Epoch 1 / 100: avg data time: 6.18e-02, avg batch time: 0.4811, average train loss: 4.6668
[09/26 00:47:15 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1579, average loss: 4.6780
[09/26 00:47:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 00:47:15 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:47:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:47:21 visual_prompt]: Epoch 2 / 100: avg data time: 6.34e-02, avg batch time: 0.4760, average train loss: 4.6347
[09/26 00:47:23 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1580, average loss: 4.5723
[09/26 00:47:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 9.50	
[09/26 00:47:23 visual_prompt]: Best epoch 2: best metric: 0.045
[09/26 00:47:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:47:30 visual_prompt]: Epoch 3 / 100: avg data time: 6.47e-02, avg batch time: 0.4785, average train loss: 4.5514
[09/26 00:47:31 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1578, average loss: 4.3680
[09/26 00:47:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 17.00	
[09/26 00:47:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:47:38 visual_prompt]: Epoch 4 / 100: avg data time: 7.37e-02, avg batch time: 0.4863, average train loss: 4.2751
[09/26 00:47:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 4.0414
[09/26 00:47:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.00	top5: 24.50	
[09/26 00:47:40 visual_prompt]: Best epoch 4: best metric: 0.100
[09/26 00:47:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:47:46 visual_prompt]: Epoch 5 / 100: avg data time: 6.28e-02, avg batch time: 0.4754, average train loss: 3.7726
[09/26 00:47:48 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 3.1972
[09/26 00:47:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 29.50	top5: 51.50	
[09/26 00:47:48 visual_prompt]: Best epoch 5: best metric: 0.295
[09/26 00:47:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:47:54 visual_prompt]: Epoch 6 / 100: avg data time: 6.28e-02, avg batch time: 0.4767, average train loss: 1.9508
[09/26 00:47:56 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1577, average loss: 1.6861
[09/26 00:47:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 61.00	top5: 80.50	
[09/26 00:47:56 visual_prompt]: Best epoch 6: best metric: 0.610
[09/26 00:47:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:48:03 visual_prompt]: Epoch 7 / 100: avg data time: 5.35e-02, avg batch time: 0.4684, average train loss: 0.7690
[09/26 00:48:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1584, average loss: 1.0025
[09/26 00:48:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 92.50	
[09/26 00:48:04 visual_prompt]: Best epoch 7: best metric: 0.755
[09/26 00:48:04 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:48:11 visual_prompt]: Epoch 8 / 100: avg data time: 6.38e-02, avg batch time: 0.4791, average train loss: 0.2796
[09/26 00:48:12 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1578, average loss: 0.8855
[09/26 00:48:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 92.00	
[09/26 00:48:12 visual_prompt]: Best epoch 8: best metric: 0.800
[09/26 00:48:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:48:19 visual_prompt]: Epoch 9 / 100: avg data time: 6.16e-02, avg batch time: 0.4744, average train loss: 0.2090
[09/26 00:48:21 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1578, average loss: 0.8275
[09/26 00:48:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 92.00	
[09/26 00:48:21 visual_prompt]: Best epoch 9: best metric: 0.810
[09/26 00:48:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:48:27 visual_prompt]: Epoch 10 / 100: avg data time: 6.60e-02, avg batch time: 0.4791, average train loss: 0.1745
[09/26 00:48:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1576, average loss: 1.0004
[09/26 00:48:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 92.50	
[09/26 00:48:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:48:35 visual_prompt]: Epoch 11 / 100: avg data time: 5.34e-02, avg batch time: 0.4681, average train loss: 0.1224
[09/26 00:48:37 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1585, average loss: 0.7730
[09/26 00:48:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.00	
[09/26 00:48:37 visual_prompt]: Best epoch 11: best metric: 0.820
[09/26 00:48:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:48:44 visual_prompt]: Epoch 12 / 100: avg data time: 7.13e-02, avg batch time: 0.4851, average train loss: 0.1351
[09/26 00:48:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1587, average loss: 0.7953
[09/26 00:48:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 94.00	
[09/26 00:48:45 visual_prompt]: Best epoch 12: best metric: 0.845
[09/26 00:48:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:48:52 visual_prompt]: Epoch 13 / 100: avg data time: 6.79e-02, avg batch time: 0.4809, average train loss: 0.1005
[09/26 00:48:54 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1582, average loss: 0.9353
[09/26 00:48:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 94.50	
[09/26 00:48:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:49:00 visual_prompt]: Epoch 14 / 100: avg data time: 5.73e-02, avg batch time: 0.4718, average train loss: 0.0819
[09/26 00:49:02 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 0.6990
[09/26 00:49:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 00:49:02 visual_prompt]: Best epoch 14: best metric: 0.850
[09/26 00:49:02 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:49:08 visual_prompt]: Epoch 15 / 100: avg data time: 6.17e-02, avg batch time: 0.4748, average train loss: 0.0721
[09/26 00:49:10 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1581, average loss: 0.9316
[09/26 00:49:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.00	
[09/26 00:49:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:49:17 visual_prompt]: Epoch 16 / 100: avg data time: 6.86e-02, avg batch time: 0.4833, average train loss: 0.1681
[09/26 00:49:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.7294
[09/26 00:49:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 96.50	
[09/26 00:49:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:49:25 visual_prompt]: Epoch 17 / 100: avg data time: 6.85e-02, avg batch time: 0.4815, average train loss: 0.0246
[09/26 00:49:27 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 1.0513
[09/26 00:49:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 96.00	
[09/26 00:49:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:49:33 visual_prompt]: Epoch 18 / 100: avg data time: 6.39e-02, avg batch time: 0.4770, average train loss: 0.1070
[09/26 00:49:35 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1582, average loss: 0.9198
[09/26 00:49:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 92.50	
[09/26 00:49:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:49:41 visual_prompt]: Epoch 19 / 100: avg data time: 6.93e-02, avg batch time: 0.4827, average train loss: 0.0249
[09/26 00:49:43 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1586, average loss: 0.7290
[09/26 00:49:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 00:49:43 visual_prompt]: Best epoch 19: best metric: 0.865
[09/26 00:49:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:49:50 visual_prompt]: Epoch 20 / 100: avg data time: 6.33e-02, avg batch time: 0.4776, average train loss: 0.0384
[09/26 00:49:51 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1584, average loss: 0.6534
[09/26 00:49:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 00:49:51 visual_prompt]: Best epoch 20: best metric: 0.880
[09/26 00:49:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:49:58 visual_prompt]: Epoch 21 / 100: avg data time: 6.36e-02, avg batch time: 0.4768, average train loss: 0.0152
[09/26 00:50:00 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1582, average loss: 0.7179
[09/26 00:50:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 94.00	
[09/26 00:50:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:50:06 visual_prompt]: Epoch 22 / 100: avg data time: 6.45e-02, avg batch time: 0.4779, average train loss: 0.0220
[09/26 00:50:08 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1583, average loss: 0.6601
[09/26 00:50:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 94.00	
[09/26 00:50:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:50:14 visual_prompt]: Epoch 23 / 100: avg data time: 6.79e-02, avg batch time: 0.4813, average train loss: 0.0152
[09/26 00:50:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.5171
[09/26 00:50:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.00	
[09/26 00:50:16 visual_prompt]: Best epoch 23: best metric: 0.885
[09/26 00:50:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:50:23 visual_prompt]: Epoch 24 / 100: avg data time: 6.77e-02, avg batch time: 0.4812, average train loss: 0.0063
[09/26 00:50:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 0.5007
[09/26 00:50:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 00:50:24 visual_prompt]: Best epoch 24: best metric: 0.895
[09/26 00:50:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:50:31 visual_prompt]: Epoch 25 / 100: avg data time: 5.68e-02, avg batch time: 0.4714, average train loss: 0.0040
[09/26 00:50:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 0.5441
[09/26 00:50:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 95.50	
[09/26 00:50:32 visual_prompt]: Best epoch 25: best metric: 0.900
[09/26 00:50:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:50:39 visual_prompt]: Epoch 26 / 100: avg data time: 5.64e-02, avg batch time: 0.4710, average train loss: 0.0029
[09/26 00:50:41 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1586, average loss: 0.5058
[09/26 00:50:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 95.50	
[09/26 00:50:41 visual_prompt]: Best epoch 26: best metric: 0.910
[09/26 00:50:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:50:47 visual_prompt]: Epoch 27 / 100: avg data time: 6.39e-02, avg batch time: 0.4773, average train loss: 0.0003
[09/26 00:50:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 0.4983
[09/26 00:50:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.00	
[09/26 00:50:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:50:55 visual_prompt]: Epoch 28 / 100: avg data time: 6.13e-02, avg batch time: 0.4756, average train loss: 0.0003
[09/26 00:50:57 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1584, average loss: 0.4988
[09/26 00:50:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.00	
[09/26 00:50:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:51:04 visual_prompt]: Epoch 29 / 100: avg data time: 7.16e-02, avg batch time: 0.4848, average train loss: 0.0002
[09/26 00:51:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.4953
[09/26 00:51:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.00	
[09/26 00:51:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:51:12 visual_prompt]: Epoch 30 / 100: avg data time: 7.16e-02, avg batch time: 0.4844, average train loss: 0.0001
[09/26 00:51:14 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1580, average loss: 0.4934
[09/26 00:51:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 00:51:14 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:51:20 visual_prompt]: Epoch 31 / 100: avg data time: 6.05e-02, avg batch time: 0.4742, average train loss: 0.0001
[09/26 00:51:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.4919
[09/26 00:51:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 00:51:22 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:51:28 visual_prompt]: Epoch 32 / 100: avg data time: 5.81e-02, avg batch time: 0.4714, average train loss: 0.0001
[09/26 00:51:30 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1578, average loss: 0.4910
[09/26 00:51:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 00:51:30 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:51:37 visual_prompt]: Epoch 33 / 100: avg data time: 5.54e-02, avg batch time: 0.4707, average train loss: 0.0001
[09/26 00:51:38 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1585, average loss: 0.4901
[09/26 00:51:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:51:38 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:51:45 visual_prompt]: Epoch 34 / 100: avg data time: 6.74e-02, avg batch time: 0.4805, average train loss: 0.0001
[09/26 00:51:46 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.4894
[09/26 00:51:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:51:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:51:53 visual_prompt]: Epoch 35 / 100: avg data time: 6.81e-02, avg batch time: 0.4819, average train loss: 0.0001
[09/26 00:51:55 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 0.4889
[09/26 00:51:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:51:55 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:52:01 visual_prompt]: Epoch 36 / 100: avg data time: 5.92e-02, avg batch time: 0.4747, average train loss: 0.0001
[09/26 00:52:03 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 0.4882
[09/26 00:52:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:52:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:52:10 visual_prompt]: Epoch 37 / 100: avg data time: 6.45e-02, avg batch time: 0.4792, average train loss: 0.0001
[09/26 00:52:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1583, average loss: 0.4878
[09/26 00:52:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:52:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:52:18 visual_prompt]: Epoch 38 / 100: avg data time: 6.12e-02, avg batch time: 0.4736, average train loss: 0.0001
[09/26 00:52:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 0.4875
[09/26 00:52:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:52:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:52:26 visual_prompt]: Epoch 39 / 100: avg data time: 5.89e-02, avg batch time: 0.4735, average train loss: 0.0001
[09/26 00:52:28 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1581, average loss: 0.4870
[09/26 00:52:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:52:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:52:34 visual_prompt]: Epoch 40 / 100: avg data time: 6.29e-02, avg batch time: 0.4755, average train loss: 0.0001
[09/26 00:52:36 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1582, average loss: 0.4866
[09/26 00:52:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 00:52:36 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:52:42 visual_prompt]: Epoch 41 / 100: avg data time: 6.42e-02, avg batch time: 0.4766, average train loss: 0.0001
[09/26 00:52:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1586, average loss: 0.4860
[09/26 00:52:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:52:44 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:52:51 visual_prompt]: Epoch 42 / 100: avg data time: 6.06e-02, avg batch time: 0.4757, average train loss: 0.0001
[09/26 00:52:52 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1586, average loss: 0.4855
[09/26 00:52:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:52:52 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:52:59 visual_prompt]: Epoch 43 / 100: avg data time: 6.81e-02, avg batch time: 0.4817, average train loss: 0.0001
[09/26 00:53:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1580, average loss: 0.4853
[09/26 00:53:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:01 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:53:07 visual_prompt]: Epoch 44 / 100: avg data time: 6.25e-02, avg batch time: 0.4766, average train loss: 0.0001
[09/26 00:53:09 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.4847
[09/26 00:53:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:53:16 visual_prompt]: Epoch 45 / 100: avg data time: 6.85e-02, avg batch time: 0.4812, average train loss: 0.0001
[09/26 00:53:17 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1584, average loss: 0.4844
[09/26 00:53:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:53:24 visual_prompt]: Epoch 46 / 100: avg data time: 6.48e-02, avg batch time: 0.4776, average train loss: 0.0001
[09/26 00:53:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.4841
[09/26 00:53:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:26 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:53:32 visual_prompt]: Epoch 47 / 100: avg data time: 7.19e-02, avg batch time: 0.4847, average train loss: 0.0001
[09/26 00:53:34 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1577, average loss: 0.4839
[09/26 00:53:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:34 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:53:40 visual_prompt]: Epoch 48 / 100: avg data time: 6.89e-02, avg batch time: 0.4835, average train loss: 0.0001
[09/26 00:53:42 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 0.4838
[09/26 00:53:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:42 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:53:49 visual_prompt]: Epoch 49 / 100: avg data time: 6.77e-02, avg batch time: 0.4809, average train loss: 0.0001
[09/26 00:53:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 0.4836
[09/26 00:53:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 00:53:51 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:53:57 visual_prompt]: Epoch 50 / 100: avg data time: 6.54e-02, avg batch time: 0.4789, average train loss: 0.0001
[09/26 00:53:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.4834
[09/26 00:53:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:53:59 visual_prompt]: Best epoch 50: best metric: 0.915
[09/26 00:53:59 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:54:06 visual_prompt]: Epoch 51 / 100: avg data time: 7.15e-02, avg batch time: 0.4848, average train loss: 0.0001
[09/26 00:54:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 0.4833
[09/26 00:54:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:07 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:54:14 visual_prompt]: Epoch 52 / 100: avg data time: 5.84e-02, avg batch time: 0.4716, average train loss: 0.0001
[09/26 00:54:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.4831
[09/26 00:54:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:15 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:54:22 visual_prompt]: Epoch 53 / 100: avg data time: 6.64e-02, avg batch time: 0.4793, average train loss: 0.0001
[09/26 00:54:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.4829
[09/26 00:54:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:24 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:54:30 visual_prompt]: Epoch 54 / 100: avg data time: 6.76e-02, avg batch time: 0.4805, average train loss: 0.0001
[09/26 00:54:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.4828
[09/26 00:54:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:32 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:54:38 visual_prompt]: Epoch 55 / 100: avg data time: 5.04e-02, avg batch time: 0.4654, average train loss: 0.0001
[09/26 00:54:40 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.4826
[09/26 00:54:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:40 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:54:47 visual_prompt]: Epoch 56 / 100: avg data time: 6.75e-02, avg batch time: 0.4802, average train loss: 0.0001
[09/26 00:54:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.4825
[09/26 00:54:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:48 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:54:55 visual_prompt]: Epoch 57 / 100: avg data time: 4.99e-02, avg batch time: 0.4677, average train loss: 0.0001
[09/26 00:54:56 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1583, average loss: 0.4824
[09/26 00:54:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:54:56 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:55:03 visual_prompt]: Epoch 58 / 100: avg data time: 6.38e-02, avg batch time: 0.4777, average train loss: 0.0001
[09/26 00:55:05 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 0.4823
[09/26 00:55:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:05 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:55:11 visual_prompt]: Epoch 59 / 100: avg data time: 6.26e-02, avg batch time: 0.4755, average train loss: 0.0001
[09/26 00:55:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1580, average loss: 0.4822
[09/26 00:55:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:13 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:55:19 visual_prompt]: Epoch 60 / 100: avg data time: 6.47e-02, avg batch time: 0.4796, average train loss: 0.0001
[09/26 00:55:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1583, average loss: 0.4821
[09/26 00:55:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:21 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:55:27 visual_prompt]: Epoch 61 / 100: avg data time: 5.71e-02, avg batch time: 0.4727, average train loss: 0.0001
[09/26 00:55:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1587, average loss: 0.4820
[09/26 00:55:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:29 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:55:36 visual_prompt]: Epoch 62 / 100: avg data time: 5.73e-02, avg batch time: 0.4712, average train loss: 0.0001
[09/26 00:55:37 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1582, average loss: 0.4819
[09/26 00:55:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:37 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:55:44 visual_prompt]: Epoch 63 / 100: avg data time: 6.02e-02, avg batch time: 0.4744, average train loss: 0.0000
[09/26 00:55:46 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1585, average loss: 0.4818
[09/26 00:55:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:55:52 visual_prompt]: Epoch 64 / 100: avg data time: 7.09e-02, avg batch time: 0.4842, average train loss: 0.0001
[09/26 00:55:54 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1585, average loss: 0.4817
[09/26 00:55:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:55:54 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:56:00 visual_prompt]: Epoch 65 / 100: avg data time: 6.86e-02, avg batch time: 0.4832, average train loss: 0.0001
[09/26 00:56:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 0.4816
[09/26 00:56:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:56:09 visual_prompt]: Epoch 66 / 100: avg data time: 6.71e-02, avg batch time: 0.4809, average train loss: 0.0000
[09/26 00:56:10 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1583, average loss: 0.4815
[09/26 00:56:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:10 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:56:17 visual_prompt]: Epoch 67 / 100: avg data time: 6.57e-02, avg batch time: 0.4796, average train loss: 0.0000
[09/26 00:56:19 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1587, average loss: 0.4814
[09/26 00:56:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:19 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:56:25 visual_prompt]: Epoch 68 / 100: avg data time: 6.57e-02, avg batch time: 0.4802, average train loss: 0.0001
[09/26 00:56:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 0.4813
[09/26 00:56:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:27 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:56:33 visual_prompt]: Epoch 69 / 100: avg data time: 5.19e-02, avg batch time: 0.4677, average train loss: 0.0001
[09/26 00:56:35 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1588, average loss: 0.4812
[09/26 00:56:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:35 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:56:42 visual_prompt]: Epoch 70 / 100: avg data time: 5.10e-02, avg batch time: 0.4655, average train loss: 0.0001
[09/26 00:56:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1578, average loss: 0.4811
[09/26 00:56:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:43 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 00:56:50 visual_prompt]: Epoch 71 / 100: avg data time: 6.25e-02, avg batch time: 0.4758, average train loss: 0.0001
[09/26 00:56:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.4810
[09/26 00:56:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:56:51 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 00:56:58 visual_prompt]: Epoch 72 / 100: avg data time: 6.54e-02, avg batch time: 0.4793, average train loss: 0.0001
[09/26 00:57:00 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1586, average loss: 0.4810
[09/26 00:57:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:00 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 00:57:06 visual_prompt]: Epoch 73 / 100: avg data time: 6.88e-02, avg batch time: 0.4831, average train loss: 0.0000
[09/26 00:57:08 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 0.4809
[09/26 00:57:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:08 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 00:57:14 visual_prompt]: Epoch 74 / 100: avg data time: 6.04e-02, avg batch time: 0.4742, average train loss: 0.0000
[09/26 00:57:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1585, average loss: 0.4809
[09/26 00:57:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:16 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 00:57:23 visual_prompt]: Epoch 75 / 100: avg data time: 7.04e-02, avg batch time: 0.4846, average train loss: 0.0001
[09/26 00:57:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.4808
[09/26 00:57:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:24 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 00:57:31 visual_prompt]: Epoch 76 / 100: avg data time: 6.13e-02, avg batch time: 0.4766, average train loss: 0.0001
[09/26 00:57:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 0.4808
[09/26 00:57:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:33 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 00:57:39 visual_prompt]: Epoch 77 / 100: avg data time: 7.01e-02, avg batch time: 0.4835, average train loss: 0.0000
[09/26 00:57:41 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1588, average loss: 0.4807
[09/26 00:57:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:41 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 00:57:47 visual_prompt]: Epoch 78 / 100: avg data time: 6.68e-02, avg batch time: 0.4805, average train loss: 0.0000
[09/26 00:57:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.4807
[09/26 00:57:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:49 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 00:57:56 visual_prompt]: Epoch 79 / 100: avg data time: 6.22e-02, avg batch time: 0.4760, average train loss: 0.0000
[09/26 00:57:57 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1583, average loss: 0.4807
[09/26 00:57:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:57:57 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 00:58:04 visual_prompt]: Epoch 80 / 100: avg data time: 6.69e-02, avg batch time: 0.4811, average train loss: 0.0001
[09/26 00:58:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 0.4806
[09/26 00:58:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:06 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 00:58:12 visual_prompt]: Epoch 81 / 100: avg data time: 6.05e-02, avg batch time: 0.4752, average train loss: 0.0000
[09/26 00:58:14 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 0.4806
[09/26 00:58:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:14 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 00:58:20 visual_prompt]: Epoch 82 / 100: avg data time: 6.69e-02, avg batch time: 0.4827, average train loss: 0.0001
[09/26 00:58:22 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1587, average loss: 0.4806
[09/26 00:58:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:22 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 00:58:29 visual_prompt]: Epoch 83 / 100: avg data time: 7.01e-02, avg batch time: 0.4837, average train loss: 0.0000
[09/26 00:58:30 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.4806
[09/26 00:58:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:30 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 00:58:37 visual_prompt]: Epoch 84 / 100: avg data time: 5.83e-02, avg batch time: 0.4741, average train loss: 0.0000
[09/26 00:58:39 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1581, average loss: 0.4805
[09/26 00:58:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:39 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 00:58:45 visual_prompt]: Epoch 85 / 100: avg data time: 7.11e-02, avg batch time: 0.4860, average train loss: 0.0000
[09/26 00:58:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.4805
[09/26 00:58:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:47 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 00:58:54 visual_prompt]: Epoch 86 / 100: avg data time: 6.64e-02, avg batch time: 0.4817, average train loss: 0.0000
[09/26 00:58:55 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 0.4805
[09/26 00:58:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:58:55 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 00:59:02 visual_prompt]: Epoch 87 / 100: avg data time: 6.79e-02, avg batch time: 0.4816, average train loss: 0.0000
[09/26 00:59:03 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1587, average loss: 0.4805
[09/26 00:59:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:03 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 00:59:10 visual_prompt]: Epoch 88 / 100: avg data time: 6.39e-02, avg batch time: 0.4789, average train loss: 0.0001
[09/26 00:59:12 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1583, average loss: 0.4805
[09/26 00:59:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:12 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 00:59:18 visual_prompt]: Epoch 89 / 100: avg data time: 6.56e-02, avg batch time: 0.4804, average train loss: 0.0000
[09/26 00:59:20 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1582, average loss: 0.4805
[09/26 00:59:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 00:59:27 visual_prompt]: Epoch 90 / 100: avg data time: 7.21e-02, avg batch time: 0.4860, average train loss: 0.0000
[09/26 00:59:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1587, average loss: 0.4805
[09/26 00:59:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:28 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 00:59:35 visual_prompt]: Epoch 91 / 100: avg data time: 6.66e-02, avg batch time: 0.4803, average train loss: 0.0000
[09/26 00:59:37 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1587, average loss: 0.4805
[09/26 00:59:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:37 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 00:59:43 visual_prompt]: Epoch 92 / 100: avg data time: 7.05e-02, avg batch time: 0.4842, average train loss: 0.0000
[09/26 00:59:45 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1581, average loss: 0.4805
[09/26 00:59:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:45 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 00:59:51 visual_prompt]: Epoch 93 / 100: avg data time: 5.67e-02, avg batch time: 0.4717, average train loss: 0.0001
[09/26 00:59:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.4804
[09/26 00:59:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 00:59:53 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 01:00:00 visual_prompt]: Epoch 94 / 100: avg data time: 6.36e-02, avg batch time: 0.4783, average train loss: 0.0001
[09/26 01:00:01 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 0.4805
[09/26 01:00:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:01 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 01:00:08 visual_prompt]: Epoch 95 / 100: avg data time: 5.06e-02, avg batch time: 0.4651, average train loss: 0.0000
[09/26 01:00:09 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.4805
[09/26 01:00:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:09 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 01:00:16 visual_prompt]: Epoch 96 / 100: avg data time: 6.87e-02, avg batch time: 0.4825, average train loss: 0.0000
[09/26 01:00:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1574, average loss: 0.4805
[09/26 01:00:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:18 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 01:00:24 visual_prompt]: Epoch 97 / 100: avg data time: 5.99e-02, avg batch time: 0.4748, average train loss: 0.0001
[09/26 01:00:26 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1584, average loss: 0.4805
[09/26 01:00:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:26 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 01:00:33 visual_prompt]: Epoch 98 / 100: avg data time: 6.30e-02, avg batch time: 0.4773, average train loss: 0.0001
[09/26 01:00:34 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1579, average loss: 0.4805
[09/26 01:00:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:34 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 01:00:41 visual_prompt]: Epoch 99 / 100: avg data time: 6.23e-02, avg batch time: 0.4772, average train loss: 0.0001
[09/26 01:00:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.4804
[09/26 01:00:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 01:00:49 visual_prompt]: Epoch 100 / 100: avg data time: 6.63e-02, avg batch time: 0.4805, average train loss: 0.0000
[09/26 01:00:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1587, average loss: 0.4804
[09/26 01:00:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:00:51 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:00:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:00:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:00:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:00:51 visual_prompt]: Training with config:
[09/26 01:00:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:00:51 visual_prompt]: Loading training data...
[09/26 01:00:51 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:00:52 visual_prompt]: Number of images: 800
[09/26 01:00:52 visual_prompt]: Number of classes: 102 / 102
[09/26 01:00:52 visual_prompt]: Loading validation data...
[09/26 01:00:52 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:00:52 visual_prompt]: Number of images: 200
[09/26 01:00:52 visual_prompt]: Number of classes: 91 / 102
[09/26 01:00:52 visual_prompt]: Constructing models...
[09/26 01:00:55 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 01:00:55 visual_prompt]: tuned percent:0.625
[09/26 01:00:55 visual_prompt]: Device used for model: 0
[09/26 01:00:55 visual_prompt]: Setting up Evaluator...
[09/26 01:00:55 visual_prompt]: Setting up Trainer...
[09/26 01:00:55 visual_prompt]: 	Setting up the optimizer...
[09/26 01:00:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:01:01 visual_prompt]: Epoch 1 / 100: avg data time: 6.82e-02, avg batch time: 0.4879, average train loss: 4.6711
[09/26 01:01:03 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 01:01:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:01:03 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:01:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:01:10 visual_prompt]: Epoch 2 / 100: avg data time: 6.94e-02, avg batch time: 0.4825, average train loss: 4.6090
[09/26 01:01:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1587, average loss: 4.5955
[09/26 01:01:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 10.00	
[09/26 01:01:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:01:18 visual_prompt]: Epoch 3 / 100: avg data time: 7.17e-02, avg batch time: 0.4844, average train loss: 4.5698
[09/26 01:01:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1581, average loss: 4.6036
[09/26 01:01:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 10.00	
[09/26 01:01:20 visual_prompt]: Best epoch 3: best metric: 0.040
[09/26 01:01:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:01:27 visual_prompt]: Epoch 4 / 100: avg data time: 6.87e-02, avg batch time: 0.4815, average train loss: 4.6387
[09/26 01:01:28 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1586, average loss: 4.6618
[09/26 01:01:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 01:01:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:01:35 visual_prompt]: Epoch 5 / 100: avg data time: 7.05e-02, avg batch time: 0.4837, average train loss: 4.6828
[09/26 01:01:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 4.6551
[09/26 01:01:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/26 01:01:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:01:43 visual_prompt]: Epoch 6 / 100: avg data time: 7.39e-02, avg batch time: 0.4875, average train loss: 4.6783
[09/26 01:01:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1576, average loss: 4.7154
[09/26 01:01:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:01:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:01:52 visual_prompt]: Epoch 7 / 100: avg data time: 6.99e-02, avg batch time: 0.4824, average train loss: 4.6926
[09/26 01:01:53 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1581, average loss: 4.7088
[09/26 01:01:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 01:01:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:02:00 visual_prompt]: Epoch 8 / 100: avg data time: 6.49e-02, avg batch time: 0.4777, average train loss: 4.7468
[09/26 01:02:02 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1589, average loss: 4.7045
[09/26 01:02:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 7.00	
[09/26 01:02:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:02:08 visual_prompt]: Epoch 9 / 100: avg data time: 6.97e-02, avg batch time: 0.4829, average train loss: 4.7500
[09/26 01:02:10 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1584, average loss: 4.7177
[09/26 01:02:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 01:02:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:02:17 visual_prompt]: Epoch 10 / 100: avg data time: 5.42e-02, avg batch time: 0.4695, average train loss: 4.7469
[09/26 01:02:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1582, average loss: 4.7361
[09/26 01:02:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/26 01:02:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:02:25 visual_prompt]: Epoch 11 / 100: avg data time: 7.30e-02, avg batch time: 0.4870, average train loss: 4.7517
[09/26 01:02:27 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1582, average loss: 4.7572
[09/26 01:02:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:02:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:02:33 visual_prompt]: Epoch 12 / 100: avg data time: 6.79e-02, avg batch time: 0.4816, average train loss: 4.7543
[09/26 01:02:35 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 4.6879
[09/26 01:02:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 01:02:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:02:42 visual_prompt]: Epoch 13 / 100: avg data time: 6.87e-02, avg batch time: 0.4826, average train loss: 4.8142
[09/26 01:02:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1585, average loss: 4.7325
[09/26 01:02:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 01:02:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:02:50 visual_prompt]: Epoch 14 / 100: avg data time: 5.81e-02, avg batch time: 0.4723, average train loss: 4.8472
[09/26 01:02:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1583, average loss: 4.8257
[09/26 01:02:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/26 01:02:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:02:58 visual_prompt]: Epoch 15 / 100: avg data time: 5.24e-02, avg batch time: 0.4668, average train loss: 4.7644
[09/26 01:03:00 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1584, average loss: 4.7929
[09/26 01:03:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/26 01:03:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:03:06 visual_prompt]: Epoch 16 / 100: avg data time: 6.86e-02, avg batch time: 0.4823, average train loss: 4.7407
[09/26 01:03:08 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1581, average loss: 4.7458
[09/26 01:03:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 01:03:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:03:15 visual_prompt]: Epoch 17 / 100: avg data time: 6.84e-02, avg batch time: 0.4817, average train loss: 4.8045
[09/26 01:03:16 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1585, average loss: 4.7972
[09/26 01:03:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 01:03:16 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:03:23 visual_prompt]: Epoch 18 / 100: avg data time: 6.25e-02, avg batch time: 0.4774, average train loss: 4.9448
[09/26 01:03:25 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1584, average loss: 4.8149
[09/26 01:03:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:03:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:03:31 visual_prompt]: Epoch 19 / 100: avg data time: 6.87e-02, avg batch time: 0.4818, average train loss: 4.9024
[09/26 01:03:33 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1581, average loss: 4.7765
[09/26 01:03:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:03:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:03:39 visual_prompt]: Epoch 20 / 100: avg data time: 5.82e-02, avg batch time: 0.4749, average train loss: 4.9423
[09/26 01:03:41 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1587, average loss: 4.7968
[09/26 01:03:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:03:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:03:48 visual_prompt]: Epoch 21 / 100: avg data time: 6.45e-02, avg batch time: 0.4777, average train loss: 4.9366
[09/26 01:03:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 4.9059
[09/26 01:03:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 01:03:50 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:03:56 visual_prompt]: Epoch 22 / 100: avg data time: 6.06e-02, avg batch time: 0.4753, average train loss: 4.9692
[09/26 01:03:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 4.7339
[09/26 01:03:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 6.50	
[09/26 01:03:58 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:04:05 visual_prompt]: Epoch 23 / 100: avg data time: 7.00e-02, avg batch time: 0.4835, average train loss: 4.7825
[09/26 01:04:06 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1583, average loss: 4.7791
[09/26 01:04:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/26 01:04:06 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:04:13 visual_prompt]: Epoch 24 / 100: avg data time: 6.95e-02, avg batch time: 0.4834, average train loss: 4.7744
[09/26 01:04:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 4.8666
[09/26 01:04:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:04:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:04:21 visual_prompt]: Epoch 25 / 100: avg data time: 6.91e-02, avg batch time: 0.4820, average train loss: 4.8183
[09/26 01:04:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 4.8544
[09/26 01:04:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 01:04:23 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:04:29 visual_prompt]: Epoch 26 / 100: avg data time: 6.69e-02, avg batch time: 0.4800, average train loss: 4.7666
[09/26 01:04:31 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 4.7128
[09/26 01:04:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:04:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:04:38 visual_prompt]: Epoch 27 / 100: avg data time: 6.95e-02, avg batch time: 0.4838, average train loss: 4.7701
[09/26 01:04:39 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1580, average loss: 4.7680
[09/26 01:04:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.00	
[09/26 01:04:39 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:04:46 visual_prompt]: Epoch 28 / 100: avg data time: 6.80e-02, avg batch time: 0.4824, average train loss: 4.7970
[09/26 01:04:48 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1586, average loss: 4.8237
[09/26 01:04:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:04:48 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:04:54 visual_prompt]: Epoch 29 / 100: avg data time: 6.83e-02, avg batch time: 0.4820, average train loss: 4.8257
[09/26 01:04:56 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 4.7451
[09/26 01:04:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 01:04:56 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:05:03 visual_prompt]: Epoch 30 / 100: avg data time: 6.69e-02, avg batch time: 0.4806, average train loss: 4.8613
[09/26 01:05:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 4.8069
[09/26 01:05:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:05:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:05:11 visual_prompt]: Epoch 31 / 100: avg data time: 6.79e-02, avg batch time: 0.4829, average train loss: 4.7371
[09/26 01:05:13 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1587, average loss: 4.7145
[09/26 01:05:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:05:13 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:05:19 visual_prompt]: Epoch 32 / 100: avg data time: 6.61e-02, avg batch time: 0.4802, average train loss: 4.7171
[09/26 01:05:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 4.7492
[09/26 01:05:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 7.50	
[09/26 01:05:21 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:05:28 visual_prompt]: Epoch 33 / 100: avg data time: 7.22e-02, avg batch time: 0.4856, average train loss: 4.8006
[09/26 01:05:29 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1582, average loss: 4.8109
[09/26 01:05:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 01:05:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:05:36 visual_prompt]: Epoch 34 / 100: avg data time: 6.93e-02, avg batch time: 0.4828, average train loss: 4.7468
[09/26 01:05:38 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 4.6919
[09/26 01:05:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 01:05:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:05:44 visual_prompt]: Epoch 35 / 100: avg data time: 5.63e-02, avg batch time: 0.4693, average train loss: 4.7334
[09/26 01:05:46 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1579, average loss: 4.7549
[09/26 01:05:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 01:05:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:05:52 visual_prompt]: Epoch 36 / 100: avg data time: 7.00e-02, avg batch time: 0.4825, average train loss: 4.7734
[09/26 01:05:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 4.8282
[09/26 01:05:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.50	
[09/26 01:05:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:06:01 visual_prompt]: Epoch 37 / 100: avg data time: 5.79e-02, avg batch time: 0.4708, average train loss: 4.7977
[09/26 01:06:02 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 4.7245
[09/26 01:06:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:06:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:06:09 visual_prompt]: Epoch 38 / 100: avg data time: 5.52e-02, avg batch time: 0.4693, average train loss: 4.7437
[09/26 01:06:10 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1576, average loss: 5.0766
[09/26 01:06:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 01:06:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:06:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.35e-02, avg batch time: 0.4670, average train loss: 4.7402
[09/26 01:06:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 4.7291
[09/26 01:06:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:06:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:06:25 visual_prompt]: Epoch 40 / 100: avg data time: 6.84e-02, avg batch time: 0.4810, average train loss: 4.7271
[09/26 01:06:27 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1582, average loss: 4.7345
[09/26 01:06:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 01:06:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:06:33 visual_prompt]: Epoch 41 / 100: avg data time: 5.56e-02, avg batch time: 0.4698, average train loss: 4.7367
[09/26 01:06:35 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1586, average loss: 4.7530
[09/26 01:06:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.00	
[09/26 01:06:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:06:42 visual_prompt]: Epoch 42 / 100: avg data time: 6.29e-02, avg batch time: 0.4764, average train loss: 4.7809
[09/26 01:06:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1585, average loss: 4.7050
[09/26 01:06:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.50	
[09/26 01:06:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:06:50 visual_prompt]: Epoch 43 / 100: avg data time: 6.73e-02, avg batch time: 0.4802, average train loss: 4.7211
[09/26 01:06:52 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1585, average loss: 4.7088
[09/26 01:06:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:06:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:06:58 visual_prompt]: Epoch 44 / 100: avg data time: 7.41e-02, avg batch time: 0.4873, average train loss: 4.7112
[09/26 01:07:00 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 4.7089
[09/26 01:07:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 01:07:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:07:07 visual_prompt]: Epoch 45 / 100: avg data time: 6.92e-02, avg batch time: 0.4830, average train loss: 4.7273
[09/26 01:07:09 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1582, average loss: 4.6997
[09/26 01:07:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 01:07:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:07:15 visual_prompt]: Epoch 46 / 100: avg data time: 6.76e-02, avg batch time: 0.4799, average train loss: 4.7302
[09/26 01:07:17 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1586, average loss: 4.7165
[09/26 01:07:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 01:07:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:07:23 visual_prompt]: Epoch 47 / 100: avg data time: 6.93e-02, avg batch time: 0.4818, average train loss: 4.7422
[09/26 01:07:25 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1579, average loss: 4.7590
[09/26 01:07:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 01:07:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:07:32 visual_prompt]: Epoch 48 / 100: avg data time: 6.65e-02, avg batch time: 0.4790, average train loss: 4.7194
[09/26 01:07:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 4.7356
[09/26 01:07:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/26 01:07:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:07:40 visual_prompt]: Epoch 49 / 100: avg data time: 6.44e-02, avg batch time: 0.4787, average train loss: 4.7043
[09/26 01:07:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1578, average loss: 4.7268
[09/26 01:07:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:07:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:07:48 visual_prompt]: Epoch 50 / 100: avg data time: 6.91e-02, avg batch time: 0.4822, average train loss: 4.7343
[09/26 01:07:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1581, average loss: 4.7061
[09/26 01:07:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:07:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:07:57 visual_prompt]: Epoch 51 / 100: avg data time: 7.32e-02, avg batch time: 0.4866, average train loss: 4.7169
[09/26 01:07:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1586, average loss: 4.6689
[09/26 01:07:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 01:07:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:08:05 visual_prompt]: Epoch 52 / 100: avg data time: 6.52e-02, avg batch time: 0.4777, average train loss: 4.6872
[09/26 01:08:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 4.6806
[09/26 01:08:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:08:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:08:14 visual_prompt]: Epoch 53 / 100: avg data time: 6.91e-02, avg batch time: 0.4818, average train loss: 4.6726
[09/26 01:08:15 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1582, average loss: 4.7267
[09/26 01:08:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:08:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:08:22 visual_prompt]: Epoch 54 / 100: avg data time: 6.26e-02, avg batch time: 0.4753, average train loss: 4.7022
[09/26 01:08:24 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1579, average loss: 4.7721
[09/26 01:08:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:08:24 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:08:30 visual_prompt]: Epoch 55 / 100: avg data time: 7.42e-02, avg batch time: 0.4869, average train loss: 4.7218
[09/26 01:08:32 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1584, average loss: 4.6790
[09/26 01:08:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/26 01:08:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:08:39 visual_prompt]: Epoch 56 / 100: avg data time: 6.74e-02, avg batch time: 0.4816, average train loss: 4.6857
[09/26 01:08:40 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1580, average loss: 4.6861
[09/26 01:08:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 01:08:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:08:47 visual_prompt]: Epoch 57 / 100: avg data time: 5.89e-02, avg batch time: 0.4722, average train loss: 4.6809
[09/26 01:08:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 4.7055
[09/26 01:08:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 01:08:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:08:55 visual_prompt]: Epoch 58 / 100: avg data time: 6.96e-02, avg batch time: 0.4826, average train loss: 4.6533
[09/26 01:08:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 4.7223
[09/26 01:08:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 01:08:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:09:03 visual_prompt]: Epoch 59 / 100: avg data time: 5.89e-02, avg batch time: 0.4719, average train loss: 4.7135
[09/26 01:09:05 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1579, average loss: 4.7023
[09/26 01:09:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/26 01:09:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:09:12 visual_prompt]: Epoch 60 / 100: avg data time: 6.60e-02, avg batch time: 0.4797, average train loss: 4.6754
[09/26 01:09:13 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1581, average loss: 4.6975
[09/26 01:09:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:09:13 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:09:20 visual_prompt]: Epoch 61 / 100: avg data time: 7.17e-02, avg batch time: 0.4838, average train loss: 4.6689
[09/26 01:09:22 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1581, average loss: 4.6995
[09/26 01:09:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:09:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:09:28 visual_prompt]: Epoch 62 / 100: avg data time: 6.26e-02, avg batch time: 0.4756, average train loss: 4.6616
[09/26 01:09:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 4.6893
[09/26 01:09:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:09:30 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:09:37 visual_prompt]: Epoch 63 / 100: avg data time: 7.38e-02, avg batch time: 0.4861, average train loss: 4.6590
[09/26 01:09:38 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1578, average loss: 4.6948
[09/26 01:09:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/26 01:09:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:09:45 visual_prompt]: Epoch 64 / 100: avg data time: 7.24e-02, avg batch time: 0.4847, average train loss: 4.6596
[09/26 01:09:47 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1586, average loss: 4.7117
[09/26 01:09:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 01:09:47 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:09:53 visual_prompt]: Epoch 65 / 100: avg data time: 6.30e-02, avg batch time: 0.4759, average train loss: 4.6422
[09/26 01:09:55 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1581, average loss: 4.6622
[09/26 01:09:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/26 01:09:55 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:10:02 visual_prompt]: Epoch 66 / 100: avg data time: 6.50e-02, avg batch time: 0.4769, average train loss: 4.6584
[09/26 01:10:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1578, average loss: 4.6736
[09/26 01:10:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:10:03 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:10:10 visual_prompt]: Epoch 67 / 100: avg data time: 6.73e-02, avg batch time: 0.4796, average train loss: 4.6473
[09/26 01:10:12 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 4.6776
[09/26 01:10:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 01:10:12 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:10:18 visual_prompt]: Epoch 68 / 100: avg data time: 5.30e-02, avg batch time: 0.4676, average train loss: 4.6400
[09/26 01:10:20 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 4.6805
[09/26 01:10:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/26 01:10:20 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:10:26 visual_prompt]: Epoch 69 / 100: avg data time: 6.84e-02, avg batch time: 0.4807, average train loss: 4.6346
[09/26 01:10:28 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 4.7085
[09/26 01:10:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.50	
[09/26 01:10:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:10:35 visual_prompt]: Epoch 70 / 100: avg data time: 5.37e-02, avg batch time: 0.4691, average train loss: 4.6444
[09/26 01:10:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 4.6766
[09/26 01:10:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 6.00	
[09/26 01:10:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:10:43 visual_prompt]: Epoch 71 / 100: avg data time: 6.45e-02, avg batch time: 0.4780, average train loss: 4.6463
[09/26 01:10:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 4.6813
[09/26 01:10:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:10:45 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:10:51 visual_prompt]: Epoch 72 / 100: avg data time: 6.91e-02, avg batch time: 0.4817, average train loss: 4.6458
[09/26 01:10:53 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1582, average loss: 4.6782
[09/26 01:10:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/26 01:10:53 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:10:59 visual_prompt]: Epoch 73 / 100: avg data time: 6.83e-02, avg batch time: 0.4812, average train loss: 4.6353
[09/26 01:11:01 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 4.6904
[09/26 01:11:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 01:11:01 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:11:08 visual_prompt]: Epoch 74 / 100: avg data time: 7.04e-02, avg batch time: 0.4824, average train loss: 4.6301
[09/26 01:11:09 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 4.6824
[09/26 01:11:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 01:11:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:11:16 visual_prompt]: Epoch 75 / 100: avg data time: 6.67e-02, avg batch time: 0.4797, average train loss: 4.6335
[09/26 01:11:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1586, average loss: 4.6699
[09/26 01:11:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:11:18 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:11:24 visual_prompt]: Epoch 76 / 100: avg data time: 5.16e-02, avg batch time: 0.4662, average train loss: 4.6312
[09/26 01:11:26 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1582, average loss: 4.6638
[09/26 01:11:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:11:26 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:11:33 visual_prompt]: Epoch 77 / 100: avg data time: 7.16e-02, avg batch time: 0.4845, average train loss: 4.6123
[09/26 01:11:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1576, average loss: 4.6715
[09/26 01:11:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 01:11:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:11:41 visual_prompt]: Epoch 78 / 100: avg data time: 5.39e-02, avg batch time: 0.4670, average train loss: 4.6066
[09/26 01:11:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1585, average loss: 4.6934
[09/26 01:11:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.50	
[09/26 01:11:42 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:11:49 visual_prompt]: Epoch 79 / 100: avg data time: 6.94e-02, avg batch time: 0.4816, average train loss: 4.6346
[09/26 01:11:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 4.6694
[09/26 01:11:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:11:51 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:11:57 visual_prompt]: Epoch 80 / 100: avg data time: 6.46e-02, avg batch time: 0.4768, average train loss: 4.6084
[09/26 01:11:59 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 4.6592
[09/26 01:11:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:11:59 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:12:06 visual_prompt]: Epoch 81 / 100: avg data time: 7.00e-02, avg batch time: 0.4827, average train loss: 4.5995
[09/26 01:12:07 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1578, average loss: 4.6651
[09/26 01:12:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/26 01:12:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:12:14 visual_prompt]: Epoch 82 / 100: avg data time: 6.89e-02, avg batch time: 0.4811, average train loss: 4.5760
[09/26 01:12:16 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1576, average loss: 4.6844
[09/26 01:12:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 01:12:16 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:12:22 visual_prompt]: Epoch 83 / 100: avg data time: 7.00e-02, avg batch time: 0.4821, average train loss: 4.6159
[09/26 01:12:24 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1581, average loss: 4.6540
[09/26 01:12:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 01:12:24 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:12:31 visual_prompt]: Epoch 84 / 100: avg data time: 7.22e-02, avg batch time: 0.4848, average train loss: 4.6088
[09/26 01:12:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1580, average loss: 4.6381
[09/26 01:12:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 5.00	
[09/26 01:12:32 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:12:39 visual_prompt]: Epoch 85 / 100: avg data time: 6.59e-02, avg batch time: 0.4784, average train loss: 4.5737
[09/26 01:12:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 4.6700
[09/26 01:12:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/26 01:12:41 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:12:47 visual_prompt]: Epoch 86 / 100: avg data time: 6.99e-02, avg batch time: 0.4826, average train loss: 4.5700
[09/26 01:12:49 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1587, average loss: 4.6524
[09/26 01:12:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 01:12:49 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:12:56 visual_prompt]: Epoch 87 / 100: avg data time: 7.03e-02, avg batch time: 0.4826, average train loss: 4.5437
[09/26 01:12:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1586, average loss: 4.6012
[09/26 01:12:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 7.00	
[09/26 01:12:58 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:13:04 visual_prompt]: Epoch 88 / 100: avg data time: 6.89e-02, avg batch time: 0.4810, average train loss: 4.5241
[09/26 01:13:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1571, average loss: 4.6805
[09/26 01:13:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 01:13:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:13:12 visual_prompt]: Epoch 89 / 100: avg data time: 6.32e-02, avg batch time: 0.4758, average train loss: 4.5741
[09/26 01:13:14 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1580, average loss: 4.6217
[09/26 01:13:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 01:13:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:13:21 visual_prompt]: Epoch 90 / 100: avg data time: 7.41e-02, avg batch time: 0.4863, average train loss: 4.5086
[09/26 01:13:22 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1580, average loss: 4.5979
[09/26 01:13:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/26 01:13:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:13:29 visual_prompt]: Epoch 91 / 100: avg data time: 6.90e-02, avg batch time: 0.4818, average train loss: 4.5041
[09/26 01:13:31 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1578, average loss: 4.6858
[09/26 01:13:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/26 01:13:31 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:13:37 visual_prompt]: Epoch 92 / 100: avg data time: 6.83e-02, avg batch time: 0.4816, average train loss: 4.5275
[09/26 01:13:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1582, average loss: 4.6315
[09/26 01:13:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 01:13:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:13:46 visual_prompt]: Epoch 93 / 100: avg data time: 5.71e-02, avg batch time: 0.4719, average train loss: 4.4513
[09/26 01:13:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 4.6441
[09/26 01:13:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 01:13:47 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:13:54 visual_prompt]: Epoch 94 / 100: avg data time: 5.28e-02, avg batch time: 0.4673, average train loss: 4.3851
[09/26 01:13:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1579, average loss: 4.5890
[09/26 01:13:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.00	
[09/26 01:13:56 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:14:02 visual_prompt]: Epoch 95 / 100: avg data time: 7.56e-02, avg batch time: 0.4885, average train loss: 4.3873
[09/26 01:14:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 4.5876
[09/26 01:14:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 01:14:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:14:11 visual_prompt]: Epoch 96 / 100: avg data time: 7.13e-02, avg batch time: 0.4845, average train loss: 4.3566
[09/26 01:14:12 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1579, average loss: 4.5947
[09/26 01:14:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 9.00	
[09/26 01:14:12 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:14:19 visual_prompt]: Epoch 97 / 100: avg data time: 7.17e-02, avg batch time: 0.4852, average train loss: 4.2951
[09/26 01:14:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1585, average loss: 4.5400
[09/26 01:14:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.50	
[09/26 01:14:21 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:14:28 visual_prompt]: Epoch 98 / 100: avg data time: 7.35e-02, avg batch time: 0.4866, average train loss: 4.2567
[09/26 01:14:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 4.6062
[09/26 01:14:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 8.50	
[09/26 01:14:29 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:14:36 visual_prompt]: Epoch 99 / 100: avg data time: 6.26e-02, avg batch time: 0.4764, average train loss: 4.2341
[09/26 01:14:38 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1580, average loss: 4.5810
[09/26 01:14:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 8.50	
[09/26 01:14:38 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:14:44 visual_prompt]: Epoch 100 / 100: avg data time: 7.19e-02, avg batch time: 0.4872, average train loss: 4.2269
[09/26 01:14:46 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 4.5591
[09/26 01:14:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 10.50	
[09/26 01:14:46 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:14:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:14:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:14:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:14:46 visual_prompt]: Training with config:
[09/26 01:14:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:14:46 visual_prompt]: Loading training data...
[09/26 01:14:46 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:14:47 visual_prompt]: Number of images: 800
[09/26 01:14:47 visual_prompt]: Number of classes: 102 / 102
[09/26 01:14:47 visual_prompt]: Loading validation data...
[09/26 01:14:47 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:14:48 visual_prompt]: Number of images: 200
[09/26 01:14:48 visual_prompt]: Number of classes: 91 / 102
[09/26 01:14:48 visual_prompt]: Constructing models...
[09/26 01:14:50 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 01:14:50 visual_prompt]: tuned percent:0.625
[09/26 01:14:50 visual_prompt]: Device used for model: 0
[09/26 01:14:50 visual_prompt]: Setting up Evaluator...
[09/26 01:14:50 visual_prompt]: Setting up Trainer...
[09/26 01:14:50 visual_prompt]: 	Setting up the optimizer...
[09/26 01:14:50 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:14:57 visual_prompt]: Epoch 1 / 100: avg data time: 6.79e-02, avg batch time: 0.4858, average train loss: 4.6734
[09/26 01:14:58 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1584, average loss: 4.6780
[09/26 01:14:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:14:58 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:14:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:15:05 visual_prompt]: Epoch 2 / 100: avg data time: 7.29e-02, avg batch time: 0.4851, average train loss: 4.6269
[09/26 01:15:07 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 4.5692
[09/26 01:15:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 8.00	
[09/26 01:15:07 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 01:15:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:15:13 visual_prompt]: Epoch 3 / 100: avg data time: 6.45e-02, avg batch time: 0.4783, average train loss: 4.4851
[09/26 01:15:15 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1584, average loss: 4.3960
[09/26 01:15:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 15.00	
[09/26 01:15:15 visual_prompt]: Best epoch 3: best metric: 0.030
[09/26 01:15:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:15:22 visual_prompt]: Epoch 4 / 100: avg data time: 6.40e-02, avg batch time: 0.4765, average train loss: 4.4888
[09/26 01:15:23 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1574, average loss: 4.3107
[09/26 01:15:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 12.50	
[09/26 01:15:23 visual_prompt]: Best epoch 4: best metric: 0.035
[09/26 01:15:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:15:30 visual_prompt]: Epoch 5 / 100: avg data time: 7.16e-02, avg batch time: 0.4849, average train loss: 3.7429
[09/26 01:15:32 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 2.9907
[09/26 01:15:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 33.00	top5: 57.50	
[09/26 01:15:32 visual_prompt]: Best epoch 5: best metric: 0.330
[09/26 01:15:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:15:39 visual_prompt]: Epoch 6 / 100: avg data time: 7.19e-02, avg batch time: 0.4853, average train loss: 1.6579
[09/26 01:15:40 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1584, average loss: 0.7817
[09/26 01:15:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 94.00	
[09/26 01:15:40 visual_prompt]: Best epoch 6: best metric: 0.835
[09/26 01:15:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:15:47 visual_prompt]: Epoch 7 / 100: avg data time: 6.98e-02, avg batch time: 0.4842, average train loss: 0.4299
[09/26 01:15:49 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 0.5560
[09/26 01:15:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 98.50	
[09/26 01:15:49 visual_prompt]: Best epoch 7: best metric: 0.890
[09/26 01:15:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:15:55 visual_prompt]: Epoch 8 / 100: avg data time: 5.70e-02, avg batch time: 0.4716, average train loss: 0.1513
[09/26 01:15:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 0.5394
[09/26 01:15:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 01:15:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:16:04 visual_prompt]: Epoch 9 / 100: avg data time: 6.40e-02, avg batch time: 0.4764, average train loss: 0.1139
[09/26 01:16:05 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 0.5375
[09/26 01:16:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 01:16:05 visual_prompt]: Best epoch 9: best metric: 0.905
[09/26 01:16:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:16:12 visual_prompt]: Epoch 10 / 100: avg data time: 6.64e-02, avg batch time: 0.4790, average train loss: 0.1051
[09/26 01:16:13 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.8728
[09/26 01:16:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 95.00	
[09/26 01:16:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:16:20 visual_prompt]: Epoch 11 / 100: avg data time: 7.28e-02, avg batch time: 0.4862, average train loss: 0.1671
[09/26 01:16:22 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1580, average loss: 0.5377
[09/26 01:16:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.50	
[09/26 01:16:22 visual_prompt]: Best epoch 11: best metric: 0.910
[09/26 01:16:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:16:29 visual_prompt]: Epoch 12 / 100: avg data time: 6.51e-02, avg batch time: 0.4790, average train loss: 0.1440
[09/26 01:16:30 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1582, average loss: 0.5261
[09/26 01:16:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.00	
[09/26 01:16:30 visual_prompt]: Best epoch 12: best metric: 0.935
[09/26 01:16:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:16:37 visual_prompt]: Epoch 13 / 100: avg data time: 7.33e-02, avg batch time: 0.4868, average train loss: 0.1495
[09/26 01:16:39 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.4527
[09/26 01:16:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.50	
[09/26 01:16:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:16:45 visual_prompt]: Epoch 14 / 100: avg data time: 6.22e-02, avg batch time: 0.4753, average train loss: 0.2083
[09/26 01:16:47 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1576, average loss: 1.6245
[09/26 01:16:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 90.00	
[09/26 01:16:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:16:54 visual_prompt]: Epoch 15 / 100: avg data time: 7.11e-02, avg batch time: 0.4844, average train loss: 0.3850
[09/26 01:16:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1591, average loss: 0.5632
[09/26 01:16:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 01:16:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:17:02 visual_prompt]: Epoch 16 / 100: avg data time: 6.15e-02, avg batch time: 0.4741, average train loss: 0.1229
[09/26 01:17:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1587, average loss: 0.5962
[09/26 01:17:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 01:17:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:17:10 visual_prompt]: Epoch 17 / 100: avg data time: 5.40e-02, avg batch time: 0.4671, average train loss: 0.1869
[09/26 01:17:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.6850
[09/26 01:17:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.00	
[09/26 01:17:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:17:18 visual_prompt]: Epoch 18 / 100: avg data time: 6.41e-02, avg batch time: 0.4768, average train loss: 0.3068
[09/26 01:17:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 0.6522
[09/26 01:17:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 01:17:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:17:27 visual_prompt]: Epoch 19 / 100: avg data time: 5.49e-02, avg batch time: 0.4696, average train loss: 0.1259
[09/26 01:17:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1580, average loss: 0.4521
[09/26 01:17:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 01:17:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:17:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.85e-02, avg batch time: 0.4717, average train loss: 0.4013
[09/26 01:17:37 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1584, average loss: 0.4477
[09/26 01:17:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.50	
[09/26 01:17:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:17:43 visual_prompt]: Epoch 21 / 100: avg data time: 6.14e-02, avg batch time: 0.4741, average train loss: 0.1156
[09/26 01:17:45 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1583, average loss: 0.4624
[09/26 01:17:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 01:17:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:17:52 visual_prompt]: Epoch 22 / 100: avg data time: 7.60e-02, avg batch time: 0.4894, average train loss: 0.0954
[09/26 01:17:53 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1583, average loss: 0.4468
[09/26 01:17:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 01:17:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:18:00 visual_prompt]: Epoch 23 / 100: avg data time: 6.89e-02, avg batch time: 0.4826, average train loss: 0.1635
[09/26 01:18:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 0.7022
[09/26 01:18:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:18:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:18:08 visual_prompt]: Epoch 24 / 100: avg data time: 6.76e-02, avg batch time: 0.4805, average train loss: 0.2514
[09/26 01:18:10 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 0.9430
[09/26 01:18:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 92.50	
[09/26 01:18:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:18:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.96e-02, avg batch time: 0.4731, average train loss: 1.5258
[09/26 01:18:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 2.5643
[09/26 01:18:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 45.50	top5: 66.00	
[09/26 01:18:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:18:25 visual_prompt]: Epoch 26 / 100: avg data time: 7.39e-02, avg batch time: 0.4881, average train loss: 1.2520
[09/26 01:18:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1587, average loss: 0.7345
[09/26 01:18:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.50	
[09/26 01:18:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:18:33 visual_prompt]: Epoch 27 / 100: avg data time: 6.15e-02, avg batch time: 0.4750, average train loss: 0.2116
[09/26 01:18:35 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1583, average loss: 0.7524
[09/26 01:18:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.00	
[09/26 01:18:35 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:18:42 visual_prompt]: Epoch 28 / 100: avg data time: 6.13e-02, avg batch time: 0.4752, average train loss: 0.1151
[09/26 01:18:43 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1581, average loss: 0.4607
[09/26 01:18:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.00	
[09/26 01:18:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:18:50 visual_prompt]: Epoch 29 / 100: avg data time: 7.30e-02, avg batch time: 0.4861, average train loss: 0.1313
[09/26 01:18:52 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1578, average loss: 0.4621
[09/26 01:18:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 01:18:52 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:18:58 visual_prompt]: Epoch 30 / 100: avg data time: 7.00e-02, avg batch time: 0.4834, average train loss: 0.1452
[09/26 01:19:00 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.4510
[09/26 01:19:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 01:19:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:19:07 visual_prompt]: Epoch 31 / 100: avg data time: 7.10e-02, avg batch time: 0.4851, average train loss: 0.0964
[09/26 01:19:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1579, average loss: 0.5209
[09/26 01:19:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 01:19:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:19:15 visual_prompt]: Epoch 32 / 100: avg data time: 7.27e-02, avg batch time: 0.4869, average train loss: 0.0914
[09/26 01:19:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1586, average loss: 0.3881
[09/26 01:19:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 01:19:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:19:24 visual_prompt]: Epoch 33 / 100: avg data time: 6.68e-02, avg batch time: 0.4798, average train loss: 2.7019
[09/26 01:19:25 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1581, average loss: 1.0671
[09/26 01:19:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 91.50	
[09/26 01:19:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:19:32 visual_prompt]: Epoch 34 / 100: avg data time: 5.51e-02, avg batch time: 0.4693, average train loss: 0.3177
[09/26 01:19:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.5936
[09/26 01:19:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 01:19:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:19:40 visual_prompt]: Epoch 35 / 100: avg data time: 7.03e-02, avg batch time: 0.4833, average train loss: 0.1507
[09/26 01:19:42 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1583, average loss: 0.5351
[09/26 01:19:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/26 01:19:42 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:19:49 visual_prompt]: Epoch 36 / 100: avg data time: 6.63e-02, avg batch time: 0.4798, average train loss: 0.0882
[09/26 01:19:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1583, average loss: 0.4982
[09/26 01:19:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 01:19:50 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:19:57 visual_prompt]: Epoch 37 / 100: avg data time: 7.41e-02, avg batch time: 0.4870, average train loss: 0.4210
[09/26 01:19:59 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1580, average loss: 0.4401
[09/26 01:19:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 01:19:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:20:05 visual_prompt]: Epoch 38 / 100: avg data time: 5.28e-02, avg batch time: 0.4681, average train loss: 0.0951
[09/26 01:20:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.5293
[09/26 01:20:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 01:20:07 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:20:14 visual_prompt]: Epoch 39 / 100: avg data time: 6.24e-02, avg batch time: 0.4758, average train loss: 0.0871
[09/26 01:20:15 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1580, average loss: 0.4384
[09/26 01:20:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 01:20:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:20:22 visual_prompt]: Epoch 40 / 100: avg data time: 7.38e-02, avg batch time: 0.4868, average train loss: 0.0866
[09/26 01:20:24 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1579, average loss: 0.4285
[09/26 01:20:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.00	
[09/26 01:20:24 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:20:30 visual_prompt]: Epoch 41 / 100: avg data time: 6.66e-02, avg batch time: 0.4805, average train loss: 0.0778
[09/26 01:20:32 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 0.4119
[09/26 01:20:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 01:20:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:20:39 visual_prompt]: Epoch 42 / 100: avg data time: 6.04e-02, avg batch time: 0.4746, average train loss: 0.0792
[09/26 01:20:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 0.3647
[09/26 01:20:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:20:40 visual_prompt]: Best epoch 42: best metric: 0.940
[09/26 01:20:40 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:20:47 visual_prompt]: Epoch 43 / 100: avg data time: 7.05e-02, avg batch time: 0.4835, average train loss: 0.0726
[09/26 01:20:49 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1580, average loss: 2.2466
[09/26 01:20:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 95.00	
[09/26 01:20:49 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:20:55 visual_prompt]: Epoch 44 / 100: avg data time: 6.13e-02, avg batch time: 0.4768, average train loss: 1.2696
[09/26 01:20:57 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1584, average loss: 0.5288
[09/26 01:20:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.50	
[09/26 01:20:57 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:21:04 visual_prompt]: Epoch 45 / 100: avg data time: 6.99e-02, avg batch time: 0.4829, average train loss: 0.1100
[09/26 01:21:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 0.4364
[09/26 01:21:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 01:21:05 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:21:12 visual_prompt]: Epoch 46 / 100: avg data time: 6.54e-02, avg batch time: 0.4788, average train loss: 0.0839
[09/26 01:21:14 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 0.5352
[09/26 01:21:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 01:21:14 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:21:20 visual_prompt]: Epoch 47 / 100: avg data time: 7.18e-02, avg batch time: 0.4848, average train loss: 0.0841
[09/26 01:21:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1587, average loss: 0.3976
[09/26 01:21:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 01:21:22 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:21:29 visual_prompt]: Epoch 48 / 100: avg data time: 6.40e-02, avg batch time: 0.4771, average train loss: 0.0864
[09/26 01:21:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1584, average loss: 0.3782
[09/26 01:21:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.00	
[09/26 01:21:30 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:21:37 visual_prompt]: Epoch 49 / 100: avg data time: 6.18e-02, avg batch time: 0.4749, average train loss: 0.0744
[09/26 01:21:39 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.4298
[09/26 01:21:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 01:21:39 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:21:45 visual_prompt]: Epoch 50 / 100: avg data time: 6.89e-02, avg batch time: 0.4828, average train loss: 0.0688
[09/26 01:21:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 0.4088
[09/26 01:21:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:21:47 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:21:54 visual_prompt]: Epoch 51 / 100: avg data time: 7.59e-02, avg batch time: 0.4896, average train loss: 0.0662
[09/26 01:21:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1592, average loss: 0.3791
[09/26 01:21:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 01:21:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:22:02 visual_prompt]: Epoch 52 / 100: avg data time: 6.89e-02, avg batch time: 0.4827, average train loss: 0.0715
[09/26 01:22:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 0.3594
[09/26 01:22:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 01:22:04 visual_prompt]: Best epoch 52: best metric: 0.950
[09/26 01:22:04 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:22:10 visual_prompt]: Epoch 53 / 100: avg data time: 7.14e-02, avg batch time: 0.4852, average train loss: 0.0687
[09/26 01:22:12 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1584, average loss: 0.3663
[09/26 01:22:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 01:22:12 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:22:19 visual_prompt]: Epoch 54 / 100: avg data time: 6.80e-02, avg batch time: 0.4813, average train loss: 0.0671
[09/26 01:22:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.4184
[09/26 01:22:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:22:21 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:22:27 visual_prompt]: Epoch 55 / 100: avg data time: 5.29e-02, avg batch time: 0.4676, average train loss: 0.0777
[09/26 01:22:29 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 0.3721
[09/26 01:22:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 01:22:29 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:22:35 visual_prompt]: Epoch 56 / 100: avg data time: 6.16e-02, avg batch time: 0.4752, average train loss: 0.0644
[09/26 01:22:37 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1585, average loss: 0.3279
[09/26 01:22:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 01:22:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:22:44 visual_prompt]: Epoch 57 / 100: avg data time: 6.86e-02, avg batch time: 0.4822, average train loss: 0.3878
[09/26 01:22:45 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1581, average loss: 0.3516
[09/26 01:22:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 01:22:45 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:22:52 visual_prompt]: Epoch 58 / 100: avg data time: 6.89e-02, avg batch time: 0.4827, average train loss: 0.0801
[09/26 01:22:54 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1579, average loss: 0.4367
[09/26 01:22:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 01:22:54 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:23:00 visual_prompt]: Epoch 59 / 100: avg data time: 7.27e-02, avg batch time: 0.4857, average train loss: 1.0532
[09/26 01:23:02 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1581, average loss: 4.3852
[09/26 01:23:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.00	top5: 17.50	
[09/26 01:23:02 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:23:09 visual_prompt]: Epoch 60 / 100: avg data time: 7.29e-02, avg batch time: 0.4874, average train loss: 1.4811
[09/26 01:23:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 0.4383
[09/26 01:23:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 01:23:10 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:23:17 visual_prompt]: Epoch 61 / 100: avg data time: 6.31e-02, avg batch time: 0.4773, average train loss: 0.1294
[09/26 01:23:19 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1582, average loss: 0.3828
[09/26 01:23:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 01:23:19 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:23:25 visual_prompt]: Epoch 62 / 100: avg data time: 7.17e-02, avg batch time: 0.4843, average train loss: 0.0775
[09/26 01:23:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 0.3666
[09/26 01:23:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:23:27 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:23:34 visual_prompt]: Epoch 63 / 100: avg data time: 6.97e-02, avg batch time: 0.4834, average train loss: 0.0493
[09/26 01:23:36 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1584, average loss: 0.3728
[09/26 01:23:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 01:23:36 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:23:42 visual_prompt]: Epoch 64 / 100: avg data time: 6.89e-02, avg batch time: 0.4814, average train loss: 0.0431
[09/26 01:23:44 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1579, average loss: 0.3384
[09/26 01:23:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 01:23:44 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:23:51 visual_prompt]: Epoch 65 / 100: avg data time: 6.76e-02, avg batch time: 0.4803, average train loss: 0.0388
[09/26 01:23:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1584, average loss: 0.3643
[09/26 01:23:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.00	
[09/26 01:23:52 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:23:59 visual_prompt]: Epoch 66 / 100: avg data time: 7.07e-02, avg batch time: 0.4830, average train loss: 0.0398
[09/26 01:24:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.3392
[09/26 01:24:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 01:24:01 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:24:08 visual_prompt]: Epoch 67 / 100: avg data time: 8.32e-02, avg batch time: 0.4955, average train loss: 0.0411
[09/26 01:24:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.3401
[09/26 01:24:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 01:24:09 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:24:16 visual_prompt]: Epoch 68 / 100: avg data time: 7.51e-02, avg batch time: 0.4889, average train loss: 0.0425
[09/26 01:24:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1574, average loss: 0.3536
[09/26 01:24:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 01:24:18 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:24:24 visual_prompt]: Epoch 69 / 100: avg data time: 7.01e-02, avg batch time: 0.4825, average train loss: 0.0427
[09/26 01:24:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1583, average loss: 0.3765
[09/26 01:24:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 99.00	
[09/26 01:24:26 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:24:33 visual_prompt]: Epoch 70 / 100: avg data time: 6.22e-02, avg batch time: 0.4747, average train loss: 0.0424
[09/26 01:24:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1579, average loss: 0.3414
[09/26 01:24:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 01:24:34 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:24:41 visual_prompt]: Epoch 71 / 100: avg data time: 6.45e-02, avg batch time: 0.4774, average train loss: 0.0420
[09/26 01:24:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1581, average loss: 0.3442
[09/26 01:24:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 01:24:43 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:24:49 visual_prompt]: Epoch 72 / 100: avg data time: 6.99e-02, avg batch time: 0.4832, average train loss: 0.0454
[09/26 01:24:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1581, average loss: 0.3444
[09/26 01:24:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 99.00	
[09/26 01:24:51 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:24:58 visual_prompt]: Epoch 73 / 100: avg data time: 5.82e-02, avg batch time: 0.4716, average train loss: 0.0512
[09/26 01:24:59 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1578, average loss: 0.3491
[09/26 01:24:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 99.00	
[09/26 01:24:59 visual_prompt]: Best epoch 73: best metric: 0.960
[09/26 01:24:59 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:25:06 visual_prompt]: Epoch 74 / 100: avg data time: 6.85e-02, avg batch time: 0.4809, average train loss: 0.0816
[09/26 01:25:08 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1583, average loss: 0.4381
[09/26 01:25:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 01:25:08 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:25:14 visual_prompt]: Epoch 75 / 100: avg data time: 7.46e-02, avg batch time: 0.4870, average train loss: 0.0748
[09/26 01:25:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.4166
[09/26 01:25:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 01:25:16 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:25:23 visual_prompt]: Epoch 76 / 100: avg data time: 6.68e-02, avg batch time: 0.4800, average train loss: 0.0611
[09/26 01:25:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 0.3405
[09/26 01:25:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.00	
[09/26 01:25:24 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:25:31 visual_prompt]: Epoch 77 / 100: avg data time: 5.94e-02, avg batch time: 0.4729, average train loss: 0.0443
[09/26 01:25:33 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1585, average loss: 0.3256
[09/26 01:25:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 01:25:33 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:25:39 visual_prompt]: Epoch 78 / 100: avg data time: 6.51e-02, avg batch time: 0.4785, average train loss: 0.0403
[09/26 01:25:41 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 0.3552
[09/26 01:25:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 01:25:41 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:25:47 visual_prompt]: Epoch 79 / 100: avg data time: 6.54e-02, avg batch time: 0.4782, average train loss: 0.0357
[09/26 01:25:49 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1585, average loss: 0.3125
[09/26 01:25:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 01:25:49 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:25:56 visual_prompt]: Epoch 80 / 100: avg data time: 7.12e-02, avg batch time: 0.4839, average train loss: 0.0327
[09/26 01:25:57 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 0.3218
[09/26 01:25:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 01:25:57 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:26:04 visual_prompt]: Epoch 81 / 100: avg data time: 6.93e-02, avg batch time: 0.4829, average train loss: 0.0309
[09/26 01:26:06 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1585, average loss: 0.3136
[09/26 01:26:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.00	
[09/26 01:26:06 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:26:12 visual_prompt]: Epoch 82 / 100: avg data time: 6.78e-02, avg batch time: 0.4820, average train loss: 0.0305
[09/26 01:26:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 0.3168
[09/26 01:26:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.50	
[09/26 01:26:14 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:26:21 visual_prompt]: Epoch 83 / 100: avg data time: 6.70e-02, avg batch time: 0.4794, average train loss: 0.0305
[09/26 01:26:23 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1584, average loss: 0.3274
[09/26 01:26:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 01:26:23 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:26:29 visual_prompt]: Epoch 84 / 100: avg data time: 6.57e-02, avg batch time: 0.4783, average train loss: 0.0308
[09/26 01:26:31 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.3343
[09/26 01:26:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 01:26:31 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:26:37 visual_prompt]: Epoch 85 / 100: avg data time: 6.04e-02, avg batch time: 0.4751, average train loss: 0.0308
[09/26 01:26:39 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1581, average loss: 0.3371
[09/26 01:26:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 01:26:39 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:26:46 visual_prompt]: Epoch 86 / 100: avg data time: 6.67e-02, avg batch time: 0.4792, average train loss: 0.0309
[09/26 01:26:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1583, average loss: 0.3359
[09/26 01:26:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 01:26:47 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:26:54 visual_prompt]: Epoch 87 / 100: avg data time: 6.49e-02, avg batch time: 0.4799, average train loss: 0.0310
[09/26 01:26:56 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1586, average loss: 0.3402
[09/26 01:26:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 01:26:56 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:27:02 visual_prompt]: Epoch 88 / 100: avg data time: 5.54e-02, avg batch time: 0.4693, average train loss: 0.0307
[09/26 01:27:04 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1586, average loss: 0.3390
[09/26 01:27:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 01:27:04 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:27:10 visual_prompt]: Epoch 89 / 100: avg data time: 6.77e-02, avg batch time: 0.4803, average train loss: 0.0306
[09/26 01:27:12 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.3415
[09/26 01:27:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:27:12 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:27:19 visual_prompt]: Epoch 90 / 100: avg data time: 5.33e-02, avg batch time: 0.4676, average train loss: 0.0302
[09/26 01:27:20 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1585, average loss: 0.3470
[09/26 01:27:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 01:27:20 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:27:27 visual_prompt]: Epoch 91 / 100: avg data time: 7.03e-02, avg batch time: 0.4836, average train loss: 0.0302
[09/26 01:27:29 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1586, average loss: 0.3490
[09/26 01:27:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 01:27:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:27:35 visual_prompt]: Epoch 92 / 100: avg data time: 7.73e-02, avg batch time: 0.4898, average train loss: 0.0302
[09/26 01:27:37 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 0.3496
[09/26 01:27:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 01:27:37 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:27:44 visual_prompt]: Epoch 93 / 100: avg data time: 6.44e-02, avg batch time: 0.4798, average train loss: 0.0302
[09/26 01:27:46 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.3475
[09/26 01:27:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 01:27:46 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:27:52 visual_prompt]: Epoch 94 / 100: avg data time: 7.40e-02, avg batch time: 0.4863, average train loss: 0.0301
[09/26 01:27:54 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1585, average loss: 0.3486
[09/26 01:27:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:27:54 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:28:01 visual_prompt]: Epoch 95 / 100: avg data time: 6.49e-02, avg batch time: 0.4774, average train loss: 0.0299
[09/26 01:28:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1579, average loss: 0.3463
[09/26 01:28:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 01:28:02 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:28:09 visual_prompt]: Epoch 96 / 100: avg data time: 6.64e-02, avg batch time: 0.4803, average train loss: 0.0299
[09/26 01:28:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 0.3457
[09/26 01:28:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:28:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:28:17 visual_prompt]: Epoch 97 / 100: avg data time: 6.27e-02, avg batch time: 0.4750, average train loss: 0.0298
[09/26 01:28:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.3464
[09/26 01:28:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:28:19 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:28:25 visual_prompt]: Epoch 98 / 100: avg data time: 6.73e-02, avg batch time: 0.4815, average train loss: 0.0298
[09/26 01:28:27 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1578, average loss: 0.3469
[09/26 01:28:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:28:27 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:28:34 visual_prompt]: Epoch 99 / 100: avg data time: 6.41e-02, avg batch time: 0.4767, average train loss: 0.0298
[09/26 01:28:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1580, average loss: 0.3478
[09/26 01:28:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:28:35 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:28:42 visual_prompt]: Epoch 100 / 100: avg data time: 5.77e-02, avg batch time: 0.4713, average train loss: 0.0298
[09/26 01:28:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1586, average loss: 0.3480
[09/26 01:28:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 01:28:44 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:28:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:28:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:28:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:28:44 visual_prompt]: Training with config:
[09/26 01:28:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:28:44 visual_prompt]: Loading training data...
[09/26 01:28:44 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:28:45 visual_prompt]: Number of images: 800
[09/26 01:28:45 visual_prompt]: Number of classes: 102 / 102
[09/26 01:28:45 visual_prompt]: Loading validation data...
[09/26 01:28:45 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:28:46 visual_prompt]: Number of images: 200
[09/26 01:28:46 visual_prompt]: Number of classes: 91 / 102
[09/26 01:28:46 visual_prompt]: Constructing models...
[09/26 01:28:48 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 01:28:48 visual_prompt]: tuned percent:0.625
[09/26 01:28:48 visual_prompt]: Device used for model: 0
[09/26 01:28:48 visual_prompt]: Setting up Evaluator...
[09/26 01:28:48 visual_prompt]: Setting up Trainer...
[09/26 01:28:48 visual_prompt]: 	Setting up the optimizer...
[09/26 01:28:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:28:55 visual_prompt]: Epoch 1 / 100: avg data time: 7.01e-02, avg batch time: 0.4864, average train loss: 4.6678
[09/26 01:28:57 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1575, average loss: 4.6780
[09/26 01:28:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:28:57 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:28:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:29:03 visual_prompt]: Epoch 2 / 100: avg data time: 7.15e-02, avg batch time: 0.4832, average train loss: 4.6465
[09/26 01:29:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1587, average loss: 4.6344
[09/26 01:29:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/26 01:29:05 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 01:29:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:29:12 visual_prompt]: Epoch 3 / 100: avg data time: 6.47e-02, avg batch time: 0.4780, average train loss: 4.5316
[09/26 01:29:13 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1586, average loss: 4.6752
[09/26 01:29:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 9.50	
[09/26 01:29:13 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:29:20 visual_prompt]: Epoch 4 / 100: avg data time: 6.69e-02, avg batch time: 0.4793, average train loss: 4.6141
[09/26 01:29:22 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1583, average loss: 4.4178
[09/26 01:29:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 13.50	
[09/26 01:29:22 visual_prompt]: Best epoch 4: best metric: 0.045
[09/26 01:29:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:29:28 visual_prompt]: Epoch 5 / 100: avg data time: 6.48e-02, avg batch time: 0.4770, average train loss: 4.4895
[09/26 01:29:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 4.4567
[09/26 01:29:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 15.00	
[09/26 01:29:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:29:37 visual_prompt]: Epoch 6 / 100: avg data time: 6.93e-02, avg batch time: 0.4814, average train loss: 4.7050
[09/26 01:29:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1577, average loss: 4.4634
[09/26 01:29:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.00	top5: 18.00	
[09/26 01:29:38 visual_prompt]: Best epoch 6: best metric: 0.060
[09/26 01:29:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:29:45 visual_prompt]: Epoch 7 / 100: avg data time: 6.73e-02, avg batch time: 0.4816, average train loss: 3.2764
[09/26 01:29:47 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 2.2254
[09/26 01:29:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 51.50	top5: 74.00	
[09/26 01:29:47 visual_prompt]: Best epoch 7: best metric: 0.515
[09/26 01:29:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:29:53 visual_prompt]: Epoch 8 / 100: avg data time: 5.41e-02, avg batch time: 0.4676, average train loss: 0.9543
[09/26 01:29:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 1.0087
[09/26 01:29:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.00	
[09/26 01:29:55 visual_prompt]: Best epoch 8: best metric: 0.815
[09/26 01:29:55 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:30:02 visual_prompt]: Epoch 9 / 100: avg data time: 7.00e-02, avg batch time: 0.4833, average train loss: 0.2198
[09/26 01:30:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1581, average loss: 0.6659
[09/26 01:30:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 93.50	
[09/26 01:30:03 visual_prompt]: Best epoch 9: best metric: 0.845
[09/26 01:30:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:30:10 visual_prompt]: Epoch 10 / 100: avg data time: 7.56e-02, avg batch time: 0.4905, average train loss: 0.0740
[09/26 01:30:12 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1584, average loss: 0.6131
[09/26 01:30:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 01:30:12 visual_prompt]: Best epoch 10: best metric: 0.855
[09/26 01:30:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:30:18 visual_prompt]: Epoch 11 / 100: avg data time: 6.46e-02, avg batch time: 0.4780, average train loss: 0.0763
[09/26 01:30:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.6332
[09/26 01:30:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 94.50	
[09/26 01:30:20 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:30:27 visual_prompt]: Epoch 12 / 100: avg data time: 6.83e-02, avg batch time: 0.4819, average train loss: 0.0443
[09/26 01:30:28 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1582, average loss: 0.5408
[09/26 01:30:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.00	
[09/26 01:30:28 visual_prompt]: Best epoch 12: best metric: 0.870
[09/26 01:30:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:30:35 visual_prompt]: Epoch 13 / 100: avg data time: 6.78e-02, avg batch time: 0.4817, average train loss: 0.0136
[09/26 01:30:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 0.5748
[09/26 01:30:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 01:30:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:30:43 visual_prompt]: Epoch 14 / 100: avg data time: 5.75e-02, avg batch time: 0.4740, average train loss: 0.0125
[09/26 01:30:45 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1585, average loss: 0.5362
[09/26 01:30:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 95.50	
[09/26 01:30:45 visual_prompt]: Best epoch 14: best metric: 0.875
[09/26 01:30:45 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:30:52 visual_prompt]: Epoch 15 / 100: avg data time: 7.52e-02, avg batch time: 0.4890, average train loss: 0.0064
[09/26 01:30:53 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 0.4951
[09/26 01:30:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.00	
[09/26 01:30:53 visual_prompt]: Best epoch 15: best metric: 0.890
[09/26 01:30:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:31:00 visual_prompt]: Epoch 16 / 100: avg data time: 6.75e-02, avg batch time: 0.4815, average train loss: 0.0044
[09/26 01:31:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.4279
[09/26 01:31:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 01:31:02 visual_prompt]: Best epoch 16: best metric: 0.900
[09/26 01:31:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:31:09 visual_prompt]: Epoch 17 / 100: avg data time: 7.46e-02, avg batch time: 0.4883, average train loss: 0.0033
[09/26 01:31:10 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1581, average loss: 0.4101
[09/26 01:31:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 01:31:10 visual_prompt]: Best epoch 17: best metric: 0.905
[09/26 01:31:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:31:17 visual_prompt]: Epoch 18 / 100: avg data time: 6.56e-02, avg batch time: 0.4796, average train loss: 0.0032
[09/26 01:31:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.4137
[09/26 01:31:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 95.50	
[09/26 01:31:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:31:25 visual_prompt]: Epoch 19 / 100: avg data time: 6.18e-02, avg batch time: 0.4758, average train loss: 0.0035
[09/26 01:31:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 0.4131
[09/26 01:31:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 95.50	
[09/26 01:31:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:31:33 visual_prompt]: Epoch 20 / 100: avg data time: 6.53e-02, avg batch time: 0.4794, average train loss: 0.0039
[09/26 01:31:35 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.4169
[09/26 01:31:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 95.50	
[09/26 01:31:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:31:42 visual_prompt]: Epoch 21 / 100: avg data time: 6.11e-02, avg batch time: 0.4757, average train loss: 0.0042
[09/26 01:31:43 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1585, average loss: 0.4178
[09/26 01:31:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.50	
[09/26 01:31:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:31:50 visual_prompt]: Epoch 22 / 100: avg data time: 6.66e-02, avg batch time: 0.4797, average train loss: 0.0046
[09/26 01:31:52 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1585, average loss: 0.4137
[09/26 01:31:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.50	
[09/26 01:31:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:31:58 visual_prompt]: Epoch 23 / 100: avg data time: 6.48e-02, avg batch time: 0.4790, average train loss: 0.0049
[09/26 01:32:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1584, average loss: 0.4112
[09/26 01:32:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 01:32:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:32:07 visual_prompt]: Epoch 24 / 100: avg data time: 6.50e-02, avg batch time: 0.4795, average train loss: 0.0051
[09/26 01:32:08 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 0.4086
[09/26 01:32:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.00	
[09/26 01:32:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:32:15 visual_prompt]: Epoch 25 / 100: avg data time: 6.66e-02, avg batch time: 0.4808, average train loss: 0.0054
[09/26 01:32:17 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1582, average loss: 0.4034
[09/26 01:32:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 01:32:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:32:23 visual_prompt]: Epoch 26 / 100: avg data time: 6.45e-02, avg batch time: 0.4788, average train loss: 0.0057
[09/26 01:32:25 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 0.4051
[09/26 01:32:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.50	
[09/26 01:32:25 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:32:32 visual_prompt]: Epoch 27 / 100: avg data time: 7.04e-02, avg batch time: 0.4839, average train loss: 0.0062
[09/26 01:32:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 0.4022
[09/26 01:32:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.00	
[09/26 01:32:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:32:40 visual_prompt]: Epoch 28 / 100: avg data time: 7.14e-02, avg batch time: 0.4849, average train loss: 0.0060
[09/26 01:32:42 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.3955
[09/26 01:32:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 01:32:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:32:48 visual_prompt]: Epoch 29 / 100: avg data time: 4.98e-02, avg batch time: 0.4640, average train loss: 0.0060
[09/26 01:32:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1585, average loss: 0.3983
[09/26 01:32:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 01:32:50 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:32:57 visual_prompt]: Epoch 30 / 100: avg data time: 7.11e-02, avg batch time: 0.4847, average train loss: 0.0060
[09/26 01:32:58 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.3872
[09/26 01:32:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 01:32:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:33:05 visual_prompt]: Epoch 31 / 100: avg data time: 7.37e-02, avg batch time: 0.4876, average train loss: 0.0062
[09/26 01:33:07 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.3899
[09/26 01:33:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 01:33:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:33:14 visual_prompt]: Epoch 32 / 100: avg data time: 6.98e-02, avg batch time: 0.4847, average train loss: 0.0062
[09/26 01:33:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1584, average loss: 0.3972
[09/26 01:33:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 01:33:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:33:22 visual_prompt]: Epoch 33 / 100: avg data time: 6.24e-02, avg batch time: 0.4765, average train loss: 0.0064
[09/26 01:33:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1586, average loss: 0.3805
[09/26 01:33:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.00	
[09/26 01:33:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:33:30 visual_prompt]: Epoch 34 / 100: avg data time: 6.84e-02, avg batch time: 0.4826, average train loss: 0.0063
[09/26 01:33:32 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 0.3902
[09/26 01:33:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 01:33:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:33:39 visual_prompt]: Epoch 35 / 100: avg data time: 6.94e-02, avg batch time: 0.4845, average train loss: 0.0062
[09/26 01:33:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 0.3795
[09/26 01:33:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 01:33:40 visual_prompt]: Best epoch 35: best metric: 0.915
[09/26 01:33:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:33:47 visual_prompt]: Epoch 36 / 100: avg data time: 7.10e-02, avg batch time: 0.4860, average train loss: 0.0064
[09/26 01:33:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.3883
[09/26 01:33:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 01:33:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:33:55 visual_prompt]: Epoch 37 / 100: avg data time: 6.39e-02, avg batch time: 0.4782, average train loss: 0.0066
[09/26 01:33:57 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1582, average loss: 0.3831
[09/26 01:33:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 01:33:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:34:04 visual_prompt]: Epoch 38 / 100: avg data time: 6.90e-02, avg batch time: 0.4831, average train loss: 0.0069
[09/26 01:34:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.3690
[09/26 01:34:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 01:34:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:34:12 visual_prompt]: Epoch 39 / 100: avg data time: 6.77e-02, avg batch time: 0.4814, average train loss: 0.0065
[09/26 01:34:14 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1585, average loss: 0.3612
[09/26 01:34:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:34:14 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:34:20 visual_prompt]: Epoch 40 / 100: avg data time: 6.85e-02, avg batch time: 0.4832, average train loss: 0.0061
[09/26 01:34:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 0.3609
[09/26 01:34:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 01:34:22 visual_prompt]: Best epoch 40: best metric: 0.920
[09/26 01:34:22 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:34:29 visual_prompt]: Epoch 41 / 100: avg data time: 5.93e-02, avg batch time: 0.4753, average train loss: 0.0062
[09/26 01:34:30 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1583, average loss: 0.3706
[09/26 01:34:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:34:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:34:37 visual_prompt]: Epoch 42 / 100: avg data time: 6.38e-02, avg batch time: 0.4779, average train loss: 0.0060
[09/26 01:34:39 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 0.3708
[09/26 01:34:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:34:39 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:34:45 visual_prompt]: Epoch 43 / 100: avg data time: 7.17e-02, avg batch time: 0.4863, average train loss: 0.0059
[09/26 01:34:47 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.3660
[09/26 01:34:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 01:34:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:34:54 visual_prompt]: Epoch 44 / 100: avg data time: 7.34e-02, avg batch time: 0.4878, average train loss: 0.0059
[09/26 01:34:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 0.3695
[09/26 01:34:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 01:34:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:35:02 visual_prompt]: Epoch 45 / 100: avg data time: 7.26e-02, avg batch time: 0.4855, average train loss: 0.0058
[09/26 01:35:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 0.3669
[09/26 01:35:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 01:35:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:35:11 visual_prompt]: Epoch 46 / 100: avg data time: 7.05e-02, avg batch time: 0.4839, average train loss: 0.0058
[09/26 01:35:13 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.3605
[09/26 01:35:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:35:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:35:19 visual_prompt]: Epoch 47 / 100: avg data time: 6.80e-02, avg batch time: 0.4810, average train loss: 0.0058
[09/26 01:35:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 0.3723
[09/26 01:35:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 01:35:21 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:35:28 visual_prompt]: Epoch 48 / 100: avg data time: 6.75e-02, avg batch time: 0.4809, average train loss: 0.0056
[09/26 01:35:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.3637
[09/26 01:35:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 01:35:29 visual_prompt]: Best epoch 48: best metric: 0.925
[09/26 01:35:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:35:36 visual_prompt]: Epoch 49 / 100: avg data time: 6.86e-02, avg batch time: 0.4810, average train loss: 0.0056
[09/26 01:35:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.3597
[09/26 01:35:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 01:35:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:35:44 visual_prompt]: Epoch 50 / 100: avg data time: 6.56e-02, avg batch time: 0.4780, average train loss: 0.0056
[09/26 01:35:46 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1579, average loss: 0.3638
[09/26 01:35:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:35:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:35:53 visual_prompt]: Epoch 51 / 100: avg data time: 6.80e-02, avg batch time: 0.4803, average train loss: 0.0057
[09/26 01:35:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1584, average loss: 0.3582
[09/26 01:35:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:35:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:36:01 visual_prompt]: Epoch 52 / 100: avg data time: 5.59e-02, avg batch time: 0.4683, average train loss: 0.0056
[09/26 01:36:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1584, average loss: 0.3630
[09/26 01:36:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:36:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:36:09 visual_prompt]: Epoch 53 / 100: avg data time: 6.08e-02, avg batch time: 0.4743, average train loss: 0.0055
[09/26 01:36:11 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1582, average loss: 0.3669
[09/26 01:36:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:36:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:36:17 visual_prompt]: Epoch 54 / 100: avg data time: 6.58e-02, avg batch time: 0.4801, average train loss: 0.0054
[09/26 01:36:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1575, average loss: 0.3685
[09/26 01:36:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 01:36:19 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:36:26 visual_prompt]: Epoch 55 / 100: avg data time: 6.43e-02, avg batch time: 0.4763, average train loss: 0.0054
[09/26 01:36:28 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 0.3552
[09/26 01:36:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.00	
[09/26 01:36:28 visual_prompt]: Best epoch 55: best metric: 0.930
[09/26 01:36:28 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:36:34 visual_prompt]: Epoch 56 / 100: avg data time: 6.36e-02, avg batch time: 0.4764, average train loss: 0.0053
[09/26 01:36:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 0.3665
[09/26 01:36:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:36:36 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:36:42 visual_prompt]: Epoch 57 / 100: avg data time: 6.56e-02, avg batch time: 0.4793, average train loss: 0.0051
[09/26 01:36:44 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 0.3741
[09/26 01:36:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 96.50	
[09/26 01:36:44 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:36:51 visual_prompt]: Epoch 58 / 100: avg data time: 6.48e-02, avg batch time: 0.4788, average train loss: 0.0119
[09/26 01:36:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 0.3785
[09/26 01:36:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 01:36:53 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:36:59 visual_prompt]: Epoch 59 / 100: avg data time: 6.79e-02, avg batch time: 0.4796, average train loss: 0.0121
[09/26 01:37:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 0.3864
[09/26 01:37:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:37:01 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:37:08 visual_prompt]: Epoch 60 / 100: avg data time: 7.48e-02, avg batch time: 0.4887, average train loss: 0.0109
[09/26 01:37:09 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.3979
[09/26 01:37:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 01:37:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:37:16 visual_prompt]: Epoch 61 / 100: avg data time: 5.45e-02, avg batch time: 0.4675, average train loss: 0.0090
[09/26 01:37:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1573, average loss: 0.3650
[09/26 01:37:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 01:37:18 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:37:24 visual_prompt]: Epoch 62 / 100: avg data time: 6.46e-02, avg batch time: 0.4762, average train loss: 0.0069
[09/26 01:37:26 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1582, average loss: 0.3568
[09/26 01:37:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 01:37:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:37:32 visual_prompt]: Epoch 63 / 100: avg data time: 6.68e-02, avg batch time: 0.4792, average train loss: 0.0059
[09/26 01:37:34 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1579, average loss: 0.3561
[09/26 01:37:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 01:37:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:37:41 visual_prompt]: Epoch 64 / 100: avg data time: 7.06e-02, avg batch time: 0.4824, average train loss: 0.0054
[09/26 01:37:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1576, average loss: 0.3530
[09/26 01:37:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:37:43 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:37:49 visual_prompt]: Epoch 65 / 100: avg data time: 6.77e-02, avg batch time: 0.4794, average train loss: 0.0051
[09/26 01:37:51 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1579, average loss: 0.3524
[09/26 01:37:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:37:51 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:37:58 visual_prompt]: Epoch 66 / 100: avg data time: 6.09e-02, avg batch time: 0.4753, average train loss: 0.0049
[09/26 01:37:59 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1580, average loss: 0.3590
[09/26 01:37:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:37:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:38:06 visual_prompt]: Epoch 67 / 100: avg data time: 6.99e-02, avg batch time: 0.4836, average train loss: 0.0049
[09/26 01:38:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1580, average loss: 0.3550
[09/26 01:38:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:38:08 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:38:14 visual_prompt]: Epoch 68 / 100: avg data time: 6.88e-02, avg batch time: 0.4818, average train loss: 0.0048
[09/26 01:38:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 0.3577
[09/26 01:38:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:38:16 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:38:22 visual_prompt]: Epoch 69 / 100: avg data time: 6.91e-02, avg batch time: 0.4814, average train loss: 0.0047
[09/26 01:38:24 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1582, average loss: 0.3586
[09/26 01:38:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 01:38:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:38:31 visual_prompt]: Epoch 70 / 100: avg data time: 6.37e-02, avg batch time: 0.4765, average train loss: 0.0046
[09/26 01:38:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1580, average loss: 0.3529
[09/26 01:38:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:38:33 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:38:39 visual_prompt]: Epoch 71 / 100: avg data time: 7.10e-02, avg batch time: 0.4827, average train loss: 0.0047
[09/26 01:38:41 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 0.3481
[09/26 01:38:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 01:38:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:38:47 visual_prompt]: Epoch 72 / 100: avg data time: 5.58e-02, avg batch time: 0.4705, average train loss: 0.0049
[09/26 01:38:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1584, average loss: 0.3501
[09/26 01:38:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 01:38:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:38:56 visual_prompt]: Epoch 73 / 100: avg data time: 6.49e-02, avg batch time: 0.4779, average train loss: 0.0047
[09/26 01:38:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.3526
[09/26 01:38:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:38:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:39:04 visual_prompt]: Epoch 74 / 100: avg data time: 6.55e-02, avg batch time: 0.4778, average train loss: 0.0047
[09/26 01:39:06 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 0.3559
[09/26 01:39:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:39:12 visual_prompt]: Epoch 75 / 100: avg data time: 5.35e-02, avg batch time: 0.4662, average train loss: 0.0045
[09/26 01:39:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.3505
[09/26 01:39:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:14 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:39:20 visual_prompt]: Epoch 76 / 100: avg data time: 7.20e-02, avg batch time: 0.4839, average train loss: 0.0045
[09/26 01:39:22 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1581, average loss: 0.3503
[09/26 01:39:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:39:29 visual_prompt]: Epoch 77 / 100: avg data time: 6.83e-02, avg batch time: 0.4833, average train loss: 0.0044
[09/26 01:39:31 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1578, average loss: 0.3530
[09/26 01:39:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:39:37 visual_prompt]: Epoch 78 / 100: avg data time: 6.87e-02, avg batch time: 0.4808, average train loss: 0.0045
[09/26 01:39:39 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 0.3513
[09/26 01:39:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:39:46 visual_prompt]: Epoch 79 / 100: avg data time: 6.01e-02, avg batch time: 0.4732, average train loss: 0.0045
[09/26 01:39:47 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1577, average loss: 0.3536
[09/26 01:39:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:47 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:39:54 visual_prompt]: Epoch 80 / 100: avg data time: 6.93e-02, avg batch time: 0.4819, average train loss: 0.0045
[09/26 01:39:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.3528
[09/26 01:39:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:39:56 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:40:02 visual_prompt]: Epoch 81 / 100: avg data time: 7.40e-02, avg batch time: 0.4870, average train loss: 0.0044
[09/26 01:40:04 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1583, average loss: 0.3532
[09/26 01:40:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:04 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:40:11 visual_prompt]: Epoch 82 / 100: avg data time: 6.67e-02, avg batch time: 0.4797, average train loss: 0.0045
[09/26 01:40:12 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 0.3516
[09/26 01:40:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:12 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:40:19 visual_prompt]: Epoch 83 / 100: avg data time: 6.73e-02, avg batch time: 0.4804, average train loss: 0.0045
[09/26 01:40:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1584, average loss: 0.3520
[09/26 01:40:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:40:27 visual_prompt]: Epoch 84 / 100: avg data time: 6.26e-02, avg batch time: 0.4757, average train loss: 0.0044
[09/26 01:40:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1586, average loss: 0.3521
[09/26 01:40:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:40:36 visual_prompt]: Epoch 85 / 100: avg data time: 6.79e-02, avg batch time: 0.4804, average train loss: 0.0044
[09/26 01:40:37 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1579, average loss: 0.3538
[09/26 01:40:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:40:44 visual_prompt]: Epoch 86 / 100: avg data time: 6.84e-02, avg batch time: 0.4812, average train loss: 0.0044
[09/26 01:40:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1578, average loss: 0.3526
[09/26 01:40:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:46 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:40:52 visual_prompt]: Epoch 87 / 100: avg data time: 6.96e-02, avg batch time: 0.4827, average train loss: 0.0044
[09/26 01:40:54 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1563, average loss: 0.3537
[09/26 01:40:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:40:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:41:01 visual_prompt]: Epoch 88 / 100: avg data time: 6.96e-02, avg batch time: 0.4830, average train loss: 0.0044
[09/26 01:41:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 0.3540
[09/26 01:41:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:02 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:41:09 visual_prompt]: Epoch 89 / 100: avg data time: 6.51e-02, avg batch time: 0.4774, average train loss: 0.0044
[09/26 01:41:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1582, average loss: 0.3567
[09/26 01:41:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:11 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:41:17 visual_prompt]: Epoch 90 / 100: avg data time: 5.64e-02, avg batch time: 0.4715, average train loss: 0.0044
[09/26 01:41:19 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1588, average loss: 0.3564
[09/26 01:41:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:19 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:41:26 visual_prompt]: Epoch 91 / 100: avg data time: 6.94e-02, avg batch time: 0.4827, average train loss: 0.0044
[09/26 01:41:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1578, average loss: 0.3566
[09/26 01:41:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:27 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:41:34 visual_prompt]: Epoch 92 / 100: avg data time: 6.10e-02, avg batch time: 0.4735, average train loss: 0.0044
[09/26 01:41:36 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1584, average loss: 0.3573
[09/26 01:41:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:36 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:41:42 visual_prompt]: Epoch 93 / 100: avg data time: 6.90e-02, avg batch time: 0.4817, average train loss: 0.0044
[09/26 01:41:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 0.3572
[09/26 01:41:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:44 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:41:51 visual_prompt]: Epoch 94 / 100: avg data time: 7.39e-02, avg batch time: 0.4866, average train loss: 0.0044
[09/26 01:41:52 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1584, average loss: 0.3573
[09/26 01:41:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:41:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:41:59 visual_prompt]: Epoch 95 / 100: avg data time: 6.45e-02, avg batch time: 0.4786, average train loss: 0.0044
[09/26 01:42:01 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1578, average loss: 0.3570
[09/26 01:42:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:42:01 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:42:07 visual_prompt]: Epoch 96 / 100: avg data time: 6.86e-02, avg batch time: 0.4834, average train loss: 0.0044
[09/26 01:42:09 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1586, average loss: 0.3568
[09/26 01:42:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:42:09 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:42:16 visual_prompt]: Epoch 97 / 100: avg data time: 6.47e-02, avg batch time: 0.4775, average train loss: 0.0044
[09/26 01:42:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1584, average loss: 0.3567
[09/26 01:42:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:42:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:42:24 visual_prompt]: Epoch 98 / 100: avg data time: 6.66e-02, avg batch time: 0.4811, average train loss: 0.0043
[09/26 01:42:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 0.3567
[09/26 01:42:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:42:26 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:42:32 visual_prompt]: Epoch 99 / 100: avg data time: 6.66e-02, avg batch time: 0.4796, average train loss: 0.0044
[09/26 01:42:34 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1580, average loss: 0.3567
[09/26 01:42:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:42:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:42:41 visual_prompt]: Epoch 100 / 100: avg data time: 6.60e-02, avg batch time: 0.4794, average train loss: 0.0044
[09/26 01:42:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1577, average loss: 0.3567
[09/26 01:42:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 01:42:42 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:42:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:42:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:42:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:42:42 visual_prompt]: Training with config:
[09/26 01:42:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:42:42 visual_prompt]: Loading training data...
[09/26 01:42:42 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:42:44 visual_prompt]: Number of images: 800
[09/26 01:42:44 visual_prompt]: Number of classes: 102 / 102
[09/26 01:42:44 visual_prompt]: Loading validation data...
[09/26 01:42:44 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:42:44 visual_prompt]: Number of images: 200
[09/26 01:42:44 visual_prompt]: Number of classes: 91 / 102
[09/26 01:42:44 visual_prompt]: Constructing models...
[09/26 01:42:46 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 01:42:46 visual_prompt]: tuned percent:0.625
[09/26 01:42:47 visual_prompt]: Device used for model: 0
[09/26 01:42:47 visual_prompt]: Setting up Evaluator...
[09/26 01:42:47 visual_prompt]: Setting up Trainer...
[09/26 01:42:47 visual_prompt]: 	Setting up the optimizer...
[09/26 01:42:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:42:53 visual_prompt]: Epoch 1 / 100: avg data time: 6.22e-02, avg batch time: 0.4811, average train loss: 4.6681
[09/26 01:42:55 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 4.6780
[09/26 01:42:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:42:55 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:42:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:43:01 visual_prompt]: Epoch 2 / 100: avg data time: 6.93e-02, avg batch time: 0.4822, average train loss: 4.6424
[09/26 01:43:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 4.6360
[09/26 01:43:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 9.50	
[09/26 01:43:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:43:10 visual_prompt]: Epoch 3 / 100: avg data time: 7.35e-02, avg batch time: 0.4863, average train loss: 4.5267
[09/26 01:43:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1582, average loss: 4.5488
[09/26 01:43:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 13.50	
[09/26 01:43:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:43:18 visual_prompt]: Epoch 4 / 100: avg data time: 6.46e-02, avg batch time: 0.4775, average train loss: 4.1207
[09/26 01:43:20 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1587, average loss: 4.1217
[09/26 01:43:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 26.00	
[09/26 01:43:20 visual_prompt]: Best epoch 4: best metric: 0.120
[09/26 01:43:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:43:27 visual_prompt]: Epoch 5 / 100: avg data time: 7.15e-02, avg batch time: 0.4851, average train loss: 2.9191
[09/26 01:43:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1571, average loss: 1.9700
[09/26 01:43:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 53.00	top5: 79.50	
[09/26 01:43:28 visual_prompt]: Best epoch 5: best metric: 0.530
[09/26 01:43:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:43:35 visual_prompt]: Epoch 6 / 100: avg data time: 5.55e-02, avg batch time: 0.4696, average train loss: 0.8328
[09/26 01:43:37 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.9960
[09/26 01:43:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.50	top5: 92.00	
[09/26 01:43:37 visual_prompt]: Best epoch 6: best metric: 0.765
[09/26 01:43:37 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:43:43 visual_prompt]: Epoch 7 / 100: avg data time: 6.55e-02, avg batch time: 0.4796, average train loss: 0.2647
[09/26 01:43:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.5071
[09/26 01:43:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 01:43:45 visual_prompt]: Best epoch 7: best metric: 0.885
[09/26 01:43:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:43:51 visual_prompt]: Epoch 8 / 100: avg data time: 6.20e-02, avg batch time: 0.4757, average train loss: 0.1534
[09/26 01:43:53 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1585, average loss: 0.7879
[09/26 01:43:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 93.00	
[09/26 01:43:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:44:00 visual_prompt]: Epoch 9 / 100: avg data time: 6.05e-02, avg batch time: 0.4750, average train loss: 0.1292
[09/26 01:44:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 0.5921
[09/26 01:44:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 01:44:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:44:08 visual_prompt]: Epoch 10 / 100: avg data time: 7.00e-02, avg batch time: 0.4832, average train loss: 0.0400
[09/26 01:44:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1586, average loss: 0.4518
[09/26 01:44:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.00	
[09/26 01:44:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:44:17 visual_prompt]: Epoch 11 / 100: avg data time: 6.74e-02, avg batch time: 0.4813, average train loss: 0.0221
[09/26 01:44:18 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1585, average loss: 0.4480
[09/26 01:44:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 01:44:18 visual_prompt]: Best epoch 11: best metric: 0.900
[09/26 01:44:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:44:25 visual_prompt]: Epoch 12 / 100: avg data time: 7.31e-02, avg batch time: 0.4868, average train loss: 0.0155
[09/26 01:44:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1581, average loss: 0.4236
[09/26 01:44:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 95.50	
[09/26 01:44:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:44:33 visual_prompt]: Epoch 13 / 100: avg data time: 5.88e-02, avg batch time: 0.4720, average train loss: 0.0230
[09/26 01:44:35 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.3832
[09/26 01:44:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 01:44:35 visual_prompt]: Best epoch 13: best metric: 0.905
[09/26 01:44:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:44:42 visual_prompt]: Epoch 14 / 100: avg data time: 6.82e-02, avg batch time: 0.4827, average train loss: 0.0086
[09/26 01:44:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 0.3284
[09/26 01:44:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:44:43 visual_prompt]: Best epoch 14: best metric: 0.920
[09/26 01:44:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:44:50 visual_prompt]: Epoch 15 / 100: avg data time: 7.18e-02, avg batch time: 0.4866, average train loss: 0.0100
[09/26 01:44:52 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1587, average loss: 0.3655
[09/26 01:44:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 01:44:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:44:58 visual_prompt]: Epoch 16 / 100: avg data time: 6.83e-02, avg batch time: 0.4827, average train loss: 0.0020
[09/26 01:45:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 0.3463
[09/26 01:45:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:45:00 visual_prompt]: Best epoch 16: best metric: 0.925
[09/26 01:45:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:45:07 visual_prompt]: Epoch 17 / 100: avg data time: 6.43e-02, avg batch time: 0.4812, average train loss: 0.0012
[09/26 01:45:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1584, average loss: 0.3293
[09/26 01:45:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:45:08 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:45:15 visual_prompt]: Epoch 18 / 100: avg data time: 7.00e-02, avg batch time: 0.4851, average train loss: 0.0010
[09/26 01:45:17 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1585, average loss: 0.3237
[09/26 01:45:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:45:17 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:45:24 visual_prompt]: Epoch 19 / 100: avg data time: 6.81e-02, avg batch time: 0.4820, average train loss: 0.0009
[09/26 01:45:25 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.3215
[09/26 01:45:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:45:25 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:45:32 visual_prompt]: Epoch 20 / 100: avg data time: 6.74e-02, avg batch time: 0.4812, average train loss: 0.0008
[09/26 01:45:34 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1586, average loss: 0.3199
[09/26 01:45:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:45:34 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:45:40 visual_prompt]: Epoch 21 / 100: avg data time: 6.31e-02, avg batch time: 0.4785, average train loss: 0.0007
[09/26 01:45:42 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1584, average loss: 0.3189
[09/26 01:45:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:45:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:45:49 visual_prompt]: Epoch 22 / 100: avg data time: 7.09e-02, avg batch time: 0.4847, average train loss: 0.0007
[09/26 01:45:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.3172
[09/26 01:45:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:45:50 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:45:57 visual_prompt]: Epoch 23 / 100: avg data time: 7.49e-02, avg batch time: 0.4882, average train loss: 0.0007
[09/26 01:45:59 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1584, average loss: 0.3163
[09/26 01:45:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:45:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:46:05 visual_prompt]: Epoch 24 / 100: avg data time: 5.06e-02, avg batch time: 0.4673, average train loss: 0.0006
[09/26 01:46:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1578, average loss: 0.3158
[09/26 01:46:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:46:14 visual_prompt]: Epoch 25 / 100: avg data time: 6.20e-02, avg batch time: 0.4763, average train loss: 0.0006
[09/26 01:46:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.3153
[09/26 01:46:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:46:22 visual_prompt]: Epoch 26 / 100: avg data time: 5.33e-02, avg batch time: 0.4685, average train loss: 0.0006
[09/26 01:46:23 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 0.3143
[09/26 01:46:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:46:30 visual_prompt]: Epoch 27 / 100: avg data time: 5.63e-02, avg batch time: 0.4705, average train loss: 0.0005
[09/26 01:46:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.3135
[09/26 01:46:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:46:38 visual_prompt]: Epoch 28 / 100: avg data time: 6.68e-02, avg batch time: 0.4803, average train loss: 0.0005
[09/26 01:46:40 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.3129
[09/26 01:46:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:46:47 visual_prompt]: Epoch 29 / 100: avg data time: 7.11e-02, avg batch time: 0.4844, average train loss: 0.0005
[09/26 01:46:48 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1582, average loss: 0.3120
[09/26 01:46:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:46:55 visual_prompt]: Epoch 30 / 100: avg data time: 7.19e-02, avg batch time: 0.4852, average train loss: 0.0005
[09/26 01:46:57 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 0.3113
[09/26 01:46:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:46:57 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:47:03 visual_prompt]: Epoch 31 / 100: avg data time: 5.84e-02, avg batch time: 0.4728, average train loss: 0.0005
[09/26 01:47:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1580, average loss: 0.3110
[09/26 01:47:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:47:12 visual_prompt]: Epoch 32 / 100: avg data time: 6.62e-02, avg batch time: 0.4793, average train loss: 0.0004
[09/26 01:47:13 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1578, average loss: 0.3106
[09/26 01:47:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:47:20 visual_prompt]: Epoch 33 / 100: avg data time: 6.65e-02, avg batch time: 0.4800, average train loss: 0.0004
[09/26 01:47:22 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.3108
[09/26 01:47:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:22 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:47:28 visual_prompt]: Epoch 34 / 100: avg data time: 6.69e-02, avg batch time: 0.4795, average train loss: 0.0004
[09/26 01:47:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.3106
[09/26 01:47:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:47:37 visual_prompt]: Epoch 35 / 100: avg data time: 7.25e-02, avg batch time: 0.4862, average train loss: 0.0004
[09/26 01:47:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1574, average loss: 0.3103
[09/26 01:47:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:47:45 visual_prompt]: Epoch 36 / 100: avg data time: 7.15e-02, avg batch time: 0.4843, average train loss: 0.0004
[09/26 01:47:47 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.3092
[09/26 01:47:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:47:53 visual_prompt]: Epoch 37 / 100: avg data time: 6.99e-02, avg batch time: 0.4826, average train loss: 0.0004
[09/26 01:47:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1578, average loss: 0.3087
[09/26 01:47:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:47:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:48:02 visual_prompt]: Epoch 38 / 100: avg data time: 6.54e-02, avg batch time: 0.4794, average train loss: 0.0004
[09/26 01:48:04 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1579, average loss: 0.3080
[09/26 01:48:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:04 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:48:10 visual_prompt]: Epoch 39 / 100: avg data time: 6.94e-02, avg batch time: 0.4830, average train loss: 0.0004
[09/26 01:48:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1576, average loss: 0.3078
[09/26 01:48:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:48:18 visual_prompt]: Epoch 40 / 100: avg data time: 6.11e-02, avg batch time: 0.4735, average train loss: 0.0004
[09/26 01:48:20 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1575, average loss: 0.3075
[09/26 01:48:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:20 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:48:27 visual_prompt]: Epoch 41 / 100: avg data time: 6.95e-02, avg batch time: 0.4823, average train loss: 0.0004
[09/26 01:48:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 0.3071
[09/26 01:48:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:48:35 visual_prompt]: Epoch 42 / 100: avg data time: 6.85e-02, avg batch time: 0.4817, average train loss: 0.0004
[09/26 01:48:37 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1579, average loss: 0.3067
[09/26 01:48:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:37 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:48:44 visual_prompt]: Epoch 43 / 100: avg data time: 6.96e-02, avg batch time: 0.4825, average train loss: 0.0003
[09/26 01:48:45 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1576, average loss: 0.3065
[09/26 01:48:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:45 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:48:52 visual_prompt]: Epoch 44 / 100: avg data time: 6.29e-02, avg batch time: 0.4756, average train loss: 0.0004
[09/26 01:48:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.3059
[09/26 01:48:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:48:53 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:49:00 visual_prompt]: Epoch 45 / 100: avg data time: 7.01e-02, avg batch time: 0.4828, average train loss: 0.0003
[09/26 01:49:02 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1580, average loss: 0.3054
[09/26 01:49:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:02 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:49:08 visual_prompt]: Epoch 46 / 100: avg data time: 6.24e-02, avg batch time: 0.4764, average train loss: 0.0003
[09/26 01:49:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1579, average loss: 0.3050
[09/26 01:49:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:10 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:49:17 visual_prompt]: Epoch 47 / 100: avg data time: 7.01e-02, avg batch time: 0.4827, average train loss: 0.0003
[09/26 01:49:19 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.3046
[09/26 01:49:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:19 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:49:25 visual_prompt]: Epoch 48 / 100: avg data time: 8.78e-02, avg batch time: 0.5002, average train loss: 0.0003
[09/26 01:49:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1586, average loss: 0.3046
[09/26 01:49:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:49:34 visual_prompt]: Epoch 49 / 100: avg data time: 6.98e-02, avg batch time: 0.4838, average train loss: 0.0003
[09/26 01:49:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.3047
[09/26 01:49:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:49:42 visual_prompt]: Epoch 50 / 100: avg data time: 6.27e-02, avg batch time: 0.4757, average train loss: 0.0003
[09/26 01:49:44 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1586, average loss: 0.3045
[09/26 01:49:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:49:51 visual_prompt]: Epoch 51 / 100: avg data time: 7.07e-02, avg batch time: 0.4832, average train loss: 0.0003
[09/26 01:49:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 0.3041
[09/26 01:49:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:49:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:49:59 visual_prompt]: Epoch 52 / 100: avg data time: 6.61e-02, avg batch time: 0.4793, average train loss: 0.0003
[09/26 01:50:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1577, average loss: 0.3040
[09/26 01:50:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:00 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:50:07 visual_prompt]: Epoch 53 / 100: avg data time: 6.48e-02, avg batch time: 0.4768, average train loss: 0.0003
[09/26 01:50:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 0.3038
[09/26 01:50:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:09 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:50:15 visual_prompt]: Epoch 54 / 100: avg data time: 6.97e-02, avg batch time: 0.4830, average train loss: 0.0003
[09/26 01:50:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1581, average loss: 0.3037
[09/26 01:50:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:17 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:50:24 visual_prompt]: Epoch 55 / 100: avg data time: 6.61e-02, avg batch time: 0.4790, average train loss: 0.0003
[09/26 01:50:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1579, average loss: 0.3038
[09/26 01:50:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:50:32 visual_prompt]: Epoch 56 / 100: avg data time: 6.68e-02, avg batch time: 0.4791, average train loss: 0.0003
[09/26 01:50:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1577, average loss: 0.3037
[09/26 01:50:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:34 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:50:40 visual_prompt]: Epoch 57 / 100: avg data time: 7.08e-02, avg batch time: 0.4839, average train loss: 0.0003
[09/26 01:50:42 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1583, average loss: 0.3035
[09/26 01:50:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:42 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:50:49 visual_prompt]: Epoch 58 / 100: avg data time: 6.67e-02, avg batch time: 0.4806, average train loss: 0.0003
[09/26 01:50:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 0.3034
[09/26 01:50:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:50 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:50:57 visual_prompt]: Epoch 59 / 100: avg data time: 7.36e-02, avg batch time: 0.4867, average train loss: 0.0003
[09/26 01:50:59 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1585, average loss: 0.3035
[09/26 01:50:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:50:59 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:51:05 visual_prompt]: Epoch 60 / 100: avg data time: 5.70e-02, avg batch time: 0.4704, average train loss: 0.0003
[09/26 01:51:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1582, average loss: 0.3033
[09/26 01:51:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:51:07 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:51:14 visual_prompt]: Epoch 61 / 100: avg data time: 7.04e-02, avg batch time: 0.4837, average train loss: 0.0003
[09/26 01:51:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1589, average loss: 0.3032
[09/26 01:51:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:51:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:51:22 visual_prompt]: Epoch 62 / 100: avg data time: 7.25e-02, avg batch time: 0.4854, average train loss: 0.0003
[09/26 01:51:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1583, average loss: 0.3030
[09/26 01:51:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:51:24 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:51:31 visual_prompt]: Epoch 63 / 100: avg data time: 6.76e-02, avg batch time: 0.4816, average train loss: 0.0003
[09/26 01:51:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 0.3028
[09/26 01:51:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:51:32 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:51:39 visual_prompt]: Epoch 64 / 100: avg data time: 7.07e-02, avg batch time: 0.4845, average train loss: 0.0003
[09/26 01:51:41 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.3026
[09/26 01:51:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 01:51:41 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:51:47 visual_prompt]: Epoch 65 / 100: avg data time: 7.08e-02, avg batch time: 0.4837, average train loss: 0.0003
[09/26 01:51:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 0.3025
[09/26 01:51:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:51:49 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:51:56 visual_prompt]: Epoch 66 / 100: avg data time: 7.79e-02, avg batch time: 0.4910, average train loss: 0.0003
[09/26 01:51:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1577, average loss: 0.3024
[09/26 01:51:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:51:58 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:52:04 visual_prompt]: Epoch 67 / 100: avg data time: 5.58e-02, avg batch time: 0.4688, average train loss: 0.0003
[09/26 01:52:06 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1579, average loss: 0.3023
[09/26 01:52:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:06 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:52:12 visual_prompt]: Epoch 68 / 100: avg data time: 6.89e-02, avg batch time: 0.4820, average train loss: 0.0003
[09/26 01:52:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.3023
[09/26 01:52:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:14 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:52:21 visual_prompt]: Epoch 69 / 100: avg data time: 6.88e-02, avg batch time: 0.4819, average train loss: 0.0003
[09/26 01:52:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1582, average loss: 0.3023
[09/26 01:52:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:22 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:52:29 visual_prompt]: Epoch 70 / 100: avg data time: 6.83e-02, avg batch time: 0.4821, average train loss: 0.0003
[09/26 01:52:31 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1578, average loss: 0.3023
[09/26 01:52:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:31 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:52:37 visual_prompt]: Epoch 71 / 100: avg data time: 7.22e-02, avg batch time: 0.4853, average train loss: 0.0003
[09/26 01:52:39 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1587, average loss: 0.3023
[09/26 01:52:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:52:46 visual_prompt]: Epoch 72 / 100: avg data time: 6.62e-02, avg batch time: 0.4793, average train loss: 0.0003
[09/26 01:52:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 0.3023
[09/26 01:52:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:52:54 visual_prompt]: Epoch 73 / 100: avg data time: 6.91e-02, avg batch time: 0.4828, average train loss: 0.0003
[09/26 01:52:56 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.3021
[09/26 01:52:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:52:56 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:53:02 visual_prompt]: Epoch 74 / 100: avg data time: 5.30e-02, avg batch time: 0.4674, average train loss: 0.0003
[09/26 01:53:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1575, average loss: 0.3020
[09/26 01:53:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:04 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:53:11 visual_prompt]: Epoch 75 / 100: avg data time: 6.99e-02, avg batch time: 0.4833, average train loss: 0.0003
[09/26 01:53:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 0.3018
[09/26 01:53:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:53:19 visual_prompt]: Epoch 76 / 100: avg data time: 6.82e-02, avg batch time: 0.4809, average train loss: 0.0003
[09/26 01:53:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.3018
[09/26 01:53:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:21 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:53:27 visual_prompt]: Epoch 77 / 100: avg data time: 6.78e-02, avg batch time: 0.4812, average train loss: 0.0003
[09/26 01:53:29 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1584, average loss: 0.3018
[09/26 01:53:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:53:36 visual_prompt]: Epoch 78 / 100: avg data time: 7.14e-02, avg batch time: 0.4842, average train loss: 0.0003
[09/26 01:53:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1575, average loss: 0.3018
[09/26 01:53:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:37 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:53:44 visual_prompt]: Epoch 79 / 100: avg data time: 5.01e-02, avg batch time: 0.4641, average train loss: 0.0003
[09/26 01:53:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.3017
[09/26 01:53:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:46 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:53:52 visual_prompt]: Epoch 80 / 100: avg data time: 6.50e-02, avg batch time: 0.4778, average train loss: 0.0003
[09/26 01:53:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1578, average loss: 0.3017
[09/26 01:53:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:53:54 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:54:00 visual_prompt]: Epoch 81 / 100: avg data time: 5.46e-02, avg batch time: 0.4692, average train loss: 0.0003
[09/26 01:54:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.3016
[09/26 01:54:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:54:08 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.4744, average train loss: 0.0003
[09/26 01:54:10 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1582, average loss: 0.3016
[09/26 01:54:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:54:17 visual_prompt]: Epoch 83 / 100: avg data time: 5.53e-02, avg batch time: 0.4687, average train loss: 0.0003
[09/26 01:54:18 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.3016
[09/26 01:54:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:54:25 visual_prompt]: Epoch 84 / 100: avg data time: 7.23e-02, avg batch time: 0.4856, average train loss: 0.0003
[09/26 01:54:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1581, average loss: 0.3016
[09/26 01:54:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:54:34 visual_prompt]: Epoch 85 / 100: avg data time: 6.91e-02, avg batch time: 0.4844, average train loss: 0.0003
[09/26 01:54:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1582, average loss: 0.3015
[09/26 01:54:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:54:42 visual_prompt]: Epoch 86 / 100: avg data time: 6.50e-02, avg batch time: 0.4783, average train loss: 0.0003
[09/26 01:54:44 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1584, average loss: 0.3015
[09/26 01:54:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:44 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:54:50 visual_prompt]: Epoch 87 / 100: avg data time: 5.87e-02, avg batch time: 0.4735, average train loss: 0.0002
[09/26 01:54:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1578, average loss: 0.3015
[09/26 01:54:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:54:52 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:54:59 visual_prompt]: Epoch 88 / 100: avg data time: 7.14e-02, avg batch time: 0.4847, average train loss: 0.0003
[09/26 01:55:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1581, average loss: 0.3015
[09/26 01:55:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:55:07 visual_prompt]: Epoch 89 / 100: avg data time: 6.21e-02, avg batch time: 0.4770, average train loss: 0.0003
[09/26 01:55:09 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.3015
[09/26 01:55:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:09 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:55:15 visual_prompt]: Epoch 90 / 100: avg data time: 7.01e-02, avg batch time: 0.4836, average train loss: 0.0003
[09/26 01:55:17 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1583, average loss: 0.3015
[09/26 01:55:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:17 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:55:24 visual_prompt]: Epoch 91 / 100: avg data time: 6.98e-02, avg batch time: 0.4842, average train loss: 0.0002
[09/26 01:55:25 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 0.3015
[09/26 01:55:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:55:32 visual_prompt]: Epoch 92 / 100: avg data time: 7.09e-02, avg batch time: 0.4845, average train loss: 0.0003
[09/26 01:55:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 0.3015
[09/26 01:55:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:34 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:55:40 visual_prompt]: Epoch 93 / 100: avg data time: 7.58e-02, avg batch time: 0.4894, average train loss: 0.0003
[09/26 01:55:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 0.3015
[09/26 01:55:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:42 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:55:49 visual_prompt]: Epoch 94 / 100: avg data time: 7.28e-02, avg batch time: 0.4873, average train loss: 0.0003
[09/26 01:55:51 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1584, average loss: 0.3015
[09/26 01:55:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:51 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:55:57 visual_prompt]: Epoch 95 / 100: avg data time: 7.39e-02, avg batch time: 0.4882, average train loss: 0.0003
[09/26 01:55:59 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.3015
[09/26 01:55:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:55:59 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:56:06 visual_prompt]: Epoch 96 / 100: avg data time: 7.13e-02, avg batch time: 0.4853, average train loss: 0.0003
[09/26 01:56:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1588, average loss: 0.3015
[09/26 01:56:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:56:07 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:56:14 visual_prompt]: Epoch 97 / 100: avg data time: 6.43e-02, avg batch time: 0.4794, average train loss: 0.0003
[09/26 01:56:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.3015
[09/26 01:56:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:56:16 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:56:22 visual_prompt]: Epoch 98 / 100: avg data time: 6.82e-02, avg batch time: 0.4842, average train loss: 0.0003
[09/26 01:56:24 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 0.3015
[09/26 01:56:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:56:24 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:56:31 visual_prompt]: Epoch 99 / 100: avg data time: 6.75e-02, avg batch time: 0.4821, average train loss: 0.0003
[09/26 01:56:33 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1586, average loss: 0.3015
[09/26 01:56:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:56:33 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:56:39 visual_prompt]: Epoch 100 / 100: avg data time: 6.38e-02, avg batch time: 0.4782, average train loss: 0.0003
[09/26 01:56:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 0.3015
[09/26 01:56:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 01:56:41 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:56:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:56:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:56:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:56:41 visual_prompt]: Training with config:
[09/26 01:56:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:56:41 visual_prompt]: Loading training data...
[09/26 01:56:41 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:56:42 visual_prompt]: Number of images: 800
[09/26 01:56:42 visual_prompt]: Number of classes: 102 / 102
[09/26 01:56:42 visual_prompt]: Loading validation data...
[09/26 01:56:42 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 01:56:42 visual_prompt]: Number of images: 200
[09/26 01:56:42 visual_prompt]: Number of classes: 91 / 102
[09/26 01:56:42 visual_prompt]: Constructing models...
[09/26 01:56:45 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 01:56:45 visual_prompt]: tuned percent:0.625
[09/26 01:56:45 visual_prompt]: Device used for model: 0
[09/26 01:56:45 visual_prompt]: Setting up Evaluator...
[09/26 01:56:45 visual_prompt]: Setting up Trainer...
[09/26 01:56:45 visual_prompt]: 	Setting up the optimizer...
[09/26 01:56:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:56:52 visual_prompt]: Epoch 1 / 100: avg data time: 6.70e-02, avg batch time: 0.4865, average train loss: 4.6607
[09/26 01:56:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1587, average loss: 4.6780
[09/26 01:56:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:56:53 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:56:53 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 01:57:00 visual_prompt]: Epoch 2 / 100: avg data time: 6.57e-02, avg batch time: 0.4811, average train loss: 4.6133
[09/26 01:57:02 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 4.5971
[09/26 01:57:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.00	
[09/26 01:57:02 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 01:57:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 01:57:08 visual_prompt]: Epoch 3 / 100: avg data time: 6.57e-02, avg batch time: 0.4788, average train loss: 4.4111
[09/26 01:57:10 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1586, average loss: 4.2962
[09/26 01:57:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 12.50	
[09/26 01:57:10 visual_prompt]: Best epoch 3: best metric: 0.035
[09/26 01:57:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 01:57:16 visual_prompt]: Epoch 4 / 100: avg data time: 6.36e-02, avg batch time: 0.4775, average train loss: 4.1918
[09/26 01:57:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1589, average loss: 3.8505
[09/26 01:57:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 15.50	top5: 35.50	
[09/26 01:57:18 visual_prompt]: Best epoch 4: best metric: 0.155
[09/26 01:57:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 01:57:25 visual_prompt]: Epoch 5 / 100: avg data time: 5.83e-02, avg batch time: 0.4723, average train loss: 3.6990
[09/26 01:57:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1592, average loss: 3.1621
[09/26 01:57:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 41.50	top5: 65.00	
[09/26 01:57:26 visual_prompt]: Best epoch 5: best metric: 0.415
[09/26 01:57:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 01:57:33 visual_prompt]: Epoch 6 / 100: avg data time: 5.18e-02, avg batch time: 0.4699, average train loss: 2.7228
[09/26 01:57:35 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 2.2027
[09/26 01:57:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.00	top5: 87.00	
[09/26 01:57:35 visual_prompt]: Best epoch 6: best metric: 0.600
[09/26 01:57:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 01:57:41 visual_prompt]: Epoch 7 / 100: avg data time: 6.05e-02, avg batch time: 0.4757, average train loss: 1.2728
[09/26 01:57:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1587, average loss: 0.9854
[09/26 01:57:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 97.00	
[09/26 01:57:43 visual_prompt]: Best epoch 7: best metric: 0.860
[09/26 01:57:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 01:57:49 visual_prompt]: Epoch 8 / 100: avg data time: 6.63e-02, avg batch time: 0.4812, average train loss: 0.7583
[09/26 01:57:51 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1586, average loss: 1.1186
[09/26 01:57:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.50	
[09/26 01:57:51 visual_prompt]: Best epoch 8: best metric: 0.885
[09/26 01:57:51 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 01:57:58 visual_prompt]: Epoch 9 / 100: avg data time: 6.26e-02, avg batch time: 0.4768, average train loss: 1.9339
[09/26 01:57:59 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 4.7091
[09/26 01:57:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 01:57:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 01:58:06 visual_prompt]: Epoch 10 / 100: avg data time: 6.71e-02, avg batch time: 0.4819, average train loss: 4.6681
[09/26 01:58:08 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1584, average loss: 4.6792
[09/26 01:58:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 01:58:08 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 01:58:14 visual_prompt]: Epoch 11 / 100: avg data time: 6.72e-02, avg batch time: 0.4812, average train loss: 4.6639
[09/26 01:58:16 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1588, average loss: 4.7065
[09/26 01:58:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/26 01:58:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 01:58:23 visual_prompt]: Epoch 12 / 100: avg data time: 6.22e-02, avg batch time: 0.4765, average train loss: 4.7199
[09/26 01:58:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1586, average loss: 4.7587
[09/26 01:58:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 01:58:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 01:58:31 visual_prompt]: Epoch 13 / 100: avg data time: 6.66e-02, avg batch time: 0.4800, average train loss: 4.7192
[09/26 01:58:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 5.0627
[09/26 01:58:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 01:58:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 01:58:39 visual_prompt]: Epoch 14 / 100: avg data time: 6.36e-02, avg batch time: 0.4777, average train loss: 4.7046
[09/26 01:58:41 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1585, average loss: 4.6997
[09/26 01:58:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/26 01:58:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 01:58:48 visual_prompt]: Epoch 15 / 100: avg data time: 6.38e-02, avg batch time: 0.4770, average train loss: 4.7041
[09/26 01:58:49 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 4.6745
[09/26 01:58:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 01:58:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 01:58:56 visual_prompt]: Epoch 16 / 100: avg data time: 6.65e-02, avg batch time: 0.4793, average train loss: 4.6766
[09/26 01:58:58 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1587, average loss: 4.6964
[09/26 01:58:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 01:58:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 01:59:04 visual_prompt]: Epoch 17 / 100: avg data time: 6.75e-02, avg batch time: 0.4806, average train loss: 4.6612
[09/26 01:59:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1585, average loss: 4.6820
[09/26 01:59:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 01:59:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 01:59:12 visual_prompt]: Epoch 18 / 100: avg data time: 6.42e-02, avg batch time: 0.4794, average train loss: 4.6502
[09/26 01:59:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 4.7536
[09/26 01:59:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 01:59:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 01:59:21 visual_prompt]: Epoch 19 / 100: avg data time: 6.82e-02, avg batch time: 0.4806, average train loss: 4.7010
[09/26 01:59:22 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1585, average loss: 4.7774
[09/26 01:59:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 1.50	
[09/26 01:59:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 01:59:29 visual_prompt]: Epoch 20 / 100: avg data time: 6.23e-02, avg batch time: 0.4765, average train loss: 4.6752
[09/26 01:59:31 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1584, average loss: 4.7006
[09/26 01:59:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/26 01:59:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 01:59:37 visual_prompt]: Epoch 21 / 100: avg data time: 6.93e-02, avg batch time: 0.4832, average train loss: 4.6818
[09/26 01:59:39 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1582, average loss: 4.6933
[09/26 01:59:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.00	
[09/26 01:59:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 01:59:46 visual_prompt]: Epoch 22 / 100: avg data time: 7.03e-02, avg batch time: 0.4841, average train loss: 4.6482
[09/26 01:59:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 4.7636
[09/26 01:59:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 01:59:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 01:59:54 visual_prompt]: Epoch 23 / 100: avg data time: 6.71e-02, avg batch time: 0.4806, average train loss: 4.6711
[09/26 01:59:56 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 4.7226
[09/26 01:59:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 3.00	
[09/26 01:59:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:00:02 visual_prompt]: Epoch 24 / 100: avg data time: 6.00e-02, avg batch time: 0.4741, average train loss: 4.6685
[09/26 02:00:04 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1585, average loss: 4.6686
[09/26 02:00:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 02:00:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:00:11 visual_prompt]: Epoch 25 / 100: avg data time: 6.49e-02, avg batch time: 0.4775, average train loss: 4.6656
[09/26 02:00:12 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1587, average loss: 4.7115
[09/26 02:00:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 02:00:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:00:19 visual_prompt]: Epoch 26 / 100: avg data time: 6.02e-02, avg batch time: 0.4721, average train loss: 4.6596
[09/26 02:00:21 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 4.6863
[09/26 02:00:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:00:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:00:27 visual_prompt]: Epoch 27 / 100: avg data time: 6.04e-02, avg batch time: 0.4739, average train loss: 4.6408
[09/26 02:00:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1576, average loss: 4.6650
[09/26 02:00:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:00:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:00:35 visual_prompt]: Epoch 28 / 100: avg data time: 7.13e-02, avg batch time: 0.4841, average train loss: 4.6363
[09/26 02:00:37 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1585, average loss: 4.6807
[09/26 02:00:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.50	
[09/26 02:00:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:00:44 visual_prompt]: Epoch 29 / 100: avg data time: 6.44e-02, avg batch time: 0.4769, average train loss: 4.6586
[09/26 02:00:45 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1578, average loss: 4.7053
[09/26 02:00:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 1.50	
[09/26 02:00:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:00:52 visual_prompt]: Epoch 30 / 100: avg data time: 6.57e-02, avg batch time: 0.4788, average train loss: 4.6747
[09/26 02:00:54 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1586, average loss: 4.6731
[09/26 02:00:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 02:00:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:01:00 visual_prompt]: Epoch 31 / 100: avg data time: 6.73e-02, avg batch time: 0.4804, average train loss: 4.6664
[09/26 02:01:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1584, average loss: 4.6937
[09/26 02:01:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 02:01:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:01:09 visual_prompt]: Epoch 32 / 100: avg data time: 6.58e-02, avg batch time: 0.4787, average train loss: 4.6468
[09/26 02:01:10 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 4.6790
[09/26 02:01:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 02:01:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:01:17 visual_prompt]: Epoch 33 / 100: avg data time: 6.87e-02, avg batch time: 0.4816, average train loss: 4.6434
[09/26 02:01:19 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1585, average loss: 4.6666
[09/26 02:01:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.50	
[09/26 02:01:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:01:25 visual_prompt]: Epoch 34 / 100: avg data time: 6.18e-02, avg batch time: 0.4762, average train loss: 4.6437
[09/26 02:01:27 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 4.6615
[09/26 02:01:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/26 02:01:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:01:34 visual_prompt]: Epoch 35 / 100: avg data time: 6.52e-02, avg batch time: 0.4789, average train loss: 4.6350
[09/26 02:01:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 4.6826
[09/26 02:01:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 02:01:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:01:42 visual_prompt]: Epoch 36 / 100: avg data time: 6.33e-02, avg batch time: 0.4758, average train loss: 4.6496
[09/26 02:01:43 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1584, average loss: 4.7173
[09/26 02:01:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/26 02:01:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:01:50 visual_prompt]: Epoch 37 / 100: avg data time: 5.85e-02, avg batch time: 0.4718, average train loss: 4.6561
[09/26 02:01:52 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 4.6777
[09/26 02:01:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:01:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:01:58 visual_prompt]: Epoch 38 / 100: avg data time: 6.74e-02, avg batch time: 0.4804, average train loss: 4.6691
[09/26 02:02:00 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1581, average loss: 4.6760
[09/26 02:02:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:02:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:02:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.72e-02, avg batch time: 0.4708, average train loss: 4.6608
[09/26 02:02:08 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1584, average loss: 4.7938
[09/26 02:02:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 2.00	
[09/26 02:02:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:02:15 visual_prompt]: Epoch 40 / 100: avg data time: 6.81e-02, avg batch time: 0.4814, average train loss: 4.6549
[09/26 02:02:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1584, average loss: 4.6607
[09/26 02:02:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 4.50	
[09/26 02:02:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:02:23 visual_prompt]: Epoch 41 / 100: avg data time: 6.69e-02, avg batch time: 0.4795, average train loss: 4.6496
[09/26 02:02:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1585, average loss: 4.7121
[09/26 02:02:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.00	
[09/26 02:02:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:02:32 visual_prompt]: Epoch 42 / 100: avg data time: 6.44e-02, avg batch time: 0.4774, average train loss: 4.6450
[09/26 02:02:33 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1584, average loss: 4.6767
[09/26 02:02:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 02:02:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:02:40 visual_prompt]: Epoch 43 / 100: avg data time: 7.02e-02, avg batch time: 0.4843, average train loss: 4.6643
[09/26 02:02:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 4.6750
[09/26 02:02:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.00	
[09/26 02:02:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:02:48 visual_prompt]: Epoch 44 / 100: avg data time: 6.42e-02, avg batch time: 0.4785, average train loss: 4.6381
[09/26 02:02:50 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1584, average loss: 4.6779
[09/26 02:02:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 02:02:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:02:56 visual_prompt]: Epoch 45 / 100: avg data time: 5.09e-02, avg batch time: 0.4646, average train loss: 4.6330
[09/26 02:02:58 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1588, average loss: 4.6985
[09/26 02:02:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.00	
[09/26 02:02:58 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:03:05 visual_prompt]: Epoch 46 / 100: avg data time: 6.74e-02, avg batch time: 0.4806, average train loss: 4.6301
[09/26 02:03:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 4.7004
[09/26 02:03:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 02:03:06 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:03:13 visual_prompt]: Epoch 47 / 100: avg data time: 6.94e-02, avg batch time: 0.4822, average train loss: 4.6451
[09/26 02:03:15 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1581, average loss: 4.6816
[09/26 02:03:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.00	
[09/26 02:03:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:03:21 visual_prompt]: Epoch 48 / 100: avg data time: 6.62e-02, avg batch time: 0.4797, average train loss: 4.6140
[09/26 02:03:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 4.7255
[09/26 02:03:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.00	top5: 4.50	
[09/26 02:03:23 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:03:30 visual_prompt]: Epoch 49 / 100: avg data time: 6.80e-02, avg batch time: 0.4806, average train loss: 4.6525
[09/26 02:03:31 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 4.7260
[09/26 02:03:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 02:03:31 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:03:38 visual_prompt]: Epoch 50 / 100: avg data time: 6.12e-02, avg batch time: 0.4741, average train loss: 4.6576
[09/26 02:03:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1583, average loss: 4.6700
[09/26 02:03:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 02:03:39 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:03:46 visual_prompt]: Epoch 51 / 100: avg data time: 6.66e-02, avg batch time: 0.4807, average train loss: 4.6405
[09/26 02:03:48 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1581, average loss: 4.6579
[09/26 02:03:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:03:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:03:54 visual_prompt]: Epoch 52 / 100: avg data time: 6.26e-02, avg batch time: 0.4767, average train loss: 4.6416
[09/26 02:03:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 4.6625
[09/26 02:03:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/26 02:03:56 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:04:03 visual_prompt]: Epoch 53 / 100: avg data time: 7.03e-02, avg batch time: 0.4829, average train loss: 4.6251
[09/26 02:04:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 4.6646
[09/26 02:04:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 02:04:04 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:04:11 visual_prompt]: Epoch 54 / 100: avg data time: 6.92e-02, avg batch time: 0.4827, average train loss: 4.6098
[09/26 02:04:13 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1585, average loss: 4.6925
[09/26 02:04:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/26 02:04:13 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:04:19 visual_prompt]: Epoch 55 / 100: avg data time: 6.30e-02, avg batch time: 0.4768, average train loss: 4.6175
[09/26 02:04:21 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1587, average loss: 4.7050
[09/26 02:04:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 02:04:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:04:28 visual_prompt]: Epoch 56 / 100: avg data time: 6.80e-02, avg batch time: 0.4832, average train loss: 4.6468
[09/26 02:04:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 4.6696
[09/26 02:04:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:04:30 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:04:36 visual_prompt]: Epoch 57 / 100: avg data time: 6.82e-02, avg batch time: 0.4812, average train loss: 4.6233
[09/26 02:04:38 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1584, average loss: 4.6819
[09/26 02:04:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 4.00	
[09/26 02:04:38 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:04:44 visual_prompt]: Epoch 58 / 100: avg data time: 5.42e-02, avg batch time: 0.4688, average train loss: 4.6167
[09/26 02:04:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 4.6490
[09/26 02:04:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 8.00	
[09/26 02:04:46 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:04:53 visual_prompt]: Epoch 59 / 100: avg data time: 6.89e-02, avg batch time: 0.4814, average train loss: 4.6149
[09/26 02:04:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 4.6731
[09/26 02:04:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 02:04:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:05:01 visual_prompt]: Epoch 60 / 100: avg data time: 6.50e-02, avg batch time: 0.4772, average train loss: 4.6338
[09/26 02:05:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 4.6691
[09/26 02:05:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:05:03 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:05:09 visual_prompt]: Epoch 61 / 100: avg data time: 6.12e-02, avg batch time: 0.4742, average train loss: 4.6142
[09/26 02:05:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 4.6828
[09/26 02:05:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/26 02:05:11 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:05:17 visual_prompt]: Epoch 62 / 100: avg data time: 6.40e-02, avg batch time: 0.4759, average train loss: 4.6472
[09/26 02:05:19 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1586, average loss: 4.6734
[09/26 02:05:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 02:05:19 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:05:26 visual_prompt]: Epoch 63 / 100: avg data time: 6.90e-02, avg batch time: 0.4810, average train loss: 4.6291
[09/26 02:05:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 4.6791
[09/26 02:05:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 02:05:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:05:34 visual_prompt]: Epoch 64 / 100: avg data time: 5.95e-02, avg batch time: 0.4725, average train loss: 4.6257
[09/26 02:05:36 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1585, average loss: 4.6784
[09/26 02:05:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 2.00	
[09/26 02:05:36 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:05:42 visual_prompt]: Epoch 65 / 100: avg data time: 6.59e-02, avg batch time: 0.4789, average train loss: 4.6137
[09/26 02:05:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 4.6623
[09/26 02:05:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/26 02:05:44 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:05:51 visual_prompt]: Epoch 66 / 100: avg data time: 6.62e-02, avg batch time: 0.4778, average train loss: 4.6102
[09/26 02:05:52 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 4.6872
[09/26 02:05:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:05:52 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:05:59 visual_prompt]: Epoch 67 / 100: avg data time: 6.34e-02, avg batch time: 0.4758, average train loss: 4.6127
[09/26 02:06:01 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1583, average loss: 4.6874
[09/26 02:06:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.00	
[09/26 02:06:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:06:07 visual_prompt]: Epoch 68 / 100: avg data time: 7.09e-02, avg batch time: 0.4837, average train loss: 4.6152
[09/26 02:06:09 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1586, average loss: 4.6775
[09/26 02:06:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 4.00	
[09/26 02:06:09 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:06:16 visual_prompt]: Epoch 69 / 100: avg data time: 6.11e-02, avg batch time: 0.4739, average train loss: 4.6256
[09/26 02:06:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 4.6725
[09/26 02:06:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 2.50	
[09/26 02:06:17 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:06:24 visual_prompt]: Epoch 70 / 100: avg data time: 6.42e-02, avg batch time: 0.4764, average train loss: 4.6152
[09/26 02:06:25 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1584, average loss: 4.6706
[09/26 02:06:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.50	
[09/26 02:06:25 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:06:32 visual_prompt]: Epoch 71 / 100: avg data time: 6.43e-02, avg batch time: 0.4771, average train loss: 4.6081
[09/26 02:06:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 4.6580
[09/26 02:06:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:06:34 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:06:40 visual_prompt]: Epoch 72 / 100: avg data time: 6.72e-02, avg batch time: 0.4794, average train loss: 4.5916
[09/26 02:06:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 4.6687
[09/26 02:06:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/26 02:06:42 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:06:49 visual_prompt]: Epoch 73 / 100: avg data time: 6.49e-02, avg batch time: 0.4775, average train loss: 4.6028
[09/26 02:06:50 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 4.6458
[09/26 02:06:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:06:50 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:06:57 visual_prompt]: Epoch 74 / 100: avg data time: 6.29e-02, avg batch time: 0.4757, average train loss: 4.6110
[09/26 02:06:58 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1580, average loss: 4.6563
[09/26 02:06:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:06:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:07:05 visual_prompt]: Epoch 75 / 100: avg data time: 6.52e-02, avg batch time: 0.4774, average train loss: 4.6116
[09/26 02:07:07 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1581, average loss: 4.6883
[09/26 02:07:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 02:07:07 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:07:13 visual_prompt]: Epoch 76 / 100: avg data time: 5.26e-02, avg batch time: 0.4648, average train loss: 4.6111
[09/26 02:07:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1575, average loss: 4.6635
[09/26 02:07:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.50	
[09/26 02:07:15 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:07:21 visual_prompt]: Epoch 77 / 100: avg data time: 6.20e-02, avg batch time: 0.4755, average train loss: 4.6087
[09/26 02:07:23 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 4.6622
[09/26 02:07:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:07:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:07:30 visual_prompt]: Epoch 78 / 100: avg data time: 6.01e-02, avg batch time: 0.4728, average train loss: 4.6012
[09/26 02:07:31 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1581, average loss: 4.6643
[09/26 02:07:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 02:07:31 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:07:38 visual_prompt]: Epoch 79 / 100: avg data time: 6.93e-02, avg batch time: 0.4812, average train loss: 4.5942
[09/26 02:07:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 4.6668
[09/26 02:07:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 02:07:40 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:07:46 visual_prompt]: Epoch 80 / 100: avg data time: 6.65e-02, avg batch time: 0.4800, average train loss: 4.6164
[09/26 02:07:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 4.6681
[09/26 02:07:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 02:07:48 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:07:54 visual_prompt]: Epoch 81 / 100: avg data time: 6.52e-02, avg batch time: 0.4791, average train loss: 4.5960
[09/26 02:07:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 4.6743
[09/26 02:07:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 3.00	
[09/26 02:07:56 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:08:03 visual_prompt]: Epoch 82 / 100: avg data time: 5.75e-02, avg batch time: 0.4718, average train loss: 4.5880
[09/26 02:08:04 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1586, average loss: 4.6677
[09/26 02:08:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 5.50	
[09/26 02:08:04 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:08:11 visual_prompt]: Epoch 83 / 100: avg data time: 6.27e-02, avg batch time: 0.4750, average train loss: 4.6083
[09/26 02:08:12 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 4.6635
[09/26 02:08:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.00	
[09/26 02:08:12 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:08:19 visual_prompt]: Epoch 84 / 100: avg data time: 6.51e-02, avg batch time: 0.4789, average train loss: 4.5822
[09/26 02:08:21 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1583, average loss: 4.6408
[09/26 02:08:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 02:08:21 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:08:27 visual_prompt]: Epoch 85 / 100: avg data time: 6.94e-02, avg batch time: 0.4837, average train loss: 4.5390
[09/26 02:08:29 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1585, average loss: 4.6615
[09/26 02:08:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 3.00	
[09/26 02:08:29 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:08:36 visual_prompt]: Epoch 86 / 100: avg data time: 6.42e-02, avg batch time: 0.4769, average train loss: 4.5876
[09/26 02:08:37 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1582, average loss: 4.6184
[09/26 02:08:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 9.00	
[09/26 02:08:37 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:08:44 visual_prompt]: Epoch 87 / 100: avg data time: 6.58e-02, avg batch time: 0.4788, average train loss: 4.5695
[09/26 02:08:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 4.7147
[09/26 02:08:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:08:46 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:08:52 visual_prompt]: Epoch 88 / 100: avg data time: 6.62e-02, avg batch time: 0.4791, average train loss: 4.5034
[09/26 02:08:54 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1587, average loss: 4.5910
[09/26 02:08:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 10.00	
[09/26 02:08:54 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:09:00 visual_prompt]: Epoch 89 / 100: avg data time: 6.00e-02, avg batch time: 0.4758, average train loss: 4.4476
[09/26 02:09:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 4.5392
[09/26 02:09:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 7.00	
[09/26 02:09:02 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:09:09 visual_prompt]: Epoch 90 / 100: avg data time: 6.29e-02, avg batch time: 0.4770, average train loss: 4.3848
[09/26 02:09:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 4.5797
[09/26 02:09:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/26 02:09:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:09:17 visual_prompt]: Epoch 91 / 100: avg data time: 6.92e-02, avg batch time: 0.4826, average train loss: 4.3326
[09/26 02:09:19 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1587, average loss: 4.5689
[09/26 02:09:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 02:09:19 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:09:25 visual_prompt]: Epoch 92 / 100: avg data time: 6.99e-02, avg batch time: 0.4840, average train loss: 4.3050
[09/26 02:09:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 4.5541
[09/26 02:09:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 9.00	
[09/26 02:09:27 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:09:34 visual_prompt]: Epoch 93 / 100: avg data time: 6.35e-02, avg batch time: 0.4771, average train loss: 4.2327
[09/26 02:09:35 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1585, average loss: 4.5371
[09/26 02:09:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 12.00	
[09/26 02:09:35 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:09:42 visual_prompt]: Epoch 94 / 100: avg data time: 7.15e-02, avg batch time: 0.4847, average train loss: 4.2363
[09/26 02:09:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1586, average loss: 4.5601
[09/26 02:09:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 11.00	
[09/26 02:09:44 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:09:50 visual_prompt]: Epoch 95 / 100: avg data time: 6.76e-02, avg batch time: 0.4824, average train loss: 4.1767
[09/26 02:09:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 4.4878
[09/26 02:09:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 14.50	
[09/26 02:09:52 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:09:59 visual_prompt]: Epoch 96 / 100: avg data time: 6.34e-02, avg batch time: 0.4776, average train loss: 4.1227
[09/26 02:10:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 4.5247
[09/26 02:10:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 13.00	
[09/26 02:10:00 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:10:07 visual_prompt]: Epoch 97 / 100: avg data time: 6.52e-02, avg batch time: 0.4782, average train loss: 4.0956
[09/26 02:10:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1585, average loss: 4.4821
[09/26 02:10:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 14.00	
[09/26 02:10:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:10:15 visual_prompt]: Epoch 98 / 100: avg data time: 7.23e-02, avg batch time: 0.4863, average train loss: 4.0669
[09/26 02:10:17 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1587, average loss: 4.4793
[09/26 02:10:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.00	top5: 14.00	
[09/26 02:10:17 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:10:24 visual_prompt]: Epoch 99 / 100: avg data time: 6.79e-02, avg batch time: 0.4810, average train loss: 4.0511
[09/26 02:10:25 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1579, average loss: 4.4716
[09/26 02:10:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.50	top5: 14.50	
[09/26 02:10:25 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:10:32 visual_prompt]: Epoch 100 / 100: avg data time: 6.63e-02, avg batch time: 0.4796, average train loss: 4.0463
[09/26 02:10:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1584, average loss: 4.4590
[09/26 02:10:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.50	top5: 15.50	
[09/26 02:10:34 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:10:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:10:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:10:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:10:34 visual_prompt]: Training with config:
[09/26 02:10:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:10:34 visual_prompt]: Loading training data...
[09/26 02:10:34 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:10:35 visual_prompt]: Number of images: 800
[09/26 02:10:35 visual_prompt]: Number of classes: 102 / 102
[09/26 02:10:35 visual_prompt]: Loading validation data...
[09/26 02:10:35 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:10:35 visual_prompt]: Number of images: 200
[09/26 02:10:35 visual_prompt]: Number of classes: 91 / 102
[09/26 02:10:35 visual_prompt]: Constructing models...
[09/26 02:10:38 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 02:10:38 visual_prompt]: tuned percent:0.625
[09/26 02:10:38 visual_prompt]: Device used for model: 0
[09/26 02:10:38 visual_prompt]: Setting up Evaluator...
[09/26 02:10:38 visual_prompt]: Setting up Trainer...
[09/26 02:10:38 visual_prompt]: 	Setting up the optimizer...
[09/26 02:10:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:10:44 visual_prompt]: Epoch 1 / 100: avg data time: 6.30e-02, avg batch time: 0.4817, average train loss: 4.6686
[09/26 02:10:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 4.6780
[09/26 02:10:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 02:10:46 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:10:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:10:53 visual_prompt]: Epoch 2 / 100: avg data time: 6.02e-02, avg batch time: 0.4737, average train loss: 4.6409
[09/26 02:10:54 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 4.6280
[09/26 02:10:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 5.50	
[09/26 02:10:54 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:11:01 visual_prompt]: Epoch 3 / 100: avg data time: 6.35e-02, avg batch time: 0.4768, average train loss: 4.4610
[09/26 02:11:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 4.3370
[09/26 02:11:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.00	top5: 15.50	
[09/26 02:11:02 visual_prompt]: Best epoch 3: best metric: 0.040
[09/26 02:11:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:11:09 visual_prompt]: Epoch 4 / 100: avg data time: 6.13e-02, avg batch time: 0.4743, average train loss: 4.1538
[09/26 02:11:11 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 3.8835
[09/26 02:11:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.00	top5: 29.50	
[09/26 02:11:11 visual_prompt]: Best epoch 4: best metric: 0.110
[09/26 02:11:11 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:11:17 visual_prompt]: Epoch 5 / 100: avg data time: 6.73e-02, avg batch time: 0.4806, average train loss: 3.2003
[09/26 02:11:19 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 2.9677
[09/26 02:11:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 28.50	top5: 57.50	
[09/26 02:11:19 visual_prompt]: Best epoch 5: best metric: 0.285
[09/26 02:11:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:11:26 visual_prompt]: Epoch 6 / 100: avg data time: 6.91e-02, avg batch time: 0.4820, average train loss: 1.8166
[09/26 02:11:27 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1585, average loss: 1.3708
[09/26 02:11:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.50	top5: 87.50	
[09/26 02:11:27 visual_prompt]: Best epoch 6: best metric: 0.665
[09/26 02:11:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:11:34 visual_prompt]: Epoch 7 / 100: avg data time: 7.16e-02, avg batch time: 0.4856, average train loss: 0.6579
[09/26 02:11:36 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1583, average loss: 0.7958
[09/26 02:11:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 94.50	
[09/26 02:11:36 visual_prompt]: Best epoch 7: best metric: 0.800
[09/26 02:11:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:11:42 visual_prompt]: Epoch 8 / 100: avg data time: 6.84e-02, avg batch time: 0.4810, average train loss: 0.2265
[09/26 02:11:44 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1589, average loss: 0.6365
[09/26 02:11:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.00	
[09/26 02:11:44 visual_prompt]: Best epoch 8: best metric: 0.855
[09/26 02:11:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:11:51 visual_prompt]: Epoch 9 / 100: avg data time: 6.55e-02, avg batch time: 0.4793, average train loss: 0.1400
[09/26 02:11:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1587, average loss: 0.5528
[09/26 02:11:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.00	
[09/26 02:11:52 visual_prompt]: Best epoch 9: best metric: 0.885
[09/26 02:11:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:11:59 visual_prompt]: Epoch 10 / 100: avg data time: 6.47e-02, avg batch time: 0.4778, average train loss: 0.1377
[09/26 02:12:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1584, average loss: 0.4886
[09/26 02:12:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 02:12:01 visual_prompt]: Best epoch 10: best metric: 0.905
[09/26 02:12:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:12:07 visual_prompt]: Epoch 11 / 100: avg data time: 7.24e-02, avg batch time: 0.4863, average train loss: 0.0860
[09/26 02:12:09 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1585, average loss: 0.4909
[09/26 02:12:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 02:12:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:12:16 visual_prompt]: Epoch 12 / 100: avg data time: 6.42e-02, avg batch time: 0.4772, average train loss: 0.0636
[09/26 02:12:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 0.5029
[09/26 02:12:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 02:12:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:12:24 visual_prompt]: Epoch 13 / 100: avg data time: 6.80e-02, avg batch time: 0.4823, average train loss: 0.0704
[09/26 02:12:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.5771
[09/26 02:12:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.50	
[09/26 02:12:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:12:32 visual_prompt]: Epoch 14 / 100: avg data time: 5.99e-02, avg batch time: 0.4735, average train loss: 0.1410
[09/26 02:12:34 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1586, average loss: 0.5426
[09/26 02:12:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 02:12:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:12:41 visual_prompt]: Epoch 15 / 100: avg data time: 7.15e-02, avg batch time: 0.4858, average train loss: 0.1320
[09/26 02:12:42 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1584, average loss: 0.4679
[09/26 02:12:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:12:42 visual_prompt]: Best epoch 15: best metric: 0.920
[09/26 02:12:42 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:12:49 visual_prompt]: Epoch 16 / 100: avg data time: 6.66e-02, avg batch time: 0.4800, average train loss: 0.0948
[09/26 02:12:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.5287
[09/26 02:12:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 95.50	
[09/26 02:12:51 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:12:57 visual_prompt]: Epoch 17 / 100: avg data time: 6.34e-02, avg batch time: 0.4784, average train loss: 0.0807
[09/26 02:12:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.5604
[09/26 02:12:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.00	
[09/26 02:12:59 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:13:06 visual_prompt]: Epoch 18 / 100: avg data time: 6.55e-02, avg batch time: 0.4792, average train loss: 0.0979
[09/26 02:13:07 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1583, average loss: 0.4596
[09/26 02:13:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 02:13:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:13:14 visual_prompt]: Epoch 19 / 100: avg data time: 5.38e-02, avg batch time: 0.4684, average train loss: 0.0820
[09/26 02:13:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 0.4331
[09/26 02:13:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:13:15 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:13:22 visual_prompt]: Epoch 20 / 100: avg data time: 5.77e-02, avg batch time: 0.4716, average train loss: 0.0699
[09/26 02:13:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1587, average loss: 0.4487
[09/26 02:13:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.00	
[09/26 02:13:24 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:13:30 visual_prompt]: Epoch 21 / 100: avg data time: 6.51e-02, avg batch time: 0.4779, average train loss: 0.0602
[09/26 02:13:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.4902
[09/26 02:13:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:13:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:13:39 visual_prompt]: Epoch 22 / 100: avg data time: 6.94e-02, avg batch time: 0.4835, average train loss: 0.0623
[09/26 02:13:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 0.5113
[09/26 02:13:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.50	
[09/26 02:13:40 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:13:47 visual_prompt]: Epoch 23 / 100: avg data time: 6.00e-02, avg batch time: 0.4753, average train loss: 0.0876
[09/26 02:13:49 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1587, average loss: 0.5448
[09/26 02:13:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 02:13:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:13:55 visual_prompt]: Epoch 24 / 100: avg data time: 7.03e-02, avg batch time: 0.4842, average train loss: 0.1284
[09/26 02:13:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 0.4487
[09/26 02:13:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 02:13:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:14:04 visual_prompt]: Epoch 25 / 100: avg data time: 6.77e-02, avg batch time: 0.4812, average train loss: 0.0881
[09/26 02:14:05 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1580, average loss: 0.4477
[09/26 02:14:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:14:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:14:12 visual_prompt]: Epoch 26 / 100: avg data time: 6.55e-02, avg batch time: 0.4800, average train loss: 0.0734
[09/26 02:14:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.3961
[09/26 02:14:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 02:14:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:14:20 visual_prompt]: Epoch 27 / 100: avg data time: 6.16e-02, avg batch time: 0.4752, average train loss: 0.0668
[09/26 02:14:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 0.4021
[09/26 02:14:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.00	
[09/26 02:14:22 visual_prompt]: Best epoch 27: best metric: 0.930
[09/26 02:14:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:14:28 visual_prompt]: Epoch 28 / 100: avg data time: 6.61e-02, avg batch time: 0.4803, average train loss: 0.0478
[09/26 02:14:30 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.4046
[09/26 02:14:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:14:30 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:14:37 visual_prompt]: Epoch 29 / 100: avg data time: 6.59e-02, avg batch time: 0.4801, average train loss: 0.0576
[09/26 02:14:38 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1583, average loss: 0.3863
[09/26 02:14:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 02:14:38 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:14:45 visual_prompt]: Epoch 30 / 100: avg data time: 6.78e-02, avg batch time: 0.4827, average train loss: 0.0651
[09/26 02:14:47 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.3820
[09/26 02:14:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 02:14:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:14:53 visual_prompt]: Epoch 31 / 100: avg data time: 6.84e-02, avg batch time: 0.4814, average train loss: 0.0701
[09/26 02:14:55 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1585, average loss: 0.3837
[09/26 02:14:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.50	
[09/26 02:14:55 visual_prompt]: Best epoch 31: best metric: 0.940
[09/26 02:14:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:15:02 visual_prompt]: Epoch 32 / 100: avg data time: 6.46e-02, avg batch time: 0.4789, average train loss: 0.0746
[09/26 02:15:03 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1584, average loss: 0.5547
[09/26 02:15:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 95.50	
[09/26 02:15:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:15:10 visual_prompt]: Epoch 33 / 100: avg data time: 6.25e-02, avg batch time: 0.4766, average train loss: 0.0777
[09/26 02:15:12 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 0.3875
[09/26 02:15:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 02:15:12 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:15:18 visual_prompt]: Epoch 34 / 100: avg data time: 6.03e-02, avg batch time: 0.4750, average train loss: 0.0608
[09/26 02:15:20 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1588, average loss: 0.4064
[09/26 02:15:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 02:15:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:15:26 visual_prompt]: Epoch 35 / 100: avg data time: 5.72e-02, avg batch time: 0.4722, average train loss: 0.0706
[09/26 02:15:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 0.3940
[09/26 02:15:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 02:15:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:15:35 visual_prompt]: Epoch 36 / 100: avg data time: 7.13e-02, avg batch time: 0.4843, average train loss: 0.0587
[09/26 02:15:37 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 0.3933
[09/26 02:15:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 97.50	
[09/26 02:15:37 visual_prompt]: Best epoch 36: best metric: 0.950
[09/26 02:15:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:15:43 visual_prompt]: Epoch 37 / 100: avg data time: 6.92e-02, avg batch time: 0.4830, average train loss: 0.0613
[09/26 02:15:45 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 0.4067
[09/26 02:15:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 02:15:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:15:51 visual_prompt]: Epoch 38 / 100: avg data time: 6.43e-02, avg batch time: 0.4774, average train loss: 0.0501
[09/26 02:15:53 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1586, average loss: 0.3829
[09/26 02:15:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 02:15:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:16:00 visual_prompt]: Epoch 39 / 100: avg data time: 6.57e-02, avg batch time: 0.4801, average train loss: 0.0386
[09/26 02:16:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 0.3382
[09/26 02:16:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 02:16:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:16:08 visual_prompt]: Epoch 40 / 100: avg data time: 6.23e-02, avg batch time: 0.4755, average train loss: 0.0324
[09/26 02:16:10 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1586, average loss: 0.3464
[09/26 02:16:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:16:10 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:16:16 visual_prompt]: Epoch 41 / 100: avg data time: 6.50e-02, avg batch time: 0.4780, average train loss: 0.0304
[09/26 02:16:18 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1585, average loss: 0.2991
[09/26 02:16:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 02:16:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:16:25 visual_prompt]: Epoch 42 / 100: avg data time: 6.54e-02, avg batch time: 0.4795, average train loss: 0.0313
[09/26 02:16:26 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1582, average loss: 0.3302
[09/26 02:16:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 02:16:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:16:33 visual_prompt]: Epoch 43 / 100: avg data time: 6.60e-02, avg batch time: 0.4786, average train loss: 0.0319
[09/26 02:16:35 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1587, average loss: 0.3185
[09/26 02:16:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:16:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:16:41 visual_prompt]: Epoch 44 / 100: avg data time: 6.53e-02, avg batch time: 0.4785, average train loss: 0.0324
[09/26 02:16:43 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.3307
[09/26 02:16:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:16:43 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:16:50 visual_prompt]: Epoch 45 / 100: avg data time: 6.72e-02, avg batch time: 0.4810, average train loss: 0.0333
[09/26 02:16:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1580, average loss: 0.3234
[09/26 02:16:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 02:16:51 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:16:58 visual_prompt]: Epoch 46 / 100: avg data time: 6.48e-02, avg batch time: 0.4782, average train loss: 0.0358
[09/26 02:17:00 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1582, average loss: 0.4109
[09/26 02:17:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.50	
[09/26 02:17:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:17:06 visual_prompt]: Epoch 47 / 100: avg data time: 5.49e-02, avg batch time: 0.4722, average train loss: 0.9390
[09/26 02:17:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1585, average loss: 3.5480
[09/26 02:17:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 40.50	top5: 66.00	
[09/26 02:17:08 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:17:14 visual_prompt]: Epoch 48 / 100: avg data time: 6.28e-02, avg batch time: 0.4760, average train loss: 2.4113
[09/26 02:17:16 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1583, average loss: 1.1108
[09/26 02:17:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 94.00	
[09/26 02:17:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:17:23 visual_prompt]: Epoch 49 / 100: avg data time: 6.36e-02, avg batch time: 0.4770, average train loss: 0.5265
[09/26 02:17:24 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1583, average loss: 0.5691
[09/26 02:17:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 98.50	
[09/26 02:17:24 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:17:31 visual_prompt]: Epoch 50 / 100: avg data time: 6.29e-02, avg batch time: 0.4758, average train loss: 0.2269
[09/26 02:17:33 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1584, average loss: 0.3580
[09/26 02:17:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 02:17:33 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:17:39 visual_prompt]: Epoch 51 / 100: avg data time: 6.64e-02, avg batch time: 0.4807, average train loss: 0.0916
[09/26 02:17:41 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1583, average loss: 0.3144
[09/26 02:17:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 02:17:41 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:17:48 visual_prompt]: Epoch 52 / 100: avg data time: 6.74e-02, avg batch time: 0.4807, average train loss: 0.0549
[09/26 02:17:49 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 0.3100
[09/26 02:17:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:17:49 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:17:56 visual_prompt]: Epoch 53 / 100: avg data time: 5.06e-02, avg batch time: 0.4644, average train loss: 0.0449
[09/26 02:17:57 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1581, average loss: 0.3165
[09/26 02:17:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 02:17:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:18:04 visual_prompt]: Epoch 54 / 100: avg data time: 6.71e-02, avg batch time: 0.4806, average train loss: 0.0403
[09/26 02:18:06 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1587, average loss: 0.3173
[09/26 02:18:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.00	
[09/26 02:18:06 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:18:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.89e-02, avg batch time: 0.4819, average train loss: 0.0384
[09/26 02:18:14 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1578, average loss: 0.3218
[09/26 02:18:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 02:18:14 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:18:21 visual_prompt]: Epoch 56 / 100: avg data time: 7.36e-02, avg batch time: 0.4872, average train loss: 0.0405
[09/26 02:18:23 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1586, average loss: 0.3339
[09/26 02:18:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 98.50	
[09/26 02:18:23 visual_prompt]: Best epoch 56: best metric: 0.960
[09/26 02:18:23 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:18:29 visual_prompt]: Epoch 57 / 100: avg data time: 5.83e-02, avg batch time: 0.4744, average train loss: 0.0415
[09/26 02:18:31 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1585, average loss: 0.3219
[09/26 02:18:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.50	top5: 98.50	
[09/26 02:18:31 visual_prompt]: Best epoch 57: best metric: 0.965
[09/26 02:18:31 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:18:37 visual_prompt]: Epoch 58 / 100: avg data time: 6.41e-02, avg batch time: 0.4789, average train loss: 0.0419
[09/26 02:18:39 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1585, average loss: 0.3212
[09/26 02:18:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 99.00	
[09/26 02:18:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:18:46 visual_prompt]: Epoch 59 / 100: avg data time: 5.18e-02, avg batch time: 0.4672, average train loss: 0.0421
[09/26 02:18:47 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1581, average loss: 0.3280
[09/26 02:18:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 99.00	
[09/26 02:18:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:18:54 visual_prompt]: Epoch 60 / 100: avg data time: 7.07e-02, avg batch time: 0.4842, average train loss: 0.0397
[09/26 02:18:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 0.3256
[09/26 02:18:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 02:18:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:19:02 visual_prompt]: Epoch 61 / 100: avg data time: 6.61e-02, avg batch time: 0.4794, average train loss: 0.0439
[09/26 02:19:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 0.3338
[09/26 02:19:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 99.00	
[09/26 02:19:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:19:11 visual_prompt]: Epoch 62 / 100: avg data time: 6.83e-02, avg batch time: 0.4820, average train loss: 0.0417
[09/26 02:19:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.3257
[09/26 02:19:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.50	top5: 98.50	
[09/26 02:19:12 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:19:19 visual_prompt]: Epoch 63 / 100: avg data time: 6.46e-02, avg batch time: 0.4788, average train loss: 0.0391
[09/26 02:19:21 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1582, average loss: 0.3119
[09/26 02:19:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.50	top5: 99.50	
[09/26 02:19:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:19:27 visual_prompt]: Epoch 64 / 100: avg data time: 6.74e-02, avg batch time: 0.4812, average train loss: 0.0370
[09/26 02:19:29 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1585, average loss: 0.3139
[09/26 02:19:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.50	
[09/26 02:19:29 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:19:35 visual_prompt]: Epoch 65 / 100: avg data time: 6.17e-02, avg batch time: 0.4745, average train loss: 0.0359
[09/26 02:19:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.3027
[09/26 02:19:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 99.50	
[09/26 02:19:37 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:19:44 visual_prompt]: Epoch 66 / 100: avg data time: 6.00e-02, avg batch time: 0.4729, average train loss: 0.0358
[09/26 02:19:45 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 0.3080
[09/26 02:19:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.00	
[09/26 02:19:45 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:19:52 visual_prompt]: Epoch 67 / 100: avg data time: 6.96e-02, avg batch time: 0.4840, average train loss: 0.0441
[09/26 02:19:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1589, average loss: 0.3406
[09/26 02:19:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 02:19:54 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:20:00 visual_prompt]: Epoch 68 / 100: avg data time: 6.41e-02, avg batch time: 0.4772, average train loss: 0.0397
[09/26 02:20:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.3310
[09/26 02:20:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 02:20:02 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:20:09 visual_prompt]: Epoch 69 / 100: avg data time: 6.31e-02, avg batch time: 0.4767, average train loss: 0.0386
[09/26 02:20:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1576, average loss: 0.3153
[09/26 02:20:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 99.00	
[09/26 02:20:10 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:20:17 visual_prompt]: Epoch 70 / 100: avg data time: 6.60e-02, avg batch time: 0.4802, average train loss: 0.0351
[09/26 02:20:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1582, average loss: 0.3099
[09/26 02:20:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 02:20:19 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:20:25 visual_prompt]: Epoch 71 / 100: avg data time: 6.06e-02, avg batch time: 0.4753, average train loss: 0.0332
[09/26 02:20:27 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1587, average loss: 0.3054
[09/26 02:20:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 02:20:27 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:20:33 visual_prompt]: Epoch 72 / 100: avg data time: 6.63e-02, avg batch time: 0.4819, average train loss: 0.0323
[09/26 02:20:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 0.3214
[09/26 02:20:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:20:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:20:42 visual_prompt]: Epoch 73 / 100: avg data time: 6.01e-02, avg batch time: 0.4740, average train loss: 0.0318
[09/26 02:20:43 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1586, average loss: 0.3267
[09/26 02:20:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 02:20:43 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:20:50 visual_prompt]: Epoch 74 / 100: avg data time: 6.93e-02, avg batch time: 0.4823, average train loss: 0.0317
[09/26 02:20:52 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1582, average loss: 0.3191
[09/26 02:20:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 02:20:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:20:58 visual_prompt]: Epoch 75 / 100: avg data time: 5.50e-02, avg batch time: 0.4700, average train loss: 0.0315
[09/26 02:21:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1586, average loss: 0.3161
[09/26 02:21:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:21:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:21:07 visual_prompt]: Epoch 76 / 100: avg data time: 6.55e-02, avg batch time: 0.4788, average train loss: 0.0312
[09/26 02:21:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1587, average loss: 0.3241
[09/26 02:21:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 02:21:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:21:15 visual_prompt]: Epoch 77 / 100: avg data time: 5.93e-02, avg batch time: 0.4756, average train loss: 0.0310
[09/26 02:21:17 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1587, average loss: 0.3241
[09/26 02:21:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 02:21:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:21:23 visual_prompt]: Epoch 78 / 100: avg data time: 5.76e-02, avg batch time: 0.4708, average train loss: 0.0311
[09/26 02:21:25 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1585, average loss: 0.3299
[09/26 02:21:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:21:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:21:31 visual_prompt]: Epoch 79 / 100: avg data time: 6.49e-02, avg batch time: 0.4802, average train loss: 0.0308
[09/26 02:21:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1586, average loss: 0.3182
[09/26 02:21:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:21:33 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:21:40 visual_prompt]: Epoch 80 / 100: avg data time: 7.00e-02, avg batch time: 0.4842, average train loss: 0.0310
[09/26 02:21:41 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 0.3146
[09/26 02:21:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:21:41 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:21:48 visual_prompt]: Epoch 81 / 100: avg data time: 7.11e-02, avg batch time: 0.4862, average train loss: 0.0305
[09/26 02:21:50 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1581, average loss: 0.3225
[09/26 02:21:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 02:21:50 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:21:56 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.4730, average train loss: 0.0306
[09/26 02:21:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.3150
[09/26 02:21:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:21:58 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:22:05 visual_prompt]: Epoch 83 / 100: avg data time: 6.76e-02, avg batch time: 0.4815, average train loss: 0.0302
[09/26 02:22:06 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1587, average loss: 0.3120
[09/26 02:22:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 02:22:06 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:22:13 visual_prompt]: Epoch 84 / 100: avg data time: 6.73e-02, avg batch time: 0.4833, average train loss: 0.0302
[09/26 02:22:15 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1580, average loss: 0.3185
[09/26 02:22:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:22:15 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:22:21 visual_prompt]: Epoch 85 / 100: avg data time: 5.91e-02, avg batch time: 0.4742, average train loss: 0.0300
[09/26 02:22:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1585, average loss: 0.3236
[09/26 02:22:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:22:23 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:22:29 visual_prompt]: Epoch 86 / 100: avg data time: 6.80e-02, avg batch time: 0.4812, average train loss: 0.0301
[09/26 02:22:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1586, average loss: 0.3197
[09/26 02:22:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 02:22:31 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:22:38 visual_prompt]: Epoch 87 / 100: avg data time: 6.29e-02, avg batch time: 0.4773, average train loss: 0.0301
[09/26 02:22:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1589, average loss: 0.3121
[09/26 02:22:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 02:22:39 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:22:46 visual_prompt]: Epoch 88 / 100: avg data time: 5.31e-02, avg batch time: 0.4684, average train loss: 0.0298
[09/26 02:22:47 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1581, average loss: 0.3131
[09/26 02:22:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 02:22:47 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:22:54 visual_prompt]: Epoch 89 / 100: avg data time: 6.38e-02, avg batch time: 0.4786, average train loss: 0.0299
[09/26 02:22:56 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1582, average loss: 0.3181
[09/26 02:22:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:22:56 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:23:02 visual_prompt]: Epoch 90 / 100: avg data time: 6.10e-02, avg batch time: 0.4741, average train loss: 0.0296
[09/26 02:23:04 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1584, average loss: 0.3238
[09/26 02:23:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 02:23:04 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:23:11 visual_prompt]: Epoch 91 / 100: avg data time: 6.91e-02, avg batch time: 0.4825, average train loss: 0.0297
[09/26 02:23:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.3175
[09/26 02:23:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:23:12 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:23:19 visual_prompt]: Epoch 92 / 100: avg data time: 6.41e-02, avg batch time: 0.4775, average train loss: 0.0295
[09/26 02:23:21 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.3191
[09/26 02:23:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:23:21 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:23:27 visual_prompt]: Epoch 93 / 100: avg data time: 6.41e-02, avg batch time: 0.4780, average train loss: 0.0296
[09/26 02:23:29 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1582, average loss: 0.3187
[09/26 02:23:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:23:29 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:23:36 visual_prompt]: Epoch 94 / 100: avg data time: 7.15e-02, avg batch time: 0.4851, average train loss: 0.0296
[09/26 02:23:37 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1586, average loss: 0.3159
[09/26 02:23:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:23:37 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:23:44 visual_prompt]: Epoch 95 / 100: avg data time: 5.72e-02, avg batch time: 0.4717, average train loss: 0.0294
[09/26 02:23:46 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.3190
[09/26 02:23:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:23:46 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:23:52 visual_prompt]: Epoch 96 / 100: avg data time: 6.55e-02, avg batch time: 0.4785, average train loss: 0.0295
[09/26 02:23:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.3190
[09/26 02:23:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:23:54 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:24:00 visual_prompt]: Epoch 97 / 100: avg data time: 6.27e-02, avg batch time: 0.4773, average train loss: 0.0295
[09/26 02:24:02 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1585, average loss: 0.3199
[09/26 02:24:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:24:02 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:24:09 visual_prompt]: Epoch 98 / 100: avg data time: 6.49e-02, avg batch time: 0.4790, average train loss: 0.0294
[09/26 02:24:11 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1582, average loss: 0.3201
[09/26 02:24:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:24:11 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:24:17 visual_prompt]: Epoch 99 / 100: avg data time: 5.99e-02, avg batch time: 0.4742, average train loss: 0.0295
[09/26 02:24:19 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1585, average loss: 0.3203
[09/26 02:24:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:24:19 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:24:25 visual_prompt]: Epoch 100 / 100: avg data time: 7.08e-02, avg batch time: 0.4841, average train loss: 0.0294
[09/26 02:24:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1587, average loss: 0.3202
[09/26 02:24:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 02:24:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:24:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:24:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:24:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:24:27 visual_prompt]: Training with config:
[09/26 02:24:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:24:27 visual_prompt]: Loading training data...
[09/26 02:24:27 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:24:28 visual_prompt]: Number of images: 800
[09/26 02:24:28 visual_prompt]: Number of classes: 102 / 102
[09/26 02:24:28 visual_prompt]: Loading validation data...
[09/26 02:24:28 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:24:29 visual_prompt]: Number of images: 200
[09/26 02:24:29 visual_prompt]: Number of classes: 91 / 102
[09/26 02:24:29 visual_prompt]: Constructing models...
[09/26 02:24:31 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 02:24:31 visual_prompt]: tuned percent:0.625
[09/26 02:24:31 visual_prompt]: Device used for model: 0
[09/26 02:24:31 visual_prompt]: Setting up Evaluator...
[09/26 02:24:31 visual_prompt]: Setting up Trainer...
[09/26 02:24:31 visual_prompt]: 	Setting up the optimizer...
[09/26 02:24:31 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:24:38 visual_prompt]: Epoch 1 / 100: avg data time: 7.47e-02, avg batch time: 0.4931, average train loss: 4.6725
[09/26 02:24:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 02:24:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 02:24:40 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:24:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:24:46 visual_prompt]: Epoch 2 / 100: avg data time: 7.12e-02, avg batch time: 0.4832, average train loss: 4.6193
[09/26 02:24:48 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1581, average loss: 4.5938
[09/26 02:24:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 10.50	
[09/26 02:24:48 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 02:24:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:24:55 visual_prompt]: Epoch 3 / 100: avg data time: 6.63e-02, avg batch time: 0.4790, average train loss: 4.4190
[09/26 02:24:56 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1587, average loss: 4.3244
[09/26 02:24:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 19.50	
[09/26 02:24:56 visual_prompt]: Best epoch 3: best metric: 0.065
[09/26 02:24:56 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:25:03 visual_prompt]: Epoch 4 / 100: avg data time: 5.94e-02, avg batch time: 0.4737, average train loss: 3.8895
[09/26 02:25:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1577, average loss: 3.5137
[09/26 02:25:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 20.50	top5: 39.00	
[09/26 02:25:05 visual_prompt]: Best epoch 4: best metric: 0.205
[09/26 02:25:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:25:11 visual_prompt]: Epoch 5 / 100: avg data time: 5.59e-02, avg batch time: 0.4694, average train loss: 2.7547
[09/26 02:25:13 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1583, average loss: 2.2004
[09/26 02:25:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 51.00	top5: 76.00	
[09/26 02:25:13 visual_prompt]: Best epoch 5: best metric: 0.510
[09/26 02:25:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:25:19 visual_prompt]: Epoch 6 / 100: avg data time: 6.43e-02, avg batch time: 0.4769, average train loss: 1.1495
[09/26 02:25:21 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.9198
[09/26 02:25:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.00	top5: 93.00	
[09/26 02:25:21 visual_prompt]: Best epoch 6: best metric: 0.780
[09/26 02:25:21 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:25:28 visual_prompt]: Epoch 7 / 100: avg data time: 6.77e-02, avg batch time: 0.4808, average train loss: 0.3596
[09/26 02:25:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 0.5839
[09/26 02:25:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 98.00	
[09/26 02:25:29 visual_prompt]: Best epoch 7: best metric: 0.865
[09/26 02:25:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:25:36 visual_prompt]: Epoch 8 / 100: avg data time: 6.10e-02, avg batch time: 0.4733, average train loss: 0.1141
[09/26 02:25:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 0.5857
[09/26 02:25:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 02:25:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:25:44 visual_prompt]: Epoch 9 / 100: avg data time: 7.01e-02, avg batch time: 0.4823, average train loss: 0.0565
[09/26 02:25:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1586, average loss: 0.4785
[09/26 02:25:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/26 02:25:46 visual_prompt]: Best epoch 9: best metric: 0.890
[09/26 02:25:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:25:53 visual_prompt]: Epoch 10 / 100: avg data time: 7.04e-02, avg batch time: 0.4829, average train loss: 0.0208
[09/26 02:25:54 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 0.4564
[09/26 02:25:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 02:25:54 visual_prompt]: Best epoch 10: best metric: 0.900
[09/26 02:25:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:26:01 visual_prompt]: Epoch 11 / 100: avg data time: 5.67e-02, avg batch time: 0.4732, average train loss: 0.0189
[09/26 02:26:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 0.4399
[09/26 02:26:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.50	
[09/26 02:26:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:26:09 visual_prompt]: Epoch 12 / 100: avg data time: 7.06e-02, avg batch time: 0.4835, average train loss: 0.0126
[09/26 02:26:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1586, average loss: 0.4271
[09/26 02:26:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 02:26:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:26:18 visual_prompt]: Epoch 13 / 100: avg data time: 6.96e-02, avg batch time: 0.4836, average train loss: 0.0102
[09/26 02:26:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1587, average loss: 0.4134
[09/26 02:26:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 02:26:19 visual_prompt]: Best epoch 13: best metric: 0.910
[09/26 02:26:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:26:26 visual_prompt]: Epoch 14 / 100: avg data time: 6.50e-02, avg batch time: 0.4787, average train loss: 0.0089
[09/26 02:26:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1582, average loss: 0.3986
[09/26 02:26:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:26:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:26:34 visual_prompt]: Epoch 15 / 100: avg data time: 6.12e-02, avg batch time: 0.4772, average train loss: 0.0074
[09/26 02:26:36 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 0.3906
[09/26 02:26:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:26:36 visual_prompt]: Best epoch 15: best metric: 0.915
[09/26 02:26:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:26:42 visual_prompt]: Epoch 16 / 100: avg data time: 6.19e-02, avg batch time: 0.4755, average train loss: 0.0061
[09/26 02:26:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1585, average loss: 0.3948
[09/26 02:26:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:26:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:26:51 visual_prompt]: Epoch 17 / 100: avg data time: 6.60e-02, avg batch time: 0.4814, average train loss: 0.0057
[09/26 02:26:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 0.3886
[09/26 02:26:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:26:53 visual_prompt]: Best epoch 17: best metric: 0.920
[09/26 02:26:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:26:59 visual_prompt]: Epoch 18 / 100: avg data time: 6.81e-02, avg batch time: 0.4816, average train loss: 0.0055
[09/26 02:27:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1583, average loss: 0.3818
[09/26 02:27:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 02:27:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:27:08 visual_prompt]: Epoch 19 / 100: avg data time: 6.15e-02, avg batch time: 0.4768, average train loss: 0.0054
[09/26 02:27:09 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1587, average loss: 0.3827
[09/26 02:27:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 02:27:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:27:16 visual_prompt]: Epoch 20 / 100: avg data time: 5.71e-02, avg batch time: 0.4715, average train loss: 0.0052
[09/26 02:27:17 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1585, average loss: 0.3858
[09/26 02:27:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:27:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:27:24 visual_prompt]: Epoch 21 / 100: avg data time: 6.69e-02, avg batch time: 0.4805, average train loss: 0.0053
[09/26 02:27:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1586, average loss: 0.3905
[09/26 02:27:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 02:27:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:27:33 visual_prompt]: Epoch 22 / 100: avg data time: 7.34e-02, avg batch time: 0.4870, average train loss: 0.0051
[09/26 02:27:34 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1589, average loss: 0.3917
[09/26 02:27:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 02:27:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:27:41 visual_prompt]: Epoch 23 / 100: avg data time: 6.83e-02, avg batch time: 0.4822, average train loss: 0.0050
[09/26 02:27:43 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1588, average loss: 0.3930
[09/26 02:27:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:27:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:27:49 visual_prompt]: Epoch 24 / 100: avg data time: 5.79e-02, avg batch time: 0.4737, average train loss: 0.0050
[09/26 02:27:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.3909
[09/26 02:27:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:27:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:27:57 visual_prompt]: Epoch 25 / 100: avg data time: 6.72e-02, avg batch time: 0.4809, average train loss: 0.0049
[09/26 02:27:59 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1587, average loss: 0.3797
[09/26 02:27:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:27:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:28:06 visual_prompt]: Epoch 26 / 100: avg data time: 6.18e-02, avg batch time: 0.4767, average train loss: 0.0049
[09/26 02:28:07 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1585, average loss: 0.3758
[09/26 02:28:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 02:28:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:28:14 visual_prompt]: Epoch 27 / 100: avg data time: 6.57e-02, avg batch time: 0.4795, average train loss: 0.0050
[09/26 02:28:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1585, average loss: 0.3737
[09/26 02:28:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 02:28:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:28:22 visual_prompt]: Epoch 28 / 100: avg data time: 6.82e-02, avg batch time: 0.4838, average train loss: 0.0049
[09/26 02:28:24 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 0.3751
[09/26 02:28:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 02:28:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:28:31 visual_prompt]: Epoch 29 / 100: avg data time: 6.56e-02, avg batch time: 0.4798, average train loss: 0.0049
[09/26 02:28:32 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1587, average loss: 0.3767
[09/26 02:28:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:28:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:28:39 visual_prompt]: Epoch 30 / 100: avg data time: 5.82e-02, avg batch time: 0.4731, average train loss: 0.0048
[09/26 02:28:41 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.3724
[09/26 02:28:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 02:28:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:28:47 visual_prompt]: Epoch 31 / 100: avg data time: 6.30e-02, avg batch time: 0.4781, average train loss: 0.0048
[09/26 02:28:49 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1585, average loss: 0.3775
[09/26 02:28:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:28:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:28:55 visual_prompt]: Epoch 32 / 100: avg data time: 6.22e-02, avg batch time: 0.4773, average train loss: 0.0049
[09/26 02:28:57 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1585, average loss: 0.3805
[09/26 02:28:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:28:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:29:04 visual_prompt]: Epoch 33 / 100: avg data time: 6.08e-02, avg batch time: 0.4751, average train loss: 0.0048
[09/26 02:29:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1589, average loss: 0.3694
[09/26 02:29:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:29:05 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:29:12 visual_prompt]: Epoch 34 / 100: avg data time: 5.88e-02, avg batch time: 0.4735, average train loss: 0.0047
[09/26 02:29:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 0.3701
[09/26 02:29:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:29:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:29:20 visual_prompt]: Epoch 35 / 100: avg data time: 6.69e-02, avg batch time: 0.4814, average train loss: 0.0048
[09/26 02:29:22 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1586, average loss: 0.3683
[09/26 02:29:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:29:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:29:29 visual_prompt]: Epoch 36 / 100: avg data time: 7.28e-02, avg batch time: 0.4861, average train loss: 0.0049
[09/26 02:29:30 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1588, average loss: 0.3728
[09/26 02:29:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 02:29:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:29:37 visual_prompt]: Epoch 37 / 100: avg data time: 6.62e-02, avg batch time: 0.4805, average train loss: 0.0048
[09/26 02:29:39 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1582, average loss: 0.3653
[09/26 02:29:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:29:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:29:45 visual_prompt]: Epoch 38 / 100: avg data time: 5.45e-02, avg batch time: 0.4689, average train loss: 0.0047
[09/26 02:29:47 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1585, average loss: 0.3701
[09/26 02:29:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:29:47 visual_prompt]: Best epoch 38: best metric: 0.925
[09/26 02:29:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:29:53 visual_prompt]: Epoch 39 / 100: avg data time: 6.69e-02, avg batch time: 0.4803, average train loss: 0.0048
[09/26 02:29:55 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1580, average loss: 0.3694
[09/26 02:29:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:29:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:30:02 visual_prompt]: Epoch 40 / 100: avg data time: 6.45e-02, avg batch time: 0.4779, average train loss: 0.0047
[09/26 02:30:03 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1578, average loss: 0.3624
[09/26 02:30:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:30:03 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:30:10 visual_prompt]: Epoch 41 / 100: avg data time: 6.11e-02, avg batch time: 0.4740, average train loss: 0.0046
[09/26 02:30:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1588, average loss: 0.3602
[09/26 02:30:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:30:12 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:30:18 visual_prompt]: Epoch 42 / 100: avg data time: 5.17e-02, avg batch time: 0.4665, average train loss: 0.0047
[09/26 02:30:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1582, average loss: 0.3613
[09/26 02:30:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:30:20 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:30:26 visual_prompt]: Epoch 43 / 100: avg data time: 6.53e-02, avg batch time: 0.4790, average train loss: 0.0046
[09/26 02:30:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 0.3592
[09/26 02:30:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:30:28 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:30:34 visual_prompt]: Epoch 44 / 100: avg data time: 5.12e-02, avg batch time: 0.4670, average train loss: 0.0046
[09/26 02:30:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1587, average loss: 0.3589
[09/26 02:30:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:30:36 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:30:43 visual_prompt]: Epoch 45 / 100: avg data time: 7.13e-02, avg batch time: 0.4840, average train loss: 0.0046
[09/26 02:30:45 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.3609
[09/26 02:30:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 02:30:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:30:51 visual_prompt]: Epoch 46 / 100: avg data time: 6.54e-02, avg batch time: 0.4784, average train loss: 0.0046
[09/26 02:30:53 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 0.3573
[09/26 02:30:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:30:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:31:00 visual_prompt]: Epoch 47 / 100: avg data time: 6.43e-02, avg batch time: 0.4793, average train loss: 0.0046
[09/26 02:31:01 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 0.3638
[09/26 02:31:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:31:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:31:08 visual_prompt]: Epoch 48 / 100: avg data time: 6.21e-02, avg batch time: 0.4759, average train loss: 0.0046
[09/26 02:31:09 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 0.3592
[09/26 02:31:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:31:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:31:16 visual_prompt]: Epoch 49 / 100: avg data time: 6.66e-02, avg batch time: 0.4791, average train loss: 0.0046
[09/26 02:31:18 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1586, average loss: 0.3589
[09/26 02:31:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:31:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:31:24 visual_prompt]: Epoch 50 / 100: avg data time: 6.62e-02, avg batch time: 0.4787, average train loss: 0.0046
[09/26 02:31:26 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1586, average loss: 0.3499
[09/26 02:31:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:31:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:31:33 visual_prompt]: Epoch 51 / 100: avg data time: 5.87e-02, avg batch time: 0.4711, average train loss: 0.0045
[09/26 02:31:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.3563
[09/26 02:31:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:31:34 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:31:41 visual_prompt]: Epoch 52 / 100: avg data time: 6.91e-02, avg batch time: 0.4818, average train loss: 0.0045
[09/26 02:31:43 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1585, average loss: 0.3626
[09/26 02:31:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 02:31:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:31:49 visual_prompt]: Epoch 53 / 100: avg data time: 5.63e-02, avg batch time: 0.4696, average train loss: 0.0045
[09/26 02:31:51 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 0.3606
[09/26 02:31:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 02:31:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:31:57 visual_prompt]: Epoch 54 / 100: avg data time: 6.45e-02, avg batch time: 0.4772, average train loss: 0.0045
[09/26 02:31:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 0.3611
[09/26 02:31:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:31:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:32:06 visual_prompt]: Epoch 55 / 100: avg data time: 5.86e-02, avg batch time: 0.4728, average train loss: 0.0045
[09/26 02:32:07 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1583, average loss: 0.3655
[09/26 02:32:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:32:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:32:14 visual_prompt]: Epoch 56 / 100: avg data time: 6.06e-02, avg batch time: 0.4752, average train loss: 0.0046
[09/26 02:32:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 0.3576
[09/26 02:32:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:32:16 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:32:22 visual_prompt]: Epoch 57 / 100: avg data time: 6.56e-02, avg batch time: 0.4788, average train loss: 0.0045
[09/26 02:32:24 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1584, average loss: 0.3546
[09/26 02:32:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:32:24 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:32:31 visual_prompt]: Epoch 58 / 100: avg data time: 7.16e-02, avg batch time: 0.4836, average train loss: 0.0045
[09/26 02:32:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.3597
[09/26 02:32:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:32:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:32:39 visual_prompt]: Epoch 59 / 100: avg data time: 5.91e-02, avg batch time: 0.4710, average train loss: 0.0046
[09/26 02:32:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.3582
[09/26 02:32:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 96.50	
[09/26 02:32:41 visual_prompt]: Best epoch 59: best metric: 0.930
[09/26 02:32:41 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:32:47 visual_prompt]: Epoch 60 / 100: avg data time: 6.84e-02, avg batch time: 0.4806, average train loss: 0.0045
[09/26 02:32:49 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 0.3512
[09/26 02:32:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:32:49 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:32:56 visual_prompt]: Epoch 61 / 100: avg data time: 7.17e-02, avg batch time: 0.4833, average train loss: 0.0044
[09/26 02:32:57 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1577, average loss: 0.3529
[09/26 02:32:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:32:57 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:33:04 visual_prompt]: Epoch 62 / 100: avg data time: 6.00e-02, avg batch time: 0.4719, average train loss: 0.0044
[09/26 02:33:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 0.3573
[09/26 02:33:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:33:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:33:12 visual_prompt]: Epoch 63 / 100: avg data time: 6.81e-02, avg batch time: 0.4808, average train loss: 0.0043
[09/26 02:33:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1578, average loss: 0.3533
[09/26 02:33:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:33:14 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:33:20 visual_prompt]: Epoch 64 / 100: avg data time: 6.49e-02, avg batch time: 0.4768, average train loss: 0.0044
[09/26 02:33:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1582, average loss: 0.3593
[09/26 02:33:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:33:22 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:33:29 visual_prompt]: Epoch 65 / 100: avg data time: 7.10e-02, avg batch time: 0.4829, average train loss: 0.0043
[09/26 02:33:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1578, average loss: 0.3540
[09/26 02:33:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:33:30 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:33:37 visual_prompt]: Epoch 66 / 100: avg data time: 5.85e-02, avg batch time: 0.4737, average train loss: 0.0044
[09/26 02:33:39 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1584, average loss: 0.3591
[09/26 02:33:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 02:33:39 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:33:45 visual_prompt]: Epoch 67 / 100: avg data time: 6.19e-02, avg batch time: 0.4752, average train loss: 0.0043
[09/26 02:33:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.3591
[09/26 02:33:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:33:47 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:33:54 visual_prompt]: Epoch 68 / 100: avg data time: 6.94e-02, avg batch time: 0.4811, average train loss: 0.0043
[09/26 02:33:55 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1576, average loss: 0.3574
[09/26 02:33:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:33:55 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:34:02 visual_prompt]: Epoch 69 / 100: avg data time: 6.30e-02, avg batch time: 0.4769, average train loss: 0.0044
[09/26 02:34:04 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1579, average loss: 0.3564
[09/26 02:34:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:34:04 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:34:10 visual_prompt]: Epoch 70 / 100: avg data time: 6.91e-02, avg batch time: 0.4818, average train loss: 0.0043
[09/26 02:34:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 0.3565
[09/26 02:34:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 96.50	
[09/26 02:34:12 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:34:19 visual_prompt]: Epoch 71 / 100: avg data time: 6.53e-02, avg batch time: 0.4792, average train loss: 0.0043
[09/26 02:34:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1579, average loss: 0.3557
[09/26 02:34:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:34:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:34:27 visual_prompt]: Epoch 72 / 100: avg data time: 6.17e-02, avg batch time: 0.4767, average train loss: 0.0043
[09/26 02:34:29 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 0.3607
[09/26 02:34:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:34:29 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:34:35 visual_prompt]: Epoch 73 / 100: avg data time: 7.18e-02, avg batch time: 0.4841, average train loss: 0.0043
[09/26 02:34:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 0.3599
[09/26 02:34:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:34:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:34:44 visual_prompt]: Epoch 74 / 100: avg data time: 7.20e-02, avg batch time: 0.4870, average train loss: 0.0044
[09/26 02:34:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 0.3540
[09/26 02:34:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:34:45 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:34:52 visual_prompt]: Epoch 75 / 100: avg data time: 6.35e-02, avg batch time: 0.4760, average train loss: 0.0043
[09/26 02:34:54 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1587, average loss: 0.3603
[09/26 02:34:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:34:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:35:00 visual_prompt]: Epoch 76 / 100: avg data time: 7.05e-02, avg batch time: 0.4836, average train loss: 0.0044
[09/26 02:35:02 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1587, average loss: 0.3596
[09/26 02:35:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:35:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:35:09 visual_prompt]: Epoch 77 / 100: avg data time: 6.20e-02, avg batch time: 0.4758, average train loss: 0.0043
[09/26 02:35:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 0.3605
[09/26 02:35:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:35:10 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:35:17 visual_prompt]: Epoch 78 / 100: avg data time: 5.55e-02, avg batch time: 0.4720, average train loss: 0.0043
[09/26 02:35:18 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1580, average loss: 0.3597
[09/26 02:35:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:35:18 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:35:25 visual_prompt]: Epoch 79 / 100: avg data time: 6.59e-02, avg batch time: 0.4789, average train loss: 0.0042
[09/26 02:35:27 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1588, average loss: 0.3608
[09/26 02:35:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:35:27 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:35:33 visual_prompt]: Epoch 80 / 100: avg data time: 5.48e-02, avg batch time: 0.4692, average train loss: 0.0042
[09/26 02:35:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1587, average loss: 0.3609
[09/26 02:35:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:35:35 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:35:42 visual_prompt]: Epoch 81 / 100: avg data time: 7.08e-02, avg batch time: 0.4861, average train loss: 0.0043
[09/26 02:35:43 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1588, average loss: 0.3607
[09/26 02:35:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:35:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:35:50 visual_prompt]: Epoch 82 / 100: avg data time: 6.68e-02, avg batch time: 0.4799, average train loss: 0.0043
[09/26 02:35:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 0.3589
[09/26 02:35:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:35:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:35:58 visual_prompt]: Epoch 83 / 100: avg data time: 7.00e-02, avg batch time: 0.4830, average train loss: 0.0043
[09/26 02:36:00 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.3604
[09/26 02:36:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 02:36:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:36:07 visual_prompt]: Epoch 84 / 100: avg data time: 7.48e-02, avg batch time: 0.4875, average train loss: 0.0042
[09/26 02:36:08 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.3602
[09/26 02:36:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:36:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:36:15 visual_prompt]: Epoch 85 / 100: avg data time: 6.58e-02, avg batch time: 0.4787, average train loss: 0.0043
[09/26 02:36:17 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1581, average loss: 0.3602
[09/26 02:36:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:36:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:36:23 visual_prompt]: Epoch 86 / 100: avg data time: 6.61e-02, avg batch time: 0.4798, average train loss: 0.0042
[09/26 02:36:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1589, average loss: 0.3616
[09/26 02:36:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:36:25 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:36:32 visual_prompt]: Epoch 87 / 100: avg data time: 6.82e-02, avg batch time: 0.4816, average train loss: 0.0043
[09/26 02:36:33 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1582, average loss: 0.3636
[09/26 02:36:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:36:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:36:40 visual_prompt]: Epoch 88 / 100: avg data time: 6.27e-02, avg batch time: 0.4764, average train loss: 0.0043
[09/26 02:36:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.3635
[09/26 02:36:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:36:42 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:36:48 visual_prompt]: Epoch 89 / 100: avg data time: 7.03e-02, avg batch time: 0.4831, average train loss: 0.0043
[09/26 02:36:50 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.3631
[09/26 02:36:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:36:50 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:36:57 visual_prompt]: Epoch 90 / 100: avg data time: 6.17e-02, avg batch time: 0.4745, average train loss: 0.0043
[09/26 02:36:58 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1583, average loss: 0.3630
[09/26 02:36:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:36:58 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:37:05 visual_prompt]: Epoch 91 / 100: avg data time: 6.78e-02, avg batch time: 0.4829, average train loss: 0.0043
[09/26 02:37:07 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1586, average loss: 0.3627
[09/26 02:37:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:37:07 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:37:13 visual_prompt]: Epoch 92 / 100: avg data time: 5.27e-02, avg batch time: 0.4695, average train loss: 0.0042
[09/26 02:37:15 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1573, average loss: 0.3624
[09/26 02:37:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:37:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:37:22 visual_prompt]: Epoch 93 / 100: avg data time: 7.25e-02, avg batch time: 0.4854, average train loss: 0.0042
[09/26 02:37:23 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1586, average loss: 0.3623
[09/26 02:37:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:37:23 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:37:30 visual_prompt]: Epoch 94 / 100: avg data time: 6.11e-02, avg batch time: 0.4741, average train loss: 0.0043
[09/26 02:37:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1579, average loss: 0.3620
[09/26 02:37:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:37:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:37:38 visual_prompt]: Epoch 95 / 100: avg data time: 7.15e-02, avg batch time: 0.4850, average train loss: 0.0042
[09/26 02:37:40 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 0.3617
[09/26 02:37:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:37:40 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:37:46 visual_prompt]: Epoch 96 / 100: avg data time: 5.56e-02, avg batch time: 0.4699, average train loss: 0.0043
[09/26 02:37:48 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.3617
[09/26 02:37:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 02:37:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:37:55 visual_prompt]: Epoch 97 / 100: avg data time: 5.91e-02, avg batch time: 0.4722, average train loss: 0.0043
[09/26 02:37:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1588, average loss: 0.3617
[09/26 02:37:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:37:56 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:38:03 visual_prompt]: Epoch 98 / 100: avg data time: 5.34e-02, avg batch time: 0.4675, average train loss: 0.0043
[09/26 02:38:04 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1583, average loss: 0.3618
[09/26 02:38:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:38:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:38:11 visual_prompt]: Epoch 99 / 100: avg data time: 7.17e-02, avg batch time: 0.4855, average train loss: 0.0042
[09/26 02:38:13 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1585, average loss: 0.3618
[09/26 02:38:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:38:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:38:19 visual_prompt]: Epoch 100 / 100: avg data time: 6.57e-02, avg batch time: 0.4787, average train loss: 0.0042
[09/26 02:38:21 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1586, average loss: 0.3617
[09/26 02:38:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 02:38:21 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:38:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:38:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:38:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:38:21 visual_prompt]: Training with config:
[09/26 02:38:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:38:21 visual_prompt]: Loading training data...
[09/26 02:38:21 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:38:22 visual_prompt]: Number of images: 800
[09/26 02:38:22 visual_prompt]: Number of classes: 102 / 102
[09/26 02:38:22 visual_prompt]: Loading validation data...
[09/26 02:38:22 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:38:23 visual_prompt]: Number of images: 200
[09/26 02:38:23 visual_prompt]: Number of classes: 91 / 102
[09/26 02:38:23 visual_prompt]: Constructing models...
[09/26 02:38:25 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 02:38:25 visual_prompt]: tuned percent:0.625
[09/26 02:38:25 visual_prompt]: Device used for model: 0
[09/26 02:38:25 visual_prompt]: Setting up Evaluator...
[09/26 02:38:25 visual_prompt]: Setting up Trainer...
[09/26 02:38:25 visual_prompt]: 	Setting up the optimizer...
[09/26 02:38:25 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:38:32 visual_prompt]: Epoch 1 / 100: avg data time: 7.16e-02, avg batch time: 0.4911, average train loss: 4.6686
[09/26 02:38:34 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1584, average loss: 4.6780
[09/26 02:38:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 02:38:34 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:38:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:38:40 visual_prompt]: Epoch 2 / 100: avg data time: 5.96e-02, avg batch time: 0.4727, average train loss: 4.6223
[09/26 02:38:42 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1579, average loss: 4.6021
[09/26 02:38:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 02:38:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:38:49 visual_prompt]: Epoch 3 / 100: avg data time: 6.58e-02, avg batch time: 0.4788, average train loss: 4.4485
[09/26 02:38:50 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 4.4330
[09/26 02:38:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.00	top5: 15.00	
[09/26 02:38:50 visual_prompt]: Best epoch 3: best metric: 0.060
[09/26 02:38:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:38:57 visual_prompt]: Epoch 4 / 100: avg data time: 7.37e-02, avg batch time: 0.4870, average train loss: 4.2009
[09/26 02:38:59 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1585, average loss: 3.9105
[09/26 02:38:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.50	top5: 32.00	
[09/26 02:38:59 visual_prompt]: Best epoch 4: best metric: 0.115
[09/26 02:38:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:39:05 visual_prompt]: Epoch 5 / 100: avg data time: 6.23e-02, avg batch time: 0.4759, average train loss: 3.4434
[09/26 02:39:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1584, average loss: 2.8851
[09/26 02:39:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 34.50	top5: 57.00	
[09/26 02:39:07 visual_prompt]: Best epoch 5: best metric: 0.345
[09/26 02:39:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:39:14 visual_prompt]: Epoch 6 / 100: avg data time: 6.67e-02, avg batch time: 0.4811, average train loss: 1.7278
[09/26 02:39:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 1.2307
[09/26 02:39:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.50	top5: 89.50	
[09/26 02:39:15 visual_prompt]: Best epoch 6: best metric: 0.725
[09/26 02:39:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:39:22 visual_prompt]: Epoch 7 / 100: avg data time: 5.66e-02, avg batch time: 0.4717, average train loss: 0.5289
[09/26 02:39:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.6275
[09/26 02:39:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.50	
[09/26 02:39:24 visual_prompt]: Best epoch 7: best metric: 0.860
[09/26 02:39:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:39:30 visual_prompt]: Epoch 8 / 100: avg data time: 6.35e-02, avg batch time: 0.4776, average train loss: 0.1594
[09/26 02:39:32 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 0.4495
[09/26 02:39:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.50	
[09/26 02:39:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:39:38 visual_prompt]: Epoch 9 / 100: avg data time: 5.33e-02, avg batch time: 0.4690, average train loss: 0.0514
[09/26 02:39:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1586, average loss: 0.4751
[09/26 02:39:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 95.00	
[09/26 02:39:40 visual_prompt]: Best epoch 9: best metric: 0.865
[09/26 02:39:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:39:47 visual_prompt]: Epoch 10 / 100: avg data time: 7.19e-02, avg batch time: 0.4861, average train loss: 0.0412
[09/26 02:39:49 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1585, average loss: 0.3839
[09/26 02:39:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 98.50	
[09/26 02:39:49 visual_prompt]: Best epoch 10: best metric: 0.880
[09/26 02:39:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:39:55 visual_prompt]: Epoch 11 / 100: avg data time: 5.71e-02, avg batch time: 0.4719, average train loss: 0.0213
[09/26 02:39:57 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1587, average loss: 0.3761
[09/26 02:39:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:39:57 visual_prompt]: Best epoch 11: best metric: 0.910
[09/26 02:39:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:40:03 visual_prompt]: Epoch 12 / 100: avg data time: 6.20e-02, avg batch time: 0.4768, average train loss: 0.0183
[09/26 02:40:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1618, average loss: 0.4361
[09/26 02:40:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 02:40:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:40:12 visual_prompt]: Epoch 13 / 100: avg data time: 7.03e-02, avg batch time: 0.4845, average train loss: 0.0265
[09/26 02:40:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1587, average loss: 0.3907
[09/26 02:40:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 97.50	
[09/26 02:40:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:40:20 visual_prompt]: Epoch 14 / 100: avg data time: 6.37e-02, avg batch time: 0.4777, average train loss: 0.0169
[09/26 02:40:22 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1588, average loss: 0.3738
[09/26 02:40:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.00	
[09/26 02:40:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:40:28 visual_prompt]: Epoch 15 / 100: avg data time: 6.31e-02, avg batch time: 0.4781, average train loss: 0.0075
[09/26 02:40:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1587, average loss: 0.3690
[09/26 02:40:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:40:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:40:37 visual_prompt]: Epoch 16 / 100: avg data time: 7.30e-02, avg batch time: 0.4881, average train loss: 0.0051
[09/26 02:40:39 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 0.3612
[09/26 02:40:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:40:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:40:45 visual_prompt]: Epoch 17 / 100: avg data time: 6.98e-02, avg batch time: 0.4845, average train loss: 0.0041
[09/26 02:40:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1585, average loss: 0.3536
[09/26 02:40:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:40:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:40:54 visual_prompt]: Epoch 18 / 100: avg data time: 6.54e-02, avg batch time: 0.4801, average train loss: 0.0034
[09/26 02:40:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.3487
[09/26 02:40:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:40:55 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:41:02 visual_prompt]: Epoch 19 / 100: avg data time: 6.04e-02, avg batch time: 0.4758, average train loss: 0.0030
[09/26 02:41:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1587, average loss: 0.3444
[09/26 02:41:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:41:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:41:10 visual_prompt]: Epoch 20 / 100: avg data time: 7.02e-02, avg batch time: 0.4849, average train loss: 0.0027
[09/26 02:41:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1586, average loss: 0.3415
[09/26 02:41:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:41:12 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:41:19 visual_prompt]: Epoch 21 / 100: avg data time: 6.36e-02, avg batch time: 0.4785, average train loss: 0.0026
[09/26 02:41:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1583, average loss: 0.3426
[09/26 02:41:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:41:20 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:41:27 visual_prompt]: Epoch 22 / 100: avg data time: 5.91e-02, avg batch time: 0.4741, average train loss: 0.0024
[09/26 02:41:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 0.3420
[09/26 02:41:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:41:29 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:41:35 visual_prompt]: Epoch 23 / 100: avg data time: 6.60e-02, avg batch time: 0.4799, average train loss: 0.0023
[09/26 02:41:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1585, average loss: 0.3420
[09/26 02:41:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:41:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:41:44 visual_prompt]: Epoch 24 / 100: avg data time: 6.68e-02, avg batch time: 0.4810, average train loss: 0.0022
[09/26 02:41:45 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.3413
[09/26 02:41:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.00	
[09/26 02:41:45 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:41:52 visual_prompt]: Epoch 25 / 100: avg data time: 6.89e-02, avg batch time: 0.4839, average train loss: 0.0021
[09/26 02:41:54 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1584, average loss: 0.3416
[09/26 02:41:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:41:54 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:42:00 visual_prompt]: Epoch 26 / 100: avg data time: 6.34e-02, avg batch time: 0.4768, average train loss: 0.0020
[09/26 02:42:02 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 0.3399
[09/26 02:42:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:42:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:42:09 visual_prompt]: Epoch 27 / 100: avg data time: 6.23e-02, avg batch time: 0.4758, average train loss: 0.0018
[09/26 02:42:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.3398
[09/26 02:42:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:42:10 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:42:17 visual_prompt]: Epoch 28 / 100: avg data time: 6.97e-02, avg batch time: 0.4840, average train loss: 0.0018
[09/26 02:42:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1578, average loss: 0.3392
[09/26 02:42:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:42:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:42:25 visual_prompt]: Epoch 29 / 100: avg data time: 6.84e-02, avg batch time: 0.4815, average train loss: 0.0017
[09/26 02:42:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1587, average loss: 0.3384
[09/26 02:42:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:42:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:42:34 visual_prompt]: Epoch 30 / 100: avg data time: 6.44e-02, avg batch time: 0.4785, average train loss: 0.0016
[09/26 02:42:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1579, average loss: 0.3383
[09/26 02:42:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:42:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:42:42 visual_prompt]: Epoch 31 / 100: avg data time: 6.88e-02, avg batch time: 0.4815, average train loss: 0.0016
[09/26 02:42:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 0.3387
[09/26 02:42:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:42:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:42:50 visual_prompt]: Epoch 32 / 100: avg data time: 6.64e-02, avg batch time: 0.4793, average train loss: 0.0016
[09/26 02:42:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.3397
[09/26 02:42:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:42:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:42:59 visual_prompt]: Epoch 33 / 100: avg data time: 6.78e-02, avg batch time: 0.4816, average train loss: 0.0015
[09/26 02:43:00 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1580, average loss: 0.3403
[09/26 02:43:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:43:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:43:07 visual_prompt]: Epoch 34 / 100: avg data time: 6.31e-02, avg batch time: 0.4762, average train loss: 0.0014
[09/26 02:43:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.3406
[09/26 02:43:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:43:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:43:15 visual_prompt]: Epoch 35 / 100: avg data time: 6.71e-02, avg batch time: 0.4814, average train loss: 0.0014
[09/26 02:43:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 0.3400
[09/26 02:43:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:43:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:43:24 visual_prompt]: Epoch 36 / 100: avg data time: 6.48e-02, avg batch time: 0.4781, average train loss: 0.0014
[09/26 02:43:25 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1580, average loss: 0.3394
[09/26 02:43:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:43:25 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:43:32 visual_prompt]: Epoch 37 / 100: avg data time: 7.14e-02, avg batch time: 0.4843, average train loss: 0.0013
[09/26 02:43:34 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1577, average loss: 0.3395
[09/26 02:43:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:43:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:43:40 visual_prompt]: Epoch 38 / 100: avg data time: 6.48e-02, avg batch time: 0.4792, average train loss: 0.0013
[09/26 02:43:42 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1584, average loss: 0.3392
[09/26 02:43:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:43:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:43:49 visual_prompt]: Epoch 39 / 100: avg data time: 6.26e-02, avg batch time: 0.4768, average train loss: 0.0013
[09/26 02:43:50 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1583, average loss: 0.3394
[09/26 02:43:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:43:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:43:57 visual_prompt]: Epoch 40 / 100: avg data time: 6.63e-02, avg batch time: 0.4794, average train loss: 0.0012
[09/26 02:43:59 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1585, average loss: 0.3394
[09/26 02:43:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:43:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:44:05 visual_prompt]: Epoch 41 / 100: avg data time: 6.42e-02, avg batch time: 0.4768, average train loss: 0.0012
[09/26 02:44:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1579, average loss: 0.3398
[09/26 02:44:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:44:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:44:13 visual_prompt]: Epoch 42 / 100: avg data time: 6.10e-02, avg batch time: 0.4741, average train loss: 0.0012
[09/26 02:44:15 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1579, average loss: 0.3409
[09/26 02:44:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:44:15 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:44:22 visual_prompt]: Epoch 43 / 100: avg data time: 6.08e-02, avg batch time: 0.4741, average train loss: 0.0012
[09/26 02:44:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1582, average loss: 0.3412
[09/26 02:44:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:44:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:44:30 visual_prompt]: Epoch 44 / 100: avg data time: 5.25e-02, avg batch time: 0.4681, average train loss: 0.0012
[09/26 02:44:31 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1581, average loss: 0.3414
[09/26 02:44:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:44:31 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:44:38 visual_prompt]: Epoch 45 / 100: avg data time: 7.39e-02, avg batch time: 0.4871, average train loss: 0.0011
[09/26 02:44:40 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1582, average loss: 0.3412
[09/26 02:44:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:44:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:44:47 visual_prompt]: Epoch 46 / 100: avg data time: 6.86e-02, avg batch time: 0.4832, average train loss: 0.0011
[09/26 02:44:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1586, average loss: 0.3416
[09/26 02:44:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:44:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:44:55 visual_prompt]: Epoch 47 / 100: avg data time: 6.89e-02, avg batch time: 0.4821, average train loss: 0.0011
[09/26 02:44:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 0.3422
[09/26 02:44:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:44:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:45:03 visual_prompt]: Epoch 48 / 100: avg data time: 6.99e-02, avg batch time: 0.4820, average train loss: 0.0010
[09/26 02:45:05 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1586, average loss: 0.3423
[09/26 02:45:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:45:12 visual_prompt]: Epoch 49 / 100: avg data time: 6.49e-02, avg batch time: 0.4778, average train loss: 0.0011
[09/26 02:45:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.3421
[09/26 02:45:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:45:20 visual_prompt]: Epoch 50 / 100: avg data time: 6.54e-02, avg batch time: 0.4786, average train loss: 0.0010
[09/26 02:45:22 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1581, average loss: 0.3423
[09/26 02:45:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:45:28 visual_prompt]: Epoch 51 / 100: avg data time: 7.00e-02, avg batch time: 0.4827, average train loss: 0.0010
[09/26 02:45:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1579, average loss: 0.3423
[09/26 02:45:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:30 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:45:36 visual_prompt]: Epoch 52 / 100: avg data time: 6.12e-02, avg batch time: 0.4740, average train loss: 0.0010
[09/26 02:45:38 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.3420
[09/26 02:45:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:45:45 visual_prompt]: Epoch 53 / 100: avg data time: 5.72e-02, avg batch time: 0.4717, average train loss: 0.0010
[09/26 02:45:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1580, average loss: 0.3422
[09/26 02:45:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:46 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:45:53 visual_prompt]: Epoch 54 / 100: avg data time: 6.22e-02, avg batch time: 0.4752, average train loss: 0.0010
[09/26 02:45:55 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1577, average loss: 0.3420
[09/26 02:45:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:45:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:46:01 visual_prompt]: Epoch 55 / 100: avg data time: 7.11e-02, avg batch time: 0.4840, average train loss: 0.0010
[09/26 02:46:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 0.3416
[09/26 02:46:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:46:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:46:10 visual_prompt]: Epoch 56 / 100: avg data time: 6.68e-02, avg batch time: 0.4790, average train loss: 0.0009
[09/26 02:46:11 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1581, average loss: 0.3410
[09/26 02:46:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 02:46:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:46:18 visual_prompt]: Epoch 57 / 100: avg data time: 6.48e-02, avg batch time: 0.4773, average train loss: 0.0010
[09/26 02:46:20 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1576, average loss: 0.3412
[09/26 02:46:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:46:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:46:26 visual_prompt]: Epoch 58 / 100: avg data time: 6.58e-02, avg batch time: 0.4800, average train loss: 0.0009
[09/26 02:46:28 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.3413
[09/26 02:46:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:46:28 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:46:35 visual_prompt]: Epoch 59 / 100: avg data time: 6.04e-02, avg batch time: 0.4736, average train loss: 0.0009
[09/26 02:46:36 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1576, average loss: 0.3415
[09/26 02:46:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:46:36 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:46:43 visual_prompt]: Epoch 60 / 100: avg data time: 6.60e-02, avg batch time: 0.4793, average train loss: 0.0009
[09/26 02:46:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1583, average loss: 0.3416
[09/26 02:46:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:46:45 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:46:51 visual_prompt]: Epoch 61 / 100: avg data time: 6.08e-02, avg batch time: 0.4752, average train loss: 0.0009
[09/26 02:46:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1576, average loss: 0.3416
[09/26 02:46:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 02:46:53 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:47:00 visual_prompt]: Epoch 62 / 100: avg data time: 6.44e-02, avg batch time: 0.4785, average train loss: 0.0009
[09/26 02:47:01 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1579, average loss: 0.3418
[09/26 02:47:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:47:01 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:47:08 visual_prompt]: Epoch 63 / 100: avg data time: 6.77e-02, avg batch time: 0.4806, average train loss: 0.0009
[09/26 02:47:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 0.3417
[09/26 02:47:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:47:09 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:47:16 visual_prompt]: Epoch 64 / 100: avg data time: 6.38e-02, avg batch time: 0.4774, average train loss: 0.0009
[09/26 02:47:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.3417
[09/26 02:47:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:47:18 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:47:24 visual_prompt]: Epoch 65 / 100: avg data time: 6.41e-02, avg batch time: 0.4776, average train loss: 0.0009
[09/26 02:47:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.3416
[09/26 02:47:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:47:26 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:47:33 visual_prompt]: Epoch 66 / 100: avg data time: 6.58e-02, avg batch time: 0.4787, average train loss: 0.0009
[09/26 02:47:34 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1578, average loss: 0.3415
[09/26 02:47:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:47:34 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:47:41 visual_prompt]: Epoch 67 / 100: avg data time: 6.91e-02, avg batch time: 0.4825, average train loss: 0.0009
[09/26 02:47:43 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1579, average loss: 0.3414
[09/26 02:47:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:47:43 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:47:49 visual_prompt]: Epoch 68 / 100: avg data time: 6.71e-02, avg batch time: 0.4804, average train loss: 0.0009
[09/26 02:47:51 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1579, average loss: 0.3414
[09/26 02:47:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:47:51 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:47:58 visual_prompt]: Epoch 69 / 100: avg data time: 7.13e-02, avg batch time: 0.4841, average train loss: 0.0008
[09/26 02:48:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 0.3414
[09/26 02:48:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 02:48:00 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:48:06 visual_prompt]: Epoch 70 / 100: avg data time: 6.49e-02, avg batch time: 0.4773, average train loss: 0.0008
[09/26 02:48:08 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1582, average loss: 0.3412
[09/26 02:48:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:08 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:48:14 visual_prompt]: Epoch 71 / 100: avg data time: 6.88e-02, avg batch time: 0.4829, average train loss: 0.0008
[09/26 02:48:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1588, average loss: 0.3413
[09/26 02:48:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:16 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:48:23 visual_prompt]: Epoch 72 / 100: avg data time: 7.39e-02, avg batch time: 0.4866, average train loss: 0.0008
[09/26 02:48:25 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1580, average loss: 0.3412
[09/26 02:48:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:25 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:48:31 visual_prompt]: Epoch 73 / 100: avg data time: 5.53e-02, avg batch time: 0.4684, average train loss: 0.0008
[09/26 02:48:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.3413
[09/26 02:48:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:48:39 visual_prompt]: Epoch 74 / 100: avg data time: 6.43e-02, avg batch time: 0.4776, average train loss: 0.0008
[09/26 02:48:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.3412
[09/26 02:48:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:41 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:48:48 visual_prompt]: Epoch 75 / 100: avg data time: 6.75e-02, avg batch time: 0.4805, average train loss: 0.0009
[09/26 02:48:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1586, average loss: 0.3413
[09/26 02:48:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:49 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:48:56 visual_prompt]: Epoch 76 / 100: avg data time: 6.60e-02, avg batch time: 0.4789, average train loss: 0.0008
[09/26 02:48:58 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 0.3416
[09/26 02:48:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:48:58 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:49:04 visual_prompt]: Epoch 77 / 100: avg data time: 6.60e-02, avg batch time: 0.4807, average train loss: 0.0008
[09/26 02:49:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.3417
[09/26 02:49:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:49:13 visual_prompt]: Epoch 78 / 100: avg data time: 6.93e-02, avg batch time: 0.4839, average train loss: 0.0008
[09/26 02:49:15 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.3417
[09/26 02:49:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:15 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:49:21 visual_prompt]: Epoch 79 / 100: avg data time: 6.72e-02, avg batch time: 0.4803, average train loss: 0.0008
[09/26 02:49:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 0.3417
[09/26 02:49:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:23 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:49:30 visual_prompt]: Epoch 80 / 100: avg data time: 7.11e-02, avg batch time: 0.4836, average train loss: 0.0008
[09/26 02:49:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.3417
[09/26 02:49:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:31 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:49:38 visual_prompt]: Epoch 81 / 100: avg data time: 6.20e-02, avg batch time: 0.4766, average train loss: 0.0008
[09/26 02:49:40 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1578, average loss: 0.3417
[09/26 02:49:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:40 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:49:46 visual_prompt]: Epoch 82 / 100: avg data time: 6.24e-02, avg batch time: 0.4757, average train loss: 0.0008
[09/26 02:49:48 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1578, average loss: 0.3417
[09/26 02:49:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:48 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:49:54 visual_prompt]: Epoch 83 / 100: avg data time: 6.47e-02, avg batch time: 0.4772, average train loss: 0.0008
[09/26 02:49:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 0.3416
[09/26 02:49:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:49:56 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:50:03 visual_prompt]: Epoch 84 / 100: avg data time: 7.06e-02, avg batch time: 0.4838, average train loss: 0.0008
[09/26 02:50:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1583, average loss: 0.3416
[09/26 02:50:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:04 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:50:11 visual_prompt]: Epoch 85 / 100: avg data time: 7.24e-02, avg batch time: 0.4857, average train loss: 0.0008
[09/26 02:50:13 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1586, average loss: 0.3415
[09/26 02:50:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:13 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:50:20 visual_prompt]: Epoch 86 / 100: avg data time: 7.31e-02, avg batch time: 0.4859, average train loss: 0.0008
[09/26 02:50:21 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1582, average loss: 0.3415
[09/26 02:50:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:21 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:50:28 visual_prompt]: Epoch 87 / 100: avg data time: 5.75e-02, avg batch time: 0.4720, average train loss: 0.0008
[09/26 02:50:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 0.3414
[09/26 02:50:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:30 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:50:36 visual_prompt]: Epoch 88 / 100: avg data time: 6.96e-02, avg batch time: 0.4819, average train loss: 0.0008
[09/26 02:50:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1579, average loss: 0.3415
[09/26 02:50:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:38 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:50:44 visual_prompt]: Epoch 89 / 100: avg data time: 5.13e-02, avg batch time: 0.4665, average train loss: 0.0008
[09/26 02:50:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1578, average loss: 0.3415
[09/26 02:50:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:46 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:50:53 visual_prompt]: Epoch 90 / 100: avg data time: 6.38e-02, avg batch time: 0.4779, average train loss: 0.0008
[09/26 02:50:54 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1581, average loss: 0.3414
[09/26 02:50:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:50:54 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:51:01 visual_prompt]: Epoch 91 / 100: avg data time: 5.86e-02, avg batch time: 0.4724, average train loss: 0.0008
[09/26 02:51:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.3414
[09/26 02:51:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:03 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:51:09 visual_prompt]: Epoch 92 / 100: avg data time: 6.97e-02, avg batch time: 0.4821, average train loss: 0.0008
[09/26 02:51:11 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1580, average loss: 0.3414
[09/26 02:51:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:11 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:51:18 visual_prompt]: Epoch 93 / 100: avg data time: 7.25e-02, avg batch time: 0.4847, average train loss: 0.0008
[09/26 02:51:19 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1582, average loss: 0.3414
[09/26 02:51:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:19 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:51:26 visual_prompt]: Epoch 94 / 100: avg data time: 7.08e-02, avg batch time: 0.4846, average train loss: 0.0008
[09/26 02:51:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.3414
[09/26 02:51:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:28 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:51:35 visual_prompt]: Epoch 95 / 100: avg data time: 6.82e-02, avg batch time: 0.4825, average train loss: 0.0008
[09/26 02:51:36 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 0.3414
[09/26 02:51:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:36 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:51:43 visual_prompt]: Epoch 96 / 100: avg data time: 6.10e-02, avg batch time: 0.4761, average train loss: 0.0008
[09/26 02:51:44 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1582, average loss: 0.3414
[09/26 02:51:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:44 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:51:51 visual_prompt]: Epoch 97 / 100: avg data time: 6.67e-02, avg batch time: 0.4790, average train loss: 0.0008
[09/26 02:51:53 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1577, average loss: 0.3414
[09/26 02:51:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:51:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:51:59 visual_prompt]: Epoch 98 / 100: avg data time: 6.65e-02, avg batch time: 0.4794, average train loss: 0.0008
[09/26 02:52:01 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1577, average loss: 0.3414
[09/26 02:52:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:52:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:52:08 visual_prompt]: Epoch 99 / 100: avg data time: 6.63e-02, avg batch time: 0.4808, average train loss: 0.0008
[09/26 02:52:10 visual_prompt]: Inference (val):avg data time: 4.75e-05, avg batch time: 0.1580, average loss: 0.3414
[09/26 02:52:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:52:10 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:52:16 visual_prompt]: Epoch 100 / 100: avg data time: 7.34e-02, avg batch time: 0.4866, average train loss: 0.0008
[09/26 02:52:18 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1580, average loss: 0.3414
[09/26 02:52:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 02:52:18 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:52:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:52:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:52:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:52:18 visual_prompt]: Training with config:
[09/26 02:52:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:52:18 visual_prompt]: Loading training data...
[09/26 02:52:18 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:52:19 visual_prompt]: Number of images: 800
[09/26 02:52:19 visual_prompt]: Number of classes: 102 / 102
[09/26 02:52:19 visual_prompt]: Loading validation data...
[09/26 02:52:19 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 02:52:19 visual_prompt]: Number of images: 200
[09/26 02:52:19 visual_prompt]: Number of classes: 91 / 102
[09/26 02:52:19 visual_prompt]: Constructing models...
[09/26 02:52:22 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 02:52:22 visual_prompt]: tuned percent:0.625
[09/26 02:52:22 visual_prompt]: Device used for model: 0
[09/26 02:52:22 visual_prompt]: Setting up Evaluator...
[09/26 02:52:22 visual_prompt]: Setting up Trainer...
[09/26 02:52:22 visual_prompt]: 	Setting up the optimizer...
[09/26 02:52:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:52:28 visual_prompt]: Epoch 1 / 100: avg data time: 5.46e-02, avg batch time: 0.4720, average train loss: 4.6709
[09/26 02:52:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1586, average loss: 4.6780
[09/26 02:52:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 02:52:30 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:52:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 02:52:37 visual_prompt]: Epoch 2 / 100: avg data time: 6.22e-02, avg batch time: 0.4741, average train loss: 4.6499
[09/26 02:52:38 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 4.6467
[09/26 02:52:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 5.00	
[09/26 02:52:38 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 02:52:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 02:52:45 visual_prompt]: Epoch 3 / 100: avg data time: 6.61e-02, avg batch time: 0.4781, average train loss: 4.5467
[09/26 02:52:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 4.4760
[09/26 02:52:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 15.50	
[09/26 02:52:47 visual_prompt]: Best epoch 3: best metric: 0.025
[09/26 02:52:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 02:52:53 visual_prompt]: Epoch 4 / 100: avg data time: 7.41e-02, avg batch time: 0.4862, average train loss: 4.2589
[09/26 02:52:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1587, average loss: 4.1556
[09/26 02:52:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.00	top5: 18.00	
[09/26 02:52:55 visual_prompt]: Best epoch 4: best metric: 0.070
[09/26 02:52:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 02:53:02 visual_prompt]: Epoch 5 / 100: avg data time: 6.33e-02, avg batch time: 0.4760, average train loss: 3.7862
[09/26 02:53:03 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1586, average loss: 3.3800
[09/26 02:53:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 29.00	top5: 51.50	
[09/26 02:53:03 visual_prompt]: Best epoch 5: best metric: 0.290
[09/26 02:53:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 02:53:10 visual_prompt]: Epoch 6 / 100: avg data time: 6.82e-02, avg batch time: 0.4813, average train loss: 2.8683
[09/26 02:53:12 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1577, average loss: 2.3942
[09/26 02:53:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 54.00	top5: 82.50	
[09/26 02:53:12 visual_prompt]: Best epoch 6: best metric: 0.540
[09/26 02:53:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 02:53:18 visual_prompt]: Epoch 7 / 100: avg data time: 7.20e-02, avg batch time: 0.4850, average train loss: 1.7171
[09/26 02:53:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 1.4496
[09/26 02:53:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.50	top5: 91.50	
[09/26 02:53:20 visual_prompt]: Best epoch 7: best metric: 0.765
[09/26 02:53:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 02:53:27 visual_prompt]: Epoch 8 / 100: avg data time: 6.33e-02, avg batch time: 0.4771, average train loss: 0.9948
[09/26 02:53:28 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 1.1363
[09/26 02:53:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 96.50	
[09/26 02:53:28 visual_prompt]: Best epoch 8: best metric: 0.810
[09/26 02:53:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 02:53:35 visual_prompt]: Epoch 9 / 100: avg data time: 6.38e-02, avg batch time: 0.4765, average train loss: 0.7401
[09/26 02:53:37 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.9668
[09/26 02:53:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 02:53:37 visual_prompt]: Best epoch 9: best metric: 0.880
[09/26 02:53:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 02:53:43 visual_prompt]: Epoch 10 / 100: avg data time: 7.20e-02, avg batch time: 0.4847, average train loss: 0.6640
[09/26 02:53:45 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1586, average loss: 1.0360
[09/26 02:53:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.00	
[09/26 02:53:45 visual_prompt]: Best epoch 10: best metric: 0.905
[09/26 02:53:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 02:53:52 visual_prompt]: Epoch 11 / 100: avg data time: 7.35e-02, avg batch time: 0.4872, average train loss: 0.8245
[09/26 02:53:53 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1579, average loss: 0.9934
[09/26 02:53:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.50	
[09/26 02:53:54 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 02:54:00 visual_prompt]: Epoch 12 / 100: avg data time: 6.36e-02, avg batch time: 0.4779, average train loss: 1.8642
[09/26 02:54:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 2.6019
[09/26 02:54:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.00	top5: 80.50	
[09/26 02:54:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 02:54:08 visual_prompt]: Epoch 13 / 100: avg data time: 7.10e-02, avg batch time: 0.4840, average train loss: 1.4378
[09/26 02:54:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1586, average loss: 1.1392
[09/26 02:54:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 02:54:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 02:54:17 visual_prompt]: Epoch 14 / 100: avg data time: 6.76e-02, avg batch time: 0.4815, average train loss: 0.7473
[09/26 02:54:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 0.8578
[09/26 02:54:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 99.00	
[09/26 02:54:19 visual_prompt]: Best epoch 14: best metric: 0.910
[09/26 02:54:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 02:54:25 visual_prompt]: Epoch 15 / 100: avg data time: 6.84e-02, avg batch time: 0.4815, average train loss: 0.7146
[09/26 02:54:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1586, average loss: 0.9826
[09/26 02:54:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.00	
[09/26 02:54:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 02:54:34 visual_prompt]: Epoch 16 / 100: avg data time: 6.75e-02, avg batch time: 0.4813, average train loss: 2.2363
[09/26 02:54:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1588, average loss: 4.6109
[09/26 02:54:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 02:54:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 02:54:42 visual_prompt]: Epoch 17 / 100: avg data time: 7.13e-02, avg batch time: 0.4854, average train loss: 4.1285
[09/26 02:54:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1586, average loss: 3.6487
[09/26 02:54:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 23.00	top5: 61.50	
[09/26 02:54:44 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 02:54:50 visual_prompt]: Epoch 18 / 100: avg data time: 6.49e-02, avg batch time: 0.4791, average train loss: 3.3020
[09/26 02:54:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 2.7051
[09/26 02:54:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 48.50	top5: 74.00	
[09/26 02:54:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 02:54:59 visual_prompt]: Epoch 19 / 100: avg data time: 6.71e-02, avg batch time: 0.4801, average train loss: 1.8521
[09/26 02:55:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 1.4990
[09/26 02:55:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 91.00	
[09/26 02:55:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 02:55:07 visual_prompt]: Epoch 20 / 100: avg data time: 7.15e-02, avg batch time: 0.4856, average train loss: 1.0663
[09/26 02:55:09 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1588, average loss: 1.2231
[09/26 02:55:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.50	
[09/26 02:55:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 02:55:16 visual_prompt]: Epoch 21 / 100: avg data time: 7.23e-02, avg batch time: 0.4875, average train loss: 2.0215
[09/26 02:55:17 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1589, average loss: 1.8346
[09/26 02:55:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 90.50	
[09/26 02:55:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 02:55:24 visual_prompt]: Epoch 22 / 100: avg data time: 6.99e-02, avg batch time: 0.4843, average train loss: 1.5761
[09/26 02:55:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 1.6877
[09/26 02:55:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.00	top5: 88.50	
[09/26 02:55:26 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 02:55:32 visual_prompt]: Epoch 23 / 100: avg data time: 5.74e-02, avg batch time: 0.4751, average train loss: 1.0865
[09/26 02:55:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1589, average loss: 1.0936
[09/26 02:55:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 02:55:34 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 02:55:41 visual_prompt]: Epoch 24 / 100: avg data time: 6.54e-02, avg batch time: 0.4788, average train loss: 0.8385
[09/26 02:55:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1586, average loss: 1.0462
[09/26 02:55:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 97.50	
[09/26 02:55:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 02:55:49 visual_prompt]: Epoch 25 / 100: avg data time: 6.87e-02, avg batch time: 0.4831, average train loss: 0.9699
[09/26 02:55:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 1.1629
[09/26 02:55:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 02:55:51 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 02:55:57 visual_prompt]: Epoch 26 / 100: avg data time: 5.92e-02, avg batch time: 0.4744, average train loss: 1.1100
[09/26 02:55:59 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1582, average loss: 1.1005
[09/26 02:55:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.50	
[09/26 02:55:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 02:56:06 visual_prompt]: Epoch 27 / 100: avg data time: 6.67e-02, avg batch time: 0.4816, average train loss: 0.8969
[09/26 02:56:08 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1587, average loss: 0.8969
[09/26 02:56:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.50	
[09/26 02:56:08 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 02:56:14 visual_prompt]: Epoch 28 / 100: avg data time: 7.12e-02, avg batch time: 0.4858, average train loss: 0.7189
[09/26 02:56:16 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1582, average loss: 0.8848
[09/26 02:56:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.50	
[09/26 02:56:16 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 02:56:23 visual_prompt]: Epoch 29 / 100: avg data time: 5.65e-02, avg batch time: 0.4718, average train loss: 0.6499
[09/26 02:56:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 1.0229
[09/26 02:56:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 02:56:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 02:56:31 visual_prompt]: Epoch 30 / 100: avg data time: 6.97e-02, avg batch time: 0.4833, average train loss: 2.3508
[09/26 02:56:32 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 3.0629
[09/26 02:56:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 46.50	top5: 73.50	
[09/26 02:56:32 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 02:56:39 visual_prompt]: Epoch 31 / 100: avg data time: 5.34e-02, avg batch time: 0.4683, average train loss: 2.1231
[09/26 02:56:41 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1576, average loss: 1.5723
[09/26 02:56:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.50	
[09/26 02:56:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 02:56:47 visual_prompt]: Epoch 32 / 100: avg data time: 6.93e-02, avg batch time: 0.4839, average train loss: 1.0174
[09/26 02:56:49 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 1.3392
[09/26 02:56:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 95.00	
[09/26 02:56:49 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 02:56:56 visual_prompt]: Epoch 33 / 100: avg data time: 6.76e-02, avg batch time: 0.4811, average train loss: 1.6082
[09/26 02:56:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1588, average loss: 3.7147
[09/26 02:56:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 21.00	top5: 49.50	
[09/26 02:56:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 02:57:04 visual_prompt]: Epoch 34 / 100: avg data time: 6.70e-02, avg batch time: 0.4818, average train loss: 2.1467
[09/26 02:57:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1588, average loss: 1.7891
[09/26 02:57:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.00	top5: 92.50	
[09/26 02:57:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 02:57:13 visual_prompt]: Epoch 35 / 100: avg data time: 7.31e-02, avg batch time: 0.4885, average train loss: 1.1629
[09/26 02:57:14 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1585, average loss: 1.1875
[09/26 02:57:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.00	
[09/26 02:57:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 02:57:21 visual_prompt]: Epoch 36 / 100: avg data time: 5.84e-02, avg batch time: 0.4722, average train loss: 1.5731
[09/26 02:57:23 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1583, average loss: 2.1132
[09/26 02:57:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 92.00	
[09/26 02:57:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 02:57:29 visual_prompt]: Epoch 37 / 100: avg data time: 5.74e-02, avg batch time: 0.4727, average train loss: 2.0140
[09/26 02:57:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 2.1843
[09/26 02:57:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.50	top5: 88.00	
[09/26 02:57:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 02:57:37 visual_prompt]: Epoch 38 / 100: avg data time: 6.57e-02, avg batch time: 0.4787, average train loss: 1.0513
[09/26 02:57:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1588, average loss: 0.9600
[09/26 02:57:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 02:57:39 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 02:57:46 visual_prompt]: Epoch 39 / 100: avg data time: 6.63e-02, avg batch time: 0.4795, average train loss: 0.6432
[09/26 02:57:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1585, average loss: 0.9374
[09/26 02:57:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.50	
[09/26 02:57:47 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 02:57:54 visual_prompt]: Epoch 40 / 100: avg data time: 6.25e-02, avg batch time: 0.4773, average train loss: 2.7127
[09/26 02:57:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1587, average loss: 2.9279
[09/26 02:57:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.00	top5: 85.50	
[09/26 02:57:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 02:58:03 visual_prompt]: Epoch 41 / 100: avg data time: 7.24e-02, avg batch time: 0.4862, average train loss: 3.4597
[09/26 02:58:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 3.4352
[09/26 02:58:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 39.50	top5: 64.00	
[09/26 02:58:04 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 02:58:11 visual_prompt]: Epoch 42 / 100: avg data time: 6.22e-02, avg batch time: 0.4753, average train loss: 2.2456
[09/26 02:58:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 2.1716
[09/26 02:58:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.00	top5: 91.00	
[09/26 02:58:13 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 02:58:19 visual_prompt]: Epoch 43 / 100: avg data time: 6.90e-02, avg batch time: 0.4821, average train loss: 2.3268
[09/26 02:58:21 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 2.1018
[09/26 02:58:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 91.50	
[09/26 02:58:21 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 02:58:28 visual_prompt]: Epoch 44 / 100: avg data time: 6.82e-02, avg batch time: 0.4821, average train loss: 1.1961
[09/26 02:58:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 1.4784
[09/26 02:58:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 97.00	
[09/26 02:58:29 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 02:58:36 visual_prompt]: Epoch 45 / 100: avg data time: 7.25e-02, avg batch time: 0.4863, average train loss: 1.1525
[09/26 02:58:38 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 1.3229
[09/26 02:58:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.50	
[09/26 02:58:38 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 02:58:44 visual_prompt]: Epoch 46 / 100: avg data time: 6.06e-02, avg batch time: 0.4751, average train loss: 1.1735
[09/26 02:58:46 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 2.7525
[09/26 02:58:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.00	top5: 92.00	
[09/26 02:58:46 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 02:58:53 visual_prompt]: Epoch 47 / 100: avg data time: 6.38e-02, avg batch time: 0.4781, average train loss: 1.9595
[09/26 02:58:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1587, average loss: 1.1338
[09/26 02:58:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.50	
[09/26 02:58:54 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 02:59:01 visual_prompt]: Epoch 48 / 100: avg data time: 4.94e-02, avg batch time: 0.4650, average train loss: 1.2374
[09/26 02:59:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 1.6681
[09/26 02:59:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 94.50	
[09/26 02:59:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 02:59:09 visual_prompt]: Epoch 49 / 100: avg data time: 6.36e-02, avg batch time: 0.4788, average train loss: 0.9313
[09/26 02:59:11 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1585, average loss: 0.9611
[09/26 02:59:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.50	
[09/26 02:59:11 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 02:59:17 visual_prompt]: Epoch 50 / 100: avg data time: 7.14e-02, avg batch time: 0.4849, average train loss: 0.6054
[09/26 02:59:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1583, average loss: 0.7811
[09/26 02:59:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 02:59:19 visual_prompt]: Best epoch 50: best metric: 0.920
[09/26 02:59:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 02:59:26 visual_prompt]: Epoch 51 / 100: avg data time: 6.28e-02, avg batch time: 0.4778, average train loss: 0.5358
[09/26 02:59:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.8602
[09/26 02:59:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 02:59:28 visual_prompt]: Best epoch 51: best metric: 0.925
[09/26 02:59:28 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 02:59:34 visual_prompt]: Epoch 52 / 100: avg data time: 6.02e-02, avg batch time: 0.4754, average train loss: 1.2511
[09/26 02:59:36 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1584, average loss: 1.4859
[09/26 02:59:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 02:59:36 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 02:59:43 visual_prompt]: Epoch 53 / 100: avg data time: 6.90e-02, avg batch time: 0.4823, average train loss: 3.3446
[09/26 02:59:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 4.2645
[09/26 02:59:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.50	top5: 28.00	
[09/26 02:59:44 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 02:59:51 visual_prompt]: Epoch 54 / 100: avg data time: 5.62e-02, avg batch time: 0.4704, average train loss: 2.5516
[09/26 02:59:53 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1586, average loss: 1.7653
[09/26 02:59:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 94.00	
[09/26 02:59:53 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 02:59:59 visual_prompt]: Epoch 55 / 100: avg data time: 7.26e-02, avg batch time: 0.4870, average train loss: 1.4575
[09/26 03:00:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1587, average loss: 1.2068
[09/26 03:00:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.50	
[09/26 03:00:01 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:00:08 visual_prompt]: Epoch 56 / 100: avg data time: 6.54e-02, avg batch time: 0.4799, average train loss: 0.7529
[09/26 03:00:09 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1584, average loss: 0.9099
[09/26 03:00:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 03:00:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:00:16 visual_prompt]: Epoch 57 / 100: avg data time: 6.69e-02, avg batch time: 0.4810, average train loss: 0.6808
[09/26 03:00:18 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 1.4193
[09/26 03:00:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.00	
[09/26 03:00:18 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:00:24 visual_prompt]: Epoch 58 / 100: avg data time: 6.79e-02, avg batch time: 0.4825, average train loss: 0.8543
[09/26 03:00:26 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1584, average loss: 1.4450
[09/26 03:00:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.50	
[09/26 03:00:26 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:00:33 visual_prompt]: Epoch 59 / 100: avg data time: 6.51e-02, avg batch time: 0.4785, average train loss: 0.7311
[09/26 03:00:35 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1584, average loss: 0.8718
[09/26 03:00:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 03:00:35 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:00:41 visual_prompt]: Epoch 60 / 100: avg data time: 6.60e-02, avg batch time: 0.4801, average train loss: 0.5131
[09/26 03:00:43 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.7660
[09/26 03:00:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.50	
[09/26 03:00:43 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:00:50 visual_prompt]: Epoch 61 / 100: avg data time: 6.64e-02, avg batch time: 0.4819, average train loss: 0.4396
[09/26 03:00:51 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1578, average loss: 0.8040
[09/26 03:00:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 03:00:51 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:00:58 visual_prompt]: Epoch 62 / 100: avg data time: 7.11e-02, avg batch time: 0.4867, average train loss: 0.4479
[09/26 03:01:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 1.0334
[09/26 03:01:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 03:01:00 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:01:06 visual_prompt]: Epoch 63 / 100: avg data time: 6.73e-02, avg batch time: 0.4819, average train loss: 0.5338
[09/26 03:01:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 0.8672
[09/26 03:01:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 03:01:08 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:01:15 visual_prompt]: Epoch 64 / 100: avg data time: 7.48e-02, avg batch time: 0.4879, average train loss: 0.5110
[09/26 03:01:17 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 0.7628
[09/26 03:01:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.50	
[09/26 03:01:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:01:23 visual_prompt]: Epoch 65 / 100: avg data time: 6.98e-02, avg batch time: 0.4838, average train loss: 0.4239
[09/26 03:01:25 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1586, average loss: 0.7022
[09/26 03:01:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.00	
[09/26 03:01:25 visual_prompt]: Best epoch 65: best metric: 0.940
[09/26 03:01:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:01:32 visual_prompt]: Epoch 66 / 100: avg data time: 6.34e-02, avg batch time: 0.4775, average train loss: 0.3804
[09/26 03:01:33 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 0.6607
[09/26 03:01:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:01:33 visual_prompt]: Best epoch 66: best metric: 0.945
[09/26 03:01:33 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:01:40 visual_prompt]: Epoch 67 / 100: avg data time: 7.26e-02, avg batch time: 0.4855, average train loss: 0.4095
[09/26 03:01:42 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1582, average loss: 1.5676
[09/26 03:01:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 03:01:42 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:01:48 visual_prompt]: Epoch 68 / 100: avg data time: 7.17e-02, avg batch time: 0.4854, average train loss: 0.7607
[09/26 03:01:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1586, average loss: 0.9017
[09/26 03:01:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 03:01:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:01:57 visual_prompt]: Epoch 69 / 100: avg data time: 6.50e-02, avg batch time: 0.4784, average train loss: 0.4767
[09/26 03:01:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 0.6972
[09/26 03:01:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 03:01:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:02:05 visual_prompt]: Epoch 70 / 100: avg data time: 6.74e-02, avg batch time: 0.4808, average train loss: 0.3675
[09/26 03:02:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.6570
[09/26 03:02:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.50	
[09/26 03:02:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:02:13 visual_prompt]: Epoch 71 / 100: avg data time: 6.54e-02, avg batch time: 0.4798, average train loss: 0.3309
[09/26 03:02:15 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1579, average loss: 0.6591
[09/26 03:02:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 99.00	
[09/26 03:02:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:02:22 visual_prompt]: Epoch 72 / 100: avg data time: 6.71e-02, avg batch time: 0.4806, average train loss: 0.3152
[09/26 03:02:23 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 0.6583
[09/26 03:02:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 03:02:23 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:02:30 visual_prompt]: Epoch 73 / 100: avg data time: 6.19e-02, avg batch time: 0.4746, average train loss: 0.3060
[09/26 03:02:32 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 0.7078
[09/26 03:02:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:02:32 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:02:38 visual_prompt]: Epoch 74 / 100: avg data time: 6.23e-02, avg batch time: 0.4758, average train loss: 0.3166
[09/26 03:02:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 0.7520
[09/26 03:02:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 03:02:40 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:02:47 visual_prompt]: Epoch 75 / 100: avg data time: 6.60e-02, avg batch time: 0.4799, average train loss: 0.3362
[09/26 03:02:48 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1577, average loss: 0.6928
[09/26 03:02:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 03:02:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:02:55 visual_prompt]: Epoch 76 / 100: avg data time: 6.24e-02, avg batch time: 0.4765, average train loss: 0.3248
[09/26 03:02:57 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1582, average loss: 0.7472
[09/26 03:02:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 03:02:57 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:03:03 visual_prompt]: Epoch 77 / 100: avg data time: 5.98e-02, avg batch time: 0.4742, average train loss: 0.3277
[09/26 03:03:05 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1579, average loss: 0.7232
[09/26 03:03:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 03:03:05 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:03:11 visual_prompt]: Epoch 78 / 100: avg data time: 5.26e-02, avg batch time: 0.4667, average train loss: 0.3080
[09/26 03:03:13 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1585, average loss: 0.7154
[09/26 03:03:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 03:03:13 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:03:20 visual_prompt]: Epoch 79 / 100: avg data time: 6.81e-02, avg batch time: 0.4806, average train loss: 0.3094
[09/26 03:03:21 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 0.6823
[09/26 03:03:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 03:03:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:03:28 visual_prompt]: Epoch 80 / 100: avg data time: 6.58e-02, avg batch time: 0.4791, average train loss: 0.3005
[09/26 03:03:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.6772
[09/26 03:03:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 99.00	
[09/26 03:03:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:03:36 visual_prompt]: Epoch 81 / 100: avg data time: 6.99e-02, avg batch time: 0.4845, average train loss: 0.2799
[09/26 03:03:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1578, average loss: 0.6310
[09/26 03:03:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:03:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:03:45 visual_prompt]: Epoch 82 / 100: avg data time: 6.34e-02, avg batch time: 0.4767, average train loss: 0.2676
[09/26 03:03:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1587, average loss: 0.6509
[09/26 03:03:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 03:03:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:03:53 visual_prompt]: Epoch 83 / 100: avg data time: 6.99e-02, avg batch time: 0.4851, average train loss: 0.2528
[09/26 03:03:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1580, average loss: 0.6451
[09/26 03:03:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 99.00	
[09/26 03:03:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:04:02 visual_prompt]: Epoch 84 / 100: avg data time: 6.39e-02, avg batch time: 0.4785, average train loss: 0.2464
[09/26 03:04:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.6569
[09/26 03:04:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 03:04:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:04:10 visual_prompt]: Epoch 85 / 100: avg data time: 6.22e-02, avg batch time: 0.4753, average train loss: 0.2444
[09/26 03:04:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1589, average loss: 0.6541
[09/26 03:04:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 03:04:12 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:04:18 visual_prompt]: Epoch 86 / 100: avg data time: 6.32e-02, avg batch time: 0.4779, average train loss: 0.2423
[09/26 03:04:20 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1586, average loss: 0.6601
[09/26 03:04:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:04:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:04:27 visual_prompt]: Epoch 87 / 100: avg data time: 7.38e-02, avg batch time: 0.4871, average train loss: 0.2398
[09/26 03:04:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1585, average loss: 0.6764
[09/26 03:04:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 03:04:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:04:35 visual_prompt]: Epoch 88 / 100: avg data time: 6.85e-02, avg batch time: 0.4826, average train loss: 0.2367
[09/26 03:04:37 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1583, average loss: 0.6891
[09/26 03:04:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 03:04:37 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:04:43 visual_prompt]: Epoch 89 / 100: avg data time: 6.61e-02, avg batch time: 0.4800, average train loss: 0.2364
[09/26 03:04:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1586, average loss: 0.7050
[09/26 03:04:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 03:04:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:04:52 visual_prompt]: Epoch 90 / 100: avg data time: 6.67e-02, avg batch time: 0.4814, average train loss: 0.2343
[09/26 03:04:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.6806
[09/26 03:04:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 03:04:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:05:00 visual_prompt]: Epoch 91 / 100: avg data time: 6.95e-02, avg batch time: 0.4859, average train loss: 0.2336
[09/26 03:05:02 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1582, average loss: 0.6833
[09/26 03:05:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.00	
[09/26 03:05:02 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:05:08 visual_prompt]: Epoch 92 / 100: avg data time: 6.44e-02, avg batch time: 0.4786, average train loss: 0.2328
[09/26 03:05:10 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1588, average loss: 0.6975
[09/26 03:05:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:05:10 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:05:17 visual_prompt]: Epoch 93 / 100: avg data time: 7.84e-02, avg batch time: 0.4917, average train loss: 0.2319
[09/26 03:05:19 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1583, average loss: 0.6830
[09/26 03:05:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 03:05:19 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:05:25 visual_prompt]: Epoch 94 / 100: avg data time: 6.05e-02, avg batch time: 0.4748, average train loss: 0.2307
[09/26 03:05:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1583, average loss: 0.6965
[09/26 03:05:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:05:27 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:05:34 visual_prompt]: Epoch 95 / 100: avg data time: 7.31e-02, avg batch time: 0.4866, average train loss: 0.2299
[09/26 03:05:35 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1586, average loss: 0.7089
[09/26 03:05:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:05:35 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:05:42 visual_prompt]: Epoch 96 / 100: avg data time: 6.81e-02, avg batch time: 0.4813, average train loss: 0.2297
[09/26 03:05:44 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1581, average loss: 0.6983
[09/26 03:05:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:05:44 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:05:50 visual_prompt]: Epoch 97 / 100: avg data time: 6.33e-02, avg batch time: 0.4775, average train loss: 0.2291
[09/26 03:05:52 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.6993
[09/26 03:05:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:05:52 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:05:59 visual_prompt]: Epoch 98 / 100: avg data time: 7.61e-02, avg batch time: 0.4897, average train loss: 0.2285
[09/26 03:06:00 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 0.7017
[09/26 03:06:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:06:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:06:07 visual_prompt]: Epoch 99 / 100: avg data time: 6.67e-02, avg batch time: 0.4813, average train loss: 0.2289
[09/26 03:06:09 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 0.7026
[09/26 03:06:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:06:09 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:06:15 visual_prompt]: Epoch 100 / 100: avg data time: 5.74e-02, avg batch time: 0.4737, average train loss: 0.2279
[09/26 03:06:17 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1585, average loss: 0.7040
[09/26 03:06:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:06:17 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:06:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:06:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:06:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:06:17 visual_prompt]: Training with config:
[09/26 03:06:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:06:17 visual_prompt]: Loading training data...
[09/26 03:06:17 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:06:18 visual_prompt]: Number of images: 800
[09/26 03:06:18 visual_prompt]: Number of classes: 102 / 102
[09/26 03:06:18 visual_prompt]: Loading validation data...
[09/26 03:06:18 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:06:19 visual_prompt]: Number of images: 200
[09/26 03:06:19 visual_prompt]: Number of classes: 91 / 102
[09/26 03:06:19 visual_prompt]: Constructing models...
[09/26 03:06:21 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 03:06:21 visual_prompt]: tuned percent:0.625
[09/26 03:06:21 visual_prompt]: Device used for model: 0
[09/26 03:06:21 visual_prompt]: Setting up Evaluator...
[09/26 03:06:21 visual_prompt]: Setting up Trainer...
[09/26 03:06:21 visual_prompt]: 	Setting up the optimizer...
[09/26 03:06:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:06:28 visual_prompt]: Epoch 1 / 100: avg data time: 6.78e-02, avg batch time: 0.4901, average train loss: 4.6672
[09/26 03:06:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1583, average loss: 4.6780
[09/26 03:06:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 03:06:30 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:06:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:06:36 visual_prompt]: Epoch 2 / 100: avg data time: 6.69e-02, avg batch time: 0.4802, average train loss: 4.6202
[09/26 03:06:38 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1581, average loss: 4.6162
[09/26 03:06:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 03:06:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:06:45 visual_prompt]: Epoch 3 / 100: avg data time: 6.90e-02, avg batch time: 0.4825, average train loss: 4.4705
[09/26 03:06:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 4.3618
[09/26 03:06:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 21.00	
[09/26 03:06:46 visual_prompt]: Best epoch 3: best metric: 0.030
[09/26 03:06:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:06:53 visual_prompt]: Epoch 4 / 100: avg data time: 6.54e-02, avg batch time: 0.4785, average train loss: 4.0905
[09/26 03:06:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 3.8762
[09/26 03:06:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 35.50	
[09/26 03:06:55 visual_prompt]: Best epoch 4: best metric: 0.120
[09/26 03:06:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:07:01 visual_prompt]: Epoch 5 / 100: avg data time: 6.29e-02, avg batch time: 0.4750, average train loss: 3.1955
[09/26 03:07:03 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1584, average loss: 2.7615
[09/26 03:07:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 38.50	top5: 64.50	
[09/26 03:07:03 visual_prompt]: Best epoch 5: best metric: 0.385
[09/26 03:07:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:07:10 visual_prompt]: Epoch 6 / 100: avg data time: 7.07e-02, avg batch time: 0.4835, average train loss: 1.9682
[09/26 03:07:11 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1583, average loss: 1.5748
[09/26 03:07:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.50	top5: 89.00	
[09/26 03:07:11 visual_prompt]: Best epoch 6: best metric: 0.695
[09/26 03:07:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:07:18 visual_prompt]: Epoch 7 / 100: avg data time: 6.24e-02, avg batch time: 0.4747, average train loss: 0.8846
[09/26 03:07:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 1.1192
[09/26 03:07:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 92.00	
[09/26 03:07:20 visual_prompt]: Best epoch 7: best metric: 0.755
[09/26 03:07:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:07:26 visual_prompt]: Epoch 8 / 100: avg data time: 6.82e-02, avg batch time: 0.4804, average train loss: 0.3975
[09/26 03:07:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1579, average loss: 0.6893
[09/26 03:07:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 95.00	
[09/26 03:07:28 visual_prompt]: Best epoch 8: best metric: 0.835
[09/26 03:07:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:07:35 visual_prompt]: Epoch 9 / 100: avg data time: 6.45e-02, avg batch time: 0.4778, average train loss: 0.1964
[09/26 03:07:37 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 0.6543
[09/26 03:07:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 03:07:37 visual_prompt]: Best epoch 9: best metric: 0.850
[09/26 03:07:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:07:43 visual_prompt]: Epoch 10 / 100: avg data time: 6.43e-02, avg batch time: 0.4781, average train loss: 0.1231
[09/26 03:07:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.5525
[09/26 03:07:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 98.00	
[09/26 03:07:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:07:51 visual_prompt]: Epoch 11 / 100: avg data time: 6.38e-02, avg batch time: 0.4771, average train loss: 0.0992
[09/26 03:07:53 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1579, average loss: 0.5694
[09/26 03:07:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 03:07:53 visual_prompt]: Best epoch 11: best metric: 0.880
[09/26 03:07:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:08:00 visual_prompt]: Epoch 12 / 100: avg data time: 6.54e-02, avg batch time: 0.4790, average train loss: 0.0678
[09/26 03:08:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.5412
[09/26 03:08:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 03:08:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:08:08 visual_prompt]: Epoch 13 / 100: avg data time: 6.27e-02, avg batch time: 0.4748, average train loss: 0.0563
[09/26 03:08:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 0.5047
[09/26 03:08:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 03:08:10 visual_prompt]: Best epoch 13: best metric: 0.915
[09/26 03:08:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:08:16 visual_prompt]: Epoch 14 / 100: avg data time: 6.31e-02, avg batch time: 0.4754, average train loss: 0.0459
[09/26 03:08:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 0.4670
[09/26 03:08:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 03:08:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:08:25 visual_prompt]: Epoch 15 / 100: avg data time: 5.74e-02, avg batch time: 0.4721, average train loss: 0.0423
[09/26 03:08:26 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1580, average loss: 0.5087
[09/26 03:08:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/26 03:08:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:08:33 visual_prompt]: Epoch 16 / 100: avg data time: 6.75e-02, avg batch time: 0.4805, average train loss: 0.0404
[09/26 03:08:35 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1584, average loss: 0.4718
[09/26 03:08:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 03:08:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:08:41 visual_prompt]: Epoch 17 / 100: avg data time: 6.82e-02, avg batch time: 0.4826, average train loss: 0.0403
[09/26 03:08:43 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1583, average loss: 0.4813
[09/26 03:08:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 03:08:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:08:50 visual_prompt]: Epoch 18 / 100: avg data time: 6.96e-02, avg batch time: 0.4821, average train loss: 0.0385
[09/26 03:08:51 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1581, average loss: 0.4291
[09/26 03:08:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.00	
[09/26 03:08:51 visual_prompt]: Best epoch 18: best metric: 0.930
[09/26 03:08:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:08:58 visual_prompt]: Epoch 19 / 100: avg data time: 6.56e-02, avg batch time: 0.4795, average train loss: 0.0400
[09/26 03:09:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1584, average loss: 0.4863
[09/26 03:09:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 03:09:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:09:06 visual_prompt]: Epoch 20 / 100: avg data time: 6.60e-02, avg batch time: 0.4789, average train loss: 0.0521
[09/26 03:09:08 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1577, average loss: 0.4799
[09/26 03:09:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 03:09:08 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:09:15 visual_prompt]: Epoch 21 / 100: avg data time: 7.18e-02, avg batch time: 0.4868, average train loss: 0.0529
[09/26 03:09:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.5022
[09/26 03:09:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.50	
[09/26 03:09:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:09:23 visual_prompt]: Epoch 22 / 100: avg data time: 6.36e-02, avg batch time: 0.4788, average train loss: 0.0516
[09/26 03:09:25 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1587, average loss: 0.5444
[09/26 03:09:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:09:25 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:09:31 visual_prompt]: Epoch 23 / 100: avg data time: 6.07e-02, avg batch time: 0.4738, average train loss: 0.0834
[09/26 03:09:33 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1585, average loss: 0.6728
[09/26 03:09:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.50	
[09/26 03:09:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:09:40 visual_prompt]: Epoch 24 / 100: avg data time: 6.70e-02, avg batch time: 0.4806, average train loss: 0.1862
[09/26 03:09:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 1.0391
[09/26 03:09:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 92.00	
[09/26 03:09:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:09:48 visual_prompt]: Epoch 25 / 100: avg data time: 6.46e-02, avg batch time: 0.4779, average train loss: 0.3260
[09/26 03:09:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 0.6240
[09/26 03:09:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:09:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:09:56 visual_prompt]: Epoch 26 / 100: avg data time: 6.95e-02, avg batch time: 0.4833, average train loss: 0.2004
[09/26 03:09:58 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1588, average loss: 0.5175
[09/26 03:09:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 03:09:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:10:05 visual_prompt]: Epoch 27 / 100: avg data time: 6.60e-02, avg batch time: 0.4790, average train loss: 0.0891
[09/26 03:10:06 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 0.4170
[09/26 03:10:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.50	
[09/26 03:10:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:10:13 visual_prompt]: Epoch 28 / 100: avg data time: 6.87e-02, avg batch time: 0.4813, average train loss: 0.0543
[09/26 03:10:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1587, average loss: 0.4408
[09/26 03:10:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.50	
[09/26 03:10:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:10:21 visual_prompt]: Epoch 29 / 100: avg data time: 6.42e-02, avg batch time: 0.4784, average train loss: 0.0388
[09/26 03:10:23 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 0.3764
[09/26 03:10:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 03:10:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:10:30 visual_prompt]: Epoch 30 / 100: avg data time: 6.85e-02, avg batch time: 0.4818, average train loss: 0.0309
[09/26 03:10:31 visual_prompt]: Inference (val):avg data time: 4.48e-05, avg batch time: 0.1580, average loss: 0.3763
[09/26 03:10:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 03:10:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:10:38 visual_prompt]: Epoch 31 / 100: avg data time: 6.17e-02, avg batch time: 0.4765, average train loss: 0.0290
[09/26 03:10:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1579, average loss: 0.3658
[09/26 03:10:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:10:40 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:10:46 visual_prompt]: Epoch 32 / 100: avg data time: 5.29e-02, avg batch time: 0.4673, average train loss: 0.0284
[09/26 03:10:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1587, average loss: 0.3740
[09/26 03:10:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 03:10:48 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:10:54 visual_prompt]: Epoch 33 / 100: avg data time: 6.49e-02, avg batch time: 0.4784, average train loss: 0.0297
[09/26 03:10:56 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1580, average loss: 0.3766
[09/26 03:10:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 03:10:56 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:11:03 visual_prompt]: Epoch 34 / 100: avg data time: 7.14e-02, avg batch time: 0.4854, average train loss: 0.0305
[09/26 03:11:05 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1583, average loss: 0.3792
[09/26 03:11:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 03:11:05 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:11:11 visual_prompt]: Epoch 35 / 100: avg data time: 6.95e-02, avg batch time: 0.4827, average train loss: 0.0318
[09/26 03:11:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 0.3814
[09/26 03:11:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 03:11:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:11:20 visual_prompt]: Epoch 36 / 100: avg data time: 6.36e-02, avg batch time: 0.4797, average train loss: 0.0322
[09/26 03:11:21 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1585, average loss: 0.3742
[09/26 03:11:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 03:11:21 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:11:28 visual_prompt]: Epoch 37 / 100: avg data time: 6.64e-02, avg batch time: 0.4804, average train loss: 0.0325
[09/26 03:11:30 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1588, average loss: 0.3891
[09/26 03:11:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 03:11:30 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:11:36 visual_prompt]: Epoch 38 / 100: avg data time: 5.33e-02, avg batch time: 0.4678, average train loss: 0.0331
[09/26 03:11:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.3963
[09/26 03:11:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 03:11:38 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:11:44 visual_prompt]: Epoch 39 / 100: avg data time: 6.75e-02, avg batch time: 0.4815, average train loss: 0.0331
[09/26 03:11:46 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.3712
[09/26 03:11:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 03:11:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:11:53 visual_prompt]: Epoch 40 / 100: avg data time: 6.32e-02, avg batch time: 0.4770, average train loss: 0.0331
[09/26 03:11:54 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1597, average loss: 0.3893
[09/26 03:11:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 03:11:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:12:01 visual_prompt]: Epoch 41 / 100: avg data time: 7.14e-02, avg batch time: 0.4846, average train loss: 0.0330
[09/26 03:12:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 0.3832
[09/26 03:12:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 03:12:03 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:12:09 visual_prompt]: Epoch 42 / 100: avg data time: 6.69e-02, avg batch time: 0.4799, average train loss: 0.0330
[09/26 03:12:11 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 0.3908
[09/26 03:12:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 03:12:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:12:18 visual_prompt]: Epoch 43 / 100: avg data time: 6.45e-02, avg batch time: 0.4785, average train loss: 0.0328
[09/26 03:12:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.3786
[09/26 03:12:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 03:12:19 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:12:26 visual_prompt]: Epoch 44 / 100: avg data time: 6.75e-02, avg batch time: 0.4813, average train loss: 0.0322
[09/26 03:12:28 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1585, average loss: 0.3589
[09/26 03:12:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 03:12:28 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:12:34 visual_prompt]: Epoch 45 / 100: avg data time: 6.41e-02, avg batch time: 0.4780, average train loss: 0.0319
[09/26 03:12:36 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1582, average loss: 0.3708
[09/26 03:12:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 03:12:36 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:12:43 visual_prompt]: Epoch 46 / 100: avg data time: 6.78e-02, avg batch time: 0.4837, average train loss: 0.0501
[09/26 03:12:45 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.6050
[09/26 03:12:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 03:12:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:12:51 visual_prompt]: Epoch 47 / 100: avg data time: 7.22e-02, avg batch time: 0.4856, average train loss: 0.2185
[09/26 03:12:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1584, average loss: 1.1674
[09/26 03:12:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 91.50	
[09/26 03:12:53 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:13:00 visual_prompt]: Epoch 48 / 100: avg data time: 6.63e-02, avg batch time: 0.4804, average train loss: 0.9729
[09/26 03:13:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1585, average loss: 0.6739
[09/26 03:13:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 03:13:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:13:08 visual_prompt]: Epoch 49 / 100: avg data time: 6.66e-02, avg batch time: 0.4803, average train loss: 0.2755
[09/26 03:13:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 0.4594
[09/26 03:13:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.00	
[09/26 03:13:10 visual_prompt]: Best epoch 49: best metric: 0.940
[09/26 03:13:10 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:13:16 visual_prompt]: Epoch 50 / 100: avg data time: 6.61e-02, avg batch time: 0.4811, average train loss: 0.1187
[09/26 03:13:18 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1588, average loss: 0.3850
[09/26 03:13:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 03:13:18 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:13:24 visual_prompt]: Epoch 51 / 100: avg data time: 5.28e-02, avg batch time: 0.4677, average train loss: 0.0663
[09/26 03:13:26 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1586, average loss: 0.3514
[09/26 03:13:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 03:13:26 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:13:33 visual_prompt]: Epoch 52 / 100: avg data time: 7.13e-02, avg batch time: 0.4858, average train loss: 0.0426
[09/26 03:13:35 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1585, average loss: 0.3071
[09/26 03:13:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.00	
[09/26 03:13:35 visual_prompt]: Best epoch 52: best metric: 0.955
[09/26 03:13:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:13:41 visual_prompt]: Epoch 53 / 100: avg data time: 7.30e-02, avg batch time: 0.4876, average train loss: 0.0341
[09/26 03:13:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 0.3089
[09/26 03:13:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.00	
[09/26 03:13:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:13:50 visual_prompt]: Epoch 54 / 100: avg data time: 6.09e-02, avg batch time: 0.4765, average train loss: 0.0296
[09/26 03:13:51 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1580, average loss: 0.3124
[09/26 03:13:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 03:13:51 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:13:58 visual_prompt]: Epoch 55 / 100: avg data time: 6.74e-02, avg batch time: 0.4808, average train loss: 0.0289
[09/26 03:14:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1587, average loss: 0.3116
[09/26 03:14:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 98.00	
[09/26 03:14:00 visual_prompt]: Best epoch 55: best metric: 0.960
[09/26 03:14:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:14:06 visual_prompt]: Epoch 56 / 100: avg data time: 5.66e-02, avg batch time: 0.4734, average train loss: 0.0288
[09/26 03:14:08 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1585, average loss: 0.3045
[09/26 03:14:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 97.50	
[09/26 03:14:08 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:14:15 visual_prompt]: Epoch 57 / 100: avg data time: 5.86e-02, avg batch time: 0.4747, average train loss: 0.0284
[09/26 03:14:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1585, average loss: 0.3039
[09/26 03:14:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 03:14:16 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:14:23 visual_prompt]: Epoch 58 / 100: avg data time: 5.94e-02, avg batch time: 0.4744, average train loss: 0.0287
[09/26 03:14:25 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1587, average loss: 0.3130
[09/26 03:14:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:14:25 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:14:31 visual_prompt]: Epoch 59 / 100: avg data time: 7.18e-02, avg batch time: 0.4853, average train loss: 0.0288
[09/26 03:14:33 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1585, average loss: 0.3107
[09/26 03:14:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 96.00	top5: 98.50	
[09/26 03:14:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:14:40 visual_prompt]: Epoch 60 / 100: avg data time: 6.76e-02, avg batch time: 0.4820, average train loss: 0.0293
[09/26 03:14:41 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1581, average loss: 0.3129
[09/26 03:14:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:14:41 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:14:48 visual_prompt]: Epoch 61 / 100: avg data time: 5.79e-02, avg batch time: 0.4729, average train loss: 0.0295
[09/26 03:14:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 0.3140
[09/26 03:14:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:14:50 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:14:56 visual_prompt]: Epoch 62 / 100: avg data time: 6.85e-02, avg batch time: 0.4831, average train loss: 0.0296
[09/26 03:14:58 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1586, average loss: 0.3216
[09/26 03:14:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:14:58 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:15:05 visual_prompt]: Epoch 63 / 100: avg data time: 7.08e-02, avg batch time: 0.4856, average train loss: 0.0299
[09/26 03:15:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.3157
[09/26 03:15:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.00	
[09/26 03:15:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:15:13 visual_prompt]: Epoch 64 / 100: avg data time: 6.25e-02, avg batch time: 0.4783, average train loss: 0.0300
[09/26 03:15:15 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 0.3164
[09/26 03:15:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:15:15 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:15:21 visual_prompt]: Epoch 65 / 100: avg data time: 6.30e-02, avg batch time: 0.4775, average train loss: 0.0302
[09/26 03:15:23 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 0.3181
[09/26 03:15:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 03:15:23 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:15:30 visual_prompt]: Epoch 66 / 100: avg data time: 6.59e-02, avg batch time: 0.4794, average train loss: 0.0299
[09/26 03:15:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 0.3203
[09/26 03:15:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:15:32 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:15:38 visual_prompt]: Epoch 67 / 100: avg data time: 6.97e-02, avg batch time: 0.4831, average train loss: 0.0305
[09/26 03:15:40 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1584, average loss: 0.3175
[09/26 03:15:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:15:40 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:15:47 visual_prompt]: Epoch 68 / 100: avg data time: 7.39e-02, avg batch time: 0.4878, average train loss: 0.0303
[09/26 03:15:48 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 0.3239
[09/26 03:15:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:15:48 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:15:55 visual_prompt]: Epoch 69 / 100: avg data time: 7.21e-02, avg batch time: 0.4859, average train loss: 0.0304
[09/26 03:15:57 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.3199
[09/26 03:15:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:15:57 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:16:04 visual_prompt]: Epoch 70 / 100: avg data time: 6.57e-02, avg batch time: 0.4803, average train loss: 0.0300
[09/26 03:16:05 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.3198
[09/26 03:16:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:16:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:16:12 visual_prompt]: Epoch 71 / 100: avg data time: 6.21e-02, avg batch time: 0.4776, average train loss: 0.0300
[09/26 03:16:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.3197
[09/26 03:16:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:16:14 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:16:20 visual_prompt]: Epoch 72 / 100: avg data time: 6.82e-02, avg batch time: 0.4817, average train loss: 0.0304
[09/26 03:16:22 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1584, average loss: 0.3196
[09/26 03:16:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:16:22 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:16:29 visual_prompt]: Epoch 73 / 100: avg data time: 6.64e-02, avg batch time: 0.4803, average train loss: 0.0302
[09/26 03:16:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1587, average loss: 0.3160
[09/26 03:16:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.50	
[09/26 03:16:30 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:16:37 visual_prompt]: Epoch 74 / 100: avg data time: 7.20e-02, avg batch time: 0.4866, average train loss: 0.0303
[09/26 03:16:39 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1589, average loss: 0.3214
[09/26 03:16:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:16:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:16:45 visual_prompt]: Epoch 75 / 100: avg data time: 6.90e-02, avg batch time: 0.4822, average train loss: 0.0299
[09/26 03:16:47 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1588, average loss: 0.3168
[09/26 03:16:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:16:47 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:16:54 visual_prompt]: Epoch 76 / 100: avg data time: 7.06e-02, avg batch time: 0.4837, average train loss: 0.0297
[09/26 03:16:56 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1586, average loss: 0.3204
[09/26 03:16:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:16:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:17:02 visual_prompt]: Epoch 77 / 100: avg data time: 7.37e-02, avg batch time: 0.4868, average train loss: 0.0300
[09/26 03:17:04 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1587, average loss: 0.3316
[09/26 03:17:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:17:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:17:11 visual_prompt]: Epoch 78 / 100: avg data time: 6.68e-02, avg batch time: 0.4810, average train loss: 0.0299
[09/26 03:17:13 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1585, average loss: 0.3282
[09/26 03:17:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:17:13 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:17:19 visual_prompt]: Epoch 79 / 100: avg data time: 6.42e-02, avg batch time: 0.4800, average train loss: 0.0299
[09/26 03:17:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1588, average loss: 0.3316
[09/26 03:17:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:17:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:17:27 visual_prompt]: Epoch 80 / 100: avg data time: 6.41e-02, avg batch time: 0.4787, average train loss: 0.0296
[09/26 03:17:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.3281
[09/26 03:17:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:17:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:17:36 visual_prompt]: Epoch 81 / 100: avg data time: 7.45e-02, avg batch time: 0.4872, average train loss: 0.0296
[09/26 03:17:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1585, average loss: 0.3236
[09/26 03:17:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:17:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:17:44 visual_prompt]: Epoch 82 / 100: avg data time: 6.07e-02, avg batch time: 0.4744, average train loss: 0.0295
[09/26 03:17:46 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1581, average loss: 0.3274
[09/26 03:17:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 03:17:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:17:52 visual_prompt]: Epoch 83 / 100: avg data time: 6.98e-02, avg batch time: 0.4833, average train loss: 0.0297
[09/26 03:17:54 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1582, average loss: 0.3242
[09/26 03:17:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:17:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:18:01 visual_prompt]: Epoch 84 / 100: avg data time: 5.81e-02, avg batch time: 0.4738, average train loss: 0.0297
[09/26 03:18:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1583, average loss: 0.3232
[09/26 03:18:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:18:02 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:18:09 visual_prompt]: Epoch 85 / 100: avg data time: 6.39e-02, avg batch time: 0.4776, average train loss: 0.0295
[09/26 03:18:11 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1586, average loss: 0.3232
[09/26 03:18:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:18:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:18:17 visual_prompt]: Epoch 86 / 100: avg data time: 7.02e-02, avg batch time: 0.4843, average train loss: 0.0296
[09/26 03:18:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.3238
[09/26 03:18:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:18:19 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:18:26 visual_prompt]: Epoch 87 / 100: avg data time: 6.71e-02, avg batch time: 0.4819, average train loss: 0.0296
[09/26 03:18:27 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 0.3268
[09/26 03:18:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:18:27 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:18:34 visual_prompt]: Epoch 88 / 100: avg data time: 6.89e-02, avg batch time: 0.4820, average train loss: 0.0293
[09/26 03:18:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1589, average loss: 0.3272
[09/26 03:18:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:18:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:18:42 visual_prompt]: Epoch 89 / 100: avg data time: 6.98e-02, avg batch time: 0.4837, average train loss: 0.0296
[09/26 03:18:44 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1587, average loss: 0.3254
[09/26 03:18:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:18:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:18:51 visual_prompt]: Epoch 90 / 100: avg data time: 6.35e-02, avg batch time: 0.4785, average train loss: 0.0296
[09/26 03:18:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 0.3254
[09/26 03:18:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:18:52 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:18:59 visual_prompt]: Epoch 91 / 100: avg data time: 6.92e-02, avg batch time: 0.4831, average train loss: 0.0295
[09/26 03:19:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1587, average loss: 0.3247
[09/26 03:19:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:01 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:19:07 visual_prompt]: Epoch 92 / 100: avg data time: 6.43e-02, avg batch time: 0.4778, average train loss: 0.0295
[09/26 03:19:09 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1582, average loss: 0.3249
[09/26 03:19:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:19:16 visual_prompt]: Epoch 93 / 100: avg data time: 6.41e-02, avg batch time: 0.4783, average train loss: 0.0295
[09/26 03:19:17 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1588, average loss: 0.3259
[09/26 03:19:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:19:24 visual_prompt]: Epoch 94 / 100: avg data time: 6.74e-02, avg batch time: 0.4824, average train loss: 0.0294
[09/26 03:19:26 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1585, average loss: 0.3256
[09/26 03:19:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:26 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:19:33 visual_prompt]: Epoch 95 / 100: avg data time: 7.24e-02, avg batch time: 0.4861, average train loss: 0.0294
[09/26 03:19:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1585, average loss: 0.3247
[09/26 03:19:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:19:41 visual_prompt]: Epoch 96 / 100: avg data time: 7.00e-02, avg batch time: 0.4836, average train loss: 0.0293
[09/26 03:19:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.3248
[09/26 03:19:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:43 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:19:49 visual_prompt]: Epoch 97 / 100: avg data time: 6.52e-02, avg batch time: 0.4792, average train loss: 0.0292
[09/26 03:19:51 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1581, average loss: 0.3249
[09/26 03:19:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:51 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:19:58 visual_prompt]: Epoch 98 / 100: avg data time: 6.75e-02, avg batch time: 0.4812, average train loss: 0.0294
[09/26 03:19:59 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1587, average loss: 0.3250
[09/26 03:19:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:19:59 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:20:06 visual_prompt]: Epoch 99 / 100: avg data time: 5.17e-02, avg batch time: 0.4664, average train loss: 0.0294
[09/26 03:20:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1583, average loss: 0.3250
[09/26 03:20:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:20:08 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:20:14 visual_prompt]: Epoch 100 / 100: avg data time: 7.21e-02, avg batch time: 0.4859, average train loss: 0.0293
[09/26 03:20:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1589, average loss: 0.3250
[09/26 03:20:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:20:16 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:20:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:20:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:20:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:20:16 visual_prompt]: Training with config:
[09/26 03:20:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:20:16 visual_prompt]: Loading training data...
[09/26 03:20:16 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:20:17 visual_prompt]: Number of images: 800
[09/26 03:20:17 visual_prompt]: Number of classes: 102 / 102
[09/26 03:20:17 visual_prompt]: Loading validation data...
[09/26 03:20:17 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:20:18 visual_prompt]: Number of images: 200
[09/26 03:20:18 visual_prompt]: Number of classes: 91 / 102
[09/26 03:20:18 visual_prompt]: Constructing models...
[09/26 03:20:20 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 03:20:20 visual_prompt]: tuned percent:0.625
[09/26 03:20:20 visual_prompt]: Device used for model: 0
[09/26 03:20:20 visual_prompt]: Setting up Evaluator...
[09/26 03:20:20 visual_prompt]: Setting up Trainer...
[09/26 03:20:20 visual_prompt]: 	Setting up the optimizer...
[09/26 03:20:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:20:27 visual_prompt]: Epoch 1 / 100: avg data time: 7.09e-02, avg batch time: 0.4878, average train loss: 4.6730
[09/26 03:20:29 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1587, average loss: 4.6780
[09/26 03:20:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 03:20:29 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:20:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:20:35 visual_prompt]: Epoch 2 / 100: avg data time: 7.31e-02, avg batch time: 0.4862, average train loss: 4.6102
[09/26 03:20:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 4.5628
[09/26 03:20:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 10.00	
[09/26 03:20:37 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 03:20:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:20:44 visual_prompt]: Epoch 3 / 100: avg data time: 5.87e-02, avg batch time: 0.4716, average train loss: 4.4349
[09/26 03:20:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 4.3080
[09/26 03:20:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 6.50	top5: 21.00	
[09/26 03:20:45 visual_prompt]: Best epoch 3: best metric: 0.065
[09/26 03:20:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:20:52 visual_prompt]: Epoch 4 / 100: avg data time: 6.49e-02, avg batch time: 0.4772, average train loss: 3.9529
[09/26 03:20:54 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1578, average loss: 3.8909
[09/26 03:20:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 13.50	top5: 34.00	
[09/26 03:20:54 visual_prompt]: Best epoch 4: best metric: 0.135
[09/26 03:20:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:21:00 visual_prompt]: Epoch 5 / 100: avg data time: 7.17e-02, avg batch time: 0.4849, average train loss: 3.1125
[09/26 03:21:02 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1580, average loss: 2.8266
[09/26 03:21:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 35.00	top5: 66.00	
[09/26 03:21:02 visual_prompt]: Best epoch 5: best metric: 0.350
[09/26 03:21:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:21:09 visual_prompt]: Epoch 6 / 100: avg data time: 6.03e-02, avg batch time: 0.4730, average train loss: 1.9375
[09/26 03:21:10 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1586, average loss: 1.6121
[09/26 03:21:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.00	top5: 85.00	
[09/26 03:21:10 visual_prompt]: Best epoch 6: best metric: 0.640
[09/26 03:21:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:21:17 visual_prompt]: Epoch 7 / 100: avg data time: 6.66e-02, avg batch time: 0.4813, average train loss: 0.9123
[09/26 03:21:19 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 0.9542
[09/26 03:21:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 93.50	
[09/26 03:21:19 visual_prompt]: Best epoch 7: best metric: 0.795
[09/26 03:21:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:21:25 visual_prompt]: Epoch 8 / 100: avg data time: 6.50e-02, avg batch time: 0.4786, average train loss: 0.3781
[09/26 03:21:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 0.7057
[09/26 03:21:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.00	
[09/26 03:21:27 visual_prompt]: Best epoch 8: best metric: 0.850
[09/26 03:21:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:21:34 visual_prompt]: Epoch 9 / 100: avg data time: 7.17e-02, avg batch time: 0.4853, average train loss: 0.1939
[09/26 03:21:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1586, average loss: 0.6319
[09/26 03:21:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.50	
[09/26 03:21:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:21:42 visual_prompt]: Epoch 10 / 100: avg data time: 5.47e-02, avg batch time: 0.4688, average train loss: 0.1395
[09/26 03:21:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 0.6114
[09/26 03:21:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 03:21:44 visual_prompt]: Best epoch 10: best metric: 0.870
[09/26 03:21:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:21:50 visual_prompt]: Epoch 11 / 100: avg data time: 6.50e-02, avg batch time: 0.4788, average train loss: 0.0948
[09/26 03:21:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1585, average loss: 0.5796
[09/26 03:21:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.00	
[09/26 03:21:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:21:59 visual_prompt]: Epoch 12 / 100: avg data time: 6.33e-02, avg batch time: 0.4776, average train loss: 0.0641
[09/26 03:22:00 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1585, average loss: 0.5653
[09/26 03:22:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 95.00	
[09/26 03:22:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:22:07 visual_prompt]: Epoch 13 / 100: avg data time: 6.36e-02, avg batch time: 0.4773, average train loss: 0.0275
[09/26 03:22:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.5409
[09/26 03:22:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:22:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:22:15 visual_prompt]: Epoch 14 / 100: avg data time: 7.21e-02, avg batch time: 0.4854, average train loss: 0.0183
[09/26 03:22:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1585, average loss: 0.5295
[09/26 03:22:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:22:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:22:24 visual_prompt]: Epoch 15 / 100: avg data time: 6.74e-02, avg batch time: 0.4817, average train loss: 0.0143
[09/26 03:22:25 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 0.5223
[09/26 03:22:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 03:22:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:22:32 visual_prompt]: Epoch 16 / 100: avg data time: 5.30e-02, avg batch time: 0.4666, average train loss: 0.0117
[09/26 03:22:34 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1578, average loss: 0.5243
[09/26 03:22:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 03:22:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:22:40 visual_prompt]: Epoch 17 / 100: avg data time: 6.00e-02, avg batch time: 0.4740, average train loss: 0.0213
[09/26 03:22:42 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.5209
[09/26 03:22:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 03:22:42 visual_prompt]: Best epoch 17: best metric: 0.875
[09/26 03:22:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:22:49 visual_prompt]: Epoch 18 / 100: avg data time: 6.20e-02, avg batch time: 0.4755, average train loss: 0.0114
[09/26 03:22:50 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 0.5286
[09/26 03:22:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 95.50	
[09/26 03:22:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:22:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.79e-02, avg batch time: 0.4814, average train loss: 0.0092
[09/26 03:22:59 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1580, average loss: 0.4912
[09/26 03:22:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 03:22:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:23:05 visual_prompt]: Epoch 20 / 100: avg data time: 6.37e-02, avg batch time: 0.4771, average train loss: 0.0084
[09/26 03:23:07 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1582, average loss: 0.4844
[09/26 03:23:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 03:23:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:23:14 visual_prompt]: Epoch 21 / 100: avg data time: 7.05e-02, avg batch time: 0.4846, average train loss: 0.0078
[09/26 03:23:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1584, average loss: 0.4727
[09/26 03:23:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:23:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:23:22 visual_prompt]: Epoch 22 / 100: avg data time: 6.20e-02, avg batch time: 0.4754, average train loss: 0.0073
[09/26 03:23:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1588, average loss: 0.4725
[09/26 03:23:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:23:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:23:30 visual_prompt]: Epoch 23 / 100: avg data time: 6.80e-02, avg batch time: 0.4821, average train loss: 0.0068
[09/26 03:23:32 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1587, average loss: 0.4837
[09/26 03:23:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 03:23:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:23:39 visual_prompt]: Epoch 24 / 100: avg data time: 6.04e-02, avg batch time: 0.4747, average train loss: 0.0068
[09/26 03:23:41 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1587, average loss: 0.4811
[09/26 03:23:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 03:23:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:23:47 visual_prompt]: Epoch 25 / 100: avg data time: 5.44e-02, avg batch time: 0.4695, average train loss: 0.0066
[09/26 03:23:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 0.4838
[09/26 03:23:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:23:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:23:55 visual_prompt]: Epoch 26 / 100: avg data time: 6.27e-02, avg batch time: 0.4762, average train loss: 0.0062
[09/26 03:23:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1586, average loss: 0.4774
[09/26 03:23:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:23:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:24:04 visual_prompt]: Epoch 27 / 100: avg data time: 6.79e-02, avg batch time: 0.4810, average train loss: 0.0060
[09/26 03:24:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 0.4686
[09/26 03:24:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 03:24:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:24:12 visual_prompt]: Epoch 28 / 100: avg data time: 6.06e-02, avg batch time: 0.4751, average train loss: 0.0058
[09/26 03:24:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.4681
[09/26 03:24:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:24:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:24:20 visual_prompt]: Epoch 29 / 100: avg data time: 6.16e-02, avg batch time: 0.4759, average train loss: 0.0057
[09/26 03:24:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 0.4674
[09/26 03:24:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:24:22 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:24:28 visual_prompt]: Epoch 30 / 100: avg data time: 6.50e-02, avg batch time: 0.4780, average train loss: 0.0056
[09/26 03:24:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1597, average loss: 0.4685
[09/26 03:24:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:24:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:24:37 visual_prompt]: Epoch 31 / 100: avg data time: 6.79e-02, avg batch time: 0.4818, average train loss: 0.0055
[09/26 03:24:38 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1581, average loss: 0.4632
[09/26 03:24:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:24:38 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:24:45 visual_prompt]: Epoch 32 / 100: avg data time: 6.50e-02, avg batch time: 0.4793, average train loss: 0.0055
[09/26 03:24:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1585, average loss: 0.4660
[09/26 03:24:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:24:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:24:53 visual_prompt]: Epoch 33 / 100: avg data time: 5.50e-02, avg batch time: 0.4696, average train loss: 0.0056
[09/26 03:24:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.4660
[09/26 03:24:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:24:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:25:02 visual_prompt]: Epoch 34 / 100: avg data time: 6.91e-02, avg batch time: 0.4822, average train loss: 0.0054
[09/26 03:25:03 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1588, average loss: 0.4627
[09/26 03:25:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:25:03 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:25:10 visual_prompt]: Epoch 35 / 100: avg data time: 7.08e-02, avg batch time: 0.4845, average train loss: 0.0053
[09/26 03:25:12 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1581, average loss: 0.4570
[09/26 03:25:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:25:12 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:25:18 visual_prompt]: Epoch 36 / 100: avg data time: 7.03e-02, avg batch time: 0.4847, average train loss: 0.0052
[09/26 03:25:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.4563
[09/26 03:25:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:25:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:25:27 visual_prompt]: Epoch 37 / 100: avg data time: 5.64e-02, avg batch time: 0.4718, average train loss: 0.0050
[09/26 03:25:28 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1580, average loss: 0.4560
[09/26 03:25:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:25:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:25:35 visual_prompt]: Epoch 38 / 100: avg data time: 7.67e-02, avg batch time: 0.4894, average train loss: 0.0050
[09/26 03:25:37 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.1585, average loss: 0.4572
[09/26 03:25:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:25:37 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:25:43 visual_prompt]: Epoch 39 / 100: avg data time: 6.14e-02, avg batch time: 0.4754, average train loss: 0.0050
[09/26 03:25:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1586, average loss: 0.4550
[09/26 03:25:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:25:45 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:25:52 visual_prompt]: Epoch 40 / 100: avg data time: 6.88e-02, avg batch time: 0.4818, average train loss: 0.0050
[09/26 03:25:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 0.4555
[09/26 03:25:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:25:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:26:00 visual_prompt]: Epoch 41 / 100: avg data time: 6.38e-02, avg batch time: 0.4791, average train loss: 0.0050
[09/26 03:26:02 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1583, average loss: 0.4552
[09/26 03:26:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:26:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:26:08 visual_prompt]: Epoch 42 / 100: avg data time: 6.39e-02, avg batch time: 0.4790, average train loss: 0.0050
[09/26 03:26:10 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1586, average loss: 0.4576
[09/26 03:26:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:26:10 visual_prompt]: Best epoch 42: best metric: 0.880
[09/26 03:26:10 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:26:17 visual_prompt]: Epoch 43 / 100: avg data time: 6.61e-02, avg batch time: 0.4793, average train loss: 0.0049
[09/26 03:26:19 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1581, average loss: 0.4558
[09/26 03:26:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:26:19 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:26:25 visual_prompt]: Epoch 44 / 100: avg data time: 6.87e-02, avg batch time: 0.4822, average train loss: 0.0050
[09/26 03:26:27 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1585, average loss: 0.4522
[09/26 03:26:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:26:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:26:34 visual_prompt]: Epoch 45 / 100: avg data time: 6.54e-02, avg batch time: 0.4782, average train loss: 0.0048
[09/26 03:26:35 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1584, average loss: 0.4560
[09/26 03:26:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:26:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:26:42 visual_prompt]: Epoch 46 / 100: avg data time: 6.79e-02, avg batch time: 0.4811, average train loss: 0.0049
[09/26 03:26:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1587, average loss: 0.4557
[09/26 03:26:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:26:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:26:50 visual_prompt]: Epoch 47 / 100: avg data time: 5.56e-02, avg batch time: 0.4703, average train loss: 0.0049
[09/26 03:26:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1580, average loss: 0.4519
[09/26 03:26:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:26:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:26:58 visual_prompt]: Epoch 48 / 100: avg data time: 5.61e-02, avg batch time: 0.4708, average train loss: 0.0048
[09/26 03:27:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 0.4473
[09/26 03:27:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:27:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:27:07 visual_prompt]: Epoch 49 / 100: avg data time: 6.62e-02, avg batch time: 0.4802, average train loss: 0.0047
[09/26 03:27:08 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1580, average loss: 0.4489
[09/26 03:27:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:27:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:27:15 visual_prompt]: Epoch 50 / 100: avg data time: 5.56e-02, avg batch time: 0.4699, average train loss: 0.0047
[09/26 03:27:17 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1580, average loss: 0.4484
[09/26 03:27:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:27:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:27:23 visual_prompt]: Epoch 51 / 100: avg data time: 5.75e-02, avg batch time: 0.4721, average train loss: 0.0048
[09/26 03:27:25 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 0.4473
[09/26 03:27:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:27:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:27:31 visual_prompt]: Epoch 52 / 100: avg data time: 5.45e-02, avg batch time: 0.4681, average train loss: 0.0047
[09/26 03:27:33 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.4447
[09/26 03:27:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:27:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:27:40 visual_prompt]: Epoch 53 / 100: avg data time: 6.62e-02, avg batch time: 0.4791, average train loss: 0.0048
[09/26 03:27:42 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1578, average loss: 0.4436
[09/26 03:27:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:27:42 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:27:48 visual_prompt]: Epoch 54 / 100: avg data time: 6.90e-02, avg batch time: 0.4814, average train loss: 0.0047
[09/26 03:27:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1583, average loss: 0.4451
[09/26 03:27:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:27:50 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:27:56 visual_prompt]: Epoch 55 / 100: avg data time: 5.18e-02, avg batch time: 0.4654, average train loss: 0.0047
[09/26 03:27:58 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 0.4457
[09/26 03:27:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:27:58 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:28:05 visual_prompt]: Epoch 56 / 100: avg data time: 6.71e-02, avg batch time: 0.4806, average train loss: 0.0047
[09/26 03:28:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.4443
[09/26 03:28:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:28:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:28:13 visual_prompt]: Epoch 57 / 100: avg data time: 5.98e-02, avg batch time: 0.4730, average train loss: 0.0047
[09/26 03:28:15 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1579, average loss: 0.4414
[09/26 03:28:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:28:15 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:28:21 visual_prompt]: Epoch 58 / 100: avg data time: 6.81e-02, avg batch time: 0.4806, average train loss: 0.0047
[09/26 03:28:23 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1586, average loss: 0.4410
[09/26 03:28:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.50	
[09/26 03:28:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:28:30 visual_prompt]: Epoch 59 / 100: avg data time: 6.43e-02, avg batch time: 0.4796, average train loss: 0.0047
[09/26 03:28:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 0.4416
[09/26 03:28:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:28:31 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:28:38 visual_prompt]: Epoch 60 / 100: avg data time: 6.43e-02, avg batch time: 0.4765, average train loss: 0.0046
[09/26 03:28:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1575, average loss: 0.4389
[09/26 03:28:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:28:40 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:28:46 visual_prompt]: Epoch 61 / 100: avg data time: 7.08e-02, avg batch time: 0.4838, average train loss: 0.0046
[09/26 03:28:48 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1583, average loss: 0.4383
[09/26 03:28:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:28:48 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:28:55 visual_prompt]: Epoch 62 / 100: avg data time: 6.09e-02, avg batch time: 0.4743, average train loss: 0.0046
[09/26 03:28:56 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 0.4400
[09/26 03:28:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:28:56 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:29:03 visual_prompt]: Epoch 63 / 100: avg data time: 5.87e-02, avg batch time: 0.4730, average train loss: 0.0046
[09/26 03:29:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1578, average loss: 0.4405
[09/26 03:29:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.00	
[09/26 03:29:05 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:29:11 visual_prompt]: Epoch 64 / 100: avg data time: 6.04e-02, avg batch time: 0.4729, average train loss: 0.0046
[09/26 03:29:13 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1579, average loss: 0.4420
[09/26 03:29:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:29:13 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:29:20 visual_prompt]: Epoch 65 / 100: avg data time: 6.34e-02, avg batch time: 0.4782, average train loss: 0.0046
[09/26 03:29:21 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 0.4397
[09/26 03:29:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:29:21 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:29:28 visual_prompt]: Epoch 66 / 100: avg data time: 6.73e-02, avg batch time: 0.4805, average train loss: 0.0046
[09/26 03:29:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1582, average loss: 0.4372
[09/26 03:29:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:29:30 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:29:36 visual_prompt]: Epoch 67 / 100: avg data time: 6.80e-02, avg batch time: 0.4806, average train loss: 0.0045
[09/26 03:29:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 0.4367
[09/26 03:29:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:29:38 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:29:45 visual_prompt]: Epoch 68 / 100: avg data time: 6.58e-02, avg batch time: 0.4789, average train loss: 0.0045
[09/26 03:29:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1577, average loss: 0.4363
[09/26 03:29:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:29:46 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:29:53 visual_prompt]: Epoch 69 / 100: avg data time: 6.41e-02, avg batch time: 0.4767, average train loss: 0.0046
[09/26 03:29:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.4369
[09/26 03:29:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 03:29:55 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:30:01 visual_prompt]: Epoch 70 / 100: avg data time: 6.43e-02, avg batch time: 0.4774, average train loss: 0.0046
[09/26 03:30:03 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1581, average loss: 0.4363
[09/26 03:30:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:30:03 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:30:10 visual_prompt]: Epoch 71 / 100: avg data time: 6.85e-02, avg batch time: 0.4809, average train loss: 0.0046
[09/26 03:30:11 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1577, average loss: 0.4364
[09/26 03:30:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:30:11 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:30:18 visual_prompt]: Epoch 72 / 100: avg data time: 6.99e-02, avg batch time: 0.4836, average train loss: 0.0046
[09/26 03:30:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.4370
[09/26 03:30:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 03:30:20 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:30:26 visual_prompt]: Epoch 73 / 100: avg data time: 5.48e-02, avg batch time: 0.4701, average train loss: 0.0046
[09/26 03:30:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1576, average loss: 0.4344
[09/26 03:30:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 03:30:28 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:30:34 visual_prompt]: Epoch 74 / 100: avg data time: 7.18e-02, avg batch time: 0.4852, average train loss: 0.0045
[09/26 03:30:36 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1588, average loss: 0.4334
[09/26 03:30:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:30:36 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:30:43 visual_prompt]: Epoch 75 / 100: avg data time: 7.09e-02, avg batch time: 0.4855, average train loss: 0.0047
[09/26 03:30:45 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1580, average loss: 0.4317
[09/26 03:30:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:30:45 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:30:51 visual_prompt]: Epoch 76 / 100: avg data time: 6.58e-02, avg batch time: 0.4795, average train loss: 0.0045
[09/26 03:30:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1578, average loss: 0.4318
[09/26 03:30:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:30:53 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:31:00 visual_prompt]: Epoch 77 / 100: avg data time: 6.90e-02, avg batch time: 0.4816, average train loss: 0.0045
[09/26 03:31:01 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1581, average loss: 0.4318
[09/26 03:31:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:31:01 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:31:08 visual_prompt]: Epoch 78 / 100: avg data time: 5.85e-02, avg batch time: 0.4748, average train loss: 0.0046
[09/26 03:31:10 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1586, average loss: 0.4315
[09/26 03:31:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:31:10 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:31:16 visual_prompt]: Epoch 79 / 100: avg data time: 5.38e-02, avg batch time: 0.4683, average train loss: 0.0045
[09/26 03:31:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1586, average loss: 0.4321
[09/26 03:31:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:31:18 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:31:25 visual_prompt]: Epoch 80 / 100: avg data time: 5.73e-02, avg batch time: 0.4701, average train loss: 0.0046
[09/26 03:31:26 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1585, average loss: 0.4314
[09/26 03:31:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 03:31:26 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:31:33 visual_prompt]: Epoch 81 / 100: avg data time: 6.12e-02, avg batch time: 0.4751, average train loss: 0.0045
[09/26 03:31:35 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1583, average loss: 0.4320
[09/26 03:31:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:31:35 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:31:41 visual_prompt]: Epoch 82 / 100: avg data time: 6.64e-02, avg batch time: 0.4798, average train loss: 0.0045
[09/26 03:31:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 0.4324
[09/26 03:31:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:31:43 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:31:50 visual_prompt]: Epoch 83 / 100: avg data time: 7.44e-02, avg batch time: 0.4894, average train loss: 0.0044
[09/26 03:31:51 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1583, average loss: 0.4327
[09/26 03:31:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 03:31:51 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:31:58 visual_prompt]: Epoch 84 / 100: avg data time: 6.64e-02, avg batch time: 0.4793, average train loss: 0.0045
[09/26 03:32:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1578, average loss: 0.4327
[09/26 03:32:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 03:32:00 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:32:06 visual_prompt]: Epoch 85 / 100: avg data time: 7.33e-02, avg batch time: 0.4858, average train loss: 0.0046
[09/26 03:32:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 0.4325
[09/26 03:32:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 03:32:08 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:32:15 visual_prompt]: Epoch 86 / 100: avg data time: 6.38e-02, avg batch time: 0.4769, average train loss: 0.0045
[09/26 03:32:16 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1587, average loss: 0.4323
[09/26 03:32:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:32:16 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:32:23 visual_prompt]: Epoch 87 / 100: avg data time: 6.99e-02, avg batch time: 0.4842, average train loss: 0.0044
[09/26 03:32:25 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.4322
[09/26 03:32:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:32:25 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:32:31 visual_prompt]: Epoch 88 / 100: avg data time: 6.60e-02, avg batch time: 0.4799, average train loss: 0.0045
[09/26 03:32:33 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1580, average loss: 0.4320
[09/26 03:32:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:32:33 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:32:40 visual_prompt]: Epoch 89 / 100: avg data time: 6.54e-02, avg batch time: 0.4798, average train loss: 0.0045
[09/26 03:32:42 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1584, average loss: 0.4320
[09/26 03:32:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:32:42 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:32:48 visual_prompt]: Epoch 90 / 100: avg data time: 6.53e-02, avg batch time: 0.4788, average train loss: 0.0045
[09/26 03:32:50 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1586, average loss: 0.4319
[09/26 03:32:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:32:50 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:32:57 visual_prompt]: Epoch 91 / 100: avg data time: 6.76e-02, avg batch time: 0.4804, average train loss: 0.0045
[09/26 03:32:58 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1579, average loss: 0.4319
[09/26 03:32:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:32:58 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:33:05 visual_prompt]: Epoch 92 / 100: avg data time: 7.24e-02, avg batch time: 0.4854, average train loss: 0.0046
[09/26 03:33:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 0.4319
[09/26 03:33:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:33:07 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:33:13 visual_prompt]: Epoch 93 / 100: avg data time: 6.62e-02, avg batch time: 0.4797, average train loss: 0.0045
[09/26 03:33:15 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1586, average loss: 0.4319
[09/26 03:33:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:33:15 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:33:22 visual_prompt]: Epoch 94 / 100: avg data time: 6.83e-02, avg batch time: 0.4823, average train loss: 0.0046
[09/26 03:33:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1584, average loss: 0.4319
[09/26 03:33:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 03:33:23 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:33:30 visual_prompt]: Epoch 95 / 100: avg data time: 6.40e-02, avg batch time: 0.4788, average train loss: 0.0046
[09/26 03:33:32 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1581, average loss: 0.4319
[09/26 03:33:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:33:32 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:33:38 visual_prompt]: Epoch 96 / 100: avg data time: 5.55e-02, avg batch time: 0.4726, average train loss: 0.0045
[09/26 03:33:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.4320
[09/26 03:33:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:33:40 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:33:47 visual_prompt]: Epoch 97 / 100: avg data time: 5.65e-02, avg batch time: 0.4708, average train loss: 0.0045
[09/26 03:33:48 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1582, average loss: 0.4319
[09/26 03:33:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:33:48 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:33:55 visual_prompt]: Epoch 98 / 100: avg data time: 7.47e-02, avg batch time: 0.4889, average train loss: 0.0045
[09/26 03:33:57 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.4319
[09/26 03:33:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:33:57 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:34:03 visual_prompt]: Epoch 99 / 100: avg data time: 6.62e-02, avg batch time: 0.4796, average train loss: 0.0045
[09/26 03:34:05 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 0.4319
[09/26 03:34:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:34:05 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:34:12 visual_prompt]: Epoch 100 / 100: avg data time: 6.56e-02, avg batch time: 0.4798, average train loss: 0.0046
[09/26 03:34:13 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 0.4319
[09/26 03:34:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 03:34:13 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:34:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:34:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:34:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:34:13 visual_prompt]: Training with config:
[09/26 03:34:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:34:13 visual_prompt]: Loading training data...
[09/26 03:34:13 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:34:15 visual_prompt]: Number of images: 800
[09/26 03:34:15 visual_prompt]: Number of classes: 102 / 102
[09/26 03:34:15 visual_prompt]: Loading validation data...
[09/26 03:34:15 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:34:15 visual_prompt]: Number of images: 200
[09/26 03:34:15 visual_prompt]: Number of classes: 91 / 102
[09/26 03:34:15 visual_prompt]: Constructing models...
[09/26 03:34:18 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 03:34:18 visual_prompt]: tuned percent:0.625
[09/26 03:34:18 visual_prompt]: Device used for model: 0
[09/26 03:34:18 visual_prompt]: Setting up Evaluator...
[09/26 03:34:18 visual_prompt]: Setting up Trainer...
[09/26 03:34:18 visual_prompt]: 	Setting up the optimizer...
[09/26 03:34:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:34:25 visual_prompt]: Epoch 1 / 100: avg data time: 6.37e-02, avg batch time: 0.4802, average train loss: 4.6686
[09/26 03:34:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 03:34:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 03:34:26 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:34:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:34:33 visual_prompt]: Epoch 2 / 100: avg data time: 6.65e-02, avg batch time: 0.4795, average train loss: 4.6182
[09/26 03:34:35 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 4.6027
[09/26 03:34:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.50	
[09/26 03:34:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:34:41 visual_prompt]: Epoch 3 / 100: avg data time: 6.29e-02, avg batch time: 0.4759, average train loss: 4.4680
[09/26 03:34:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 4.3317
[09/26 03:34:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.00	top5: 20.00	
[09/26 03:34:43 visual_prompt]: Best epoch 3: best metric: 0.050
[09/26 03:34:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:34:50 visual_prompt]: Epoch 4 / 100: avg data time: 7.01e-02, avg batch time: 0.4827, average train loss: 4.0164
[09/26 03:34:51 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1581, average loss: 3.7706
[09/26 03:34:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 14.00	top5: 37.50	
[09/26 03:34:51 visual_prompt]: Best epoch 4: best metric: 0.140
[09/26 03:34:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:34:58 visual_prompt]: Epoch 5 / 100: avg data time: 6.34e-02, avg batch time: 0.4774, average train loss: 3.1729
[09/26 03:35:00 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 2.7310
[09/26 03:35:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 40.50	top5: 65.00	
[09/26 03:35:00 visual_prompt]: Best epoch 5: best metric: 0.405
[09/26 03:35:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:35:06 visual_prompt]: Epoch 6 / 100: avg data time: 7.05e-02, avg batch time: 0.4830, average train loss: 1.8840
[09/26 03:35:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1581, average loss: 1.5850
[09/26 03:35:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 64.50	top5: 86.50	
[09/26 03:35:08 visual_prompt]: Best epoch 6: best metric: 0.645
[09/26 03:35:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:35:15 visual_prompt]: Epoch 7 / 100: avg data time: 5.32e-02, avg batch time: 0.4659, average train loss: 0.8965
[09/26 03:35:16 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1578, average loss: 0.9818
[09/26 03:35:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.50	top5: 94.00	
[09/26 03:35:16 visual_prompt]: Best epoch 7: best metric: 0.735
[09/26 03:35:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:35:23 visual_prompt]: Epoch 8 / 100: avg data time: 7.25e-02, avg batch time: 0.4854, average train loss: 0.3939
[09/26 03:35:25 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 0.6854
[09/26 03:35:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 96.00	
[09/26 03:35:25 visual_prompt]: Best epoch 8: best metric: 0.805
[09/26 03:35:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:35:31 visual_prompt]: Epoch 9 / 100: avg data time: 7.13e-02, avg batch time: 0.4839, average train loss: 0.1890
[09/26 03:35:33 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1586, average loss: 0.5086
[09/26 03:35:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.50	
[09/26 03:35:33 visual_prompt]: Best epoch 9: best metric: 0.875
[09/26 03:35:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:35:40 visual_prompt]: Epoch 10 / 100: avg data time: 6.81e-02, avg batch time: 0.4813, average train loss: 0.1018
[09/26 03:35:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1586, average loss: 0.4732
[09/26 03:35:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.50	
[09/26 03:35:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:35:48 visual_prompt]: Epoch 11 / 100: avg data time: 7.13e-02, avg batch time: 0.4836, average train loss: 0.0600
[09/26 03:35:50 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1585, average loss: 0.4869
[09/26 03:35:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 97.00	
[09/26 03:35:50 visual_prompt]: Best epoch 11: best metric: 0.890
[09/26 03:35:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:35:57 visual_prompt]: Epoch 12 / 100: avg data time: 7.02e-02, avg batch time: 0.4824, average train loss: 0.0346
[09/26 03:35:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1585, average loss: 0.4710
[09/26 03:35:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.50	
[09/26 03:35:58 visual_prompt]: Best epoch 12: best metric: 0.900
[09/26 03:35:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:36:05 visual_prompt]: Epoch 13 / 100: avg data time: 5.17e-02, avg batch time: 0.4654, average train loss: 0.0191
[09/26 03:36:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1582, average loss: 0.4271
[09/26 03:36:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 03:36:06 visual_prompt]: Best epoch 13: best metric: 0.905
[09/26 03:36:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:36:13 visual_prompt]: Epoch 14 / 100: avg data time: 6.98e-02, avg batch time: 0.4832, average train loss: 0.0126
[09/26 03:36:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.4264
[09/26 03:36:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 03:36:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:36:22 visual_prompt]: Epoch 15 / 100: avg data time: 6.91e-02, avg batch time: 0.4818, average train loss: 0.0102
[09/26 03:36:23 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1580, average loss: 0.4342
[09/26 03:36:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.50	
[09/26 03:36:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:36:30 visual_prompt]: Epoch 16 / 100: avg data time: 6.53e-02, avg batch time: 0.4790, average train loss: 0.0087
[09/26 03:36:32 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.4309
[09/26 03:36:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.00	
[09/26 03:36:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:36:38 visual_prompt]: Epoch 17 / 100: avg data time: 5.02e-02, avg batch time: 0.4647, average train loss: 0.0074
[09/26 03:36:40 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1587, average loss: 0.4193
[09/26 03:36:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.50	
[09/26 03:36:40 visual_prompt]: Best epoch 17: best metric: 0.915
[09/26 03:36:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:36:46 visual_prompt]: Epoch 18 / 100: avg data time: 6.34e-02, avg batch time: 0.4764, average train loss: 0.0067
[09/26 03:36:48 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1586, average loss: 0.4204
[09/26 03:36:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.50	
[09/26 03:36:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:36:55 visual_prompt]: Epoch 19 / 100: avg data time: 6.50e-02, avg batch time: 0.4775, average train loss: 0.0060
[09/26 03:36:57 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1586, average loss: 0.4189
[09/26 03:36:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:36:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:37:03 visual_prompt]: Epoch 20 / 100: avg data time: 6.51e-02, avg batch time: 0.4780, average train loss: 0.0058
[09/26 03:37:05 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 0.4173
[09/26 03:37:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:37:05 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:37:11 visual_prompt]: Epoch 21 / 100: avg data time: 5.39e-02, avg batch time: 0.4683, average train loss: 0.0052
[09/26 03:37:13 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1585, average loss: 0.4150
[09/26 03:37:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:37:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:37:20 visual_prompt]: Epoch 22 / 100: avg data time: 6.95e-02, avg batch time: 0.4831, average train loss: 0.0049
[09/26 03:37:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1579, average loss: 0.4206
[09/26 03:37:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:37:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:37:28 visual_prompt]: Epoch 23 / 100: avg data time: 6.64e-02, avg batch time: 0.4806, average train loss: 0.0046
[09/26 03:37:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1586, average loss: 0.4207
[09/26 03:37:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.50	
[09/26 03:37:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:37:37 visual_prompt]: Epoch 24 / 100: avg data time: 7.15e-02, avg batch time: 0.4853, average train loss: 0.0045
[09/26 03:37:38 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1585, average loss: 0.4151
[09/26 03:37:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:37:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:37:45 visual_prompt]: Epoch 25 / 100: avg data time: 6.46e-02, avg batch time: 0.4786, average train loss: 0.0042
[09/26 03:37:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1584, average loss: 0.4086
[09/26 03:37:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:37:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:37:53 visual_prompt]: Epoch 26 / 100: avg data time: 6.56e-02, avg batch time: 0.4789, average train loss: 0.0040
[09/26 03:37:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1584, average loss: 0.4098
[09/26 03:37:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.50	
[09/26 03:37:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:38:02 visual_prompt]: Epoch 27 / 100: avg data time: 6.68e-02, avg batch time: 0.4811, average train loss: 0.0037
[09/26 03:38:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 0.4105
[09/26 03:38:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.50	
[09/26 03:38:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:38:10 visual_prompt]: Epoch 28 / 100: avg data time: 6.79e-02, avg batch time: 0.4818, average train loss: 0.0034
[09/26 03:38:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.4111
[09/26 03:38:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:38:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:38:19 visual_prompt]: Epoch 29 / 100: avg data time: 7.43e-02, avg batch time: 0.4874, average train loss: 0.0034
[09/26 03:38:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 0.4125
[09/26 03:38:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:38:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:38:27 visual_prompt]: Epoch 30 / 100: avg data time: 6.57e-02, avg batch time: 0.4793, average train loss: 0.0033
[09/26 03:38:29 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1581, average loss: 0.4118
[09/26 03:38:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:38:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:38:35 visual_prompt]: Epoch 31 / 100: avg data time: 6.53e-02, avg batch time: 0.4797, average train loss: 0.0032
[09/26 03:38:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.4106
[09/26 03:38:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:38:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:38:44 visual_prompt]: Epoch 32 / 100: avg data time: 6.79e-02, avg batch time: 0.4813, average train loss: 0.0030
[09/26 03:38:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 0.4101
[09/26 03:38:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:38:46 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:38:52 visual_prompt]: Epoch 33 / 100: avg data time: 6.49e-02, avg batch time: 0.4800, average train loss: 0.0029
[09/26 03:38:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 0.4094
[09/26 03:38:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:38:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:39:01 visual_prompt]: Epoch 34 / 100: avg data time: 7.18e-02, avg batch time: 0.4870, average train loss: 0.0029
[09/26 03:39:02 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1585, average loss: 0.4081
[09/26 03:39:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.50	
[09/26 03:39:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:39:09 visual_prompt]: Epoch 35 / 100: avg data time: 7.02e-02, avg batch time: 0.4838, average train loss: 0.0028
[09/26 03:39:11 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1585, average loss: 0.4075
[09/26 03:39:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:39:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:39:17 visual_prompt]: Epoch 36 / 100: avg data time: 7.47e-02, avg batch time: 0.4883, average train loss: 0.0028
[09/26 03:39:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.4089
[09/26 03:39:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:39:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:39:26 visual_prompt]: Epoch 37 / 100: avg data time: 6.40e-02, avg batch time: 0.4783, average train loss: 0.0027
[09/26 03:39:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 0.4121
[09/26 03:39:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:39:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:39:34 visual_prompt]: Epoch 38 / 100: avg data time: 6.59e-02, avg batch time: 0.4802, average train loss: 0.0025
[09/26 03:39:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1589, average loss: 0.4103
[09/26 03:39:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:39:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:39:43 visual_prompt]: Epoch 39 / 100: avg data time: 6.78e-02, avg batch time: 0.4819, average train loss: 0.0025
[09/26 03:39:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1587, average loss: 0.4078
[09/26 03:39:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 98.50	
[09/26 03:39:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:39:51 visual_prompt]: Epoch 40 / 100: avg data time: 7.34e-02, avg batch time: 0.4877, average train loss: 0.0025
[09/26 03:39:53 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1587, average loss: 0.4066
[09/26 03:39:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:39:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:39:59 visual_prompt]: Epoch 41 / 100: avg data time: 6.87e-02, avg batch time: 0.4820, average train loss: 0.0023
[09/26 03:40:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1587, average loss: 0.4065
[09/26 03:40:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:40:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:40:08 visual_prompt]: Epoch 42 / 100: avg data time: 6.68e-02, avg batch time: 0.4808, average train loss: 0.0024
[09/26 03:40:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1586, average loss: 0.4056
[09/26 03:40:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:40:10 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:40:16 visual_prompt]: Epoch 43 / 100: avg data time: 6.81e-02, avg batch time: 0.4833, average train loss: 0.0024
[09/26 03:40:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1585, average loss: 0.4049
[09/26 03:40:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:40:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:40:25 visual_prompt]: Epoch 44 / 100: avg data time: 6.85e-02, avg batch time: 0.4823, average train loss: 0.0022
[09/26 03:40:26 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 0.4023
[09/26 03:40:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:40:26 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:40:33 visual_prompt]: Epoch 45 / 100: avg data time: 6.56e-02, avg batch time: 0.4803, average train loss: 0.0022
[09/26 03:40:35 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1586, average loss: 0.4028
[09/26 03:40:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:40:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:40:41 visual_prompt]: Epoch 46 / 100: avg data time: 7.48e-02, avg batch time: 0.4884, average train loss: 0.0021
[09/26 03:40:43 visual_prompt]: Inference (val):avg data time: 4.52e-05, avg batch time: 0.1586, average loss: 0.4060
[09/26 03:40:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:40:43 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:40:50 visual_prompt]: Epoch 47 / 100: avg data time: 6.67e-02, avg batch time: 0.4816, average train loss: 0.0022
[09/26 03:40:52 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 0.4078
[09/26 03:40:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:40:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:40:58 visual_prompt]: Epoch 48 / 100: avg data time: 7.27e-02, avg batch time: 0.4862, average train loss: 0.0021
[09/26 03:41:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.4092
[09/26 03:41:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:41:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:41:07 visual_prompt]: Epoch 49 / 100: avg data time: 6.70e-02, avg batch time: 0.4822, average train loss: 0.0020
[09/26 03:41:08 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1588, average loss: 0.4120
[09/26 03:41:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:41:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:41:15 visual_prompt]: Epoch 50 / 100: avg data time: 6.69e-02, avg batch time: 0.4807, average train loss: 0.0020
[09/26 03:41:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1588, average loss: 0.4107
[09/26 03:41:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:41:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:41:24 visual_prompt]: Epoch 51 / 100: avg data time: 7.37e-02, avg batch time: 0.4882, average train loss: 0.0020
[09/26 03:41:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.4083
[09/26 03:41:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:41:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:41:32 visual_prompt]: Epoch 52 / 100: avg data time: 7.39e-02, avg batch time: 0.4880, average train loss: 0.0019
[09/26 03:41:34 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 0.4083
[09/26 03:41:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:41:34 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:41:41 visual_prompt]: Epoch 53 / 100: avg data time: 6.76e-02, avg batch time: 0.4819, average train loss: 0.0019
[09/26 03:41:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.4081
[09/26 03:41:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:41:42 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:41:49 visual_prompt]: Epoch 54 / 100: avg data time: 7.51e-02, avg batch time: 0.4887, average train loss: 0.0019
[09/26 03:41:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1588, average loss: 0.4079
[09/26 03:41:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:41:51 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:41:57 visual_prompt]: Epoch 55 / 100: avg data time: 6.14e-02, avg batch time: 0.4762, average train loss: 0.0019
[09/26 03:41:59 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1584, average loss: 0.4077
[09/26 03:41:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:41:59 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:42:06 visual_prompt]: Epoch 56 / 100: avg data time: 5.40e-02, avg batch time: 0.4694, average train loss: 0.0018
[09/26 03:42:07 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1586, average loss: 0.4080
[09/26 03:42:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 98.50	
[09/26 03:42:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:42:14 visual_prompt]: Epoch 57 / 100: avg data time: 6.21e-02, avg batch time: 0.4772, average train loss: 0.0018
[09/26 03:42:16 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1588, average loss: 0.4080
[09/26 03:42:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 98.50	
[09/26 03:42:16 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:42:22 visual_prompt]: Epoch 58 / 100: avg data time: 6.23e-02, avg batch time: 0.4776, average train loss: 0.0018
[09/26 03:42:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1589, average loss: 0.4091
[09/26 03:42:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 98.50	
[09/26 03:42:24 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:42:31 visual_prompt]: Epoch 59 / 100: avg data time: 6.09e-02, avg batch time: 0.4762, average train loss: 0.0018
[09/26 03:42:32 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1589, average loss: 0.4096
[09/26 03:42:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 98.50	
[09/26 03:42:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:42:39 visual_prompt]: Epoch 60 / 100: avg data time: 6.39e-02, avg batch time: 0.4774, average train loss: 0.0017
[09/26 03:42:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 0.4105
[09/26 03:42:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:42:41 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:42:47 visual_prompt]: Epoch 61 / 100: avg data time: 7.01e-02, avg batch time: 0.4836, average train loss: 0.0017
[09/26 03:42:49 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1588, average loss: 0.4096
[09/26 03:42:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:42:49 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:42:56 visual_prompt]: Epoch 62 / 100: avg data time: 6.95e-02, avg batch time: 0.4840, average train loss: 0.0017
[09/26 03:42:58 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1585, average loss: 0.4079
[09/26 03:42:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:42:58 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:43:04 visual_prompt]: Epoch 63 / 100: avg data time: 5.87e-02, avg batch time: 0.4722, average train loss: 0.0017
[09/26 03:43:06 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1589, average loss: 0.4079
[09/26 03:43:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:43:13 visual_prompt]: Epoch 64 / 100: avg data time: 7.32e-02, avg batch time: 0.4881, average train loss: 0.0017
[09/26 03:43:14 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1585, average loss: 0.4088
[09/26 03:43:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:43:21 visual_prompt]: Epoch 65 / 100: avg data time: 7.12e-02, avg batch time: 0.4865, average train loss: 0.0017
[09/26 03:43:23 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1581, average loss: 0.4089
[09/26 03:43:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:23 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:43:29 visual_prompt]: Epoch 66 / 100: avg data time: 6.09e-02, avg batch time: 0.4754, average train loss: 0.0017
[09/26 03:43:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1585, average loss: 0.4085
[09/26 03:43:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:43:38 visual_prompt]: Epoch 67 / 100: avg data time: 6.59e-02, avg batch time: 0.4805, average train loss: 0.0017
[09/26 03:43:39 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1594, average loss: 0.4082
[09/26 03:43:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:39 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:43:46 visual_prompt]: Epoch 68 / 100: avg data time: 6.36e-02, avg batch time: 0.4779, average train loss: 0.0017
[09/26 03:43:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1584, average loss: 0.4082
[09/26 03:43:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:48 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:43:54 visual_prompt]: Epoch 69 / 100: avg data time: 6.58e-02, avg batch time: 0.4799, average train loss: 0.0017
[09/26 03:43:56 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1576, average loss: 0.4085
[09/26 03:43:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:43:56 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:44:03 visual_prompt]: Epoch 70 / 100: avg data time: 6.45e-02, avg batch time: 0.4779, average train loss: 0.0016
[09/26 03:44:04 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1585, average loss: 0.4094
[09/26 03:44:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:04 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:44:11 visual_prompt]: Epoch 71 / 100: avg data time: 7.03e-02, avg batch time: 0.4845, average train loss: 0.0016
[09/26 03:44:13 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1589, average loss: 0.4089
[09/26 03:44:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:13 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:44:19 visual_prompt]: Epoch 72 / 100: avg data time: 6.68e-02, avg batch time: 0.4800, average train loss: 0.0016
[09/26 03:44:21 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1579, average loss: 0.4087
[09/26 03:44:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:21 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:44:28 visual_prompt]: Epoch 73 / 100: avg data time: 5.59e-02, avg batch time: 0.4701, average train loss: 0.0015
[09/26 03:44:29 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1587, average loss: 0.4088
[09/26 03:44:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:29 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:44:36 visual_prompt]: Epoch 74 / 100: avg data time: 5.42e-02, avg batch time: 0.4691, average train loss: 0.0016
[09/26 03:44:38 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1584, average loss: 0.4087
[09/26 03:44:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:38 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:44:44 visual_prompt]: Epoch 75 / 100: avg data time: 6.33e-02, avg batch time: 0.4792, average train loss: 0.0016
[09/26 03:44:46 visual_prompt]: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1588, average loss: 0.4089
[09/26 03:44:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:46 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:44:53 visual_prompt]: Epoch 76 / 100: avg data time: 5.86e-02, avg batch time: 0.4723, average train loss: 0.0016
[09/26 03:44:54 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1583, average loss: 0.4087
[09/26 03:44:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:44:54 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:45:01 visual_prompt]: Epoch 77 / 100: avg data time: 6.31e-02, avg batch time: 0.4768, average train loss: 0.0016
[09/26 03:45:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.4084
[09/26 03:45:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:03 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:45:09 visual_prompt]: Epoch 78 / 100: avg data time: 6.44e-02, avg batch time: 0.4793, average train loss: 0.0015
[09/26 03:45:11 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1588, average loss: 0.4085
[09/26 03:45:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:11 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:45:18 visual_prompt]: Epoch 79 / 100: avg data time: 6.21e-02, avg batch time: 0.4772, average train loss: 0.0016
[09/26 03:45:19 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1587, average loss: 0.4088
[09/26 03:45:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:19 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:45:26 visual_prompt]: Epoch 80 / 100: avg data time: 6.14e-02, avg batch time: 0.4763, average train loss: 0.0016
[09/26 03:45:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 0.4093
[09/26 03:45:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:28 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:45:34 visual_prompt]: Epoch 81 / 100: avg data time: 6.95e-02, avg batch time: 0.4842, average train loss: 0.0016
[09/26 03:45:36 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1585, average loss: 0.4095
[09/26 03:45:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:36 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:45:43 visual_prompt]: Epoch 82 / 100: avg data time: 6.49e-02, avg batch time: 0.4805, average train loss: 0.0016
[09/26 03:45:45 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1582, average loss: 0.4093
[09/26 03:45:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:45 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:45:51 visual_prompt]: Epoch 83 / 100: avg data time: 6.51e-02, avg batch time: 0.4799, average train loss: 0.0015
[09/26 03:45:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 0.4093
[09/26 03:45:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:45:53 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:45:59 visual_prompt]: Epoch 84 / 100: avg data time: 6.43e-02, avg batch time: 0.4796, average train loss: 0.0016
[09/26 03:46:01 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.4095
[09/26 03:46:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:01 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:46:08 visual_prompt]: Epoch 85 / 100: avg data time: 6.68e-02, avg batch time: 0.4812, average train loss: 0.0016
[09/26 03:46:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.4095
[09/26 03:46:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:10 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:46:16 visual_prompt]: Epoch 86 / 100: avg data time: 7.14e-02, avg batch time: 0.4852, average train loss: 0.0015
[09/26 03:46:18 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1582, average loss: 0.4095
[09/26 03:46:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:18 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:46:25 visual_prompt]: Epoch 87 / 100: avg data time: 6.56e-02, avg batch time: 0.4794, average train loss: 0.0015
[09/26 03:46:26 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1588, average loss: 0.4096
[09/26 03:46:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:26 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:46:33 visual_prompt]: Epoch 88 / 100: avg data time: 6.95e-02, avg batch time: 0.4833, average train loss: 0.0015
[09/26 03:46:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1585, average loss: 0.4096
[09/26 03:46:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:35 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:46:41 visual_prompt]: Epoch 89 / 100: avg data time: 6.60e-02, avg batch time: 0.4811, average train loss: 0.0016
[09/26 03:46:43 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1583, average loss: 0.4095
[09/26 03:46:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:43 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:46:50 visual_prompt]: Epoch 90 / 100: avg data time: 7.00e-02, avg batch time: 0.4839, average train loss: 0.0016
[09/26 03:46:51 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1587, average loss: 0.4094
[09/26 03:46:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:46:51 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:46:58 visual_prompt]: Epoch 91 / 100: avg data time: 7.59e-02, avg batch time: 0.4899, average train loss: 0.0016
[09/26 03:47:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.4094
[09/26 03:47:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:47:07 visual_prompt]: Epoch 92 / 100: avg data time: 6.78e-02, avg batch time: 0.4814, average train loss: 0.0015
[09/26 03:47:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 0.4094
[09/26 03:47:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:08 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:47:15 visual_prompt]: Epoch 93 / 100: avg data time: 6.48e-02, avg batch time: 0.4803, average train loss: 0.0015
[09/26 03:47:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 0.4094
[09/26 03:47:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:47:23 visual_prompt]: Epoch 94 / 100: avg data time: 6.68e-02, avg batch time: 0.4826, average train loss: 0.0015
[09/26 03:47:25 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1586, average loss: 0.4094
[09/26 03:47:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:25 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:47:32 visual_prompt]: Epoch 95 / 100: avg data time: 7.09e-02, avg batch time: 0.4837, average train loss: 0.0015
[09/26 03:47:33 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1586, average loss: 0.4094
[09/26 03:47:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:33 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:47:40 visual_prompt]: Epoch 96 / 100: avg data time: 6.78e-02, avg batch time: 0.4805, average train loss: 0.0015
[09/26 03:47:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 0.4094
[09/26 03:47:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:42 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:47:48 visual_prompt]: Epoch 97 / 100: avg data time: 6.90e-02, avg batch time: 0.4817, average train loss: 0.0016
[09/26 03:47:50 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1586, average loss: 0.4094
[09/26 03:47:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:50 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:47:57 visual_prompt]: Epoch 98 / 100: avg data time: 6.85e-02, avg batch time: 0.4820, average train loss: 0.0015
[09/26 03:47:59 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1580, average loss: 0.4094
[09/26 03:47:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:47:59 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:48:05 visual_prompt]: Epoch 99 / 100: avg data time: 7.35e-02, avg batch time: 0.4858, average train loss: 0.0015
[09/26 03:48:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1583, average loss: 0.4094
[09/26 03:48:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:48:07 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:48:14 visual_prompt]: Epoch 100 / 100: avg data time: 6.37e-02, avg batch time: 0.4774, average train loss: 0.0015
[09/26 03:48:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1577, average loss: 0.4094
[09/26 03:48:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.50	
[09/26 03:48:15 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:48:15 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:48:15 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:48:15 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:48:15 visual_prompt]: Training with config:
[09/26 03:48:15 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:48:15 visual_prompt]: Loading training data...
[09/26 03:48:15 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:48:16 visual_prompt]: Number of images: 800
[09/26 03:48:16 visual_prompt]: Number of classes: 102 / 102
[09/26 03:48:16 visual_prompt]: Loading validation data...
[09/26 03:48:16 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 03:48:17 visual_prompt]: Number of images: 200
[09/26 03:48:17 visual_prompt]: Number of classes: 91 / 102
[09/26 03:48:17 visual_prompt]: Constructing models...
[09/26 03:48:19 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 03:48:19 visual_prompt]: tuned percent:0.625
[09/26 03:48:19 visual_prompt]: Device used for model: 0
[09/26 03:48:19 visual_prompt]: Setting up Evaluator...
[09/26 03:48:19 visual_prompt]: Setting up Trainer...
[09/26 03:48:19 visual_prompt]: 	Setting up the optimizer...
[09/26 03:48:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:48:26 visual_prompt]: Epoch 1 / 100: avg data time: 6.90e-02, avg batch time: 0.4886, average train loss: 4.6691
[09/26 03:48:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 03:48:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 03:48:28 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:48:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 03:48:34 visual_prompt]: Epoch 2 / 100: avg data time: 5.82e-02, avg batch time: 0.4722, average train loss: 4.6320
[09/26 03:48:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 4.6230
[09/26 03:48:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 03:48:36 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 03:48:43 visual_prompt]: Epoch 3 / 100: avg data time: 6.82e-02, avg batch time: 0.4804, average train loss: 4.5268
[09/26 03:48:44 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 4.4942
[09/26 03:48:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 16.00	
[09/26 03:48:44 visual_prompt]: Best epoch 3: best metric: 0.035
[09/26 03:48:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 03:48:51 visual_prompt]: Epoch 4 / 100: avg data time: 6.68e-02, avg batch time: 0.4793, average train loss: 4.2483
[09/26 03:48:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 4.0841
[09/26 03:48:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 10.00	top5: 32.50	
[09/26 03:48:53 visual_prompt]: Best epoch 4: best metric: 0.100
[09/26 03:48:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 03:48:59 visual_prompt]: Epoch 5 / 100: avg data time: 6.78e-02, avg batch time: 0.4813, average train loss: 3.6439
[09/26 03:49:01 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 3.5265
[09/26 03:49:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 18.50	top5: 43.50	
[09/26 03:49:01 visual_prompt]: Best epoch 5: best metric: 0.185
[09/26 03:49:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 03:49:08 visual_prompt]: Epoch 6 / 100: avg data time: 6.62e-02, avg batch time: 0.4777, average train loss: 2.9690
[09/26 03:49:10 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1579, average loss: 2.9292
[09/26 03:49:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 35.00	top5: 64.50	
[09/26 03:49:10 visual_prompt]: Best epoch 6: best metric: 0.350
[09/26 03:49:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 03:49:16 visual_prompt]: Epoch 7 / 100: avg data time: 7.09e-02, avg batch time: 0.4829, average train loss: 2.2190
[09/26 03:49:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 2.0388
[09/26 03:49:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 62.00	top5: 84.00	
[09/26 03:49:18 visual_prompt]: Best epoch 7: best metric: 0.620
[09/26 03:49:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 03:49:25 visual_prompt]: Epoch 8 / 100: avg data time: 6.90e-02, avg batch time: 0.4810, average train loss: 1.4684
[09/26 03:49:26 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1574, average loss: 1.6024
[09/26 03:49:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.50	top5: 90.00	
[09/26 03:49:26 visual_prompt]: Best epoch 8: best metric: 0.725
[09/26 03:49:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 03:49:33 visual_prompt]: Epoch 9 / 100: avg data time: 6.97e-02, avg batch time: 0.4828, average train loss: 1.0543
[09/26 03:49:35 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 1.2683
[09/26 03:49:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 03:49:35 visual_prompt]: Best epoch 9: best metric: 0.805
[09/26 03:49:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 03:49:41 visual_prompt]: Epoch 10 / 100: avg data time: 5.66e-02, avg batch time: 0.4687, average train loss: 0.8109
[09/26 03:49:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1581, average loss: 1.1258
[09/26 03:49:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 95.50	
[09/26 03:49:43 visual_prompt]: Best epoch 10: best metric: 0.815
[09/26 03:49:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 03:49:50 visual_prompt]: Epoch 11 / 100: avg data time: 6.86e-02, avg batch time: 0.4810, average train loss: 0.8743
[09/26 03:49:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 1.2203
[09/26 03:49:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 93.50	
[09/26 03:49:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 03:49:58 visual_prompt]: Epoch 12 / 100: avg data time: 6.03e-02, avg batch time: 0.4727, average train loss: 1.8933
[09/26 03:50:00 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1577, average loss: 1.5138
[09/26 03:50:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 94.50	
[09/26 03:50:00 visual_prompt]: Best epoch 12: best metric: 0.825
[09/26 03:50:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 03:50:06 visual_prompt]: Epoch 13 / 100: avg data time: 5.70e-02, avg batch time: 0.4708, average train loss: 1.1109
[09/26 03:50:08 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 1.0707
[09/26 03:50:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 94.50	
[09/26 03:50:08 visual_prompt]: Best epoch 13: best metric: 0.875
[09/26 03:50:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 03:50:15 visual_prompt]: Epoch 14 / 100: avg data time: 6.22e-02, avg batch time: 0.4760, average train loss: 0.6637
[09/26 03:50:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1579, average loss: 0.8290
[09/26 03:50:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 03:50:16 visual_prompt]: Best epoch 14: best metric: 0.905
[09/26 03:50:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 03:50:23 visual_prompt]: Epoch 15 / 100: avg data time: 5.87e-02, avg batch time: 0.4717, average train loss: 0.5163
[09/26 03:50:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 0.8328
[09/26 03:50:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 03:50:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 03:50:31 visual_prompt]: Epoch 16 / 100: avg data time: 6.38e-02, avg batch time: 0.4768, average train loss: 0.4727
[09/26 03:50:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.7956
[09/26 03:50:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 03:50:33 visual_prompt]: Best epoch 16: best metric: 0.915
[09/26 03:50:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 03:50:39 visual_prompt]: Epoch 17 / 100: avg data time: 6.15e-02, avg batch time: 0.4751, average train loss: 0.5018
[09/26 03:50:41 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1582, average loss: 0.7886
[09/26 03:50:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 03:50:41 visual_prompt]: Best epoch 17: best metric: 0.920
[09/26 03:50:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 03:50:48 visual_prompt]: Epoch 18 / 100: avg data time: 6.92e-02, avg batch time: 0.4825, average train loss: 0.5903
[09/26 03:50:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 0.9681
[09/26 03:50:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.00	
[09/26 03:50:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 03:50:56 visual_prompt]: Epoch 19 / 100: avg data time: 6.85e-02, avg batch time: 0.4820, average train loss: 1.0182
[09/26 03:50:58 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1581, average loss: 2.3599
[09/26 03:50:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 57.50	top5: 77.00	
[09/26 03:50:58 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 03:51:05 visual_prompt]: Epoch 20 / 100: avg data time: 6.55e-02, avg batch time: 0.4778, average train loss: 2.3641
[09/26 03:51:06 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1580, average loss: 1.3798
[09/26 03:51:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 95.00	
[09/26 03:51:06 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 03:51:13 visual_prompt]: Epoch 21 / 100: avg data time: 7.01e-02, avg batch time: 0.4825, average train loss: 0.8687
[09/26 03:51:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 0.9683
[09/26 03:51:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 03:51:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 03:51:21 visual_prompt]: Epoch 22 / 100: avg data time: 6.66e-02, avg batch time: 0.4803, average train loss: 0.5428
[09/26 03:51:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 0.7609
[09/26 03:51:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 03:51:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 03:51:30 visual_prompt]: Epoch 23 / 100: avg data time: 6.77e-02, avg batch time: 0.4809, average train loss: 0.4691
[09/26 03:51:31 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 0.7596
[09/26 03:51:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.00	
[09/26 03:51:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 03:51:38 visual_prompt]: Epoch 24 / 100: avg data time: 6.66e-02, avg batch time: 0.4796, average train loss: 0.4742
[09/26 03:51:40 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1578, average loss: 0.8004
[09/26 03:51:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 03:51:40 visual_prompt]: Best epoch 24: best metric: 0.925
[09/26 03:51:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 03:51:46 visual_prompt]: Epoch 25 / 100: avg data time: 6.90e-02, avg batch time: 0.4815, average train loss: 0.5054
[09/26 03:51:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1584, average loss: 0.8112
[09/26 03:51:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 03:51:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 03:51:55 visual_prompt]: Epoch 26 / 100: avg data time: 6.35e-02, avg batch time: 0.4766, average train loss: 0.5537
[09/26 03:51:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 1.0154
[09/26 03:51:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.00	
[09/26 03:51:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 03:52:03 visual_prompt]: Epoch 27 / 100: avg data time: 6.74e-02, avg batch time: 0.4802, average train loss: 1.6753
[09/26 03:52:05 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 2.5271
[09/26 03:52:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 57.00	top5: 80.00	
[09/26 03:52:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 03:52:12 visual_prompt]: Epoch 28 / 100: avg data time: 7.39e-02, avg batch time: 0.4861, average train loss: 1.1065
[09/26 03:52:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1577, average loss: 1.0010
[09/26 03:52:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.50	
[09/26 03:52:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 03:52:20 visual_prompt]: Epoch 29 / 100: avg data time: 6.35e-02, avg batch time: 0.4762, average train loss: 0.5908
[09/26 03:52:22 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1584, average loss: 0.7773
[09/26 03:52:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 03:52:22 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 03:52:28 visual_prompt]: Epoch 30 / 100: avg data time: 6.30e-02, avg batch time: 0.4759, average train loss: 0.4652
[09/26 03:52:30 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 0.8153
[09/26 03:52:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 03:52:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 03:52:37 visual_prompt]: Epoch 31 / 100: avg data time: 6.49e-02, avg batch time: 0.4790, average train loss: 0.4528
[09/26 03:52:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1577, average loss: 0.7642
[09/26 03:52:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:52:38 visual_prompt]: Best epoch 31: best metric: 0.935
[09/26 03:52:38 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 03:52:45 visual_prompt]: Epoch 32 / 100: avg data time: 7.01e-02, avg batch time: 0.4829, average train loss: 0.4316
[09/26 03:52:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1575, average loss: 0.7445
[09/26 03:52:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:52:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 03:52:53 visual_prompt]: Epoch 33 / 100: avg data time: 6.01e-02, avg batch time: 0.4735, average train loss: 0.4731
[09/26 03:52:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1579, average loss: 0.8027
[09/26 03:52:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 03:52:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 03:53:02 visual_prompt]: Epoch 34 / 100: avg data time: 6.94e-02, avg batch time: 0.4826, average train loss: 0.5035
[09/26 03:53:03 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1579, average loss: 0.8914
[09/26 03:53:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 03:53:03 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 03:53:10 visual_prompt]: Epoch 35 / 100: avg data time: 6.69e-02, avg batch time: 0.4810, average train loss: 0.4884
[09/26 03:53:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1578, average loss: 0.7840
[09/26 03:53:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.50	
[09/26 03:53:12 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 03:53:18 visual_prompt]: Epoch 36 / 100: avg data time: 6.84e-02, avg batch time: 0.4820, average train loss: 0.4258
[09/26 03:53:20 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1579, average loss: 1.2504
[09/26 03:53:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.00	
[09/26 03:53:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 03:53:27 visual_prompt]: Epoch 37 / 100: avg data time: 6.32e-02, avg batch time: 0.4754, average train loss: 0.7958
[09/26 03:53:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1580, average loss: 1.0412
[09/26 03:53:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 03:53:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 03:53:35 visual_prompt]: Epoch 38 / 100: avg data time: 7.28e-02, avg batch time: 0.4859, average train loss: 0.5057
[09/26 03:53:37 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1586, average loss: 0.7973
[09/26 03:53:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 03:53:37 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 03:53:44 visual_prompt]: Epoch 39 / 100: avg data time: 6.37e-02, avg batch time: 0.4780, average train loss: 0.4006
[09/26 03:53:45 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1584, average loss: 0.7470
[09/26 03:53:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.50	
[09/26 03:53:45 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 03:53:52 visual_prompt]: Epoch 40 / 100: avg data time: 6.35e-02, avg batch time: 0.4760, average train loss: 0.3772
[09/26 03:53:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.6753
[09/26 03:53:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:53:53 visual_prompt]: Best epoch 40: best metric: 0.940
[09/26 03:53:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 03:54:00 visual_prompt]: Epoch 41 / 100: avg data time: 6.20e-02, avg batch time: 0.4744, average train loss: 0.3907
[09/26 03:54:02 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 0.7728
[09/26 03:54:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 03:54:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 03:54:08 visual_prompt]: Epoch 42 / 100: avg data time: 5.79e-02, avg batch time: 0.4716, average train loss: 0.4453
[09/26 03:54:10 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1579, average loss: 0.8285
[09/26 03:54:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 03:54:10 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 03:54:17 visual_prompt]: Epoch 43 / 100: avg data time: 6.93e-02, avg batch time: 0.4825, average train loss: 0.4830
[09/26 03:54:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 0.8862
[09/26 03:54:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 98.00	
[09/26 03:54:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 03:54:25 visual_prompt]: Epoch 44 / 100: avg data time: 6.63e-02, avg batch time: 0.4804, average train loss: 0.4705
[09/26 03:54:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1587, average loss: 0.7644
[09/26 03:54:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.50	
[09/26 03:54:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 03:54:33 visual_prompt]: Epoch 45 / 100: avg data time: 5.86e-02, avg batch time: 0.4737, average train loss: 0.4496
[09/26 03:54:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 0.8263
[09/26 03:54:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 03:54:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 03:54:42 visual_prompt]: Epoch 46 / 100: avg data time: 7.25e-02, avg batch time: 0.4871, average train loss: 0.4084
[09/26 03:54:44 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1581, average loss: 0.7091
[09/26 03:54:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 03:54:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 03:54:50 visual_prompt]: Epoch 47 / 100: avg data time: 6.46e-02, avg batch time: 0.4777, average train loss: 0.3545
[09/26 03:54:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1586, average loss: 0.6849
[09/26 03:54:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.00	
[09/26 03:54:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 03:54:59 visual_prompt]: Epoch 48 / 100: avg data time: 6.58e-02, avg batch time: 0.4797, average train loss: 0.3433
[09/26 03:55:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1584, average loss: 0.6909
[09/26 03:55:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:55:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 03:55:07 visual_prompt]: Epoch 49 / 100: avg data time: 6.91e-02, avg batch time: 0.4820, average train loss: 0.3596
[09/26 03:55:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 0.6939
[09/26 03:55:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:55:09 visual_prompt]: Best epoch 49: best metric: 0.945
[09/26 03:55:09 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 03:55:15 visual_prompt]: Epoch 50 / 100: avg data time: 6.54e-02, avg batch time: 0.4797, average train loss: 0.3658
[09/26 03:55:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 0.8255
[09/26 03:55:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 03:55:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 03:55:24 visual_prompt]: Epoch 51 / 100: avg data time: 6.48e-02, avg batch time: 0.4785, average train loss: 0.4269
[09/26 03:55:25 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1581, average loss: 0.7793
[09/26 03:55:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 03:55:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 03:55:32 visual_prompt]: Epoch 52 / 100: avg data time: 6.95e-02, avg batch time: 0.4830, average train loss: 0.4118
[09/26 03:55:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1577, average loss: 0.8450
[09/26 03:55:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 03:55:34 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 03:55:40 visual_prompt]: Epoch 53 / 100: avg data time: 6.88e-02, avg batch time: 0.4815, average train loss: 0.3888
[09/26 03:55:42 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1583, average loss: 3.9244
[09/26 03:55:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 81.00	
[09/26 03:55:42 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 03:55:49 visual_prompt]: Epoch 54 / 100: avg data time: 6.72e-02, avg batch time: 0.4810, average train loss: 0.7755
[09/26 03:55:50 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.6925
[09/26 03:55:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 03:55:50 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 03:55:57 visual_prompt]: Epoch 55 / 100: avg data time: 6.84e-02, avg batch time: 0.4820, average train loss: 0.3614
[09/26 03:55:59 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1587, average loss: 0.6849
[09/26 03:55:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.50	
[09/26 03:55:59 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 03:56:06 visual_prompt]: Epoch 56 / 100: avg data time: 6.94e-02, avg batch time: 0.4834, average train loss: 0.3241
[09/26 03:56:07 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1586, average loss: 0.6141
[09/26 03:56:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.50	
[09/26 03:56:07 visual_prompt]: Best epoch 56: best metric: 0.950
[09/26 03:56:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 03:56:14 visual_prompt]: Epoch 57 / 100: avg data time: 7.18e-02, avg batch time: 0.4844, average train loss: 0.2894
[09/26 03:56:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1586, average loss: 0.6196
[09/26 03:56:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 99.00	
[09/26 03:56:16 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 03:56:22 visual_prompt]: Epoch 58 / 100: avg data time: 7.13e-02, avg batch time: 0.4840, average train loss: 0.2923
[09/26 03:56:24 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.6291
[09/26 03:56:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:56:24 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 03:56:31 visual_prompt]: Epoch 59 / 100: avg data time: 7.35e-02, avg batch time: 0.4857, average train loss: 0.3052
[09/26 03:56:33 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 0.6361
[09/26 03:56:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 03:56:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 03:56:39 visual_prompt]: Epoch 60 / 100: avg data time: 7.25e-02, avg batch time: 0.4852, average train loss: 0.3016
[09/26 03:56:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1586, average loss: 0.6534
[09/26 03:56:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.50	
[09/26 03:56:41 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 03:56:48 visual_prompt]: Epoch 61 / 100: avg data time: 6.18e-02, avg batch time: 0.4755, average train loss: 0.4263
[09/26 03:56:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1580, average loss: 1.0183
[09/26 03:56:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 03:56:49 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 03:56:56 visual_prompt]: Epoch 62 / 100: avg data time: 5.94e-02, avg batch time: 0.4727, average train loss: 0.5245
[09/26 03:56:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 0.8177
[09/26 03:56:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 03:56:58 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 03:57:04 visual_prompt]: Epoch 63 / 100: avg data time: 6.96e-02, avg batch time: 0.4826, average train loss: 0.4529
[09/26 03:57:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.6733
[09/26 03:57:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 99.50	
[09/26 03:57:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 03:57:12 visual_prompt]: Epoch 64 / 100: avg data time: 6.59e-02, avg batch time: 0.4794, average train loss: 0.3500
[09/26 03:57:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1581, average loss: 0.6375
[09/26 03:57:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.50	
[09/26 03:57:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 03:57:21 visual_prompt]: Epoch 65 / 100: avg data time: 6.89e-02, avg batch time: 0.4810, average train loss: 0.2966
[09/26 03:57:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1581, average loss: 0.6039
[09/26 03:57:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.50	
[09/26 03:57:23 visual_prompt]: Best epoch 65: best metric: 0.955
[09/26 03:57:23 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 03:57:29 visual_prompt]: Epoch 66 / 100: avg data time: 6.52e-02, avg batch time: 0.4776, average train loss: 0.2765
[09/26 03:57:31 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1578, average loss: 0.5899
[09/26 03:57:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:57:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 03:57:38 visual_prompt]: Epoch 67 / 100: avg data time: 7.18e-02, avg batch time: 0.4837, average train loss: 0.2617
[09/26 03:57:39 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1582, average loss: 0.5952
[09/26 03:57:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.50	top5: 98.00	
[09/26 03:57:39 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 03:57:46 visual_prompt]: Epoch 68 / 100: avg data time: 6.64e-02, avg batch time: 0.4792, average train loss: 0.2563
[09/26 03:57:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1580, average loss: 0.6012
[09/26 03:57:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:57:48 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 03:57:54 visual_prompt]: Epoch 69 / 100: avg data time: 7.68e-02, avg batch time: 0.4899, average train loss: 0.2546
[09/26 03:57:56 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1579, average loss: 0.6167
[09/26 03:57:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 95.00	top5: 98.00	
[09/26 03:57:56 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 03:58:03 visual_prompt]: Epoch 70 / 100: avg data time: 6.70e-02, avg batch time: 0.4813, average train loss: 0.2613
[09/26 03:58:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 0.6092
[09/26 03:58:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 03:58:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 03:58:11 visual_prompt]: Epoch 71 / 100: avg data time: 7.03e-02, avg batch time: 0.4823, average train loss: 0.2593
[09/26 03:58:13 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1580, average loss: 0.6108
[09/26 03:58:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 03:58:13 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 03:58:20 visual_prompt]: Epoch 72 / 100: avg data time: 6.50e-02, avg batch time: 0.4787, average train loss: 0.2547
[09/26 03:58:21 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1577, average loss: 0.5992
[09/26 03:58:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:58:21 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 03:58:28 visual_prompt]: Epoch 73 / 100: avg data time: 6.76e-02, avg batch time: 0.4802, average train loss: 0.2527
[09/26 03:58:30 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 0.6412
[09/26 03:58:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 03:58:30 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 03:58:37 visual_prompt]: Epoch 74 / 100: avg data time: 6.98e-02, avg batch time: 0.4831, average train loss: 0.2517
[09/26 03:58:38 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.6349
[09/26 03:58:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.00	
[09/26 03:58:38 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 03:58:45 visual_prompt]: Epoch 75 / 100: avg data time: 6.30e-02, avg batch time: 0.4760, average train loss: 0.2501
[09/26 03:58:47 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1579, average loss: 0.6217
[09/26 03:58:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 03:58:47 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 03:58:53 visual_prompt]: Epoch 76 / 100: avg data time: 7.68e-02, avg batch time: 0.4896, average train loss: 0.2456
[09/26 03:58:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1579, average loss: 0.6222
[09/26 03:58:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 99.00	
[09/26 03:58:55 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 03:59:02 visual_prompt]: Epoch 77 / 100: avg data time: 6.37e-02, avg batch time: 0.4790, average train loss: 0.2455
[09/26 03:59:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.5914
[09/26 03:59:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.00	
[09/26 03:59:03 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 03:59:10 visual_prompt]: Epoch 78 / 100: avg data time: 6.08e-02, avg batch time: 0.4741, average train loss: 0.2455
[09/26 03:59:12 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 0.5997
[09/26 03:59:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 99.00	
[09/26 03:59:12 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 03:59:18 visual_prompt]: Epoch 79 / 100: avg data time: 7.20e-02, avg batch time: 0.4842, average train loss: 0.2410
[09/26 03:59:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.6165
[09/26 03:59:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 98.50	
[09/26 03:59:20 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 03:59:27 visual_prompt]: Epoch 80 / 100: avg data time: 6.91e-02, avg batch time: 0.4824, average train loss: 0.2375
[09/26 03:59:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1585, average loss: 0.5878
[09/26 03:59:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 99.00	
[09/26 03:59:28 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 03:59:35 visual_prompt]: Epoch 81 / 100: avg data time: 5.77e-02, avg batch time: 0.4710, average train loss: 0.2359
[09/26 03:59:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1580, average loss: 0.6208
[09/26 03:59:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.50	
[09/26 03:59:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 03:59:43 visual_prompt]: Epoch 82 / 100: avg data time: 6.91e-02, avg batch time: 0.4824, average train loss: 0.2341
[09/26 03:59:45 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.6124
[09/26 03:59:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 98.00	
[09/26 03:59:45 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 03:59:52 visual_prompt]: Epoch 83 / 100: avg data time: 6.61e-02, avg batch time: 0.4794, average train loss: 0.2315
[09/26 03:59:53 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.6356
[09/26 03:59:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 03:59:53 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:00:00 visual_prompt]: Epoch 84 / 100: avg data time: 6.74e-02, avg batch time: 0.4798, average train loss: 0.2297
[09/26 04:00:02 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1582, average loss: 0.5858
[09/26 04:00:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.00	top5: 97.50	
[09/26 04:00:02 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:00:09 visual_prompt]: Epoch 85 / 100: avg data time: 6.98e-02, avg batch time: 0.4821, average train loss: 0.2280
[09/26 04:00:10 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 0.6309
[09/26 04:00:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 97.50	
[09/26 04:00:10 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:00:17 visual_prompt]: Epoch 86 / 100: avg data time: 5.29e-02, avg batch time: 0.4667, average train loss: 0.2280
[09/26 04:00:18 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1581, average loss: 0.5926
[09/26 04:00:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 04:00:18 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:00:25 visual_prompt]: Epoch 87 / 100: avg data time: 7.03e-02, avg batch time: 0.4830, average train loss: 0.2272
[09/26 04:00:27 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1577, average loss: 0.6014
[09/26 04:00:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 94.50	top5: 98.50	
[09/26 04:00:27 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:00:33 visual_prompt]: Epoch 88 / 100: avg data time: 6.43e-02, avg batch time: 0.4764, average train loss: 0.2264
[09/26 04:00:35 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1571, average loss: 0.6384
[09/26 04:00:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 04:00:35 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:00:42 visual_prompt]: Epoch 89 / 100: avg data time: 7.00e-02, avg batch time: 0.4832, average train loss: 0.2252
[09/26 04:00:44 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1581, average loss: 0.6163
[09/26 04:00:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 04:00:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:00:50 visual_prompt]: Epoch 90 / 100: avg data time: 6.24e-02, avg batch time: 0.4763, average train loss: 0.2243
[09/26 04:00:52 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1581, average loss: 0.6261
[09/26 04:00:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 04:00:52 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:00:59 visual_prompt]: Epoch 91 / 100: avg data time: 6.52e-02, avg batch time: 0.4801, average train loss: 0.2239
[09/26 04:01:00 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1583, average loss: 0.6242
[09/26 04:01:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 04:01:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:01:07 visual_prompt]: Epoch 92 / 100: avg data time: 6.80e-02, avg batch time: 0.4820, average train loss: 0.2232
[09/26 04:01:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1584, average loss: 0.6267
[09/26 04:01:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.50	top5: 98.00	
[09/26 04:01:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:01:15 visual_prompt]: Epoch 93 / 100: avg data time: 6.39e-02, avg batch time: 0.4775, average train loss: 0.2228
[09/26 04:01:17 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1578, average loss: 0.6346
[09/26 04:01:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 04:01:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:01:24 visual_prompt]: Epoch 94 / 100: avg data time: 6.62e-02, avg batch time: 0.4795, average train loss: 0.2226
[09/26 04:01:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.6382
[09/26 04:01:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:01:26 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:01:32 visual_prompt]: Epoch 95 / 100: avg data time: 6.19e-02, avg batch time: 0.4751, average train loss: 0.2225
[09/26 04:01:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.6263
[09/26 04:01:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 04:01:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:01:40 visual_prompt]: Epoch 96 / 100: avg data time: 6.41e-02, avg batch time: 0.4776, average train loss: 0.2221
[09/26 04:01:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1579, average loss: 0.6370
[09/26 04:01:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 04:01:42 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:01:49 visual_prompt]: Epoch 97 / 100: avg data time: 7.27e-02, avg batch time: 0.4862, average train loss: 0.2220
[09/26 04:01:51 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1583, average loss: 0.6343
[09/26 04:01:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 98.00	
[09/26 04:01:51 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:01:57 visual_prompt]: Epoch 98 / 100: avg data time: 6.49e-02, avg batch time: 0.4782, average train loss: 0.2222
[09/26 04:01:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.6331
[09/26 04:01:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 04:01:59 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:02:06 visual_prompt]: Epoch 99 / 100: avg data time: 6.44e-02, avg batch time: 0.4770, average train loss: 0.2222
[09/26 04:02:07 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1581, average loss: 0.6326
[09/26 04:02:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 04:02:07 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:02:14 visual_prompt]: Epoch 100 / 100: avg data time: 6.81e-02, avg batch time: 0.4810, average train loss: 0.2219
[09/26 04:02:16 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1582, average loss: 0.6325
[09/26 04:02:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 04:02:16 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:02:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:02:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:02:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:02:16 visual_prompt]: Training with config:
[09/26 04:02:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:02:16 visual_prompt]: Loading training data...
[09/26 04:02:16 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:02:17 visual_prompt]: Number of images: 800
[09/26 04:02:17 visual_prompt]: Number of classes: 102 / 102
[09/26 04:02:17 visual_prompt]: Loading validation data...
[09/26 04:02:17 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:02:18 visual_prompt]: Number of images: 200
[09/26 04:02:18 visual_prompt]: Number of classes: 91 / 102
[09/26 04:02:18 visual_prompt]: Constructing models...
[09/26 04:02:20 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 04:02:20 visual_prompt]: tuned percent:0.625
[09/26 04:02:20 visual_prompt]: Device used for model: 0
[09/26 04:02:20 visual_prompt]: Setting up Evaluator...
[09/26 04:02:20 visual_prompt]: Setting up Trainer...
[09/26 04:02:20 visual_prompt]: 	Setting up the optimizer...
[09/26 04:02:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:02:27 visual_prompt]: Epoch 1 / 100: avg data time: 7.47e-02, avg batch time: 0.4923, average train loss: 4.6652
[09/26 04:02:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 4.6780
[09/26 04:02:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 04:02:29 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:02:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:02:35 visual_prompt]: Epoch 2 / 100: avg data time: 6.66e-02, avg batch time: 0.4789, average train loss: 4.6311
[09/26 04:02:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 4.6310
[09/26 04:02:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 04:02:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:02:44 visual_prompt]: Epoch 3 / 100: avg data time: 5.47e-02, avg batch time: 0.4699, average train loss: 4.5546
[09/26 04:02:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 4.5329
[09/26 04:02:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 12.00	
[09/26 04:02:45 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 04:02:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:02:52 visual_prompt]: Epoch 4 / 100: avg data time: 5.98e-02, avg batch time: 0.4740, average train loss: 4.3316
[09/26 04:02:54 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1579, average loss: 4.2405
[09/26 04:02:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.50	top5: 22.50	
[09/26 04:02:54 visual_prompt]: Best epoch 4: best metric: 0.075
[09/26 04:02:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:03:00 visual_prompt]: Epoch 5 / 100: avg data time: 6.84e-02, avg batch time: 0.4825, average train loss: 3.8609
[09/26 04:03:02 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1587, average loss: 3.5913
[09/26 04:03:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 18.00	top5: 35.50	
[09/26 04:03:02 visual_prompt]: Best epoch 5: best metric: 0.180
[09/26 04:03:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:03:09 visual_prompt]: Epoch 6 / 100: avg data time: 6.38e-02, avg batch time: 0.4766, average train loss: 3.2239
[09/26 04:03:10 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1574, average loss: 3.0377
[09/26 04:03:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 26.50	top5: 60.00	
[09/26 04:03:10 visual_prompt]: Best epoch 6: best metric: 0.265
[09/26 04:03:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:03:17 visual_prompt]: Epoch 7 / 100: avg data time: 7.02e-02, avg batch time: 0.4848, average train loss: 2.2876
[09/26 04:03:19 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1586, average loss: 2.1961
[09/26 04:03:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 50.50	top5: 78.50	
[09/26 04:03:19 visual_prompt]: Best epoch 7: best metric: 0.505
[09/26 04:03:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:03:26 visual_prompt]: Epoch 8 / 100: avg data time: 6.27e-02, avg batch time: 0.4766, average train loss: 1.3126
[09/26 04:03:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 1.3879
[09/26 04:03:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 71.50	top5: 89.50	
[09/26 04:03:27 visual_prompt]: Best epoch 8: best metric: 0.715
[09/26 04:03:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:03:34 visual_prompt]: Epoch 9 / 100: avg data time: 5.44e-02, avg batch time: 0.4697, average train loss: 0.6796
[09/26 04:03:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 0.9779
[09/26 04:03:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 95.50	
[09/26 04:03:36 visual_prompt]: Best epoch 9: best metric: 0.755
[09/26 04:03:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:03:42 visual_prompt]: Epoch 10 / 100: avg data time: 6.54e-02, avg batch time: 0.4788, average train loss: 0.3557
[09/26 04:03:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1582, average loss: 0.8325
[09/26 04:03:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 95.00	
[09/26 04:03:44 visual_prompt]: Best epoch 10: best metric: 0.790
[09/26 04:03:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:03:50 visual_prompt]: Epoch 11 / 100: avg data time: 5.77e-02, avg batch time: 0.4718, average train loss: 0.1956
[09/26 04:03:52 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1586, average loss: 0.7027
[09/26 04:03:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.50	
[09/26 04:03:52 visual_prompt]: Best epoch 11: best metric: 0.830
[09/26 04:03:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:03:59 visual_prompt]: Epoch 12 / 100: avg data time: 5.72e-02, avg batch time: 0.4711, average train loss: 0.1211
[09/26 04:04:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 0.6473
[09/26 04:04:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 04:04:00 visual_prompt]: Best epoch 12: best metric: 0.845
[09/26 04:04:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:04:07 visual_prompt]: Epoch 13 / 100: avg data time: 5.46e-02, avg batch time: 0.4699, average train loss: 0.0784
[09/26 04:04:09 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1580, average loss: 0.6381
[09/26 04:04:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 04:04:09 visual_prompt]: Best epoch 13: best metric: 0.855
[09/26 04:04:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:04:15 visual_prompt]: Epoch 14 / 100: avg data time: 7.15e-02, avg batch time: 0.4859, average train loss: 0.0599
[09/26 04:04:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 0.5868
[09/26 04:04:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:04:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:04:24 visual_prompt]: Epoch 15 / 100: avg data time: 6.55e-02, avg batch time: 0.4794, average train loss: 0.0486
[09/26 04:04:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 0.5812
[09/26 04:04:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.00	
[09/26 04:04:25 visual_prompt]: Best epoch 15: best metric: 0.865
[09/26 04:04:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:04:32 visual_prompt]: Epoch 16 / 100: avg data time: 5.69e-02, avg batch time: 0.4716, average train loss: 0.0424
[09/26 04:04:34 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1587, average loss: 0.5880
[09/26 04:04:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.50	
[09/26 04:04:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:04:40 visual_prompt]: Epoch 17 / 100: avg data time: 6.47e-02, avg batch time: 0.4783, average train loss: 0.0401
[09/26 04:04:42 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1583, average loss: 0.5966
[09/26 04:04:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 97.50	
[09/26 04:04:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:04:49 visual_prompt]: Epoch 18 / 100: avg data time: 6.67e-02, avg batch time: 0.4808, average train loss: 0.0374
[09/26 04:04:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1591, average loss: 0.5856
[09/26 04:04:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 04:04:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:04:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.23e-02, avg batch time: 0.4784, average train loss: 0.0364
[09/26 04:04:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 0.5803
[09/26 04:04:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:04:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:05:05 visual_prompt]: Epoch 20 / 100: avg data time: 7.43e-02, avg batch time: 0.4887, average train loss: 0.0365
[09/26 04:05:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 0.5798
[09/26 04:05:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 04:05:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:05:14 visual_prompt]: Epoch 21 / 100: avg data time: 6.55e-02, avg batch time: 0.4798, average train loss: 0.0356
[09/26 04:05:15 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.5789
[09/26 04:05:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:05:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:05:22 visual_prompt]: Epoch 22 / 100: avg data time: 6.52e-02, avg batch time: 0.4785, average train loss: 0.0348
[09/26 04:05:24 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1585, average loss: 0.5515
[09/26 04:05:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 04:05:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:05:30 visual_prompt]: Epoch 23 / 100: avg data time: 6.73e-02, avg batch time: 0.4808, average train loss: 0.0348
[09/26 04:05:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 0.5460
[09/26 04:05:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.50	
[09/26 04:05:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:05:39 visual_prompt]: Epoch 24 / 100: avg data time: 7.07e-02, avg batch time: 0.4841, average train loss: 0.0346
[09/26 04:05:41 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 0.5672
[09/26 04:05:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 04:05:41 visual_prompt]: Best epoch 24: best metric: 0.875
[09/26 04:05:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:05:47 visual_prompt]: Epoch 25 / 100: avg data time: 7.34e-02, avg batch time: 0.4875, average train loss: 0.0346
[09/26 04:05:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1582, average loss: 0.5528
[09/26 04:05:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 04:05:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:05:56 visual_prompt]: Epoch 26 / 100: avg data time: 5.81e-02, avg batch time: 0.4726, average train loss: 0.0346
[09/26 04:05:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.5623
[09/26 04:05:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.50	
[09/26 04:05:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:06:04 visual_prompt]: Epoch 27 / 100: avg data time: 6.70e-02, avg batch time: 0.4808, average train loss: 0.0354
[09/26 04:06:06 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1588, average loss: 0.5494
[09/26 04:06:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 04:06:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:06:12 visual_prompt]: Epoch 28 / 100: avg data time: 6.80e-02, avg batch time: 0.4814, average train loss: 0.0351
[09/26 04:06:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 0.5316
[09/26 04:06:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.50	
[09/26 04:06:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:06:21 visual_prompt]: Epoch 29 / 100: avg data time: 6.36e-02, avg batch time: 0.4782, average train loss: 0.0357
[09/26 04:06:22 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1585, average loss: 0.5448
[09/26 04:06:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 04:06:22 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:06:29 visual_prompt]: Epoch 30 / 100: avg data time: 6.98e-02, avg batch time: 0.4828, average train loss: 0.0363
[09/26 04:06:31 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 0.5615
[09/26 04:06:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:06:31 visual_prompt]: Best epoch 30: best metric: 0.880
[09/26 04:06:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:06:37 visual_prompt]: Epoch 31 / 100: avg data time: 7.09e-02, avg batch time: 0.4838, average train loss: 0.0358
[09/26 04:06:39 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1588, average loss: 0.5122
[09/26 04:06:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 98.00	
[09/26 04:06:39 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:06:46 visual_prompt]: Epoch 32 / 100: avg data time: 7.04e-02, avg batch time: 0.4843, average train loss: 0.0354
[09/26 04:06:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1579, average loss: 0.5548
[09/26 04:06:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 97.00	
[09/26 04:06:48 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:06:54 visual_prompt]: Epoch 33 / 100: avg data time: 5.74e-02, avg batch time: 0.4731, average train loss: 0.0348
[09/26 04:06:56 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1582, average loss: 0.4975
[09/26 04:06:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 98.50	
[09/26 04:06:56 visual_prompt]: Best epoch 33: best metric: 0.890
[09/26 04:06:56 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:07:02 visual_prompt]: Epoch 34 / 100: avg data time: 5.23e-02, avg batch time: 0.4657, average train loss: 0.0344
[09/26 04:07:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1586, average loss: 0.5296
[09/26 04:07:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.50	
[09/26 04:07:04 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:07:11 visual_prompt]: Epoch 35 / 100: avg data time: 5.68e-02, avg batch time: 0.4727, average train loss: 0.0668
[09/26 04:07:12 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1586, average loss: 0.7013
[09/26 04:07:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:07:12 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:07:19 visual_prompt]: Epoch 36 / 100: avg data time: 6.54e-02, avg batch time: 0.4797, average train loss: 0.2088
[09/26 04:07:21 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1584, average loss: 0.8329
[09/26 04:07:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.00	
[09/26 04:07:21 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:07:27 visual_prompt]: Epoch 37 / 100: avg data time: 6.97e-02, avg batch time: 0.4833, average train loss: 0.2680
[09/26 04:07:29 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1580, average loss: 0.7966
[09/26 04:07:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.50	
[09/26 04:07:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:07:36 visual_prompt]: Epoch 38 / 100: avg data time: 6.50e-02, avg batch time: 0.4795, average train loss: 0.2163
[09/26 04:07:38 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1581, average loss: 0.6369
[09/26 04:07:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 04:07:38 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:07:44 visual_prompt]: Epoch 39 / 100: avg data time: 6.39e-02, avg batch time: 0.4772, average train loss: 0.1240
[09/26 04:07:46 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1582, average loss: 0.5203
[09/26 04:07:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.50	
[09/26 04:07:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:07:53 visual_prompt]: Epoch 40 / 100: avg data time: 6.39e-02, avg batch time: 0.4781, average train loss: 0.0728
[09/26 04:07:54 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1579, average loss: 0.4844
[09/26 04:07:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 98.00	
[09/26 04:07:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:08:01 visual_prompt]: Epoch 41 / 100: avg data time: 6.43e-02, avg batch time: 0.4791, average train loss: 0.0412
[09/26 04:08:03 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1581, average loss: 0.4094
[09/26 04:08:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 98.00	
[09/26 04:08:03 visual_prompt]: Best epoch 41: best metric: 0.925
[09/26 04:08:03 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:08:09 visual_prompt]: Epoch 42 / 100: avg data time: 6.53e-02, avg batch time: 0.4797, average train loss: 0.0346
[09/26 04:08:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1586, average loss: 0.3974
[09/26 04:08:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 04:08:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:08:18 visual_prompt]: Epoch 43 / 100: avg data time: 7.10e-02, avg batch time: 0.4852, average train loss: 0.0301
[09/26 04:08:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1585, average loss: 0.4108
[09/26 04:08:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:08:20 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:08:26 visual_prompt]: Epoch 44 / 100: avg data time: 6.97e-02, avg batch time: 0.4837, average train loss: 0.0285
[09/26 04:08:28 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1578, average loss: 0.3919
[09/26 04:08:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 04:08:28 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:08:35 visual_prompt]: Epoch 45 / 100: avg data time: 6.42e-02, avg batch time: 0.4796, average train loss: 0.0270
[09/26 04:08:36 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1584, average loss: 0.3944
[09/26 04:08:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.50	
[09/26 04:08:36 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:08:43 visual_prompt]: Epoch 46 / 100: avg data time: 7.03e-02, avg batch time: 0.4841, average train loss: 0.0272
[09/26 04:08:45 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.4004
[09/26 04:08:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:08:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:08:52 visual_prompt]: Epoch 47 / 100: avg data time: 6.37e-02, avg batch time: 0.4805, average train loss: 0.0273
[09/26 04:08:53 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1579, average loss: 0.3982
[09/26 04:08:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:08:53 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:09:00 visual_prompt]: Epoch 48 / 100: avg data time: 6.48e-02, avg batch time: 0.4777, average train loss: 0.0275
[09/26 04:09:02 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1583, average loss: 0.4036
[09/26 04:09:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 04:09:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:09:08 visual_prompt]: Epoch 49 / 100: avg data time: 6.39e-02, avg batch time: 0.4775, average train loss: 0.0276
[09/26 04:09:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.4046
[09/26 04:09:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 98.00	
[09/26 04:09:10 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:09:17 visual_prompt]: Epoch 50 / 100: avg data time: 6.93e-02, avg batch time: 0.4832, average train loss: 0.0280
[09/26 04:09:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.4044
[09/26 04:09:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 98.00	
[09/26 04:09:18 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:09:25 visual_prompt]: Epoch 51 / 100: avg data time: 6.28e-02, avg batch time: 0.4782, average train loss: 0.0282
[09/26 04:09:27 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1581, average loss: 0.4082
[09/26 04:09:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:09:27 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:09:33 visual_prompt]: Epoch 52 / 100: avg data time: 6.57e-02, avg batch time: 0.4800, average train loss: 0.0283
[09/26 04:09:35 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1583, average loss: 0.3996
[09/26 04:09:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:09:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:09:42 visual_prompt]: Epoch 53 / 100: avg data time: 6.77e-02, avg batch time: 0.4835, average train loss: 0.0288
[09/26 04:09:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1578, average loss: 0.3993
[09/26 04:09:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:09:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:09:50 visual_prompt]: Epoch 54 / 100: avg data time: 6.84e-02, avg batch time: 0.4818, average train loss: 0.0291
[09/26 04:09:52 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1581, average loss: 0.3975
[09/26 04:09:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:09:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:09:59 visual_prompt]: Epoch 55 / 100: avg data time: 6.47e-02, avg batch time: 0.4793, average train loss: 0.0294
[09/26 04:10:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1587, average loss: 0.3982
[09/26 04:10:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:10:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:10:07 visual_prompt]: Epoch 56 / 100: avg data time: 6.76e-02, avg batch time: 0.4828, average train loss: 0.0292
[09/26 04:10:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 0.4100
[09/26 04:10:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 04:10:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:10:15 visual_prompt]: Epoch 57 / 100: avg data time: 6.09e-02, avg batch time: 0.4762, average train loss: 0.0297
[09/26 04:10:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.3911
[09/26 04:10:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:10:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:10:24 visual_prompt]: Epoch 58 / 100: avg data time: 6.82e-02, avg batch time: 0.4815, average train loss: 0.0297
[09/26 04:10:25 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.4056
[09/26 04:10:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:10:25 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:10:32 visual_prompt]: Epoch 59 / 100: avg data time: 6.47e-02, avg batch time: 0.4800, average train loss: 0.0298
[09/26 04:10:34 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1580, average loss: 0.3985
[09/26 04:10:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:10:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:10:40 visual_prompt]: Epoch 60 / 100: avg data time: 5.00e-02, avg batch time: 0.4656, average train loss: 0.0297
[09/26 04:10:42 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1584, average loss: 0.4061
[09/26 04:10:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 04:10:42 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:10:49 visual_prompt]: Epoch 61 / 100: avg data time: 6.97e-02, avg batch time: 0.4855, average train loss: 0.0301
[09/26 04:10:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.4052
[09/26 04:10:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:10:50 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:10:57 visual_prompt]: Epoch 62 / 100: avg data time: 5.49e-02, avg batch time: 0.4706, average train loss: 0.0298
[09/26 04:10:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1587, average loss: 0.4141
[09/26 04:10:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 04:10:59 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:11:05 visual_prompt]: Epoch 63 / 100: avg data time: 6.98e-02, avg batch time: 0.4833, average train loss: 0.0300
[09/26 04:11:07 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 0.3983
[09/26 04:11:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:11:07 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:11:14 visual_prompt]: Epoch 64 / 100: avg data time: 6.71e-02, avg batch time: 0.4804, average train loss: 0.0303
[09/26 04:11:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1586, average loss: 0.4057
[09/26 04:11:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:11:15 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:11:22 visual_prompt]: Epoch 65 / 100: avg data time: 6.86e-02, avg batch time: 0.4827, average train loss: 0.0300
[09/26 04:11:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1580, average loss: 0.3955
[09/26 04:11:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:11:24 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:11:30 visual_prompt]: Epoch 66 / 100: avg data time: 6.61e-02, avg batch time: 0.4804, average train loss: 0.0300
[09/26 04:11:32 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1584, average loss: 0.3983
[09/26 04:11:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 04:11:32 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:11:39 visual_prompt]: Epoch 67 / 100: avg data time: 6.80e-02, avg batch time: 0.4811, average train loss: 0.0299
[09/26 04:11:40 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1581, average loss: 0.4063
[09/26 04:11:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.00	
[09/26 04:11:40 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:11:47 visual_prompt]: Epoch 68 / 100: avg data time: 6.70e-02, avg batch time: 0.4802, average train loss: 0.0303
[09/26 04:11:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1578, average loss: 0.4012
[09/26 04:11:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:11:49 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:11:55 visual_prompt]: Epoch 69 / 100: avg data time: 6.60e-02, avg batch time: 0.4817, average train loss: 0.0302
[09/26 04:11:57 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1586, average loss: 0.3999
[09/26 04:11:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:11:57 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:12:04 visual_prompt]: Epoch 70 / 100: avg data time: 6.91e-02, avg batch time: 0.4829, average train loss: 0.0302
[09/26 04:12:05 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1584, average loss: 0.3909
[09/26 04:12:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:12:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:12:12 visual_prompt]: Epoch 71 / 100: avg data time: 5.57e-02, avg batch time: 0.4722, average train loss: 0.0301
[09/26 04:12:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.3978
[09/26 04:12:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:12:14 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:12:20 visual_prompt]: Epoch 72 / 100: avg data time: 6.68e-02, avg batch time: 0.4804, average train loss: 0.0300
[09/26 04:12:22 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1581, average loss: 0.3958
[09/26 04:12:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.50	
[09/26 04:12:22 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:12:29 visual_prompt]: Epoch 73 / 100: avg data time: 6.58e-02, avg batch time: 0.4801, average train loss: 0.0302
[09/26 04:12:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1578, average loss: 0.4037
[09/26 04:12:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:12:30 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:12:37 visual_prompt]: Epoch 74 / 100: avg data time: 6.11e-02, avg batch time: 0.4742, average train loss: 0.0300
[09/26 04:12:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1578, average loss: 0.3920
[09/26 04:12:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 04:12:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:12:45 visual_prompt]: Epoch 75 / 100: avg data time: 6.48e-02, avg batch time: 0.4795, average train loss: 0.0300
[09/26 04:12:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.3949
[09/26 04:12:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:12:47 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:12:54 visual_prompt]: Epoch 76 / 100: avg data time: 6.31e-02, avg batch time: 0.4762, average train loss: 0.0301
[09/26 04:12:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1584, average loss: 0.3884
[09/26 04:12:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:12:55 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:13:02 visual_prompt]: Epoch 77 / 100: avg data time: 6.73e-02, avg batch time: 0.4802, average train loss: 0.0298
[09/26 04:13:04 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1577, average loss: 0.3945
[09/26 04:13:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:13:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:13:10 visual_prompt]: Epoch 78 / 100: avg data time: 6.59e-02, avg batch time: 0.4802, average train loss: 0.0298
[09/26 04:13:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 0.3930
[09/26 04:13:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:13:12 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:13:19 visual_prompt]: Epoch 79 / 100: avg data time: 7.16e-02, avg batch time: 0.4854, average train loss: 0.0300
[09/26 04:13:20 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 0.3911
[09/26 04:13:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:13:20 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:13:27 visual_prompt]: Epoch 80 / 100: avg data time: 6.29e-02, avg batch time: 0.4758, average train loss: 0.0299
[09/26 04:13:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1586, average loss: 0.3952
[09/26 04:13:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:13:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:13:35 visual_prompt]: Epoch 81 / 100: avg data time: 6.65e-02, avg batch time: 0.4792, average train loss: 0.0300
[09/26 04:13:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.3901
[09/26 04:13:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:13:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:13:44 visual_prompt]: Epoch 82 / 100: avg data time: 6.28e-02, avg batch time: 0.4758, average train loss: 0.0298
[09/26 04:13:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1585, average loss: 0.3879
[09/26 04:13:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:13:45 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:13:52 visual_prompt]: Epoch 83 / 100: avg data time: 5.23e-02, avg batch time: 0.4689, average train loss: 0.0299
[09/26 04:13:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1577, average loss: 0.3904
[09/26 04:13:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:13:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:14:00 visual_prompt]: Epoch 84 / 100: avg data time: 5.67e-02, avg batch time: 0.4729, average train loss: 0.0300
[09/26 04:14:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.3927
[09/26 04:14:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:02 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:14:09 visual_prompt]: Epoch 85 / 100: avg data time: 6.55e-02, avg batch time: 0.4798, average train loss: 0.0297
[09/26 04:14:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1579, average loss: 0.3905
[09/26 04:14:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:10 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:14:17 visual_prompt]: Epoch 86 / 100: avg data time: 6.49e-02, avg batch time: 0.4791, average train loss: 0.0297
[09/26 04:14:19 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1587, average loss: 0.3894
[09/26 04:14:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:19 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:14:25 visual_prompt]: Epoch 87 / 100: avg data time: 6.22e-02, avg batch time: 0.4749, average train loss: 0.0299
[09/26 04:14:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1580, average loss: 0.3909
[09/26 04:14:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:27 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:14:33 visual_prompt]: Epoch 88 / 100: avg data time: 6.26e-02, avg batch time: 0.4764, average train loss: 0.0299
[09/26 04:14:35 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.3938
[09/26 04:14:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:35 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:14:42 visual_prompt]: Epoch 89 / 100: avg data time: 6.80e-02, avg batch time: 0.4815, average train loss: 0.0297
[09/26 04:14:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 0.3913
[09/26 04:14:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:14:50 visual_prompt]: Epoch 90 / 100: avg data time: 5.87e-02, avg batch time: 0.4737, average train loss: 0.0296
[09/26 04:14:52 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1586, average loss: 0.3903
[09/26 04:14:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:14:52 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:14:59 visual_prompt]: Epoch 91 / 100: avg data time: 6.82e-02, avg batch time: 0.4807, average train loss: 0.0298
[09/26 04:15:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1582, average loss: 0.3901
[09/26 04:15:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:15:07 visual_prompt]: Epoch 92 / 100: avg data time: 5.35e-02, avg batch time: 0.4680, average train loss: 0.0296
[09/26 04:15:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 0.3893
[09/26 04:15:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:15:15 visual_prompt]: Epoch 93 / 100: avg data time: 6.76e-02, avg batch time: 0.4800, average train loss: 0.0298
[09/26 04:15:17 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1575, average loss: 0.3884
[09/26 04:15:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:15:24 visual_prompt]: Epoch 94 / 100: avg data time: 6.93e-02, avg batch time: 0.4836, average train loss: 0.0297
[09/26 04:15:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1576, average loss: 0.3882
[09/26 04:15:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:25 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:15:32 visual_prompt]: Epoch 95 / 100: avg data time: 6.13e-02, avg batch time: 0.4755, average train loss: 0.0296
[09/26 04:15:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1585, average loss: 0.3891
[09/26 04:15:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:15:40 visual_prompt]: Epoch 96 / 100: avg data time: 5.85e-02, avg batch time: 0.4715, average train loss: 0.0297
[09/26 04:15:42 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1579, average loss: 0.3888
[09/26 04:15:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:42 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:15:49 visual_prompt]: Epoch 97 / 100: avg data time: 5.35e-02, avg batch time: 0.4676, average train loss: 0.0296
[09/26 04:15:50 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1583, average loss: 0.3888
[09/26 04:15:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:50 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:15:57 visual_prompt]: Epoch 98 / 100: avg data time: 6.27e-02, avg batch time: 0.4761, average train loss: 0.0296
[09/26 04:15:59 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 0.3888
[09/26 04:15:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:15:59 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:16:05 visual_prompt]: Epoch 99 / 100: avg data time: 6.82e-02, avg batch time: 0.4812, average train loss: 0.0296
[09/26 04:16:07 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1589, average loss: 0.3888
[09/26 04:16:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:16:07 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:16:14 visual_prompt]: Epoch 100 / 100: avg data time: 6.22e-02, avg batch time: 0.4779, average train loss: 0.0298
[09/26 04:16:15 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1581, average loss: 0.3888
[09/26 04:16:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.50	
[09/26 04:16:16 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:16:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:16:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:16:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:16:16 visual_prompt]: Training with config:
[09/26 04:16:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:16:16 visual_prompt]: Loading training data...
[09/26 04:16:16 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:16:17 visual_prompt]: Number of images: 800
[09/26 04:16:17 visual_prompt]: Number of classes: 102 / 102
[09/26 04:16:17 visual_prompt]: Loading validation data...
[09/26 04:16:17 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:16:17 visual_prompt]: Number of images: 200
[09/26 04:16:17 visual_prompt]: Number of classes: 91 / 102
[09/26 04:16:17 visual_prompt]: Constructing models...
[09/26 04:16:20 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 04:16:20 visual_prompt]: tuned percent:0.625
[09/26 04:16:20 visual_prompt]: Device used for model: 0
[09/26 04:16:20 visual_prompt]: Setting up Evaluator...
[09/26 04:16:20 visual_prompt]: Setting up Trainer...
[09/26 04:16:20 visual_prompt]: 	Setting up the optimizer...
[09/26 04:16:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:16:27 visual_prompt]: Epoch 1 / 100: avg data time: 6.22e-02, avg batch time: 0.4818, average train loss: 4.6687
[09/26 04:16:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1578, average loss: 4.6780
[09/26 04:16:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 04:16:28 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:16:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:16:35 visual_prompt]: Epoch 2 / 100: avg data time: 6.65e-02, avg batch time: 0.4788, average train loss: 4.6282
[09/26 04:16:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 4.6036
[09/26 04:16:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 04:16:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:16:43 visual_prompt]: Epoch 3 / 100: avg data time: 5.68e-02, avg batch time: 0.4709, average train loss: 4.5042
[09/26 04:16:45 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1580, average loss: 4.4673
[09/26 04:16:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.00	top5: 13.50	
[09/26 04:16:45 visual_prompt]: Best epoch 3: best metric: 0.050
[09/26 04:16:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:16:52 visual_prompt]: Epoch 4 / 100: avg data time: 6.70e-02, avg batch time: 0.4810, average train loss: 4.2214
[09/26 04:16:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 4.2888
[09/26 04:16:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.50	top5: 22.00	
[09/26 04:16:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:17:00 visual_prompt]: Epoch 5 / 100: avg data time: 6.42e-02, avg batch time: 0.4770, average train loss: 3.7029
[09/26 04:17:02 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 3.3783
[09/26 04:17:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 18.50	top5: 48.00	
[09/26 04:17:02 visual_prompt]: Best epoch 5: best metric: 0.185
[09/26 04:17:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:17:08 visual_prompt]: Epoch 6 / 100: avg data time: 6.40e-02, avg batch time: 0.4771, average train loss: 2.8280
[09/26 04:17:10 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1581, average loss: 2.6836
[09/26 04:17:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 36.00	top5: 67.00	
[09/26 04:17:10 visual_prompt]: Best epoch 6: best metric: 0.360
[09/26 04:17:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:17:17 visual_prompt]: Epoch 7 / 100: avg data time: 5.35e-02, avg batch time: 0.4672, average train loss: 1.8752
[09/26 04:17:18 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1581, average loss: 1.7635
[09/26 04:17:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 59.50	top5: 83.50	
[09/26 04:17:18 visual_prompt]: Best epoch 7: best metric: 0.595
[09/26 04:17:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:17:25 visual_prompt]: Epoch 8 / 100: avg data time: 6.39e-02, avg batch time: 0.4777, average train loss: 1.0784
[09/26 04:17:27 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1582, average loss: 1.2974
[09/26 04:17:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.00	top5: 89.00	
[09/26 04:17:27 visual_prompt]: Best epoch 8: best metric: 0.720
[09/26 04:17:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:17:33 visual_prompt]: Epoch 9 / 100: avg data time: 6.43e-02, avg batch time: 0.4800, average train loss: 0.5786
[09/26 04:17:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 1.0214
[09/26 04:17:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 92.00	
[09/26 04:17:35 visual_prompt]: Best epoch 9: best metric: 0.770
[09/26 04:17:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:17:42 visual_prompt]: Epoch 10 / 100: avg data time: 6.89e-02, avg batch time: 0.4829, average train loss: 0.3202
[09/26 04:17:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 0.8555
[09/26 04:17:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 93.00	
[09/26 04:17:43 visual_prompt]: Best epoch 10: best metric: 0.795
[09/26 04:17:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:17:50 visual_prompt]: Epoch 11 / 100: avg data time: 6.86e-02, avg batch time: 0.4817, average train loss: 0.1885
[09/26 04:17:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.6498
[09/26 04:17:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.50	
[09/26 04:17:52 visual_prompt]: Best epoch 11: best metric: 0.850
[09/26 04:17:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:17:59 visual_prompt]: Epoch 12 / 100: avg data time: 6.92e-02, avg batch time: 0.4827, average train loss: 0.1020
[09/26 04:18:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.6243
[09/26 04:18:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 04:18:00 visual_prompt]: Best epoch 12: best metric: 0.865
[09/26 04:18:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:18:07 visual_prompt]: Epoch 13 / 100: avg data time: 5.43e-02, avg batch time: 0.4691, average train loss: 0.0638
[09/26 04:18:09 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1586, average loss: 0.6138
[09/26 04:18:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.00	
[09/26 04:18:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:18:15 visual_prompt]: Epoch 14 / 100: avg data time: 6.20e-02, avg batch time: 0.4765, average train loss: 0.0412
[09/26 04:18:17 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1581, average loss: 0.5849
[09/26 04:18:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:18:17 visual_prompt]: Best epoch 14: best metric: 0.870
[09/26 04:18:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:18:24 visual_prompt]: Epoch 15 / 100: avg data time: 6.66e-02, avg batch time: 0.4803, average train loss: 0.0306
[09/26 04:18:25 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1582, average loss: 0.5798
[09/26 04:18:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.50	
[09/26 04:18:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:18:32 visual_prompt]: Epoch 16 / 100: avg data time: 5.44e-02, avg batch time: 0.4705, average train loss: 0.0241
[09/26 04:18:34 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 0.5584
[09/26 04:18:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:18:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:18:40 visual_prompt]: Epoch 17 / 100: avg data time: 5.34e-02, avg batch time: 0.4706, average train loss: 0.0232
[09/26 04:18:42 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1585, average loss: 0.5684
[09/26 04:18:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.00	
[09/26 04:18:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:18:48 visual_prompt]: Epoch 18 / 100: avg data time: 6.26e-02, avg batch time: 0.4767, average train loss: 0.0189
[09/26 04:18:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1582, average loss: 0.5426
[09/26 04:18:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:18:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:18:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.27e-02, avg batch time: 0.4788, average train loss: 0.0162
[09/26 04:18:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 0.5276
[09/26 04:18:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.50	
[09/26 04:18:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:19:05 visual_prompt]: Epoch 20 / 100: avg data time: 6.04e-02, avg batch time: 0.4755, average train loss: 0.0141
[09/26 04:19:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1585, average loss: 0.5397
[09/26 04:19:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:19:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:19:13 visual_prompt]: Epoch 21 / 100: avg data time: 6.21e-02, avg batch time: 0.4759, average train loss: 0.0129
[09/26 04:19:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1587, average loss: 0.5388
[09/26 04:19:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:19:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:19:22 visual_prompt]: Epoch 22 / 100: avg data time: 6.35e-02, avg batch time: 0.4771, average train loss: 0.0119
[09/26 04:19:23 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1586, average loss: 0.5298
[09/26 04:19:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:19:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:19:30 visual_prompt]: Epoch 23 / 100: avg data time: 6.43e-02, avg batch time: 0.4787, average train loss: 0.0113
[09/26 04:19:32 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1584, average loss: 0.5261
[09/26 04:19:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.00	
[09/26 04:19:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:19:39 visual_prompt]: Epoch 24 / 100: avg data time: 6.85e-02, avg batch time: 0.4827, average train loss: 0.0109
[09/26 04:19:40 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 0.5280
[09/26 04:19:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:19:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:19:47 visual_prompt]: Epoch 25 / 100: avg data time: 6.40e-02, avg batch time: 0.4776, average train loss: 0.0102
[09/26 04:19:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 0.5292
[09/26 04:19:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:19:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:19:55 visual_prompt]: Epoch 26 / 100: avg data time: 6.35e-02, avg batch time: 0.4775, average train loss: 0.0097
[09/26 04:19:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1584, average loss: 0.5348
[09/26 04:19:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:19:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:20:03 visual_prompt]: Epoch 27 / 100: avg data time: 6.66e-02, avg batch time: 0.4812, average train loss: 0.0093
[09/26 04:20:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1580, average loss: 0.5286
[09/26 04:20:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 97.00	
[09/26 04:20:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:20:12 visual_prompt]: Epoch 28 / 100: avg data time: 6.63e-02, avg batch time: 0.4799, average train loss: 0.0088
[09/26 04:20:14 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1578, average loss: 0.5273
[09/26 04:20:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 04:20:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:20:20 visual_prompt]: Epoch 29 / 100: avg data time: 6.82e-02, avg batch time: 0.4817, average train loss: 0.0088
[09/26 04:20:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.5254
[09/26 04:20:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:20:22 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:20:29 visual_prompt]: Epoch 30 / 100: avg data time: 6.43e-02, avg batch time: 0.4789, average train loss: 0.0086
[09/26 04:20:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1581, average loss: 0.5260
[09/26 04:20:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:20:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:20:37 visual_prompt]: Epoch 31 / 100: avg data time: 6.97e-02, avg batch time: 0.4837, average train loss: 0.0080
[09/26 04:20:39 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1583, average loss: 0.5246
[09/26 04:20:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:20:39 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:20:45 visual_prompt]: Epoch 32 / 100: avg data time: 5.98e-02, avg batch time: 0.4732, average train loss: 0.0080
[09/26 04:20:47 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1584, average loss: 0.5245
[09/26 04:20:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:20:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:20:54 visual_prompt]: Epoch 33 / 100: avg data time: 6.94e-02, avg batch time: 0.4831, average train loss: 0.0078
[09/26 04:20:56 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1584, average loss: 0.5191
[09/26 04:20:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 04:20:56 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:21:02 visual_prompt]: Epoch 34 / 100: avg data time: 6.90e-02, avg batch time: 0.4835, average train loss: 0.0077
[09/26 04:21:04 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1582, average loss: 0.5193
[09/26 04:21:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:21:04 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:21:11 visual_prompt]: Epoch 35 / 100: avg data time: 7.25e-02, avg batch time: 0.4862, average train loss: 0.0072
[09/26 04:21:13 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1581, average loss: 0.5225
[09/26 04:21:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:21:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:21:19 visual_prompt]: Epoch 36 / 100: avg data time: 7.19e-02, avg batch time: 0.4861, average train loss: 0.0073
[09/26 04:21:21 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.5241
[09/26 04:21:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:21:21 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:21:28 visual_prompt]: Epoch 37 / 100: avg data time: 7.54e-02, avg batch time: 0.4887, average train loss: 0.0073
[09/26 04:21:30 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1582, average loss: 0.5245
[09/26 04:21:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:21:30 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:21:36 visual_prompt]: Epoch 38 / 100: avg data time: 6.94e-02, avg batch time: 0.4852, average train loss: 0.0072
[09/26 04:21:38 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1578, average loss: 0.5254
[09/26 04:21:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 04:21:38 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:21:45 visual_prompt]: Epoch 39 / 100: avg data time: 6.57e-02, avg batch time: 0.4785, average train loss: 0.0068
[09/26 04:21:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1577, average loss: 0.5340
[09/26 04:21:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 04:21:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:21:53 visual_prompt]: Epoch 40 / 100: avg data time: 6.19e-02, avg batch time: 0.4758, average train loss: 0.0066
[09/26 04:21:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1586, average loss: 0.5272
[09/26 04:21:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:21:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:22:01 visual_prompt]: Epoch 41 / 100: avg data time: 6.90e-02, avg batch time: 0.4822, average train loss: 0.0068
[09/26 04:22:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1584, average loss: 0.5177
[09/26 04:22:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:22:03 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:22:10 visual_prompt]: Epoch 42 / 100: avg data time: 6.57e-02, avg batch time: 0.4787, average train loss: 0.0066
[09/26 04:22:11 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 0.5165
[09/26 04:22:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:22:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:22:18 visual_prompt]: Epoch 43 / 100: avg data time: 6.54e-02, avg batch time: 0.4782, average train loss: 0.0068
[09/26 04:22:20 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.5194
[09/26 04:22:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.50	
[09/26 04:22:20 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:22:27 visual_prompt]: Epoch 44 / 100: avg data time: 6.44e-02, avg batch time: 0.4780, average train loss: 0.0065
[09/26 04:22:28 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 0.5177
[09/26 04:22:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 04:22:28 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:22:35 visual_prompt]: Epoch 45 / 100: avg data time: 6.51e-02, avg batch time: 0.4788, average train loss: 0.0063
[09/26 04:22:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1577, average loss: 0.5154
[09/26 04:22:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 97.00	
[09/26 04:22:37 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:22:43 visual_prompt]: Epoch 46 / 100: avg data time: 6.14e-02, avg batch time: 0.4766, average train loss: 0.0063
[09/26 04:22:45 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.5136
[09/26 04:22:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 04:22:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:22:52 visual_prompt]: Epoch 47 / 100: avg data time: 5.75e-02, avg batch time: 0.4722, average train loss: 0.0062
[09/26 04:22:53 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1584, average loss: 0.5141
[09/26 04:22:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 04:22:53 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:23:00 visual_prompt]: Epoch 48 / 100: avg data time: 7.28e-02, avg batch time: 0.4878, average train loss: 0.0061
[09/26 04:23:02 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1580, average loss: 0.5118
[09/26 04:23:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 04:23:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:23:08 visual_prompt]: Epoch 49 / 100: avg data time: 6.39e-02, avg batch time: 0.4785, average train loss: 0.0059
[09/26 04:23:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1578, average loss: 0.5121
[09/26 04:23:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 04:23:10 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:23:17 visual_prompt]: Epoch 50 / 100: avg data time: 7.11e-02, avg batch time: 0.4851, average train loss: 0.0060
[09/26 04:23:19 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1583, average loss: 0.5128
[09/26 04:23:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 04:23:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:23:25 visual_prompt]: Epoch 51 / 100: avg data time: 6.50e-02, avg batch time: 0.4777, average train loss: 0.0058
[09/26 04:23:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 0.5142
[09/26 04:23:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.50	
[09/26 04:23:27 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:23:34 visual_prompt]: Epoch 52 / 100: avg data time: 6.76e-02, avg batch time: 0.4810, average train loss: 0.0058
[09/26 04:23:35 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1585, average loss: 0.5108
[09/26 04:23:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 04:23:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:23:42 visual_prompt]: Epoch 53 / 100: avg data time: 6.02e-02, avg batch time: 0.4733, average train loss: 0.0059
[09/26 04:23:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1585, average loss: 0.5042
[09/26 04:23:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 04:23:44 visual_prompt]: Best epoch 53: best metric: 0.875
[09/26 04:23:44 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:23:50 visual_prompt]: Epoch 54 / 100: avg data time: 6.44e-02, avg batch time: 0.4781, average train loss: 0.0057
[09/26 04:23:52 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1579, average loss: 0.5069
[09/26 04:23:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 04:23:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:23:59 visual_prompt]: Epoch 55 / 100: avg data time: 6.41e-02, avg batch time: 0.4780, average train loss: 0.0057
[09/26 04:24:00 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 0.5078
[09/26 04:24:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 04:24:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:24:07 visual_prompt]: Epoch 56 / 100: avg data time: 6.81e-02, avg batch time: 0.4805, average train loss: 0.0059
[09/26 04:24:09 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1581, average loss: 0.5099
[09/26 04:24:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 04:24:09 visual_prompt]: Best epoch 56: best metric: 0.880
[09/26 04:24:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:24:15 visual_prompt]: Epoch 57 / 100: avg data time: 6.23e-02, avg batch time: 0.4764, average train loss: 0.0057
[09/26 04:24:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.5095
[09/26 04:24:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 04:24:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:24:24 visual_prompt]: Epoch 58 / 100: avg data time: 7.10e-02, avg batch time: 0.4847, average train loss: 0.0056
[09/26 04:24:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.5086
[09/26 04:24:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 04:24:25 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:24:32 visual_prompt]: Epoch 59 / 100: avg data time: 6.92e-02, avg batch time: 0.4829, average train loss: 0.0057
[09/26 04:24:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 0.5056
[09/26 04:24:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:24:34 visual_prompt]: Best epoch 59: best metric: 0.885
[09/26 04:24:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:24:41 visual_prompt]: Epoch 60 / 100: avg data time: 6.95e-02, avg batch time: 0.4830, average train loss: 0.0056
[09/26 04:24:42 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1581, average loss: 0.5072
[09/26 04:24:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:24:42 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:24:49 visual_prompt]: Epoch 61 / 100: avg data time: 6.17e-02, avg batch time: 0.4762, average train loss: 0.0056
[09/26 04:24:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1587, average loss: 0.5066
[09/26 04:24:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:24:51 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:24:57 visual_prompt]: Epoch 62 / 100: avg data time: 6.49e-02, avg batch time: 0.4780, average train loss: 0.0055
[09/26 04:24:59 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1576, average loss: 0.5042
[09/26 04:24:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:24:59 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:25:06 visual_prompt]: Epoch 63 / 100: avg data time: 6.61e-02, avg batch time: 0.4797, average train loss: 0.0055
[09/26 04:25:07 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1585, average loss: 0.5034
[09/26 04:25:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:25:07 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:25:14 visual_prompt]: Epoch 64 / 100: avg data time: 6.36e-02, avg batch time: 0.4769, average train loss: 0.0056
[09/26 04:25:16 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1586, average loss: 0.5045
[09/26 04:25:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:25:16 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:25:22 visual_prompt]: Epoch 65 / 100: avg data time: 6.41e-02, avg batch time: 0.4773, average train loss: 0.0055
[09/26 04:25:24 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1583, average loss: 0.5064
[09/26 04:25:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:25:24 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:25:31 visual_prompt]: Epoch 66 / 100: avg data time: 6.45e-02, avg batch time: 0.4781, average train loss: 0.0054
[09/26 04:25:32 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1585, average loss: 0.5070
[09/26 04:25:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 04:25:32 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:25:39 visual_prompt]: Epoch 67 / 100: avg data time: 6.66e-02, avg batch time: 0.4795, average train loss: 0.0055
[09/26 04:25:41 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1583, average loss: 0.5070
[09/26 04:25:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 04:25:41 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:25:47 visual_prompt]: Epoch 68 / 100: avg data time: 6.32e-02, avg batch time: 0.4770, average train loss: 0.0054
[09/26 04:25:49 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 0.5072
[09/26 04:25:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 97.00	
[09/26 04:25:49 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:25:55 visual_prompt]: Epoch 69 / 100: avg data time: 6.14e-02, avg batch time: 0.4747, average train loss: 0.0055
[09/26 04:25:57 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1583, average loss: 0.5052
[09/26 04:25:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:25:57 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:26:04 visual_prompt]: Epoch 70 / 100: avg data time: 7.09e-02, avg batch time: 0.4838, average train loss: 0.0054
[09/26 04:26:06 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 0.5038
[09/26 04:26:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:06 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:26:12 visual_prompt]: Epoch 71 / 100: avg data time: 5.30e-02, avg batch time: 0.4673, average train loss: 0.0052
[09/26 04:26:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 0.5028
[09/26 04:26:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:14 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:26:21 visual_prompt]: Epoch 72 / 100: avg data time: 7.24e-02, avg batch time: 0.4873, average train loss: 0.0054
[09/26 04:26:22 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1582, average loss: 0.5026
[09/26 04:26:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:22 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:26:29 visual_prompt]: Epoch 73 / 100: avg data time: 6.82e-02, avg batch time: 0.4819, average train loss: 0.0053
[09/26 04:26:31 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1585, average loss: 0.5031
[09/26 04:26:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:26:38 visual_prompt]: Epoch 74 / 100: avg data time: 6.21e-02, avg batch time: 0.4764, average train loss: 0.0054
[09/26 04:26:39 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1588, average loss: 0.5042
[09/26 04:26:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:26:46 visual_prompt]: Epoch 75 / 100: avg data time: 6.54e-02, avg batch time: 0.4792, average train loss: 0.0052
[09/26 04:26:48 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1580, average loss: 0.5037
[09/26 04:26:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:26:54 visual_prompt]: Epoch 76 / 100: avg data time: 6.61e-02, avg batch time: 0.4791, average train loss: 0.0053
[09/26 04:26:56 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.5060
[09/26 04:26:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:26:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:27:03 visual_prompt]: Epoch 77 / 100: avg data time: 5.62e-02, avg batch time: 0.4709, average train loss: 0.0053
[09/26 04:27:04 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1586, average loss: 0.5055
[09/26 04:27:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:27:11 visual_prompt]: Epoch 78 / 100: avg data time: 7.36e-02, avg batch time: 0.4873, average train loss: 0.0052
[09/26 04:27:13 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1584, average loss: 0.5048
[09/26 04:27:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:13 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:27:19 visual_prompt]: Epoch 79 / 100: avg data time: 6.74e-02, avg batch time: 0.4827, average train loss: 0.0052
[09/26 04:27:21 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1585, average loss: 0.5046
[09/26 04:27:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:27:28 visual_prompt]: Epoch 80 / 100: avg data time: 7.25e-02, avg batch time: 0.4870, average train loss: 0.0052
[09/26 04:27:30 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 0.5043
[09/26 04:27:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:27:36 visual_prompt]: Epoch 81 / 100: avg data time: 6.67e-02, avg batch time: 0.4811, average train loss: 0.0053
[09/26 04:27:38 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 0.5037
[09/26 04:27:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:27:45 visual_prompt]: Epoch 82 / 100: avg data time: 6.72e-02, avg batch time: 0.4811, average train loss: 0.0054
[09/26 04:27:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1587, average loss: 0.5028
[09/26 04:27:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:27:53 visual_prompt]: Epoch 83 / 100: avg data time: 6.30e-02, avg batch time: 0.4794, average train loss: 0.0052
[09/26 04:27:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1585, average loss: 0.5025
[09/26 04:27:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:27:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:28:01 visual_prompt]: Epoch 84 / 100: avg data time: 5.85e-02, avg batch time: 0.4737, average train loss: 0.0051
[09/26 04:28:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1589, average loss: 0.5024
[09/26 04:28:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:28:10 visual_prompt]: Epoch 85 / 100: avg data time: 6.80e-02, avg batch time: 0.4822, average train loss: 0.0053
[09/26 04:28:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1589, average loss: 0.5020
[09/26 04:28:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:28:18 visual_prompt]: Epoch 86 / 100: avg data time: 6.83e-02, avg batch time: 0.4819, average train loss: 0.0054
[09/26 04:28:20 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1582, average loss: 0.5018
[09/26 04:28:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:28:26 visual_prompt]: Epoch 87 / 100: avg data time: 7.01e-02, avg batch time: 0.4845, average train loss: 0.0052
[09/26 04:28:28 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1582, average loss: 0.5019
[09/26 04:28:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:28:35 visual_prompt]: Epoch 88 / 100: avg data time: 7.33e-02, avg batch time: 0.4873, average train loss: 0.0052
[09/26 04:28:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1585, average loss: 0.5022
[09/26 04:28:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:37 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:28:43 visual_prompt]: Epoch 89 / 100: avg data time: 6.49e-02, avg batch time: 0.4788, average train loss: 0.0052
[09/26 04:28:45 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1582, average loss: 0.5022
[09/26 04:28:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:28:52 visual_prompt]: Epoch 90 / 100: avg data time: 5.66e-02, avg batch time: 0.4713, average train loss: 0.0052
[09/26 04:28:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1582, average loss: 0.5021
[09/26 04:28:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:28:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:29:00 visual_prompt]: Epoch 91 / 100: avg data time: 6.24e-02, avg batch time: 0.4767, average train loss: 0.0051
[09/26 04:29:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 0.5021
[09/26 04:29:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:02 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:29:08 visual_prompt]: Epoch 92 / 100: avg data time: 5.99e-02, avg batch time: 0.4740, average train loss: 0.0053
[09/26 04:29:10 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 0.5020
[09/26 04:29:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:10 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:29:17 visual_prompt]: Epoch 93 / 100: avg data time: 6.75e-02, avg batch time: 0.4802, average train loss: 0.0051
[09/26 04:29:18 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1581, average loss: 0.5020
[09/26 04:29:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:18 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:29:25 visual_prompt]: Epoch 94 / 100: avg data time: 6.49e-02, avg batch time: 0.4778, average train loss: 0.0053
[09/26 04:29:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.5019
[09/26 04:29:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:27 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:29:33 visual_prompt]: Epoch 95 / 100: avg data time: 5.75e-02, avg batch time: 0.4721, average train loss: 0.0053
[09/26 04:29:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 0.5018
[09/26 04:29:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:35 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:29:42 visual_prompt]: Epoch 96 / 100: avg data time: 6.59e-02, avg batch time: 0.4788, average train loss: 0.0051
[09/26 04:29:43 visual_prompt]: Inference (val):avg data time: 4.62e-05, avg batch time: 0.1583, average loss: 0.5018
[09/26 04:29:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:43 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:29:50 visual_prompt]: Epoch 97 / 100: avg data time: 7.02e-02, avg batch time: 0.4831, average train loss: 0.0053
[09/26 04:29:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 0.5018
[09/26 04:29:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:29:52 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:29:59 visual_prompt]: Epoch 98 / 100: avg data time: 6.72e-02, avg batch time: 0.4814, average train loss: 0.0052
[09/26 04:30:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.5018
[09/26 04:30:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:30:00 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:30:07 visual_prompt]: Epoch 99 / 100: avg data time: 5.36e-02, avg batch time: 0.4687, average train loss: 0.0052
[09/26 04:30:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 0.5018
[09/26 04:30:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:30:08 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:30:15 visual_prompt]: Epoch 100 / 100: avg data time: 6.98e-02, avg batch time: 0.4824, average train loss: 0.0051
[09/26 04:30:17 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1579, average loss: 0.5018
[09/26 04:30:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 04:30:17 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:30:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:30:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:30:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:30:17 visual_prompt]: Training with config:
[09/26 04:30:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:30:17 visual_prompt]: Loading training data...
[09/26 04:30:17 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:30:18 visual_prompt]: Number of images: 800
[09/26 04:30:18 visual_prompt]: Number of classes: 102 / 102
[09/26 04:30:18 visual_prompt]: Loading validation data...
[09/26 04:30:18 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:30:18 visual_prompt]: Number of images: 200
[09/26 04:30:18 visual_prompt]: Number of classes: 91 / 102
[09/26 04:30:18 visual_prompt]: Constructing models...
[09/26 04:30:21 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 04:30:21 visual_prompt]: tuned percent:0.625
[09/26 04:30:21 visual_prompt]: Device used for model: 0
[09/26 04:30:21 visual_prompt]: Setting up Evaluator...
[09/26 04:30:21 visual_prompt]: Setting up Trainer...
[09/26 04:30:21 visual_prompt]: 	Setting up the optimizer...
[09/26 04:30:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:30:28 visual_prompt]: Epoch 1 / 100: avg data time: 6.63e-02, avg batch time: 0.4877, average train loss: 4.6670
[09/26 04:30:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 04:30:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 04:30:29 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:30:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:30:36 visual_prompt]: Epoch 2 / 100: avg data time: 6.62e-02, avg batch time: 0.4784, average train loss: 4.6399
[09/26 04:30:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1584, average loss: 4.6157
[09/26 04:30:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.00	
[09/26 04:30:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:30:44 visual_prompt]: Epoch 3 / 100: avg data time: 6.77e-02, avg batch time: 0.4795, average train loss: 4.5365
[09/26 04:30:46 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 4.5328
[09/26 04:30:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 11.00	
[09/26 04:30:46 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 04:30:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:30:53 visual_prompt]: Epoch 4 / 100: avg data time: 6.57e-02, avg batch time: 0.4786, average train loss: 4.2812
[09/26 04:30:54 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1579, average loss: 4.1910
[09/26 04:30:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 7.50	top5: 26.50	
[09/26 04:30:54 visual_prompt]: Best epoch 4: best metric: 0.075
[09/26 04:30:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:31:01 visual_prompt]: Epoch 5 / 100: avg data time: 6.44e-02, avg batch time: 0.4771, average train loss: 3.7112
[09/26 04:31:03 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 3.3593
[09/26 04:31:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 20.00	top5: 45.00	
[09/26 04:31:03 visual_prompt]: Best epoch 5: best metric: 0.200
[09/26 04:31:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:31:09 visual_prompt]: Epoch 6 / 100: avg data time: 5.16e-02, avg batch time: 0.4653, average train loss: 2.9070
[09/26 04:31:11 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1579, average loss: 2.6608
[09/26 04:31:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 43.00	top5: 65.50	
[09/26 04:31:11 visual_prompt]: Best epoch 6: best metric: 0.430
[09/26 04:31:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:31:18 visual_prompt]: Epoch 7 / 100: avg data time: 7.22e-02, avg batch time: 0.4855, average train loss: 1.9550
[09/26 04:31:19 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1576, average loss: 1.8424
[09/26 04:31:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 56.00	top5: 83.50	
[09/26 04:31:19 visual_prompt]: Best epoch 7: best metric: 0.560
[09/26 04:31:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:31:26 visual_prompt]: Epoch 8 / 100: avg data time: 6.36e-02, avg batch time: 0.4771, average train loss: 1.1342
[09/26 04:31:28 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 1.2862
[09/26 04:31:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.50	top5: 92.50	
[09/26 04:31:28 visual_prompt]: Best epoch 8: best metric: 0.705
[09/26 04:31:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:31:34 visual_prompt]: Epoch 9 / 100: avg data time: 6.15e-02, avg batch time: 0.4750, average train loss: 0.5994
[09/26 04:31:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1583, average loss: 0.9359
[09/26 04:31:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 91.50	
[09/26 04:31:36 visual_prompt]: Best epoch 9: best metric: 0.795
[09/26 04:31:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:31:43 visual_prompt]: Epoch 10 / 100: avg data time: 7.12e-02, avg batch time: 0.4848, average train loss: 0.3145
[09/26 04:31:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1571, average loss: 0.7963
[09/26 04:31:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 04:31:44 visual_prompt]: Best epoch 10: best metric: 0.810
[09/26 04:31:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:31:51 visual_prompt]: Epoch 11 / 100: avg data time: 6.17e-02, avg batch time: 0.4751, average train loss: 0.1691
[09/26 04:31:53 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1587, average loss: 0.6789
[09/26 04:31:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/26 04:31:53 visual_prompt]: Best epoch 11: best metric: 0.820
[09/26 04:31:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:31:59 visual_prompt]: Epoch 12 / 100: avg data time: 6.30e-02, avg batch time: 0.4758, average train loss: 0.1160
[09/26 04:32:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 0.6729
[09/26 04:32:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 95.50	
[09/26 04:32:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:32:08 visual_prompt]: Epoch 13 / 100: avg data time: 5.92e-02, avg batch time: 0.4726, average train loss: 0.0659
[09/26 04:32:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 0.6406
[09/26 04:32:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 94.50	
[09/26 04:32:09 visual_prompt]: Best epoch 13: best metric: 0.835
[09/26 04:32:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:32:16 visual_prompt]: Epoch 14 / 100: avg data time: 6.11e-02, avg batch time: 0.4742, average train loss: 0.0454
[09/26 04:32:18 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1584, average loss: 0.6165
[09/26 04:32:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 95.50	
[09/26 04:32:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:32:24 visual_prompt]: Epoch 15 / 100: avg data time: 7.31e-02, avg batch time: 0.4858, average train loss: 0.0301
[09/26 04:32:26 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1581, average loss: 0.5775
[09/26 04:32:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 04:32:26 visual_prompt]: Best epoch 15: best metric: 0.845
[09/26 04:32:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:32:33 visual_prompt]: Epoch 16 / 100: avg data time: 6.79e-02, avg batch time: 0.4814, average train loss: 0.0230
[09/26 04:32:35 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 0.5753
[09/26 04:32:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.50	
[09/26 04:32:35 visual_prompt]: Best epoch 16: best metric: 0.850
[09/26 04:32:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:32:41 visual_prompt]: Epoch 17 / 100: avg data time: 5.59e-02, avg batch time: 0.4713, average train loss: 0.0188
[09/26 04:32:43 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1583, average loss: 0.5830
[09/26 04:32:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.00	
[09/26 04:32:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:32:49 visual_prompt]: Epoch 18 / 100: avg data time: 6.22e-02, avg batch time: 0.4759, average train loss: 0.0157
[09/26 04:32:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1582, average loss: 0.5757
[09/26 04:32:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.00	
[09/26 04:32:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:32:58 visual_prompt]: Epoch 19 / 100: avg data time: 6.35e-02, avg batch time: 0.4771, average train loss: 0.0134
[09/26 04:33:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.5762
[09/26 04:33:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.50	
[09/26 04:33:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:33:06 visual_prompt]: Epoch 20 / 100: avg data time: 6.17e-02, avg batch time: 0.4764, average train loss: 0.0126
[09/26 04:33:08 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1576, average loss: 0.5673
[09/26 04:33:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 04:33:08 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:33:15 visual_prompt]: Epoch 21 / 100: avg data time: 5.92e-02, avg batch time: 0.4745, average train loss: 0.0112
[09/26 04:33:16 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1588, average loss: 0.5638
[09/26 04:33:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 95.50	
[09/26 04:33:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:33:23 visual_prompt]: Epoch 22 / 100: avg data time: 7.02e-02, avg batch time: 0.4838, average train loss: 0.0106
[09/26 04:33:25 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1585, average loss: 0.5564
[09/26 04:33:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:33:25 visual_prompt]: Best epoch 22: best metric: 0.855
[09/26 04:33:25 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:33:31 visual_prompt]: Epoch 23 / 100: avg data time: 6.59e-02, avg batch time: 0.4799, average train loss: 0.0099
[09/26 04:33:33 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1584, average loss: 0.5539
[09/26 04:33:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:33:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:33:40 visual_prompt]: Epoch 24 / 100: avg data time: 6.39e-02, avg batch time: 0.4778, average train loss: 0.0096
[09/26 04:33:41 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1579, average loss: 0.5510
[09/26 04:33:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:33:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:33:48 visual_prompt]: Epoch 25 / 100: avg data time: 6.71e-02, avg batch time: 0.4802, average train loss: 0.0087
[09/26 04:33:50 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1580, average loss: 0.5476
[09/26 04:33:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.50	
[09/26 04:33:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:33:56 visual_prompt]: Epoch 26 / 100: avg data time: 5.28e-02, avg batch time: 0.4673, average train loss: 0.0080
[09/26 04:33:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1587, average loss: 0.5461
[09/26 04:33:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 04:33:58 visual_prompt]: Best epoch 26: best metric: 0.860
[09/26 04:33:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:34:05 visual_prompt]: Epoch 27 / 100: avg data time: 6.73e-02, avg batch time: 0.4822, average train loss: 0.0078
[09/26 04:34:06 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1585, average loss: 0.5408
[09/26 04:34:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:34:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:34:13 visual_prompt]: Epoch 28 / 100: avg data time: 7.13e-02, avg batch time: 0.4846, average train loss: 0.0076
[09/26 04:34:15 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.5440
[09/26 04:34:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:34:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:34:21 visual_prompt]: Epoch 29 / 100: avg data time: 5.77e-02, avg batch time: 0.4729, average train loss: 0.0071
[09/26 04:34:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.5477
[09/26 04:34:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:34:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:34:30 visual_prompt]: Epoch 30 / 100: avg data time: 6.65e-02, avg batch time: 0.4797, average train loss: 0.0070
[09/26 04:34:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1581, average loss: 0.5501
[09/26 04:34:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:34:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:34:38 visual_prompt]: Epoch 31 / 100: avg data time: 6.38e-02, avg batch time: 0.4769, average train loss: 0.0065
[09/26 04:34:40 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1586, average loss: 0.5464
[09/26 04:34:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:34:40 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:34:46 visual_prompt]: Epoch 32 / 100: avg data time: 7.02e-02, avg batch time: 0.4837, average train loss: 0.0064
[09/26 04:34:48 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.5484
[09/26 04:34:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:34:48 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:34:55 visual_prompt]: Epoch 33 / 100: avg data time: 6.55e-02, avg batch time: 0.4794, average train loss: 0.0061
[09/26 04:34:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1584, average loss: 0.5463
[09/26 04:34:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 04:34:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:35:03 visual_prompt]: Epoch 34 / 100: avg data time: 7.15e-02, avg batch time: 0.4857, average train loss: 0.0057
[09/26 04:35:05 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.1583, average loss: 0.5422
[09/26 04:35:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 04:35:05 visual_prompt]: Best epoch 34: best metric: 0.865
[09/26 04:35:05 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:35:12 visual_prompt]: Epoch 35 / 100: avg data time: 6.68e-02, avg batch time: 0.4796, average train loss: 0.0056
[09/26 04:35:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.5414
[09/26 04:35:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 04:35:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:35:20 visual_prompt]: Epoch 36 / 100: avg data time: 6.33e-02, avg batch time: 0.4780, average train loss: 0.0053
[09/26 04:35:22 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1580, average loss: 0.5411
[09/26 04:35:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:35:22 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:35:28 visual_prompt]: Epoch 37 / 100: avg data time: 6.90e-02, avg batch time: 0.4819, average train loss: 0.0054
[09/26 04:35:30 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 0.5437
[09/26 04:35:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 04:35:30 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:35:37 visual_prompt]: Epoch 38 / 100: avg data time: 6.28e-02, avg batch time: 0.4766, average train loss: 0.0051
[09/26 04:35:39 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1582, average loss: 0.5431
[09/26 04:35:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 04:35:39 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:35:45 visual_prompt]: Epoch 39 / 100: avg data time: 6.59e-02, avg batch time: 0.4791, average train loss: 0.0052
[09/26 04:35:47 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1582, average loss: 0.5352
[09/26 04:35:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 95.50	
[09/26 04:35:47 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:35:54 visual_prompt]: Epoch 40 / 100: avg data time: 6.92e-02, avg batch time: 0.4828, average train loss: 0.0049
[09/26 04:35:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 0.5333
[09/26 04:35:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 04:35:55 visual_prompt]: Best epoch 40: best metric: 0.870
[09/26 04:35:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:36:02 visual_prompt]: Epoch 41 / 100: avg data time: 6.92e-02, avg batch time: 0.4828, average train loss: 0.0049
[09/26 04:36:04 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1583, average loss: 0.5431
[09/26 04:36:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 04:36:04 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:36:10 visual_prompt]: Epoch 42 / 100: avg data time: 6.26e-02, avg batch time: 0.4756, average train loss: 0.0048
[09/26 04:36:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 0.5482
[09/26 04:36:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:36:12 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:36:19 visual_prompt]: Epoch 43 / 100: avg data time: 7.27e-02, avg batch time: 0.4850, average train loss: 0.0045
[09/26 04:36:21 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1582, average loss: 0.5451
[09/26 04:36:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:36:21 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:36:27 visual_prompt]: Epoch 44 / 100: avg data time: 7.05e-02, avg batch time: 0.4836, average train loss: 0.0045
[09/26 04:36:29 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.5428
[09/26 04:36:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:36:29 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:36:36 visual_prompt]: Epoch 45 / 100: avg data time: 6.91e-02, avg batch time: 0.4815, average train loss: 0.0044
[09/26 04:36:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 0.5396
[09/26 04:36:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:36:37 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:36:44 visual_prompt]: Epoch 46 / 100: avg data time: 7.03e-02, avg batch time: 0.4842, average train loss: 0.0044
[09/26 04:36:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 0.5351
[09/26 04:36:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:36:46 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:36:53 visual_prompt]: Epoch 47 / 100: avg data time: 7.15e-02, avg batch time: 0.4848, average train loss: 0.0042
[09/26 04:36:54 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1584, average loss: 0.5335
[09/26 04:36:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:36:54 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:37:01 visual_prompt]: Epoch 48 / 100: avg data time: 6.40e-02, avg batch time: 0.4774, average train loss: 0.0040
[09/26 04:37:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1579, average loss: 0.5320
[09/26 04:37:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:37:03 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:37:09 visual_prompt]: Epoch 49 / 100: avg data time: 6.10e-02, avg batch time: 0.4748, average train loss: 0.0041
[09/26 04:37:11 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1582, average loss: 0.5314
[09/26 04:37:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 04:37:11 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:37:17 visual_prompt]: Epoch 50 / 100: avg data time: 5.67e-02, avg batch time: 0.4706, average train loss: 0.0039
[09/26 04:37:19 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1581, average loss: 0.5327
[09/26 04:37:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 04:37:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:37:26 visual_prompt]: Epoch 51 / 100: avg data time: 6.52e-02, avg batch time: 0.4773, average train loss: 0.0040
[09/26 04:37:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1581, average loss: 0.5334
[09/26 04:37:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 04:37:28 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:37:34 visual_prompt]: Epoch 52 / 100: avg data time: 6.62e-02, avg batch time: 0.4803, average train loss: 0.0039
[09/26 04:37:36 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 0.5340
[09/26 04:37:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:37:36 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:37:43 visual_prompt]: Epoch 53 / 100: avg data time: 6.78e-02, avg batch time: 0.4800, average train loss: 0.0038
[09/26 04:37:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 0.5313
[09/26 04:37:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:37:44 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:37:51 visual_prompt]: Epoch 54 / 100: avg data time: 6.94e-02, avg batch time: 0.4815, average train loss: 0.0038
[09/26 04:37:53 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1585, average loss: 0.5353
[09/26 04:37:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:37:53 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:38:00 visual_prompt]: Epoch 55 / 100: avg data time: 7.20e-02, avg batch time: 0.4849, average train loss: 0.0037
[09/26 04:38:01 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 0.5335
[09/26 04:38:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:38:01 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:38:08 visual_prompt]: Epoch 56 / 100: avg data time: 6.31e-02, avg batch time: 0.4759, average train loss: 0.0035
[09/26 04:38:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1584, average loss: 0.5329
[09/26 04:38:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:38:10 visual_prompt]: Best epoch 56: best metric: 0.875
[09/26 04:38:10 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:38:16 visual_prompt]: Epoch 57 / 100: avg data time: 5.31e-02, avg batch time: 0.4669, average train loss: 0.0037
[09/26 04:38:18 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1581, average loss: 0.5343
[09/26 04:38:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:38:18 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:38:24 visual_prompt]: Epoch 58 / 100: avg data time: 6.59e-02, avg batch time: 0.4788, average train loss: 0.0036
[09/26 04:38:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 0.5359
[09/26 04:38:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:38:26 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:38:33 visual_prompt]: Epoch 59 / 100: avg data time: 6.50e-02, avg batch time: 0.4772, average train loss: 0.0035
[09/26 04:38:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1586, average loss: 0.5369
[09/26 04:38:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:38:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:38:41 visual_prompt]: Epoch 60 / 100: avg data time: 6.65e-02, avg batch time: 0.4783, average train loss: 0.0035
[09/26 04:38:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 0.5362
[09/26 04:38:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:38:43 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:38:49 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.4737, average train loss: 0.0035
[09/26 04:38:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1578, average loss: 0.5353
[09/26 04:38:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:38:51 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:38:58 visual_prompt]: Epoch 62 / 100: avg data time: 7.05e-02, avg batch time: 0.4827, average train loss: 0.0034
[09/26 04:38:59 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1585, average loss: 0.5354
[09/26 04:38:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:38:59 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:39:06 visual_prompt]: Epoch 63 / 100: avg data time: 6.68e-02, avg batch time: 0.4803, average train loss: 0.0034
[09/26 04:39:08 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1578, average loss: 0.5348
[09/26 04:39:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:39:08 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:39:14 visual_prompt]: Epoch 64 / 100: avg data time: 5.81e-02, avg batch time: 0.4704, average train loss: 0.0035
[09/26 04:39:16 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1584, average loss: 0.5339
[09/26 04:39:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:39:16 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:39:23 visual_prompt]: Epoch 65 / 100: avg data time: 6.81e-02, avg batch time: 0.4800, average train loss: 0.0034
[09/26 04:39:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 0.5337
[09/26 04:39:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:39:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:39:31 visual_prompt]: Epoch 66 / 100: avg data time: 6.77e-02, avg batch time: 0.4807, average train loss: 0.0033
[09/26 04:39:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1578, average loss: 0.5332
[09/26 04:39:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:39:33 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:39:40 visual_prompt]: Epoch 67 / 100: avg data time: 6.09e-02, avg batch time: 0.4744, average train loss: 0.0033
[09/26 04:39:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1585, average loss: 0.5325
[09/26 04:39:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:39:41 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:39:48 visual_prompt]: Epoch 68 / 100: avg data time: 6.12e-02, avg batch time: 0.4739, average train loss: 0.0033
[09/26 04:39:50 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1584, average loss: 0.5321
[09/26 04:39:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:39:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:39:56 visual_prompt]: Epoch 69 / 100: avg data time: 6.62e-02, avg batch time: 0.4784, average train loss: 0.0033
[09/26 04:39:58 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1580, average loss: 0.5320
[09/26 04:39:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:39:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:40:05 visual_prompt]: Epoch 70 / 100: avg data time: 6.88e-02, avg batch time: 0.4812, average train loss: 0.0032
[09/26 04:40:06 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1585, average loss: 0.5313
[09/26 04:40:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:40:06 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:40:13 visual_prompt]: Epoch 71 / 100: avg data time: 5.65e-02, avg batch time: 0.4693, average train loss: 0.0033
[09/26 04:40:15 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.5300
[09/26 04:40:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:40:15 visual_prompt]: Best epoch 71: best metric: 0.880
[09/26 04:40:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:40:21 visual_prompt]: Epoch 72 / 100: avg data time: 5.38e-02, avg batch time: 0.4674, average train loss: 0.0032
[09/26 04:40:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1586, average loss: 0.5294
[09/26 04:40:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:40:23 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:40:29 visual_prompt]: Epoch 73 / 100: avg data time: 6.49e-02, avg batch time: 0.4771, average train loss: 0.0032
[09/26 04:40:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.5293
[09/26 04:40:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:40:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:40:38 visual_prompt]: Epoch 74 / 100: avg data time: 7.08e-02, avg batch time: 0.4832, average train loss: 0.0031
[09/26 04:40:40 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1582, average loss: 0.5288
[09/26 04:40:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:40:40 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:40:46 visual_prompt]: Epoch 75 / 100: avg data time: 6.55e-02, avg batch time: 0.4782, average train loss: 0.0030
[09/26 04:40:48 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1582, average loss: 0.5283
[09/26 04:40:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:40:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:40:55 visual_prompt]: Epoch 76 / 100: avg data time: 6.90e-02, avg batch time: 0.4815, average train loss: 0.0031
[09/26 04:40:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 0.5281
[09/26 04:40:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:40:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:41:03 visual_prompt]: Epoch 77 / 100: avg data time: 7.14e-02, avg batch time: 0.4836, average train loss: 0.0030
[09/26 04:41:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 0.5279
[09/26 04:41:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:41:05 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:41:11 visual_prompt]: Epoch 78 / 100: avg data time: 6.55e-02, avg batch time: 0.4778, average train loss: 0.0032
[09/26 04:41:13 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1583, average loss: 0.5278
[09/26 04:41:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:41:13 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:41:20 visual_prompt]: Epoch 79 / 100: avg data time: 7.16e-02, avg batch time: 0.4841, average train loss: 0.0031
[09/26 04:41:21 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1578, average loss: 0.5276
[09/26 04:41:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:41:22 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:41:28 visual_prompt]: Epoch 80 / 100: avg data time: 6.63e-02, avg batch time: 0.4795, average train loss: 0.0030
[09/26 04:41:30 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1579, average loss: 0.5274
[09/26 04:41:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:41:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:41:36 visual_prompt]: Epoch 81 / 100: avg data time: 5.53e-02, avg batch time: 0.4697, average train loss: 0.0032
[09/26 04:41:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1581, average loss: 0.5276
[09/26 04:41:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:41:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:41:45 visual_prompt]: Epoch 82 / 100: avg data time: 6.24e-02, avg batch time: 0.4750, average train loss: 0.0032
[09/26 04:41:46 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 0.5271
[09/26 04:41:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:41:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:41:53 visual_prompt]: Epoch 83 / 100: avg data time: 6.44e-02, avg batch time: 0.4768, average train loss: 0.0031
[09/26 04:41:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1580, average loss: 0.5270
[09/26 04:41:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:41:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:42:01 visual_prompt]: Epoch 84 / 100: avg data time: 6.85e-02, avg batch time: 0.4807, average train loss: 0.0031
[09/26 04:42:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1583, average loss: 0.5270
[09/26 04:42:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 04:42:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:42:10 visual_prompt]: Epoch 85 / 100: avg data time: 5.40e-02, avg batch time: 0.4698, average train loss: 0.0030
[09/26 04:42:11 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1582, average loss: 0.5270
[09/26 04:42:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:42:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:42:18 visual_prompt]: Epoch 86 / 100: avg data time: 6.97e-02, avg batch time: 0.4822, average train loss: 0.0030
[09/26 04:42:20 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1578, average loss: 0.5272
[09/26 04:42:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:42:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:42:26 visual_prompt]: Epoch 87 / 100: avg data time: 6.35e-02, avg batch time: 0.4770, average train loss: 0.0031
[09/26 04:42:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1584, average loss: 0.5271
[09/26 04:42:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:42:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:42:35 visual_prompt]: Epoch 88 / 100: avg data time: 6.69e-02, avg batch time: 0.4795, average train loss: 0.0030
[09/26 04:42:37 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1582, average loss: 0.5271
[09/26 04:42:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:42:37 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:42:43 visual_prompt]: Epoch 89 / 100: avg data time: 6.94e-02, avg batch time: 0.4820, average train loss: 0.0030
[09/26 04:42:45 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 0.5272
[09/26 04:42:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:42:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:42:52 visual_prompt]: Epoch 90 / 100: avg data time: 6.38e-02, avg batch time: 0.4782, average train loss: 0.0030
[09/26 04:42:53 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1581, average loss: 0.5272
[09/26 04:42:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:42:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:43:00 visual_prompt]: Epoch 91 / 100: avg data time: 6.32e-02, avg batch time: 0.4765, average train loss: 0.0030
[09/26 04:43:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 0.5272
[09/26 04:43:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:43:02 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:43:08 visual_prompt]: Epoch 92 / 100: avg data time: 6.53e-02, avg batch time: 0.4790, average train loss: 0.0030
[09/26 04:43:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1579, average loss: 0.5273
[09/26 04:43:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 04:43:10 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:43:17 visual_prompt]: Epoch 93 / 100: avg data time: 7.05e-02, avg batch time: 0.4837, average train loss: 0.0030
[09/26 04:43:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1581, average loss: 0.5273
[09/26 04:43:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:43:19 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:43:25 visual_prompt]: Epoch 94 / 100: avg data time: 6.17e-02, avg batch time: 0.4753, average train loss: 0.0031
[09/26 04:43:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1586, average loss: 0.5274
[09/26 04:43:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:43:27 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:43:33 visual_prompt]: Epoch 95 / 100: avg data time: 6.94e-02, avg batch time: 0.4825, average train loss: 0.0030
[09/26 04:43:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 0.5274
[09/26 04:43:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:43:35 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:43:42 visual_prompt]: Epoch 96 / 100: avg data time: 6.70e-02, avg batch time: 0.4801, average train loss: 0.0031
[09/26 04:43:43 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1585, average loss: 0.5274
[09/26 04:43:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:43:44 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:43:50 visual_prompt]: Epoch 97 / 100: avg data time: 6.66e-02, avg batch time: 0.4800, average train loss: 0.0030
[09/26 04:43:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.5274
[09/26 04:43:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:43:52 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:43:59 visual_prompt]: Epoch 98 / 100: avg data time: 6.65e-02, avg batch time: 0.4805, average train loss: 0.0029
[09/26 04:44:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.5274
[09/26 04:44:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:44:00 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:44:07 visual_prompt]: Epoch 99 / 100: avg data time: 6.05e-02, avg batch time: 0.4746, average train loss: 0.0029
[09/26 04:44:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 0.5274
[09/26 04:44:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:44:09 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:44:15 visual_prompt]: Epoch 100 / 100: avg data time: 6.48e-02, avg batch time: 0.4778, average train loss: 0.0030
[09/26 04:44:17 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1586, average loss: 0.5274
[09/26 04:44:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:44:17 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:44:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:44:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:44:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:44:17 visual_prompt]: Training with config:
[09/26 04:44:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:44:17 visual_prompt]: Loading training data...
[09/26 04:44:17 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:44:18 visual_prompt]: Number of images: 800
[09/26 04:44:18 visual_prompt]: Number of classes: 102 / 102
[09/26 04:44:18 visual_prompt]: Loading validation data...
[09/26 04:44:18 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:44:19 visual_prompt]: Number of images: 200
[09/26 04:44:19 visual_prompt]: Number of classes: 91 / 102
[09/26 04:44:19 visual_prompt]: Constructing models...
[09/26 04:44:21 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 04:44:21 visual_prompt]: tuned percent:0.625
[09/26 04:44:21 visual_prompt]: Device used for model: 0
[09/26 04:44:21 visual_prompt]: Setting up Evaluator...
[09/26 04:44:21 visual_prompt]: Setting up Trainer...
[09/26 04:44:21 visual_prompt]: 	Setting up the optimizer...
[09/26 04:44:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:44:28 visual_prompt]: Epoch 1 / 100: avg data time: 7.20e-02, avg batch time: 0.4891, average train loss: 4.6644
[09/26 04:44:30 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1583, average loss: 4.6780
[09/26 04:44:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 04:44:30 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:44:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 04:44:36 visual_prompt]: Epoch 2 / 100: avg data time: 7.36e-02, avg batch time: 0.4858, average train loss: 4.6506
[09/26 04:44:38 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1584, average loss: 4.6357
[09/26 04:44:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 6.50	
[09/26 04:44:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 04:44:45 visual_prompt]: Epoch 3 / 100: avg data time: 6.59e-02, avg batch time: 0.4784, average train loss: 4.5923
[09/26 04:44:46 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1580, average loss: 4.5914
[09/26 04:44:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.50	top5: 6.00	
[09/26 04:44:46 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 04:44:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 04:44:53 visual_prompt]: Epoch 4 / 100: avg data time: 6.74e-02, avg batch time: 0.4808, average train loss: 4.4692
[09/26 04:44:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1579, average loss: 4.4588
[09/26 04:44:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 4.50	top5: 15.00	
[09/26 04:44:55 visual_prompt]: Best epoch 4: best metric: 0.045
[09/26 04:44:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 04:45:02 visual_prompt]: Epoch 5 / 100: avg data time: 7.42e-02, avg batch time: 0.4877, average train loss: 4.1761
[09/26 04:45:03 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1584, average loss: 4.1612
[09/26 04:45:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.00	top5: 29.00	
[09/26 04:45:03 visual_prompt]: Best epoch 5: best metric: 0.110
[09/26 04:45:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 04:45:10 visual_prompt]: Epoch 6 / 100: avg data time: 6.72e-02, avg batch time: 0.4809, average train loss: 3.7189
[09/26 04:45:12 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1574, average loss: 3.6151
[09/26 04:45:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 21.00	top5: 44.50	
[09/26 04:45:12 visual_prompt]: Best epoch 6: best metric: 0.210
[09/26 04:45:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 04:45:19 visual_prompt]: Epoch 7 / 100: avg data time: 7.23e-02, avg batch time: 0.4864, average train loss: 3.1148
[09/26 04:45:20 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1587, average loss: 3.0780
[09/26 04:45:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 33.00	top5: 65.00	
[09/26 04:45:20 visual_prompt]: Best epoch 7: best metric: 0.330
[09/26 04:45:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 04:45:27 visual_prompt]: Epoch 8 / 100: avg data time: 5.19e-02, avg batch time: 0.4661, average train loss: 2.5352
[09/26 04:45:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1578, average loss: 2.6390
[09/26 04:45:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 44.50	top5: 71.50	
[09/26 04:45:28 visual_prompt]: Best epoch 8: best metric: 0.445
[09/26 04:45:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 04:45:35 visual_prompt]: Epoch 9 / 100: avg data time: 5.97e-02, avg batch time: 0.4725, average train loss: 1.9967
[09/26 04:45:37 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1588, average loss: 2.0750
[09/26 04:45:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.50	top5: 82.50	
[09/26 04:45:37 visual_prompt]: Best epoch 9: best metric: 0.605
[09/26 04:45:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 04:45:43 visual_prompt]: Epoch 10 / 100: avg data time: 6.09e-02, avg batch time: 0.4766, average train loss: 1.4641
[09/26 04:45:45 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1579, average loss: 1.6628
[09/26 04:45:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.00	top5: 90.00	
[09/26 04:45:45 visual_prompt]: Best epoch 10: best metric: 0.700
[09/26 04:45:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 04:45:52 visual_prompt]: Epoch 11 / 100: avg data time: 6.48e-02, avg batch time: 0.4786, average train loss: 1.0864
[09/26 04:45:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 1.3514
[09/26 04:45:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 92.00	
[09/26 04:45:53 visual_prompt]: Best epoch 11: best metric: 0.770
[09/26 04:45:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 04:46:00 visual_prompt]: Epoch 12 / 100: avg data time: 6.29e-02, avg batch time: 0.4781, average train loss: 0.8405
[09/26 04:46:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 1.2481
[09/26 04:46:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 93.00	
[09/26 04:46:02 visual_prompt]: Best epoch 12: best metric: 0.795
[09/26 04:46:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 04:46:08 visual_prompt]: Epoch 13 / 100: avg data time: 6.42e-02, avg batch time: 0.4785, average train loss: 0.6766
[09/26 04:46:10 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1576, average loss: 1.1216
[09/26 04:46:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.50	
[09/26 04:46:10 visual_prompt]: Best epoch 13: best metric: 0.825
[09/26 04:46:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 04:46:17 visual_prompt]: Epoch 14 / 100: avg data time: 6.65e-02, avg batch time: 0.4797, average train loss: 0.5840
[09/26 04:46:19 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1587, average loss: 1.0415
[09/26 04:46:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 04:46:19 visual_prompt]: Best epoch 14: best metric: 0.855
[09/26 04:46:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 04:46:25 visual_prompt]: Epoch 15 / 100: avg data time: 6.22e-02, avg batch time: 0.4760, average train loss: 0.5156
[09/26 04:46:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.9709
[09/26 04:46:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.00	
[09/26 04:46:27 visual_prompt]: Best epoch 15: best metric: 0.885
[09/26 04:46:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 04:46:34 visual_prompt]: Epoch 16 / 100: avg data time: 7.68e-02, avg batch time: 0.4908, average train loss: 0.4777
[09/26 04:46:35 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.9586
[09/26 04:46:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:46:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 04:46:42 visual_prompt]: Epoch 17 / 100: avg data time: 6.69e-02, avg batch time: 0.4800, average train loss: 0.4655
[09/26 04:46:44 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1584, average loss: 0.9840
[09/26 04:46:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 04:46:44 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 04:46:51 visual_prompt]: Epoch 18 / 100: avg data time: 6.47e-02, avg batch time: 0.4789, average train loss: 0.4720
[09/26 04:46:52 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 1.0457
[09/26 04:46:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.00	
[09/26 04:46:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 04:46:59 visual_prompt]: Epoch 19 / 100: avg data time: 6.62e-02, avg batch time: 0.4803, average train loss: 0.4879
[09/26 04:47:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 1.0299
[09/26 04:47:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.50	
[09/26 04:47:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 04:47:07 visual_prompt]: Epoch 20 / 100: avg data time: 6.52e-02, avg batch time: 0.4786, average train loss: 0.5192
[09/26 04:47:09 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 0.9397
[09/26 04:47:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 95.50	
[09/26 04:47:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 04:47:16 visual_prompt]: Epoch 21 / 100: avg data time: 7.35e-02, avg batch time: 0.4887, average train loss: 0.4777
[09/26 04:47:18 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1586, average loss: 0.9900
[09/26 04:47:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 94.50	
[09/26 04:47:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 04:47:24 visual_prompt]: Epoch 22 / 100: avg data time: 6.51e-02, avg batch time: 0.4804, average train loss: 0.5038
[09/26 04:47:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1586, average loss: 0.9824
[09/26 04:47:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 04:47:26 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 04:47:33 visual_prompt]: Epoch 23 / 100: avg data time: 6.24e-02, avg batch time: 0.4762, average train loss: 0.4514
[09/26 04:47:34 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1585, average loss: 0.9363
[09/26 04:47:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 95.50	
[09/26 04:47:34 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 04:47:41 visual_prompt]: Epoch 24 / 100: avg data time: 6.44e-02, avg batch time: 0.4787, average train loss: 0.4657
[09/26 04:47:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1587, average loss: 0.8903
[09/26 04:47:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 94.50	
[09/26 04:47:43 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 04:47:49 visual_prompt]: Epoch 25 / 100: avg data time: 6.60e-02, avg batch time: 0.4804, average train loss: 0.4485
[09/26 04:47:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1586, average loss: 0.8778
[09/26 04:47:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.00	
[09/26 04:47:51 visual_prompt]: Best epoch 25: best metric: 0.895
[09/26 04:47:51 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 04:47:58 visual_prompt]: Epoch 26 / 100: avg data time: 6.68e-02, avg batch time: 0.4810, average train loss: 0.4018
[09/26 04:48:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1589, average loss: 0.7824
[09/26 04:48:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.50	
[09/26 04:48:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 04:48:06 visual_prompt]: Epoch 27 / 100: avg data time: 6.52e-02, avg batch time: 0.4787, average train loss: 0.3350
[09/26 04:48:08 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1583, average loss: 0.7591
[09/26 04:48:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 04:48:08 visual_prompt]: Best epoch 27: best metric: 0.905
[09/26 04:48:08 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 04:48:15 visual_prompt]: Epoch 28 / 100: avg data time: 7.05e-02, avg batch time: 0.4857, average train loss: 0.3325
[09/26 04:48:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1585, average loss: 0.7586
[09/26 04:48:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 04:48:16 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 04:48:23 visual_prompt]: Epoch 29 / 100: avg data time: 6.53e-02, avg batch time: 0.4787, average train loss: 0.3339
[09/26 04:48:25 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 0.7785
[09/26 04:48:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 04:48:25 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 04:48:31 visual_prompt]: Epoch 30 / 100: avg data time: 6.36e-02, avg batch time: 0.4780, average train loss: 0.3702
[09/26 04:48:33 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1585, average loss: 0.8499
[09/26 04:48:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 94.50	
[09/26 04:48:33 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 04:48:40 visual_prompt]: Epoch 31 / 100: avg data time: 6.44e-02, avg batch time: 0.4781, average train loss: 0.4204
[09/26 04:48:42 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1583, average loss: 0.8986
[09/26 04:48:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:48:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 04:48:48 visual_prompt]: Epoch 32 / 100: avg data time: 7.08e-02, avg batch time: 0.4843, average train loss: 0.4073
[09/26 04:48:50 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1585, average loss: 0.8424
[09/26 04:48:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 04:48:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 04:48:57 visual_prompt]: Epoch 33 / 100: avg data time: 6.90e-02, avg batch time: 0.4823, average train loss: 0.3696
[09/26 04:48:58 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.8063
[09/26 04:48:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 95.50	
[09/26 04:48:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 04:49:05 visual_prompt]: Epoch 34 / 100: avg data time: 6.28e-02, avg batch time: 0.4772, average train loss: 0.3414
[09/26 04:49:07 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1582, average loss: 0.8031
[09/26 04:49:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 95.50	
[09/26 04:49:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 04:49:13 visual_prompt]: Epoch 35 / 100: avg data time: 6.88e-02, avg batch time: 0.4822, average train loss: 0.3607
[09/26 04:49:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1586, average loss: 0.8225
[09/26 04:49:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 95.50	
[09/26 04:49:15 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 04:49:22 visual_prompt]: Epoch 36 / 100: avg data time: 6.16e-02, avg batch time: 0.4750, average train loss: 0.3517
[09/26 04:49:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.8769
[09/26 04:49:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.00	
[09/26 04:49:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 04:49:30 visual_prompt]: Epoch 37 / 100: avg data time: 7.07e-02, avg batch time: 0.4848, average train loss: 0.3828
[09/26 04:49:32 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1585, average loss: 0.7385
[09/26 04:49:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.50	
[09/26 04:49:32 visual_prompt]: Best epoch 37: best metric: 0.930
[09/26 04:49:32 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 04:49:39 visual_prompt]: Epoch 38 / 100: avg data time: 7.17e-02, avg batch time: 0.4859, average train loss: 0.3882
[09/26 04:49:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1581, average loss: 0.7549
[09/26 04:49:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 04:49:40 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 04:49:47 visual_prompt]: Epoch 39 / 100: avg data time: 6.58e-02, avg batch time: 0.4797, average train loss: 0.3683
[09/26 04:49:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1587, average loss: 0.8268
[09/26 04:49:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 04:49:49 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 04:49:55 visual_prompt]: Epoch 40 / 100: avg data time: 6.34e-02, avg batch time: 0.4773, average train loss: 0.3586
[09/26 04:49:57 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1579, average loss: 0.8038
[09/26 04:49:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.00	
[09/26 04:49:57 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 04:50:04 visual_prompt]: Epoch 41 / 100: avg data time: 6.65e-02, avg batch time: 0.4805, average train loss: 0.3438
[09/26 04:50:06 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 0.8021
[09/26 04:50:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 04:50:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 04:50:12 visual_prompt]: Epoch 42 / 100: avg data time: 7.36e-02, avg batch time: 0.4875, average train loss: 0.3344
[09/26 04:50:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.7175
[09/26 04:50:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 04:50:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 04:50:21 visual_prompt]: Epoch 43 / 100: avg data time: 7.00e-02, avg batch time: 0.4841, average train loss: 0.3131
[09/26 04:50:23 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1577, average loss: 0.7280
[09/26 04:50:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 95.00	
[09/26 04:50:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 04:50:29 visual_prompt]: Epoch 44 / 100: avg data time: 7.19e-02, avg batch time: 0.4854, average train loss: 0.2812
[09/26 04:50:31 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1578, average loss: 0.6816
[09/26 04:50:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 04:50:31 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 04:50:38 visual_prompt]: Epoch 45 / 100: avg data time: 6.47e-02, avg batch time: 0.4783, average train loss: 0.2606
[09/26 04:50:40 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1584, average loss: 0.6320
[09/26 04:50:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 96.00	
[09/26 04:50:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 04:50:46 visual_prompt]: Epoch 46 / 100: avg data time: 6.67e-02, avg batch time: 0.4795, average train loss: 0.2459
[09/26 04:50:48 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1587, average loss: 0.6280
[09/26 04:50:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:50:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 04:50:54 visual_prompt]: Epoch 47 / 100: avg data time: 5.32e-02, avg batch time: 0.4683, average train loss: 0.2422
[09/26 04:50:56 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1581, average loss: 0.6431
[09/26 04:50:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 96.50	
[09/26 04:50:56 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 04:51:03 visual_prompt]: Epoch 48 / 100: avg data time: 5.56e-02, avg batch time: 0.4707, average train loss: 0.2417
[09/26 04:51:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.6283
[09/26 04:51:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 04:51:04 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 04:51:11 visual_prompt]: Epoch 49 / 100: avg data time: 6.08e-02, avg batch time: 0.4766, average train loss: 0.2456
[09/26 04:51:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 0.6537
[09/26 04:51:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:51:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 04:51:19 visual_prompt]: Epoch 50 / 100: avg data time: 6.86e-02, avg batch time: 0.4814, average train loss: 0.2478
[09/26 04:51:21 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.6937
[09/26 04:51:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 04:51:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 04:51:28 visual_prompt]: Epoch 51 / 100: avg data time: 6.42e-02, avg batch time: 0.4782, average train loss: 0.2533
[09/26 04:51:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.7089
[09/26 04:51:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 04:51:30 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 04:51:36 visual_prompt]: Epoch 52 / 100: avg data time: 6.86e-02, avg batch time: 0.4825, average train loss: 0.2550
[09/26 04:51:38 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 0.6712
[09/26 04:51:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 04:51:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 04:51:45 visual_prompt]: Epoch 53 / 100: avg data time: 6.16e-02, avg batch time: 0.4755, average train loss: 0.3339
[09/26 04:51:46 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1579, average loss: 0.9563
[09/26 04:51:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 04:51:46 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 04:51:53 visual_prompt]: Epoch 54 / 100: avg data time: 6.60e-02, avg batch time: 0.4793, average train loss: 0.9335
[09/26 04:51:55 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1585, average loss: 1.4999
[09/26 04:51:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 96.00	
[09/26 04:51:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 04:52:01 visual_prompt]: Epoch 55 / 100: avg data time: 6.85e-02, avg batch time: 0.4820, average train loss: 0.9950
[09/26 04:52:03 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 1.1558
[09/26 04:52:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 94.50	
[09/26 04:52:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 04:52:10 visual_prompt]: Epoch 56 / 100: avg data time: 5.80e-02, avg batch time: 0.4722, average train loss: 0.5680
[09/26 04:52:11 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1575, average loss: 0.7723
[09/26 04:52:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 93.00	top5: 97.00	
[09/26 04:52:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 04:52:18 visual_prompt]: Epoch 57 / 100: avg data time: 6.31e-02, avg batch time: 0.4769, average train loss: 0.3812
[09/26 04:52:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 0.6885
[09/26 04:52:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 04:52:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 04:52:26 visual_prompt]: Epoch 58 / 100: avg data time: 6.60e-02, avg batch time: 0.4799, average train loss: 0.2949
[09/26 04:52:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.6406
[09/26 04:52:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:52:28 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 04:52:35 visual_prompt]: Epoch 59 / 100: avg data time: 6.07e-02, avg batch time: 0.4758, average train loss: 0.2580
[09/26 04:52:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 0.6395
[09/26 04:52:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.50	top5: 97.00	
[09/26 04:52:36 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 04:52:43 visual_prompt]: Epoch 60 / 100: avg data time: 6.74e-02, avg batch time: 0.4813, average train loss: 0.2431
[09/26 04:52:45 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1580, average loss: 0.6219
[09/26 04:52:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 04:52:45 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 04:52:51 visual_prompt]: Epoch 61 / 100: avg data time: 6.81e-02, avg batch time: 0.4815, average train loss: 0.2344
[09/26 04:52:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1586, average loss: 0.6419
[09/26 04:52:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 97.00	
[09/26 04:52:53 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 04:53:00 visual_prompt]: Epoch 62 / 100: avg data time: 6.56e-02, avg batch time: 0.4796, average train loss: 0.2359
[09/26 04:53:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.6248
[09/26 04:53:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 04:53:02 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 04:53:08 visual_prompt]: Epoch 63 / 100: avg data time: 6.60e-02, avg batch time: 0.4792, average train loss: 0.2377
[09/26 04:53:10 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1586, average loss: 0.6419
[09/26 04:53:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.00	
[09/26 04:53:10 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 04:53:17 visual_prompt]: Epoch 64 / 100: avg data time: 6.42e-02, avg batch time: 0.4773, average train loss: 0.2367
[09/26 04:53:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.6358
[09/26 04:53:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 97.50	
[09/26 04:53:18 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 04:53:25 visual_prompt]: Epoch 65 / 100: avg data time: 4.84e-02, avg batch time: 0.4634, average train loss: 0.2364
[09/26 04:53:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1586, average loss: 0.6302
[09/26 04:53:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 04:53:26 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 04:53:33 visual_prompt]: Epoch 66 / 100: avg data time: 5.78e-02, avg batch time: 0.4725, average train loss: 0.2367
[09/26 04:53:35 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1588, average loss: 0.6441
[09/26 04:53:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 04:53:35 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 04:53:41 visual_prompt]: Epoch 67 / 100: avg data time: 7.05e-02, avg batch time: 0.4835, average train loss: 0.2364
[09/26 04:53:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 0.6531
[09/26 04:53:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.00	
[09/26 04:53:43 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 04:53:50 visual_prompt]: Epoch 68 / 100: avg data time: 6.70e-02, avg batch time: 0.4800, average train loss: 0.2363
[09/26 04:53:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.6557
[09/26 04:53:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 04:53:51 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 04:53:58 visual_prompt]: Epoch 69 / 100: avg data time: 6.21e-02, avg batch time: 0.4753, average train loss: 0.2362
[09/26 04:54:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.6683
[09/26 04:54:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 04:54:00 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 04:54:06 visual_prompt]: Epoch 70 / 100: avg data time: 6.69e-02, avg batch time: 0.4809, average train loss: 0.2354
[09/26 04:54:08 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1584, average loss: 0.6612
[09/26 04:54:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 04:54:08 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 04:54:15 visual_prompt]: Epoch 71 / 100: avg data time: 6.91e-02, avg batch time: 0.4844, average train loss: 0.2371
[09/26 04:54:17 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1583, average loss: 0.6876
[09/26 04:54:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 04:54:17 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 04:54:23 visual_prompt]: Epoch 72 / 100: avg data time: 7.08e-02, avg batch time: 0.4835, average train loss: 0.2367
[09/26 04:54:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 0.6644
[09/26 04:54:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 04:54:25 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 04:54:32 visual_prompt]: Epoch 73 / 100: avg data time: 6.49e-02, avg batch time: 0.4778, average train loss: 0.2369
[09/26 04:54:33 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.6926
[09/26 04:54:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 04:54:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 04:54:40 visual_prompt]: Epoch 74 / 100: avg data time: 6.78e-02, avg batch time: 0.4809, average train loss: 0.2361
[09/26 04:54:42 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1583, average loss: 0.6731
[09/26 04:54:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.50	
[09/26 04:54:42 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 04:54:48 visual_prompt]: Epoch 75 / 100: avg data time: 5.60e-02, avg batch time: 0.4708, average train loss: 0.2352
[09/26 04:54:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1584, average loss: 0.6793
[09/26 04:54:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 04:54:50 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 04:54:57 visual_prompt]: Epoch 76 / 100: avg data time: 6.55e-02, avg batch time: 0.4782, average train loss: 0.2348
[09/26 04:54:59 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1583, average loss: 0.6716
[09/26 04:54:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 04:54:59 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 04:55:05 visual_prompt]: Epoch 77 / 100: avg data time: 6.48e-02, avg batch time: 0.4797, average train loss: 0.2339
[09/26 04:55:07 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1580, average loss: 0.6739
[09/26 04:55:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:55:07 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 04:55:14 visual_prompt]: Epoch 78 / 100: avg data time: 6.49e-02, avg batch time: 0.4789, average train loss: 0.2336
[09/26 04:55:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.6717
[09/26 04:55:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:55:15 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 04:55:22 visual_prompt]: Epoch 79 / 100: avg data time: 5.91e-02, avg batch time: 0.4728, average train loss: 0.2335
[09/26 04:55:24 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 0.6876
[09/26 04:55:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.00	
[09/26 04:55:24 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 04:55:30 visual_prompt]: Epoch 80 / 100: avg data time: 5.19e-02, avg batch time: 0.4662, average train loss: 0.2330
[09/26 04:55:32 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1585, average loss: 0.6956
[09/26 04:55:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 04:55:32 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 04:55:38 visual_prompt]: Epoch 81 / 100: avg data time: 6.58e-02, avg batch time: 0.4794, average train loss: 0.2326
[09/26 04:55:40 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1582, average loss: 0.6856
[09/26 04:55:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 92.00	top5: 96.50	
[09/26 04:55:40 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 04:55:47 visual_prompt]: Epoch 82 / 100: avg data time: 6.54e-02, avg batch time: 0.4785, average train loss: 0.2321
[09/26 04:55:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.6970
[09/26 04:55:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 97.00	
[09/26 04:55:48 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 04:55:55 visual_prompt]: Epoch 83 / 100: avg data time: 6.58e-02, avg batch time: 0.4794, average train loss: 0.2319
[09/26 04:55:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 0.6933
[09/26 04:55:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 97.00	
[09/26 04:55:57 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 04:56:03 visual_prompt]: Epoch 84 / 100: avg data time: 6.59e-02, avg batch time: 0.4797, average train loss: 0.2317
[09/26 04:56:05 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1577, average loss: 0.6836
[09/26 04:56:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 04:56:05 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 04:56:12 visual_prompt]: Epoch 85 / 100: avg data time: 6.67e-02, avg batch time: 0.4804, average train loss: 0.2312
[09/26 04:56:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1579, average loss: 0.7037
[09/26 04:56:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 95.50	
[09/26 04:56:14 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 04:56:20 visual_prompt]: Epoch 86 / 100: avg data time: 6.45e-02, avg batch time: 0.4792, average train loss: 0.2308
[09/26 04:56:22 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1576, average loss: 0.6970
[09/26 04:56:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.50	
[09/26 04:56:22 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 04:56:29 visual_prompt]: Epoch 87 / 100: avg data time: 6.86e-02, avg batch time: 0.4822, average train loss: 0.2310
[09/26 04:56:30 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1582, average loss: 0.6962
[09/26 04:56:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:56:30 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 04:56:37 visual_prompt]: Epoch 88 / 100: avg data time: 7.54e-02, avg batch time: 0.4896, average train loss: 0.2305
[09/26 04:56:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1583, average loss: 0.7135
[09/26 04:56:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 95.50	
[09/26 04:56:39 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 04:56:46 visual_prompt]: Epoch 89 / 100: avg data time: 7.13e-02, avg batch time: 0.4842, average train loss: 0.2307
[09/26 04:56:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1581, average loss: 0.6945
[09/26 04:56:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 04:56:47 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 04:56:54 visual_prompt]: Epoch 90 / 100: avg data time: 6.47e-02, avg batch time: 0.4798, average train loss: 0.2300
[09/26 04:56:56 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1581, average loss: 0.7010
[09/26 04:56:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:56:56 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 04:57:02 visual_prompt]: Epoch 91 / 100: avg data time: 6.24e-02, avg batch time: 0.4764, average train loss: 0.2298
[09/26 04:57:04 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1582, average loss: 0.6962
[09/26 04:57:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:04 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 04:57:11 visual_prompt]: Epoch 92 / 100: avg data time: 6.54e-02, avg batch time: 0.4786, average train loss: 0.2297
[09/26 04:57:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1585, average loss: 0.6930
[09/26 04:57:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:12 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 04:57:19 visual_prompt]: Epoch 93 / 100: avg data time: 7.01e-02, avg batch time: 0.4835, average train loss: 0.2292
[09/26 04:57:21 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1582, average loss: 0.6924
[09/26 04:57:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:21 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 04:57:28 visual_prompt]: Epoch 94 / 100: avg data time: 6.66e-02, avg batch time: 0.4808, average train loss: 0.2294
[09/26 04:57:29 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1584, average loss: 0.6875
[09/26 04:57:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:29 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 04:57:36 visual_prompt]: Epoch 95 / 100: avg data time: 6.73e-02, avg batch time: 0.4815, average train loss: 0.2295
[09/26 04:57:38 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1583, average loss: 0.6879
[09/26 04:57:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 04:57:44 visual_prompt]: Epoch 96 / 100: avg data time: 6.23e-02, avg batch time: 0.4755, average train loss: 0.2293
[09/26 04:57:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 0.6901
[09/26 04:57:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:46 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 04:57:53 visual_prompt]: Epoch 97 / 100: avg data time: 6.62e-02, avg batch time: 0.4808, average train loss: 0.2295
[09/26 04:57:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1587, average loss: 0.6926
[09/26 04:57:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:57:55 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 04:58:01 visual_prompt]: Epoch 98 / 100: avg data time: 7.00e-02, avg batch time: 0.4841, average train loss: 0.2299
[09/26 04:58:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 0.6934
[09/26 04:58:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:58:03 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 04:58:10 visual_prompt]: Epoch 99 / 100: avg data time: 6.77e-02, avg batch time: 0.4807, average train loss: 0.2293
[09/26 04:58:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 0.6937
[09/26 04:58:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:58:11 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 04:58:18 visual_prompt]: Epoch 100 / 100: avg data time: 6.96e-02, avg batch time: 0.4843, average train loss: 0.2292
[09/26 04:58:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 0.6937
[09/26 04:58:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.50	top5: 96.00	
[09/26 04:58:20 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:58:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:58:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:58:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:58:20 visual_prompt]: Training with config:
[09/26 04:58:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:58:20 visual_prompt]: Loading training data...
[09/26 04:58:20 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:58:21 visual_prompt]: Number of images: 800
[09/26 04:58:21 visual_prompt]: Number of classes: 102 / 102
[09/26 04:58:21 visual_prompt]: Loading validation data...
[09/26 04:58:21 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 04:58:21 visual_prompt]: Number of images: 200
[09/26 04:58:21 visual_prompt]: Number of classes: 91 / 102
[09/26 04:58:21 visual_prompt]: Constructing models...
[09/26 04:58:24 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 04:58:24 visual_prompt]: tuned percent:0.625
[09/26 04:58:24 visual_prompt]: Device used for model: 0
[09/26 04:58:24 visual_prompt]: Setting up Evaluator...
[09/26 04:58:24 visual_prompt]: Setting up Trainer...
[09/26 04:58:24 visual_prompt]: 	Setting up the optimizer...
[09/26 04:58:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:58:31 visual_prompt]: Epoch 1 / 100: avg data time: 6.78e-02, avg batch time: 0.4874, average train loss: 4.6665
[09/26 04:58:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1577, average loss: 4.6780
[09/26 04:58:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 04:58:32 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:58:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 04:58:39 visual_prompt]: Epoch 2 / 100: avg data time: 6.22e-02, avg batch time: 0.4756, average train loss: 4.6472
[09/26 04:58:41 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1583, average loss: 4.6372
[09/26 04:58:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 04:58:41 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 04:58:47 visual_prompt]: Epoch 3 / 100: avg data time: 6.16e-02, avg batch time: 0.4750, average train loss: 4.5879
[09/26 04:58:49 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1583, average loss: 4.5757
[09/26 04:58:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 9.00	
[09/26 04:58:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 04:58:56 visual_prompt]: Epoch 4 / 100: avg data time: 6.87e-02, avg batch time: 0.4808, average train loss: 4.4713
[09/26 04:58:57 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 4.4653
[09/26 04:58:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 15.50	
[09/26 04:58:57 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 04:58:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 04:59:04 visual_prompt]: Epoch 5 / 100: avg data time: 6.81e-02, avg batch time: 0.4814, average train loss: 4.2106
[09/26 04:59:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1580, average loss: 4.0612
[09/26 04:59:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.50	top5: 32.00	
[09/26 04:59:06 visual_prompt]: Best epoch 5: best metric: 0.095
[09/26 04:59:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 04:59:12 visual_prompt]: Epoch 6 / 100: avg data time: 5.98e-02, avg batch time: 0.4732, average train loss: 3.6688
[09/26 04:59:14 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1579, average loss: 3.6197
[09/26 04:59:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 18.50	top5: 40.50	
[09/26 04:59:14 visual_prompt]: Best epoch 6: best metric: 0.185
[09/26 04:59:14 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 04:59:21 visual_prompt]: Epoch 7 / 100: avg data time: 6.75e-02, avg batch time: 0.4801, average train loss: 3.0718
[09/26 04:59:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 2.9517
[09/26 04:59:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 31.50	top5: 60.50	
[09/26 04:59:22 visual_prompt]: Best epoch 7: best metric: 0.315
[09/26 04:59:22 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 04:59:29 visual_prompt]: Epoch 8 / 100: avg data time: 6.82e-02, avg batch time: 0.4826, average train loss: 2.4097
[09/26 04:59:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 2.5410
[09/26 04:59:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 41.00	top5: 69.50	
[09/26 04:59:31 visual_prompt]: Best epoch 8: best metric: 0.410
[09/26 04:59:31 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 04:59:38 visual_prompt]: Epoch 9 / 100: avg data time: 7.05e-02, avg batch time: 0.4839, average train loss: 1.7356
[09/26 04:59:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 1.8956
[09/26 04:59:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 61.00	top5: 81.50	
[09/26 04:59:39 visual_prompt]: Best epoch 9: best metric: 0.610
[09/26 04:59:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 04:59:46 visual_prompt]: Epoch 10 / 100: avg data time: 6.50e-02, avg batch time: 0.4779, average train loss: 1.1603
[09/26 04:59:48 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1581, average loss: 1.4253
[09/26 04:59:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.50	top5: 89.00	
[09/26 04:59:48 visual_prompt]: Best epoch 10: best metric: 0.705
[09/26 04:59:48 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 04:59:54 visual_prompt]: Epoch 11 / 100: avg data time: 6.53e-02, avg batch time: 0.4785, average train loss: 0.7432
[09/26 04:59:56 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1587, average loss: 1.2288
[09/26 04:59:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 73.00	top5: 89.50	
[09/26 04:59:56 visual_prompt]: Best epoch 11: best metric: 0.730
[09/26 04:59:56 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:00:03 visual_prompt]: Epoch 12 / 100: avg data time: 6.04e-02, avg batch time: 0.4740, average train loss: 0.4836
[09/26 05:00:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1581, average loss: 1.0206
[09/26 05:00:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.00	top5: 93.00	
[09/26 05:00:04 visual_prompt]: Best epoch 12: best metric: 0.750
[09/26 05:00:04 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:00:11 visual_prompt]: Epoch 13 / 100: avg data time: 6.68e-02, avg batch time: 0.4793, average train loss: 0.3034
[09/26 05:00:13 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1583, average loss: 0.9635
[09/26 05:00:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 94.00	
[09/26 05:00:13 visual_prompt]: Best epoch 13: best metric: 0.775
[09/26 05:00:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:00:19 visual_prompt]: Epoch 14 / 100: avg data time: 6.64e-02, avg batch time: 0.4796, average train loss: 0.2117
[09/26 05:00:21 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1579, average loss: 0.8986
[09/26 05:00:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 94.50	
[09/26 05:00:21 visual_prompt]: Best epoch 14: best metric: 0.785
[09/26 05:00:21 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:00:28 visual_prompt]: Epoch 15 / 100: avg data time: 6.15e-02, avg batch time: 0.4741, average train loss: 0.1542
[09/26 05:00:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 0.8368
[09/26 05:00:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 96.00	
[09/26 05:00:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:00:36 visual_prompt]: Epoch 16 / 100: avg data time: 5.38e-02, avg batch time: 0.4674, average train loss: 0.1197
[09/26 05:00:38 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1582, average loss: 0.8037
[09/26 05:00:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 97.00	
[09/26 05:00:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:00:44 visual_prompt]: Epoch 17 / 100: avg data time: 5.75e-02, avg batch time: 0.4713, average train loss: 0.0951
[09/26 05:00:46 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1581, average loss: 0.7577
[09/26 05:00:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 97.00	
[09/26 05:00:46 visual_prompt]: Best epoch 17: best metric: 0.800
[09/26 05:00:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:00:53 visual_prompt]: Epoch 18 / 100: avg data time: 6.46e-02, avg batch time: 0.4775, average train loss: 0.0751
[09/26 05:00:54 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1586, average loss: 0.7694
[09/26 05:00:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 05:00:54 visual_prompt]: Best epoch 18: best metric: 0.825
[09/26 05:00:54 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:01:01 visual_prompt]: Epoch 19 / 100: avg data time: 7.00e-02, avg batch time: 0.4831, average train loss: 0.0656
[09/26 05:01:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 0.7382
[09/26 05:01:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 96.00	
[09/26 05:01:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:01:10 visual_prompt]: Epoch 20 / 100: avg data time: 6.65e-02, avg batch time: 0.4798, average train loss: 0.0568
[09/26 05:01:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1584, average loss: 0.7214
[09/26 05:01:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 96.00	
[09/26 05:01:11 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:01:18 visual_prompt]: Epoch 21 / 100: avg data time: 7.22e-02, avg batch time: 0.4863, average train loss: 0.0523
[09/26 05:01:20 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.7331
[09/26 05:01:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.50	
[09/26 05:01:20 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:01:26 visual_prompt]: Epoch 22 / 100: avg data time: 6.32e-02, avg batch time: 0.4760, average train loss: 0.0482
[09/26 05:01:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 0.7244
[09/26 05:01:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.00	
[09/26 05:01:28 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:01:35 visual_prompt]: Epoch 23 / 100: avg data time: 7.07e-02, avg batch time: 0.4837, average train loss: 0.0464
[09/26 05:01:37 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1579, average loss: 0.6961
[09/26 05:01:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.50	
[09/26 05:01:37 visual_prompt]: Best epoch 23: best metric: 0.830
[09/26 05:01:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:01:43 visual_prompt]: Epoch 24 / 100: avg data time: 5.99e-02, avg batch time: 0.4744, average train loss: 0.0440
[09/26 05:01:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1583, average loss: 0.7113
[09/26 05:01:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 97.00	
[09/26 05:01:45 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:01:51 visual_prompt]: Epoch 25 / 100: avg data time: 5.31e-02, avg batch time: 0.4673, average train loss: 0.0427
[09/26 05:01:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1581, average loss: 0.7115
[09/26 05:01:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 96.00	
[09/26 05:01:53 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:02:00 visual_prompt]: Epoch 26 / 100: avg data time: 5.49e-02, avg batch time: 0.4729, average train loss: 0.0422
[09/26 05:02:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 0.6857
[09/26 05:02:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.50	
[09/26 05:02:01 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:02:08 visual_prompt]: Epoch 27 / 100: avg data time: 6.78e-02, avg batch time: 0.4807, average train loss: 0.0415
[09/26 05:02:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 0.7120
[09/26 05:02:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 97.00	
[09/26 05:02:10 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:02:17 visual_prompt]: Epoch 28 / 100: avg data time: 7.07e-02, avg batch time: 0.4841, average train loss: 0.0417
[09/26 05:02:18 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1584, average loss: 0.6783
[09/26 05:02:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 96.50	
[09/26 05:02:18 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:02:25 visual_prompt]: Epoch 29 / 100: avg data time: 7.29e-02, avg batch time: 0.4865, average train loss: 0.0384
[09/26 05:02:27 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1583, average loss: 0.6719
[09/26 05:02:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:02:27 visual_prompt]: Best epoch 29: best metric: 0.840
[09/26 05:02:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:02:33 visual_prompt]: Epoch 30 / 100: avg data time: 6.70e-02, avg batch time: 0.4799, average train loss: 0.0388
[09/26 05:02:35 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1584, average loss: 0.6841
[09/26 05:02:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.50	
[09/26 05:02:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:02:42 visual_prompt]: Epoch 31 / 100: avg data time: 6.67e-02, avg batch time: 0.4799, average train loss: 0.0375
[09/26 05:02:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 0.6836
[09/26 05:02:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.00	
[09/26 05:02:43 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:02:50 visual_prompt]: Epoch 32 / 100: avg data time: 5.84e-02, avg batch time: 0.4724, average train loss: 0.0369
[09/26 05:02:52 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1583, average loss: 0.6746
[09/26 05:02:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.00	
[09/26 05:02:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:02:58 visual_prompt]: Epoch 33 / 100: avg data time: 6.94e-02, avg batch time: 0.4831, average train loss: 0.0363
[09/26 05:03:00 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1585, average loss: 0.6822
[09/26 05:03:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.00	
[09/26 05:03:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:03:07 visual_prompt]: Epoch 34 / 100: avg data time: 6.51e-02, avg batch time: 0.4796, average train loss: 0.0352
[09/26 05:03:09 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1585, average loss: 0.6826
[09/26 05:03:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.00	
[09/26 05:03:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:03:15 visual_prompt]: Epoch 35 / 100: avg data time: 6.86e-02, avg batch time: 0.4822, average train loss: 0.0347
[09/26 05:03:17 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1584, average loss: 0.6750
[09/26 05:03:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.50	
[09/26 05:03:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:03:24 visual_prompt]: Epoch 36 / 100: avg data time: 5.66e-02, avg batch time: 0.4719, average train loss: 0.0342
[09/26 05:03:25 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1579, average loss: 0.6832
[09/26 05:03:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 96.50	
[09/26 05:03:25 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:03:32 visual_prompt]: Epoch 37 / 100: avg data time: 7.09e-02, avg batch time: 0.4844, average train loss: 0.0341
[09/26 05:03:34 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.6810
[09/26 05:03:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.50	
[09/26 05:03:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:03:40 visual_prompt]: Epoch 38 / 100: avg data time: 6.28e-02, avg batch time: 0.4765, average train loss: 0.0339
[09/26 05:03:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1583, average loss: 0.6856
[09/26 05:03:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.00	
[09/26 05:03:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:03:48 visual_prompt]: Epoch 39 / 100: avg data time: 5.61e-02, avg batch time: 0.4695, average train loss: 0.0342
[09/26 05:03:50 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1579, average loss: 0.6794
[09/26 05:03:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.00	
[09/26 05:03:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:03:57 visual_prompt]: Epoch 40 / 100: avg data time: 6.37e-02, avg batch time: 0.4772, average train loss: 0.0340
[09/26 05:03:59 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1586, average loss: 0.6539
[09/26 05:03:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.00	
[09/26 05:03:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:04:05 visual_prompt]: Epoch 41 / 100: avg data time: 6.48e-02, avg batch time: 0.4796, average train loss: 0.0344
[09/26 05:04:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.6704
[09/26 05:04:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 97.50	
[09/26 05:04:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:04:14 visual_prompt]: Epoch 42 / 100: avg data time: 6.66e-02, avg batch time: 0.4796, average train loss: 0.0349
[09/26 05:04:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.6563
[09/26 05:04:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.50	
[09/26 05:04:15 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:04:22 visual_prompt]: Epoch 43 / 100: avg data time: 7.16e-02, avg batch time: 0.4843, average train loss: 0.0338
[09/26 05:04:24 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.6710
[09/26 05:04:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 97.00	
[09/26 05:04:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:04:30 visual_prompt]: Epoch 44 / 100: avg data time: 7.09e-02, avg batch time: 0.4844, average train loss: 0.0329
[09/26 05:04:32 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1583, average loss: 0.6644
[09/26 05:04:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 05:04:32 visual_prompt]: Best epoch 44: best metric: 0.855
[09/26 05:04:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:04:39 visual_prompt]: Epoch 45 / 100: avg data time: 6.35e-02, avg batch time: 0.4776, average train loss: 0.0330
[09/26 05:04:41 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.6646
[09/26 05:04:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:04:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:04:47 visual_prompt]: Epoch 46 / 100: avg data time: 6.47e-02, avg batch time: 0.4775, average train loss: 0.0324
[09/26 05:04:49 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 0.6734
[09/26 05:04:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.50	
[09/26 05:04:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:04:56 visual_prompt]: Epoch 47 / 100: avg data time: 6.96e-02, avg batch time: 0.4825, average train loss: 0.0327
[09/26 05:04:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.6616
[09/26 05:04:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.00	
[09/26 05:04:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:05:04 visual_prompt]: Epoch 48 / 100: avg data time: 6.47e-02, avg batch time: 0.4773, average train loss: 0.0321
[09/26 05:05:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 0.6613
[09/26 05:05:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 97.50	
[09/26 05:05:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:05:12 visual_prompt]: Epoch 49 / 100: avg data time: 5.80e-02, avg batch time: 0.4728, average train loss: 0.0319
[09/26 05:05:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.6564
[09/26 05:05:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.00	
[09/26 05:05:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:05:21 visual_prompt]: Epoch 50 / 100: avg data time: 6.71e-02, avg batch time: 0.4797, average train loss: 0.0327
[09/26 05:05:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1574, average loss: 0.6404
[09/26 05:05:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.00	
[09/26 05:05:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:05:29 visual_prompt]: Epoch 51 / 100: avg data time: 6.95e-02, avg batch time: 0.4832, average train loss: 0.0319
[09/26 05:05:31 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1584, average loss: 0.6539
[09/26 05:05:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 96.50	
[09/26 05:05:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:05:38 visual_prompt]: Epoch 52 / 100: avg data time: 7.12e-02, avg batch time: 0.4835, average train loss: 0.0319
[09/26 05:05:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1584, average loss: 0.6658
[09/26 05:05:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.00	
[09/26 05:05:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:05:46 visual_prompt]: Epoch 53 / 100: avg data time: 6.55e-02, avg batch time: 0.4779, average train loss: 0.0318
[09/26 05:05:48 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1577, average loss: 0.6655
[09/26 05:05:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.50	
[09/26 05:05:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:05:54 visual_prompt]: Epoch 54 / 100: avg data time: 6.61e-02, avg batch time: 0.4785, average train loss: 0.0320
[09/26 05:05:56 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1581, average loss: 0.6619
[09/26 05:05:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 96.50	
[09/26 05:05:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:06:03 visual_prompt]: Epoch 55 / 100: avg data time: 5.85e-02, avg batch time: 0.4728, average train loss: 0.0317
[09/26 05:06:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 0.6668
[09/26 05:06:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.00	
[09/26 05:06:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:06:11 visual_prompt]: Epoch 56 / 100: avg data time: 6.83e-02, avg batch time: 0.4810, average train loss: 0.0316
[09/26 05:06:13 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.6592
[09/26 05:06:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 96.50	
[09/26 05:06:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:06:19 visual_prompt]: Epoch 57 / 100: avg data time: 6.46e-02, avg batch time: 0.4777, average train loss: 0.0316
[09/26 05:06:21 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 0.6421
[09/26 05:06:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 98.00	
[09/26 05:06:21 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:06:28 visual_prompt]: Epoch 58 / 100: avg data time: 6.64e-02, avg batch time: 0.4790, average train loss: 0.0316
[09/26 05:06:29 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1578, average loss: 0.6473
[09/26 05:06:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.00	
[09/26 05:06:29 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:06:36 visual_prompt]: Epoch 59 / 100: avg data time: 5.87e-02, avg batch time: 0.4721, average train loss: 0.0314
[09/26 05:06:38 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1584, average loss: 0.6508
[09/26 05:06:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.50	
[09/26 05:06:38 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:06:44 visual_prompt]: Epoch 60 / 100: avg data time: 7.14e-02, avg batch time: 0.4839, average train loss: 0.0317
[09/26 05:06:46 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1579, average loss: 0.6500
[09/26 05:06:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:06:46 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:06:53 visual_prompt]: Epoch 61 / 100: avg data time: 7.32e-02, avg batch time: 0.4851, average train loss: 0.0317
[09/26 05:06:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 0.6498
[09/26 05:06:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 97.00	
[09/26 05:06:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:07:01 visual_prompt]: Epoch 62 / 100: avg data time: 6.99e-02, avg batch time: 0.4833, average train loss: 0.0317
[09/26 05:07:03 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.6578
[09/26 05:07:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:07:03 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:07:10 visual_prompt]: Epoch 63 / 100: avg data time: 7.14e-02, avg batch time: 0.4833, average train loss: 0.0312
[09/26 05:07:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.6561
[09/26 05:07:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.50	
[09/26 05:07:11 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:07:18 visual_prompt]: Epoch 64 / 100: avg data time: 6.41e-02, avg batch time: 0.4769, average train loss: 0.0318
[09/26 05:07:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1580, average loss: 0.6565
[09/26 05:07:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.50	
[09/26 05:07:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:07:26 visual_prompt]: Epoch 65 / 100: avg data time: 6.63e-02, avg batch time: 0.4785, average train loss: 0.0314
[09/26 05:07:28 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1578, average loss: 0.6572
[09/26 05:07:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 05:07:28 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:07:35 visual_prompt]: Epoch 66 / 100: avg data time: 6.89e-02, avg batch time: 0.4815, average train loss: 0.0312
[09/26 05:07:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1580, average loss: 0.6496
[09/26 05:07:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:07:36 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:07:43 visual_prompt]: Epoch 67 / 100: avg data time: 6.32e-02, avg batch time: 0.4755, average train loss: 0.0310
[09/26 05:07:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1584, average loss: 0.6484
[09/26 05:07:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.50	
[09/26 05:07:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:07:52 visual_prompt]: Epoch 68 / 100: avg data time: 7.12e-02, avg batch time: 0.4848, average train loss: 0.0310
[09/26 05:07:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1583, average loss: 0.6469
[09/26 05:07:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 05:07:53 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:08:00 visual_prompt]: Epoch 69 / 100: avg data time: 6.87e-02, avg batch time: 0.4819, average train loss: 0.0310
[09/26 05:08:02 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 0.6583
[09/26 05:08:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 96.50	
[09/26 05:08:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:08:08 visual_prompt]: Epoch 70 / 100: avg data time: 6.91e-02, avg batch time: 0.4812, average train loss: 0.0309
[09/26 05:08:10 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1574, average loss: 0.6575
[09/26 05:08:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 98.00	
[09/26 05:08:10 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:08:17 visual_prompt]: Epoch 71 / 100: avg data time: 6.74e-02, avg batch time: 0.4821, average train loss: 0.0309
[09/26 05:08:19 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1581, average loss: 0.6564
[09/26 05:08:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.00	
[09/26 05:08:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:08:25 visual_prompt]: Epoch 72 / 100: avg data time: 7.10e-02, avg batch time: 0.4833, average train loss: 0.0314
[09/26 05:08:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.6494
[09/26 05:08:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.00	
[09/26 05:08:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:08:34 visual_prompt]: Epoch 73 / 100: avg data time: 5.59e-02, avg batch time: 0.4695, average train loss: 0.0312
[09/26 05:08:35 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1580, average loss: 0.6453
[09/26 05:08:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:08:35 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:08:42 visual_prompt]: Epoch 74 / 100: avg data time: 6.53e-02, avg batch time: 0.4782, average train loss: 0.0312
[09/26 05:08:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1578, average loss: 0.6480
[09/26 05:08:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.00	
[09/26 05:08:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:08:50 visual_prompt]: Epoch 75 / 100: avg data time: 6.33e-02, avg batch time: 0.4762, average train loss: 0.0309
[09/26 05:08:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 0.6531
[09/26 05:08:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.50	
[09/26 05:08:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:08:59 visual_prompt]: Epoch 76 / 100: avg data time: 5.68e-02, avg batch time: 0.4706, average train loss: 0.0306
[09/26 05:09:00 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1583, average loss: 0.6487
[09/26 05:09:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.00	
[09/26 05:09:00 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:09:07 visual_prompt]: Epoch 77 / 100: avg data time: 5.20e-02, avg batch time: 0.4651, average train loss: 0.0302
[09/26 05:09:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1586, average loss: 0.6463
[09/26 05:09:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:09:08 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:09:15 visual_prompt]: Epoch 78 / 100: avg data time: 6.65e-02, avg batch time: 0.4791, average train loss: 0.0303
[09/26 05:09:17 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1574, average loss: 0.6454
[09/26 05:09:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:09:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:09:23 visual_prompt]: Epoch 79 / 100: avg data time: 6.25e-02, avg batch time: 0.4754, average train loss: 0.0304
[09/26 05:09:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1572, average loss: 0.6456
[09/26 05:09:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:09:25 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:09:32 visual_prompt]: Epoch 80 / 100: avg data time: 5.26e-02, avg batch time: 0.4664, average train loss: 0.0309
[09/26 05:09:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 0.6475
[09/26 05:09:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 05:09:33 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:09:40 visual_prompt]: Epoch 81 / 100: avg data time: 5.37e-02, avg batch time: 0.4671, average train loss: 0.0307
[09/26 05:09:42 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1584, average loss: 0.6490
[09/26 05:09:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.00	
[09/26 05:09:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:09:48 visual_prompt]: Epoch 82 / 100: avg data time: 7.40e-02, avg batch time: 0.4880, average train loss: 0.0304
[09/26 05:09:50 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1585, average loss: 0.6501
[09/26 05:09:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.50	
[09/26 05:09:50 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:09:57 visual_prompt]: Epoch 83 / 100: avg data time: 5.50e-02, avg batch time: 0.4697, average train loss: 0.0304
[09/26 05:09:58 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1582, average loss: 0.6489
[09/26 05:09:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:09:58 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:10:05 visual_prompt]: Epoch 84 / 100: avg data time: 6.48e-02, avg batch time: 0.4786, average train loss: 0.0305
[09/26 05:10:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.6488
[09/26 05:10:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:10:07 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:10:13 visual_prompt]: Epoch 85 / 100: avg data time: 6.57e-02, avg batch time: 0.4783, average train loss: 0.0306
[09/26 05:10:15 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1580, average loss: 0.6488
[09/26 05:10:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.50	
[09/26 05:10:15 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:10:22 visual_prompt]: Epoch 86 / 100: avg data time: 6.56e-02, avg batch time: 0.4787, average train loss: 0.0306
[09/26 05:10:23 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.6481
[09/26 05:10:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 97.50	
[09/26 05:10:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:10:30 visual_prompt]: Epoch 87 / 100: avg data time: 6.26e-02, avg batch time: 0.4752, average train loss: 0.0301
[09/26 05:10:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.6484
[09/26 05:10:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:10:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:10:39 visual_prompt]: Epoch 88 / 100: avg data time: 7.08e-02, avg batch time: 0.4843, average train loss: 0.0306
[09/26 05:10:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1586, average loss: 0.6507
[09/26 05:10:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 97.00	
[09/26 05:10:40 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:10:47 visual_prompt]: Epoch 89 / 100: avg data time: 6.88e-02, avg batch time: 0.4819, average train loss: 0.0301
[09/26 05:10:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1587, average loss: 0.6517
[09/26 05:10:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:10:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:10:55 visual_prompt]: Epoch 90 / 100: avg data time: 6.91e-02, avg batch time: 0.4823, average train loss: 0.0304
[09/26 05:10:57 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.6515
[09/26 05:10:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:10:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:11:04 visual_prompt]: Epoch 91 / 100: avg data time: 6.51e-02, avg batch time: 0.4788, average train loss: 0.0306
[09/26 05:11:05 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1581, average loss: 0.6504
[09/26 05:11:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:11:05 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:11:12 visual_prompt]: Epoch 92 / 100: avg data time: 7.08e-02, avg batch time: 0.4832, average train loss: 0.0305
[09/26 05:11:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 0.6495
[09/26 05:11:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:11:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:11:21 visual_prompt]: Epoch 93 / 100: avg data time: 6.50e-02, avg batch time: 0.4783, average train loss: 0.0305
[09/26 05:11:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1581, average loss: 0.6498
[09/26 05:11:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:11:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:11:29 visual_prompt]: Epoch 94 / 100: avg data time: 6.37e-02, avg batch time: 0.4768, average train loss: 0.0301
[09/26 05:11:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1580, average loss: 0.6500
[09/26 05:11:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:11:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:11:37 visual_prompt]: Epoch 95 / 100: avg data time: 5.92e-02, avg batch time: 0.4733, average train loss: 0.0302
[09/26 05:11:39 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1584, average loss: 0.6500
[09/26 05:11:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:11:39 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:11:46 visual_prompt]: Epoch 96 / 100: avg data time: 6.12e-02, avg batch time: 0.4738, average train loss: 0.0302
[09/26 05:11:47 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1581, average loss: 0.6502
[09/26 05:11:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:11:47 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:11:54 visual_prompt]: Epoch 97 / 100: avg data time: 7.13e-02, avg batch time: 0.4842, average train loss: 0.0301
[09/26 05:11:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1582, average loss: 0.6503
[09/26 05:11:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 97.50	
[09/26 05:11:56 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:12:02 visual_prompt]: Epoch 98 / 100: avg data time: 6.24e-02, avg batch time: 0.4760, average train loss: 0.0299
[09/26 05:12:04 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1580, average loss: 0.6503
[09/26 05:12:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:12:04 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:12:11 visual_prompt]: Epoch 99 / 100: avg data time: 6.58e-02, avg batch time: 0.4778, average train loss: 0.0305
[09/26 05:12:12 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1582, average loss: 0.6502
[09/26 05:12:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:12:12 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:12:19 visual_prompt]: Epoch 100 / 100: avg data time: 6.69e-02, avg batch time: 0.4797, average train loss: 0.0303
[09/26 05:12:21 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1580, average loss: 0.6502
[09/26 05:12:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 97.50	
[09/26 05:12:21 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:12:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:12:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:12:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:12:21 visual_prompt]: Training with config:
[09/26 05:12:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:12:21 visual_prompt]: Loading training data...
[09/26 05:12:21 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:12:22 visual_prompt]: Number of images: 800
[09/26 05:12:22 visual_prompt]: Number of classes: 102 / 102
[09/26 05:12:22 visual_prompt]: Loading validation data...
[09/26 05:12:22 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:12:22 visual_prompt]: Number of images: 200
[09/26 05:12:22 visual_prompt]: Number of classes: 91 / 102
[09/26 05:12:22 visual_prompt]: Constructing models...
[09/26 05:12:25 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 05:12:25 visual_prompt]: tuned percent:0.625
[09/26 05:12:25 visual_prompt]: Device used for model: 0
[09/26 05:12:25 visual_prompt]: Setting up Evaluator...
[09/26 05:12:25 visual_prompt]: Setting up Trainer...
[09/26 05:12:25 visual_prompt]: 	Setting up the optimizer...
[09/26 05:12:25 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:12:32 visual_prompt]: Epoch 1 / 100: avg data time: 6.33e-02, avg batch time: 0.4814, average train loss: 4.6750
[09/26 05:12:33 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 05:12:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 05:12:33 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:12:33 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:12:40 visual_prompt]: Epoch 2 / 100: avg data time: 6.57e-02, avg batch time: 0.4775, average train loss: 4.6513
[09/26 05:12:42 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1577, average loss: 4.6407
[09/26 05:12:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 05:12:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:12:48 visual_prompt]: Epoch 3 / 100: avg data time: 6.39e-02, avg batch time: 0.4770, average train loss: 4.5853
[09/26 05:12:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1584, average loss: 4.5817
[09/26 05:12:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 11.50	
[09/26 05:12:50 visual_prompt]: Best epoch 3: best metric: 0.025
[09/26 05:12:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 05:12:57 visual_prompt]: Epoch 4 / 100: avg data time: 6.06e-02, avg batch time: 0.4747, average train loss: 4.4540
[09/26 05:12:58 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1580, average loss: 4.4330
[09/26 05:12:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 14.50	
[09/26 05:12:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:13:05 visual_prompt]: Epoch 5 / 100: avg data time: 6.06e-02, avg batch time: 0.4729, average train loss: 4.1516
[09/26 05:13:07 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 4.0413
[09/26 05:13:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.00	top5: 30.50	
[09/26 05:13:07 visual_prompt]: Best epoch 5: best metric: 0.120
[09/26 05:13:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 05:13:13 visual_prompt]: Epoch 6 / 100: avg data time: 6.09e-02, avg batch time: 0.4737, average train loss: 3.6004
[09/26 05:13:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1576, average loss: 3.4956
[09/26 05:13:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 17.50	top5: 46.00	
[09/26 05:13:15 visual_prompt]: Best epoch 6: best metric: 0.175
[09/26 05:13:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 05:13:22 visual_prompt]: Epoch 7 / 100: avg data time: 6.51e-02, avg batch time: 0.4778, average train loss: 2.9854
[09/26 05:13:23 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1583, average loss: 2.8184
[09/26 05:13:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 35.50	top5: 62.50	
[09/26 05:13:23 visual_prompt]: Best epoch 7: best metric: 0.355
[09/26 05:13:23 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 05:13:30 visual_prompt]: Epoch 8 / 100: avg data time: 6.53e-02, avg batch time: 0.4783, average train loss: 2.2943
[09/26 05:13:32 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1582, average loss: 2.3445
[09/26 05:13:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 47.00	top5: 77.50	
[09/26 05:13:32 visual_prompt]: Best epoch 8: best metric: 0.470
[09/26 05:13:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 05:13:38 visual_prompt]: Epoch 9 / 100: avg data time: 6.43e-02, avg batch time: 0.4773, average train loss: 1.6240
[09/26 05:13:40 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1583, average loss: 1.8180
[09/26 05:13:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 61.50	top5: 84.50	
[09/26 05:13:40 visual_prompt]: Best epoch 9: best metric: 0.615
[09/26 05:13:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 05:13:47 visual_prompt]: Epoch 10 / 100: avg data time: 7.17e-02, avg batch time: 0.4851, average train loss: 1.0476
[09/26 05:13:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1580, average loss: 1.4433
[09/26 05:13:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 87.00	
[09/26 05:13:49 visual_prompt]: Best epoch 10: best metric: 0.680
[09/26 05:13:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 05:13:55 visual_prompt]: Epoch 11 / 100: avg data time: 5.24e-02, avg batch time: 0.4661, average train loss: 0.6969
[09/26 05:13:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 1.2146
[09/26 05:13:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.50	top5: 92.00	
[09/26 05:13:57 visual_prompt]: Best epoch 11: best metric: 0.725
[09/26 05:13:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:14:04 visual_prompt]: Epoch 12 / 100: avg data time: 6.66e-02, avg batch time: 0.4799, average train loss: 0.4371
[09/26 05:14:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 1.0781
[09/26 05:14:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 94.00	
[09/26 05:14:05 visual_prompt]: Best epoch 12: best metric: 0.745
[09/26 05:14:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:14:12 visual_prompt]: Epoch 13 / 100: avg data time: 7.32e-02, avg batch time: 0.4868, average train loss: 0.2842
[09/26 05:14:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1589, average loss: 0.9188
[09/26 05:14:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 93.50	
[09/26 05:14:14 visual_prompt]: Best epoch 13: best metric: 0.785
[09/26 05:14:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:14:20 visual_prompt]: Epoch 14 / 100: avg data time: 6.40e-02, avg batch time: 0.4780, average train loss: 0.1814
[09/26 05:14:22 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1585, average loss: 0.8559
[09/26 05:14:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 94.00	
[09/26 05:14:22 visual_prompt]: Best epoch 14: best metric: 0.800
[09/26 05:14:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:14:29 visual_prompt]: Epoch 15 / 100: avg data time: 7.19e-02, avg batch time: 0.4867, average train loss: 0.1213
[09/26 05:14:31 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1586, average loss: 0.7730
[09/26 05:14:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 96.00	
[09/26 05:14:31 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:14:37 visual_prompt]: Epoch 16 / 100: avg data time: 6.56e-02, avg batch time: 0.4803, average train loss: 0.0918
[09/26 05:14:39 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1585, average loss: 0.7554
[09/26 05:14:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 96.00	
[09/26 05:14:39 visual_prompt]: Best epoch 16: best metric: 0.805
[09/26 05:14:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:14:46 visual_prompt]: Epoch 17 / 100: avg data time: 6.90e-02, avg batch time: 0.4829, average train loss: 0.0783
[09/26 05:14:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.7371
[09/26 05:14:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/26 05:14:47 visual_prompt]: Best epoch 17: best metric: 0.820
[09/26 05:14:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:14:54 visual_prompt]: Epoch 18 / 100: avg data time: 7.17e-02, avg batch time: 0.4878, average train loss: 0.0643
[09/26 05:14:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1584, average loss: 0.7111
[09/26 05:14:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 96.00	
[09/26 05:14:56 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:15:03 visual_prompt]: Epoch 19 / 100: avg data time: 6.86e-02, avg batch time: 0.4824, average train loss: 0.0490
[09/26 05:15:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1586, average loss: 0.6980
[09/26 05:15:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/26 05:15:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:15:11 visual_prompt]: Epoch 20 / 100: avg data time: 6.35e-02, avg batch time: 0.4779, average train loss: 0.0428
[09/26 05:15:13 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1589, average loss: 0.6812
[09/26 05:15:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 96.00	
[09/26 05:15:13 visual_prompt]: Best epoch 20: best metric: 0.825
[09/26 05:15:13 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:15:19 visual_prompt]: Epoch 21 / 100: avg data time: 6.65e-02, avg batch time: 0.4807, average train loss: 0.0368
[09/26 05:15:21 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1587, average loss: 0.6612
[09/26 05:15:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 96.50	
[09/26 05:15:21 visual_prompt]: Best epoch 21: best metric: 0.835
[09/26 05:15:21 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:15:28 visual_prompt]: Epoch 22 / 100: avg data time: 6.61e-02, avg batch time: 0.4809, average train loss: 0.0329
[09/26 05:15:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 0.6475
[09/26 05:15:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 05:15:29 visual_prompt]: Best epoch 22: best metric: 0.850
[09/26 05:15:29 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:15:36 visual_prompt]: Epoch 23 / 100: avg data time: 6.72e-02, avg batch time: 0.4812, average train loss: 0.0298
[09/26 05:15:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1585, average loss: 0.6593
[09/26 05:15:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 96.00	
[09/26 05:15:38 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:15:45 visual_prompt]: Epoch 24 / 100: avg data time: 7.09e-02, avg batch time: 0.4863, average train loss: 0.0285
[09/26 05:15:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1588, average loss: 0.6613
[09/26 05:15:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 05:15:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:15:53 visual_prompt]: Epoch 25 / 100: avg data time: 6.67e-02, avg batch time: 0.4815, average train loss: 0.0264
[09/26 05:15:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.6475
[09/26 05:15:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 96.00	
[09/26 05:15:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:16:01 visual_prompt]: Epoch 26 / 100: avg data time: 6.82e-02, avg batch time: 0.4821, average train loss: 0.0237
[09/26 05:16:03 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1588, average loss: 0.6391
[09/26 05:16:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 05:16:03 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:16:10 visual_prompt]: Epoch 27 / 100: avg data time: 6.99e-02, avg batch time: 0.4838, average train loss: 0.0226
[09/26 05:16:11 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1585, average loss: 0.6365
[09/26 05:16:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 05:16:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:16:18 visual_prompt]: Epoch 28 / 100: avg data time: 6.31e-02, avg batch time: 0.4779, average train loss: 0.0220
[09/26 05:16:20 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1586, average loss: 0.6362
[09/26 05:16:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 05:16:20 visual_prompt]: Best epoch 28: best metric: 0.855
[09/26 05:16:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:16:26 visual_prompt]: Epoch 29 / 100: avg data time: 5.53e-02, avg batch time: 0.4709, average train loss: 0.0206
[09/26 05:16:28 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1587, average loss: 0.6316
[09/26 05:16:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 05:16:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:16:35 visual_prompt]: Epoch 30 / 100: avg data time: 7.20e-02, avg batch time: 0.4855, average train loss: 0.0198
[09/26 05:16:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1583, average loss: 0.6267
[09/26 05:16:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 05:16:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:16:43 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e-02, avg batch time: 0.4727, average train loss: 0.0190
[09/26 05:16:45 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1585, average loss: 0.6255
[09/26 05:16:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:16:45 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:16:51 visual_prompt]: Epoch 32 / 100: avg data time: 6.70e-02, avg batch time: 0.4822, average train loss: 0.0178
[09/26 05:16:53 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1590, average loss: 0.6183
[09/26 05:16:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.50	
[09/26 05:16:53 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:17:00 visual_prompt]: Epoch 33 / 100: avg data time: 6.92e-02, avg batch time: 0.4834, average train loss: 0.0168
[09/26 05:17:02 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1580, average loss: 0.6145
[09/26 05:17:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.50	
[09/26 05:17:02 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:17:08 visual_prompt]: Epoch 34 / 100: avg data time: 6.36e-02, avg batch time: 0.4773, average train loss: 0.0168
[09/26 05:17:10 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1579, average loss: 0.6136
[09/26 05:17:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:17:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:17:17 visual_prompt]: Epoch 35 / 100: avg data time: 6.89e-02, avg batch time: 0.4820, average train loss: 0.0158
[09/26 05:17:18 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1584, average loss: 0.6100
[09/26 05:17:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 05:17:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:17:25 visual_prompt]: Epoch 36 / 100: avg data time: 6.56e-02, avg batch time: 0.4784, average train loss: 0.0154
[09/26 05:17:27 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.6077
[09/26 05:17:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:17:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:17:33 visual_prompt]: Epoch 37 / 100: avg data time: 6.49e-02, avg batch time: 0.4804, average train loss: 0.0151
[09/26 05:17:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.6075
[09/26 05:17:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:17:35 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:17:42 visual_prompt]: Epoch 38 / 100: avg data time: 6.58e-02, avg batch time: 0.4781, average train loss: 0.0148
[09/26 05:17:44 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1583, average loss: 0.6075
[09/26 05:17:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:17:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:17:50 visual_prompt]: Epoch 39 / 100: avg data time: 7.12e-02, avg batch time: 0.4853, average train loss: 0.0136
[09/26 05:17:52 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1583, average loss: 0.6051
[09/26 05:17:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.50	
[09/26 05:17:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:17:59 visual_prompt]: Epoch 40 / 100: avg data time: 7.44e-02, avg batch time: 0.4881, average train loss: 0.0133
[09/26 05:18:00 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1581, average loss: 0.6049
[09/26 05:18:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 05:18:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:18:07 visual_prompt]: Epoch 41 / 100: avg data time: 6.34e-02, avg batch time: 0.4756, average train loss: 0.0131
[09/26 05:18:09 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.6039
[09/26 05:18:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 05:18:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:18:15 visual_prompt]: Epoch 42 / 100: avg data time: 4.83e-02, avg batch time: 0.4644, average train loss: 0.0128
[09/26 05:18:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 0.6051
[09/26 05:18:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 96.00	
[09/26 05:18:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:18:24 visual_prompt]: Epoch 43 / 100: avg data time: 6.96e-02, avg batch time: 0.4819, average train loss: 0.0128
[09/26 05:18:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1578, average loss: 0.6064
[09/26 05:18:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 96.00	
[09/26 05:18:25 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:18:32 visual_prompt]: Epoch 44 / 100: avg data time: 7.28e-02, avg batch time: 0.4848, average train loss: 0.0123
[09/26 05:18:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1578, average loss: 0.6036
[09/26 05:18:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:18:34 visual_prompt]: Best epoch 44: best metric: 0.860
[09/26 05:18:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:18:41 visual_prompt]: Epoch 45 / 100: avg data time: 6.99e-02, avg batch time: 0.4827, average train loss: 0.0125
[09/26 05:18:42 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1583, average loss: 0.6035
[09/26 05:18:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:18:42 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:18:49 visual_prompt]: Epoch 46 / 100: avg data time: 6.04e-02, avg batch time: 0.4741, average train loss: 0.0119
[09/26 05:18:51 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1578, average loss: 0.5997
[09/26 05:18:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:18:51 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:18:57 visual_prompt]: Epoch 47 / 100: avg data time: 6.31e-02, avg batch time: 0.4757, average train loss: 0.0119
[09/26 05:18:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.5926
[09/26 05:18:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:18:59 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:19:05 visual_prompt]: Epoch 48 / 100: avg data time: 6.06e-02, avg batch time: 0.4742, average train loss: 0.0116
[09/26 05:19:07 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 0.5920
[09/26 05:19:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:19:07 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:19:14 visual_prompt]: Epoch 49 / 100: avg data time: 6.35e-02, avg batch time: 0.4773, average train loss: 0.0114
[09/26 05:19:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1584, average loss: 0.5883
[09/26 05:19:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:19:16 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:19:22 visual_prompt]: Epoch 50 / 100: avg data time: 6.82e-02, avg batch time: 0.4826, average train loss: 0.0115
[09/26 05:19:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.5897
[09/26 05:19:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:19:24 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:19:31 visual_prompt]: Epoch 51 / 100: avg data time: 7.00e-02, avg batch time: 0.4830, average train loss: 0.0114
[09/26 05:19:32 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1583, average loss: 0.5923
[09/26 05:19:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:19:32 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:19:39 visual_prompt]: Epoch 52 / 100: avg data time: 6.48e-02, avg batch time: 0.4785, average train loss: 0.0110
[09/26 05:19:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1580, average loss: 0.5951
[09/26 05:19:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:19:41 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:19:47 visual_prompt]: Epoch 53 / 100: avg data time: 7.03e-02, avg batch time: 0.4825, average train loss: 0.0106
[09/26 05:19:49 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1582, average loss: 0.5934
[09/26 05:19:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:19:49 visual_prompt]: Best epoch 53: best metric: 0.865
[09/26 05:19:49 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:19:56 visual_prompt]: Epoch 54 / 100: avg data time: 6.15e-02, avg batch time: 0.4753, average train loss: 0.0106
[09/26 05:19:57 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1578, average loss: 0.5886
[09/26 05:19:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:19:57 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:20:04 visual_prompt]: Epoch 55 / 100: avg data time: 6.39e-02, avg batch time: 0.4766, average train loss: 0.0103
[09/26 05:20:06 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1583, average loss: 0.5872
[09/26 05:20:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:20:06 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:20:12 visual_prompt]: Epoch 56 / 100: avg data time: 6.93e-02, avg batch time: 0.4824, average train loss: 0.0102
[09/26 05:20:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1585, average loss: 0.5863
[09/26 05:20:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:20:14 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:20:21 visual_prompt]: Epoch 57 / 100: avg data time: 6.96e-02, avg batch time: 0.4819, average train loss: 0.0103
[09/26 05:20:23 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 0.5837
[09/26 05:20:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.50	
[09/26 05:20:23 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:20:29 visual_prompt]: Epoch 58 / 100: avg data time: 5.81e-02, avg batch time: 0.4714, average train loss: 0.0104
[09/26 05:20:31 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 0.5849
[09/26 05:20:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:20:31 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:20:37 visual_prompt]: Epoch 59 / 100: avg data time: 6.80e-02, avg batch time: 0.4809, average train loss: 0.0101
[09/26 05:20:39 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1579, average loss: 0.5835
[09/26 05:20:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:20:39 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:20:46 visual_prompt]: Epoch 60 / 100: avg data time: 6.58e-02, avg batch time: 0.4788, average train loss: 0.0102
[09/26 05:20:48 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 0.5825
[09/26 05:20:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:20:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:20:54 visual_prompt]: Epoch 61 / 100: avg data time: 6.31e-02, avg batch time: 0.4756, average train loss: 0.0099
[09/26 05:20:56 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 0.5808
[09/26 05:20:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:20:56 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:21:03 visual_prompt]: Epoch 62 / 100: avg data time: 7.22e-02, avg batch time: 0.4866, average train loss: 0.0098
[09/26 05:21:04 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1580, average loss: 0.5835
[09/26 05:21:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:21:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:21:11 visual_prompt]: Epoch 63 / 100: avg data time: 6.35e-02, avg batch time: 0.4757, average train loss: 0.0099
[09/26 05:21:13 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 0.5820
[09/26 05:21:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:21:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:21:19 visual_prompt]: Epoch 64 / 100: avg data time: 6.71e-02, avg batch time: 0.4800, average train loss: 0.0096
[09/26 05:21:21 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1580, average loss: 0.5811
[09/26 05:21:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 05:21:21 visual_prompt]: Best epoch 64: best metric: 0.870
[09/26 05:21:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:21:28 visual_prompt]: Epoch 65 / 100: avg data time: 6.43e-02, avg batch time: 0.4768, average train loss: 0.0097
[09/26 05:21:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1580, average loss: 0.5797
[09/26 05:21:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:21:29 visual_prompt]: Best epoch 65: best metric: 0.875
[09/26 05:21:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:21:36 visual_prompt]: Epoch 66 / 100: avg data time: 5.74e-02, avg batch time: 0.4712, average train loss: 0.0097
[09/26 05:21:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1579, average loss: 0.5798
[09/26 05:21:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 96.00	
[09/26 05:21:38 visual_prompt]: Best epoch 66: best metric: 0.880
[09/26 05:21:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:21:44 visual_prompt]: Epoch 67 / 100: avg data time: 6.40e-02, avg batch time: 0.4772, average train loss: 0.0094
[09/26 05:21:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1578, average loss: 0.5798
[09/26 05:21:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:21:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:21:53 visual_prompt]: Epoch 68 / 100: avg data time: 6.63e-02, avg batch time: 0.4786, average train loss: 0.0093
[09/26 05:21:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1581, average loss: 0.5803
[09/26 05:21:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 05:21:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:22:01 visual_prompt]: Epoch 69 / 100: avg data time: 7.58e-02, avg batch time: 0.4882, average train loss: 0.0093
[09/26 05:22:03 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1581, average loss: 0.5809
[09/26 05:22:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 96.00	
[09/26 05:22:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:22:09 visual_prompt]: Epoch 70 / 100: avg data time: 6.53e-02, avg batch time: 0.4788, average train loss: 0.0092
[09/26 05:22:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1581, average loss: 0.5809
[09/26 05:22:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:22:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:22:18 visual_prompt]: Epoch 71 / 100: avg data time: 5.90e-02, avg batch time: 0.4720, average train loss: 0.0092
[09/26 05:22:20 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1581, average loss: 0.5790
[09/26 05:22:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:22:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:22:26 visual_prompt]: Epoch 72 / 100: avg data time: 6.67e-02, avg batch time: 0.4793, average train loss: 0.0092
[09/26 05:22:28 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 0.5776
[09/26 05:22:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:22:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:22:35 visual_prompt]: Epoch 73 / 100: avg data time: 6.56e-02, avg batch time: 0.4803, average train loss: 0.0093
[09/26 05:22:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1579, average loss: 0.5773
[09/26 05:22:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:22:36 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:22:43 visual_prompt]: Epoch 74 / 100: avg data time: 6.75e-02, avg batch time: 0.4796, average train loss: 0.0091
[09/26 05:22:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.5776
[09/26 05:22:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:22:45 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:22:51 visual_prompt]: Epoch 75 / 100: avg data time: 6.65e-02, avg batch time: 0.4789, average train loss: 0.0093
[09/26 05:22:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1578, average loss: 0.5780
[09/26 05:22:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 05:22:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:23:00 visual_prompt]: Epoch 76 / 100: avg data time: 6.03e-02, avg batch time: 0.4734, average train loss: 0.0092
[09/26 05:23:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1577, average loss: 0.5792
[09/26 05:23:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 05:23:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:23:08 visual_prompt]: Epoch 77 / 100: avg data time: 7.03e-02, avg batch time: 0.4824, average train loss: 0.0091
[09/26 05:23:10 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 0.5793
[09/26 05:23:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 05:23:10 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:23:16 visual_prompt]: Epoch 78 / 100: avg data time: 6.39e-02, avg batch time: 0.4775, average train loss: 0.0091
[09/26 05:23:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 0.5796
[09/26 05:23:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 96.00	
[09/26 05:23:18 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:23:25 visual_prompt]: Epoch 79 / 100: avg data time: 6.62e-02, avg batch time: 0.4793, average train loss: 0.0089
[09/26 05:23:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1581, average loss: 0.5792
[09/26 05:23:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:23:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:23:33 visual_prompt]: Epoch 80 / 100: avg data time: 5.18e-02, avg batch time: 0.4655, average train loss: 0.0088
[09/26 05:23:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.5788
[09/26 05:23:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:23:35 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:23:41 visual_prompt]: Epoch 81 / 100: avg data time: 5.52e-02, avg batch time: 0.4695, average train loss: 0.0090
[09/26 05:23:43 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1576, average loss: 0.5778
[09/26 05:23:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:23:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:23:50 visual_prompt]: Epoch 82 / 100: avg data time: 6.67e-02, avg batch time: 0.4801, average train loss: 0.0091
[09/26 05:23:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1578, average loss: 0.5772
[09/26 05:23:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 05:23:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:23:58 visual_prompt]: Epoch 83 / 100: avg data time: 6.13e-02, avg batch time: 0.4747, average train loss: 0.0089
[09/26 05:24:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 0.5769
[09/26 05:24:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 05:24:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:24:06 visual_prompt]: Epoch 84 / 100: avg data time: 6.52e-02, avg batch time: 0.4777, average train loss: 0.0088
[09/26 05:24:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1578, average loss: 0.5770
[09/26 05:24:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 05:24:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:24:15 visual_prompt]: Epoch 85 / 100: avg data time: 7.46e-02, avg batch time: 0.4870, average train loss: 0.0088
[09/26 05:24:17 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1576, average loss: 0.5774
[09/26 05:24:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:24:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:24:23 visual_prompt]: Epoch 86 / 100: avg data time: 6.94e-02, avg batch time: 0.4816, average train loss: 0.0090
[09/26 05:24:25 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1581, average loss: 0.5775
[09/26 05:24:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:24:25 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:24:31 visual_prompt]: Epoch 87 / 100: avg data time: 5.88e-02, avg batch time: 0.4727, average train loss: 0.0087
[09/26 05:24:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.5776
[09/26 05:24:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:24:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:24:40 visual_prompt]: Epoch 88 / 100: avg data time: 6.50e-02, avg batch time: 0.4780, average train loss: 0.0089
[09/26 05:24:41 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1578, average loss: 0.5773
[09/26 05:24:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:24:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:24:48 visual_prompt]: Epoch 89 / 100: avg data time: 5.96e-02, avg batch time: 0.4746, average train loss: 0.0085
[09/26 05:24:50 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1579, average loss: 0.5771
[09/26 05:24:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:24:50 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:24:56 visual_prompt]: Epoch 90 / 100: avg data time: 6.81e-02, avg batch time: 0.4808, average train loss: 0.0090
[09/26 05:24:58 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.5771
[09/26 05:24:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:24:58 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:25:05 visual_prompt]: Epoch 91 / 100: avg data time: 6.19e-02, avg batch time: 0.4745, average train loss: 0.0091
[09/26 05:25:06 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1581, average loss: 0.5772
[09/26 05:25:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:25:13 visual_prompt]: Epoch 92 / 100: avg data time: 6.27e-02, avg batch time: 0.4753, average train loss: 0.0089
[09/26 05:25:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1580, average loss: 0.5771
[09/26 05:25:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:25:21 visual_prompt]: Epoch 93 / 100: avg data time: 6.65e-02, avg batch time: 0.4789, average train loss: 0.0088
[09/26 05:25:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 0.5770
[09/26 05:25:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:23 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:25:30 visual_prompt]: Epoch 94 / 100: avg data time: 7.20e-02, avg batch time: 0.4839, average train loss: 0.0088
[09/26 05:25:32 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1570, average loss: 0.5769
[09/26 05:25:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:25:38 visual_prompt]: Epoch 95 / 100: avg data time: 6.57e-02, avg batch time: 0.4788, average train loss: 0.0087
[09/26 05:25:40 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1582, average loss: 0.5769
[09/26 05:25:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:40 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:25:47 visual_prompt]: Epoch 96 / 100: avg data time: 6.52e-02, avg batch time: 0.4792, average train loss: 0.0089
[09/26 05:25:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1582, average loss: 0.5769
[09/26 05:25:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:25:55 visual_prompt]: Epoch 97 / 100: avg data time: 6.56e-02, avg batch time: 0.4786, average train loss: 0.0087
[09/26 05:25:57 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1579, average loss: 0.5769
[09/26 05:25:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:25:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:26:03 visual_prompt]: Epoch 98 / 100: avg data time: 6.12e-02, avg batch time: 0.4756, average train loss: 0.0088
[09/26 05:26:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.5769
[09/26 05:26:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:26:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:26:12 visual_prompt]: Epoch 99 / 100: avg data time: 6.60e-02, avg batch time: 0.4790, average train loss: 0.0086
[09/26 05:26:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1579, average loss: 0.5769
[09/26 05:26:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:26:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:26:20 visual_prompt]: Epoch 100 / 100: avg data time: 6.56e-02, avg batch time: 0.4784, average train loss: 0.0089
[09/26 05:26:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1579, average loss: 0.5769
[09/26 05:26:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.00	
[09/26 05:26:22 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:26:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:26:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:26:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:26:22 visual_prompt]: Training with config:
[09/26 05:26:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:26:22 visual_prompt]: Loading training data...
[09/26 05:26:22 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:26:23 visual_prompt]: Number of images: 800
[09/26 05:26:23 visual_prompt]: Number of classes: 102 / 102
[09/26 05:26:23 visual_prompt]: Loading validation data...
[09/26 05:26:23 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:26:23 visual_prompt]: Number of images: 200
[09/26 05:26:23 visual_prompt]: Number of classes: 91 / 102
[09/26 05:26:23 visual_prompt]: Constructing models...
[09/26 05:26:26 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 05:26:26 visual_prompt]: tuned percent:0.625
[09/26 05:26:26 visual_prompt]: Device used for model: 0
[09/26 05:26:26 visual_prompt]: Setting up Evaluator...
[09/26 05:26:26 visual_prompt]: Setting up Trainer...
[09/26 05:26:26 visual_prompt]: 	Setting up the optimizer...
[09/26 05:26:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:26:32 visual_prompt]: Epoch 1 / 100: avg data time: 6.92e-02, avg batch time: 0.4864, average train loss: 4.6695
[09/26 05:26:34 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1584, average loss: 4.6780
[09/26 05:26:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 05:26:34 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:26:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:26:41 visual_prompt]: Epoch 2 / 100: avg data time: 6.61e-02, avg batch time: 0.4781, average train loss: 4.6566
[09/26 05:26:42 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1584, average loss: 4.6409
[09/26 05:26:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 7.00	
[09/26 05:26:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:26:49 visual_prompt]: Epoch 3 / 100: avg data time: 6.61e-02, avg batch time: 0.4779, average train loss: 4.6016
[09/26 05:26:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1584, average loss: 4.5978
[09/26 05:26:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.50	
[09/26 05:26:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 05:26:58 visual_prompt]: Epoch 4 / 100: avg data time: 7.42e-02, avg batch time: 0.4881, average train loss: 4.4980
[09/26 05:26:59 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1583, average loss: 4.4960
[09/26 05:26:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 10.00	
[09/26 05:26:59 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 05:26:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:27:06 visual_prompt]: Epoch 5 / 100: avg data time: 6.96e-02, avg batch time: 0.4832, average train loss: 4.2697
[09/26 05:27:08 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1581, average loss: 4.1767
[09/26 05:27:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 11.50	top5: 26.50	
[09/26 05:27:08 visual_prompt]: Best epoch 5: best metric: 0.115
[09/26 05:27:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 05:27:15 visual_prompt]: Epoch 6 / 100: avg data time: 6.67e-02, avg batch time: 0.4795, average train loss: 3.8234
[09/26 05:27:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 3.6145
[09/26 05:27:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 19.50	top5: 38.50	
[09/26 05:27:16 visual_prompt]: Best epoch 6: best metric: 0.195
[09/26 05:27:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 05:27:23 visual_prompt]: Epoch 7 / 100: avg data time: 6.74e-02, avg batch time: 0.4816, average train loss: 3.1511
[09/26 05:27:25 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1580, average loss: 3.0427
[09/26 05:27:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 30.00	top5: 60.00	
[09/26 05:27:25 visual_prompt]: Best epoch 7: best metric: 0.300
[09/26 05:27:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 05:27:31 visual_prompt]: Epoch 8 / 100: avg data time: 6.70e-02, avg batch time: 0.4791, average train loss: 2.4392
[09/26 05:27:33 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1579, average loss: 2.3948
[09/26 05:27:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 50.00	top5: 73.00	
[09/26 05:27:33 visual_prompt]: Best epoch 8: best metric: 0.500
[09/26 05:27:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 05:27:40 visual_prompt]: Epoch 9 / 100: avg data time: 6.38e-02, avg batch time: 0.4768, average train loss: 1.7922
[09/26 05:27:42 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1581, average loss: 1.8813
[09/26 05:27:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 55.00	top5: 83.50	
[09/26 05:27:42 visual_prompt]: Best epoch 9: best metric: 0.550
[09/26 05:27:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 05:27:48 visual_prompt]: Epoch 10 / 100: avg data time: 6.14e-02, avg batch time: 0.4746, average train loss: 1.2370
[09/26 05:27:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1580, average loss: 1.4593
[09/26 05:27:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 69.00	top5: 89.50	
[09/26 05:27:50 visual_prompt]: Best epoch 10: best metric: 0.690
[09/26 05:27:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 05:27:56 visual_prompt]: Epoch 11 / 100: avg data time: 6.00e-02, avg batch time: 0.4745, average train loss: 0.7752
[09/26 05:27:58 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1575, average loss: 1.1818
[09/26 05:27:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 90.50	
[09/26 05:27:58 visual_prompt]: Best epoch 11: best metric: 0.775
[09/26 05:27:58 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:28:05 visual_prompt]: Epoch 12 / 100: avg data time: 6.20e-02, avg batch time: 0.4764, average train loss: 0.4590
[09/26 05:28:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 1.0095
[09/26 05:28:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 93.00	
[09/26 05:28:07 visual_prompt]: Best epoch 12: best metric: 0.785
[09/26 05:28:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:28:13 visual_prompt]: Epoch 13 / 100: avg data time: 6.21e-02, avg batch time: 0.4751, average train loss: 0.2846
[09/26 05:28:15 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 0.8938
[09/26 05:28:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 93.50	
[09/26 05:28:15 visual_prompt]: Best epoch 13: best metric: 0.810
[09/26 05:28:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:28:22 visual_prompt]: Epoch 14 / 100: avg data time: 6.35e-02, avg batch time: 0.4773, average train loss: 0.1935
[09/26 05:28:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1580, average loss: 0.8136
[09/26 05:28:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 96.50	
[09/26 05:28:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:28:30 visual_prompt]: Epoch 15 / 100: avg data time: 6.45e-02, avg batch time: 0.4789, average train loss: 0.1315
[09/26 05:28:32 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1582, average loss: 0.7177
[09/26 05:28:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.00	
[09/26 05:28:32 visual_prompt]: Best epoch 15: best metric: 0.860
[09/26 05:28:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:28:38 visual_prompt]: Epoch 16 / 100: avg data time: 6.62e-02, avg batch time: 0.4794, average train loss: 0.1027
[09/26 05:28:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.7744
[09/26 05:28:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.00	
[09/26 05:28:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:28:47 visual_prompt]: Epoch 17 / 100: avg data time: 5.64e-02, avg batch time: 0.4710, average train loss: 0.0749
[09/26 05:28:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1585, average loss: 0.7233
[09/26 05:28:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 94.50	
[09/26 05:28:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:28:55 visual_prompt]: Epoch 18 / 100: avg data time: 5.77e-02, avg batch time: 0.4714, average train loss: 0.0587
[09/26 05:28:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.6994
[09/26 05:28:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.50	
[09/26 05:28:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:29:03 visual_prompt]: Epoch 19 / 100: avg data time: 6.59e-02, avg batch time: 0.4800, average train loss: 0.0458
[09/26 05:29:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1578, average loss: 0.6552
[09/26 05:29:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.00	
[09/26 05:29:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:29:12 visual_prompt]: Epoch 20 / 100: avg data time: 5.92e-02, avg batch time: 0.4737, average train loss: 0.0389
[09/26 05:29:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1582, average loss: 0.6867
[09/26 05:29:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 95.50	
[09/26 05:29:13 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:29:20 visual_prompt]: Epoch 21 / 100: avg data time: 6.01e-02, avg batch time: 0.4746, average train loss: 0.0349
[09/26 05:29:22 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1585, average loss: 0.6586
[09/26 05:29:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.50	
[09/26 05:29:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:29:28 visual_prompt]: Epoch 22 / 100: avg data time: 6.47e-02, avg batch time: 0.4776, average train loss: 0.0315
[09/26 05:29:30 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1584, average loss: 0.6767
[09/26 05:29:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.50	
[09/26 05:29:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:29:36 visual_prompt]: Epoch 23 / 100: avg data time: 5.64e-02, avg batch time: 0.4709, average train loss: 0.0279
[09/26 05:29:38 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1585, average loss: 0.6594
[09/26 05:29:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.50	
[09/26 05:29:38 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:29:45 visual_prompt]: Epoch 24 / 100: avg data time: 6.79e-02, avg batch time: 0.4809, average train loss: 0.0255
[09/26 05:29:47 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1585, average loss: 0.6578
[09/26 05:29:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.50	
[09/26 05:29:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:29:53 visual_prompt]: Epoch 25 / 100: avg data time: 6.87e-02, avg batch time: 0.4824, average train loss: 0.0241
[09/26 05:29:55 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1586, average loss: 0.6387
[09/26 05:29:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 95.00	
[09/26 05:29:55 visual_prompt]: Best epoch 25: best metric: 0.865
[09/26 05:29:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:30:02 visual_prompt]: Epoch 26 / 100: avg data time: 6.38e-02, avg batch time: 0.4766, average train loss: 0.0225
[09/26 05:30:03 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.6446
[09/26 05:30:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:30:03 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:30:10 visual_prompt]: Epoch 27 / 100: avg data time: 5.75e-02, avg batch time: 0.4714, average train loss: 0.0201
[09/26 05:30:12 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1583, average loss: 0.6474
[09/26 05:30:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:30:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:30:18 visual_prompt]: Epoch 28 / 100: avg data time: 6.94e-02, avg batch time: 0.4823, average train loss: 0.0193
[09/26 05:30:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 0.6402
[09/26 05:30:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:30:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:30:27 visual_prompt]: Epoch 29 / 100: avg data time: 6.89e-02, avg batch time: 0.4841, average train loss: 0.0186
[09/26 05:30:29 visual_prompt]: Inference (val):avg data time: 4.53e-05, avg batch time: 0.1584, average loss: 0.6412
[09/26 05:30:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:30:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:30:35 visual_prompt]: Epoch 30 / 100: avg data time: 5.90e-02, avg batch time: 0.4731, average train loss: 0.0176
[09/26 05:30:37 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 0.6415
[09/26 05:30:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.50	
[09/26 05:30:37 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:30:43 visual_prompt]: Epoch 31 / 100: avg data time: 5.17e-02, avg batch time: 0.4673, average train loss: 0.0168
[09/26 05:30:45 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1575, average loss: 0.6371
[09/26 05:30:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.00	
[09/26 05:30:45 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:30:52 visual_prompt]: Epoch 32 / 100: avg data time: 6.05e-02, avg batch time: 0.4742, average train loss: 0.0163
[09/26 05:30:53 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 0.6325
[09/26 05:30:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.00	
[09/26 05:30:53 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:31:00 visual_prompt]: Epoch 33 / 100: avg data time: 5.73e-02, avg batch time: 0.4718, average train loss: 0.0153
[09/26 05:31:02 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1582, average loss: 0.6365
[09/26 05:31:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.00	
[09/26 05:31:02 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:31:08 visual_prompt]: Epoch 34 / 100: avg data time: 6.29e-02, avg batch time: 0.4767, average train loss: 0.0146
[09/26 05:31:10 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1586, average loss: 0.6393
[09/26 05:31:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.00	top5: 94.00	
[09/26 05:31:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:31:16 visual_prompt]: Epoch 35 / 100: avg data time: 5.54e-02, avg batch time: 0.4690, average train loss: 0.0140
[09/26 05:31:18 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1583, average loss: 0.6250
[09/26 05:31:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:31:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:31:25 visual_prompt]: Epoch 36 / 100: avg data time: 5.74e-02, avg batch time: 0.4723, average train loss: 0.0137
[09/26 05:31:27 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1583, average loss: 0.6236
[09/26 05:31:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:31:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:31:33 visual_prompt]: Epoch 37 / 100: avg data time: 6.54e-02, avg batch time: 0.4789, average train loss: 0.0132
[09/26 05:31:35 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1575, average loss: 0.6212
[09/26 05:31:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 95.00	
[09/26 05:31:35 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:31:42 visual_prompt]: Epoch 38 / 100: avg data time: 6.38e-02, avg batch time: 0.4775, average train loss: 0.0125
[09/26 05:31:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1587, average loss: 0.6150
[09/26 05:31:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 95.00	
[09/26 05:31:43 visual_prompt]: Best epoch 38: best metric: 0.870
[09/26 05:31:43 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:31:50 visual_prompt]: Epoch 39 / 100: avg data time: 6.63e-02, avg batch time: 0.4787, average train loss: 0.0125
[09/26 05:31:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.6161
[09/26 05:31:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 05:31:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:31:58 visual_prompt]: Epoch 40 / 100: avg data time: 6.50e-02, avg batch time: 0.4790, average train loss: 0.0119
[09/26 05:32:00 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1581, average loss: 0.6161
[09/26 05:32:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 05:32:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:32:07 visual_prompt]: Epoch 41 / 100: avg data time: 6.58e-02, avg batch time: 0.4807, average train loss: 0.0119
[09/26 05:32:09 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1583, average loss: 0.6210
[09/26 05:32:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 05:32:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:32:15 visual_prompt]: Epoch 42 / 100: avg data time: 6.22e-02, avg batch time: 0.4756, average train loss: 0.0113
[09/26 05:32:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1583, average loss: 0.6179
[09/26 05:32:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 05:32:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:32:24 visual_prompt]: Epoch 43 / 100: avg data time: 7.05e-02, avg batch time: 0.4837, average train loss: 0.0110
[09/26 05:32:25 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1583, average loss: 0.6189
[09/26 05:32:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:32:25 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:32:32 visual_prompt]: Epoch 44 / 100: avg data time: 5.17e-02, avg batch time: 0.4658, average train loss: 0.0111
[09/26 05:32:34 visual_prompt]: Inference (val):avg data time: 4.66e-05, avg batch time: 0.1581, average loss: 0.6200
[09/26 05:32:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:32:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:32:40 visual_prompt]: Epoch 45 / 100: avg data time: 6.66e-02, avg batch time: 0.4794, average train loss: 0.0104
[09/26 05:32:42 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1582, average loss: 0.6191
[09/26 05:32:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 05:32:42 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:32:49 visual_prompt]: Epoch 46 / 100: avg data time: 6.31e-02, avg batch time: 0.4768, average train loss: 0.0102
[09/26 05:32:50 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1579, average loss: 0.6199
[09/26 05:32:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.50	
[09/26 05:32:50 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:32:57 visual_prompt]: Epoch 47 / 100: avg data time: 5.97e-02, avg batch time: 0.4738, average train loss: 0.0102
[09/26 05:32:59 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 0.6163
[09/26 05:32:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.00	
[09/26 05:32:59 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:33:05 visual_prompt]: Epoch 48 / 100: avg data time: 6.50e-02, avg batch time: 0.4793, average train loss: 0.0100
[09/26 05:33:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.6153
[09/26 05:33:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 94.00	
[09/26 05:33:07 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:33:14 visual_prompt]: Epoch 49 / 100: avg data time: 7.03e-02, avg batch time: 0.4841, average train loss: 0.0100
[09/26 05:33:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1586, average loss: 0.6129
[09/26 05:33:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:33:16 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:33:22 visual_prompt]: Epoch 50 / 100: avg data time: 6.71e-02, avg batch time: 0.4809, average train loss: 0.0094
[09/26 05:33:24 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1585, average loss: 0.6104
[09/26 05:33:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:33:24 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:33:31 visual_prompt]: Epoch 51 / 100: avg data time: 6.51e-02, avg batch time: 0.4797, average train loss: 0.0095
[09/26 05:33:33 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1579, average loss: 0.6097
[09/26 05:33:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:33:33 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:33:39 visual_prompt]: Epoch 52 / 100: avg data time: 7.42e-02, avg batch time: 0.4873, average train loss: 0.0093
[09/26 05:33:41 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 0.6101
[09/26 05:33:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:33:41 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:33:48 visual_prompt]: Epoch 53 / 100: avg data time: 6.29e-02, avg batch time: 0.4769, average train loss: 0.0090
[09/26 05:33:49 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1583, average loss: 0.6119
[09/26 05:33:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.00	
[09/26 05:33:49 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:33:56 visual_prompt]: Epoch 54 / 100: avg data time: 6.13e-02, avg batch time: 0.4784, average train loss: 0.0090
[09/26 05:33:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1578, average loss: 0.6146
[09/26 05:33:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.00	
[09/26 05:33:58 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:34:04 visual_prompt]: Epoch 55 / 100: avg data time: 6.62e-02, avg batch time: 0.4810, average train loss: 0.0089
[09/26 05:34:06 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1580, average loss: 0.6147
[09/26 05:34:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:34:06 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:34:13 visual_prompt]: Epoch 56 / 100: avg data time: 6.09e-02, avg batch time: 0.4757, average train loss: 0.0087
[09/26 05:34:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1585, average loss: 0.6102
[09/26 05:34:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:34:14 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:34:21 visual_prompt]: Epoch 57 / 100: avg data time: 6.67e-02, avg batch time: 0.4811, average train loss: 0.0086
[09/26 05:34:23 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1580, average loss: 0.6075
[09/26 05:34:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:34:23 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:34:29 visual_prompt]: Epoch 58 / 100: avg data time: 6.75e-02, avg batch time: 0.4815, average train loss: 0.0086
[09/26 05:34:31 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1585, average loss: 0.6037
[09/26 05:34:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:34:31 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:34:38 visual_prompt]: Epoch 59 / 100: avg data time: 6.85e-02, avg batch time: 0.4820, average train loss: 0.0083
[09/26 05:34:40 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.6042
[09/26 05:34:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:34:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:34:46 visual_prompt]: Epoch 60 / 100: avg data time: 6.76e-02, avg batch time: 0.4810, average train loss: 0.0084
[09/26 05:34:48 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1576, average loss: 0.6094
[09/26 05:34:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:34:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:34:55 visual_prompt]: Epoch 61 / 100: avg data time: 6.55e-02, avg batch time: 0.4786, average train loss: 0.0082
[09/26 05:34:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 0.6073
[09/26 05:34:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:34:56 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:35:03 visual_prompt]: Epoch 62 / 100: avg data time: 6.46e-02, avg batch time: 0.4774, average train loss: 0.0082
[09/26 05:35:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1583, average loss: 0.6049
[09/26 05:35:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:35:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:35:11 visual_prompt]: Epoch 63 / 100: avg data time: 6.56e-02, avg batch time: 0.4795, average train loss: 0.0079
[09/26 05:35:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 0.6044
[09/26 05:35:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:35:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:35:20 visual_prompt]: Epoch 64 / 100: avg data time: 5.15e-02, avg batch time: 0.4670, average train loss: 0.0080
[09/26 05:35:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 0.6039
[09/26 05:35:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:35:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:35:28 visual_prompt]: Epoch 65 / 100: avg data time: 6.85e-02, avg batch time: 0.4822, average train loss: 0.0079
[09/26 05:35:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.6056
[09/26 05:35:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:35:30 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:35:36 visual_prompt]: Epoch 66 / 100: avg data time: 6.56e-02, avg batch time: 0.4781, average train loss: 0.0077
[09/26 05:35:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1582, average loss: 0.6061
[09/26 05:35:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:35:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:35:45 visual_prompt]: Epoch 67 / 100: avg data time: 6.52e-02, avg batch time: 0.4787, average train loss: 0.0078
[09/26 05:35:46 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1588, average loss: 0.6050
[09/26 05:35:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 94.50	
[09/26 05:35:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:35:53 visual_prompt]: Epoch 68 / 100: avg data time: 5.76e-02, avg batch time: 0.4710, average train loss: 0.0077
[09/26 05:35:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1583, average loss: 0.6025
[09/26 05:35:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:35:55 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:36:01 visual_prompt]: Epoch 69 / 100: avg data time: 6.85e-02, avg batch time: 0.4811, average train loss: 0.0076
[09/26 05:36:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1581, average loss: 0.6017
[09/26 05:36:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:36:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:36:10 visual_prompt]: Epoch 70 / 100: avg data time: 7.29e-02, avg batch time: 0.4852, average train loss: 0.0075
[09/26 05:36:12 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1584, average loss: 0.6022
[09/26 05:36:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:36:12 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:36:18 visual_prompt]: Epoch 71 / 100: avg data time: 6.51e-02, avg batch time: 0.4786, average train loss: 0.0076
[09/26 05:36:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.6028
[09/26 05:36:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:36:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:36:26 visual_prompt]: Epoch 72 / 100: avg data time: 5.41e-02, avg batch time: 0.4715, average train loss: 0.0075
[09/26 05:36:28 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1582, average loss: 0.6043
[09/26 05:36:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:36:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:36:35 visual_prompt]: Epoch 73 / 100: avg data time: 6.79e-02, avg batch time: 0.4813, average train loss: 0.0076
[09/26 05:36:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 0.6048
[09/26 05:36:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:36:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:36:43 visual_prompt]: Epoch 74 / 100: avg data time: 6.69e-02, avg batch time: 0.4802, average train loss: 0.0074
[09/26 05:36:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1585, average loss: 0.6035
[09/26 05:36:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:36:45 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:36:52 visual_prompt]: Epoch 75 / 100: avg data time: 6.16e-02, avg batch time: 0.4758, average train loss: 0.0075
[09/26 05:36:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.6019
[09/26 05:36:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:36:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:37:00 visual_prompt]: Epoch 76 / 100: avg data time: 6.98e-02, avg batch time: 0.4842, average train loss: 0.0073
[09/26 05:37:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1578, average loss: 0.6013
[09/26 05:37:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:37:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:37:08 visual_prompt]: Epoch 77 / 100: avg data time: 6.48e-02, avg batch time: 0.4798, average train loss: 0.0074
[09/26 05:37:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1581, average loss: 0.6012
[09/26 05:37:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:37:10 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:37:17 visual_prompt]: Epoch 78 / 100: avg data time: 6.57e-02, avg batch time: 0.4786, average train loss: 0.0076
[09/26 05:37:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.6011
[09/26 05:37:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:37:19 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:37:25 visual_prompt]: Epoch 79 / 100: avg data time: 6.28e-02, avg batch time: 0.4751, average train loss: 0.0073
[09/26 05:37:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1578, average loss: 0.6010
[09/26 05:37:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:37:27 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:37:34 visual_prompt]: Epoch 80 / 100: avg data time: 7.02e-02, avg batch time: 0.4826, average train loss: 0.0073
[09/26 05:37:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1579, average loss: 0.6010
[09/26 05:37:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:37:36 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:37:42 visual_prompt]: Epoch 81 / 100: avg data time: 6.05e-02, avg batch time: 0.4746, average train loss: 0.0072
[09/26 05:37:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1582, average loss: 0.6015
[09/26 05:37:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:37:44 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:37:50 visual_prompt]: Epoch 82 / 100: avg data time: 5.27e-02, avg batch time: 0.4676, average train loss: 0.0072
[09/26 05:37:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.6017
[09/26 05:37:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:37:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:37:59 visual_prompt]: Epoch 83 / 100: avg data time: 6.85e-02, avg batch time: 0.4819, average train loss: 0.0072
[09/26 05:38:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1581, average loss: 0.6011
[09/26 05:38:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:38:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:38:07 visual_prompt]: Epoch 84 / 100: avg data time: 7.27e-02, avg batch time: 0.4855, average train loss: 0.0071
[09/26 05:38:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 0.6006
[09/26 05:38:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:38:09 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:38:16 visual_prompt]: Epoch 85 / 100: avg data time: 6.91e-02, avg batch time: 0.4823, average train loss: 0.0071
[09/26 05:38:17 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1579, average loss: 0.6002
[09/26 05:38:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:38:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:38:24 visual_prompt]: Epoch 86 / 100: avg data time: 6.90e-02, avg batch time: 0.4830, average train loss: 0.0073
[09/26 05:38:26 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 0.6006
[09/26 05:38:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:38:26 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:38:32 visual_prompt]: Epoch 87 / 100: avg data time: 6.32e-02, avg batch time: 0.4758, average train loss: 0.0072
[09/26 05:38:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1585, average loss: 0.6007
[09/26 05:38:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:38:34 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:38:41 visual_prompt]: Epoch 88 / 100: avg data time: 5.63e-02, avg batch time: 0.4714, average train loss: 0.0072
[09/26 05:38:42 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1575, average loss: 0.6008
[09/26 05:38:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:38:42 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:38:49 visual_prompt]: Epoch 89 / 100: avg data time: 6.63e-02, avg batch time: 0.4798, average train loss: 0.0069
[09/26 05:38:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1579, average loss: 0.6006
[09/26 05:38:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:38:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:38:57 visual_prompt]: Epoch 90 / 100: avg data time: 6.58e-02, avg batch time: 0.4786, average train loss: 0.0070
[09/26 05:38:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 0.6007
[09/26 05:38:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:38:59 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:39:06 visual_prompt]: Epoch 91 / 100: avg data time: 6.65e-02, avg batch time: 0.4794, average train loss: 0.0070
[09/26 05:39:07 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1577, average loss: 0.6009
[09/26 05:39:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:07 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:39:14 visual_prompt]: Epoch 92 / 100: avg data time: 6.74e-02, avg batch time: 0.4813, average train loss: 0.0070
[09/26 05:39:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1584, average loss: 0.6011
[09/26 05:39:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:16 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:39:22 visual_prompt]: Epoch 93 / 100: avg data time: 6.38e-02, avg batch time: 0.4784, average train loss: 0.0071
[09/26 05:39:24 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1585, average loss: 0.6011
[09/26 05:39:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:24 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:39:31 visual_prompt]: Epoch 94 / 100: avg data time: 6.86e-02, avg batch time: 0.4819, average train loss: 0.0071
[09/26 05:39:33 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.6011
[09/26 05:39:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:33 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:39:39 visual_prompt]: Epoch 95 / 100: avg data time: 5.88e-02, avg batch time: 0.4734, average train loss: 0.0069
[09/26 05:39:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.6012
[09/26 05:39:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:39:48 visual_prompt]: Epoch 96 / 100: avg data time: 6.59e-02, avg batch time: 0.4800, average train loss: 0.0073
[09/26 05:39:49 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1583, average loss: 0.6011
[09/26 05:39:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:49 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:39:56 visual_prompt]: Epoch 97 / 100: avg data time: 6.36e-02, avg batch time: 0.4780, average train loss: 0.0069
[09/26 05:39:58 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1581, average loss: 0.6011
[09/26 05:39:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:39:58 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:40:05 visual_prompt]: Epoch 98 / 100: avg data time: 6.60e-02, avg batch time: 0.4796, average train loss: 0.0070
[09/26 05:40:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1582, average loss: 0.6011
[09/26 05:40:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:40:06 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:40:13 visual_prompt]: Epoch 99 / 100: avg data time: 7.12e-02, avg batch time: 0.4846, average train loss: 0.0070
[09/26 05:40:15 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1585, average loss: 0.6011
[09/26 05:40:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:40:15 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:40:21 visual_prompt]: Epoch 100 / 100: avg data time: 6.81e-02, avg batch time: 0.4813, average train loss: 0.0069
[09/26 05:40:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1580, average loss: 0.6011
[09/26 05:40:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.50	
[09/26 05:40:23 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:40:23 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:40:23 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:40:23 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:40:23 visual_prompt]: Training with config:
[09/26 05:40:23 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:40:23 visual_prompt]: Loading training data...
[09/26 05:40:23 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:40:24 visual_prompt]: Number of images: 800
[09/26 05:40:24 visual_prompt]: Number of classes: 102 / 102
[09/26 05:40:24 visual_prompt]: Loading validation data...
[09/26 05:40:24 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:40:25 visual_prompt]: Number of images: 200
[09/26 05:40:25 visual_prompt]: Number of classes: 91 / 102
[09/26 05:40:25 visual_prompt]: Constructing models...
[09/26 05:40:27 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 05:40:27 visual_prompt]: tuned percent:0.625
[09/26 05:40:27 visual_prompt]: Device used for model: 0
[09/26 05:40:27 visual_prompt]: Setting up Evaluator...
[09/26 05:40:27 visual_prompt]: Setting up Trainer...
[09/26 05:40:27 visual_prompt]: 	Setting up the optimizer...
[09/26 05:40:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:40:34 visual_prompt]: Epoch 1 / 100: avg data time: 6.62e-02, avg batch time: 0.4844, average train loss: 4.6695
[09/26 05:40:36 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1577, average loss: 4.6780
[09/26 05:40:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 05:40:36 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:40:36 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 05:40:42 visual_prompt]: Epoch 2 / 100: avg data time: 6.55e-02, avg batch time: 0.4780, average train loss: 4.6577
[09/26 05:40:44 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1580, average loss: 4.6481
[09/26 05:40:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 6.00	
[09/26 05:40:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:40:51 visual_prompt]: Epoch 3 / 100: avg data time: 6.78e-02, avg batch time: 0.4829, average train loss: 4.6212
[09/26 05:40:52 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1585, average loss: 4.6181
[09/26 05:40:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.00	
[09/26 05:40:53 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 05:40:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 05:40:59 visual_prompt]: Epoch 4 / 100: avg data time: 6.21e-02, avg batch time: 0.4752, average train loss: 4.5641
[09/26 05:41:01 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1579, average loss: 4.5718
[09/26 05:41:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 10.00	
[09/26 05:41:01 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 05:41:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:41:08 visual_prompt]: Epoch 5 / 100: avg data time: 6.95e-02, avg batch time: 0.4830, average train loss: 4.4638
[09/26 05:41:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1582, average loss: 4.4439
[09/26 05:41:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 5.50	top5: 14.00	
[09/26 05:41:09 visual_prompt]: Best epoch 5: best metric: 0.055
[09/26 05:41:09 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 05:41:16 visual_prompt]: Epoch 6 / 100: avg data time: 6.50e-02, avg batch time: 0.4784, average train loss: 4.2337
[09/26 05:41:18 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1574, average loss: 4.2141
[09/26 05:41:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.00	top5: 22.50	
[09/26 05:41:18 visual_prompt]: Best epoch 6: best metric: 0.090
[09/26 05:41:18 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 05:41:24 visual_prompt]: Epoch 7 / 100: avg data time: 6.84e-02, avg batch time: 0.4816, average train loss: 3.8502
[09/26 05:41:26 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1579, average loss: 3.9261
[09/26 05:41:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 14.00	top5: 31.00	
[09/26 05:41:26 visual_prompt]: Best epoch 7: best metric: 0.140
[09/26 05:41:26 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 05:41:33 visual_prompt]: Epoch 8 / 100: avg data time: 6.78e-02, avg batch time: 0.4820, average train loss: 3.4446
[09/26 05:41:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1584, average loss: 3.3338
[09/26 05:41:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 25.00	top5: 52.00	
[09/26 05:41:34 visual_prompt]: Best epoch 8: best metric: 0.250
[09/26 05:41:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:41:41 visual_prompt]: Epoch 9 / 100: avg data time: 6.40e-02, avg batch time: 0.4786, average train loss: 2.9475
[09/26 05:41:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1587, average loss: 2.8744
[09/26 05:41:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 36.50	top5: 68.00	
[09/26 05:41:43 visual_prompt]: Best epoch 9: best metric: 0.365
[09/26 05:41:43 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 05:41:49 visual_prompt]: Epoch 10 / 100: avg data time: 6.36e-02, avg batch time: 0.4772, average train loss: 2.4281
[09/26 05:41:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1587, average loss: 2.5347
[09/26 05:41:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 44.50	top5: 76.00	
[09/26 05:41:51 visual_prompt]: Best epoch 10: best metric: 0.445
[09/26 05:41:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 05:41:58 visual_prompt]: Epoch 11 / 100: avg data time: 6.30e-02, avg batch time: 0.4757, average train loss: 1.9758
[09/26 05:42:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1585, average loss: 2.1156
[09/26 05:42:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 60.00	top5: 86.50	
[09/26 05:42:00 visual_prompt]: Best epoch 11: best metric: 0.600
[09/26 05:42:00 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 05:42:06 visual_prompt]: Epoch 12 / 100: avg data time: 6.51e-02, avg batch time: 0.4793, average train loss: 1.5401
[09/26 05:42:08 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1586, average loss: 1.8797
[09/26 05:42:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.00	top5: 86.50	
[09/26 05:42:08 visual_prompt]: Best epoch 12: best metric: 0.650
[09/26 05:42:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 05:42:15 visual_prompt]: Epoch 13 / 100: avg data time: 7.00e-02, avg batch time: 0.4840, average train loss: 1.2205
[09/26 05:42:16 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 1.6873
[09/26 05:42:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 90.50	
[09/26 05:42:16 visual_prompt]: Best epoch 13: best metric: 0.680
[09/26 05:42:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 05:42:23 visual_prompt]: Epoch 14 / 100: avg data time: 5.90e-02, avg batch time: 0.4736, average train loss: 0.9793
[09/26 05:42:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1585, average loss: 1.4410
[09/26 05:42:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 92.00	
[09/26 05:42:25 visual_prompt]: Best epoch 14: best metric: 0.740
[09/26 05:42:25 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 05:42:31 visual_prompt]: Epoch 15 / 100: avg data time: 6.91e-02, avg batch time: 0.4820, average train loss: 0.7981
[09/26 05:42:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1596, average loss: 1.3098
[09/26 05:42:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 93.00	
[09/26 05:42:33 visual_prompt]: Best epoch 15: best metric: 0.785
[09/26 05:42:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 05:42:40 visual_prompt]: Epoch 16 / 100: avg data time: 6.56e-02, avg batch time: 0.4786, average train loss: 0.6642
[09/26 05:42:41 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1581, average loss: 1.2434
[09/26 05:42:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 93.00	
[09/26 05:42:41 visual_prompt]: Best epoch 16: best metric: 0.790
[09/26 05:42:41 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 05:42:48 visual_prompt]: Epoch 17 / 100: avg data time: 6.63e-02, avg batch time: 0.4797, average train loss: 0.5668
[09/26 05:42:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 1.1386
[09/26 05:42:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.50	
[09/26 05:42:50 visual_prompt]: Best epoch 17: best metric: 0.845
[09/26 05:42:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 05:42:57 visual_prompt]: Epoch 18 / 100: avg data time: 6.35e-02, avg batch time: 0.4768, average train loss: 0.4985
[09/26 05:42:58 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1586, average loss: 1.0927
[09/26 05:42:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 96.00	
[09/26 05:42:58 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 05:43:05 visual_prompt]: Epoch 19 / 100: avg data time: 6.49e-02, avg batch time: 0.4782, average train loss: 0.4566
[09/26 05:43:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1579, average loss: 1.0945
[09/26 05:43:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.50	
[09/26 05:43:07 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 05:43:13 visual_prompt]: Epoch 20 / 100: avg data time: 6.57e-02, avg batch time: 0.4790, average train loss: 0.4363
[09/26 05:43:15 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1580, average loss: 1.0383
[09/26 05:43:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.50	
[09/26 05:43:15 visual_prompt]: Best epoch 20: best metric: 0.855
[09/26 05:43:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 05:43:22 visual_prompt]: Epoch 21 / 100: avg data time: 6.35e-02, avg batch time: 0.4770, average train loss: 0.4198
[09/26 05:43:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1585, average loss: 1.0446
[09/26 05:43:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.00	
[09/26 05:43:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 05:43:30 visual_prompt]: Epoch 22 / 100: avg data time: 6.59e-02, avg batch time: 0.4803, average train loss: 0.3917
[09/26 05:43:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1585, average loss: 1.0130
[09/26 05:43:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 94.50	
[09/26 05:43:32 visual_prompt]: Best epoch 22: best metric: 0.865
[09/26 05:43:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 05:43:38 visual_prompt]: Epoch 23 / 100: avg data time: 6.82e-02, avg batch time: 0.4817, average train loss: 0.3654
[09/26 05:43:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1587, average loss: 0.9865
[09/26 05:43:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.50	top5: 95.50	
[09/26 05:43:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 05:43:47 visual_prompt]: Epoch 24 / 100: avg data time: 6.03e-02, avg batch time: 0.4763, average train loss: 0.3569
[09/26 05:43:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1584, average loss: 1.0138
[09/26 05:43:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.50	top5: 93.50	
[09/26 05:43:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 05:43:55 visual_prompt]: Epoch 25 / 100: avg data time: 6.43e-02, avg batch time: 0.4788, average train loss: 0.3618
[09/26 05:43:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1585, average loss: 0.9510
[09/26 05:43:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 95.50	
[09/26 05:43:57 visual_prompt]: Best epoch 25: best metric: 0.875
[09/26 05:43:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 05:44:03 visual_prompt]: Epoch 26 / 100: avg data time: 5.87e-02, avg batch time: 0.4733, average train loss: 0.3631
[09/26 05:44:05 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 1.0367
[09/26 05:44:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 94.00	
[09/26 05:44:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 05:44:12 visual_prompt]: Epoch 27 / 100: avg data time: 7.13e-02, avg batch time: 0.4859, average train loss: 0.3729
[09/26 05:44:14 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1584, average loss: 0.9813
[09/26 05:44:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.00	top5: 94.50	
[09/26 05:44:14 visual_prompt]: Best epoch 27: best metric: 0.880
[09/26 05:44:14 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 05:44:20 visual_prompt]: Epoch 28 / 100: avg data time: 5.97e-02, avg batch time: 0.4749, average train loss: 0.3824
[09/26 05:44:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1586, average loss: 1.0304
[09/26 05:44:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 95.00	
[09/26 05:44:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 05:44:29 visual_prompt]: Epoch 29 / 100: avg data time: 6.33e-02, avg batch time: 0.4778, average train loss: 0.4142
[09/26 05:44:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1586, average loss: 0.9661
[09/26 05:44:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 95.00	
[09/26 05:44:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 05:44:37 visual_prompt]: Epoch 30 / 100: avg data time: 6.22e-02, avg batch time: 0.4770, average train loss: 0.4136
[09/26 05:44:39 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1578, average loss: 0.9890
[09/26 05:44:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 96.00	
[09/26 05:44:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 05:44:45 visual_prompt]: Epoch 31 / 100: avg data time: 6.42e-02, avg batch time: 0.4783, average train loss: 0.4134
[09/26 05:44:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.9743
[09/26 05:44:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 97.00	
[09/26 05:44:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 05:44:54 visual_prompt]: Epoch 32 / 100: avg data time: 7.28e-02, avg batch time: 0.4868, average train loss: 0.4105
[09/26 05:44:55 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 0.9493
[09/26 05:44:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 97.00	
[09/26 05:44:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 05:45:02 visual_prompt]: Epoch 33 / 100: avg data time: 5.24e-02, avg batch time: 0.4672, average train loss: 0.3863
[09/26 05:45:04 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1582, average loss: 0.8689
[09/26 05:45:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 05:45:04 visual_prompt]: Best epoch 33: best metric: 0.885
[09/26 05:45:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 05:45:10 visual_prompt]: Epoch 34 / 100: avg data time: 6.82e-02, avg batch time: 0.4818, average train loss: 0.3692
[09/26 05:45:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1584, average loss: 0.8811
[09/26 05:45:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 05:45:12 visual_prompt]: Best epoch 34: best metric: 0.900
[09/26 05:45:12 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 05:45:19 visual_prompt]: Epoch 35 / 100: avg data time: 6.72e-02, avg batch time: 0.4803, average train loss: 0.3311
[09/26 05:45:20 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1580, average loss: 0.8411
[09/26 05:45:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 94.50	
[09/26 05:45:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 05:45:27 visual_prompt]: Epoch 36 / 100: avg data time: 6.22e-02, avg batch time: 0.4768, average train loss: 0.3004
[09/26 05:45:29 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1583, average loss: 0.8386
[09/26 05:45:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.50	top5: 96.50	
[09/26 05:45:29 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 05:45:35 visual_prompt]: Epoch 37 / 100: avg data time: 5.96e-02, avg batch time: 0.4736, average train loss: 0.2756
[09/26 05:45:37 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.8124
[09/26 05:45:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.00	
[09/26 05:45:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 05:45:44 visual_prompt]: Epoch 38 / 100: avg data time: 6.30e-02, avg batch time: 0.4765, average train loss: 0.2656
[09/26 05:45:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1578, average loss: 0.7552
[09/26 05:45:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 05:45:46 visual_prompt]: Best epoch 38: best metric: 0.905
[09/26 05:45:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 05:45:52 visual_prompt]: Epoch 39 / 100: avg data time: 5.29e-02, avg batch time: 0.4662, average train loss: 0.2565
[09/26 05:45:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1580, average loss: 0.7747
[09/26 05:45:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:45:54 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 05:46:00 visual_prompt]: Epoch 40 / 100: avg data time: 5.19e-02, avg batch time: 0.4650, average train loss: 0.2614
[09/26 05:46:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1585, average loss: 0.7997
[09/26 05:46:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:46:02 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 05:46:09 visual_prompt]: Epoch 41 / 100: avg data time: 5.78e-02, avg batch time: 0.4707, average train loss: 0.2714
[09/26 05:46:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.7672
[09/26 05:46:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:46:10 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 05:46:17 visual_prompt]: Epoch 42 / 100: avg data time: 6.47e-02, avg batch time: 0.4780, average train loss: 0.2709
[09/26 05:46:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1584, average loss: 0.7757
[09/26 05:46:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.50	
[09/26 05:46:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 05:46:25 visual_prompt]: Epoch 43 / 100: avg data time: 6.91e-02, avg batch time: 0.4822, average train loss: 0.2850
[09/26 05:46:27 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1584, average loss: 0.8061
[09/26 05:46:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.00	
[09/26 05:46:27 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 05:46:34 visual_prompt]: Epoch 44 / 100: avg data time: 6.12e-02, avg batch time: 0.4757, average train loss: 0.2767
[09/26 05:46:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 0.8059
[09/26 05:46:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:46:36 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 05:46:42 visual_prompt]: Epoch 45 / 100: avg data time: 6.72e-02, avg batch time: 0.4825, average train loss: 0.2682
[09/26 05:46:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1581, average loss: 0.8033
[09/26 05:46:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 96.50	
[09/26 05:46:44 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 05:46:51 visual_prompt]: Epoch 46 / 100: avg data time: 7.06e-02, avg batch time: 0.4833, average train loss: 0.2690
[09/26 05:46:52 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1583, average loss: 0.8951
[09/26 05:46:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 86.00	top5: 96.00	
[09/26 05:46:52 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 05:46:59 visual_prompt]: Epoch 47 / 100: avg data time: 6.60e-02, avg batch time: 0.4799, average train loss: 0.2907
[09/26 05:47:01 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1584, average loss: 0.8747
[09/26 05:47:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 95.00	
[09/26 05:47:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 05:47:08 visual_prompt]: Epoch 48 / 100: avg data time: 6.45e-02, avg batch time: 0.4775, average train loss: 0.3471
[09/26 05:47:09 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1583, average loss: 0.9469
[09/26 05:47:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 87.00	top5: 93.00	
[09/26 05:47:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 05:47:16 visual_prompt]: Epoch 49 / 100: avg data time: 7.01e-02, avg batch time: 0.4829, average train loss: 0.3694
[09/26 05:47:18 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1577, average loss: 1.1735
[09/26 05:47:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.00	
[09/26 05:47:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 05:47:24 visual_prompt]: Epoch 50 / 100: avg data time: 6.81e-02, avg batch time: 0.4813, average train loss: 0.5099
[09/26 05:47:26 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1584, average loss: 1.0974
[09/26 05:47:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.50	
[09/26 05:47:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 05:47:33 visual_prompt]: Epoch 51 / 100: avg data time: 6.04e-02, avg batch time: 0.4743, average train loss: 0.6174
[09/26 05:47:35 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1587, average loss: 1.1505
[09/26 05:47:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 94.50	
[09/26 05:47:35 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 05:47:41 visual_prompt]: Epoch 52 / 100: avg data time: 6.62e-02, avg batch time: 0.4790, average train loss: 0.5360
[09/26 05:47:43 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1586, average loss: 1.0445
[09/26 05:47:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 85.50	top5: 95.00	
[09/26 05:47:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 05:47:49 visual_prompt]: Epoch 53 / 100: avg data time: 5.28e-02, avg batch time: 0.4662, average train loss: 0.4080
[09/26 05:47:51 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1586, average loss: 0.8461
[09/26 05:47:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 97.50	
[09/26 05:47:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 05:47:58 visual_prompt]: Epoch 54 / 100: avg data time: 6.33e-02, avg batch time: 0.4785, average train loss: 0.3404
[09/26 05:47:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1581, average loss: 0.8111
[09/26 05:47:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 88.50	top5: 97.00	
[09/26 05:47:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 05:48:06 visual_prompt]: Epoch 55 / 100: avg data time: 5.85e-02, avg batch time: 0.4723, average train loss: 0.2851
[09/26 05:48:08 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1579, average loss: 0.7584
[09/26 05:48:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 05:48:08 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 05:48:15 visual_prompt]: Epoch 56 / 100: avg data time: 7.18e-02, avg batch time: 0.4868, average train loss: 0.2540
[09/26 05:48:16 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1583, average loss: 0.7220
[09/26 05:48:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 05:48:16 visual_prompt]: Best epoch 56: best metric: 0.910
[09/26 05:48:16 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 05:48:23 visual_prompt]: Epoch 57 / 100: avg data time: 5.16e-02, avg batch time: 0.4654, average train loss: 0.2394
[09/26 05:48:25 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1583, average loss: 0.6994
[09/26 05:48:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.00	
[09/26 05:48:25 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 05:48:31 visual_prompt]: Epoch 58 / 100: avg data time: 5.83e-02, avg batch time: 0.4724, average train loss: 0.2323
[09/26 05:48:33 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1582, average loss: 0.6947
[09/26 05:48:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 91.00	top5: 96.50	
[09/26 05:48:33 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 05:48:40 visual_prompt]: Epoch 59 / 100: avg data time: 6.72e-02, avg batch time: 0.4805, average train loss: 0.2297
[09/26 05:48:41 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1582, average loss: 0.6978
[09/26 05:48:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:48:41 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 05:48:48 visual_prompt]: Epoch 60 / 100: avg data time: 6.84e-02, avg batch time: 0.4820, average train loss: 0.2293
[09/26 05:48:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1579, average loss: 0.7007
[09/26 05:48:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:48:50 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 05:48:57 visual_prompt]: Epoch 61 / 100: avg data time: 6.44e-02, avg batch time: 0.4774, average train loss: 0.2286
[09/26 05:48:58 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1578, average loss: 0.6986
[09/26 05:48:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 05:48:58 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 05:49:05 visual_prompt]: Epoch 62 / 100: avg data time: 6.67e-02, avg batch time: 0.4797, average train loss: 0.2299
[09/26 05:49:07 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1582, average loss: 0.7058
[09/26 05:49:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:49:07 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 05:49:13 visual_prompt]: Epoch 63 / 100: avg data time: 6.77e-02, avg batch time: 0.4816, average train loss: 0.2313
[09/26 05:49:15 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1586, average loss: 0.6881
[09/26 05:49:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:49:15 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 05:49:22 visual_prompt]: Epoch 64 / 100: avg data time: 5.97e-02, avg batch time: 0.4726, average train loss: 0.2321
[09/26 05:49:23 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1584, average loss: 0.6873
[09/26 05:49:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:49:23 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 05:49:30 visual_prompt]: Epoch 65 / 100: avg data time: 7.13e-02, avg batch time: 0.4850, average train loss: 0.2323
[09/26 05:49:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 0.6898
[09/26 05:49:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:49:32 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 05:49:39 visual_prompt]: Epoch 66 / 100: avg data time: 6.87e-02, avg batch time: 0.4823, average train loss: 0.2332
[09/26 05:49:40 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1581, average loss: 0.7060
[09/26 05:49:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:49:40 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 05:49:47 visual_prompt]: Epoch 67 / 100: avg data time: 6.24e-02, avg batch time: 0.4757, average train loss: 0.2327
[09/26 05:49:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1583, average loss: 0.6851
[09/26 05:49:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 05:49:49 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 05:49:55 visual_prompt]: Epoch 68 / 100: avg data time: 6.39e-02, avg batch time: 0.4772, average train loss: 0.2335
[09/26 05:49:57 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1581, average loss: 0.7000
[09/26 05:49:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/26 05:49:57 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 05:50:04 visual_prompt]: Epoch 69 / 100: avg data time: 5.98e-02, avg batch time: 0.4737, average train loss: 0.2337
[09/26 05:50:05 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1586, average loss: 0.6827
[09/26 05:50:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 05:50:05 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 05:50:12 visual_prompt]: Epoch 70 / 100: avg data time: 5.98e-02, avg batch time: 0.4735, average train loss: 0.2352
[09/26 05:50:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1579, average loss: 0.6888
[09/26 05:50:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.50	top5: 96.50	
[09/26 05:50:14 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 05:50:20 visual_prompt]: Epoch 71 / 100: avg data time: 5.68e-02, avg batch time: 0.4720, average train loss: 0.2349
[09/26 05:50:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1574, average loss: 0.6933
[09/26 05:50:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:50:22 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 05:50:29 visual_prompt]: Epoch 72 / 100: avg data time: 6.59e-02, avg batch time: 0.4795, average train loss: 0.2364
[09/26 05:50:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 0.7018
[09/26 05:50:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:50:30 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 05:50:37 visual_prompt]: Epoch 73 / 100: avg data time: 6.79e-02, avg batch time: 0.4811, average train loss: 0.2364
[09/26 05:50:39 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1584, average loss: 0.7068
[09/26 05:50:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/26 05:50:39 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 05:50:45 visual_prompt]: Epoch 74 / 100: avg data time: 6.87e-02, avg batch time: 0.4823, average train loss: 0.2350
[09/26 05:50:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.7064
[09/26 05:50:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:50:47 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 05:50:54 visual_prompt]: Epoch 75 / 100: avg data time: 6.54e-02, avg batch time: 0.4786, average train loss: 0.2345
[09/26 05:50:55 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 0.7055
[09/26 05:50:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.00	
[09/26 05:50:56 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 05:51:02 visual_prompt]: Epoch 76 / 100: avg data time: 5.78e-02, avg batch time: 0.4708, average train loss: 0.2349
[09/26 05:51:04 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1581, average loss: 0.6786
[09/26 05:51:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 05:51:04 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 05:51:11 visual_prompt]: Epoch 77 / 100: avg data time: 6.95e-02, avg batch time: 0.4835, average train loss: 0.2340
[09/26 05:51:12 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.6846
[09/26 05:51:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.00	top5: 96.50	
[09/26 05:51:12 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 05:51:19 visual_prompt]: Epoch 78 / 100: avg data time: 6.20e-02, avg batch time: 0.4766, average train loss: 0.2349
[09/26 05:51:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1580, average loss: 0.6821
[09/26 05:51:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.00	
[09/26 05:51:21 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 05:51:27 visual_prompt]: Epoch 79 / 100: avg data time: 6.48e-02, avg batch time: 0.4786, average train loss: 0.2337
[09/26 05:51:29 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1586, average loss: 0.6820
[09/26 05:51:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:51:29 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 05:51:36 visual_prompt]: Epoch 80 / 100: avg data time: 6.77e-02, avg batch time: 0.4807, average train loss: 0.2342
[09/26 05:51:37 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1585, average loss: 0.6910
[09/26 05:51:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:51:37 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 05:51:44 visual_prompt]: Epoch 81 / 100: avg data time: 7.03e-02, avg batch time: 0.4835, average train loss: 0.2343
[09/26 05:51:46 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1584, average loss: 0.6847
[09/26 05:51:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 96.50	
[09/26 05:51:46 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 05:51:52 visual_prompt]: Epoch 82 / 100: avg data time: 7.18e-02, avg batch time: 0.4849, average train loss: 0.2344
[09/26 05:51:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1578, average loss: 0.6888
[09/26 05:51:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 90.00	top5: 97.00	
[09/26 05:51:54 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 05:52:01 visual_prompt]: Epoch 83 / 100: avg data time: 7.55e-02, avg batch time: 0.4897, average train loss: 0.2340
[09/26 05:52:03 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1584, average loss: 0.6904
[09/26 05:52:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.50	
[09/26 05:52:03 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 05:52:09 visual_prompt]: Epoch 84 / 100: avg data time: 6.19e-02, avg batch time: 0.4750, average train loss: 0.2342
[09/26 05:52:11 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1583, average loss: 0.6870
[09/26 05:52:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:52:11 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 05:52:18 visual_prompt]: Epoch 85 / 100: avg data time: 6.60e-02, avg batch time: 0.4801, average train loss: 0.2335
[09/26 05:52:19 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1586, average loss: 0.6908
[09/26 05:52:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:52:20 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 05:52:26 visual_prompt]: Epoch 86 / 100: avg data time: 6.89e-02, avg batch time: 0.4835, average train loss: 0.2338
[09/26 05:52:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1581, average loss: 0.6901
[09/26 05:52:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 95.50	
[09/26 05:52:28 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 05:52:35 visual_prompt]: Epoch 87 / 100: avg data time: 6.71e-02, avg batch time: 0.4832, average train loss: 0.2329
[09/26 05:52:36 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1586, average loss: 0.6859
[09/26 05:52:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.50	
[09/26 05:52:36 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 05:52:43 visual_prompt]: Epoch 88 / 100: avg data time: 6.14e-02, avg batch time: 0.4747, average train loss: 0.2328
[09/26 05:52:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1582, average loss: 0.6947
[09/26 05:52:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:52:45 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 05:52:51 visual_prompt]: Epoch 89 / 100: avg data time: 7.16e-02, avg batch time: 0.4848, average train loss: 0.2331
[09/26 05:52:53 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1587, average loss: 0.6845
[09/26 05:52:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.50	
[09/26 05:52:53 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 05:53:00 visual_prompt]: Epoch 90 / 100: avg data time: 7.08e-02, avg batch time: 0.4844, average train loss: 0.2325
[09/26 05:53:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1590, average loss: 0.6898
[09/26 05:53:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:02 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 05:53:08 visual_prompt]: Epoch 91 / 100: avg data time: 5.89e-02, avg batch time: 0.4739, average train loss: 0.2330
[09/26 05:53:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.6948
[09/26 05:53:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:10 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 05:53:17 visual_prompt]: Epoch 92 / 100: avg data time: 7.22e-02, avg batch time: 0.4855, average train loss: 0.2331
[09/26 05:53:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.6959
[09/26 05:53:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:18 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 05:53:25 visual_prompt]: Epoch 93 / 100: avg data time: 5.01e-02, avg batch time: 0.4650, average train loss: 0.2327
[09/26 05:53:27 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1587, average loss: 0.6934
[09/26 05:53:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:27 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 05:53:33 visual_prompt]: Epoch 94 / 100: avg data time: 7.13e-02, avg batch time: 0.4851, average train loss: 0.2329
[09/26 05:53:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1583, average loss: 0.6910
[09/26 05:53:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:35 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 05:53:42 visual_prompt]: Epoch 95 / 100: avg data time: 6.41e-02, avg batch time: 0.4783, average train loss: 0.2327
[09/26 05:53:43 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1584, average loss: 0.6903
[09/26 05:53:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:43 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 05:53:50 visual_prompt]: Epoch 96 / 100: avg data time: 6.79e-02, avg batch time: 0.4817, average train loss: 0.2329
[09/26 05:53:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 0.6898
[09/26 05:53:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:53:52 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 05:53:59 visual_prompt]: Epoch 97 / 100: avg data time: 6.65e-02, avg batch time: 0.4807, average train loss: 0.2324
[09/26 05:54:00 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 0.6890
[09/26 05:54:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:54:00 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 05:54:07 visual_prompt]: Epoch 98 / 100: avg data time: 6.60e-02, avg batch time: 0.4792, average train loss: 0.2323
[09/26 05:54:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.6890
[09/26 05:54:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:54:09 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 05:54:15 visual_prompt]: Epoch 99 / 100: avg data time: 6.93e-02, avg batch time: 0.4830, average train loss: 0.2327
[09/26 05:54:17 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1581, average loss: 0.6891
[09/26 05:54:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:54:17 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 05:54:24 visual_prompt]: Epoch 100 / 100: avg data time: 6.13e-02, avg batch time: 0.4746, average train loss: 0.2324
[09/26 05:54:25 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1583, average loss: 0.6891
[09/26 05:54:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 89.50	top5: 96.00	
[09/26 05:54:26 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:54:26 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:54:26 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:54:26 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:54:26 visual_prompt]: Training with config:
[09/26 05:54:26 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:54:26 visual_prompt]: Loading training data...
[09/26 05:54:26 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:54:27 visual_prompt]: Number of images: 800
[09/26 05:54:27 visual_prompt]: Number of classes: 102 / 102
[09/26 05:54:27 visual_prompt]: Loading validation data...
[09/26 05:54:27 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 05:54:27 visual_prompt]: Number of images: 200
[09/26 05:54:27 visual_prompt]: Number of classes: 91 / 102
[09/26 05:54:27 visual_prompt]: Constructing models...
[09/26 05:54:29 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 05:54:29 visual_prompt]: tuned percent:0.625
[09/26 05:54:29 visual_prompt]: Device used for model: 0
[09/26 05:54:29 visual_prompt]: Setting up Evaluator...
[09/26 05:54:29 visual_prompt]: Setting up Trainer...
[09/26 05:54:29 visual_prompt]: 	Setting up the optimizer...
[09/26 05:54:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:54:36 visual_prompt]: Epoch 1 / 100: avg data time: 6.82e-02, avg batch time: 0.4871, average train loss: 4.6693
[09/26 05:54:38 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1582, average loss: 4.6780
[09/26 05:54:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 05:54:38 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:54:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 05:54:44 visual_prompt]: Epoch 2 / 100: avg data time: 5.77e-02, avg batch time: 0.4725, average train loss: 4.6572
[09/26 05:54:46 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1580, average loss: 4.6490
[09/26 05:54:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 05:54:46 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:54:53 visual_prompt]: Epoch 3 / 100: avg data time: 7.15e-02, avg batch time: 0.4836, average train loss: 4.6203
[09/26 05:54:55 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1579, average loss: 4.6243
[09/26 05:54:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 4.50	
[09/26 05:54:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 05:55:01 visual_prompt]: Epoch 4 / 100: avg data time: 7.02e-02, avg batch time: 0.4821, average train loss: 4.5597
[09/26 05:55:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1583, average loss: 4.5610
[09/26 05:55:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 9.50	
[09/26 05:55:03 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 05:55:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:55:10 visual_prompt]: Epoch 5 / 100: avg data time: 7.20e-02, avg batch time: 0.4851, average train loss: 4.4377
[09/26 05:55:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 4.4593
[09/26 05:55:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 15.00	
[09/26 05:55:12 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 05:55:18 visual_prompt]: Epoch 6 / 100: avg data time: 6.26e-02, avg batch time: 0.4756, average train loss: 4.2001
[09/26 05:55:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1580, average loss: 4.1120
[09/26 05:55:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.50	top5: 27.00	
[09/26 05:55:20 visual_prompt]: Best epoch 6: best metric: 0.095
[09/26 05:55:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 05:55:27 visual_prompt]: Epoch 7 / 100: avg data time: 6.70e-02, avg batch time: 0.4799, average train loss: 3.8142
[09/26 05:55:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1583, average loss: 3.6978
[09/26 05:55:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 16.00	top5: 35.50	
[09/26 05:55:28 visual_prompt]: Best epoch 7: best metric: 0.160
[09/26 05:55:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 05:55:35 visual_prompt]: Epoch 8 / 100: avg data time: 6.77e-02, avg batch time: 0.4806, average train loss: 3.3064
[09/26 05:55:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1576, average loss: 3.4381
[09/26 05:55:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 22.50	top5: 48.00	
[09/26 05:55:37 visual_prompt]: Best epoch 8: best metric: 0.225
[09/26 05:55:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:55:43 visual_prompt]: Epoch 9 / 100: avg data time: 6.69e-02, avg batch time: 0.4795, average train loss: 2.8885
[09/26 05:55:45 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1583, average loss: 2.8482
[09/26 05:55:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 38.50	top5: 66.50	
[09/26 05:55:45 visual_prompt]: Best epoch 9: best metric: 0.385
[09/26 05:55:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 05:55:52 visual_prompt]: Epoch 10 / 100: avg data time: 6.83e-02, avg batch time: 0.4807, average train loss: 2.3016
[09/26 05:55:53 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1580, average loss: 2.4607
[09/26 05:55:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 44.50	top5: 76.00	
[09/26 05:55:53 visual_prompt]: Best epoch 10: best metric: 0.445
[09/26 05:55:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 05:56:00 visual_prompt]: Epoch 11 / 100: avg data time: 7.04e-02, avg batch time: 0.4823, average train loss: 1.7833
[09/26 05:56:02 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1574, average loss: 2.0444
[09/26 05:56:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 58.00	top5: 80.00	
[09/26 05:56:02 visual_prompt]: Best epoch 11: best metric: 0.580
[09/26 05:56:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 05:56:09 visual_prompt]: Epoch 12 / 100: avg data time: 6.94e-02, avg batch time: 0.4821, average train loss: 1.3178
[09/26 05:56:10 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1578, average loss: 1.7465
[09/26 05:56:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 62.00	top5: 87.00	
[09/26 05:56:10 visual_prompt]: Best epoch 12: best metric: 0.620
[09/26 05:56:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 05:56:17 visual_prompt]: Epoch 13 / 100: avg data time: 6.48e-02, avg batch time: 0.4774, average train loss: 0.9479
[09/26 05:56:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1579, average loss: 1.4655
[09/26 05:56:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 66.00	top5: 86.00	
[09/26 05:56:19 visual_prompt]: Best epoch 13: best metric: 0.660
[09/26 05:56:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 05:56:25 visual_prompt]: Epoch 14 / 100: avg data time: 6.21e-02, avg batch time: 0.4753, average train loss: 0.6873
[09/26 05:56:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 1.2873
[09/26 05:56:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.50	top5: 90.50	
[09/26 05:56:27 visual_prompt]: Best epoch 14: best metric: 0.745
[09/26 05:56:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 05:56:34 visual_prompt]: Epoch 15 / 100: avg data time: 6.79e-02, avg batch time: 0.4809, average train loss: 0.5087
[09/26 05:56:35 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 1.1494
[09/26 05:56:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 92.50	
[09/26 05:56:35 visual_prompt]: Best epoch 15: best metric: 0.755
[09/26 05:56:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 05:56:42 visual_prompt]: Epoch 16 / 100: avg data time: 6.06e-02, avg batch time: 0.4734, average train loss: 0.3692
[09/26 05:56:44 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1586, average loss: 1.0707
[09/26 05:56:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.50	top5: 92.00	
[09/26 05:56:44 visual_prompt]: Best epoch 16: best metric: 0.765
[09/26 05:56:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 05:56:50 visual_prompt]: Epoch 17 / 100: avg data time: 6.51e-02, avg batch time: 0.4776, average train loss: 0.2811
[09/26 05:56:52 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1585, average loss: 1.0191
[09/26 05:56:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 92.00	
[09/26 05:56:52 visual_prompt]: Best epoch 17: best metric: 0.785
[09/26 05:56:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 05:56:59 visual_prompt]: Epoch 18 / 100: avg data time: 6.08e-02, avg batch time: 0.4737, average train loss: 0.2302
[09/26 05:57:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1581, average loss: 0.9976
[09/26 05:57:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.50	top5: 91.50	
[09/26 05:57:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 05:57:07 visual_prompt]: Epoch 19 / 100: avg data time: 6.80e-02, avg batch time: 0.4802, average train loss: 0.1845
[09/26 05:57:09 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1580, average loss: 0.9631
[09/26 05:57:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.00	top5: 93.00	
[09/26 05:57:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 05:57:15 visual_prompt]: Epoch 20 / 100: avg data time: 6.57e-02, avg batch time: 0.4781, average train loss: 0.1468
[09/26 05:57:17 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1574, average loss: 0.8923
[09/26 05:57:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 92.00	
[09/26 05:57:17 visual_prompt]: Best epoch 20: best metric: 0.790
[09/26 05:57:17 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 05:57:24 visual_prompt]: Epoch 21 / 100: avg data time: 7.24e-02, avg batch time: 0.4846, average train loss: 0.1247
[09/26 05:57:26 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1583, average loss: 0.8558
[09/26 05:57:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 92.00	
[09/26 05:57:26 visual_prompt]: Best epoch 21: best metric: 0.805
[09/26 05:57:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 05:57:32 visual_prompt]: Epoch 22 / 100: avg data time: 6.54e-02, avg batch time: 0.4779, average train loss: 0.1069
[09/26 05:57:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1586, average loss: 0.8524
[09/26 05:57:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 93.00	
[09/26 05:57:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 05:57:41 visual_prompt]: Epoch 23 / 100: avg data time: 6.78e-02, avg batch time: 0.4809, average train loss: 0.0925
[09/26 05:57:42 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1584, average loss: 0.8419
[09/26 05:57:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 93.50	
[09/26 05:57:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 05:57:49 visual_prompt]: Epoch 24 / 100: avg data time: 6.79e-02, avg batch time: 0.4820, average train loss: 0.0852
[09/26 05:57:51 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1579, average loss: 0.8308
[09/26 05:57:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 93.50	
[09/26 05:57:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 05:57:57 visual_prompt]: Epoch 25 / 100: avg data time: 6.88e-02, avg batch time: 0.4811, average train loss: 0.0785
[09/26 05:57:59 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1580, average loss: 0.8295
[09/26 05:57:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.00	
[09/26 05:57:59 visual_prompt]: Best epoch 25: best metric: 0.815
[09/26 05:57:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 05:58:06 visual_prompt]: Epoch 26 / 100: avg data time: 5.63e-02, avg batch time: 0.4711, average train loss: 0.0752
[09/26 05:58:07 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1589, average loss: 0.8163
[09/26 05:58:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 05:58:07 visual_prompt]: Best epoch 26: best metric: 0.825
[09/26 05:58:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 05:58:14 visual_prompt]: Epoch 27 / 100: avg data time: 6.72e-02, avg batch time: 0.4804, average train loss: 0.0679
[09/26 05:58:16 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1584, average loss: 0.8058
[09/26 05:58:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.00	
[09/26 05:58:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 05:58:22 visual_prompt]: Epoch 28 / 100: avg data time: 6.78e-02, avg batch time: 0.4800, average train loss: 0.0651
[09/26 05:58:24 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1581, average loss: 0.7999
[09/26 05:58:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 93.00	
[09/26 05:58:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 05:58:31 visual_prompt]: Epoch 29 / 100: avg data time: 6.96e-02, avg batch time: 0.4829, average train loss: 0.0608
[09/26 05:58:33 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1582, average loss: 0.8163
[09/26 05:58:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 92.50	
[09/26 05:58:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 05:58:39 visual_prompt]: Epoch 30 / 100: avg data time: 6.18e-02, avg batch time: 0.4749, average train loss: 0.0634
[09/26 05:58:41 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1584, average loss: 0.8029
[09/26 05:58:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.50	
[09/26 05:58:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 05:58:47 visual_prompt]: Epoch 31 / 100: avg data time: 5.98e-02, avg batch time: 0.4745, average train loss: 0.0563
[09/26 05:58:49 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1583, average loss: 0.8108
[09/26 05:58:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 93.00	
[09/26 05:58:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 05:58:56 visual_prompt]: Epoch 32 / 100: avg data time: 6.41e-02, avg batch time: 0.4770, average train loss: 0.0549
[09/26 05:58:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1584, average loss: 0.8068
[09/26 05:58:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 93.00	
[09/26 05:58:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 05:59:04 visual_prompt]: Epoch 33 / 100: avg data time: 6.46e-02, avg batch time: 0.4776, average train loss: 0.0521
[09/26 05:59:06 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1579, average loss: 0.8045
[09/26 05:59:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 93.50	
[09/26 05:59:06 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 05:59:13 visual_prompt]: Epoch 34 / 100: avg data time: 6.40e-02, avg batch time: 0.4789, average train loss: 0.0506
[09/26 05:59:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1579, average loss: 0.7997
[09/26 05:59:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.00	
[09/26 05:59:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 05:59:21 visual_prompt]: Epoch 35 / 100: avg data time: 7.01e-02, avg batch time: 0.4827, average train loss: 0.0505
[09/26 05:59:23 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.8023
[09/26 05:59:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.50	
[09/26 05:59:23 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 05:59:29 visual_prompt]: Epoch 36 / 100: avg data time: 5.87e-02, avg batch time: 0.4733, average train loss: 0.0478
[09/26 05:59:31 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1581, average loss: 0.7997
[09/26 05:59:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.00	
[09/26 05:59:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 05:59:38 visual_prompt]: Epoch 37 / 100: avg data time: 6.71e-02, avg batch time: 0.4804, average train loss: 0.0453
[09/26 05:59:40 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1582, average loss: 0.7803
[09/26 05:59:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 94.50	
[09/26 05:59:40 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 05:59:46 visual_prompt]: Epoch 38 / 100: avg data time: 6.72e-02, avg batch time: 0.4800, average train loss: 0.0443
[09/26 05:59:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1586, average loss: 0.7733
[09/26 05:59:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 94.00	
[09/26 05:59:48 visual_prompt]: Best epoch 38: best metric: 0.830
[09/26 05:59:48 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 05:59:55 visual_prompt]: Epoch 39 / 100: avg data time: 6.54e-02, avg batch time: 0.4788, average train loss: 0.0444
[09/26 05:59:56 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1584, average loss: 0.7723
[09/26 05:59:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.00	
[09/26 05:59:56 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:00:03 visual_prompt]: Epoch 40 / 100: avg data time: 7.05e-02, avg batch time: 0.4830, average train loss: 0.0432
[09/26 06:00:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1583, average loss: 0.7701
[09/26 06:00:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/26 06:00:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:00:11 visual_prompt]: Epoch 41 / 100: avg data time: 5.95e-02, avg batch time: 0.4726, average train loss: 0.0419
[09/26 06:00:13 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 0.7679
[09/26 06:00:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.00	
[09/26 06:00:13 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:00:20 visual_prompt]: Epoch 42 / 100: avg data time: 6.76e-02, avg batch time: 0.4817, average train loss: 0.0415
[09/26 06:00:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1581, average loss: 0.7658
[09/26 06:00:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:00:21 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:00:28 visual_prompt]: Epoch 43 / 100: avg data time: 6.44e-02, avg batch time: 0.4772, average train loss: 0.0412
[09/26 06:00:30 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1576, average loss: 0.7591
[09/26 06:00:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.50	
[09/26 06:00:30 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:00:36 visual_prompt]: Epoch 44 / 100: avg data time: 6.33e-02, avg batch time: 0.4771, average train loss: 0.0397
[09/26 06:00:38 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1588, average loss: 0.7634
[09/26 06:00:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.50	
[09/26 06:00:38 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:00:45 visual_prompt]: Epoch 45 / 100: avg data time: 5.94e-02, avg batch time: 0.4720, average train loss: 0.0401
[09/26 06:00:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1578, average loss: 0.7651
[09/26 06:00:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 94.00	
[09/26 06:00:46 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:00:53 visual_prompt]: Epoch 46 / 100: avg data time: 6.67e-02, avg batch time: 0.4802, average train loss: 0.0394
[09/26 06:00:55 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.7669
[09/26 06:00:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:00:55 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:01:01 visual_prompt]: Epoch 47 / 100: avg data time: 6.09e-02, avg batch time: 0.4746, average train loss: 0.0385
[09/26 06:01:03 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1594, average loss: 0.7648
[09/26 06:01:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 94.00	
[09/26 06:01:03 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:01:10 visual_prompt]: Epoch 48 / 100: avg data time: 6.72e-02, avg batch time: 0.4805, average train loss: 0.0383
[09/26 06:01:11 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1584, average loss: 0.7631
[09/26 06:01:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/26 06:01:11 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:01:18 visual_prompt]: Epoch 49 / 100: avg data time: 6.53e-02, avg batch time: 0.4785, average train loss: 0.0381
[09/26 06:01:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1580, average loss: 0.7651
[09/26 06:01:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 94.50	
[09/26 06:01:20 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:01:27 visual_prompt]: Epoch 50 / 100: avg data time: 6.82e-02, avg batch time: 0.4823, average train loss: 0.0374
[09/26 06:01:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1580, average loss: 0.7578
[09/26 06:01:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.00	
[09/26 06:01:28 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:01:35 visual_prompt]: Epoch 51 / 100: avg data time: 6.10e-02, avg batch time: 0.4735, average train loss: 0.0372
[09/26 06:01:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1582, average loss: 0.7467
[09/26 06:01:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:01:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:01:43 visual_prompt]: Epoch 52 / 100: avg data time: 6.51e-02, avg batch time: 0.4781, average train loss: 0.0371
[09/26 06:01:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1575, average loss: 0.7512
[09/26 06:01:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 95.50	
[09/26 06:01:45 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:01:52 visual_prompt]: Epoch 53 / 100: avg data time: 6.72e-02, avg batch time: 0.4804, average train loss: 0.0367
[09/26 06:01:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1577, average loss: 0.7422
[09/26 06:01:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:01:53 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:02:00 visual_prompt]: Epoch 54 / 100: avg data time: 6.55e-02, avg batch time: 0.4806, average train loss: 0.0366
[09/26 06:02:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1576, average loss: 0.7416
[09/26 06:02:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 94.50	
[09/26 06:02:02 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:02:08 visual_prompt]: Epoch 55 / 100: avg data time: 5.56e-02, avg batch time: 0.4696, average train loss: 0.0361
[09/26 06:02:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1580, average loss: 0.7456
[09/26 06:02:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 95.00	
[09/26 06:02:10 visual_prompt]: Best epoch 55: best metric: 0.835
[09/26 06:02:10 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:02:17 visual_prompt]: Epoch 56 / 100: avg data time: 7.48e-02, avg batch time: 0.4876, average train loss: 0.0353
[09/26 06:02:19 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1586, average loss: 0.7482
[09/26 06:02:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 94.50	
[09/26 06:02:19 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:02:25 visual_prompt]: Epoch 57 / 100: avg data time: 6.77e-02, avg batch time: 0.4802, average train loss: 0.0354
[09/26 06:02:27 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1580, average loss: 0.7395
[09/26 06:02:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:02:27 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:02:34 visual_prompt]: Epoch 58 / 100: avg data time: 6.48e-02, avg batch time: 0.4789, average train loss: 0.0358
[09/26 06:02:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 0.7467
[09/26 06:02:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.00	
[09/26 06:02:35 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:02:42 visual_prompt]: Epoch 59 / 100: avg data time: 6.54e-02, avg batch time: 0.4789, average train loss: 0.0351
[09/26 06:02:44 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1577, average loss: 0.7443
[09/26 06:02:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:02:44 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:02:50 visual_prompt]: Epoch 60 / 100: avg data time: 6.83e-02, avg batch time: 0.4812, average train loss: 0.0352
[09/26 06:02:52 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1581, average loss: 0.7460
[09/26 06:02:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.00	
[09/26 06:02:52 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:02:59 visual_prompt]: Epoch 61 / 100: avg data time: 6.55e-02, avg batch time: 0.4790, average train loss: 0.0351
[09/26 06:03:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1578, average loss: 0.7495
[09/26 06:03:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:03:00 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:03:07 visual_prompt]: Epoch 62 / 100: avg data time: 6.55e-02, avg batch time: 0.4784, average train loss: 0.0338
[09/26 06:03:09 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1579, average loss: 0.7456
[09/26 06:03:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:03:09 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:03:15 visual_prompt]: Epoch 63 / 100: avg data time: 6.52e-02, avg batch time: 0.4788, average train loss: 0.0344
[09/26 06:03:17 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1582, average loss: 0.7398
[09/26 06:03:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:03:17 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:03:24 visual_prompt]: Epoch 64 / 100: avg data time: 6.33e-02, avg batch time: 0.4767, average train loss: 0.0343
[09/26 06:03:26 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1582, average loss: 0.7367
[09/26 06:03:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:03:26 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:03:32 visual_prompt]: Epoch 65 / 100: avg data time: 6.25e-02, avg batch time: 0.4758, average train loss: 0.0342
[09/26 06:03:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 0.7345
[09/26 06:03:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:03:34 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:03:40 visual_prompt]: Epoch 66 / 100: avg data time: 6.51e-02, avg batch time: 0.4786, average train loss: 0.0334
[09/26 06:03:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1579, average loss: 0.7334
[09/26 06:03:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:03:42 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:03:49 visual_prompt]: Epoch 67 / 100: avg data time: 6.64e-02, avg batch time: 0.4791, average train loss: 0.0339
[09/26 06:03:51 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1580, average loss: 0.7354
[09/26 06:03:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:03:51 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:03:57 visual_prompt]: Epoch 68 / 100: avg data time: 5.96e-02, avg batch time: 0.4740, average train loss: 0.0332
[09/26 06:03:59 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1581, average loss: 0.7341
[09/26 06:03:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:03:59 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:04:06 visual_prompt]: Epoch 69 / 100: avg data time: 5.86e-02, avg batch time: 0.4727, average train loss: 0.0342
[09/26 06:04:07 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.7304
[09/26 06:04:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 96.00	
[09/26 06:04:07 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:04:14 visual_prompt]: Epoch 70 / 100: avg data time: 6.69e-02, avg batch time: 0.4815, average train loss: 0.0332
[09/26 06:04:16 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1578, average loss: 0.7348
[09/26 06:04:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:04:16 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:04:22 visual_prompt]: Epoch 71 / 100: avg data time: 7.05e-02, avg batch time: 0.4838, average train loss: 0.0327
[09/26 06:04:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1579, average loss: 0.7399
[09/26 06:04:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:04:24 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:04:31 visual_prompt]: Epoch 72 / 100: avg data time: 6.43e-02, avg batch time: 0.4782, average train loss: 0.0332
[09/26 06:04:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1575, average loss: 0.7342
[09/26 06:04:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:04:32 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:04:39 visual_prompt]: Epoch 73 / 100: avg data time: 7.30e-02, avg batch time: 0.4860, average train loss: 0.0334
[09/26 06:04:41 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1577, average loss: 0.7305
[09/26 06:04:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:04:41 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:04:48 visual_prompt]: Epoch 74 / 100: avg data time: 6.93e-02, avg batch time: 0.4821, average train loss: 0.0329
[09/26 06:04:49 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 0.7311
[09/26 06:04:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:04:49 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:04:56 visual_prompt]: Epoch 75 / 100: avg data time: 7.01e-02, avg batch time: 0.4833, average train loss: 0.0322
[09/26 06:04:58 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1584, average loss: 0.7335
[09/26 06:04:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:04:58 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:05:04 visual_prompt]: Epoch 76 / 100: avg data time: 5.08e-02, avg batch time: 0.4657, average train loss: 0.0338
[09/26 06:05:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1585, average loss: 0.7335
[09/26 06:05:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:05:06 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:05:13 visual_prompt]: Epoch 77 / 100: avg data time: 7.09e-02, avg batch time: 0.4846, average train loss: 0.0328
[09/26 06:05:15 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1579, average loss: 0.7316
[09/26 06:05:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 95.50	
[09/26 06:05:15 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:05:21 visual_prompt]: Epoch 78 / 100: avg data time: 6.59e-02, avg batch time: 0.4805, average train loss: 0.0327
[09/26 06:05:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1582, average loss: 0.7315
[09/26 06:05:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:05:23 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:05:30 visual_prompt]: Epoch 79 / 100: avg data time: 6.32e-02, avg batch time: 0.4773, average train loss: 0.0328
[09/26 06:05:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1585, average loss: 0.7346
[09/26 06:05:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:05:31 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:05:38 visual_prompt]: Epoch 80 / 100: avg data time: 6.72e-02, avg batch time: 0.4819, average train loss: 0.0329
[09/26 06:05:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 0.7347
[09/26 06:05:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:05:40 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:05:46 visual_prompt]: Epoch 81 / 100: avg data time: 5.69e-02, avg batch time: 0.4706, average train loss: 0.0329
[09/26 06:05:48 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1579, average loss: 0.7353
[09/26 06:05:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:05:48 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:05:55 visual_prompt]: Epoch 82 / 100: avg data time: 7.03e-02, avg batch time: 0.4836, average train loss: 0.0328
[09/26 06:05:56 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1587, average loss: 0.7352
[09/26 06:05:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:05:56 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:06:03 visual_prompt]: Epoch 83 / 100: avg data time: 6.45e-02, avg batch time: 0.4794, average train loss: 0.0331
[09/26 06:06:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1580, average loss: 0.7344
[09/26 06:06:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:06:05 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:06:11 visual_prompt]: Epoch 84 / 100: avg data time: 6.77e-02, avg batch time: 0.4814, average train loss: 0.0331
[09/26 06:06:13 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.7328
[09/26 06:06:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:06:13 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:06:20 visual_prompt]: Epoch 85 / 100: avg data time: 7.15e-02, avg batch time: 0.4854, average train loss: 0.0333
[09/26 06:06:22 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1583, average loss: 0.7317
[09/26 06:06:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:06:22 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:06:28 visual_prompt]: Epoch 86 / 100: avg data time: 5.15e-02, avg batch time: 0.4651, average train loss: 0.0323
[09/26 06:06:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1582, average loss: 0.7322
[09/26 06:06:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:06:30 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:06:36 visual_prompt]: Epoch 87 / 100: avg data time: 5.29e-02, avg batch time: 0.4681, average train loss: 0.0324
[09/26 06:06:38 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1583, average loss: 0.7321
[09/26 06:06:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:06:38 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:06:45 visual_prompt]: Epoch 88 / 100: avg data time: 6.68e-02, avg batch time: 0.4822, average train loss: 0.0330
[09/26 06:06:47 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1585, average loss: 0.7329
[09/26 06:06:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 96.00	
[09/26 06:06:47 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:06:53 visual_prompt]: Epoch 89 / 100: avg data time: 6.75e-02, avg batch time: 0.4805, average train loss: 0.0329
[09/26 06:06:55 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1583, average loss: 0.7325
[09/26 06:06:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:06:55 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:07:02 visual_prompt]: Epoch 90 / 100: avg data time: 7.15e-02, avg batch time: 0.4857, average train loss: 0.0329
[09/26 06:07:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1585, average loss: 0.7324
[09/26 06:07:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:03 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:07:10 visual_prompt]: Epoch 91 / 100: avg data time: 5.81e-02, avg batch time: 0.4737, average train loss: 0.0323
[09/26 06:07:12 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1584, average loss: 0.7329
[09/26 06:07:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:12 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:07:18 visual_prompt]: Epoch 92 / 100: avg data time: 6.93e-02, avg batch time: 0.4830, average train loss: 0.0324
[09/26 06:07:20 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1585, average loss: 0.7327
[09/26 06:07:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:20 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:07:27 visual_prompt]: Epoch 93 / 100: avg data time: 7.59e-02, avg batch time: 0.4892, average train loss: 0.0323
[09/26 06:07:29 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1584, average loss: 0.7326
[09/26 06:07:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:29 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:07:35 visual_prompt]: Epoch 94 / 100: avg data time: 6.84e-02, avg batch time: 0.4827, average train loss: 0.0318
[09/26 06:07:37 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1587, average loss: 0.7324
[09/26 06:07:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:37 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:07:44 visual_prompt]: Epoch 95 / 100: avg data time: 5.90e-02, avg batch time: 0.4731, average train loss: 0.0325
[09/26 06:07:45 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1587, average loss: 0.7323
[09/26 06:07:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:45 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:07:52 visual_prompt]: Epoch 96 / 100: avg data time: 7.01e-02, avg batch time: 0.4830, average train loss: 0.0325
[09/26 06:07:54 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1582, average loss: 0.7322
[09/26 06:07:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:07:54 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:08:00 visual_prompt]: Epoch 97 / 100: avg data time: 6.80e-02, avg batch time: 0.4813, average train loss: 0.0320
[09/26 06:08:02 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1581, average loss: 0.7322
[09/26 06:08:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:08:02 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:08:09 visual_prompt]: Epoch 98 / 100: avg data time: 7.04e-02, avg batch time: 0.4844, average train loss: 0.0323
[09/26 06:08:11 visual_prompt]: Inference (val):avg data time: 5.02e-05, avg batch time: 0.1583, average loss: 0.7322
[09/26 06:08:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:08:11 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:08:17 visual_prompt]: Epoch 99 / 100: avg data time: 6.42e-02, avg batch time: 0.4782, average train loss: 0.0325
[09/26 06:08:19 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1584, average loss: 0.7322
[09/26 06:08:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:08:19 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:08:26 visual_prompt]: Epoch 100 / 100: avg data time: 6.97e-02, avg batch time: 0.4844, average train loss: 0.0321
[09/26 06:08:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1585, average loss: 0.7322
[09/26 06:08:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 95.50	
[09/26 06:08:28 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:08:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:08:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:08:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:08:28 visual_prompt]: Training with config:
[09/26 06:08:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:08:28 visual_prompt]: Loading training data...
[09/26 06:08:28 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 06:08:29 visual_prompt]: Number of images: 800
[09/26 06:08:29 visual_prompt]: Number of classes: 102 / 102
[09/26 06:08:29 visual_prompt]: Loading validation data...
[09/26 06:08:29 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 06:08:29 visual_prompt]: Number of images: 200
[09/26 06:08:29 visual_prompt]: Number of classes: 91 / 102
[09/26 06:08:29 visual_prompt]: Constructing models...
[09/26 06:08:31 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 06:08:31 visual_prompt]: tuned percent:0.625
[09/26 06:08:32 visual_prompt]: Device used for model: 0
[09/26 06:08:32 visual_prompt]: Setting up Evaluator...
[09/26 06:08:32 visual_prompt]: Setting up Trainer...
[09/26 06:08:32 visual_prompt]: 	Setting up the optimizer...
[09/26 06:08:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:08:38 visual_prompt]: Epoch 1 / 100: avg data time: 6.92e-02, avg batch time: 0.4895, average train loss: 4.6675
[09/26 06:08:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1580, average loss: 4.6780
[09/26 06:08:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 06:08:40 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 06:08:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 06:08:47 visual_prompt]: Epoch 2 / 100: avg data time: 6.45e-02, avg batch time: 0.4771, average train loss: 4.6580
[09/26 06:08:48 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1583, average loss: 4.6491
[09/26 06:08:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 06:08:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 06:08:55 visual_prompt]: Epoch 3 / 100: avg data time: 6.98e-02, avg batch time: 0.4846, average train loss: 4.6288
[09/26 06:08:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 4.6186
[09/26 06:08:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 6.50	
[09/26 06:08:57 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 06:08:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 06:09:03 visual_prompt]: Epoch 4 / 100: avg data time: 4.98e-02, avg batch time: 0.4647, average train loss: 4.5691
[09/26 06:09:05 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1589, average loss: 4.5694
[09/26 06:09:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 9.00	
[09/26 06:09:05 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 06:09:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 06:09:12 visual_prompt]: Epoch 5 / 100: avg data time: 6.80e-02, avg batch time: 0.4820, average train loss: 4.4774
[09/26 06:09:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1581, average loss: 4.4582
[09/26 06:09:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.00	top5: 16.00	
[09/26 06:09:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 06:09:20 visual_prompt]: Epoch 6 / 100: avg data time: 5.99e-02, avg batch time: 0.4732, average train loss: 4.2885
[09/26 06:09:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1586, average loss: 4.3228
[09/26 06:09:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 8.00	top5: 18.50	
[09/26 06:09:22 visual_prompt]: Best epoch 6: best metric: 0.080
[09/26 06:09:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 06:09:28 visual_prompt]: Epoch 7 / 100: avg data time: 6.30e-02, avg batch time: 0.4771, average train loss: 3.9735
[09/26 06:09:30 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1585, average loss: 3.9154
[09/26 06:09:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 12.50	top5: 34.50	
[09/26 06:09:30 visual_prompt]: Best epoch 7: best metric: 0.125
[09/26 06:09:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 06:09:37 visual_prompt]: Epoch 8 / 100: avg data time: 7.60e-02, avg batch time: 0.4894, average train loss: 3.4866
[09/26 06:09:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1584, average loss: 3.3775
[09/26 06:09:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 24.00	top5: 42.50	
[09/26 06:09:39 visual_prompt]: Best epoch 8: best metric: 0.240
[09/26 06:09:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 06:09:45 visual_prompt]: Epoch 9 / 100: avg data time: 6.78e-02, avg batch time: 0.4830, average train loss: 2.9554
[09/26 06:09:47 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1581, average loss: 3.0007
[09/26 06:09:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 30.00	top5: 60.50	
[09/26 06:09:47 visual_prompt]: Best epoch 9: best metric: 0.300
[09/26 06:09:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 06:09:54 visual_prompt]: Epoch 10 / 100: avg data time: 6.64e-02, avg batch time: 0.4801, average train loss: 2.3952
[09/26 06:09:55 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1589, average loss: 2.3652
[09/26 06:09:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 49.50	top5: 75.00	
[09/26 06:09:55 visual_prompt]: Best epoch 10: best metric: 0.495
[09/26 06:09:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 06:10:02 visual_prompt]: Epoch 11 / 100: avg data time: 6.57e-02, avg batch time: 0.4803, average train loss: 1.8394
[09/26 06:10:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1577, average loss: 2.0131
[09/26 06:10:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 56.50	top5: 83.00	
[09/26 06:10:04 visual_prompt]: Best epoch 11: best metric: 0.565
[09/26 06:10:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 06:10:10 visual_prompt]: Epoch 12 / 100: avg data time: 5.83e-02, avg batch time: 0.4747, average train loss: 1.3283
[09/26 06:10:12 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1588, average loss: 1.6977
[09/26 06:10:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 65.50	top5: 87.00	
[09/26 06:10:12 visual_prompt]: Best epoch 12: best metric: 0.655
[09/26 06:10:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 06:10:19 visual_prompt]: Epoch 13 / 100: avg data time: 6.94e-02, avg batch time: 0.4849, average train loss: 0.9240
[09/26 06:10:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1585, average loss: 1.4046
[09/26 06:10:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 70.50	top5: 90.00	
[09/26 06:10:21 visual_prompt]: Best epoch 13: best metric: 0.705
[09/26 06:10:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 06:10:27 visual_prompt]: Epoch 14 / 100: avg data time: 6.64e-02, avg batch time: 0.4804, average train loss: 0.6474
[09/26 06:10:29 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1582, average loss: 1.2904
[09/26 06:10:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.00	top5: 89.50	
[09/26 06:10:29 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 06:10:36 visual_prompt]: Epoch 15 / 100: avg data time: 5.85e-02, avg batch time: 0.4746, average train loss: 0.4597
[09/26 06:10:37 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 1.1257
[09/26 06:10:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 74.00	top5: 91.50	
[09/26 06:10:37 visual_prompt]: Best epoch 15: best metric: 0.740
[09/26 06:10:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 06:10:44 visual_prompt]: Epoch 16 / 100: avg data time: 6.11e-02, avg batch time: 0.4763, average train loss: 0.3402
[09/26 06:10:46 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1588, average loss: 1.0773
[09/26 06:10:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 75.50	top5: 92.50	
[09/26 06:10:46 visual_prompt]: Best epoch 16: best metric: 0.755
[09/26 06:10:46 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 06:10:52 visual_prompt]: Epoch 17 / 100: avg data time: 6.72e-02, avg batch time: 0.4820, average train loss: 0.2530
[09/26 06:10:54 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1585, average loss: 1.0405
[09/26 06:10:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 76.00	top5: 92.00	
[09/26 06:10:54 visual_prompt]: Best epoch 17: best metric: 0.760
[09/26 06:10:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 06:11:01 visual_prompt]: Epoch 18 / 100: avg data time: 6.56e-02, avg batch time: 0.4796, average train loss: 0.1980
[09/26 06:11:03 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1586, average loss: 0.9732
[09/26 06:11:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 91.50	
[09/26 06:11:03 visual_prompt]: Best epoch 18: best metric: 0.785
[09/26 06:11:03 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 06:11:09 visual_prompt]: Epoch 19 / 100: avg data time: 5.17e-02, avg batch time: 0.4664, average train loss: 0.1611
[09/26 06:11:11 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1585, average loss: 0.9861
[09/26 06:11:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 92.00	
[09/26 06:11:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 06:11:18 visual_prompt]: Epoch 20 / 100: avg data time: 7.22e-02, avg batch time: 0.4862, average train loss: 0.1335
[09/26 06:11:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1587, average loss: 0.9093
[09/26 06:11:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.50	top5: 93.50	
[09/26 06:11:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 06:11:26 visual_prompt]: Epoch 21 / 100: avg data time: 6.70e-02, avg batch time: 0.4815, average train loss: 0.1114
[09/26 06:11:28 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1580, average loss: 0.8952
[09/26 06:11:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 94.00	
[09/26 06:11:28 visual_prompt]: Best epoch 21: best metric: 0.800
[09/26 06:11:28 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 06:11:34 visual_prompt]: Epoch 22 / 100: avg data time: 6.86e-02, avg batch time: 0.4827, average train loss: 0.0901
[09/26 06:11:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1582, average loss: 0.8693
[09/26 06:11:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 93.00	
[09/26 06:11:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 06:11:43 visual_prompt]: Epoch 23 / 100: avg data time: 5.80e-02, avg batch time: 0.4745, average train loss: 0.0824
[09/26 06:11:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1581, average loss: 0.8559
[09/26 06:11:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 78.00	top5: 93.00	
[09/26 06:11:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 06:11:51 visual_prompt]: Epoch 24 / 100: avg data time: 6.86e-02, avg batch time: 0.4839, average train loss: 0.0758
[09/26 06:11:53 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1581, average loss: 0.8515
[09/26 06:11:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 94.00	
[09/26 06:11:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 06:12:00 visual_prompt]: Epoch 25 / 100: avg data time: 6.92e-02, avg batch time: 0.4831, average train loss: 0.0650
[09/26 06:12:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1583, average loss: 0.8701
[09/26 06:12:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 93.00	
[09/26 06:12:01 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 06:12:08 visual_prompt]: Epoch 26 / 100: avg data time: 6.00e-02, avg batch time: 0.4743, average train loss: 0.0609
[09/26 06:12:10 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.8102
[09/26 06:12:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 93.50	
[09/26 06:12:10 visual_prompt]: Best epoch 26: best metric: 0.805
[09/26 06:12:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 06:12:16 visual_prompt]: Epoch 27 / 100: avg data time: 6.00e-02, avg batch time: 0.4753, average train loss: 0.0577
[09/26 06:12:18 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1585, average loss: 0.8108
[09/26 06:12:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 94.00	
[09/26 06:12:18 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 06:12:25 visual_prompt]: Epoch 28 / 100: avg data time: 7.21e-02, avg batch time: 0.4862, average train loss: 0.0522
[09/26 06:12:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1581, average loss: 0.8031
[09/26 06:12:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 94.00	
[09/26 06:12:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 06:12:33 visual_prompt]: Epoch 29 / 100: avg data time: 6.63e-02, avg batch time: 0.4803, average train loss: 0.0479
[09/26 06:12:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.8119
[09/26 06:12:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 93.00	
[09/26 06:12:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 06:12:41 visual_prompt]: Epoch 30 / 100: avg data time: 5.27e-02, avg batch time: 0.4663, average train loss: 0.0445
[09/26 06:12:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 0.7979
[09/26 06:12:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.00	
[09/26 06:12:43 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 06:12:50 visual_prompt]: Epoch 31 / 100: avg data time: 6.18e-02, avg batch time: 0.4762, average train loss: 0.0414
[09/26 06:12:51 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1579, average loss: 0.7731
[09/26 06:12:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 93.50	
[09/26 06:12:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 06:12:58 visual_prompt]: Epoch 32 / 100: avg data time: 5.61e-02, avg batch time: 0.4715, average train loss: 0.0403
[09/26 06:13:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 0.7825
[09/26 06:13:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 93.50	
[09/26 06:13:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 06:13:06 visual_prompt]: Epoch 33 / 100: avg data time: 6.62e-02, avg batch time: 0.4801, average train loss: 0.0365
[09/26 06:13:08 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1584, average loss: 0.7856
[09/26 06:13:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 93.00	
[09/26 06:13:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 06:13:15 visual_prompt]: Epoch 34 / 100: avg data time: 6.01e-02, avg batch time: 0.4760, average train loss: 0.0347
[09/26 06:13:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1584, average loss: 0.7696
[09/26 06:13:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 06:13:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 06:13:23 visual_prompt]: Epoch 35 / 100: avg data time: 6.55e-02, avg batch time: 0.4791, average train loss: 0.0346
[09/26 06:13:25 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1581, average loss: 0.7891
[09/26 06:13:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 94.50	
[09/26 06:13:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 06:13:31 visual_prompt]: Epoch 36 / 100: avg data time: 5.16e-02, avg batch time: 0.4668, average train loss: 0.0323
[09/26 06:13:33 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.7919
[09/26 06:13:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 93.50	
[09/26 06:13:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 06:13:40 visual_prompt]: Epoch 37 / 100: avg data time: 6.66e-02, avg batch time: 0.4791, average train loss: 0.0311
[09/26 06:13:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1578, average loss: 0.7687
[09/26 06:13:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 93.50	
[09/26 06:13:41 visual_prompt]: Best epoch 37: best metric: 0.810
[09/26 06:13:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 06:13:48 visual_prompt]: Epoch 38 / 100: avg data time: 6.51e-02, avg batch time: 0.4788, average train loss: 0.0297
[09/26 06:13:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1580, average loss: 0.7718
[09/26 06:13:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 93.50	
[09/26 06:13:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 06:13:56 visual_prompt]: Epoch 39 / 100: avg data time: 6.47e-02, avg batch time: 0.4780, average train loss: 0.0288
[09/26 06:13:58 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1580, average loss: 0.7726
[09/26 06:13:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 93.50	
[09/26 06:13:58 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:14:05 visual_prompt]: Epoch 40 / 100: avg data time: 5.79e-02, avg batch time: 0.4712, average train loss: 0.0286
[09/26 06:14:06 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1580, average loss: 0.7661
[09/26 06:14:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.00	
[09/26 06:14:06 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:14:13 visual_prompt]: Epoch 41 / 100: avg data time: 6.24e-02, avg batch time: 0.4748, average train loss: 0.0270
[09/26 06:14:15 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1582, average loss: 0.7787
[09/26 06:14:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 94.00	
[09/26 06:14:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:14:21 visual_prompt]: Epoch 42 / 100: avg data time: 6.60e-02, avg batch time: 0.4782, average train loss: 0.0263
[09/26 06:14:23 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 0.7672
[09/26 06:14:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 93.50	
[09/26 06:14:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:14:30 visual_prompt]: Epoch 43 / 100: avg data time: 6.53e-02, avg batch time: 0.4780, average train loss: 0.0256
[09/26 06:14:32 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1583, average loss: 0.7682
[09/26 06:14:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.00	
[09/26 06:14:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:14:38 visual_prompt]: Epoch 44 / 100: avg data time: 6.08e-02, avg batch time: 0.4737, average train loss: 0.0251
[09/26 06:14:40 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1579, average loss: 0.7618
[09/26 06:14:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:14:40 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:14:47 visual_prompt]: Epoch 45 / 100: avg data time: 6.73e-02, avg batch time: 0.4803, average train loss: 0.0248
[09/26 06:14:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1581, average loss: 0.7645
[09/26 06:14:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.00	
[09/26 06:14:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:14:55 visual_prompt]: Epoch 46 / 100: avg data time: 6.17e-02, avg batch time: 0.4756, average train loss: 0.0239
[09/26 06:14:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1580, average loss: 0.7583
[09/26 06:14:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:14:57 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:15:03 visual_prompt]: Epoch 47 / 100: avg data time: 6.19e-02, avg batch time: 0.4745, average train loss: 0.0237
[09/26 06:15:05 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1584, average loss: 0.7507
[09/26 06:15:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 06:15:05 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:15:12 visual_prompt]: Epoch 48 / 100: avg data time: 6.51e-02, avg batch time: 0.4788, average train loss: 0.0229
[09/26 06:15:13 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1581, average loss: 0.7526
[09/26 06:15:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 95.50	
[09/26 06:15:13 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:15:20 visual_prompt]: Epoch 49 / 100: avg data time: 6.76e-02, avg batch time: 0.4801, average train loss: 0.0233
[09/26 06:15:22 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1582, average loss: 0.7548
[09/26 06:15:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.00	
[09/26 06:15:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:15:28 visual_prompt]: Epoch 50 / 100: avg data time: 6.47e-02, avg batch time: 0.4782, average train loss: 0.0231
[09/26 06:15:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1578, average loss: 0.7580
[09/26 06:15:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.50	
[09/26 06:15:30 visual_prompt]: Best epoch 50: best metric: 0.815
[09/26 06:15:30 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:15:37 visual_prompt]: Epoch 51 / 100: avg data time: 7.04e-02, avg batch time: 0.4829, average train loss: 0.0221
[09/26 06:15:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1585, average loss: 0.7576
[09/26 06:15:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:15:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:15:45 visual_prompt]: Epoch 52 / 100: avg data time: 5.87e-02, avg batch time: 0.4712, average train loss: 0.0214
[09/26 06:15:47 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1580, average loss: 0.7522
[09/26 06:15:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:15:47 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:15:54 visual_prompt]: Epoch 53 / 100: avg data time: 6.77e-02, avg batch time: 0.4815, average train loss: 0.0216
[09/26 06:15:55 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1580, average loss: 0.7498
[09/26 06:15:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 94.50	
[09/26 06:15:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:16:02 visual_prompt]: Epoch 54 / 100: avg data time: 7.23e-02, avg batch time: 0.4851, average train loss: 0.0212
[09/26 06:16:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1582, average loss: 0.7525
[09/26 06:16:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.50	top5: 95.00	
[09/26 06:16:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:16:10 visual_prompt]: Epoch 55 / 100: avg data time: 6.96e-02, avg batch time: 0.4830, average train loss: 0.0198
[09/26 06:16:12 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1578, average loss: 0.7532
[09/26 06:16:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:16:12 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:16:19 visual_prompt]: Epoch 56 / 100: avg data time: 7.05e-02, avg batch time: 0.4829, average train loss: 0.0202
[09/26 06:16:21 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1578, average loss: 0.7504
[09/26 06:16:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:16:21 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:16:27 visual_prompt]: Epoch 57 / 100: avg data time: 6.39e-02, avg batch time: 0.4779, average train loss: 0.0202
[09/26 06:16:29 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1580, average loss: 0.7496
[09/26 06:16:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:16:29 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:16:36 visual_prompt]: Epoch 58 / 100: avg data time: 6.71e-02, avg batch time: 0.4795, average train loss: 0.0195
[09/26 06:16:37 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1582, average loss: 0.7505
[09/26 06:16:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 95.00	
[09/26 06:16:37 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:16:44 visual_prompt]: Epoch 59 / 100: avg data time: 6.37e-02, avg batch time: 0.4762, average train loss: 0.0200
[09/26 06:16:46 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1583, average loss: 0.7478
[09/26 06:16:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:16:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:16:52 visual_prompt]: Epoch 60 / 100: avg data time: 6.49e-02, avg batch time: 0.4768, average train loss: 0.0190
[09/26 06:16:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1583, average loss: 0.7422
[09/26 06:16:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:16:54 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:17:01 visual_prompt]: Epoch 61 / 100: avg data time: 7.09e-02, avg batch time: 0.4837, average train loss: 0.0195
[09/26 06:17:03 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1583, average loss: 0.7491
[09/26 06:17:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:17:03 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:17:09 visual_prompt]: Epoch 62 / 100: avg data time: 6.78e-02, avg batch time: 0.4798, average train loss: 0.0182
[09/26 06:17:11 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1579, average loss: 0.7587
[09/26 06:17:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.00	top5: 95.00	
[09/26 06:17:11 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:17:18 visual_prompt]: Epoch 63 / 100: avg data time: 7.33e-02, avg batch time: 0.4852, average train loss: 0.0184
[09/26 06:17:20 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1583, average loss: 0.7469
[09/26 06:17:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:17:20 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:17:26 visual_prompt]: Epoch 64 / 100: avg data time: 6.73e-02, avg batch time: 0.4803, average train loss: 0.0179
[09/26 06:17:28 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1585, average loss: 0.7431
[09/26 06:17:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.50	
[09/26 06:17:28 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:17:35 visual_prompt]: Epoch 65 / 100: avg data time: 6.61e-02, avg batch time: 0.4791, average train loss: 0.0180
[09/26 06:17:36 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1578, average loss: 0.7452
[09/26 06:17:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.50	
[09/26 06:17:36 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:17:43 visual_prompt]: Epoch 66 / 100: avg data time: 6.67e-02, avg batch time: 0.4792, average train loss: 0.0185
[09/26 06:17:45 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1578, average loss: 0.7468
[09/26 06:17:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.50	
[09/26 06:17:45 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:17:51 visual_prompt]: Epoch 67 / 100: avg data time: 6.75e-02, avg batch time: 0.4805, average train loss: 0.0182
[09/26 06:17:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1576, average loss: 0.7467
[09/26 06:17:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:17:53 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:18:00 visual_prompt]: Epoch 68 / 100: avg data time: 6.14e-02, avg batch time: 0.4744, average train loss: 0.0186
[09/26 06:18:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.7440
[09/26 06:18:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:18:01 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:18:08 visual_prompt]: Epoch 69 / 100: avg data time: 5.17e-02, avg batch time: 0.4638, average train loss: 0.0168
[09/26 06:18:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1579, average loss: 0.7422
[09/26 06:18:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.50	
[09/26 06:18:10 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:18:16 visual_prompt]: Epoch 70 / 100: avg data time: 6.14e-02, avg batch time: 0.4739, average train loss: 0.0178
[09/26 06:18:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1581, average loss: 0.7401
[09/26 06:18:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.50	
[09/26 06:18:18 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:18:25 visual_prompt]: Epoch 71 / 100: avg data time: 6.81e-02, avg batch time: 0.4800, average train loss: 0.0177
[09/26 06:18:26 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1583, average loss: 0.7419
[09/26 06:18:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 95.00	
[09/26 06:18:26 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:18:33 visual_prompt]: Epoch 72 / 100: avg data time: 6.43e-02, avg batch time: 0.4770, average train loss: 0.0183
[09/26 06:18:35 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1581, average loss: 0.7450
[09/26 06:18:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 95.00	
[09/26 06:18:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:18:41 visual_prompt]: Epoch 73 / 100: avg data time: 6.61e-02, avg batch time: 0.4784, average train loss: 0.0175
[09/26 06:18:43 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 0.7412
[09/26 06:18:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 06:18:43 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:18:50 visual_prompt]: Epoch 74 / 100: avg data time: 6.26e-02, avg batch time: 0.4752, average train loss: 0.0171
[09/26 06:18:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.7381
[09/26 06:18:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 06:18:51 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:18:58 visual_prompt]: Epoch 75 / 100: avg data time: 6.40e-02, avg batch time: 0.4762, average train loss: 0.0170
[09/26 06:19:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1581, average loss: 0.7388
[09/26 06:19:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:19:06 visual_prompt]: Epoch 76 / 100: avg data time: 6.82e-02, avg batch time: 0.4810, average train loss: 0.0173
[09/26 06:19:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 0.7417
[09/26 06:19:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 94.50	
[09/26 06:19:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:19:15 visual_prompt]: Epoch 77 / 100: avg data time: 6.48e-02, avg batch time: 0.4782, average train loss: 0.0166
[09/26 06:19:17 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1581, average loss: 0.7427
[09/26 06:19:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:19:23 visual_prompt]: Epoch 78 / 100: avg data time: 6.09e-02, avg batch time: 0.4742, average train loss: 0.0166
[09/26 06:19:25 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1580, average loss: 0.7414
[09/26 06:19:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:19:31 visual_prompt]: Epoch 79 / 100: avg data time: 5.44e-02, avg batch time: 0.4685, average train loss: 0.0169
[09/26 06:19:33 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1582, average loss: 0.7386
[09/26 06:19:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:33 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:19:40 visual_prompt]: Epoch 80 / 100: avg data time: 6.61e-02, avg batch time: 0.4783, average train loss: 0.0170
[09/26 06:19:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1584, average loss: 0.7387
[09/26 06:19:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:41 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:19:48 visual_prompt]: Epoch 81 / 100: avg data time: 7.00e-02, avg batch time: 0.4836, average train loss: 0.0171
[09/26 06:19:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1583, average loss: 0.7397
[09/26 06:19:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:50 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:19:57 visual_prompt]: Epoch 82 / 100: avg data time: 6.64e-02, avg batch time: 0.4783, average train loss: 0.0169
[09/26 06:19:58 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1580, average loss: 0.7405
[09/26 06:19:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:19:58 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:20:05 visual_prompt]: Epoch 83 / 100: avg data time: 6.81e-02, avg batch time: 0.4826, average train loss: 0.0162
[09/26 06:20:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1582, average loss: 0.7414
[09/26 06:20:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:20:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:20:13 visual_prompt]: Epoch 84 / 100: avg data time: 6.41e-02, avg batch time: 0.4766, average train loss: 0.0167
[09/26 06:20:15 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1586, average loss: 0.7409
[09/26 06:20:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:20:15 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:20:22 visual_prompt]: Epoch 85 / 100: avg data time: 6.36e-02, avg batch time: 0.4761, average train loss: 0.0164
[09/26 06:20:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1578, average loss: 0.7397
[09/26 06:20:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 95.00	
[09/26 06:20:24 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:20:30 visual_prompt]: Epoch 86 / 100: avg data time: 6.63e-02, avg batch time: 0.4801, average train loss: 0.0160
[09/26 06:20:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1587, average loss: 0.7392
[09/26 06:20:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:20:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:20:39 visual_prompt]: Epoch 87 / 100: avg data time: 7.01e-02, avg batch time: 0.4828, average train loss: 0.0162
[09/26 06:20:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1583, average loss: 0.7388
[09/26 06:20:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:20:40 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:20:47 visual_prompt]: Epoch 88 / 100: avg data time: 5.88e-02, avg batch time: 0.4726, average train loss: 0.0160
[09/26 06:20:49 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1582, average loss: 0.7388
[09/26 06:20:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:20:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:20:55 visual_prompt]: Epoch 89 / 100: avg data time: 6.73e-02, avg batch time: 0.4810, average train loss: 0.0164
[09/26 06:20:57 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1583, average loss: 0.7395
[09/26 06:20:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:20:57 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:21:04 visual_prompt]: Epoch 90 / 100: avg data time: 6.68e-02, avg batch time: 0.4806, average train loss: 0.0164
[09/26 06:21:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1579, average loss: 0.7396
[09/26 06:21:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:06 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:21:12 visual_prompt]: Epoch 91 / 100: avg data time: 7.02e-02, avg batch time: 0.4838, average train loss: 0.0164
[09/26 06:21:14 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1584, average loss: 0.7395
[09/26 06:21:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:14 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:21:21 visual_prompt]: Epoch 92 / 100: avg data time: 7.03e-02, avg batch time: 0.4846, average train loss: 0.0158
[09/26 06:21:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1580, average loss: 0.7393
[09/26 06:21:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:22 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:21:29 visual_prompt]: Epoch 93 / 100: avg data time: 6.73e-02, avg batch time: 0.4812, average train loss: 0.0161
[09/26 06:21:31 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1582, average loss: 0.7393
[09/26 06:21:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:31 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:21:38 visual_prompt]: Epoch 94 / 100: avg data time: 6.92e-02, avg batch time: 0.4829, average train loss: 0.0161
[09/26 06:21:39 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1583, average loss: 0.7393
[09/26 06:21:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:39 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:21:46 visual_prompt]: Epoch 95 / 100: avg data time: 5.52e-02, avg batch time: 0.4689, average train loss: 0.0166
[09/26 06:21:47 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1579, average loss: 0.7392
[09/26 06:21:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:21:54 visual_prompt]: Epoch 96 / 100: avg data time: 6.97e-02, avg batch time: 0.4833, average train loss: 0.0160
[09/26 06:21:56 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1579, average loss: 0.7392
[09/26 06:21:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:21:56 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:22:03 visual_prompt]: Epoch 97 / 100: avg data time: 7.14e-02, avg batch time: 0.4845, average train loss: 0.0159
[09/26 06:22:04 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1586, average loss: 0.7392
[09/26 06:22:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:22:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:22:11 visual_prompt]: Epoch 98 / 100: avg data time: 6.85e-02, avg batch time: 0.4822, average train loss: 0.0163
[09/26 06:22:13 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1584, average loss: 0.7392
[09/26 06:22:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:22:13 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:22:19 visual_prompt]: Epoch 99 / 100: avg data time: 5.76e-02, avg batch time: 0.4727, average train loss: 0.0167
[09/26 06:22:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1584, average loss: 0.7392
[09/26 06:22:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:22:21 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:22:28 visual_prompt]: Epoch 100 / 100: avg data time: 6.66e-02, avg batch time: 0.4810, average train loss: 0.0160
[09/26 06:22:29 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1582, average loss: 0.7392
[09/26 06:22:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.00	top5: 94.50	
[09/26 06:22:29 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:22:29 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:22:29 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-caltech101', 'DATA.NUMBER_CLASSES', '102', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:22:29 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:22:29 visual_prompt]: Training with config:
[09/26 06:22:29 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-caltech101/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-caltech101', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 102, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:22:29 visual_prompt]: Loading training data...
[09/26 06:22:29 visual_prompt]: Constructing vtab-caltech101 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[:800], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 06:22:31 visual_prompt]: Number of images: 800
[09/26 06:22:31 visual_prompt]: Number of classes: 102 / 102
[09/26 06:22:31 visual_prompt]: Loading validation data...
[09/26 06:22:31 visual_prompt]: Constructing vtab-caltech101 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/caltech101/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset caltech101 (visual_prompt_tuning/data_path/caltech101/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset caltech101 for split train[2754:2954], from visual_prompt_tuning/data_path/caltech101/3.0.1
[09/26 06:22:31 visual_prompt]: Number of images: 200
[09/26 06:22:31 visual_prompt]: Number of classes: 91 / 102
[09/26 06:22:31 visual_prompt]: Constructing models...
[09/26 06:22:34 visual_prompt]: Total Parameters: 86337894	 Gradient Parameters: 539238
[09/26 06:22:34 visual_prompt]: tuned percent:0.625
[09/26 06:22:34 visual_prompt]: Device used for model: 0
[09/26 06:22:34 visual_prompt]: Setting up Evaluator...
[09/26 06:22:34 visual_prompt]: Setting up Trainer...
[09/26 06:22:34 visual_prompt]: 	Setting up the optimizer...
[09/26 06:22:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:22:40 visual_prompt]: Epoch 1 / 100: avg data time: 7.19e-02, avg batch time: 0.4888, average train loss: 4.6652
[09/26 06:22:42 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1584, average loss: 4.6780
[09/26 06:22:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.00	
[09/26 06:22:42 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 06:22:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 06:22:49 visual_prompt]: Epoch 2 / 100: avg data time: 6.64e-02, avg batch time: 0.4787, average train loss: 4.6585
[09/26 06:22:50 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1583, average loss: 4.6489
[09/26 06:22:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 1.00	top5: 4.50	
[09/26 06:22:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 06:22:57 visual_prompt]: Epoch 3 / 100: avg data time: 6.46e-02, avg batch time: 0.4768, average train loss: 4.6163
[09/26 06:22:59 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1582, average loss: 4.6206
[09/26 06:22:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 0.50	top5: 5.50	
[09/26 06:22:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 06:23:05 visual_prompt]: Epoch 4 / 100: avg data time: 5.76e-02, avg batch time: 0.4718, average train loss: 4.5517
[09/26 06:23:07 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1585, average loss: 4.5772
[09/26 06:23:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 3.00	top5: 8.50	
[09/26 06:23:07 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 06:23:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 06:23:14 visual_prompt]: Epoch 5 / 100: avg data time: 6.23e-02, avg batch time: 0.4761, average train loss: 4.4835
[09/26 06:23:16 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1582, average loss: 4.4792
[09/26 06:23:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 2.50	top5: 14.50	
[09/26 06:23:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 06:23:22 visual_prompt]: Epoch 6 / 100: avg data time: 7.00e-02, avg batch time: 0.4834, average train loss: 4.2913
[09/26 06:23:24 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1580, average loss: 4.2667
[09/26 06:23:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 9.00	top5: 25.50	
[09/26 06:23:24 visual_prompt]: Best epoch 6: best metric: 0.090
[09/26 06:23:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 06:23:31 visual_prompt]: Epoch 7 / 100: avg data time: 5.76e-02, avg batch time: 0.4721, average train loss: 3.9015
[09/26 06:23:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1588, average loss: 3.7889
[09/26 06:23:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 17.50	top5: 37.00	
[09/26 06:23:32 visual_prompt]: Best epoch 7: best metric: 0.175
[09/26 06:23:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 06:23:39 visual_prompt]: Epoch 8 / 100: avg data time: 6.57e-02, avg batch time: 0.4797, average train loss: 3.3752
[09/26 06:23:41 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1579, average loss: 3.3110
[09/26 06:23:41 visual_prompt]: Classification results with val_vtab-caltech101: top1: 26.00	top5: 51.00	
[09/26 06:23:41 visual_prompt]: Best epoch 8: best metric: 0.260
[09/26 06:23:41 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 06:23:47 visual_prompt]: Epoch 9 / 100: avg data time: 6.18e-02, avg batch time: 0.4743, average train loss: 2.8316
[09/26 06:23:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1577, average loss: 2.8857
[09/26 06:23:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 36.50	top5: 64.00	
[09/26 06:23:49 visual_prompt]: Best epoch 9: best metric: 0.365
[09/26 06:23:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 06:23:56 visual_prompt]: Epoch 10 / 100: avg data time: 6.46e-02, avg batch time: 0.4781, average train loss: 2.1873
[09/26 06:23:58 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1583, average loss: 2.3672
[09/26 06:23:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 48.50	top5: 73.50	
[09/26 06:23:58 visual_prompt]: Best epoch 10: best metric: 0.485
[09/26 06:23:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 06:24:04 visual_prompt]: Epoch 11 / 100: avg data time: 6.52e-02, avg batch time: 0.4775, average train loss: 1.7055
[09/26 06:24:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1578, average loss: 1.9473
[09/26 06:24:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 56.50	top5: 82.50	
[09/26 06:24:06 visual_prompt]: Best epoch 11: best metric: 0.565
[09/26 06:24:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 06:24:13 visual_prompt]: Epoch 12 / 100: avg data time: 7.25e-02, avg batch time: 0.4859, average train loss: 1.2747
[09/26 06:24:14 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1585, average loss: 1.5966
[09/26 06:24:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 68.50	top5: 90.00	
[09/26 06:24:14 visual_prompt]: Best epoch 12: best metric: 0.685
[09/26 06:24:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 06:24:21 visual_prompt]: Epoch 13 / 100: avg data time: 6.44e-02, avg batch time: 0.4773, average train loss: 0.9009
[09/26 06:24:23 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1582, average loss: 1.3686
[09/26 06:24:23 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.00	top5: 88.50	
[09/26 06:24:23 visual_prompt]: Best epoch 13: best metric: 0.720
[09/26 06:24:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 06:24:29 visual_prompt]: Epoch 14 / 100: avg data time: 5.21e-02, avg batch time: 0.4661, average train loss: 0.6339
[09/26 06:24:31 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1577, average loss: 1.2065
[09/26 06:24:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 72.50	top5: 90.00	
[09/26 06:24:31 visual_prompt]: Best epoch 14: best metric: 0.725
[09/26 06:24:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 06:24:38 visual_prompt]: Epoch 15 / 100: avg data time: 7.28e-02, avg batch time: 0.4865, average train loss: 0.4427
[09/26 06:24:39 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1580, average loss: 1.0909
[09/26 06:24:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.00	top5: 91.50	
[09/26 06:24:39 visual_prompt]: Best epoch 15: best metric: 0.770
[09/26 06:24:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 06:24:46 visual_prompt]: Epoch 16 / 100: avg data time: 6.82e-02, avg batch time: 0.4821, average train loss: 0.3108
[09/26 06:24:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1580, average loss: 1.0104
[09/26 06:24:48 visual_prompt]: Classification results with val_vtab-caltech101: top1: 77.50	top5: 91.50	
[09/26 06:24:48 visual_prompt]: Best epoch 16: best metric: 0.775
[09/26 06:24:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 06:24:54 visual_prompt]: Epoch 17 / 100: avg data time: 6.24e-02, avg batch time: 0.4756, average train loss: 0.2407
[09/26 06:24:56 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1586, average loss: 0.9512
[09/26 06:24:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 80.50	top5: 92.50	
[09/26 06:24:56 visual_prompt]: Best epoch 17: best metric: 0.805
[09/26 06:24:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 06:25:03 visual_prompt]: Epoch 18 / 100: avg data time: 7.11e-02, avg batch time: 0.4839, average train loss: 0.1992
[09/26 06:25:05 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1584, average loss: 0.9624
[09/26 06:25:05 visual_prompt]: Classification results with val_vtab-caltech101: top1: 79.00	top5: 91.00	
[09/26 06:25:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 06:25:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.72e-02, avg batch time: 0.4714, average train loss: 0.1523
[09/26 06:25:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1581, average loss: 0.9384
[09/26 06:25:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 91.50	
[09/26 06:25:13 visual_prompt]: Best epoch 19: best metric: 0.815
[09/26 06:25:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 06:25:20 visual_prompt]: Epoch 20 / 100: avg data time: 6.25e-02, avg batch time: 0.4778, average train loss: 0.1279
[09/26 06:25:21 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1582, average loss: 0.8899
[09/26 06:25:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.00	
[09/26 06:25:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 06:25:28 visual_prompt]: Epoch 21 / 100: avg data time: 6.89e-02, avg batch time: 0.4814, average train loss: 0.1077
[09/26 06:25:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1581, average loss: 0.9186
[09/26 06:25:30 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 91.00	
[09/26 06:25:30 visual_prompt]: Best epoch 21: best metric: 0.820
[09/26 06:25:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 06:25:36 visual_prompt]: Epoch 22 / 100: avg data time: 6.19e-02, avg batch time: 0.4776, average train loss: 0.0927
[09/26 06:25:38 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1572, average loss: 0.8495
[09/26 06:25:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 93.00	
[09/26 06:25:38 visual_prompt]: Best epoch 22: best metric: 0.840
[09/26 06:25:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 06:25:45 visual_prompt]: Epoch 23 / 100: avg data time: 6.91e-02, avg batch time: 0.4824, average train loss: 0.0778
[09/26 06:25:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1578, average loss: 0.8607
[09/26 06:25:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 92.00	
[09/26 06:25:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 06:25:53 visual_prompt]: Epoch 24 / 100: avg data time: 6.83e-02, avg batch time: 0.4806, average train loss: 0.0714
[09/26 06:25:55 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1583, average loss: 0.8454
[09/26 06:25:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 92.00	
[09/26 06:25:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 06:26:01 visual_prompt]: Epoch 25 / 100: avg data time: 6.28e-02, avg batch time: 0.4761, average train loss: 0.0637
[09/26 06:26:03 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1577, average loss: 0.8303
[09/26 06:26:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:26:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 06:26:10 visual_prompt]: Epoch 26 / 100: avg data time: 6.21e-02, avg batch time: 0.4752, average train loss: 0.0590
[09/26 06:26:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.8279
[09/26 06:26:12 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:26:12 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 06:26:18 visual_prompt]: Epoch 27 / 100: avg data time: 6.85e-02, avg batch time: 0.4817, average train loss: 0.0545
[09/26 06:26:20 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1583, average loss: 0.8264
[09/26 06:26:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:26:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 06:26:27 visual_prompt]: Epoch 28 / 100: avg data time: 6.86e-02, avg batch time: 0.4803, average train loss: 0.0512
[09/26 06:26:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1582, average loss: 0.8121
[09/26 06:26:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:26:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 06:26:35 visual_prompt]: Epoch 29 / 100: avg data time: 6.60e-02, avg batch time: 0.4782, average train loss: 0.0447
[09/26 06:26:37 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1580, average loss: 0.8103
[09/26 06:26:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 81.50	top5: 93.00	
[09/26 06:26:37 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 06:26:43 visual_prompt]: Epoch 30 / 100: avg data time: 6.69e-02, avg batch time: 0.4800, average train loss: 0.0440
[09/26 06:26:45 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1582, average loss: 0.7943
[09/26 06:26:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:26:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 06:26:52 visual_prompt]: Epoch 31 / 100: avg data time: 6.25e-02, avg batch time: 0.4752, average train loss: 0.0414
[09/26 06:26:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1582, average loss: 0.7828
[09/26 06:26:53 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.00	
[09/26 06:26:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 06:27:00 visual_prompt]: Epoch 32 / 100: avg data time: 7.33e-02, avg batch time: 0.4854, average train loss: 0.0394
[09/26 06:27:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1584, average loss: 0.7964
[09/26 06:27:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 93.50	
[09/26 06:27:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 06:27:09 visual_prompt]: Epoch 33 / 100: avg data time: 7.07e-02, avg batch time: 0.4830, average train loss: 0.0370
[09/26 06:27:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 0.7896
[09/26 06:27:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:27:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 06:27:17 visual_prompt]: Epoch 34 / 100: avg data time: 6.52e-02, avg batch time: 0.4780, average train loss: 0.0343
[09/26 06:27:19 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1585, average loss: 0.7897
[09/26 06:27:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:27:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 06:27:25 visual_prompt]: Epoch 35 / 100: avg data time: 6.23e-02, avg batch time: 0.4760, average train loss: 0.0343
[09/26 06:27:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1582, average loss: 0.7861
[09/26 06:27:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 84.00	top5: 93.00	
[09/26 06:27:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 06:27:34 visual_prompt]: Epoch 36 / 100: avg data time: 6.46e-02, avg batch time: 0.4778, average train loss: 0.0317
[09/26 06:27:35 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1581, average loss: 0.7796
[09/26 06:27:35 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 92.50	
[09/26 06:27:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 06:27:42 visual_prompt]: Epoch 37 / 100: avg data time: 6.61e-02, avg batch time: 0.4787, average train loss: 0.0316
[09/26 06:27:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1585, average loss: 0.7802
[09/26 06:27:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 92.50	
[09/26 06:27:44 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 06:27:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.51e-02, avg batch time: 0.4701, average train loss: 0.0298
[09/26 06:27:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1579, average loss: 0.7782
[09/26 06:27:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:27:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 06:27:59 visual_prompt]: Epoch 39 / 100: avg data time: 6.43e-02, avg batch time: 0.4774, average train loss: 0.0283
[09/26 06:28:00 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1585, average loss: 0.7742
[09/26 06:28:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:28:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:28:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.48e-02, avg batch time: 0.4687, average train loss: 0.0270
[09/26 06:28:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1582, average loss: 0.7674
[09/26 06:28:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:28:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:28:15 visual_prompt]: Epoch 41 / 100: avg data time: 5.85e-02, avg batch time: 0.4733, average train loss: 0.0259
[09/26 06:28:17 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 0.7746
[09/26 06:28:17 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:28:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:28:24 visual_prompt]: Epoch 42 / 100: avg data time: 6.36e-02, avg batch time: 0.4782, average train loss: 0.0259
[09/26 06:28:25 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1579, average loss: 0.7736
[09/26 06:28:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 92.50	
[09/26 06:28:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:28:32 visual_prompt]: Epoch 43 / 100: avg data time: 6.41e-02, avg batch time: 0.4774, average train loss: 0.0242
[09/26 06:28:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1584, average loss: 0.7666
[09/26 06:28:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:28:34 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:28:40 visual_prompt]: Epoch 44 / 100: avg data time: 6.37e-02, avg batch time: 0.4767, average train loss: 0.0243
[09/26 06:28:42 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.7659
[09/26 06:28:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.00	top5: 92.50	
[09/26 06:28:42 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:28:49 visual_prompt]: Epoch 45 / 100: avg data time: 5.82e-02, avg batch time: 0.4738, average train loss: 0.0236
[09/26 06:28:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1580, average loss: 0.7671
[09/26 06:28:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:28:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:28:57 visual_prompt]: Epoch 46 / 100: avg data time: 5.44e-02, avg batch time: 0.4695, average train loss: 0.0230
[09/26 06:28:59 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1581, average loss: 0.7587
[09/26 06:28:59 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.00	
[09/26 06:28:59 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:29:05 visual_prompt]: Epoch 47 / 100: avg data time: 5.74e-02, avg batch time: 0.4704, average train loss: 0.0221
[09/26 06:29:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1583, average loss: 0.7705
[09/26 06:29:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 92.00	
[09/26 06:29:07 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:29:13 visual_prompt]: Epoch 48 / 100: avg data time: 6.28e-02, avg batch time: 0.4771, average train loss: 0.0219
[09/26 06:29:15 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1579, average loss: 0.7660
[09/26 06:29:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:29:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:29:22 visual_prompt]: Epoch 49 / 100: avg data time: 6.24e-02, avg batch time: 0.4772, average train loss: 0.0213
[09/26 06:29:24 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1586, average loss: 0.7597
[09/26 06:29:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 93.00	
[09/26 06:29:24 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:29:30 visual_prompt]: Epoch 50 / 100: avg data time: 7.12e-02, avg batch time: 0.4843, average train loss: 0.0213
[09/26 06:29:32 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1580, average loss: 0.7588
[09/26 06:29:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.00	
[09/26 06:29:32 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:29:39 visual_prompt]: Epoch 51 / 100: avg data time: 7.18e-02, avg batch time: 0.4848, average train loss: 0.0204
[09/26 06:29:40 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1585, average loss: 0.7599
[09/26 06:29:40 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:29:40 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:29:47 visual_prompt]: Epoch 52 / 100: avg data time: 6.74e-02, avg batch time: 0.4821, average train loss: 0.0196
[09/26 06:29:49 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1580, average loss: 0.7617
[09/26 06:29:49 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.00	
[09/26 06:29:49 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:29:56 visual_prompt]: Epoch 53 / 100: avg data time: 6.40e-02, avg batch time: 0.4778, average train loss: 0.0199
[09/26 06:29:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1583, average loss: 0.7600
[09/26 06:29:57 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:29:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:30:04 visual_prompt]: Epoch 54 / 100: avg data time: 6.67e-02, avg batch time: 0.4793, average train loss: 0.0196
[09/26 06:30:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1587, average loss: 0.7523
[09/26 06:30:06 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:30:06 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:30:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.20e-02, avg batch time: 0.4762, average train loss: 0.0191
[09/26 06:30:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1587, average loss: 0.7508
[09/26 06:30:14 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 93.00	
[09/26 06:30:14 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:30:21 visual_prompt]: Epoch 56 / 100: avg data time: 6.62e-02, avg batch time: 0.4795, average train loss: 0.0187
[09/26 06:30:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1584, average loss: 0.7506
[09/26 06:30:22 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.50	top5: 93.00	
[09/26 06:30:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:30:29 visual_prompt]: Epoch 57 / 100: avg data time: 5.92e-02, avg batch time: 0.4729, average train loss: 0.0181
[09/26 06:30:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1580, average loss: 0.7516
[09/26 06:30:31 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:30:31 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:30:37 visual_prompt]: Epoch 58 / 100: avg data time: 6.66e-02, avg batch time: 0.4802, average train loss: 0.0187
[09/26 06:30:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1582, average loss: 0.7459
[09/26 06:30:39 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:30:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:30:46 visual_prompt]: Epoch 59 / 100: avg data time: 6.96e-02, avg batch time: 0.4823, average train loss: 0.0181
[09/26 06:30:47 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1579, average loss: 0.7439
[09/26 06:30:47 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:30:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:30:54 visual_prompt]: Epoch 60 / 100: avg data time: 6.79e-02, avg batch time: 0.4812, average train loss: 0.0177
[09/26 06:30:56 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1580, average loss: 0.7446
[09/26 06:30:56 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:30:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:31:02 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.4744, average train loss: 0.0175
[09/26 06:31:04 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1584, average loss: 0.7512
[09/26 06:31:04 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:31:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:31:11 visual_prompt]: Epoch 62 / 100: avg data time: 6.85e-02, avg batch time: 0.4826, average train loss: 0.0175
[09/26 06:31:13 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1581, average loss: 0.7553
[09/26 06:31:13 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:31:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:31:19 visual_prompt]: Epoch 63 / 100: avg data time: 6.80e-02, avg batch time: 0.4820, average train loss: 0.0168
[09/26 06:31:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1578, average loss: 0.7529
[09/26 06:31:21 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:31:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:31:28 visual_prompt]: Epoch 64 / 100: avg data time: 6.23e-02, avg batch time: 0.4754, average train loss: 0.0169
[09/26 06:31:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1580, average loss: 0.7489
[09/26 06:31:29 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:31:29 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:31:36 visual_prompt]: Epoch 65 / 100: avg data time: 7.23e-02, avg batch time: 0.4854, average train loss: 0.0165
[09/26 06:31:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1582, average loss: 0.7462
[09/26 06:31:38 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:31:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:31:45 visual_prompt]: Epoch 66 / 100: avg data time: 6.76e-02, avg batch time: 0.4816, average train loss: 0.0169
[09/26 06:31:46 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1585, average loss: 0.7447
[09/26 06:31:46 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:31:46 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:31:53 visual_prompt]: Epoch 67 / 100: avg data time: 6.04e-02, avg batch time: 0.4731, average train loss: 0.0163
[09/26 06:31:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1583, average loss: 0.7441
[09/26 06:31:55 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:31:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:32:01 visual_prompt]: Epoch 68 / 100: avg data time: 6.28e-02, avg batch time: 0.4785, average train loss: 0.0161
[09/26 06:32:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1583, average loss: 0.7455
[09/26 06:32:03 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:32:03 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:32:10 visual_prompt]: Epoch 69 / 100: avg data time: 5.92e-02, avg batch time: 0.4724, average train loss: 0.0161
[09/26 06:32:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1578, average loss: 0.7469
[09/26 06:32:11 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:32:11 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:32:18 visual_prompt]: Epoch 70 / 100: avg data time: 6.71e-02, avg batch time: 0.4804, average train loss: 0.0160
[09/26 06:32:20 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1581, average loss: 0.7461
[09/26 06:32:20 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.50	
[09/26 06:32:20 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:32:26 visual_prompt]: Epoch 71 / 100: avg data time: 7.11e-02, avg batch time: 0.4870, average train loss: 0.0154
[09/26 06:32:28 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1579, average loss: 0.7431
[09/26 06:32:28 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.50	
[09/26 06:32:28 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:32:35 visual_prompt]: Epoch 72 / 100: avg data time: 6.92e-02, avg batch time: 0.4830, average train loss: 0.0159
[09/26 06:32:37 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1582, average loss: 0.7401
[09/26 06:32:37 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:32:37 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:32:43 visual_prompt]: Epoch 73 / 100: avg data time: 7.12e-02, avg batch time: 0.4851, average train loss: 0.0160
[09/26 06:32:45 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1580, average loss: 0.7389
[09/26 06:32:45 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:32:45 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:32:52 visual_prompt]: Epoch 74 / 100: avg data time: 6.76e-02, avg batch time: 0.4811, average train loss: 0.0156
[09/26 06:32:54 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1581, average loss: 0.7404
[09/26 06:32:54 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:32:54 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:33:00 visual_prompt]: Epoch 75 / 100: avg data time: 7.25e-02, avg batch time: 0.4851, average train loss: 0.0153
[09/26 06:33:02 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1586, average loss: 0.7405
[09/26 06:33:02 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:33:02 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:33:09 visual_prompt]: Epoch 76 / 100: avg data time: 5.80e-02, avg batch time: 0.4722, average train loss: 0.0159
[09/26 06:33:10 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1582, average loss: 0.7401
[09/26 06:33:10 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:33:10 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:33:17 visual_prompt]: Epoch 77 / 100: avg data time: 6.40e-02, avg batch time: 0.4783, average train loss: 0.0155
[09/26 06:33:19 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1581, average loss: 0.7401
[09/26 06:33:19 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:33:19 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:33:25 visual_prompt]: Epoch 78 / 100: avg data time: 7.71e-02, avg batch time: 0.4908, average train loss: 0.0155
[09/26 06:33:27 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1582, average loss: 0.7401
[09/26 06:33:27 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:33:27 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:33:34 visual_prompt]: Epoch 79 / 100: avg data time: 6.48e-02, avg batch time: 0.4776, average train loss: 0.0154
[09/26 06:33:36 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1581, average loss: 0.7411
[09/26 06:33:36 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:33:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:33:42 visual_prompt]: Epoch 80 / 100: avg data time: 6.38e-02, avg batch time: 0.4770, average train loss: 0.0154
[09/26 06:33:44 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1583, average loss: 0.7421
[09/26 06:33:44 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:33:44 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:33:51 visual_prompt]: Epoch 81 / 100: avg data time: 6.82e-02, avg batch time: 0.4815, average train loss: 0.0160
[09/26 06:33:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1580, average loss: 0.7422
[09/26 06:33:52 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:33:52 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:33:59 visual_prompt]: Epoch 82 / 100: avg data time: 6.30e-02, avg batch time: 0.4767, average train loss: 0.0148
[09/26 06:34:01 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1582, average loss: 0.7412
[09/26 06:34:01 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:34:01 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:34:07 visual_prompt]: Epoch 83 / 100: avg data time: 6.19e-02, avg batch time: 0.4759, average train loss: 0.0143
[09/26 06:34:09 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1583, average loss: 0.7408
[09/26 06:34:09 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 93.00	
[09/26 06:34:09 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:34:16 visual_prompt]: Epoch 84 / 100: avg data time: 7.18e-02, avg batch time: 0.4845, average train loss: 0.0147
[09/26 06:34:18 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1581, average loss: 0.7412
[09/26 06:34:18 visual_prompt]: Classification results with val_vtab-caltech101: top1: 82.50	top5: 92.50	
[09/26 06:34:18 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:34:24 visual_prompt]: Epoch 85 / 100: avg data time: 6.48e-02, avg batch time: 0.4790, average train loss: 0.0147
[09/26 06:34:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1587, average loss: 0.7414
[09/26 06:34:26 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:34:26 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:34:33 visual_prompt]: Epoch 86 / 100: avg data time: 6.76e-02, avg batch time: 0.4806, average train loss: 0.0149
[09/26 06:34:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1584, average loss: 0.7413
[09/26 06:34:34 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 92.50	
[09/26 06:34:34 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:34:41 visual_prompt]: Epoch 87 / 100: avg data time: 6.46e-02, avg batch time: 0.4779, average train loss: 0.0150
[09/26 06:34:43 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1580, average loss: 0.7415
[09/26 06:34:43 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:34:43 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:34:50 visual_prompt]: Epoch 88 / 100: avg data time: 7.10e-02, avg batch time: 0.4847, average train loss: 0.0150
[09/26 06:34:51 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1586, average loss: 0.7416
[09/26 06:34:51 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.50	
[09/26 06:34:51 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:34:58 visual_prompt]: Epoch 89 / 100: avg data time: 6.61e-02, avg batch time: 0.4799, average train loss: 0.0150
[09/26 06:35:00 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1586, average loss: 0.7418
[09/26 06:35:00 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.50	
[09/26 06:35:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:35:06 visual_prompt]: Epoch 90 / 100: avg data time: 6.41e-02, avg batch time: 0.4788, average train loss: 0.0144
[09/26 06:35:08 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1584, average loss: 0.7418
[09/26 06:35:08 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.50	
[09/26 06:35:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:35:15 visual_prompt]: Epoch 91 / 100: avg data time: 6.58e-02, avg batch time: 0.4795, average train loss: 0.0147
[09/26 06:35:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1574, average loss: 0.7421
[09/26 06:35:16 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:35:16 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:35:23 visual_prompt]: Epoch 92 / 100: avg data time: 5.55e-02, avg batch time: 0.4712, average train loss: 0.0152
[09/26 06:35:25 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1583, average loss: 0.7423
[09/26 06:35:25 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:35:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:35:32 visual_prompt]: Epoch 93 / 100: avg data time: 7.33e-02, avg batch time: 0.4864, average train loss: 0.0146
[09/26 06:35:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1582, average loss: 0.7424
[09/26 06:35:33 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:35:33 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:35:40 visual_prompt]: Epoch 94 / 100: avg data time: 6.44e-02, avg batch time: 0.4789, average train loss: 0.0147
[09/26 06:35:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1581, average loss: 0.7423
[09/26 06:35:42 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:35:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:35:48 visual_prompt]: Epoch 95 / 100: avg data time: 6.71e-02, avg batch time: 0.4808, average train loss: 0.0154
[09/26 06:35:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 0.7424
[09/26 06:35:50 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:35:50 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:35:57 visual_prompt]: Epoch 96 / 100: avg data time: 6.64e-02, avg batch time: 0.4807, average train loss: 0.0150
[09/26 06:35:58 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1583, average loss: 0.7425
[09/26 06:35:58 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:35:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:36:05 visual_prompt]: Epoch 97 / 100: avg data time: 7.43e-02, avg batch time: 0.4881, average train loss: 0.0150
[09/26 06:36:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1585, average loss: 0.7425
[09/26 06:36:07 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:36:07 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:36:14 visual_prompt]: Epoch 98 / 100: avg data time: 5.70e-02, avg batch time: 0.4720, average train loss: 0.0147
[09/26 06:36:15 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1583, average loss: 0.7424
[09/26 06:36:15 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:36:15 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:36:22 visual_prompt]: Epoch 99 / 100: avg data time: 7.46e-02, avg batch time: 0.4876, average train loss: 0.0150
[09/26 06:36:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1582, average loss: 0.7424
[09/26 06:36:24 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
[09/26 06:36:24 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:36:30 visual_prompt]: Epoch 100 / 100: avg data time: 7.25e-02, avg batch time: 0.4857, average train loss: 0.0150
[09/26 06:36:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1583, average loss: 0.7424
[09/26 06:36:32 visual_prompt]: Classification results with val_vtab-caltech101: top1: 83.00	top5: 93.00	
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 289, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 284, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 113, in train
    seed(cfg)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 136, in seed
    torch.manual_seed(SEED)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/torch/random.py", line 36, in manual_seed
    seed = int(seed)
           ^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'tuple'
