/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 05:22:18 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 05:22:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 05:22:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 05:22:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 05:22:18 visual_prompt]: Training with config:
[09/28 05:22:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_elevation")/sup_vitb16_imagenet21k/prompt50/crop224/test/seed2524/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 2524, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 9, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 05:22:18 visual_prompt]: Loading training data...
2023-09-28 05:22:18.480590: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-28 05:22:18.529271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-28 05:22:19.817770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/28 05:22:21 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800]+test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 05:22:23 visual_prompt]: Number of images: 1000
[09/28 05:22:23 visual_prompt]: Number of classes: 9 / 9
[09/28 05:22:23 visual_prompt]: Loading validation data...
[09/28 05:22:23 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 05:22:24 visual_prompt]: Number of images: 200
[09/28 05:22:24 visual_prompt]: Number of classes: 9 / 9
[09/28 05:22:24 visual_prompt]: Loading test data...
[09/28 05:22:24 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[50%:], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 05:22:40 visual_prompt]: Number of images: 12150
[09/28 05:22:40 visual_prompt]: Number of classes: 9 / 9
[09/28 05:22:40 visual_prompt]: Constructing models...
[09/28 05:22:42 visual_prompt]: Total Parameters: 86266377	 Gradient Parameters: 467721
[09/28 05:22:42 visual_prompt]: tuned percent:0.542
[09/28 05:22:44 visual_prompt]: Device used for model: 0
[09/28 05:22:44 visual_prompt]: Setting up Evaluator...
[09/28 05:22:44 visual_prompt]: Setting up Trainer...
[09/28 05:22:44 visual_prompt]: 	Setting up the optimizer...
[09/28 05:22:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 05:22:58 visual_prompt]: Epoch 1 / 100: avg data time: 1.93e-01, avg batch time: 0.7970, average train loss: 2.3722
[09/28 05:23:00 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1655, average loss: 2.3352
[09/28 05:23:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.50	top5: 54.50	
[09/28 05:23:23 visual_prompt]: 	Test 100/190. loss: 2.253, 0.2120 s / batch. (data: 6.01e-05)max mem: 7.80407 GB 
[09/28 05:23:43 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2127, average loss: 2.3370
[09/28 05:23:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.86	top5: 55.32	
[09/28 05:23:43 visual_prompt]: Best epoch 1: best metric: 0.135
[09/28 05:23:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/28 05:23:52 visual_prompt]: Epoch 2 / 100: avg data time: 7.86e-02, avg batch time: 0.5285, average train loss: 2.4006
[09/28 05:23:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 2.2687
[09/28 05:23:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 54.50	
[09/28 05:24:18 visual_prompt]: 	Test 100/190. loss: 2.257, 0.2157 s / batch. (data: 2.88e-05)max mem: 7.80407 GB 
[09/28 05:24:38 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2148, average loss: 2.2651
[09/28 05:24:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 55.26	
[09/28 05:24:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/28 05:24:47 visual_prompt]: Epoch 3 / 100: avg data time: 8.19e-02, avg batch time: 0.5330, average train loss: 2.2417
[09/28 05:24:50 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1673, average loss: 2.2168
[09/28 05:24:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 56.50	
[09/28 05:25:13 visual_prompt]: 	Test 100/190. loss: 2.205, 0.2170 s / batch. (data: 2.53e-05)max mem: 7.80407 GB 
[09/28 05:25:33 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2160, average loss: 2.2466
[09/28 05:25:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 55.18	
[09/28 05:25:33 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/28 05:25:42 visual_prompt]: Epoch 4 / 100: avg data time: 7.83e-02, avg batch time: 0.5308, average train loss: 2.2321
[09/28 05:25:45 visual_prompt]: Inference (val):avg data time: 1.50e-05, avg batch time: 0.1676, average loss: 2.2800
[09/28 05:25:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.00	top5: 59.50	
[09/28 05:26:08 visual_prompt]: 	Test 100/190. loss: 2.272, 0.2170 s / batch. (data: 2.38e-05)max mem: 7.80407 GB 
[09/28 05:26:28 visual_prompt]: Inference (test):avg data time: 7.62e-05, avg batch time: 0.2166, average loss: 2.3147
[09/28 05:26:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.41	top5: 56.09	
[09/28 05:26:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/28 05:26:37 visual_prompt]: Epoch 5 / 100: avg data time: 8.77e-02, avg batch time: 0.5409, average train loss: 2.2114
[09/28 05:26:40 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1680, average loss: 2.1448
[09/28 05:26:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.50	top5: 75.00	
[09/28 05:27:03 visual_prompt]: 	Test 100/190. loss: 2.131, 0.2172 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 05:27:23 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2168, average loss: 2.1374
[09/28 05:27:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.03	top5: 72.82	
[09/28 05:27:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/28 05:27:33 visual_prompt]: Epoch 6 / 100: avg data time: 8.27e-02, avg batch time: 0.5362, average train loss: 2.2910
[09/28 05:27:35 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1683, average loss: 2.2275
[09/28 05:27:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 61.50	
[09/28 05:27:58 visual_prompt]: 	Test 100/190. loss: 2.187, 0.2167 s / batch. (data: 2.43e-05)max mem: 7.80407 GB 
[09/28 05:28:19 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2167, average loss: 2.2453
[09/28 05:28:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 56.44	
[09/28 05:28:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/28 05:28:28 visual_prompt]: Epoch 7 / 100: avg data time: 8.37e-02, avg batch time: 0.5379, average train loss: 2.2579
[09/28 05:28:30 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1678, average loss: 2.2575
[09/28 05:28:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 55.50	
[09/28 05:28:53 visual_prompt]: 	Test 100/190. loss: 2.232, 0.2175 s / batch. (data: 2.41e-05)max mem: 7.80407 GB 
[09/28 05:29:14 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2166, average loss: 2.2331
[09/28 05:29:14 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.15	top5: 59.62	
[09/28 05:29:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/28 05:29:23 visual_prompt]: Epoch 8 / 100: avg data time: 8.38e-02, avg batch time: 0.5373, average train loss: 2.1496
[09/28 05:29:26 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1681, average loss: 2.0767
[09/28 05:29:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.50	top5: 71.50	
[09/28 05:29:49 visual_prompt]: 	Test 100/190. loss: 2.177, 0.2168 s / batch. (data: 2.36e-05)max mem: 7.80407 GB 
[09/28 05:30:09 visual_prompt]: Inference (test):avg data time: 8.11e-05, avg batch time: 0.2168, average loss: 2.0925
[09/28 05:30:09 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.95	top5: 69.44	
[09/28 05:30:09 visual_prompt]: Best epoch 8: best metric: 0.225
[09/28 05:30:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/28 05:30:18 visual_prompt]: Epoch 9 / 100: avg data time: 7.85e-02, avg batch time: 0.5334, average train loss: 2.0415
[09/28 05:30:21 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1682, average loss: 2.1667
[09/28 05:30:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.50	top5: 71.50	
[09/28 05:30:44 visual_prompt]: 	Test 100/190. loss: 1.975, 0.2163 s / batch. (data: 2.26e-05)max mem: 7.80407 GB 
[09/28 05:31:04 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2168, average loss: 2.1298
[09/28 05:31:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.08	top5: 74.99	
[09/28 05:31:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/28 05:31:13 visual_prompt]: Epoch 10 / 100: avg data time: 7.55e-02, avg batch time: 0.5312, average train loss: 2.2180
[09/28 05:31:16 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1681, average loss: 1.9539
[09/28 05:31:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.50	top5: 82.50	
[09/28 05:31:39 visual_prompt]: 	Test 100/190. loss: 1.980, 0.2175 s / batch. (data: 2.74e-05)max mem: 7.80407 GB 
[09/28 05:31:59 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2170, average loss: 2.0206
[09/28 05:31:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.11	top5: 80.94	
[09/28 05:31:59 visual_prompt]: Best epoch 10: best metric: 0.235
[09/28 05:31:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/28 05:32:09 visual_prompt]: Epoch 11 / 100: avg data time: 7.71e-02, avg batch time: 0.5315, average train loss: 2.0248
[09/28 05:32:11 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1684, average loss: 2.3595
[09/28 05:32:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 71.50	
[09/28 05:32:34 visual_prompt]: 	Test 100/190. loss: 2.256, 0.2178 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 05:32:55 visual_prompt]: Inference (test):avg data time: 1.09e-04, avg batch time: 0.2168, average loss: 2.4308
[09/28 05:32:55 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.44	top5: 68.11	
[09/28 05:32:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/28 05:33:04 visual_prompt]: Epoch 12 / 100: avg data time: 8.41e-02, avg batch time: 0.5378, average train loss: 1.9717
[09/28 05:33:06 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1683, average loss: 1.7699
[09/28 05:33:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.00	top5: 86.50	
[09/28 05:33:29 visual_prompt]: 	Test 100/190. loss: 1.758, 0.2167 s / batch. (data: 2.84e-05)max mem: 7.80407 GB 
[09/28 05:33:50 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2171, average loss: 1.8978
[09/28 05:33:50 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.17	top5: 85.93	
[09/28 05:33:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/28 05:33:59 visual_prompt]: Epoch 13 / 100: avg data time: 6.84e-02, avg batch time: 0.5252, average train loss: 1.8228
[09/28 05:34:02 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1680, average loss: 1.7145
[09/28 05:34:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.00	top5: 94.50	
[09/28 05:34:25 visual_prompt]: 	Test 100/190. loss: 1.896, 0.2177 s / batch. (data: 2.77e-05)max mem: 7.80407 GB 
[09/28 05:34:45 visual_prompt]: Inference (test):avg data time: 1.14e-04, avg batch time: 0.2169, average loss: 1.9123
[09/28 05:34:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.97	top5: 91.93	
[09/28 05:34:45 visual_prompt]: Best epoch 13: best metric: 0.280
[09/28 05:34:45 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/28 05:34:54 visual_prompt]: Epoch 14 / 100: avg data time: 7.80e-02, avg batch time: 0.5337, average train loss: 1.9838
[09/28 05:34:57 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1684, average loss: 1.9136
[09/28 05:34:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.50	top5: 90.50	
[09/28 05:35:20 visual_prompt]: 	Test 100/190. loss: 1.851, 0.2176 s / batch. (data: 2.50e-05)max mem: 7.80407 GB 
[09/28 05:35:40 visual_prompt]: Inference (test):avg data time: 1.46e-04, avg batch time: 0.2169, average loss: 1.9830
[09/28 05:35:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.42	top5: 89.06	
[09/28 05:35:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/28 05:35:49 visual_prompt]: Epoch 15 / 100: avg data time: 7.32e-02, avg batch time: 0.5288, average train loss: 1.8349
[09/28 05:35:52 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1682, average loss: 1.6042
[09/28 05:35:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.00	top5: 95.00	
[09/28 05:36:15 visual_prompt]: 	Test 100/190. loss: 1.876, 0.2170 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 05:36:36 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2172, average loss: 1.8090
[09/28 05:36:36 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.58	top5: 92.50	
[09/28 05:36:36 visual_prompt]: Best epoch 15: best metric: 0.300
[09/28 05:36:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/28 05:36:45 visual_prompt]: Epoch 16 / 100: avg data time: 8.45e-02, avg batch time: 0.5390, average train loss: 1.7192
[09/28 05:36:47 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1681, average loss: 1.8358
[09/28 05:36:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.50	top5: 89.50	
[09/28 05:37:10 visual_prompt]: 	Test 100/190. loss: 2.034, 0.2159 s / batch. (data: 2.65e-05)max mem: 7.80407 GB 
[09/28 05:37:31 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2170, average loss: 2.0576
[09/28 05:37:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.70	top5: 86.40	
[09/28 05:37:31 visual_prompt]: Best epoch 16: best metric: 0.305
[09/28 05:37:31 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/28 05:37:40 visual_prompt]: Epoch 17 / 100: avg data time: 7.55e-02, avg batch time: 0.5305, average train loss: 1.7313
[09/28 05:37:43 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1681, average loss: 1.6111
[09/28 05:37:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.00	top5: 94.00	
[09/28 05:38:06 visual_prompt]: 	Test 100/190. loss: 1.602, 0.2174 s / batch. (data: 2.50e-05)max mem: 7.80407 GB 
[09/28 05:38:26 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2169, average loss: 1.8285
[09/28 05:38:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.19	top5: 91.78	
[09/28 05:38:26 visual_prompt]: Best epoch 17: best metric: 0.360
[09/28 05:38:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/28 05:38:35 visual_prompt]: Epoch 18 / 100: avg data time: 7.08e-02, avg batch time: 0.5258, average train loss: 1.6684
[09/28 05:38:38 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1680, average loss: 1.8585
[09/28 05:38:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.50	top5: 94.50	
[09/28 05:39:01 visual_prompt]: 	Test 100/190. loss: 2.089, 0.2173 s / batch. (data: 2.72e-05)max mem: 7.80407 GB 
[09/28 05:39:21 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2168, average loss: 2.1833
[09/28 05:39:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.32	top5: 92.90	
[09/28 05:39:21 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/28 05:39:30 visual_prompt]: Epoch 19 / 100: avg data time: 8.70e-02, avg batch time: 0.5405, average train loss: 1.7671
[09/28 05:39:33 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1681, average loss: 1.7672
[09/28 05:39:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.50	top5: 97.50	
[09/28 05:39:56 visual_prompt]: 	Test 100/190. loss: 1.743, 0.2165 s / batch. (data: 2.74e-05)max mem: 7.80407 GB 
[09/28 05:40:16 visual_prompt]: Inference (test):avg data time: 5.98e-05, avg batch time: 0.2169, average loss: 2.0136
[09/28 05:40:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.40	top5: 93.33	
[09/28 05:40:16 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/28 05:40:26 visual_prompt]: Epoch 20 / 100: avg data time: 6.92e-02, avg batch time: 0.5255, average train loss: 1.5500
[09/28 05:40:28 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1687, average loss: 1.5003
[09/28 05:40:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.50	top5: 99.50	
[09/28 05:40:51 visual_prompt]: 	Test 100/190. loss: 1.791, 0.2166 s / batch. (data: 8.03e-05)max mem: 7.80407 GB 
[09/28 05:41:12 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2169, average loss: 1.9052
[09/28 05:41:12 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.47	top5: 95.23	
[09/28 05:41:12 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/28 05:41:21 visual_prompt]: Epoch 21 / 100: avg data time: 8.53e-02, avg batch time: 0.5413, average train loss: 1.3977
[09/28 05:41:24 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1684, average loss: 1.2832
[09/28 05:41:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 42.00	top5: 100.00	
[09/28 05:41:46 visual_prompt]: 	Test 100/190. loss: 1.633, 0.2172 s / batch. (data: 6.41e-05)max mem: 7.80407 GB 
[09/28 05:42:07 visual_prompt]: Inference (test):avg data time: 1.70e-04, avg batch time: 0.2170, average loss: 1.6352
[09/28 05:42:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.30	top5: 96.84	
[09/28 05:42:07 visual_prompt]: Best epoch 21: best metric: 0.420
[09/28 05:42:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/28 05:42:16 visual_prompt]: Epoch 22 / 100: avg data time: 8.03e-02, avg batch time: 0.5345, average train loss: 1.3604
[09/28 05:42:19 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1682, average loss: 1.2830
[09/28 05:42:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 45.50	top5: 100.00	
[09/28 05:42:42 visual_prompt]: 	Test 100/190. loss: 1.573, 0.2176 s / batch. (data: 2.31e-05)max mem: 7.80407 GB 
[09/28 05:43:02 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2169, average loss: 1.7443
[09/28 05:43:02 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.84	top5: 95.84	
[09/28 05:43:02 visual_prompt]: Best epoch 22: best metric: 0.455
[09/28 05:43:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/28 05:43:11 visual_prompt]: Epoch 23 / 100: avg data time: 7.45e-02, avg batch time: 0.5292, average train loss: 1.3667
[09/28 05:43:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1683, average loss: 1.3564
[09/28 05:43:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 44.50	top5: 99.00	
[09/28 05:43:37 visual_prompt]: 	Test 100/190. loss: 1.783, 0.2181 s / batch. (data: 2.50e-05)max mem: 7.80407 GB 
[09/28 05:43:57 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2167, average loss: 1.8085
[09/28 05:43:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.51	top5: 95.28	
[09/28 05:43:57 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/28 05:44:07 visual_prompt]: Epoch 24 / 100: avg data time: 9.02e-02, avg batch time: 0.5453, average train loss: 1.4068
[09/28 05:44:09 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1683, average loss: 1.7247
[09/28 05:44:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.50	top5: 94.50	
[09/28 05:44:32 visual_prompt]: 	Test 100/190. loss: 2.612, 0.2164 s / batch. (data: 3.05e-05)max mem: 7.80407 GB 
[09/28 05:44:53 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2169, average loss: 2.3184
[09/28 05:44:53 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.05	top5: 88.86	
[09/28 05:44:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/28 05:45:02 visual_prompt]: Epoch 25 / 100: avg data time: 7.18e-02, avg batch time: 0.5258, average train loss: 1.4376
[09/28 05:45:04 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1683, average loss: 1.2476
[09/28 05:45:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 45.50	top5: 99.50	
[09/28 05:45:27 visual_prompt]: 	Test 100/190. loss: 1.540, 0.2176 s / batch. (data: 2.55e-05)max mem: 7.80407 GB 
[09/28 05:45:48 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2168, average loss: 1.6326
[09/28 05:45:48 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.86	top5: 95.99	
[09/28 05:45:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/28 05:45:58 visual_prompt]: Epoch 26 / 100: avg data time: 9.25e-02, avg batch time: 0.5466, average train loss: 1.1206
[09/28 05:46:00 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1677, average loss: 1.1107
[09/28 05:46:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 46.50	top5: 100.00	
[09/28 05:46:23 visual_prompt]: 	Test 100/190. loss: 1.531, 0.2166 s / batch. (data: 9.61e-05)max mem: 7.80407 GB 
[09/28 05:46:44 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2168, average loss: 1.8626
[09/28 05:46:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.87	top5: 95.27	
[09/28 05:46:44 visual_prompt]: Best epoch 26: best metric: 0.465
[09/28 05:46:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/28 05:46:53 visual_prompt]: Epoch 27 / 100: avg data time: 8.23e-02, avg batch time: 0.5371, average train loss: 1.0601
[09/28 05:46:55 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1682, average loss: 0.8588
[09/28 05:46:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 63.00	top5: 100.00	
[09/28 05:47:18 visual_prompt]: 	Test 100/190. loss: 1.609, 0.2168 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 05:47:39 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2168, average loss: 1.6241
[09/28 05:47:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.79	top5: 97.41	
[09/28 05:47:39 visual_prompt]: Best epoch 27: best metric: 0.630
[09/28 05:47:39 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/28 05:47:48 visual_prompt]: Epoch 28 / 100: avg data time: 8.31e-02, avg batch time: 0.5370, average train loss: 0.9900
[09/28 05:47:51 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1682, average loss: 0.8246
[09/28 05:47:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 60.00	top5: 100.00	
[09/28 05:48:14 visual_prompt]: 	Test 100/190. loss: 1.777, 0.2171 s / batch. (data: 2.46e-05)max mem: 7.80407 GB 
[09/28 05:48:34 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2169, average loss: 1.8010
[09/28 05:48:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.86	top5: 97.34	
[09/28 05:48:34 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/28 05:48:44 visual_prompt]: Epoch 29 / 100: avg data time: 8.46e-02, avg batch time: 0.5386, average train loss: 1.1747
[09/28 05:48:46 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1679, average loss: 1.5314
[09/28 05:48:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 43.00	top5: 99.50	
[09/28 05:49:09 visual_prompt]: 	Test 100/190. loss: 1.734, 0.2165 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 05:49:30 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2170, average loss: 2.2443
[09/28 05:49:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.64	top5: 94.59	
[09/28 05:49:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/28 05:49:39 visual_prompt]: Epoch 30 / 100: avg data time: 7.32e-02, avg batch time: 0.5295, average train loss: 1.0653
[09/28 05:49:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1679, average loss: 1.2231
[09/28 05:49:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 47.50	top5: 100.00	
[09/28 05:50:04 visual_prompt]: 	Test 100/190. loss: 1.819, 0.2173 s / batch. (data: 2.79e-05)max mem: 7.80407 GB 
[09/28 05:50:25 visual_prompt]: Inference (test):avg data time: 9.82e-05, avg batch time: 0.2170, average loss: 1.9651
[09/28 05:50:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.53	top5: 95.46	
[09/28 05:50:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/28 05:50:34 visual_prompt]: Epoch 31 / 100: avg data time: 8.46e-02, avg batch time: 0.5387, average train loss: 1.0493
[09/28 05:50:37 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1683, average loss: 0.9491
[09/28 05:50:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 57.00	top5: 100.00	
[09/28 05:51:00 visual_prompt]: 	Test 100/190. loss: 1.661, 0.2177 s / batch. (data: 2.67e-05)max mem: 7.80407 GB 
[09/28 05:51:20 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2170, average loss: 1.9560
[09/28 05:51:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.76	top5: 97.17	
[09/28 05:51:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/28 05:51:30 visual_prompt]: Epoch 32 / 100: avg data time: 8.31e-02, avg batch time: 0.5374, average train loss: 0.8301
[09/28 05:51:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1678, average loss: 0.9944
[09/28 05:51:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 58.50	top5: 100.00	
[09/28 05:51:55 visual_prompt]: 	Test 100/190. loss: 2.093, 0.2175 s / batch. (data: 2.50e-05)max mem: 7.80407 GB 
[09/28 05:52:16 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2172, average loss: 2.1848
[09/28 05:52:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.35	top5: 97.15	
[09/28 05:52:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/28 05:52:25 visual_prompt]: Epoch 33 / 100: avg data time: 8.07e-02, avg batch time: 0.5360, average train loss: 0.9674
[09/28 05:52:27 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1682, average loss: 0.7984
[09/28 05:52:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 66.00	top5: 100.00	
[09/28 05:52:51 visual_prompt]: 	Test 100/190. loss: 1.749, 0.2169 s / batch. (data: 2.57e-05)max mem: 7.80407 GB 
[09/28 05:53:11 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2170, average loss: 1.9401
[09/28 05:53:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.53	top5: 96.78	
[09/28 05:53:11 visual_prompt]: Best epoch 33: best metric: 0.660
[09/28 05:53:11 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/28 05:53:20 visual_prompt]: Epoch 34 / 100: avg data time: 8.04e-02, avg batch time: 0.5344, average train loss: 0.8203
[09/28 05:53:23 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1681, average loss: 0.8623
[09/28 05:53:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 64.00	top5: 100.00	
[09/28 05:53:46 visual_prompt]: 	Test 100/190. loss: 2.328, 0.2180 s / batch. (data: 7.51e-05)max mem: 7.80407 GB 
[09/28 05:54:06 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2169, average loss: 2.3752
[09/28 05:54:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.70	top5: 96.06	
[09/28 05:54:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/28 05:54:16 visual_prompt]: Epoch 35 / 100: avg data time: 8.54e-02, avg batch time: 0.5392, average train loss: 0.7895
[09/28 05:54:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1680, average loss: 0.7593
[09/28 05:54:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 68.50	top5: 100.00	
[09/28 05:54:41 visual_prompt]: 	Test 100/190. loss: 1.775, 0.2176 s / batch. (data: 2.81e-05)max mem: 7.80407 GB 
[09/28 05:55:02 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2170, average loss: 2.2623
[09/28 05:55:02 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.16	top5: 97.33	
[09/28 05:55:02 visual_prompt]: Best epoch 35: best metric: 0.685
[09/28 05:55:02 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/28 05:55:11 visual_prompt]: Epoch 36 / 100: avg data time: 7.01e-02, avg batch time: 0.5272, average train loss: 0.7664
[09/28 05:55:13 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1683, average loss: 0.6654
[09/28 05:55:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 73.00	top5: 99.50	
[09/28 05:55:36 visual_prompt]: 	Test 100/190. loss: 2.137, 0.2177 s / batch. (data: 2.53e-05)max mem: 7.80407 GB 
[09/28 05:55:57 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2171, average loss: 2.1711
[09/28 05:55:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.18	top5: 96.74	
[09/28 05:55:57 visual_prompt]: Best epoch 36: best metric: 0.730
[09/28 05:55:57 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/28 05:56:06 visual_prompt]: Epoch 37 / 100: avg data time: 7.80e-02, avg batch time: 0.5327, average train loss: 0.6657
[09/28 05:56:09 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1684, average loss: 0.5521
[09/28 05:56:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.00	top5: 100.00	
[09/28 05:56:32 visual_prompt]: 	Test 100/190. loss: 2.178, 0.2166 s / batch. (data: 2.36e-05)max mem: 7.80407 GB 
[09/28 05:56:52 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2169, average loss: 2.1261
[09/28 05:56:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.01	top5: 97.09	
[09/28 05:56:52 visual_prompt]: Best epoch 37: best metric: 0.740
[09/28 05:56:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/28 05:57:01 visual_prompt]: Epoch 38 / 100: avg data time: 8.10e-02, avg batch time: 0.5357, average train loss: 0.8752
[09/28 05:57:04 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1683, average loss: 1.4411
[09/28 05:57:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 53.50	top5: 99.50	
[09/28 05:57:27 visual_prompt]: 	Test 100/190. loss: 2.308, 0.2175 s / batch. (data: 6.60e-05)max mem: 7.80407 GB 
[09/28 05:57:47 visual_prompt]: Inference (test):avg data time: 1.09e-04, avg batch time: 0.2170, average loss: 2.8200
[09/28 05:57:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.48	top5: 93.14	
[09/28 05:57:48 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/28 05:57:57 visual_prompt]: Epoch 39 / 100: avg data time: 7.67e-02, avg batch time: 0.5309, average train loss: 0.7360
[09/28 05:57:59 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1681, average loss: 0.5653
[09/28 05:57:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.00	top5: 100.00	
[09/28 05:58:22 visual_prompt]: 	Test 100/190. loss: 2.135, 0.2175 s / batch. (data: 2.69e-05)max mem: 7.80407 GB 
[09/28 05:58:43 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2170, average loss: 2.1119
[09/28 05:58:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.82	top5: 97.05	
[09/28 05:58:43 visual_prompt]: Best epoch 39: best metric: 0.790
[09/28 05:58:43 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/28 05:58:52 visual_prompt]: Epoch 40 / 100: avg data time: 7.30e-02, avg batch time: 0.5270, average train loss: 0.5638
[09/28 05:58:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1681, average loss: 0.4194
[09/28 05:58:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 82.50	top5: 100.00	
[09/28 05:59:17 visual_prompt]: 	Test 100/190. loss: 2.487, 0.2166 s / batch. (data: 2.69e-05)max mem: 7.80407 GB 
[09/28 05:59:38 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2169, average loss: 2.5157
[09/28 05:59:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.49	top5: 97.49	
[09/28 05:59:38 visual_prompt]: Best epoch 40: best metric: 0.825
[09/28 05:59:38 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/28 05:59:47 visual_prompt]: Epoch 41 / 100: avg data time: 7.92e-02, avg batch time: 0.5333, average train loss: 0.6361
[09/28 05:59:50 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1684, average loss: 0.6643
[09/28 05:59:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 76.00	top5: 100.00	
[09/28 06:00:13 visual_prompt]: 	Test 100/190. loss: 3.134, 0.2178 s / batch. (data: 2.17e-05)max mem: 7.80407 GB 
[09/28 06:00:33 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2169, average loss: 2.8674
[09/28 06:00:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.36	top5: 97.17	
[09/28 06:00:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/28 06:00:42 visual_prompt]: Epoch 42 / 100: avg data time: 8.08e-02, avg batch time: 0.5356, average train loss: 0.6806
[09/28 06:00:45 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1683, average loss: 0.6266
[09/28 06:00:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 77.00	top5: 100.00	
[09/28 06:01:08 visual_prompt]: 	Test 100/190. loss: 2.243, 0.2181 s / batch. (data: 2.26e-05)max mem: 7.80407 GB 
[09/28 06:01:28 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2169, average loss: 2.2905
[09/28 06:01:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.94	top5: 97.06	
[09/28 06:01:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/28 06:01:38 visual_prompt]: Epoch 43 / 100: avg data time: 8.72e-02, avg batch time: 0.5407, average train loss: 0.5867
[09/28 06:01:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1685, average loss: 0.9692
[09/28 06:01:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 64.00	top5: 100.00	
[09/28 06:02:03 visual_prompt]: 	Test 100/190. loss: 2.285, 0.2178 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 06:02:24 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2169, average loss: 3.1249
[09/28 06:02:24 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.23	top5: 94.61	
[09/28 06:02:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/28 06:02:33 visual_prompt]: Epoch 44 / 100: avg data time: 7.37e-02, avg batch time: 0.5286, average train loss: 0.7065
[09/28 06:02:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1680, average loss: 0.7411
[09/28 06:02:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 66.00	top5: 100.00	
[09/28 06:02:59 visual_prompt]: 	Test 100/190. loss: 2.334, 0.2166 s / batch. (data: 2.24e-05)max mem: 7.80407 GB 
[09/28 06:03:19 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2168, average loss: 2.7912
[09/28 06:03:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.16	top5: 95.70	
[09/28 06:03:19 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/28 06:03:29 visual_prompt]: Epoch 45 / 100: avg data time: 8.85e-02, avg batch time: 0.5423, average train loss: 0.7447
[09/28 06:03:31 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1679, average loss: 0.7432
[09/28 06:03:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 68.50	top5: 100.00	
[09/28 06:03:54 visual_prompt]: 	Test 100/190. loss: 1.775, 0.2166 s / batch. (data: 2.43e-05)max mem: 7.80407 GB 
[09/28 06:04:15 visual_prompt]: Inference (test):avg data time: 2.94e-05, avg batch time: 0.2169, average loss: 2.4931
[09/28 06:04:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.81	top5: 95.37	
[09/28 06:04:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/28 06:04:24 visual_prompt]: Epoch 46 / 100: avg data time: 8.62e-02, avg batch time: 0.5399, average train loss: 0.5590
[09/28 06:04:27 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1682, average loss: 0.4276
[09/28 06:04:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 82.00	top5: 100.00	
[09/28 06:04:50 visual_prompt]: 	Test 100/190. loss: 2.331, 0.2174 s / batch. (data: 2.41e-05)max mem: 7.80407 GB 
[09/28 06:05:10 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2168, average loss: 2.5526
[09/28 06:05:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.79	top5: 97.54	
[09/28 06:05:10 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/28 06:05:19 visual_prompt]: Epoch 47 / 100: avg data time: 8.45e-02, avg batch time: 0.5380, average train loss: 0.3222
[09/28 06:05:22 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1683, average loss: 0.3221
[09/28 06:05:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.50	top5: 100.00	
[09/28 06:05:45 visual_prompt]: 	Test 100/190. loss: 2.946, 0.2177 s / batch. (data: 2.77e-05)max mem: 7.80407 GB 
[09/28 06:06:05 visual_prompt]: Inference (test):avg data time: 5.56e-05, avg batch time: 0.2171, average loss: 3.0389
[09/28 06:06:05 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.60	top5: 97.32	
[09/28 06:06:05 visual_prompt]: Best epoch 47: best metric: 0.885
[09/28 06:06:05 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/28 06:06:14 visual_prompt]: Epoch 48 / 100: avg data time: 8.49e-02, avg batch time: 0.5387, average train loss: 0.2553
[09/28 06:06:17 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1681, average loss: 0.3493
[09/28 06:06:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.00	top5: 100.00	
[09/28 06:06:40 visual_prompt]: 	Test 100/190. loss: 4.210, 0.2165 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 06:07:01 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2168, average loss: 3.8079
[09/28 06:07:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.39	top5: 97.17	
[09/28 06:07:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/28 06:07:10 visual_prompt]: Epoch 49 / 100: avg data time: 7.27e-02, avg batch time: 0.5279, average train loss: 0.3364
[09/28 06:07:12 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1685, average loss: 0.2200
[09/28 06:07:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.00	top5: 100.00	
[09/28 06:07:35 visual_prompt]: 	Test 100/190. loss: 2.937, 0.2188 s / batch. (data: 2.86e-05)max mem: 7.80407 GB 
[09/28 06:07:56 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2171, average loss: 3.2736
[09/28 06:07:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.19	top5: 97.05	
[09/28 06:07:56 visual_prompt]: Best epoch 49: best metric: 0.920
[09/28 06:07:56 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/28 06:08:05 visual_prompt]: Epoch 50 / 100: avg data time: 8.36e-02, avg batch time: 0.5370, average train loss: 0.3340
[09/28 06:08:07 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1684, average loss: 0.5732
[09/28 06:08:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 80.00	top5: 100.00	
[09/28 06:08:31 visual_prompt]: 	Test 100/190. loss: 3.247, 0.2180 s / batch. (data: 2.41e-05)max mem: 7.80407 GB 
[09/28 06:08:51 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2170, average loss: 3.9538
[09/28 06:08:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.47	top5: 95.77	
[09/28 06:08:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/28 06:09:00 visual_prompt]: Epoch 51 / 100: avg data time: 7.19e-02, avg batch time: 0.5274, average train loss: 0.3663
[09/28 06:09:03 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1682, average loss: 0.4032
[09/28 06:09:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 85.50	top5: 100.00	
[09/28 06:09:26 visual_prompt]: 	Test 100/190. loss: 2.527, 0.2177 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 06:09:46 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2169, average loss: 3.0050
[09/28 06:09:46 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.60	top5: 97.46	
[09/28 06:09:46 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/28 06:09:55 visual_prompt]: Epoch 52 / 100: avg data time: 7.02e-02, avg batch time: 0.5263, average train loss: 0.3657
[09/28 06:09:58 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1684, average loss: 0.2103
[09/28 06:09:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.50	top5: 100.00	
[09/28 06:10:21 visual_prompt]: 	Test 100/190. loss: 2.709, 0.2168 s / batch. (data: 2.62e-05)max mem: 7.80407 GB 
[09/28 06:10:41 visual_prompt]: Inference (test):avg data time: 4.02e-05, avg batch time: 0.2170, average loss: 2.8358
[09/28 06:10:41 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.42	top5: 96.30	
[09/28 06:10:41 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/28 06:10:50 visual_prompt]: Epoch 53 / 100: avg data time: 7.86e-02, avg batch time: 0.5333, average train loss: 0.3598
[09/28 06:10:53 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1681, average loss: 0.3020
[09/28 06:10:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.50	top5: 100.00	
[09/28 06:11:16 visual_prompt]: 	Test 100/190. loss: 2.544, 0.2174 s / batch. (data: 7.96e-05)max mem: 7.80407 GB 
[09/28 06:11:36 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2169, average loss: 3.0727
[09/28 06:11:36 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.49	top5: 96.79	
[09/28 06:11:36 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/28 06:11:46 visual_prompt]: Epoch 54 / 100: avg data time: 8.11e-02, avg batch time: 0.5359, average train loss: 0.2489
[09/28 06:11:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1683, average loss: 0.1845
[09/28 06:11:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.00	top5: 100.00	
[09/28 06:12:11 visual_prompt]: 	Test 100/190. loss: 2.504, 0.2176 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 06:12:31 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2167, average loss: 3.4882
[09/28 06:12:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.86	top5: 96.94	
[09/28 06:12:32 visual_prompt]: Best epoch 54: best metric: 0.950
[09/28 06:12:32 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/28 06:12:41 visual_prompt]: Epoch 55 / 100: avg data time: 7.41e-02, avg batch time: 0.5292, average train loss: 0.2349
[09/28 06:12:43 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1686, average loss: 0.1819
[09/28 06:12:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.00	top5: 100.00	
[09/28 06:13:06 visual_prompt]: 	Test 100/190. loss: 2.978, 0.2171 s / batch. (data: 6.01e-05)max mem: 7.80407 GB 
[09/28 06:13:27 visual_prompt]: Inference (test):avg data time: 3.95e-05, avg batch time: 0.2168, average loss: 3.6904
[09/28 06:13:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.01	top5: 96.77	
[09/28 06:13:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/28 06:13:36 visual_prompt]: Epoch 56 / 100: avg data time: 7.96e-02, avg batch time: 0.5333, average train loss: 0.2108
[09/28 06:13:38 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1679, average loss: 0.0833
[09/28 06:13:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 06:14:01 visual_prompt]: 	Test 100/190. loss: 2.608, 0.2172 s / batch. (data: 2.67e-05)max mem: 7.80407 GB 
[09/28 06:14:22 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2168, average loss: 3.7759
[09/28 06:14:22 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.17	top5: 96.67	
[09/28 06:14:22 visual_prompt]: Best epoch 56: best metric: 0.980
[09/28 06:14:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/28 06:14:31 visual_prompt]: Epoch 57 / 100: avg data time: 7.94e-02, avg batch time: 0.5330, average train loss: 0.1187
[09/28 06:14:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1681, average loss: 0.1447
[09/28 06:14:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.50	top5: 100.00	
[09/28 06:14:57 visual_prompt]: 	Test 100/190. loss: 2.978, 0.2172 s / batch. (data: 2.86e-05)max mem: 7.80407 GB 
[09/28 06:15:20 visual_prompt]: Inference (test):avg data time: 2.73e-03, avg batch time: 0.2195, average loss: 4.2850
[09/28 06:15:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.15	top5: 96.51	
[09/28 06:15:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/28 06:15:29 visual_prompt]: Epoch 58 / 100: avg data time: 8.62e-02, avg batch time: 0.5406, average train loss: 0.1447
[09/28 06:15:31 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1679, average loss: 0.0787
[09/28 06:15:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 06:15:54 visual_prompt]: 	Test 100/190. loss: 3.620, 0.2171 s / batch. (data: 2.55e-05)max mem: 7.80407 GB 
[09/28 06:16:15 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2167, average loss: 4.5242
[09/28 06:16:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.74	top5: 96.80	
[09/28 06:16:15 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/28 06:16:24 visual_prompt]: Epoch 59 / 100: avg data time: 7.27e-02, avg batch time: 0.5290, average train loss: 0.1528
[09/28 06:16:27 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1680, average loss: 0.2095
[09/28 06:16:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.50	top5: 100.00	
[09/28 06:16:50 visual_prompt]: 	Test 100/190. loss: 3.949, 0.2168 s / batch. (data: 7.56e-05)max mem: 7.80407 GB 
[09/28 06:17:10 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2167, average loss: 4.6716
[09/28 06:17:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.97	top5: 96.95	
[09/28 06:17:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/28 06:17:19 visual_prompt]: Epoch 60 / 100: avg data time: 8.53e-02, avg batch time: 0.5386, average train loss: 0.1138
[09/28 06:17:22 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1683, average loss: 0.0720
[09/28 06:17:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 06:17:45 visual_prompt]: 	Test 100/190. loss: 3.089, 0.2178 s / batch. (data: 2.12e-05)max mem: 7.80407 GB 
[09/28 06:18:05 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2167, average loss: 4.2472
[09/28 06:18:05 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.95	top5: 97.23	
[09/28 06:18:05 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/28 06:18:15 visual_prompt]: Epoch 61 / 100: avg data time: 8.44e-02, avg batch time: 0.5383, average train loss: 0.0946
[09/28 06:18:17 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1682, average loss: 0.0449
[09/28 06:18:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 06:18:40 visual_prompt]: 	Test 100/190. loss: 3.337, 0.2169 s / batch. (data: 2.62e-05)max mem: 7.80407 GB 
[09/28 06:19:00 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2167, average loss: 4.4483
[09/28 06:19:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.97	top5: 97.01	
[09/28 06:19:01 visual_prompt]: Best epoch 61: best metric: 0.995
[09/28 06:19:01 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/28 06:19:10 visual_prompt]: Epoch 62 / 100: avg data time: 7.54e-02, avg batch time: 0.5304, average train loss: 0.0980
[09/28 06:19:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1683, average loss: 0.2193
[09/28 06:19:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.00	top5: 99.50	
[09/28 06:19:35 visual_prompt]: 	Test 100/190. loss: 4.388, 0.2167 s / batch. (data: 2.57e-05)max mem: 7.80407 GB 
[09/28 06:19:56 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2167, average loss: 5.3604
[09/28 06:19:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.69	top5: 96.65	
[09/28 06:19:56 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/28 06:20:05 visual_prompt]: Epoch 63 / 100: avg data time: 8.24e-02, avg batch time: 0.5366, average train loss: 0.1101
[09/28 06:20:08 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1681, average loss: 0.0409
[09/28 06:20:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 06:20:31 visual_prompt]: 	Test 100/190. loss: 3.683, 0.2179 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 06:20:51 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2170, average loss: 4.7595
[09/28 06:20:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.95	top5: 96.54	
[09/28 06:20:51 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/28 06:21:01 visual_prompt]: Epoch 64 / 100: avg data time: 8.28e-02, avg batch time: 0.5373, average train loss: 0.0921
[09/28 06:21:03 visual_prompt]: Inference (val):avg data time: 1.74e-05, avg batch time: 0.1683, average loss: 0.0300
[09/28 06:21:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 06:21:26 visual_prompt]: 	Test 100/190. loss: 3.940, 0.2170 s / batch. (data: 2.67e-05)max mem: 7.80407 GB 
[09/28 06:21:46 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2168, average loss: 4.9434
[09/28 06:21:46 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.80	top5: 96.76	
[09/28 06:21:46 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/28 06:21:56 visual_prompt]: Epoch 65 / 100: avg data time: 7.62e-02, avg batch time: 0.5313, average train loss: 0.0656
[09/28 06:21:58 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1680, average loss: 0.0341
[09/28 06:21:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 06:22:21 visual_prompt]: 	Test 100/190. loss: 3.960, 0.2185 s / batch. (data: 2.55e-05)max mem: 7.80407 GB 
[09/28 06:22:42 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2169, average loss: 4.9814
[09/28 06:22:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.79	top5: 96.71	
[09/28 06:22:42 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/28 06:22:51 visual_prompt]: Epoch 66 / 100: avg data time: 7.79e-02, avg batch time: 0.5326, average train loss: 0.0607
[09/28 06:22:53 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1681, average loss: 0.1405
[09/28 06:22:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.00	top5: 100.00	
[09/28 06:23:16 visual_prompt]: 	Test 100/190. loss: 3.624, 0.2169 s / batch. (data: 2.53e-05)max mem: 7.80407 GB 
[09/28 06:23:37 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2169, average loss: 4.5322
[09/28 06:23:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.40	top5: 97.09	
[09/28 06:23:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/28 06:23:46 visual_prompt]: Epoch 67 / 100: avg data time: 7.48e-02, avg batch time: 0.5296, average train loss: 0.0548
[09/28 06:23:49 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 0.0988
[09/28 06:23:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 06:24:12 visual_prompt]: 	Test 100/190. loss: 3.767, 0.2176 s / batch. (data: 2.74e-05)max mem: 7.80407 GB 
[09/28 06:24:32 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2171, average loss: 4.9128
[09/28 06:24:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.53	top5: 97.23	
[09/28 06:24:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/28 06:24:41 visual_prompt]: Epoch 68 / 100: avg data time: 7.62e-02, avg batch time: 0.5302, average train loss: 0.0420
[09/28 06:24:44 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1683, average loss: 0.0639
[09/28 06:24:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 06:25:07 visual_prompt]: 	Test 100/190. loss: 3.809, 0.2171 s / batch. (data: 7.08e-05)max mem: 7.80407 GB 
[09/28 06:25:27 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2168, average loss: 5.0306
[09/28 06:25:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.29	top5: 97.10	
[09/28 06:25:27 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/28 06:25:37 visual_prompt]: Epoch 69 / 100: avg data time: 7.74e-02, avg batch time: 0.5327, average train loss: 0.0331
[09/28 06:25:39 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1683, average loss: 0.0606
[09/28 06:25:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 06:26:02 visual_prompt]: 	Test 100/190. loss: 4.368, 0.2213 s / batch. (data: 2.72e-05)max mem: 7.80407 GB 
[09/28 06:26:23 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2167, average loss: 5.1125
[09/28 06:26:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.14	top5: 97.06	
[09/28 06:26:23 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/28 06:26:32 visual_prompt]: Epoch 70 / 100: avg data time: 7.96e-02, avg batch time: 0.5347, average train loss: 0.0279
[09/28 06:26:34 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1679, average loss: 0.0280
[09/28 06:26:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 06:26:57 visual_prompt]: 	Test 100/190. loss: 3.790, 0.2165 s / batch. (data: 2.69e-05)max mem: 7.80407 GB 
[09/28 06:27:18 visual_prompt]: Inference (test):avg data time: 1.31e-04, avg batch time: 0.2170, average loss: 5.1164
[09/28 06:27:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.61	top5: 97.05	
[09/28 06:27:18 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/28 06:27:27 visual_prompt]: Epoch 71 / 100: avg data time: 7.71e-02, avg batch time: 0.5314, average train loss: 0.0258
[09/28 06:27:30 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1683, average loss: 0.0188
[09/28 06:27:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 06:27:53 visual_prompt]: 	Test 100/190. loss: 3.886, 0.2164 s / batch. (data: 9.44e-05)max mem: 7.80407 GB 
[09/28 06:28:13 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2168, average loss: 5.0717
[09/28 06:28:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.53	top5: 97.40	
[09/28 06:28:13 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/28 06:28:22 visual_prompt]: Epoch 72 / 100: avg data time: 8.11e-02, avg batch time: 0.5351, average train loss: 0.0326
[09/28 06:28:25 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1680, average loss: 0.0143
[09/28 06:28:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 06:28:48 visual_prompt]: 	Test 100/190. loss: 3.554, 0.2169 s / batch. (data: 2.62e-05)max mem: 7.80407 GB 
[09/28 06:29:08 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2169, average loss: 4.9156
[09/28 06:29:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.44	top5: 97.46	
[09/28 06:29:08 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/28 06:29:18 visual_prompt]: Epoch 73 / 100: avg data time: 7.77e-02, avg batch time: 0.5326, average train loss: 0.0266
[09/28 06:29:20 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1680, average loss: 0.0289
[09/28 06:29:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 06:29:43 visual_prompt]: 	Test 100/190. loss: 3.940, 0.2171 s / batch. (data: 2.55e-05)max mem: 7.80407 GB 
[09/28 06:30:04 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2171, average loss: 5.1425
[09/28 06:30:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.83	top5: 96.95	
[09/28 06:30:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/28 06:30:13 visual_prompt]: Epoch 74 / 100: avg data time: 6.63e-02, avg batch time: 0.5231, average train loss: 0.0297
[09/28 06:30:15 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1801, average loss: 0.0227
[09/28 06:30:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 06:30:38 visual_prompt]: 	Test 100/190. loss: 3.783, 0.2165 s / batch. (data: 3.12e-05)max mem: 7.80407 GB 
[09/28 06:30:59 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2171, average loss: 5.1034
[09/28 06:30:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.61	top5: 97.38	
[09/28 06:30:59 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/28 06:31:08 visual_prompt]: Epoch 75 / 100: avg data time: 8.50e-02, avg batch time: 0.5390, average train loss: 0.0146
[09/28 06:31:11 visual_prompt]: Inference (val):avg data time: 1.56e-05, avg batch time: 0.1682, average loss: 0.0229
[09/28 06:31:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 06:31:34 visual_prompt]: 	Test 100/190. loss: 3.606, 0.2158 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 06:31:54 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2169, average loss: 4.9530
[09/28 06:31:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.76	top5: 97.51	
[09/28 06:31:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/28 06:32:03 visual_prompt]: Epoch 76 / 100: avg data time: 8.19e-02, avg batch time: 0.5355, average train loss: 0.0101
[09/28 06:32:06 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1682, average loss: 0.0099
[09/28 06:32:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:32:29 visual_prompt]: 	Test 100/190. loss: 3.667, 0.2185 s / batch. (data: 2.79e-05)max mem: 7.80407 GB 
[09/28 06:32:49 visual_prompt]: Inference (test):avg data time: 1.15e-04, avg batch time: 0.2169, average loss: 5.0416
[09/28 06:32:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.47	top5: 97.39	
[09/28 06:32:49 visual_prompt]: Best epoch 76: best metric: 1.000
[09/28 06:32:49 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/28 06:32:58 visual_prompt]: Epoch 77 / 100: avg data time: 7.67e-02, avg batch time: 0.5307, average train loss: 0.0084
[09/28 06:33:01 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1684, average loss: 0.0090
[09/28 06:33:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:33:24 visual_prompt]: 	Test 100/190. loss: 3.642, 0.2167 s / batch. (data: 2.65e-05)max mem: 7.80407 GB 
[09/28 06:33:44 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2170, average loss: 4.9991
[09/28 06:33:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.60	top5: 97.49	
[09/28 06:33:45 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/28 06:33:54 visual_prompt]: Epoch 78 / 100: avg data time: 8.22e-02, avg batch time: 0.5364, average train loss: 0.0069
[09/28 06:33:56 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1680, average loss: 0.0082
[09/28 06:33:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:34:19 visual_prompt]: 	Test 100/190. loss: 3.560, 0.2177 s / batch. (data: 2.41e-05)max mem: 7.80407 GB 
[09/28 06:34:40 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2168, average loss: 4.9802
[09/28 06:34:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.53	top5: 97.44	
[09/28 06:34:40 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/28 06:34:49 visual_prompt]: Epoch 79 / 100: avg data time: 6.90e-02, avg batch time: 0.5249, average train loss: 0.0043
[09/28 06:34:51 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1683, average loss: 0.0090
[09/28 06:34:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:35:14 visual_prompt]: 	Test 100/190. loss: 3.542, 0.2160 s / batch. (data: 6.51e-05)max mem: 7.80407 GB 
[09/28 06:35:35 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2169, average loss: 4.9494
[09/28 06:35:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.55	top5: 97.48	
[09/28 06:35:35 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/28 06:35:44 visual_prompt]: Epoch 80 / 100: avg data time: 7.02e-02, avg batch time: 0.5240, average train loss: 0.0043
[09/28 06:35:47 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1679, average loss: 0.0129
[09/28 06:35:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 06:36:09 visual_prompt]: 	Test 100/190. loss: 3.565, 0.2177 s / batch. (data: 2.29e-05)max mem: 7.80407 GB 
[09/28 06:36:30 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2168, average loss: 4.9964
[09/28 06:36:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.32	top5: 97.42	
[09/28 06:36:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/28 06:36:39 visual_prompt]: Epoch 81 / 100: avg data time: 8.34e-02, avg batch time: 0.5373, average train loss: 0.0041
[09/28 06:36:42 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1680, average loss: 0.0109
[09/28 06:36:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:37:05 visual_prompt]: 	Test 100/190. loss: 3.554, 0.2169 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 06:37:25 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2167, average loss: 4.9768
[09/28 06:37:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.42	
[09/28 06:37:25 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/28 06:37:35 visual_prompt]: Epoch 82 / 100: avg data time: 8.82e-02, avg batch time: 0.5415, average train loss: 0.0060
[09/28 06:37:37 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1683, average loss: 0.0101
[09/28 06:37:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:38:00 visual_prompt]: 	Test 100/190. loss: 3.787, 0.2172 s / batch. (data: 9.08e-05)max mem: 7.80407 GB 
[09/28 06:38:21 visual_prompt]: Inference (test):avg data time: 7.04e-05, avg batch time: 0.2170, average loss: 5.1550
[09/28 06:38:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.79	top5: 97.23	
[09/28 06:38:21 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/28 06:38:30 visual_prompt]: Epoch 83 / 100: avg data time: 7.83e-02, avg batch time: 0.5325, average train loss: 0.0054
[09/28 06:38:32 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1685, average loss: 0.0027
[09/28 06:38:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:38:55 visual_prompt]: 	Test 100/190. loss: 3.797, 0.2174 s / batch. (data: 2.38e-05)max mem: 7.80407 GB 
[09/28 06:39:16 visual_prompt]: Inference (test):avg data time: 1.14e-04, avg batch time: 0.2168, average loss: 4.9613
[09/28 06:39:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.41	top5: 97.42	
[09/28 06:39:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/28 06:39:25 visual_prompt]: Epoch 84 / 100: avg data time: 6.87e-02, avg batch time: 0.5241, average train loss: 0.0043
[09/28 06:39:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1684, average loss: 0.0032
[09/28 06:39:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:39:51 visual_prompt]: 	Test 100/190. loss: 3.688, 0.2174 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 06:40:11 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2169, average loss: 4.9379
[09/28 06:40:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.45	
[09/28 06:40:11 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/28 06:40:20 visual_prompt]: Epoch 85 / 100: avg data time: 8.42e-02, avg batch time: 0.5387, average train loss: 0.0042
[09/28 06:40:23 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1679, average loss: 0.0032
[09/28 06:40:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:40:46 visual_prompt]: 	Test 100/190. loss: 3.670, 0.2168 s / batch. (data: 2.86e-05)max mem: 7.80407 GB 
[09/28 06:41:06 visual_prompt]: Inference (test):avg data time: 5.03e-05, avg batch time: 0.2170, average loss: 4.9700
[09/28 06:41:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.25	top5: 97.47	
[09/28 06:41:06 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/28 06:41:15 visual_prompt]: Epoch 86 / 100: avg data time: 6.89e-02, avg batch time: 0.5237, average train loss: 0.0034
[09/28 06:41:18 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1682, average loss: 0.0037
[09/28 06:41:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:41:41 visual_prompt]: 	Test 100/190. loss: 3.668, 0.2165 s / batch. (data: 2.60e-05)max mem: 7.80407 GB 
[09/28 06:42:01 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2167, average loss: 5.0040
[09/28 06:42:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.17	top5: 97.43	
[09/28 06:42:01 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/28 06:42:11 visual_prompt]: Epoch 87 / 100: avg data time: 7.14e-02, avg batch time: 0.5258, average train loss: 0.0044
[09/28 06:42:13 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1681, average loss: 0.0026
[09/28 06:42:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:42:36 visual_prompt]: 	Test 100/190. loss: 3.673, 0.2170 s / batch. (data: 2.41e-05)max mem: 7.80407 GB 
[09/28 06:42:57 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2168, average loss: 4.9448
[09/28 06:42:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.46	top5: 97.48	
[09/28 06:42:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/28 06:43:06 visual_prompt]: Epoch 88 / 100: avg data time: 8.38e-02, avg batch time: 0.5374, average train loss: 0.0063
[09/28 06:43:09 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1681, average loss: 0.0026
[09/28 06:43:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:43:32 visual_prompt]: 	Test 100/190. loss: 3.715, 0.2172 s / batch. (data: 2.69e-05)max mem: 7.80407 GB 
[09/28 06:43:52 visual_prompt]: Inference (test):avg data time: 4.58e-05, avg batch time: 0.2168, average loss: 4.8880
[09/28 06:43:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.77	top5: 97.47	
[09/28 06:43:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/28 06:44:01 visual_prompt]: Epoch 89 / 100: avg data time: 8.57e-02, avg batch time: 0.5394, average train loss: 0.0044
[09/28 06:44:04 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1686, average loss: 0.0027
[09/28 06:44:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:44:27 visual_prompt]: 	Test 100/190. loss: 3.705, 0.2171 s / batch. (data: 2.36e-05)max mem: 7.80407 GB 
[09/28 06:44:47 visual_prompt]: Inference (test):avg data time: 8.60e-05, avg batch time: 0.2169, average loss: 4.9023
[09/28 06:44:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.79	top5: 97.46	
[09/28 06:44:47 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/28 06:44:57 visual_prompt]: Epoch 90 / 100: avg data time: 8.17e-02, avg batch time: 0.5357, average train loss: 0.0034
[09/28 06:44:59 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1687, average loss: 0.0027
[09/28 06:44:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:45:22 visual_prompt]: 	Test 100/190. loss: 3.704, 0.2172 s / batch. (data: 2.48e-05)max mem: 7.80407 GB 
[09/28 06:45:43 visual_prompt]: Inference (test):avg data time: 2.63e-05, avg batch time: 0.2167, average loss: 4.9158
[09/28 06:45:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.63	top5: 97.42	
[09/28 06:45:43 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/28 06:45:52 visual_prompt]: Epoch 91 / 100: avg data time: 8.03e-02, avg batch time: 0.5335, average train loss: 0.0035
[09/28 06:45:54 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1681, average loss: 0.0029
[09/28 06:45:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:46:17 visual_prompt]: 	Test 100/190. loss: 3.702, 0.2170 s / batch. (data: 2.72e-05)max mem: 7.80407 GB 
[09/28 06:46:38 visual_prompt]: Inference (test):avg data time: 4.05e-05, avg batch time: 0.2167, average loss: 4.9371
[09/28 06:46:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.54	top5: 97.43	
[09/28 06:46:38 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/28 06:46:47 visual_prompt]: Epoch 92 / 100: avg data time: 7.40e-02, avg batch time: 0.5273, average train loss: 0.0027
[09/28 06:46:49 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1682, average loss: 0.0032
[09/28 06:46:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:47:26 visual_prompt]: 	Test 100/190. loss: 3.697, 0.2157 s / batch. (data: 1.93e-05)max mem: 7.80407 GB 
[09/28 06:47:47 visual_prompt]: Inference (test):avg data time: 1.89e-04, avg batch time: 0.2251, average loss: 4.9444
[09/28 06:47:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.47	top5: 97.42	
[09/28 06:47:47 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/28 06:47:56 visual_prompt]: Epoch 93 / 100: avg data time: 8.87e-02, avg batch time: 0.5403, average train loss: 0.0038
[09/28 06:47:59 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 0.0032
[09/28 06:47:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:48:21 visual_prompt]: 	Test 100/190. loss: 3.694, 0.2175 s / batch. (data: 2.57e-05)max mem: 7.80407 GB 
[09/28 06:49:03 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.3299, average loss: 4.9411
[09/28 06:49:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.53	top5: 97.45	
[09/28 06:49:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/28 06:49:13 visual_prompt]: Epoch 94 / 100: avg data time: 7.75e-02, avg batch time: 0.5279, average train loss: 0.0032
[09/28 06:49:15 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1664, average loss: 0.0034
[09/28 06:49:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:49:47 visual_prompt]: 	Test 100/190. loss: 3.692, 0.2130 s / batch. (data: 2.81e-05)max mem: 7.80407 GB 
[09/28 06:50:07 visual_prompt]: Inference (test):avg data time: 1.48e-03, avg batch time: 0.2337, average loss: 4.9505
[09/28 06:50:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.51	top5: 97.45	
[09/28 06:50:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/28 06:50:17 visual_prompt]: Epoch 95 / 100: avg data time: 7.62e-02, avg batch time: 0.5300, average train loss: 0.0041
[09/28 06:50:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 0.0034
[09/28 06:50:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:50:42 visual_prompt]: 	Test 100/190. loss: 3.689, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.80407 GB 
[09/28 06:51:03 visual_prompt]: Inference (test):avg data time: 4.35e-05, avg batch time: 0.2156, average loss: 4.9551
[09/28 06:51:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.44	
[09/28 06:51:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/28 06:51:12 visual_prompt]: Epoch 96 / 100: avg data time: 7.49e-02, avg batch time: 0.5278, average train loss: 0.0035
[09/28 06:51:14 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1680, average loss: 0.0034
[09/28 06:51:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:51:37 visual_prompt]: 	Test 100/190. loss: 3.689, 0.2161 s / batch. (data: 2.86e-05)max mem: 7.80407 GB 
[09/28 06:51:57 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2162, average loss: 4.9572
[09/28 06:51:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.42	
[09/28 06:51:57 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/28 06:52:07 visual_prompt]: Epoch 97 / 100: avg data time: 7.72e-02, avg batch time: 0.5313, average train loss: 0.0032
[09/28 06:52:09 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1691, average loss: 0.0034
[09/28 06:52:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:52:32 visual_prompt]: 	Test 100/190. loss: 3.688, 0.2163 s / batch. (data: 2.62e-05)max mem: 7.80407 GB 
[09/28 06:52:52 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2165, average loss: 4.9552
[09/28 06:52:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.36	top5: 97.42	
[09/28 06:52:52 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/28 06:53:02 visual_prompt]: Epoch 98 / 100: avg data time: 7.50e-02, avg batch time: 0.5277, average train loss: 0.0029
[09/28 06:53:04 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1677, average loss: 0.0033
[09/28 06:53:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:53:27 visual_prompt]: 	Test 100/190. loss: 3.687, 0.2158 s / batch. (data: 2.55e-05)max mem: 7.80407 GB 
[09/28 06:53:47 visual_prompt]: Inference (test):avg data time: 4.13e-05, avg batch time: 0.2164, average loss: 4.9539
[09/28 06:53:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.42	
[09/28 06:53:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/28 06:53:56 visual_prompt]: Epoch 99 / 100: avg data time: 6.65e-02, avg batch time: 0.5217, average train loss: 0.0034
[09/28 06:53:59 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1678, average loss: 0.0033
[09/28 06:53:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:54:22 visual_prompt]: 	Test 100/190. loss: 3.686, 0.2174 s / batch. (data: 2.65e-05)max mem: 7.80407 GB 
[09/28 06:54:42 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2165, average loss: 4.9539
[09/28 06:54:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.43	
[09/28 06:54:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/28 06:54:51 visual_prompt]: Epoch 100 / 100: avg data time: 7.45e-02, avg batch time: 0.5292, average train loss: 0.0030
[09/28 06:54:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1679, average loss: 0.0033
[09/28 06:54:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 06:55:17 visual_prompt]: 	Test 100/190. loss: 3.686, 0.2163 s / batch. (data: 2.67e-05)max mem: 7.80407 GB 
[09/28 06:55:37 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2168, average loss: 4.9539
[09/28 06:55:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.40	top5: 97.44	
[09/28 06:55:37 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 06:55:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 06:55:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 06:55:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 06:55:37 visual_prompt]: Training with config:
[09/28 06:55:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_elevation")/sup_vitb16_imagenet21k/prompt50/crop224/test/seed1332/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 1332, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 9, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 06:55:37 visual_prompt]: Loading training data...
[09/28 06:55:37 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800]+test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 06:55:48 visual_prompt]: Number of images: 1000
[09/28 06:55:48 visual_prompt]: Number of classes: 9 / 9
[09/28 06:55:48 visual_prompt]: Loading validation data...
[09/28 06:55:48 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 06:55:49 visual_prompt]: Number of images: 200
[09/28 06:55:49 visual_prompt]: Number of classes: 9 / 9
[09/28 06:55:49 visual_prompt]: Loading test data...
[09/28 06:55:49 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[50%:], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 06:56:03 visual_prompt]: Number of images: 12150
[09/28 06:56:03 visual_prompt]: Number of classes: 9 / 9
[09/28 06:56:03 visual_prompt]: Constructing models...
[09/28 06:56:06 visual_prompt]: Total Parameters: 86266377	 Gradient Parameters: 467721
[09/28 06:56:06 visual_prompt]: tuned percent:0.542
[09/28 06:56:06 visual_prompt]: Device used for model: 0
[09/28 06:56:06 visual_prompt]: Setting up Evaluator...
[09/28 06:56:06 visual_prompt]: Setting up Trainer...
[09/28 06:56:06 visual_prompt]: 	Setting up the optimizer...
[09/28 06:56:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 06:56:16 visual_prompt]: Epoch 1 / 100: avg data time: 7.82e-02, avg batch time: 0.5259, average train loss: 2.4452
[09/28 06:56:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1657, average loss: 2.4271
[09/28 06:56:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 52.00	
[09/28 06:56:41 visual_prompt]: 	Test 100/190. loss: 2.266, 0.2146 s / batch. (data: 2.57e-05)max mem: 7.80576 GB 
[09/28 06:57:01 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2141, average loss: 2.3934
[09/28 06:57:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 55.97	
[09/28 06:57:01 visual_prompt]: Best epoch 1: best metric: 0.095
[09/28 06:57:01 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/28 06:57:10 visual_prompt]: Epoch 2 / 100: avg data time: 8.01e-02, avg batch time: 0.5310, average train loss: 2.6281
[09/28 06:57:13 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1669, average loss: 2.3839
[09/28 06:57:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 55.50	
[09/28 06:57:36 visual_prompt]: 	Test 100/190. loss: 2.519, 0.2147 s / batch. (data: 6.20e-05)max mem: 7.80576 GB 
[09/28 06:57:56 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2154, average loss: 2.4364
[09/28 06:57:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.97	
[09/28 06:57:56 visual_prompt]: Best epoch 2: best metric: 0.130
[09/28 06:57:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/28 06:58:05 visual_prompt]: Epoch 3 / 100: avg data time: 7.68e-02, avg batch time: 0.5302, average train loss: 2.3136
[09/28 06:58:08 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1675, average loss: 2.2062
[09/28 06:58:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 63.50	
[09/28 06:58:31 visual_prompt]: 	Test 100/190. loss: 2.235, 0.2160 s / batch. (data: 2.74e-05)max mem: 7.80576 GB 
[09/28 06:58:51 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2158, average loss: 2.2219
[09/28 06:58:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 58.65	
[09/28 06:58:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/28 06:59:00 visual_prompt]: Epoch 4 / 100: avg data time: 7.21e-02, avg batch time: 0.5256, average train loss: 2.2357
[09/28 06:59:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 2.2070
[09/28 06:59:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.50	top5: 60.00	
[09/28 06:59:26 visual_prompt]: 	Test 100/190. loss: 2.181, 0.2161 s / batch. (data: 2.48e-05)max mem: 7.80576 GB 
[09/28 06:59:46 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2160, average loss: 2.2176
[09/28 06:59:46 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.78	top5: 58.44	
[09/28 06:59:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/28 06:59:55 visual_prompt]: Epoch 5 / 100: avg data time: 7.48e-02, avg batch time: 0.5290, average train loss: 2.2368
[09/28 06:59:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1677, average loss: 2.2476
[09/28 06:59:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 62.00	
[09/28 07:00:20 visual_prompt]: 	Test 100/190. loss: 2.210, 0.2163 s / batch. (data: 2.24e-05)max mem: 7.80576 GB 
[09/28 07:00:41 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2161, average loss: 2.2652
[09/28 07:00:41 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 58.93	
[09/28 07:00:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/28 07:00:50 visual_prompt]: Epoch 6 / 100: avg data time: 6.84e-02, avg batch time: 0.5218, average train loss: 2.1909
[09/28 07:00:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1677, average loss: 2.2396
[09/28 07:00:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 66.00	
[09/28 07:01:15 visual_prompt]: 	Test 100/190. loss: 2.161, 0.2182 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 07:01:36 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2162, average loss: 2.1915
[09/28 07:01:36 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.80	top5: 67.78	
[09/28 07:01:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/28 07:01:45 visual_prompt]: Epoch 7 / 100: avg data time: 7.22e-02, avg batch time: 0.5258, average train loss: 2.1349
[09/28 07:01:48 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1681, average loss: 2.1496
[09/28 07:01:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.00	top5: 71.50	
[09/28 07:02:11 visual_prompt]: 	Test 100/190. loss: 2.232, 0.2166 s / batch. (data: 2.77e-05)max mem: 7.80576 GB 
[09/28 07:02:31 visual_prompt]: Inference (test):avg data time: 3.72e-05, avg batch time: 0.2164, average loss: 2.1495
[09/28 07:02:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.58	top5: 72.97	
[09/28 07:02:31 visual_prompt]: Best epoch 7: best metric: 0.180
[09/28 07:02:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/28 07:02:40 visual_prompt]: Epoch 8 / 100: avg data time: 8.19e-02, avg batch time: 0.5359, average train loss: 2.1656
[09/28 07:02:43 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1677, average loss: 2.1460
[09/28 07:02:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.50	top5: 70.50	
[09/28 07:03:06 visual_prompt]: 	Test 100/190. loss: 2.300, 0.2159 s / batch. (data: 2.79e-05)max mem: 7.80576 GB 
[09/28 07:03:26 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2165, average loss: 2.2372
[09/28 07:03:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.24	top5: 67.43	
[09/28 07:03:26 visual_prompt]: Best epoch 8: best metric: 0.195
[09/28 07:03:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/28 07:03:35 visual_prompt]: Epoch 9 / 100: avg data time: 7.96e-02, avg batch time: 0.5325, average train loss: 2.1462
[09/28 07:03:38 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1680, average loss: 2.4381
[09/28 07:03:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 63.50	
[09/28 07:04:01 visual_prompt]: 	Test 100/190. loss: 2.813, 0.2174 s / batch. (data: 2.88e-05)max mem: 7.80576 GB 
[09/28 07:04:21 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2164, average loss: 2.5418
[09/28 07:04:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.87	top5: 63.23	
[09/28 07:04:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/28 07:04:31 visual_prompt]: Epoch 10 / 100: avg data time: 8.22e-02, avg batch time: 0.5363, average train loss: 2.2165
[09/28 07:04:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 1.8876
[09/28 07:04:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.00	top5: 82.50	
[09/28 07:04:56 visual_prompt]: 	Test 100/190. loss: 1.847, 0.2167 s / batch. (data: 6.53e-05)max mem: 7.80576 GB 
[09/28 07:05:16 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2165, average loss: 1.9300
[09/28 07:05:17 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.44	top5: 83.09	
[09/28 07:05:17 visual_prompt]: Best epoch 10: best metric: 0.220
[09/28 07:05:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/28 07:05:26 visual_prompt]: Epoch 11 / 100: avg data time: 7.04e-02, avg batch time: 0.5248, average train loss: 1.9533
[09/28 07:05:28 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1679, average loss: 1.9970
[09/28 07:05:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.00	top5: 81.50	
[09/28 07:05:51 visual_prompt]: 	Test 100/190. loss: 2.289, 0.2175 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 07:06:11 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2164, average loss: 2.0818
[09/28 07:06:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.55	top5: 79.88	
[09/28 07:06:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/28 07:06:21 visual_prompt]: Epoch 12 / 100: avg data time: 7.02e-02, avg batch time: 0.5248, average train loss: 1.9703
[09/28 07:06:23 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1682, average loss: 1.8467
[09/28 07:06:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.50	top5: 82.00	
[09/28 07:06:46 visual_prompt]: 	Test 100/190. loss: 2.062, 0.2158 s / batch. (data: 2.48e-05)max mem: 7.80576 GB 
[09/28 07:07:07 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2163, average loss: 1.9165
[09/28 07:07:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.51	top5: 82.21	
[09/28 07:07:07 visual_prompt]: Best epoch 12: best metric: 0.265
[09/28 07:07:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/28 07:07:16 visual_prompt]: Epoch 13 / 100: avg data time: 8.12e-02, avg batch time: 0.5356, average train loss: 2.0371
[09/28 07:07:18 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1679, average loss: 2.2461
[09/28 07:07:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.00	top5: 73.50	
[09/28 07:07:41 visual_prompt]: 	Test 100/190. loss: 2.248, 0.2165 s / batch. (data: 2.57e-05)max mem: 7.80576 GB 
[09/28 07:08:02 visual_prompt]: Inference (test):avg data time: 7.57e-05, avg batch time: 0.2165, average loss: 2.2646
[09/28 07:08:02 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.99	top5: 78.77	
[09/28 07:08:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/28 07:08:11 visual_prompt]: Epoch 14 / 100: avg data time: 7.98e-02, avg batch time: 0.5343, average train loss: 1.8646
[09/28 07:08:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 1.6494
[09/28 07:08:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.00	top5: 94.50	
[09/28 07:08:37 visual_prompt]: 	Test 100/190. loss: 1.645, 0.2165 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 07:08:57 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2164, average loss: 1.7388
[09/28 07:08:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.92	top5: 92.79	
[09/28 07:08:57 visual_prompt]: Best epoch 14: best metric: 0.310
[09/28 07:08:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/28 07:09:06 visual_prompt]: Epoch 15 / 100: avg data time: 7.73e-02, avg batch time: 0.5311, average train loss: 1.6385
[09/28 07:09:09 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1678, average loss: 1.5319
[09/28 07:09:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.00	top5: 97.00	
[09/28 07:09:32 visual_prompt]: 	Test 100/190. loss: 1.747, 0.2175 s / batch. (data: 2.24e-05)max mem: 7.80576 GB 
[09/28 07:09:52 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2164, average loss: 1.7348
[09/28 07:09:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.35	top5: 93.90	
[09/28 07:09:52 visual_prompt]: Best epoch 15: best metric: 0.380
[09/28 07:09:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/28 07:10:02 visual_prompt]: Epoch 16 / 100: avg data time: 8.18e-02, avg batch time: 0.5356, average train loss: 1.7145
[09/28 07:10:04 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1683, average loss: 2.7260
[09/28 07:10:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.50	top5: 76.00	
[09/28 07:10:27 visual_prompt]: 	Test 100/190. loss: 3.273, 0.2179 s / batch. (data: 2.50e-05)max mem: 7.80576 GB 
[09/28 07:10:48 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2164, average loss: 2.9486
[09/28 07:10:48 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.33	top5: 71.54	
[09/28 07:10:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/28 07:10:57 visual_prompt]: Epoch 17 / 100: avg data time: 8.02e-02, avg batch time: 0.5349, average train loss: 2.5704
[09/28 07:10:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1679, average loss: 2.4830
[09/28 07:10:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 59.50	
[09/28 07:11:22 visual_prompt]: 	Test 100/190. loss: 2.468, 0.2156 s / batch. (data: 3.10e-05)max mem: 7.80576 GB 
[09/28 07:11:43 visual_prompt]: Inference (test):avg data time: 4.92e-05, avg batch time: 0.2161, average loss: 2.4774
[09/28 07:11:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 59.64	
[09/28 07:11:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/28 07:11:52 visual_prompt]: Epoch 18 / 100: avg data time: 6.76e-02, avg batch time: 0.5225, average train loss: 2.2392
[09/28 07:11:54 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1676, average loss: 2.0300
[09/28 07:11:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.50	top5: 82.00	
[09/28 07:12:17 visual_prompt]: 	Test 100/190. loss: 2.037, 0.2159 s / batch. (data: 2.62e-05)max mem: 7.80576 GB 
[09/28 07:12:38 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2163, average loss: 2.0467
[09/28 07:12:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.93	top5: 79.40	
[09/28 07:12:38 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/28 07:12:47 visual_prompt]: Epoch 19 / 100: avg data time: 6.85e-02, avg batch time: 0.5253, average train loss: 1.9260
[09/28 07:12:49 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1679, average loss: 1.8640
[09/28 07:12:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.00	top5: 86.50	
[09/28 07:13:12 visual_prompt]: 	Test 100/190. loss: 2.022, 0.2176 s / batch. (data: 2.53e-05)max mem: 7.80576 GB 
[09/28 07:13:33 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2165, average loss: 1.9915
[09/28 07:13:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.45	top5: 82.94	
[09/28 07:13:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/28 07:13:42 visual_prompt]: Epoch 20 / 100: avg data time: 8.03e-02, avg batch time: 0.5345, average train loss: 1.7433
[09/28 07:13:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1682, average loss: 1.6956
[09/28 07:13:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.00	top5: 90.00	
[09/28 07:14:07 visual_prompt]: 	Test 100/190. loss: 1.949, 0.2162 s / batch. (data: 2.57e-05)max mem: 7.80576 GB 
[09/28 07:14:28 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2164, average loss: 1.8467
[09/28 07:14:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.45	top5: 89.19	
[09/28 07:14:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/28 07:14:37 visual_prompt]: Epoch 21 / 100: avg data time: 8.42e-02, avg batch time: 0.5374, average train loss: 1.6685
[09/28 07:14:40 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1678, average loss: 3.1719
[09/28 07:14:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.00	top5: 72.00	
[09/28 07:15:03 visual_prompt]: 	Test 100/190. loss: 3.035, 0.2168 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 07:15:23 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2166, average loss: 3.3946
[09/28 07:15:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.48	top5: 71.31	
[09/28 07:15:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/28 07:15:33 visual_prompt]: Epoch 22 / 100: avg data time: 8.35e-02, avg batch time: 0.5376, average train loss: 1.8119
[09/28 07:15:35 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1680, average loss: 1.8046
[09/28 07:15:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.00	top5: 93.50	
[09/28 07:15:58 visual_prompt]: 	Test 100/190. loss: 1.892, 0.2169 s / batch. (data: 7.75e-05)max mem: 7.80576 GB 
[09/28 07:16:18 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2166, average loss: 1.9301
[09/28 07:16:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.13	top5: 90.67	
[09/28 07:16:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/28 07:16:28 visual_prompt]: Epoch 23 / 100: avg data time: 7.89e-02, avg batch time: 0.5330, average train loss: 1.6580
[09/28 07:16:30 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1681, average loss: 1.4552
[09/28 07:16:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.50	top5: 97.00	
[09/28 07:16:53 visual_prompt]: 	Test 100/190. loss: 1.972, 0.2170 s / batch. (data: 2.53e-05)max mem: 7.80576 GB 
[09/28 07:17:14 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2165, average loss: 1.6786
[09/28 07:17:14 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.11	top5: 94.28	
[09/28 07:17:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/28 07:17:23 visual_prompt]: Epoch 24 / 100: avg data time: 8.28e-02, avg batch time: 0.5368, average train loss: 1.6206
[09/28 07:17:25 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1681, average loss: 1.9472
[09/28 07:17:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.50	top5: 94.00	
[09/28 07:17:48 visual_prompt]: 	Test 100/190. loss: 2.389, 0.2169 s / batch. (data: 7.30e-05)max mem: 7.80576 GB 
[09/28 07:18:09 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2165, average loss: 2.1590
[09/28 07:18:09 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.60	top5: 90.82	
[09/28 07:18:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/28 07:18:18 visual_prompt]: Epoch 25 / 100: avg data time: 8.58e-02, avg batch time: 0.5396, average train loss: 1.6390
[09/28 07:18:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1679, average loss: 1.5341
[09/28 07:18:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.50	top5: 97.00	
[09/28 07:18:44 visual_prompt]: 	Test 100/190. loss: 1.756, 0.2160 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 07:19:04 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2165, average loss: 1.7609
[09/28 07:19:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.21	top5: 92.49	
[09/28 07:19:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/28 07:19:14 visual_prompt]: Epoch 26 / 100: avg data time: 7.83e-02, avg batch time: 0.5327, average train loss: 1.5365
[09/28 07:19:16 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1680, average loss: 1.4759
[09/28 07:19:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.00	top5: 96.50	
[09/28 07:19:39 visual_prompt]: 	Test 100/190. loss: 1.922, 0.2170 s / batch. (data: 2.53e-05)max mem: 7.80576 GB 
[09/28 07:19:59 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2166, average loss: 1.7515
[09/28 07:19:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.84	top5: 93.70	
[09/28 07:19:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/28 07:20:09 visual_prompt]: Epoch 27 / 100: avg data time: 7.53e-02, avg batch time: 0.5304, average train loss: 1.4165
[09/28 07:20:11 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1683, average loss: 1.1981
[09/28 07:20:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 44.50	top5: 100.00	
[09/28 07:20:34 visual_prompt]: 	Test 100/190. loss: 1.812, 0.2166 s / batch. (data: 2.48e-05)max mem: 7.80576 GB 
[09/28 07:20:54 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2166, average loss: 1.7185
[09/28 07:20:55 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.67	top5: 96.38	
[09/28 07:20:55 visual_prompt]: Best epoch 27: best metric: 0.445
[09/28 07:20:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/28 07:21:04 visual_prompt]: Epoch 28 / 100: avg data time: 7.10e-02, avg batch time: 0.5255, average train loss: 1.2959
[09/28 07:21:06 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1679, average loss: 1.1275
[09/28 07:21:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 54.00	top5: 100.00	
[09/28 07:21:29 visual_prompt]: 	Test 100/190. loss: 1.805, 0.2169 s / batch. (data: 2.69e-05)max mem: 7.80576 GB 
[09/28 07:21:50 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2165, average loss: 1.6726
[09/28 07:21:50 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.30	top5: 96.44	
[09/28 07:21:50 visual_prompt]: Best epoch 28: best metric: 0.540
[09/28 07:21:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/28 07:21:59 visual_prompt]: Epoch 29 / 100: avg data time: 7.85e-02, avg batch time: 0.5332, average train loss: 1.2254
[09/28 07:22:01 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1680, average loss: 1.0013
[09/28 07:22:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 56.00	top5: 99.50	
[09/28 07:22:24 visual_prompt]: 	Test 100/190. loss: 1.602, 0.2172 s / batch. (data: 2.57e-05)max mem: 7.80576 GB 
[09/28 07:22:45 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2167, average loss: 1.6665
[09/28 07:22:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.50	top5: 95.99	
[09/28 07:22:45 visual_prompt]: Best epoch 29: best metric: 0.560
[09/28 07:22:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/28 07:22:54 visual_prompt]: Epoch 30 / 100: avg data time: 9.07e-02, avg batch time: 0.5444, average train loss: 1.1683
[09/28 07:22:57 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1680, average loss: 1.3237
[09/28 07:22:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 42.50	top5: 100.00	
[09/28 07:23:20 visual_prompt]: 	Test 100/190. loss: 2.165, 0.2169 s / batch. (data: 6.41e-05)max mem: 7.80576 GB 
[09/28 07:23:40 visual_prompt]: Inference (test):avg data time: 5.57e-05, avg batch time: 0.2166, average loss: 1.9341
[09/28 07:23:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.09	top5: 94.80	
[09/28 07:23:40 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/28 07:23:50 visual_prompt]: Epoch 31 / 100: avg data time: 8.13e-02, avg batch time: 0.5368, average train loss: 1.2524
[09/28 07:23:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1681, average loss: 1.3127
[09/28 07:23:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.50	top5: 99.50	
[09/28 07:24:15 visual_prompt]: 	Test 100/190. loss: 1.787, 0.2169 s / batch. (data: 2.81e-05)max mem: 7.80576 GB 
[09/28 07:24:35 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2166, average loss: 1.9484
[09/28 07:24:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.85	top5: 94.05	
[09/28 07:24:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/28 07:24:45 visual_prompt]: Epoch 32 / 100: avg data time: 8.34e-02, avg batch time: 0.5374, average train loss: 1.3108
[09/28 07:24:47 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1680, average loss: 1.2012
[09/28 07:24:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 46.50	top5: 100.00	
[09/28 07:25:10 visual_prompt]: 	Test 100/190. loss: 1.845, 0.2162 s / batch. (data: 2.98e-05)max mem: 7.80576 GB 
[09/28 07:25:31 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2164, average loss: 1.7716
[09/28 07:25:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.40	top5: 94.07	
[09/28 07:25:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/28 07:25:40 visual_prompt]: Epoch 33 / 100: avg data time: 8.07e-02, avg batch time: 0.5349, average train loss: 1.3068
[09/28 07:25:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1680, average loss: 1.1259
[09/28 07:25:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 54.00	top5: 98.50	
[09/28 07:26:05 visual_prompt]: 	Test 100/190. loss: 1.573, 0.2166 s / batch. (data: 2.60e-05)max mem: 7.80576 GB 
[09/28 07:26:26 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2166, average loss: 1.6403
[09/28 07:26:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.60	top5: 95.47	
[09/28 07:26:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/28 07:26:35 visual_prompt]: Epoch 34 / 100: avg data time: 6.94e-02, avg batch time: 0.5246, average train loss: 1.1178
[09/28 07:26:37 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1681, average loss: 1.1080
[09/28 07:26:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 53.50	top5: 99.50	
[09/28 07:27:00 visual_prompt]: 	Test 100/190. loss: 1.637, 0.2161 s / batch. (data: 2.69e-05)max mem: 7.80576 GB 
[09/28 07:27:42 visual_prompt]: Inference (test):avg data time: 4.08e-05, avg batch time: 0.3290, average loss: 1.8968
[09/28 07:27:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.65	top5: 95.27	
[09/28 07:27:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/28 07:27:51 visual_prompt]: Epoch 35 / 100: avg data time: 7.23e-02, avg batch time: 0.5232, average train loss: 1.0667
[09/28 07:27:54 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1667, average loss: 0.9445
[09/28 07:27:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 55.50	top5: 99.00	
[09/28 07:28:16 visual_prompt]: 	Test 100/190. loss: 1.740, 0.2158 s / batch. (data: 7.65e-05)max mem: 7.80576 GB 
[09/28 07:28:37 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2154, average loss: 1.7944
[09/28 07:28:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.07	top5: 96.31	
[09/28 07:28:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/28 07:28:46 visual_prompt]: Epoch 36 / 100: avg data time: 7.28e-02, avg batch time: 0.5253, average train loss: 0.9694
[09/28 07:28:48 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 1.1705
[09/28 07:28:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 49.00	top5: 100.00	
[09/28 07:29:11 visual_prompt]: 	Test 100/190. loss: 1.846, 0.2161 s / batch. (data: 2.84e-05)max mem: 7.80576 GB 
[09/28 07:29:32 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2164, average loss: 2.2235
[09/28 07:29:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.79	top5: 95.01	
[09/28 07:29:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/28 07:29:41 visual_prompt]: Epoch 37 / 100: avg data time: 7.05e-02, avg batch time: 0.5253, average train loss: 1.0872
[09/28 07:29:43 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 1.0411
[09/28 07:29:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 54.00	top5: 100.00	
[09/28 07:30:06 visual_prompt]: 	Test 100/190. loss: 1.861, 0.2174 s / batch. (data: 2.41e-05)max mem: 7.80576 GB 
[09/28 07:30:27 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2164, average loss: 1.9230
[09/28 07:30:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.36	top5: 95.20	
[09/28 07:30:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/28 07:30:36 visual_prompt]: Epoch 38 / 100: avg data time: 8.31e-02, avg batch time: 0.5363, average train loss: 0.9087
[09/28 07:30:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1679, average loss: 0.8439
[09/28 07:30:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 58.50	top5: 100.00	
[09/28 07:31:02 visual_prompt]: 	Test 100/190. loss: 1.598, 0.2169 s / batch. (data: 2.79e-05)max mem: 7.80576 GB 
[09/28 07:31:22 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2166, average loss: 1.8322
[09/28 07:31:22 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.49	top5: 96.73	
[09/28 07:31:22 visual_prompt]: Best epoch 38: best metric: 0.585
[09/28 07:31:22 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/28 07:31:31 visual_prompt]: Epoch 39 / 100: avg data time: 7.95e-02, avg batch time: 0.5337, average train loss: 0.8456
[09/28 07:31:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1680, average loss: 0.9057
[09/28 07:31:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 62.00	top5: 100.00	
[09/28 07:31:57 visual_prompt]: 	Test 100/190. loss: 2.028, 0.2169 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 07:32:17 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2166, average loss: 2.1272
[09/28 07:32:17 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.21	top5: 97.14	
[09/28 07:32:17 visual_prompt]: Best epoch 39: best metric: 0.620
[09/28 07:32:17 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/28 07:32:26 visual_prompt]: Epoch 40 / 100: avg data time: 7.28e-02, avg batch time: 0.5281, average train loss: 0.9345
[09/28 07:32:29 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1681, average loss: 0.8287
[09/28 07:32:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 64.00	top5: 100.00	
[09/28 07:32:52 visual_prompt]: 	Test 100/190. loss: 1.718, 0.2173 s / batch. (data: 2.86e-05)max mem: 7.80576 GB 
[09/28 07:33:12 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2165, average loss: 1.8586
[09/28 07:33:12 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.14	top5: 96.57	
[09/28 07:33:12 visual_prompt]: Best epoch 40: best metric: 0.640
[09/28 07:33:12 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/28 07:33:21 visual_prompt]: Epoch 41 / 100: avg data time: 7.39e-02, avg batch time: 0.5285, average train loss: 0.9328
[09/28 07:33:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1679, average loss: 0.9568
[09/28 07:33:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 58.50	top5: 100.00	
[09/28 07:33:47 visual_prompt]: 	Test 100/190. loss: 1.841, 0.2164 s / batch. (data: 2.72e-05)max mem: 7.80576 GB 
[09/28 07:34:07 visual_prompt]: Inference (test):avg data time: 5.43e-05, avg batch time: 0.2167, average loss: 2.1030
[09/28 07:34:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.44	top5: 95.90	
[09/28 07:34:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/28 07:34:17 visual_prompt]: Epoch 42 / 100: avg data time: 7.51e-02, avg batch time: 0.5297, average train loss: 0.8386
[09/28 07:34:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1680, average loss: 0.7764
[09/28 07:34:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 65.50	top5: 100.00	
[09/28 07:34:42 visual_prompt]: 	Test 100/190. loss: 1.797, 0.2159 s / batch. (data: 2.98e-05)max mem: 7.80576 GB 
[09/28 07:35:02 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2165, average loss: 2.0596
[09/28 07:35:02 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.81	top5: 96.27	
[09/28 07:35:02 visual_prompt]: Best epoch 42: best metric: 0.655
[09/28 07:35:02 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/28 07:35:12 visual_prompt]: Epoch 43 / 100: avg data time: 7.01e-02, avg batch time: 0.5244, average train loss: 0.7393
[09/28 07:35:14 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1681, average loss: 0.7899
[09/28 07:35:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 67.50	top5: 100.00	
[09/28 07:35:37 visual_prompt]: 	Test 100/190. loss: 1.704, 0.2181 s / batch. (data: 2.60e-05)max mem: 7.80576 GB 
[09/28 07:35:57 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2167, average loss: 2.2476
[09/28 07:35:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.88	top5: 95.99	
[09/28 07:35:57 visual_prompt]: Best epoch 43: best metric: 0.675
[09/28 07:35:57 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/28 07:36:07 visual_prompt]: Epoch 44 / 100: avg data time: 7.93e-02, avg batch time: 0.5345, average train loss: 0.6594
[09/28 07:36:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1680, average loss: 0.8384
[09/28 07:36:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 66.00	top5: 100.00	
[09/28 07:36:32 visual_prompt]: 	Test 100/190. loss: 2.077, 0.2165 s / batch. (data: 2.57e-05)max mem: 7.80576 GB 
[09/28 07:36:52 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2165, average loss: 2.4742
[09/28 07:36:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.62	top5: 95.71	
[09/28 07:36:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/28 07:37:02 visual_prompt]: Epoch 45 / 100: avg data time: 7.85e-02, avg batch time: 0.5322, average train loss: 0.9279
[09/28 07:37:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1684, average loss: 1.0942
[09/28 07:37:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 54.50	top5: 98.50	
[09/28 07:37:27 visual_prompt]: 	Test 100/190. loss: 2.127, 0.2170 s / batch. (data: 2.38e-05)max mem: 7.80576 GB 
[09/28 07:37:47 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2166, average loss: 2.3238
[09/28 07:37:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.70	top5: 92.51	
[09/28 07:37:47 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/28 07:37:57 visual_prompt]: Epoch 46 / 100: avg data time: 8.58e-02, avg batch time: 0.5399, average train loss: 0.8929
[09/28 07:37:59 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1680, average loss: 0.6630
[09/28 07:37:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 71.00	top5: 100.00	
[09/28 07:38:22 visual_prompt]: 	Test 100/190. loss: 1.781, 0.2166 s / batch. (data: 2.48e-05)max mem: 7.80576 GB 
[09/28 07:38:43 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2165, average loss: 1.9310
[09/28 07:38:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.86	top5: 96.43	
[09/28 07:38:43 visual_prompt]: Best epoch 46: best metric: 0.710
[09/28 07:38:43 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/28 07:38:52 visual_prompt]: Epoch 47 / 100: avg data time: 7.60e-02, avg batch time: 0.5301, average train loss: 0.6530
[09/28 07:38:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1680, average loss: 0.8477
[09/28 07:38:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 66.00	top5: 100.00	
[09/28 07:39:17 visual_prompt]: 	Test 100/190. loss: 2.032, 0.2162 s / batch. (data: 2.88e-05)max mem: 7.80576 GB 
[09/28 07:39:38 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2166, average loss: 2.5254
[09/28 07:39:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.72	top5: 96.35	
[09/28 07:39:38 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/28 07:39:47 visual_prompt]: Epoch 48 / 100: avg data time: 7.33e-02, avg batch time: 0.5276, average train loss: 0.5857
[09/28 07:39:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1683, average loss: 0.6781
[09/28 07:39:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 73.00	top5: 100.00	
[09/28 07:40:12 visual_prompt]: 	Test 100/190. loss: 2.122, 0.2164 s / batch. (data: 3.05e-05)max mem: 7.80576 GB 
[09/28 07:40:33 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2165, average loss: 2.4779
[09/28 07:40:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.63	top5: 96.98	
[09/28 07:40:33 visual_prompt]: Best epoch 48: best metric: 0.730
[09/28 07:40:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/28 07:40:42 visual_prompt]: Epoch 49 / 100: avg data time: 7.78e-02, avg batch time: 0.5320, average train loss: 0.5586
[09/28 07:40:45 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1680, average loss: 0.7044
[09/28 07:40:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 72.00	top5: 100.00	
[09/28 07:41:08 visual_prompt]: 	Test 100/190. loss: 2.430, 0.2169 s / batch. (data: 2.86e-05)max mem: 7.80576 GB 
[09/28 07:41:28 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2166, average loss: 2.6410
[09/28 07:41:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.12	top5: 96.53	
[09/28 07:41:28 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/28 07:41:37 visual_prompt]: Epoch 50 / 100: avg data time: 8.30e-02, avg batch time: 0.5367, average train loss: 0.4785
[09/28 07:41:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1682, average loss: 0.5976
[09/28 07:41:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.00	top5: 100.00	
[09/28 07:42:03 visual_prompt]: 	Test 100/190. loss: 2.279, 0.2163 s / batch. (data: 2.72e-05)max mem: 7.80576 GB 
[09/28 07:42:23 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2164, average loss: 2.9335
[09/28 07:42:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.16	top5: 96.92	
[09/28 07:42:23 visual_prompt]: Best epoch 50: best metric: 0.790
[09/28 07:42:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/28 07:42:32 visual_prompt]: Epoch 51 / 100: avg data time: 6.82e-02, avg batch time: 0.5225, average train loss: 0.6066
[09/28 07:42:35 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1680, average loss: 1.2337
[09/28 07:42:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 61.00	top5: 99.00	
[09/28 07:42:58 visual_prompt]: 	Test 100/190. loss: 2.214, 0.2173 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 07:43:18 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2165, average loss: 2.9081
[09/28 07:43:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.17	top5: 95.05	
[09/28 07:43:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/28 07:43:28 visual_prompt]: Epoch 52 / 100: avg data time: 8.30e-02, avg batch time: 0.5362, average train loss: 0.5550
[09/28 07:43:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1680, average loss: 0.4509
[09/28 07:43:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.50	top5: 100.00	
[09/28 07:43:53 visual_prompt]: 	Test 100/190. loss: 2.220, 0.2160 s / batch. (data: 7.92e-05)max mem: 7.80576 GB 
[09/28 07:44:13 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2166, average loss: 2.3564
[09/28 07:44:14 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.81	top5: 96.99	
[09/28 07:44:14 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/28 07:44:23 visual_prompt]: Epoch 53 / 100: avg data time: 8.58e-02, avg batch time: 0.5390, average train loss: 0.4315
[09/28 07:44:25 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1679, average loss: 0.6082
[09/28 07:44:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.00	top5: 100.00	
[09/28 07:44:48 visual_prompt]: 	Test 100/190. loss: 2.953, 0.2173 s / batch. (data: 2.74e-05)max mem: 7.80576 GB 
[09/28 07:45:09 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2164, average loss: 2.8187
[09/28 07:45:09 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.22	top5: 96.73	
[09/28 07:45:09 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/28 07:45:18 visual_prompt]: Epoch 54 / 100: avg data time: 7.76e-02, avg batch time: 0.5327, average train loss: 0.5127
[09/28 07:45:21 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1677, average loss: 0.6801
[09/28 07:45:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.00	top5: 100.00	
[09/28 07:45:44 visual_prompt]: 	Test 100/190. loss: 2.741, 0.2166 s / batch. (data: 2.74e-05)max mem: 7.80576 GB 
[09/28 07:46:04 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2166, average loss: 2.9266
[09/28 07:46:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.20	top5: 96.38	
[09/28 07:46:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/28 07:46:13 visual_prompt]: Epoch 55 / 100: avg data time: 7.25e-02, avg batch time: 0.5271, average train loss: 0.6076
[09/28 07:46:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1679, average loss: 0.5749
[09/28 07:46:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 76.00	top5: 100.00	
[09/28 07:46:39 visual_prompt]: 	Test 100/190. loss: 1.921, 0.2169 s / batch. (data: 2.38e-05)max mem: 7.80576 GB 
[09/28 07:46:59 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2165, average loss: 2.3221
[09/28 07:46:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.74	top5: 96.08	
[09/28 07:46:59 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/28 07:47:08 visual_prompt]: Epoch 56 / 100: avg data time: 6.99e-02, avg batch time: 0.5242, average train loss: 0.4492
[09/28 07:47:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1680, average loss: 0.5142
[09/28 07:47:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.00	top5: 100.00	
[09/28 07:47:34 visual_prompt]: 	Test 100/190. loss: 2.386, 0.2168 s / batch. (data: 2.81e-05)max mem: 7.80576 GB 
[09/28 07:47:54 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.2165, average loss: 2.5855
[09/28 07:47:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.60	top5: 97.15	
[09/28 07:47:54 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/28 07:48:04 visual_prompt]: Epoch 57 / 100: avg data time: 7.86e-02, avg batch time: 0.5334, average train loss: 0.2784
[09/28 07:48:06 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1681, average loss: 0.2015
[09/28 07:48:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 07:48:29 visual_prompt]: 	Test 100/190. loss: 2.825, 0.2178 s / batch. (data: 2.81e-05)max mem: 7.80576 GB 
[09/28 07:48:49 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2164, average loss: 3.0332
[09/28 07:48:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.09	top5: 96.98	
[09/28 07:48:49 visual_prompt]: Best epoch 57: best metric: 0.930
[09/28 07:48:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/28 07:48:58 visual_prompt]: Epoch 58 / 100: avg data time: 7.33e-02, avg batch time: 0.5281, average train loss: 0.2014
[09/28 07:49:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1678, average loss: 0.2188
[09/28 07:49:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.50	top5: 100.00	
[09/28 07:49:24 visual_prompt]: 	Test 100/190. loss: 3.256, 0.2160 s / batch. (data: 2.91e-05)max mem: 7.80576 GB 
[09/28 07:49:44 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2164, average loss: 3.7424
[09/28 07:49:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.78	top5: 96.33	
[09/28 07:49:44 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/28 07:49:53 visual_prompt]: Epoch 59 / 100: avg data time: 6.88e-02, avg batch time: 0.5231, average train loss: 0.2986
[09/28 07:49:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 0.3641
[09/28 07:49:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.50	top5: 100.00	
[09/28 07:50:19 visual_prompt]: 	Test 100/190. loss: 3.200, 0.2175 s / batch. (data: 2.84e-05)max mem: 7.80576 GB 
[09/28 07:50:39 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2165, average loss: 3.5863
[09/28 07:50:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.17	top5: 95.98	
[09/28 07:50:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/28 07:50:49 visual_prompt]: Epoch 60 / 100: avg data time: 7.47e-02, avg batch time: 0.5292, average train loss: 0.4653
[09/28 07:50:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1682, average loss: 0.6481
[09/28 07:50:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.00	top5: 99.00	
[09/28 07:51:14 visual_prompt]: 	Test 100/190. loss: 3.175, 0.2177 s / batch. (data: 2.91e-05)max mem: 7.80576 GB 
[09/28 07:51:35 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2165, average loss: 3.2225
[09/28 07:51:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.51	top5: 94.46	
[09/28 07:51:35 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/28 07:51:44 visual_prompt]: Epoch 61 / 100: avg data time: 7.47e-02, avg batch time: 0.5296, average train loss: 0.3142
[09/28 07:51:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1678, average loss: 0.3378
[09/28 07:51:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.50	top5: 100.00	
[09/28 07:52:09 visual_prompt]: 	Test 100/190. loss: 2.836, 0.2173 s / batch. (data: 2.43e-05)max mem: 7.80576 GB 
[09/28 07:52:30 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2167, average loss: 3.2299
[09/28 07:52:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.25	top5: 96.04	
[09/28 07:52:30 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/28 07:52:39 visual_prompt]: Epoch 62 / 100: avg data time: 8.07e-02, avg batch time: 0.5350, average train loss: 0.2080
[09/28 07:52:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1681, average loss: 0.2521
[09/28 07:52:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.00	top5: 100.00	
[09/28 07:53:04 visual_prompt]: 	Test 100/190. loss: 2.971, 0.2158 s / batch. (data: 8.58e-05)max mem: 7.80576 GB 
[09/28 07:53:25 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2164, average loss: 3.3313
[09/28 07:53:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.86	top5: 96.84	
[09/28 07:53:25 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/28 07:53:34 visual_prompt]: Epoch 63 / 100: avg data time: 8.40e-02, avg batch time: 0.5380, average train loss: 0.2020
[09/28 07:53:37 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1680, average loss: 0.2945
[09/28 07:53:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 89.00	top5: 100.00	
[09/28 07:54:00 visual_prompt]: 	Test 100/190. loss: 2.679, 0.2169 s / batch. (data: 2.79e-05)max mem: 7.80576 GB 
[09/28 07:54:20 visual_prompt]: Inference (test):avg data time: 5.48e-05, avg batch time: 0.2163, average loss: 3.6635
[09/28 07:54:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.35	top5: 96.16	
[09/28 07:54:20 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/28 07:54:29 visual_prompt]: Epoch 64 / 100: avg data time: 7.37e-02, avg batch time: 0.5273, average train loss: 0.2653
[09/28 07:54:32 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1677, average loss: 0.5417
[09/28 07:54:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 85.00	top5: 100.00	
[09/28 07:54:55 visual_prompt]: 	Test 100/190. loss: 3.199, 0.2171 s / batch. (data: 2.74e-05)max mem: 7.80576 GB 
[09/28 07:55:15 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2165, average loss: 3.7018
[09/28 07:55:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.54	top5: 96.53	
[09/28 07:55:15 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/28 07:55:25 visual_prompt]: Epoch 65 / 100: avg data time: 8.16e-02, avg batch time: 0.5352, average train loss: 0.3214
[09/28 07:55:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1680, average loss: 0.3205
[09/28 07:55:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.50	top5: 100.00	
[09/28 07:55:50 visual_prompt]: 	Test 100/190. loss: 2.982, 0.2178 s / batch. (data: 8.56e-05)max mem: 7.80576 GB 
[09/28 07:56:11 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2164, average loss: 3.4349
[09/28 07:56:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.09	top5: 96.12	
[09/28 07:56:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/28 07:56:20 visual_prompt]: Epoch 66 / 100: avg data time: 8.27e-02, avg batch time: 0.5367, average train loss: 0.2266
[09/28 07:56:23 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1680, average loss: 0.3648
[09/28 07:56:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.00	top5: 100.00	
[09/28 07:56:45 visual_prompt]: 	Test 100/190. loss: 3.050, 0.2169 s / batch. (data: 2.79e-05)max mem: 7.80576 GB 
[09/28 07:57:06 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2164, average loss: 3.6117
[09/28 07:57:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.83	top5: 96.58	
[09/28 07:57:06 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/28 07:57:15 visual_prompt]: Epoch 67 / 100: avg data time: 7.23e-02, avg batch time: 0.5291, average train loss: 0.1690
[09/28 07:57:18 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1680, average loss: 0.1967
[09/28 07:57:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.50	top5: 100.00	
[09/28 07:57:40 visual_prompt]: 	Test 100/190. loss: 3.062, 0.2165 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 07:58:01 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2165, average loss: 3.7815
[09/28 07:58:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.69	top5: 96.63	
[09/28 07:58:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/28 07:58:10 visual_prompt]: Epoch 68 / 100: avg data time: 7.55e-02, avg batch time: 0.5299, average train loss: 0.1700
[09/28 07:58:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1681, average loss: 0.3615
[09/28 07:58:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.50	top5: 100.00	
[09/28 07:58:36 visual_prompt]: 	Test 100/190. loss: 3.583, 0.2175 s / batch. (data: 6.87e-05)max mem: 7.80576 GB 
[09/28 07:58:56 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2166, average loss: 4.2361
[09/28 07:58:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.30	top5: 95.86	
[09/28 07:58:56 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/28 07:59:05 visual_prompt]: Epoch 69 / 100: avg data time: 7.33e-02, avg batch time: 0.5287, average train loss: 0.1683
[09/28 07:59:08 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1679, average loss: 0.2788
[09/28 07:59:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.50	top5: 100.00	
[09/28 07:59:31 visual_prompt]: 	Test 100/190. loss: 3.809, 0.2175 s / batch. (data: 2.57e-05)max mem: 7.80576 GB 
[09/28 07:59:51 visual_prompt]: Inference (test):avg data time: 9.56e-05, avg batch time: 0.2166, average loss: 3.9531
[09/28 07:59:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.03	top5: 96.70	
[09/28 07:59:51 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/28 08:00:00 visual_prompt]: Epoch 70 / 100: avg data time: 7.21e-02, avg batch time: 0.5268, average train loss: 0.1284
[09/28 08:00:03 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1680, average loss: 0.2645
[09/28 08:00:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 08:00:26 visual_prompt]: 	Test 100/190. loss: 3.043, 0.2173 s / batch. (data: 2.36e-05)max mem: 7.80576 GB 
[09/28 08:00:46 visual_prompt]: Inference (test):avg data time: 9.39e-05, avg batch time: 0.2166, average loss: 4.1453
[09/28 08:00:46 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.11	top5: 95.58	
[09/28 08:00:46 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/28 08:00:55 visual_prompt]: Epoch 71 / 100: avg data time: 7.33e-02, avg batch time: 0.5274, average train loss: 0.1063
[09/28 08:00:58 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1683, average loss: 0.2837
[09/28 08:00:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 89.50	top5: 100.00	
[09/28 08:01:21 visual_prompt]: 	Test 100/190. loss: 3.124, 0.2174 s / batch. (data: 2.77e-05)max mem: 7.80576 GB 
[09/28 08:01:41 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2166, average loss: 4.4130
[09/28 08:01:41 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.72	top5: 96.72	
[09/28 08:01:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/28 08:01:50 visual_prompt]: Epoch 72 / 100: avg data time: 7.70e-02, avg batch time: 0.5303, average train loss: 0.0776
[09/28 08:01:53 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1682, average loss: 0.1492
[09/28 08:01:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 08:02:16 visual_prompt]: 	Test 100/190. loss: 3.513, 0.2165 s / batch. (data: 3.00e-05)max mem: 7.80576 GB 
[09/28 08:02:36 visual_prompt]: Inference (test):avg data time: 9.31e-05, avg batch time: 0.2167, average loss: 4.4366
[09/28 08:02:36 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.04	top5: 96.48	
[09/28 08:02:36 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/28 08:02:46 visual_prompt]: Epoch 73 / 100: avg data time: 7.45e-02, avg batch time: 0.5286, average train loss: 0.0562
[09/28 08:02:48 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1683, average loss: 0.1349
[09/28 08:02:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.00	top5: 100.00	
[09/28 08:03:11 visual_prompt]: 	Test 100/190. loss: 3.458, 0.2171 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 08:03:31 visual_prompt]: Inference (test):avg data time: 4.72e-05, avg batch time: 0.2165, average loss: 4.6740
[09/28 08:03:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.30	top5: 96.65	
[09/28 08:03:31 visual_prompt]: Best epoch 73: best metric: 0.960
[09/28 08:03:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/28 08:03:41 visual_prompt]: Epoch 74 / 100: avg data time: 7.77e-02, avg batch time: 0.5327, average train loss: 0.0464
[09/28 08:03:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1680, average loss: 0.0666
[09/28 08:03:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 08:04:06 visual_prompt]: 	Test 100/190. loss: 3.741, 0.2172 s / batch. (data: 2.55e-05)max mem: 7.80576 GB 
[09/28 08:04:27 visual_prompt]: Inference (test):avg data time: 4.35e-05, avg batch time: 0.2167, average loss: 4.7411
[09/28 08:04:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.88	top5: 96.85	
[09/28 08:04:27 visual_prompt]: Best epoch 74: best metric: 0.985
[09/28 08:04:27 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/28 08:04:36 visual_prompt]: Epoch 75 / 100: avg data time: 6.61e-02, avg batch time: 0.5194, average train loss: 0.0269
[09/28 08:04:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1679, average loss: 0.1166
[09/28 08:04:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 08:05:01 visual_prompt]: 	Test 100/190. loss: 3.995, 0.2164 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 08:05:22 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2166, average loss: 5.1711
[09/28 08:05:22 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.60	top5: 96.42	
[09/28 08:05:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/28 08:05:31 visual_prompt]: Epoch 76 / 100: avg data time: 7.92e-02, avg batch time: 0.5334, average train loss: 0.0275
[09/28 08:05:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1680, average loss: 0.1172
[09/28 08:05:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 08:05:56 visual_prompt]: 	Test 100/190. loss: 4.329, 0.2170 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 08:06:17 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2167, average loss: 5.1121
[09/28 08:06:17 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.62	top5: 96.92	
[09/28 08:06:17 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/28 08:06:26 visual_prompt]: Epoch 77 / 100: avg data time: 7.55e-02, avg batch time: 0.5302, average train loss: 0.0270
[09/28 08:06:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1680, average loss: 0.1712
[09/28 08:06:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.00	top5: 100.00	
[09/28 08:06:51 visual_prompt]: 	Test 100/190. loss: 4.530, 0.2166 s / batch. (data: 2.81e-05)max mem: 7.80576 GB 
[09/28 08:07:12 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2166, average loss: 5.4202
[09/28 08:07:12 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.02	top5: 96.58	
[09/28 08:07:12 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/28 08:07:21 visual_prompt]: Epoch 78 / 100: avg data time: 8.20e-02, avg batch time: 0.5353, average train loss: 0.0257
[09/28 08:07:24 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1679, average loss: 0.0324
[09/28 08:07:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 08:07:47 visual_prompt]: 	Test 100/190. loss: 4.417, 0.2169 s / batch. (data: 2.79e-05)max mem: 7.80576 GB 
[09/28 08:08:07 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2165, average loss: 5.3020
[09/28 08:08:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.18	top5: 97.14	
[09/28 08:08:07 visual_prompt]: Best epoch 78: best metric: 0.990
[09/28 08:08:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/28 08:08:16 visual_prompt]: Epoch 79 / 100: avg data time: 8.02e-02, avg batch time: 0.5342, average train loss: 0.0255
[09/28 08:08:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1678, average loss: 0.0453
[09/28 08:08:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:08:42 visual_prompt]: 	Test 100/190. loss: 4.419, 0.2178 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 08:09:02 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2164, average loss: 5.3534
[09/28 08:09:02 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.04	top5: 96.80	
[09/28 08:09:02 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/28 08:09:11 visual_prompt]: Epoch 80 / 100: avg data time: 6.88e-02, avg batch time: 0.5245, average train loss: 0.0214
[09/28 08:09:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1682, average loss: 0.1230
[09/28 08:09:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.00	top5: 100.00	
[09/28 08:09:37 visual_prompt]: 	Test 100/190. loss: 4.613, 0.2171 s / batch. (data: 2.81e-05)max mem: 7.80576 GB 
[09/28 08:09:57 visual_prompt]: Inference (test):avg data time: 1.00e-04, avg batch time: 0.2165, average loss: 5.6988
[09/28 08:09:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.66	top5: 96.86	
[09/28 08:09:57 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/28 08:10:06 visual_prompt]: Epoch 81 / 100: avg data time: 7.99e-02, avg batch time: 0.5333, average train loss: 0.0222
[09/28 08:10:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1678, average loss: 0.0343
[09/28 08:10:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 08:10:32 visual_prompt]: 	Test 100/190. loss: 4.490, 0.2174 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 08:10:52 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2165, average loss: 5.5085
[09/28 08:10:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.18	top5: 96.76	
[09/28 08:10:52 visual_prompt]: Best epoch 81: best metric: 0.995
[09/28 08:10:52 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/28 08:11:02 visual_prompt]: Epoch 82 / 100: avg data time: 8.04e-02, avg batch time: 0.5344, average train loss: 0.0184
[09/28 08:11:04 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1682, average loss: 0.1074
[09/28 08:11:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 08:11:27 visual_prompt]: 	Test 100/190. loss: 4.642, 0.2173 s / batch. (data: 2.81e-05)max mem: 7.80576 GB 
[09/28 08:11:47 visual_prompt]: Inference (test):avg data time: 9.93e-05, avg batch time: 0.2167, average loss: 5.7492
[09/28 08:11:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.89	top5: 96.72	
[09/28 08:11:47 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/28 08:11:57 visual_prompt]: Epoch 83 / 100: avg data time: 7.66e-02, avg batch time: 0.5308, average train loss: 0.0121
[09/28 08:11:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1677, average loss: 0.0444
[09/28 08:11:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 08:12:22 visual_prompt]: 	Test 100/190. loss: 4.589, 0.2164 s / batch. (data: 6.51e-05)max mem: 7.80576 GB 
[09/28 08:12:42 visual_prompt]: Inference (test):avg data time: 1.16e-04, avg batch time: 0.2167, average loss: 5.5274
[09/28 08:12:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.59	top5: 96.82	
[09/28 08:12:42 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/28 08:12:52 visual_prompt]: Epoch 84 / 100: avg data time: 7.57e-02, avg batch time: 0.5298, average train loss: 0.0083
[09/28 08:12:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1682, average loss: 0.0490
[09/28 08:12:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 08:13:17 visual_prompt]: 	Test 100/190. loss: 4.698, 0.2158 s / batch. (data: 2.77e-05)max mem: 7.80576 GB 
[09/28 08:13:37 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2164, average loss: 5.6763
[09/28 08:13:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.36	top5: 96.78	
[09/28 08:13:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/28 08:13:47 visual_prompt]: Epoch 85 / 100: avg data time: 7.32e-02, avg batch time: 0.5286, average train loss: 0.0054
[09/28 08:13:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 0.0542
[09/28 08:13:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:14:12 visual_prompt]: 	Test 100/190. loss: 4.770, 0.2163 s / batch. (data: 2.46e-05)max mem: 7.80576 GB 
[09/28 08:14:32 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2167, average loss: 5.6608
[09/28 08:14:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.73	top5: 96.87	
[09/28 08:14:33 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/28 08:14:42 visual_prompt]: Epoch 86 / 100: avg data time: 7.81e-02, avg batch time: 0.5326, average train loss: 0.0081
[09/28 08:14:44 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1679, average loss: 0.0340
[09/28 08:14:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 08:15:07 visual_prompt]: 	Test 100/190. loss: 4.778, 0.2169 s / batch. (data: 2.77e-05)max mem: 7.80576 GB 
[09/28 08:15:28 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2166, average loss: 5.6857
[09/28 08:15:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.72	top5: 96.89	
[09/28 08:15:28 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/28 08:15:37 visual_prompt]: Epoch 87 / 100: avg data time: 7.97e-02, avg batch time: 0.5329, average train loss: 0.0059
[09/28 08:15:40 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1678, average loss: 0.0395
[09/28 08:15:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:16:03 visual_prompt]: 	Test 100/190. loss: 4.779, 0.2164 s / batch. (data: 2.77e-05)max mem: 7.80576 GB 
[09/28 08:16:23 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2164, average loss: 5.6721
[09/28 08:16:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.72	top5: 96.99	
[09/28 08:16:23 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/28 08:16:32 visual_prompt]: Epoch 88 / 100: avg data time: 7.48e-02, avg batch time: 0.5296, average train loss: 0.0041
[09/28 08:16:35 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1677, average loss: 0.0562
[09/28 08:16:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 08:16:58 visual_prompt]: 	Test 100/190. loss: 4.807, 0.2176 s / batch. (data: 3.00e-05)max mem: 7.80576 GB 
[09/28 08:17:18 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2166, average loss: 5.6902
[09/28 08:17:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.69	top5: 97.03	
[09/28 08:17:18 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/28 08:17:27 visual_prompt]: Epoch 89 / 100: avg data time: 7.76e-02, avg batch time: 0.5319, average train loss: 0.0045
[09/28 08:17:30 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1680, average loss: 0.0674
[09/28 08:17:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 08:17:53 visual_prompt]: 	Test 100/190. loss: 4.840, 0.2165 s / batch. (data: 2.77e-05)max mem: 7.80576 GB 
[09/28 08:18:13 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2166, average loss: 5.7203
[09/28 08:18:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.72	top5: 96.98	
[09/28 08:18:13 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/28 08:18:23 visual_prompt]: Epoch 90 / 100: avg data time: 8.42e-02, avg batch time: 0.5377, average train loss: 0.0085
[09/28 08:18:25 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1678, average loss: 0.0712
[09/28 08:18:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 08:18:48 visual_prompt]: 	Test 100/190. loss: 4.815, 0.2170 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 08:19:08 visual_prompt]: Inference (test):avg data time: 5.20e-05, avg batch time: 0.2167, average loss: 5.7385
[09/28 08:19:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.67	top5: 96.95	
[09/28 08:19:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/28 08:19:18 visual_prompt]: Epoch 91 / 100: avg data time: 8.01e-02, avg batch time: 0.5336, average train loss: 0.0114
[09/28 08:19:20 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1681, average loss: 0.0589
[09/28 08:19:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 08:19:43 visual_prompt]: 	Test 100/190. loss: 4.810, 0.2161 s / batch. (data: 2.62e-05)max mem: 7.80576 GB 
[09/28 08:20:04 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2164, average loss: 5.7499
[09/28 08:20:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.56	top5: 96.92	
[09/28 08:20:04 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/28 08:20:13 visual_prompt]: Epoch 92 / 100: avg data time: 6.75e-02, avg batch time: 0.5211, average train loss: 0.0060
[09/28 08:20:15 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1682, average loss: 0.0392
[09/28 08:20:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:20:38 visual_prompt]: 	Test 100/190. loss: 4.805, 0.2180 s / batch. (data: 7.56e-05)max mem: 7.80576 GB 
[09/28 08:20:58 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2167, average loss: 5.7086
[09/28 08:20:58 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.71	top5: 96.94	
[09/28 08:20:58 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/28 08:21:08 visual_prompt]: Epoch 93 / 100: avg data time: 8.25e-02, avg batch time: 0.5360, average train loss: 0.0039
[09/28 08:21:10 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1678, average loss: 0.0380
[09/28 08:21:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 08:21:33 visual_prompt]: 	Test 100/190. loss: 4.789, 0.2175 s / batch. (data: 2.84e-05)max mem: 7.80576 GB 
[09/28 08:21:54 visual_prompt]: Inference (test):avg data time: 3.75e-05, avg batch time: 0.2165, average loss: 5.7183
[09/28 08:21:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.59	top5: 96.95	
[09/28 08:21:54 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/28 08:22:03 visual_prompt]: Epoch 94 / 100: avg data time: 8.26e-02, avg batch time: 0.5365, average train loss: 0.0046
[09/28 08:22:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 0.0408
[09/28 08:22:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:22:28 visual_prompt]: 	Test 100/190. loss: 4.781, 0.2167 s / batch. (data: 2.79e-05)max mem: 7.80576 GB 
[09/28 08:22:49 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2165, average loss: 5.7208
[09/28 08:22:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.67	top5: 96.98	
[09/28 08:22:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/28 08:22:58 visual_prompt]: Epoch 95 / 100: avg data time: 7.67e-02, avg batch time: 0.5303, average train loss: 0.0043
[09/28 08:23:01 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 0.0442
[09/28 08:23:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:23:23 visual_prompt]: 	Test 100/190. loss: 4.788, 0.2171 s / batch. (data: 2.93e-05)max mem: 7.80576 GB 
[09/28 08:23:44 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2165, average loss: 5.7335
[09/28 08:23:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.66	top5: 96.96	
[09/28 08:23:44 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/28 08:23:53 visual_prompt]: Epoch 96 / 100: avg data time: 7.43e-02, avg batch time: 0.5286, average train loss: 0.0050
[09/28 08:23:56 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 0.0453
[09/28 08:23:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:24:18 visual_prompt]: 	Test 100/190. loss: 4.785, 0.2169 s / batch. (data: 2.65e-05)max mem: 7.80576 GB 
[09/28 08:24:39 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2166, average loss: 5.7396
[09/28 08:24:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.63	top5: 96.98	
[09/28 08:24:39 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/28 08:24:48 visual_prompt]: Epoch 97 / 100: avg data time: 7.11e-02, avg batch time: 0.5247, average train loss: 0.0043
[09/28 08:24:50 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1682, average loss: 0.0477
[09/28 08:24:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:25:13 visual_prompt]: 	Test 100/190. loss: 4.784, 0.2159 s / batch. (data: 2.62e-05)max mem: 7.80576 GB 
[09/28 08:25:34 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2165, average loss: 5.7562
[09/28 08:25:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.53	top5: 96.92	
[09/28 08:25:34 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/28 08:25:43 visual_prompt]: Epoch 98 / 100: avg data time: 6.84e-02, avg batch time: 0.5217, average train loss: 0.0039
[09/28 08:25:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 0.0484
[09/28 08:25:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:26:08 visual_prompt]: 	Test 100/190. loss: 4.787, 0.2174 s / batch. (data: 2.67e-05)max mem: 7.80576 GB 
[09/28 08:26:29 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2167, average loss: 5.7620
[09/28 08:26:29 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.57	top5: 96.92	
[09/28 08:26:29 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/28 08:26:38 visual_prompt]: Epoch 99 / 100: avg data time: 7.78e-02, avg batch time: 0.5327, average train loss: 0.0030
[09/28 08:26:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1679, average loss: 0.0487
[09/28 08:26:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:27:03 visual_prompt]: 	Test 100/190. loss: 4.789, 0.2169 s / batch. (data: 2.69e-05)max mem: 7.80576 GB 
[09/28 08:27:24 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2165, average loss: 5.7623
[09/28 08:27:24 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.55	top5: 96.92	
[09/28 08:27:24 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/28 08:27:33 visual_prompt]: Epoch 100 / 100: avg data time: 7.58e-02, avg batch time: 0.5307, average train loss: 0.0055
[09/28 08:27:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1680, average loss: 0.0487
[09/28 08:27:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 08:27:59 visual_prompt]: 	Test 100/190. loss: 4.789, 0.2172 s / batch. (data: 2.84e-05)max mem: 7.80576 GB 
[09/28 08:28:19 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2164, average loss: 5.7625
[09/28 08:28:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.55	top5: 96.92	
[09/28 08:28:19 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 08:28:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 08:28:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 08:28:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 08:28:19 visual_prompt]: Training with config:
[09/28 08:28:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_elevation")/sup_vitb16_imagenet21k/prompt50/crop224/test/seed4755/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 4755, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 9, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 08:28:19 visual_prompt]: Loading training data...
[09/28 08:28:19 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800]+test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 08:28:21 visual_prompt]: Number of images: 1000
[09/28 08:28:21 visual_prompt]: Number of classes: 9 / 9
[09/28 08:28:21 visual_prompt]: Loading validation data...
[09/28 08:28:21 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 08:28:21 visual_prompt]: Number of images: 200
[09/28 08:28:21 visual_prompt]: Number of classes: 9 / 9
[09/28 08:28:21 visual_prompt]: Loading test data...
[09/28 08:28:21 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[50%:], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 08:28:36 visual_prompt]: Number of images: 12150
[09/28 08:28:36 visual_prompt]: Number of classes: 9 / 9
[09/28 08:28:36 visual_prompt]: Constructing models...
[09/28 08:28:39 visual_prompt]: Total Parameters: 86266377	 Gradient Parameters: 467721
[09/28 08:28:39 visual_prompt]: tuned percent:0.542
[09/28 08:28:39 visual_prompt]: Device used for model: 0
[09/28 08:28:39 visual_prompt]: Setting up Evaluator...
[09/28 08:28:39 visual_prompt]: Setting up Trainer...
[09/28 08:28:39 visual_prompt]: 	Setting up the optimizer...
[09/28 08:28:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 08:28:49 visual_prompt]: Epoch 1 / 100: avg data time: 7.76e-02, avg batch time: 0.5278, average train loss: 2.4792
[09/28 08:28:51 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1661, average loss: 2.4694
[09/28 08:28:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.50	top5: 53.00	
[09/28 08:29:14 visual_prompt]: 	Test 100/190. loss: 2.576, 0.2155 s / batch. (data: 2.48e-05)max mem: 7.81213 GB 
[09/28 08:29:34 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2146, average loss: 2.4517
[09/28 08:29:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.27	top5: 56.03	
[09/28 08:29:34 visual_prompt]: Best epoch 1: best metric: 0.175
[09/28 08:29:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/28 08:29:44 visual_prompt]: Epoch 2 / 100: avg data time: 8.82e-02, avg batch time: 0.5392, average train loss: 2.3932
[09/28 08:29:46 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1672, average loss: 2.2549
[09/28 08:29:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 15.00	top5: 59.50	
[09/28 08:30:09 visual_prompt]: 	Test 100/190. loss: 2.318, 0.2155 s / batch. (data: 9.75e-05)max mem: 7.81213 GB 
[09/28 08:30:30 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2155, average loss: 2.2970
[09/28 08:30:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.33	top5: 55.42	
[09/28 08:30:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/28 08:30:39 visual_prompt]: Epoch 3 / 100: avg data time: 8.25e-02, avg batch time: 0.5350, average train loss: 2.2445
[09/28 08:30:42 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1676, average loss: 2.1924
[09/28 08:30:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.50	top5: 60.00	
[09/28 08:31:04 visual_prompt]: 	Test 100/190. loss: 2.242, 0.2160 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 08:31:25 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2160, average loss: 2.2265
[09/28 08:31:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.68	top5: 56.12	
[09/28 08:31:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/28 08:31:34 visual_prompt]: Epoch 4 / 100: avg data time: 7.23e-02, avg batch time: 0.5261, average train loss: 2.2459
[09/28 08:31:36 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1676, average loss: 2.2678
[09/28 08:31:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 63.00	
[09/28 08:31:59 visual_prompt]: 	Test 100/190. loss: 2.338, 0.2158 s / batch. (data: 7.96e-05)max mem: 7.81213 GB 
[09/28 08:32:20 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2160, average loss: 2.2952
[09/28 08:32:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 58.91	
[09/28 08:32:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/28 08:32:29 visual_prompt]: Epoch 5 / 100: avg data time: 8.43e-02, avg batch time: 0.5377, average train loss: 2.2020
[09/28 08:32:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1679, average loss: 2.2156
[09/28 08:32:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 64.00	
[09/28 08:32:55 visual_prompt]: 	Test 100/190. loss: 2.275, 0.2153 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 08:33:15 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2161, average loss: 2.2432
[09/28 08:33:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 61.00	
[09/28 08:33:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/28 08:33:24 visual_prompt]: Epoch 6 / 100: avg data time: 6.91e-02, avg batch time: 0.5232, average train loss: 2.1481
[09/28 08:33:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1677, average loss: 2.1506
[09/28 08:33:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 70.00	
[09/28 08:33:50 visual_prompt]: 	Test 100/190. loss: 2.229, 0.2171 s / batch. (data: 2.91e-05)max mem: 7.81213 GB 
[09/28 08:34:10 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2162, average loss: 2.1419
[09/28 08:34:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.82	top5: 71.49	
[09/28 08:34:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/28 08:34:19 visual_prompt]: Epoch 7 / 100: avg data time: 7.87e-02, avg batch time: 0.5314, average train loss: 2.1550
[09/28 08:34:22 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1679, average loss: 2.2667
[09/28 08:34:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.50	top5: 75.50	
[09/28 08:34:45 visual_prompt]: 	Test 100/190. loss: 2.026, 0.2156 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 08:35:05 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2162, average loss: 2.2502
[09/28 08:35:05 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.00	top5: 74.61	
[09/28 08:35:05 visual_prompt]: Best epoch 7: best metric: 0.205
[09/28 08:35:05 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/28 08:35:14 visual_prompt]: Epoch 8 / 100: avg data time: 7.89e-02, avg batch time: 0.5324, average train loss: 2.1139
[09/28 08:35:17 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1681, average loss: 1.9694
[09/28 08:35:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.50	top5: 80.50	
[09/28 08:35:40 visual_prompt]: 	Test 100/190. loss: 1.959, 0.2174 s / batch. (data: 2.98e-05)max mem: 7.81213 GB 
[09/28 08:36:00 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2162, average loss: 2.0283
[09/28 08:36:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.19	top5: 78.31	
[09/28 08:36:01 visual_prompt]: Best epoch 8: best metric: 0.245
[09/28 08:36:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/28 08:36:10 visual_prompt]: Epoch 9 / 100: avg data time: 7.15e-02, avg batch time: 0.5261, average train loss: 2.0350
[09/28 08:36:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1678, average loss: 1.8069
[09/28 08:36:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.00	top5: 88.50	
[09/28 08:36:35 visual_prompt]: 	Test 100/190. loss: 1.713, 0.2160 s / batch. (data: 7.08e-05)max mem: 7.81213 GB 
[09/28 08:36:56 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2162, average loss: 1.8227
[09/28 08:36:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.06	top5: 89.32	
[09/28 08:36:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/28 08:37:05 visual_prompt]: Epoch 10 / 100: avg data time: 7.98e-02, avg batch time: 0.5333, average train loss: 2.0534
[09/28 08:37:07 visual_prompt]: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1676, average loss: 2.1128
[09/28 08:37:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.00	top5: 84.00	
[09/28 08:37:30 visual_prompt]: 	Test 100/190. loss: 2.262, 0.2176 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 08:37:51 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2163, average loss: 2.1473
[09/28 08:37:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.49	top5: 85.14	
[09/28 08:37:51 visual_prompt]: Best epoch 10: best metric: 0.250
[09/28 08:37:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/28 08:38:00 visual_prompt]: Epoch 11 / 100: avg data time: 7.87e-02, avg batch time: 0.5316, average train loss: 1.9172
[09/28 08:38:03 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1679, average loss: 1.9873
[09/28 08:38:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.50	top5: 79.00	
[09/28 08:38:26 visual_prompt]: 	Test 100/190. loss: 2.205, 0.2169 s / batch. (data: 7.30e-05)max mem: 7.81213 GB 
[09/28 08:38:46 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2162, average loss: 2.0713
[09/28 08:38:46 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.37	top5: 78.74	
[09/28 08:38:46 visual_prompt]: Best epoch 11: best metric: 0.255
[09/28 08:38:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/28 08:38:55 visual_prompt]: Epoch 12 / 100: avg data time: 7.56e-02, avg batch time: 0.5291, average train loss: 1.9240
[09/28 08:38:58 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 1.6022
[09/28 08:38:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.00	top5: 97.50	
[09/28 08:39:21 visual_prompt]: 	Test 100/190. loss: 1.647, 0.2158 s / batch. (data: 7.20e-05)max mem: 7.81213 GB 
[09/28 08:39:41 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2163, average loss: 1.7360
[09/28 08:39:41 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.54	top5: 94.41	
[09/28 08:39:41 visual_prompt]: Best epoch 12: best metric: 0.260
[09/28 08:39:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/28 08:39:51 visual_prompt]: Epoch 13 / 100: avg data time: 8.45e-02, avg batch time: 0.5379, average train loss: 1.7244
[09/28 08:39:53 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1678, average loss: 1.9549
[09/28 08:39:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.00	top5: 85.00	
[09/28 08:40:16 visual_prompt]: 	Test 100/190. loss: 1.682, 0.2155 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 08:40:37 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2164, average loss: 2.0419
[09/28 08:40:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.38	top5: 85.37	
[09/28 08:40:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/28 08:40:46 visual_prompt]: Epoch 14 / 100: avg data time: 8.64e-02, avg batch time: 0.5402, average train loss: 1.7186
[09/28 08:40:49 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1674, average loss: 1.7563
[09/28 08:40:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.00	top5: 92.00	
[09/28 08:41:12 visual_prompt]: 	Test 100/190. loss: 1.971, 0.2157 s / batch. (data: 2.98e-05)max mem: 7.81213 GB 
[09/28 08:41:32 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2162, average loss: 1.9210
[09/28 08:41:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.62	top5: 88.54	
[09/28 08:41:32 visual_prompt]: Best epoch 14: best metric: 0.300
[09/28 08:41:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/28 08:41:41 visual_prompt]: Epoch 15 / 100: avg data time: 7.79e-02, avg batch time: 0.5309, average train loss: 1.6504
[09/28 08:41:44 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1677, average loss: 1.5842
[09/28 08:41:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.50	top5: 95.50	
[09/28 08:42:07 visual_prompt]: 	Test 100/190. loss: 1.741, 0.2156 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 08:42:27 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2163, average loss: 1.8824
[09/28 08:42:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.79	top5: 90.95	
[09/28 08:42:27 visual_prompt]: Best epoch 15: best metric: 0.325
[09/28 08:42:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/28 08:42:37 visual_prompt]: Epoch 16 / 100: avg data time: 7.34e-02, avg batch time: 0.5292, average train loss: 1.5877
[09/28 08:42:39 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1677, average loss: 1.3749
[09/28 08:42:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.50	top5: 98.00	
[09/28 08:43:02 visual_prompt]: 	Test 100/190. loss: 1.633, 0.2172 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 08:43:22 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2165, average loss: 1.6946
[09/28 08:43:22 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.00	top5: 94.72	
[09/28 08:43:22 visual_prompt]: Best epoch 16: best metric: 0.365
[09/28 08:43:22 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/28 08:43:32 visual_prompt]: Epoch 17 / 100: avg data time: 7.56e-02, avg batch time: 0.5298, average train loss: 1.5519
[09/28 08:43:34 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1682, average loss: 1.4107
[09/28 08:43:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.50	top5: 97.00	
[09/28 08:43:57 visual_prompt]: 	Test 100/190. loss: 1.495, 0.2165 s / batch. (data: 1.17e-04)max mem: 7.81213 GB 
[09/28 08:44:18 visual_prompt]: Inference (test):avg data time: 4.66e-05, avg batch time: 0.2163, average loss: 1.6522
[09/28 08:44:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.03	top5: 94.44	
[09/28 08:44:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/28 08:44:27 visual_prompt]: Epoch 18 / 100: avg data time: 7.67e-02, avg batch time: 0.5327, average train loss: 1.4945
[09/28 08:44:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1678, average loss: 1.5577
[09/28 08:44:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.00	top5: 96.50	
[09/28 08:44:52 visual_prompt]: 	Test 100/190. loss: 1.660, 0.2167 s / batch. (data: 7.68e-05)max mem: 7.81213 GB 
[09/28 08:45:13 visual_prompt]: Inference (test):avg data time: 4.43e-05, avg batch time: 0.2163, average loss: 1.9132
[09/28 08:45:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.28	top5: 92.67	
[09/28 08:45:13 visual_prompt]: Best epoch 18: best metric: 0.370
[09/28 08:45:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/28 08:45:22 visual_prompt]: Epoch 19 / 100: avg data time: 7.86e-02, avg batch time: 0.5319, average train loss: 1.4519
[09/28 08:45:25 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1678, average loss: 1.3566
[09/28 08:45:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.50	top5: 100.00	
[09/28 08:45:48 visual_prompt]: 	Test 100/190. loss: 1.581, 0.2169 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 08:46:08 visual_prompt]: Inference (test):avg data time: 3.75e-05, avg batch time: 0.2163, average loss: 1.7150
[09/28 08:46:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.79	top5: 96.63	
[09/28 08:46:08 visual_prompt]: Best epoch 19: best metric: 0.385
[09/28 08:46:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/28 08:46:17 visual_prompt]: Epoch 20 / 100: avg data time: 7.93e-02, avg batch time: 0.5329, average train loss: 1.3577
[09/28 08:46:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 1.1949
[09/28 08:46:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 48.50	top5: 99.50	
[09/28 08:46:43 visual_prompt]: 	Test 100/190. loss: 1.553, 0.2172 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 08:47:03 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2162, average loss: 1.6444
[09/28 08:47:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.39	top5: 96.40	
[09/28 08:47:03 visual_prompt]: Best epoch 20: best metric: 0.485
[09/28 08:47:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/28 08:47:12 visual_prompt]: Epoch 21 / 100: avg data time: 7.23e-02, avg batch time: 0.5267, average train loss: 1.4310
[09/28 08:47:15 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1682, average loss: 1.6574
[09/28 08:47:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.00	top5: 98.50	
[09/28 08:47:38 visual_prompt]: 	Test 100/190. loss: 2.018, 0.2154 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 08:47:58 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2162, average loss: 2.1357
[09/28 08:47:58 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.96	top5: 94.01	
[09/28 08:47:58 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/28 08:48:07 visual_prompt]: Epoch 22 / 100: avg data time: 7.53e-02, avg batch time: 0.5300, average train loss: 1.3452
[09/28 08:48:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1677, average loss: 1.2255
[09/28 08:48:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 48.00	top5: 100.00	
[09/28 08:48:33 visual_prompt]: 	Test 100/190. loss: 1.650, 0.2164 s / batch. (data: 2.91e-05)max mem: 7.81213 GB 
[09/28 08:48:53 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2163, average loss: 1.8496
[09/28 08:48:53 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.23	top5: 95.52	
[09/28 08:48:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/28 08:49:03 visual_prompt]: Epoch 23 / 100: avg data time: 8.19e-02, avg batch time: 0.5348, average train loss: 1.4367
[09/28 08:49:05 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1679, average loss: 1.2848
[09/28 08:49:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.50	top5: 100.00	
[09/28 08:49:28 visual_prompt]: 	Test 100/190. loss: 1.750, 0.2166 s / batch. (data: 2.57e-05)max mem: 7.81213 GB 
[09/28 08:49:49 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2162, average loss: 1.8744
[09/28 08:49:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.38	top5: 93.53	
[09/28 08:49:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/28 08:49:58 visual_prompt]: Epoch 24 / 100: avg data time: 7.63e-02, avg batch time: 0.5303, average train loss: 1.1963
[09/28 08:50:01 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1678, average loss: 1.1115
[09/28 08:50:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 55.00	top5: 100.00	
[09/28 08:50:24 visual_prompt]: 	Test 100/190. loss: 1.667, 0.2170 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 08:50:44 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2163, average loss: 1.7589
[09/28 08:50:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.06	top5: 96.44	
[09/28 08:50:44 visual_prompt]: Best epoch 24: best metric: 0.550
[09/28 08:50:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/28 08:50:53 visual_prompt]: Epoch 25 / 100: avg data time: 7.29e-02, avg batch time: 0.5288, average train loss: 1.1064
[09/28 08:50:56 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1681, average loss: 1.0634
[09/28 08:50:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 52.00	top5: 100.00	
[09/28 08:51:19 visual_prompt]: 	Test 100/190. loss: 1.700, 0.2182 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 08:51:39 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2164, average loss: 1.7488
[09/28 08:51:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.93	top5: 96.79	
[09/28 08:51:39 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/28 08:51:49 visual_prompt]: Epoch 26 / 100: avg data time: 8.30e-02, avg batch time: 0.5367, average train loss: 1.0496
[09/28 08:51:51 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1679, average loss: 1.3451
[09/28 08:51:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 45.00	top5: 100.00	
[09/28 08:52:14 visual_prompt]: 	Test 100/190. loss: 1.740, 0.2167 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 08:52:35 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2165, average loss: 2.1984
[09/28 08:52:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.17	top5: 94.99	
[09/28 08:52:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/28 08:52:44 visual_prompt]: Epoch 27 / 100: avg data time: 8.38e-02, avg batch time: 0.5371, average train loss: 1.2870
[09/28 08:52:47 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1676, average loss: 1.0766
[09/28 08:52:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 56.00	top5: 99.50	
[09/28 08:53:10 visual_prompt]: 	Test 100/190. loss: 1.636, 0.2149 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 08:53:30 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2163, average loss: 1.7457
[09/28 08:53:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.85	top5: 96.40	
[09/28 08:53:30 visual_prompt]: Best epoch 27: best metric: 0.560
[09/28 08:53:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/28 08:53:39 visual_prompt]: Epoch 28 / 100: avg data time: 8.16e-02, avg batch time: 0.5346, average train loss: 1.1229
[09/28 08:53:42 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1679, average loss: 0.8818
[09/28 08:53:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 58.50	top5: 100.00	
[09/28 08:54:05 visual_prompt]: 	Test 100/190. loss: 1.631, 0.2156 s / batch. (data: 3.89e-05)max mem: 7.81213 GB 
[09/28 08:54:25 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2164, average loss: 1.7057
[09/28 08:54:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.68	top5: 97.48	
[09/28 08:54:25 visual_prompt]: Best epoch 28: best metric: 0.585
[09/28 08:54:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/28 08:54:35 visual_prompt]: Epoch 29 / 100: avg data time: 8.18e-02, avg batch time: 0.5355, average train loss: 0.9604
[09/28 08:54:37 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1679, average loss: 1.0640
[09/28 08:54:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 52.50	top5: 100.00	
[09/28 08:55:00 visual_prompt]: 	Test 100/190. loss: 1.907, 0.2175 s / batch. (data: 4.10e-05)max mem: 7.81213 GB 
[09/28 08:55:21 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2165, average loss: 1.9748
[09/28 08:55:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.49	top5: 96.77	
[09/28 08:55:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/28 08:55:30 visual_prompt]: Epoch 30 / 100: avg data time: 7.95e-02, avg batch time: 0.5325, average train loss: 1.0813
[09/28 08:55:32 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1676, average loss: 0.8827
[09/28 08:55:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 62.50	top5: 100.00	
[09/28 08:55:55 visual_prompt]: 	Test 100/190. loss: 1.662, 0.2164 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 08:56:16 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2163, average loss: 1.7036
[09/28 08:56:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.88	top5: 97.25	
[09/28 08:56:16 visual_prompt]: Best epoch 30: best metric: 0.625
[09/28 08:56:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/28 08:56:25 visual_prompt]: Epoch 31 / 100: avg data time: 7.56e-02, avg batch time: 0.5300, average train loss: 0.9392
[09/28 08:56:28 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1676, average loss: 0.9614
[09/28 08:56:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 58.50	top5: 100.00	
[09/28 08:56:50 visual_prompt]: 	Test 100/190. loss: 2.083, 0.2172 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 08:57:11 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2166, average loss: 2.1227
[09/28 08:57:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.74	top5: 96.58	
[09/28 08:57:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/28 08:57:20 visual_prompt]: Epoch 32 / 100: avg data time: 8.40e-02, avg batch time: 0.5369, average train loss: 0.8427
[09/28 08:57:23 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1678, average loss: 0.8154
[09/28 08:57:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 61.00	top5: 100.00	
[09/28 08:57:46 visual_prompt]: 	Test 100/190. loss: 1.616, 0.2162 s / batch. (data: 9.35e-05)max mem: 7.81213 GB 
[09/28 08:58:06 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2163, average loss: 1.9902
[09/28 08:58:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.26	top5: 97.51	
[09/28 08:58:06 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/28 08:58:15 visual_prompt]: Epoch 33 / 100: avg data time: 7.99e-02, avg batch time: 0.5346, average train loss: 0.8254
[09/28 08:58:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1678, average loss: 0.7983
[09/28 08:58:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 65.00	top5: 100.00	
[09/28 08:58:41 visual_prompt]: 	Test 100/190. loss: 1.967, 0.2170 s / batch. (data: 3.12e-05)max mem: 7.81213 GB 
[09/28 08:59:01 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2163, average loss: 1.9867
[09/28 08:59:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.62	top5: 97.28	
[09/28 08:59:01 visual_prompt]: Best epoch 33: best metric: 0.650
[09/28 08:59:01 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/28 08:59:11 visual_prompt]: Epoch 34 / 100: avg data time: 8.02e-02, avg batch time: 0.5343, average train loss: 0.7875
[09/28 08:59:13 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1681, average loss: 0.8456
[09/28 08:59:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 67.00	top5: 100.00	
[09/28 08:59:36 visual_prompt]: 	Test 100/190. loss: 1.899, 0.2156 s / batch. (data: 7.99e-05)max mem: 7.81213 GB 
[09/28 08:59:56 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2162, average loss: 2.2297
[09/28 08:59:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.38	top5: 96.30	
[09/28 08:59:57 visual_prompt]: Best epoch 34: best metric: 0.670
[09/28 08:59:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/28 09:00:06 visual_prompt]: Epoch 35 / 100: avg data time: 8.30e-02, avg batch time: 0.5365, average train loss: 0.7181
[09/28 09:00:08 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1677, average loss: 0.5621
[09/28 09:00:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.50	top5: 100.00	
[09/28 09:00:31 visual_prompt]: 	Test 100/190. loss: 1.847, 0.2167 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 09:00:52 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2163, average loss: 1.9812
[09/28 09:00:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.95	top5: 96.86	
[09/28 09:00:52 visual_prompt]: Best epoch 35: best metric: 0.745
[09/28 09:00:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/28 09:01:01 visual_prompt]: Epoch 36 / 100: avg data time: 7.43e-02, avg batch time: 0.5277, average train loss: 0.6672
[09/28 09:01:03 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 1.0514
[09/28 09:01:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 63.00	top5: 99.00	
[09/28 09:01:26 visual_prompt]: 	Test 100/190. loss: 2.825, 0.2161 s / batch. (data: 3.19e-05)max mem: 7.81213 GB 
[09/28 09:01:47 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2164, average loss: 2.4602
[09/28 09:01:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.76	top5: 96.44	
[09/28 09:01:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/28 09:01:56 visual_prompt]: Epoch 37 / 100: avg data time: 8.62e-02, avg batch time: 0.5407, average train loss: 0.7238
[09/28 09:01:59 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1682, average loss: 0.6781
[09/28 09:01:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.00	top5: 100.00	
[09/28 09:02:22 visual_prompt]: 	Test 100/190. loss: 1.759, 0.2168 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 09:02:42 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2163, average loss: 2.1376
[09/28 09:02:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.56	top5: 96.91	
[09/28 09:02:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/28 09:02:51 visual_prompt]: Epoch 38 / 100: avg data time: 7.86e-02, avg batch time: 0.5336, average train loss: 0.6179
[09/28 09:02:54 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1679, average loss: 0.5535
[09/28 09:02:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.00	top5: 100.00	
[09/28 09:03:17 visual_prompt]: 	Test 100/190. loss: 2.149, 0.2164 s / batch. (data: 6.87e-05)max mem: 7.81213 GB 
[09/28 09:03:37 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2162, average loss: 2.3027
[09/28 09:03:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.82	top5: 97.22	
[09/28 09:03:37 visual_prompt]: Best epoch 38: best metric: 0.780
[09/28 09:03:37 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/28 09:03:47 visual_prompt]: Epoch 39 / 100: avg data time: 7.55e-02, avg batch time: 0.5316, average train loss: 0.6101
[09/28 09:03:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 0.7317
[09/28 09:03:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.00	top5: 100.00	
[09/28 09:04:12 visual_prompt]: 	Test 100/190. loss: 3.045, 0.2170 s / batch. (data: 2.50e-05)max mem: 7.81213 GB 
[09/28 09:04:32 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2163, average loss: 2.7464
[09/28 09:04:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.32	top5: 97.38	
[09/28 09:04:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/28 09:04:41 visual_prompt]: Epoch 40 / 100: avg data time: 7.03e-02, avg batch time: 0.5248, average train loss: 0.6429
[09/28 09:04:44 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1676, average loss: 0.7774
[09/28 09:04:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 71.50	top5: 100.00	
[09/28 09:05:07 visual_prompt]: 	Test 100/190. loss: 2.490, 0.2167 s / batch. (data: 7.89e-05)max mem: 7.81213 GB 
[09/28 09:05:27 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2163, average loss: 2.5964
[09/28 09:05:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.85	top5: 96.11	
[09/28 09:05:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/28 09:05:37 visual_prompt]: Epoch 41 / 100: avg data time: 8.55e-02, avg batch time: 0.5390, average train loss: 0.6032
[09/28 09:05:39 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1677, average loss: 0.4584
[09/28 09:05:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 81.00	top5: 100.00	
[09/28 09:06:03 visual_prompt]: 	Test 100/190. loss: 2.276, 0.2172 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 09:06:23 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2164, average loss: 2.2840
[09/28 09:06:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.86	top5: 97.34	
[09/28 09:06:23 visual_prompt]: Best epoch 41: best metric: 0.810
[09/28 09:06:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/28 09:06:32 visual_prompt]: Epoch 42 / 100: avg data time: 7.65e-02, avg batch time: 0.5297, average train loss: 0.6851
[09/28 09:06:35 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1679, average loss: 0.5326
[09/28 09:06:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.50	top5: 100.00	
[09/28 09:06:58 visual_prompt]: 	Test 100/190. loss: 2.236, 0.2175 s / batch. (data: 2.96e-05)max mem: 7.81213 GB 
[09/28 09:07:18 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2163, average loss: 2.2305
[09/28 09:07:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.56	top5: 96.96	
[09/28 09:07:18 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/28 09:07:27 visual_prompt]: Epoch 43 / 100: avg data time: 7.83e-02, avg batch time: 0.5313, average train loss: 0.5399
[09/28 09:07:30 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1681, average loss: 0.5000
[09/28 09:07:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 80.50	top5: 100.00	
[09/28 09:07:53 visual_prompt]: 	Test 100/190. loss: 2.017, 0.2172 s / batch. (data: 2.48e-05)max mem: 7.81213 GB 
[09/28 09:08:13 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2163, average loss: 2.3551
[09/28 09:08:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.79	top5: 97.19	
[09/28 09:08:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/28 09:08:23 visual_prompt]: Epoch 44 / 100: avg data time: 7.14e-02, avg batch time: 0.5250, average train loss: 0.4396
[09/28 09:08:25 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1682, average loss: 0.6334
[09/28 09:08:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 75.00	top5: 100.00	
[09/28 09:08:48 visual_prompt]: 	Test 100/190. loss: 2.809, 0.2167 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 09:09:08 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2164, average loss: 3.1164
[09/28 09:09:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.98	top5: 96.66	
[09/28 09:09:08 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/28 09:09:17 visual_prompt]: Epoch 45 / 100: avg data time: 7.23e-02, avg batch time: 0.5257, average train loss: 0.5105
[09/28 09:09:20 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1678, average loss: 0.4057
[09/28 09:09:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 84.00	top5: 100.00	
[09/28 09:09:43 visual_prompt]: 	Test 100/190. loss: 2.472, 0.2171 s / batch. (data: 8.63e-05)max mem: 7.81213 GB 
[09/28 09:10:03 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2164, average loss: 2.6001
[09/28 09:10:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.66	top5: 96.79	
[09/28 09:10:04 visual_prompt]: Best epoch 45: best metric: 0.840
[09/28 09:10:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/28 09:10:13 visual_prompt]: Epoch 46 / 100: avg data time: 8.10e-02, avg batch time: 0.5353, average train loss: 0.4854
[09/28 09:10:15 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1679, average loss: 0.3632
[09/28 09:10:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.00	top5: 100.00	
[09/28 09:10:38 visual_prompt]: 	Test 100/190. loss: 2.642, 0.2153 s / batch. (data: 2.46e-05)max mem: 7.81213 GB 
[09/28 09:10:59 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2164, average loss: 2.5707
[09/28 09:10:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.15	top5: 96.27	
[09/28 09:10:59 visual_prompt]: Best epoch 46: best metric: 0.870
[09/28 09:10:59 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/28 09:11:08 visual_prompt]: Epoch 47 / 100: avg data time: 7.95e-02, avg batch time: 0.5334, average train loss: 0.4232
[09/28 09:11:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1678, average loss: 0.4655
[09/28 09:11:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 85.50	top5: 99.50	
[09/28 09:11:34 visual_prompt]: 	Test 100/190. loss: 2.756, 0.2161 s / batch. (data: 2.41e-05)max mem: 7.81213 GB 
[09/28 09:11:54 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2165, average loss: 2.9912
[09/28 09:11:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.91	top5: 95.00	
[09/28 09:11:54 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/28 09:12:03 visual_prompt]: Epoch 48 / 100: avg data time: 7.85e-02, avg batch time: 0.5324, average train loss: 0.4939
[09/28 09:12:06 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 0.5333
[09/28 09:12:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.00	top5: 100.00	
[09/28 09:12:29 visual_prompt]: 	Test 100/190. loss: 2.286, 0.2160 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 09:12:49 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2164, average loss: 2.6411
[09/28 09:12:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.84	top5: 96.86	
[09/28 09:12:49 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/28 09:12:59 visual_prompt]: Epoch 49 / 100: avg data time: 8.47e-02, avg batch time: 0.5392, average train loss: 0.4135
[09/28 09:13:01 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1682, average loss: 0.3667
[09/28 09:13:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 84.00	top5: 100.00	
[09/28 09:13:24 visual_prompt]: 	Test 100/190. loss: 2.678, 0.2159 s / batch. (data: 2.57e-05)max mem: 7.81213 GB 
[09/28 09:13:44 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2163, average loss: 2.8291
[09/28 09:13:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.43	top5: 96.96	
[09/28 09:13:45 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/28 09:13:54 visual_prompt]: Epoch 50 / 100: avg data time: 7.24e-02, avg batch time: 0.5264, average train loss: 0.2818
[09/28 09:13:56 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.1687, average loss: 0.2497
[09/28 09:13:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.50	top5: 100.00	
[09/28 09:14:19 visual_prompt]: 	Test 100/190. loss: 3.120, 0.2173 s / batch. (data: 7.80e-05)max mem: 7.81213 GB 
[09/28 09:14:40 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2164, average loss: 3.0298
[09/28 09:14:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.18	top5: 96.47	
[09/28 09:14:40 visual_prompt]: Best epoch 50: best metric: 0.915
[09/28 09:14:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/28 09:14:49 visual_prompt]: Epoch 51 / 100: avg data time: 7.93e-02, avg batch time: 0.5322, average train loss: 0.2859
[09/28 09:14:52 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1678, average loss: 0.2064
[09/28 09:14:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 09:15:15 visual_prompt]: 	Test 100/190. loss: 3.494, 0.2162 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 09:15:35 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2162, average loss: 3.4461
[09/28 09:15:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.44	top5: 96.34	
[09/28 09:15:35 visual_prompt]: Best epoch 51: best metric: 0.930
[09/28 09:15:35 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/28 09:15:44 visual_prompt]: Epoch 52 / 100: avg data time: 7.48e-02, avg batch time: 0.5295, average train loss: 0.3988
[09/28 09:15:47 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1678, average loss: 0.3479
[09/28 09:15:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 89.50	top5: 100.00	
[09/28 09:16:10 visual_prompt]: 	Test 100/190. loss: 2.889, 0.2172 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 09:16:30 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2163, average loss: 2.6374
[09/28 09:16:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.24	top5: 96.69	
[09/28 09:16:30 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/28 09:16:40 visual_prompt]: Epoch 53 / 100: avg data time: 7.74e-02, avg batch time: 0.5320, average train loss: 0.2734
[09/28 09:16:42 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1677, average loss: 0.2215
[09/28 09:16:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.50	top5: 99.50	
[09/28 09:17:05 visual_prompt]: 	Test 100/190. loss: 3.011, 0.2171 s / batch. (data: 3.31e-05)max mem: 7.81213 GB 
[09/28 09:17:25 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2165, average loss: 3.2263
[09/28 09:17:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.95	top5: 96.58	
[09/28 09:17:25 visual_prompt]: Best epoch 53: best metric: 0.935
[09/28 09:17:25 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/28 09:17:35 visual_prompt]: Epoch 54 / 100: avg data time: 8.35e-02, avg batch time: 0.5371, average train loss: 0.1969
[09/28 09:17:37 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1678, average loss: 0.3905
[09/28 09:17:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 88.00	top5: 100.00	
[09/28 09:18:00 visual_prompt]: 	Test 100/190. loss: 3.434, 0.2156 s / batch. (data: 2.43e-05)max mem: 7.81213 GB 
[09/28 09:18:21 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2162, average loss: 3.9317
[09/28 09:18:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.64	top5: 96.60	
[09/28 09:18:21 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/28 09:18:30 visual_prompt]: Epoch 55 / 100: avg data time: 6.99e-02, avg batch time: 0.5253, average train loss: 0.3256
[09/28 09:18:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1678, average loss: 0.7178
[09/28 09:18:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 75.00	top5: 100.00	
[09/28 09:18:55 visual_prompt]: 	Test 100/190. loss: 2.489, 0.2163 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 09:19:16 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2163, average loss: 3.2846
[09/28 09:19:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.39	top5: 95.97	
[09/28 09:19:16 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/28 09:19:25 visual_prompt]: Epoch 56 / 100: avg data time: 7.67e-02, avg batch time: 0.5314, average train loss: 0.2973
[09/28 09:19:28 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1677, average loss: 0.3364
[09/28 09:19:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.00	top5: 100.00	
[09/28 09:19:50 visual_prompt]: 	Test 100/190. loss: 2.643, 0.2172 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 09:20:11 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2167, average loss: 3.1005
[09/28 09:20:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.51	top5: 96.22	
[09/28 09:20:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/28 09:20:20 visual_prompt]: Epoch 57 / 100: avg data time: 7.49e-02, avg batch time: 0.5289, average train loss: 0.2394
[09/28 09:20:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1678, average loss: 0.1128
[09/28 09:20:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 09:20:46 visual_prompt]: 	Test 100/190. loss: 3.161, 0.2163 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 09:21:06 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2163, average loss: 3.2629
[09/28 09:21:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.68	top5: 96.83	
[09/28 09:21:06 visual_prompt]: Best epoch 57: best metric: 0.965
[09/28 09:21:06 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/28 09:21:15 visual_prompt]: Epoch 58 / 100: avg data time: 8.62e-02, avg batch time: 0.5394, average train loss: 0.1764
[09/28 09:21:18 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1679, average loss: 0.1869
[09/28 09:21:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.00	top5: 99.50	
[09/28 09:21:41 visual_prompt]: 	Test 100/190. loss: 3.127, 0.2178 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 09:22:01 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2164, average loss: 3.5890
[09/28 09:22:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.51	top5: 96.75	
[09/28 09:22:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/28 09:22:10 visual_prompt]: Epoch 59 / 100: avg data time: 7.93e-02, avg batch time: 0.5341, average train loss: 0.1994
[09/28 09:22:13 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1677, average loss: 0.1248
[09/28 09:22:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.00	top5: 100.00	
[09/28 09:22:36 visual_prompt]: 	Test 100/190. loss: 3.217, 0.2171 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 09:22:56 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2163, average loss: 3.6105
[09/28 09:22:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.03	top5: 96.90	
[09/28 09:22:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/28 09:23:06 visual_prompt]: Epoch 60 / 100: avg data time: 7.68e-02, avg batch time: 0.5304, average train loss: 0.2004
[09/28 09:23:08 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1679, average loss: 0.1669
[09/28 09:23:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.00	top5: 100.00	
[09/28 09:23:31 visual_prompt]: 	Test 100/190. loss: 3.517, 0.2159 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 09:23:51 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2164, average loss: 3.4188
[09/28 09:23:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.35	top5: 96.86	
[09/28 09:23:51 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/28 09:24:01 visual_prompt]: Epoch 61 / 100: avg data time: 7.80e-02, avg batch time: 0.5324, average train loss: 0.1374
[09/28 09:24:03 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1679, average loss: 0.1605
[09/28 09:24:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.50	top5: 100.00	
[09/28 09:24:26 visual_prompt]: 	Test 100/190. loss: 4.144, 0.2167 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 09:24:47 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2162, average loss: 3.7560
[09/28 09:24:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.51	top5: 96.54	
[09/28 09:24:47 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/28 09:24:56 visual_prompt]: Epoch 62 / 100: avg data time: 7.34e-02, avg batch time: 0.5279, average train loss: 0.1866
[09/28 09:24:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1677, average loss: 0.0991
[09/28 09:24:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 09:25:21 visual_prompt]: 	Test 100/190. loss: 3.739, 0.2174 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 09:25:42 visual_prompt]: Inference (test):avg data time: 3.69e-05, avg batch time: 0.2163, average loss: 3.6523
[09/28 09:25:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.07	top5: 96.49	
[09/28 09:25:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/28 09:25:51 visual_prompt]: Epoch 63 / 100: avg data time: 6.77e-02, avg batch time: 0.5216, average train loss: 0.0942
[09/28 09:25:53 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1678, average loss: 0.1528
[09/28 09:25:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.00	top5: 100.00	
[09/28 09:26:16 visual_prompt]: 	Test 100/190. loss: 3.775, 0.2158 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 09:26:37 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2164, average loss: 4.0970
[09/28 09:26:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.73	top5: 96.22	
[09/28 09:26:37 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/28 09:26:46 visual_prompt]: Epoch 64 / 100: avg data time: 8.59e-02, avg batch time: 0.5396, average train loss: 0.0976
[09/28 09:26:49 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1680, average loss: 0.1427
[09/28 09:26:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 09:27:12 visual_prompt]: 	Test 100/190. loss: 3.975, 0.2168 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 09:27:32 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2165, average loss: 4.1751
[09/28 09:27:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.16	top5: 96.66	
[09/28 09:27:32 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/28 09:27:41 visual_prompt]: Epoch 65 / 100: avg data time: 8.07e-02, avg batch time: 0.5345, average train loss: 0.0886
[09/28 09:27:44 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1679, average loss: 0.3004
[09/28 09:27:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.00	top5: 100.00	
[09/28 09:28:07 visual_prompt]: 	Test 100/190. loss: 4.360, 0.2178 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 09:28:27 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2164, average loss: 4.3609
[09/28 09:28:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.23	top5: 96.33	
[09/28 09:28:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/28 09:28:37 visual_prompt]: Epoch 66 / 100: avg data time: 8.49e-02, avg batch time: 0.5404, average train loss: 0.0678
[09/28 09:28:39 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1677, average loss: 0.1739
[09/28 09:28:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 09:29:02 visual_prompt]: 	Test 100/190. loss: 4.137, 0.2172 s / batch. (data: 9.42e-05)max mem: 7.81213 GB 
[09/28 09:29:23 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2163, average loss: 4.5157
[09/28 09:29:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.82	top5: 96.45	
[09/28 09:29:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/28 09:29:32 visual_prompt]: Epoch 67 / 100: avg data time: 7.40e-02, avg batch time: 0.5284, average train loss: 0.0611
[09/28 09:29:35 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1681, average loss: 0.1617
[09/28 09:29:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.50	top5: 100.00	
[09/28 09:29:58 visual_prompt]: 	Test 100/190. loss: 4.459, 0.2172 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 09:30:18 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2163, average loss: 4.5844
[09/28 09:30:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.95	top5: 96.60	
[09/28 09:30:18 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/28 09:30:27 visual_prompt]: Epoch 68 / 100: avg data time: 7.77e-02, avg batch time: 0.5329, average train loss: 0.0598
[09/28 09:30:30 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1679, average loss: 0.1398
[09/28 09:30:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.50	top5: 100.00	
[09/28 09:30:53 visual_prompt]: 	Test 100/190. loss: 4.030, 0.2166 s / batch. (data: 8.70e-05)max mem: 7.81213 GB 
[09/28 09:31:13 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2164, average loss: 4.8095
[09/28 09:31:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.40	top5: 96.54	
[09/28 09:31:13 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/28 09:31:22 visual_prompt]: Epoch 69 / 100: avg data time: 8.38e-02, avg batch time: 0.5380, average train loss: 0.0445
[09/28 09:31:25 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1680, average loss: 0.0709
[09/28 09:31:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 09:31:48 visual_prompt]: 	Test 100/190. loss: 4.437, 0.2162 s / batch. (data: 3.24e-05)max mem: 7.81213 GB 
[09/28 09:32:08 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2163, average loss: 4.9693
[09/28 09:32:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.33	top5: 96.79	
[09/28 09:32:08 visual_prompt]: Best epoch 69: best metric: 0.985
[09/28 09:32:08 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/28 09:32:18 visual_prompt]: Epoch 70 / 100: avg data time: 8.58e-02, avg batch time: 0.5387, average train loss: 0.0312
[09/28 09:32:20 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1676, average loss: 0.0379
[09/28 09:32:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 09:32:43 visual_prompt]: 	Test 100/190. loss: 4.931, 0.2164 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 09:33:03 visual_prompt]: Inference (test):avg data time: 5.05e-05, avg batch time: 0.2164, average loss: 5.0218
[09/28 09:33:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.87	top5: 96.57	
[09/28 09:33:03 visual_prompt]: Best epoch 70: best metric: 0.990
[09/28 09:33:03 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/28 09:33:13 visual_prompt]: Epoch 71 / 100: avg data time: 7.84e-02, avg batch time: 0.5323, average train loss: 0.0636
[09/28 09:33:15 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1686, average loss: 0.0148
[09/28 09:33:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 09:33:38 visual_prompt]: 	Test 100/190. loss: 4.780, 0.2160 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 09:33:59 visual_prompt]: Inference (test):avg data time: 9.47e-05, avg batch time: 0.2165, average loss: 5.0812
[09/28 09:33:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.91	top5: 96.72	
[09/28 09:33:59 visual_prompt]: Best epoch 71: best metric: 1.000
[09/28 09:33:59 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/28 09:34:08 visual_prompt]: Epoch 72 / 100: avg data time: 7.79e-02, avg batch time: 0.5324, average train loss: 0.0536
[09/28 09:34:11 visual_prompt]: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1679, average loss: 0.0312
[09/28 09:34:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 09:34:33 visual_prompt]: 	Test 100/190. loss: 4.933, 0.2168 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 09:34:54 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2163, average loss: 4.9658
[09/28 09:34:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.19	top5: 96.74	
[09/28 09:34:54 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/28 09:35:03 visual_prompt]: Epoch 73 / 100: avg data time: 7.18e-02, avg batch time: 0.5262, average train loss: 0.0217
[09/28 09:35:06 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1681, average loss: 0.0311
[09/28 09:35:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 09:35:29 visual_prompt]: 	Test 100/190. loss: 4.977, 0.2171 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 09:35:49 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2164, average loss: 5.1721
[09/28 09:35:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.37	top5: 96.59	
[09/28 09:35:49 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/28 09:35:58 visual_prompt]: Epoch 74 / 100: avg data time: 7.85e-02, avg batch time: 0.5335, average train loss: 0.0174
[09/28 09:36:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1710, average loss: 0.2280
[09/28 09:36:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.50	top5: 100.00	
[09/28 09:36:24 visual_prompt]: 	Test 100/190. loss: 5.076, 0.2161 s / batch. (data: 8.89e-05)max mem: 7.81213 GB 
[09/28 09:36:44 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2163, average loss: 5.4197
[09/28 09:36:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.19	top5: 96.69	
[09/28 09:36:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/28 09:36:53 visual_prompt]: Epoch 75 / 100: avg data time: 6.92e-02, avg batch time: 0.5226, average train loss: 0.0092
[09/28 09:36:56 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1678, average loss: 0.0061
[09/28 09:36:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 09:37:19 visual_prompt]: 	Test 100/190. loss: 4.988, 0.2160 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 09:37:39 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2165, average loss: 5.2998
[09/28 09:37:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.97	top5: 96.68	
[09/28 09:37:39 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/28 09:37:49 visual_prompt]: Epoch 76 / 100: avg data time: 8.06e-02, avg batch time: 0.5344, average train loss: 0.0112
[09/28 09:37:51 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1682, average loss: 0.1239
[09/28 09:37:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 09:38:14 visual_prompt]: 	Test 100/190. loss: 5.192, 0.2172 s / batch. (data: 2.53e-05)max mem: 7.81213 GB 
[09/28 09:38:34 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2166, average loss: 5.4565
[09/28 09:38:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.80	top5: 96.53	
[09/28 09:38:34 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/28 09:38:44 visual_prompt]: Epoch 77 / 100: avg data time: 8.79e-02, avg batch time: 0.5416, average train loss: 0.0174
[09/28 09:38:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1677, average loss: 0.0194
[09/28 09:38:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 09:39:09 visual_prompt]: 	Test 100/190. loss: 5.478, 0.2162 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 09:39:30 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2164, average loss: 5.6318
[09/28 09:39:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.53	top5: 96.40	
[09/28 09:39:30 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/28 09:39:39 visual_prompt]: Epoch 78 / 100: avg data time: 7.81e-02, avg batch time: 0.5334, average train loss: 0.0136
[09/28 09:39:42 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1678, average loss: 0.0547
[09/28 09:39:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 09:40:05 visual_prompt]: 	Test 100/190. loss: 5.664, 0.2166 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 09:40:25 visual_prompt]: Inference (test):avg data time: 5.46e-05, avg batch time: 0.2164, average loss: 5.5990
[09/28 09:40:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.35	top5: 96.72	
[09/28 09:40:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/28 09:40:34 visual_prompt]: Epoch 79 / 100: avg data time: 7.67e-02, avg batch time: 0.5305, average train loss: 0.0081
[09/28 09:40:37 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1678, average loss: 0.0613
[09/28 09:40:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 09:41:00 visual_prompt]: 	Test 100/190. loss: 5.840, 0.2162 s / batch. (data: 7.08e-05)max mem: 7.81213 GB 
[09/28 09:41:20 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2164, average loss: 5.9920
[09/28 09:41:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.93	top5: 96.34	
[09/28 09:41:20 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/28 09:41:29 visual_prompt]: Epoch 80 / 100: avg data time: 8.05e-02, avg batch time: 0.5350, average train loss: 0.0061
[09/28 09:41:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1681, average loss: 0.0217
[09/28 09:41:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 09:41:55 visual_prompt]: 	Test 100/190. loss: 5.658, 0.2169 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 09:42:15 visual_prompt]: Inference (test):avg data time: 3.85e-05, avg batch time: 0.2163, average loss: 5.7183
[09/28 09:42:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.49	top5: 96.72	
[09/28 09:42:15 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/28 09:42:25 visual_prompt]: Epoch 81 / 100: avg data time: 7.65e-02, avg batch time: 0.5314, average train loss: 0.0071
[09/28 09:42:27 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1680, average loss: 0.0090
[09/28 09:42:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 09:42:50 visual_prompt]: 	Test 100/190. loss: 5.736, 0.2163 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 09:43:10 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2164, average loss: 5.7925
[09/28 09:43:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.06	top5: 96.72	
[09/28 09:43:10 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/28 09:43:20 visual_prompt]: Epoch 82 / 100: avg data time: 7.49e-02, avg batch time: 0.5297, average train loss: 0.0046
[09/28 09:43:22 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1682, average loss: 0.0039
[09/28 09:43:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 09:43:45 visual_prompt]: 	Test 100/190. loss: 5.687, 0.2164 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 09:44:06 visual_prompt]: Inference (test):avg data time: 4.83e-05, avg batch time: 0.2165, average loss: 5.8091
[09/28 09:44:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.09	top5: 96.63	
[09/28 09:44:06 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/28 09:44:15 visual_prompt]: Epoch 83 / 100: avg data time: 8.80e-02, avg batch time: 0.5418, average train loss: 0.0038
[09/28 09:44:18 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1680, average loss: 0.0055
[09/28 09:44:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 09:44:40 visual_prompt]: 	Test 100/190. loss: 5.674, 0.2160 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 09:45:01 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2163, average loss: 5.8271
[09/28 09:45:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.28	top5: 96.64	
[09/28 09:45:01 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/28 09:45:10 visual_prompt]: Epoch 84 / 100: avg data time: 7.07e-02, avg batch time: 0.5243, average train loss: 0.0081
[09/28 09:45:13 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1679, average loss: 0.0156
[09/28 09:45:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:45:36 visual_prompt]: 	Test 100/190. loss: 5.744, 0.2169 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 09:45:56 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2164, average loss: 5.8746
[09/28 09:45:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.90	top5: 96.56	
[09/28 09:45:56 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/28 09:46:05 visual_prompt]: Epoch 85 / 100: avg data time: 8.13e-02, avg batch time: 0.5361, average train loss: 0.0029
[09/28 09:46:08 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1678, average loss: 0.0125
[09/28 09:46:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:46:31 visual_prompt]: 	Test 100/190. loss: 5.725, 0.2171 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 09:46:51 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2164, average loss: 5.8450
[09/28 09:46:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.99	top5: 96.63	
[09/28 09:46:51 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/28 09:47:01 visual_prompt]: Epoch 86 / 100: avg data time: 8.21e-02, avg batch time: 0.5362, average train loss: 0.0033
[09/28 09:47:03 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1675, average loss: 0.0080
[09/28 09:47:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:47:26 visual_prompt]: 	Test 100/190. loss: 5.713, 0.2162 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 09:47:47 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2163, average loss: 5.8827
[09/28 09:47:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.96	top5: 96.61	
[09/28 09:47:47 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/28 09:47:56 visual_prompt]: Epoch 87 / 100: avg data time: 8.10e-02, avg batch time: 0.5353, average train loss: 0.0030
[09/28 09:47:59 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1683, average loss: 0.0075
[09/28 09:47:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:48:22 visual_prompt]: 	Test 100/190. loss: 5.724, 0.2160 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 09:48:42 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2164, average loss: 5.8886
[09/28 09:48:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.08	top5: 96.59	
[09/28 09:48:42 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/28 09:48:51 visual_prompt]: Epoch 88 / 100: avg data time: 7.58e-02, avg batch time: 0.5296, average train loss: 0.0016
[09/28 09:48:54 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1678, average loss: 0.0064
[09/28 09:48:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:49:17 visual_prompt]: 	Test 100/190. loss: 5.733, 0.2151 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 09:49:37 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2165, average loss: 5.8969
[09/28 09:49:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.11	top5: 96.60	
[09/28 09:49:37 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/28 09:49:46 visual_prompt]: Epoch 89 / 100: avg data time: 6.95e-02, avg batch time: 0.5232, average train loss: 0.0022
[09/28 09:49:49 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1680, average loss: 0.0091
[09/28 09:49:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:50:12 visual_prompt]: 	Test 100/190. loss: 5.741, 0.2157 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 09:50:32 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2163, average loss: 5.9149
[09/28 09:50:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.06	top5: 96.59	
[09/28 09:50:32 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/28 09:50:42 visual_prompt]: Epoch 90 / 100: avg data time: 8.70e-02, avg batch time: 0.5402, average train loss: 0.0015
[09/28 09:50:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 0.0093
[09/28 09:50:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:51:07 visual_prompt]: 	Test 100/190. loss: 5.741, 0.2169 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 09:51:28 visual_prompt]: Inference (test):avg data time: 5.24e-05, avg batch time: 0.2165, average loss: 5.9191
[09/28 09:51:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.14	top5: 96.58	
[09/28 09:51:28 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/28 09:51:37 visual_prompt]: Epoch 91 / 100: avg data time: 7.85e-02, avg batch time: 0.5329, average train loss: 0.0019
[09/28 09:51:39 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1681, average loss: 0.0100
[09/28 09:51:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:52:02 visual_prompt]: 	Test 100/190. loss: 5.752, 0.2162 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 09:52:23 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2164, average loss: 5.9348
[09/28 09:52:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.00	top5: 96.60	
[09/28 09:52:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/28 09:52:32 visual_prompt]: Epoch 92 / 100: avg data time: 7.06e-02, avg batch time: 0.5252, average train loss: 0.0056
[09/28 09:52:34 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1679, average loss: 0.0084
[09/28 09:52:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:52:57 visual_prompt]: 	Test 100/190. loss: 5.711, 0.2149 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 09:53:18 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2164, average loss: 5.9087
[09/28 09:53:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.24	top5: 96.58	
[09/28 09:53:18 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/28 09:53:27 visual_prompt]: Epoch 93 / 100: avg data time: 7.84e-02, avg batch time: 0.5323, average train loss: 0.0018
[09/28 09:53:30 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1681, average loss: 0.0082
[09/28 09:53:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:53:53 visual_prompt]: 	Test 100/190. loss: 5.712, 0.2163 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 09:54:13 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2165, average loss: 5.9131
[09/28 09:54:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.28	top5: 96.58	
[09/28 09:54:13 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/28 09:54:22 visual_prompt]: Epoch 94 / 100: avg data time: 8.30e-02, avg batch time: 0.5362, average train loss: 0.0018
[09/28 09:54:25 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1682, average loss: 0.0085
[09/28 09:54:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:54:48 visual_prompt]: 	Test 100/190. loss: 5.716, 0.2167 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 09:55:08 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2162, average loss: 5.9200
[09/28 09:55:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.28	top5: 96.58	
[09/28 09:55:08 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/28 09:55:17 visual_prompt]: Epoch 95 / 100: avg data time: 8.15e-02, avg batch time: 0.5358, average train loss: 0.0023
[09/28 09:55:20 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1679, average loss: 0.0091
[09/28 09:55:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:55:43 visual_prompt]: 	Test 100/190. loss: 5.728, 0.2172 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 09:56:03 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2163, average loss: 5.9337
[09/28 09:56:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.28	top5: 96.57	
[09/28 09:56:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/28 09:56:13 visual_prompt]: Epoch 96 / 100: avg data time: 7.28e-02, avg batch time: 0.5264, average train loss: 0.0019
[09/28 09:56:15 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1679, average loss: 0.0093
[09/28 09:56:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:56:38 visual_prompt]: 	Test 100/190. loss: 5.732, 0.2158 s / batch. (data: 2.60e-05)max mem: 7.81213 GB 
[09/28 09:56:58 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2163, average loss: 5.9411
[09/28 09:56:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.28	top5: 96.58	
[09/28 09:56:59 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/28 09:57:08 visual_prompt]: Epoch 97 / 100: avg data time: 6.99e-02, avg batch time: 0.5250, average train loss: 0.0031
[09/28 09:57:10 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1694, average loss: 0.0093
[09/28 09:57:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:57:33 visual_prompt]: 	Test 100/190. loss: 5.733, 0.2172 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 09:57:53 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2163, average loss: 5.9446
[09/28 09:57:53 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.29	top5: 96.59	
[09/28 09:57:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/28 09:58:03 visual_prompt]: Epoch 98 / 100: avg data time: 7.90e-02, avg batch time: 0.5347, average train loss: 0.0056
[09/28 09:58:05 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1679, average loss: 0.0094
[09/28 09:58:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:58:28 visual_prompt]: 	Test 100/190. loss: 5.736, 0.2154 s / batch. (data: 7.01e-05)max mem: 7.81213 GB 
[09/28 09:58:48 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2165, average loss: 5.9478
[09/28 09:58:48 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.32	top5: 96.60	
[09/28 09:58:48 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/28 09:58:58 visual_prompt]: Epoch 99 / 100: avg data time: 8.16e-02, avg batch time: 0.5349, average train loss: 0.0023
[09/28 09:59:00 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1677, average loss: 0.0094
[09/28 09:59:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 09:59:23 visual_prompt]: 	Test 100/190. loss: 5.737, 0.2169 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 09:59:44 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2163, average loss: 5.9482
[09/28 09:59:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.33	top5: 96.60	
[09/28 09:59:44 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/28 09:59:53 visual_prompt]: Epoch 100 / 100: avg data time: 7.34e-02, avg batch time: 0.5280, average train loss: 0.0032
[09/28 09:59:55 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1684, average loss: 0.0094
[09/28 09:59:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 10:00:18 visual_prompt]: 	Test 100/190. loss: 5.737, 0.2161 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 10:00:39 visual_prompt]: Inference (test):avg data time: 3.99e-05, avg batch time: 0.2163, average loss: 5.9486
[09/28 10:00:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.32	top5: 96.59	
[09/28 10:00:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 10:00:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 10:00:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 10:00:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 10:00:39 visual_prompt]: Training with config:
[09/28 10:00:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_elevation")/sup_vitb16_imagenet21k/prompt50/crop224/test/seed4228/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 4228, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 9, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 10:00:39 visual_prompt]: Loading training data...
[09/28 10:00:39 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800]+test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 10:00:40 visual_prompt]: Number of images: 1000
[09/28 10:00:40 visual_prompt]: Number of classes: 9 / 9
[09/28 10:00:40 visual_prompt]: Loading validation data...
[09/28 10:00:40 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 10:00:40 visual_prompt]: Number of images: 200
[09/28 10:00:40 visual_prompt]: Number of classes: 9 / 9
[09/28 10:00:40 visual_prompt]: Loading test data...
[09/28 10:00:40 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[50%:], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 10:00:56 visual_prompt]: Number of images: 12150
[09/28 10:00:56 visual_prompt]: Number of classes: 9 / 9
[09/28 10:00:56 visual_prompt]: Constructing models...
[09/28 10:00:58 visual_prompt]: Total Parameters: 86266377	 Gradient Parameters: 467721
[09/28 10:00:58 visual_prompt]: tuned percent:0.542
[09/28 10:00:58 visual_prompt]: Device used for model: 0
[09/28 10:00:58 visual_prompt]: Setting up Evaluator...
[09/28 10:00:58 visual_prompt]: Setting up Trainer...
[09/28 10:00:58 visual_prompt]: 	Setting up the optimizer...
[09/28 10:00:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 10:01:07 visual_prompt]: Epoch 1 / 100: avg data time: 7.10e-02, avg batch time: 0.5228, average train loss: 2.4731
[09/28 10:01:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 2.4511
[09/28 10:01:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 53.50	
[09/28 10:01:33 visual_prompt]: 	Test 100/190. loss: 2.533, 0.2143 s / batch. (data: 7.65e-05)max mem: 7.81213 GB 
[09/28 10:01:53 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2148, average loss: 2.4547
[09/28 10:01:53 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 8.43	top5: 55.79	
[09/28 10:01:53 visual_prompt]: Best epoch 1: best metric: 0.110
[09/28 10:01:53 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/28 10:02:02 visual_prompt]: Epoch 2 / 100: avg data time: 8.42e-02, avg batch time: 0.5368, average train loss: 2.4437
[09/28 10:02:05 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1675, average loss: 2.2700
[09/28 10:02:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 54.50	
[09/28 10:02:28 visual_prompt]: 	Test 100/190. loss: 2.248, 0.2157 s / batch. (data: 3.17e-05)max mem: 7.81213 GB 
[09/28 10:02:48 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2157, average loss: 2.2493
[09/28 10:02:48 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 56.16	
[09/28 10:02:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/28 10:02:58 visual_prompt]: Epoch 3 / 100: avg data time: 8.25e-02, avg batch time: 0.5360, average train loss: 2.2704
[09/28 10:03:00 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1675, average loss: 2.2603
[09/28 10:03:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 57.50	
[09/28 10:03:23 visual_prompt]: 	Test 100/190. loss: 2.232, 0.2165 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 10:03:44 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2160, average loss: 2.2500
[09/28 10:03:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 61.37	
[09/28 10:03:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/28 10:03:53 visual_prompt]: Epoch 4 / 100: avg data time: 7.21e-02, avg batch time: 0.5259, average train loss: 2.2853
[09/28 10:03:56 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1676, average loss: 2.2211
[09/28 10:03:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 55.50	
[09/28 10:04:18 visual_prompt]: 	Test 100/190. loss: 2.209, 0.2163 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 10:04:39 visual_prompt]: Inference (test):avg data time: 3.69e-05, avg batch time: 0.2161, average loss: 2.2249
[09/28 10:04:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 15.83	top5: 55.54	
[09/28 10:04:39 visual_prompt]: Best epoch 4: best metric: 0.145
[09/28 10:04:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/28 10:04:48 visual_prompt]: Epoch 5 / 100: avg data time: 8.23e-02, avg batch time: 0.5356, average train loss: 2.2454
[09/28 10:04:51 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1677, average loss: 2.2453
[09/28 10:04:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.00	top5: 58.00	
[09/28 10:05:14 visual_prompt]: 	Test 100/190. loss: 2.258, 0.2168 s / batch. (data: 3.17e-05)max mem: 7.81213 GB 
[09/28 10:05:34 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2162, average loss: 2.2412
[09/28 10:05:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.26	top5: 55.86	
[09/28 10:05:34 visual_prompt]: Best epoch 5: best metric: 0.160
[09/28 10:05:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/28 10:05:44 visual_prompt]: Epoch 6 / 100: avg data time: 8.32e-02, avg batch time: 0.5368, average train loss: 2.2724
[09/28 10:05:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 2.1947
[09/28 10:05:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.00	top5: 65.50	
[09/28 10:06:09 visual_prompt]: 	Test 100/190. loss: 2.195, 0.2157 s / batch. (data: 3.22e-05)max mem: 7.81213 GB 
[09/28 10:06:29 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2161, average loss: 2.2057
[09/28 10:06:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 15.71	top5: 58.55	
[09/28 10:06:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/28 10:06:39 visual_prompt]: Epoch 7 / 100: avg data time: 8.46e-02, avg batch time: 0.5380, average train loss: 2.2254
[09/28 10:06:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1678, average loss: 2.1022
[09/28 10:06:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.00	top5: 72.00	
[09/28 10:07:05 visual_prompt]: 	Test 100/190. loss: 2.210, 0.2161 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 10:07:25 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2163, average loss: 2.1411
[09/28 10:07:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.23	top5: 72.96	
[09/28 10:07:25 visual_prompt]: Best epoch 7: best metric: 0.180
[09/28 10:07:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/28 10:07:34 visual_prompt]: Epoch 8 / 100: avg data time: 8.65e-02, avg batch time: 0.5393, average train loss: 2.1712
[09/28 10:07:37 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1681, average loss: 2.3238
[09/28 10:07:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 65.00	
[09/28 10:08:00 visual_prompt]: 	Test 100/190. loss: 2.499, 0.2163 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 10:08:20 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2163, average loss: 2.3744
[09/28 10:08:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.58	top5: 64.30	
[09/28 10:08:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/28 10:08:30 visual_prompt]: Epoch 9 / 100: avg data time: 7.53e-02, avg batch time: 0.5295, average train loss: 2.2809
[09/28 10:08:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1681, average loss: 2.0396
[09/28 10:08:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.50	top5: 75.50	
[09/28 10:08:55 visual_prompt]: 	Test 100/190. loss: 2.101, 0.2168 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 10:09:15 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2162, average loss: 2.0998
[09/28 10:09:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.75	top5: 71.47	
[09/28 10:09:16 visual_prompt]: Best epoch 9: best metric: 0.225
[09/28 10:09:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/28 10:09:25 visual_prompt]: Epoch 10 / 100: avg data time: 7.29e-02, avg batch time: 0.5264, average train loss: 2.2157
[09/28 10:09:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 2.1079
[09/28 10:09:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 84.00	
[09/28 10:09:50 visual_prompt]: 	Test 100/190. loss: 2.151, 0.2157 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 10:10:11 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2162, average loss: 2.1421
[09/28 10:10:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.28	top5: 80.96	
[09/28 10:10:11 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/28 10:10:20 visual_prompt]: Epoch 11 / 100: avg data time: 6.90e-02, avg batch time: 0.5240, average train loss: 2.5647
[09/28 10:10:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1681, average loss: 2.5913
[09/28 10:10:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.00	top5: 56.00	
[09/28 10:10:45 visual_prompt]: 	Test 100/190. loss: 2.429, 0.2152 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 10:11:06 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2163, average loss: 2.4874
[09/28 10:11:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.72	top5: 60.81	
[09/28 10:11:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/28 10:11:15 visual_prompt]: Epoch 12 / 100: avg data time: 7.05e-02, avg batch time: 0.5238, average train loss: 2.3604
[09/28 10:11:18 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1678, average loss: 2.1661
[09/28 10:11:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.00	top5: 76.50	
[09/28 10:11:40 visual_prompt]: 	Test 100/190. loss: 1.960, 0.2164 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 10:12:01 visual_prompt]: Inference (test):avg data time: 1.84e-04, avg batch time: 0.2164, average loss: 2.1547
[09/28 10:12:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.04	top5: 74.74	
[09/28 10:12:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/28 10:12:10 visual_prompt]: Epoch 13 / 100: avg data time: 7.35e-02, avg batch time: 0.5271, average train loss: 2.0656
[09/28 10:12:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1680, average loss: 2.2617
[09/28 10:12:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 84.50	
[09/28 10:12:36 visual_prompt]: 	Test 100/190. loss: 2.087, 0.2176 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 10:12:56 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2163, average loss: 2.2638
[09/28 10:12:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.20	top5: 83.91	
[09/28 10:12:56 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/28 10:13:05 visual_prompt]: Epoch 14 / 100: avg data time: 7.84e-02, avg batch time: 0.5325, average train loss: 1.9280
[09/28 10:13:08 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1678, average loss: 2.0806
[09/28 10:13:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.50	top5: 85.00	
[09/28 10:13:31 visual_prompt]: 	Test 100/190. loss: 2.047, 0.2153 s / batch. (data: 3.08e-05)max mem: 7.81213 GB 
[09/28 10:13:51 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2164, average loss: 2.0928
[09/28 10:13:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.64	top5: 86.34	
[09/28 10:13:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/28 10:14:01 visual_prompt]: Epoch 15 / 100: avg data time: 8.47e-02, avg batch time: 0.5390, average train loss: 1.9062
[09/28 10:14:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1678, average loss: 1.9387
[09/28 10:14:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.50	top5: 80.00	
[09/28 10:14:26 visual_prompt]: 	Test 100/190. loss: 2.004, 0.2158 s / batch. (data: 3.03e-05)max mem: 7.81213 GB 
[09/28 10:14:47 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2164, average loss: 2.0103
[09/28 10:14:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.41	top5: 84.49	
[09/28 10:14:47 visual_prompt]: Best epoch 15: best metric: 0.235
[09/28 10:14:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/28 10:14:56 visual_prompt]: Epoch 16 / 100: avg data time: 8.00e-02, avg batch time: 0.5337, average train loss: 1.7371
[09/28 10:14:59 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1681, average loss: 1.7064
[09/28 10:14:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.50	top5: 92.50	
[09/28 10:15:22 visual_prompt]: 	Test 100/190. loss: 1.935, 0.2159 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 10:15:42 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2164, average loss: 1.8705
[09/28 10:15:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.35	top5: 91.98	
[09/28 10:15:42 visual_prompt]: Best epoch 16: best metric: 0.295
[09/28 10:15:42 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/28 10:15:51 visual_prompt]: Epoch 17 / 100: avg data time: 7.36e-02, avg batch time: 0.5283, average train loss: 1.6342
[09/28 10:15:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1681, average loss: 1.7643
[09/28 10:15:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.50	top5: 93.00	
[09/28 10:16:17 visual_prompt]: 	Test 100/190. loss: 2.161, 0.2173 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 10:16:37 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2166, average loss: 2.0477
[09/28 10:16:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.16	top5: 88.40	
[09/28 10:16:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/28 10:16:47 visual_prompt]: Epoch 18 / 100: avg data time: 8.19e-02, avg batch time: 0.5356, average train loss: 1.8607
[09/28 10:16:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1680, average loss: 1.8833
[09/28 10:16:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.50	top5: 88.00	
[09/28 10:17:12 visual_prompt]: 	Test 100/190. loss: 1.978, 0.2163 s / batch. (data: 7.82e-05)max mem: 7.81213 GB 
[09/28 10:17:32 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2166, average loss: 1.9262
[09/28 10:17:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.70	top5: 88.05	
[09/28 10:17:32 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/28 10:17:42 visual_prompt]: Epoch 19 / 100: avg data time: 8.32e-02, avg batch time: 0.5378, average train loss: 1.8341
[09/28 10:17:44 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1680, average loss: 1.7538
[09/28 10:17:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.50	top5: 88.50	
[09/28 10:18:07 visual_prompt]: 	Test 100/190. loss: 1.662, 0.2174 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 10:18:28 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2165, average loss: 1.8509
[09/28 10:18:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.72	top5: 87.30	
[09/28 10:18:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/28 10:18:37 visual_prompt]: Epoch 20 / 100: avg data time: 9.09e-02, avg batch time: 0.5440, average train loss: 1.6523
[09/28 10:18:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1681, average loss: 1.5515
[09/28 10:18:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.00	top5: 98.50	
[09/28 10:19:03 visual_prompt]: 	Test 100/190. loss: 1.706, 0.2167 s / batch. (data: 3.27e-05)max mem: 7.81213 GB 
[09/28 10:19:23 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2165, average loss: 1.8079
[09/28 10:19:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.34	top5: 93.82	
[09/28 10:19:23 visual_prompt]: Best epoch 20: best metric: 0.300
[09/28 10:19:23 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/28 10:19:33 visual_prompt]: Epoch 21 / 100: avg data time: 8.70e-02, avg batch time: 0.5402, average train loss: 1.6690
[09/28 10:19:35 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1676, average loss: 1.7020
[09/28 10:19:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.50	top5: 97.00	
[09/28 10:19:58 visual_prompt]: 	Test 100/190. loss: 2.080, 0.2179 s / batch. (data: 7.82e-05)max mem: 7.81213 GB 
[09/28 10:20:18 visual_prompt]: Inference (test):avg data time: 4.45e-05, avg batch time: 0.2164, average loss: 2.0045
[09/28 10:20:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.37	top5: 92.18	
[09/28 10:20:19 visual_prompt]: Best epoch 21: best metric: 0.335
[09/28 10:20:19 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/28 10:20:28 visual_prompt]: Epoch 22 / 100: avg data time: 8.84e-02, avg batch time: 0.5417, average train loss: 1.5189
[09/28 10:20:31 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1679, average loss: 1.3340
[09/28 10:20:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.00	top5: 100.00	
[09/28 10:20:53 visual_prompt]: 	Test 100/190. loss: 1.493, 0.2170 s / batch. (data: 2.91e-05)max mem: 7.81213 GB 
[09/28 10:21:14 visual_prompt]: Inference (test):avg data time: 3.79e-05, avg batch time: 0.2165, average loss: 1.6143
[09/28 10:21:14 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.31	top5: 95.93	
[09/28 10:21:14 visual_prompt]: Best epoch 22: best metric: 0.380
[09/28 10:21:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/28 10:21:23 visual_prompt]: Epoch 23 / 100: avg data time: 7.06e-02, avg batch time: 0.5244, average train loss: 1.3948
[09/28 10:21:25 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1676, average loss: 1.3385
[09/28 10:21:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 39.50	top5: 99.50	
[09/28 10:21:48 visual_prompt]: 	Test 100/190. loss: 1.729, 0.2167 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 10:22:09 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2165, average loss: 1.7391
[09/28 10:22:09 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.09	top5: 94.18	
[09/28 10:22:09 visual_prompt]: Best epoch 23: best metric: 0.395
[09/28 10:22:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/28 10:22:18 visual_prompt]: Epoch 24 / 100: avg data time: 8.00e-02, avg batch time: 0.5333, average train loss: 1.3922
[09/28 10:22:21 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1682, average loss: 1.5273
[09/28 10:22:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.50	top5: 99.50	
[09/28 10:22:44 visual_prompt]: 	Test 100/190. loss: 2.075, 0.2170 s / batch. (data: 3.46e-05)max mem: 7.81213 GB 
[09/28 10:23:04 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2165, average loss: 1.9331
[09/28 10:23:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.43	top5: 95.22	
[09/28 10:23:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/28 10:23:14 visual_prompt]: Epoch 25 / 100: avg data time: 8.99e-02, avg batch time: 0.5435, average train loss: 1.4267
[09/28 10:23:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1677, average loss: 1.2410
[09/28 10:23:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 44.50	top5: 100.00	
[09/28 10:23:39 visual_prompt]: 	Test 100/190. loss: 1.664, 0.2165 s / batch. (data: 3.48e-05)max mem: 7.81213 GB 
[09/28 10:23:59 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2164, average loss: 1.7472
[09/28 10:24:00 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.53	top5: 95.67	
[09/28 10:24:00 visual_prompt]: Best epoch 25: best metric: 0.445
[09/28 10:24:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/28 10:24:09 visual_prompt]: Epoch 26 / 100: avg data time: 7.63e-02, avg batch time: 0.5302, average train loss: 1.3224
[09/28 10:24:11 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1681, average loss: 1.1677
[09/28 10:24:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 46.00	top5: 100.00	
[09/28 10:24:34 visual_prompt]: 	Test 100/190. loss: 1.802, 0.2162 s / batch. (data: 9.73e-05)max mem: 7.81213 GB 
[09/28 10:24:55 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2164, average loss: 1.6849
[09/28 10:24:55 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.65	top5: 95.73	
[09/28 10:24:55 visual_prompt]: Best epoch 26: best metric: 0.460
[09/28 10:24:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/28 10:25:04 visual_prompt]: Epoch 27 / 100: avg data time: 7.33e-02, avg batch time: 0.5275, average train loss: 1.2889
[09/28 10:25:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 1.4176
[09/28 10:25:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.50	top5: 100.00	
[09/28 10:25:29 visual_prompt]: 	Test 100/190. loss: 2.049, 0.2168 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 10:25:50 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2164, average loss: 1.9642
[09/28 10:25:50 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.13	top5: 93.57	
[09/28 10:25:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/28 10:25:59 visual_prompt]: Epoch 28 / 100: avg data time: 7.05e-02, avg batch time: 0.5257, average train loss: 1.2479
[09/28 10:26:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1680, average loss: 0.9598
[09/28 10:26:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 57.00	top5: 100.00	
[09/28 10:26:25 visual_prompt]: 	Test 100/190. loss: 1.717, 0.2162 s / batch. (data: 3.05e-05)max mem: 7.81213 GB 
[09/28 10:26:45 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2164, average loss: 1.7175
[09/28 10:26:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.32	top5: 96.43	
[09/28 10:26:45 visual_prompt]: Best epoch 28: best metric: 0.570
[09/28 10:26:45 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/28 10:26:54 visual_prompt]: Epoch 29 / 100: avg data time: 8.54e-02, avg batch time: 0.5396, average train loss: 1.0978
[09/28 10:26:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1681, average loss: 0.9809
[09/28 10:26:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 57.00	top5: 100.00	
[09/28 10:27:20 visual_prompt]: 	Test 100/190. loss: 1.775, 0.2161 s / batch. (data: 2.19e-05)max mem: 7.81213 GB 
[09/28 10:27:40 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2165, average loss: 1.8008
[09/28 10:27:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.50	top5: 95.33	
[09/28 10:27:40 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/28 10:27:50 visual_prompt]: Epoch 30 / 100: avg data time: 7.13e-02, avg batch time: 0.5252, average train loss: 1.1067
[09/28 10:27:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1678, average loss: 0.9662
[09/28 10:27:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 55.00	top5: 100.00	
[09/28 10:28:15 visual_prompt]: 	Test 100/190. loss: 1.782, 0.2166 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 10:28:35 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2165, average loss: 1.8598
[09/28 10:28:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.30	top5: 96.42	
[09/28 10:28:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/28 10:28:45 visual_prompt]: Epoch 31 / 100: avg data time: 7.21e-02, avg batch time: 0.5273, average train loss: 1.0315
[09/28 10:28:47 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1684, average loss: 1.4010
[09/28 10:28:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 42.50	top5: 100.00	
[09/28 10:29:10 visual_prompt]: 	Test 100/190. loss: 2.744, 0.2171 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 10:29:31 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2164, average loss: 2.5190
[09/28 10:29:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.95	top5: 92.60	
[09/28 10:29:31 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/28 10:29:40 visual_prompt]: Epoch 32 / 100: avg data time: 7.20e-02, avg batch time: 0.5263, average train loss: 1.1164
[09/28 10:29:42 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1677, average loss: 1.0227
[09/28 10:29:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 54.00	top5: 100.00	
[09/28 10:30:05 visual_prompt]: 	Test 100/190. loss: 1.779, 0.2162 s / batch. (data: 2.91e-05)max mem: 7.81213 GB 
[09/28 10:30:26 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2164, average loss: 1.9740
[09/28 10:30:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.30	top5: 95.12	
[09/28 10:30:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/28 10:30:35 visual_prompt]: Epoch 33 / 100: avg data time: 7.93e-02, avg batch time: 0.5326, average train loss: 1.0639
[09/28 10:30:38 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 1.0205
[09/28 10:30:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 55.00	top5: 100.00	
[09/28 10:31:01 visual_prompt]: 	Test 100/190. loss: 1.934, 0.2162 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 10:31:21 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2164, average loss: 2.0080
[09/28 10:31:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.96	top5: 95.93	
[09/28 10:31:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/28 10:31:30 visual_prompt]: Epoch 34 / 100: avg data time: 8.04e-02, avg batch time: 0.5345, average train loss: 1.1356
[09/28 10:31:33 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 1.1364
[09/28 10:31:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 50.50	top5: 100.00	
[09/28 10:31:56 visual_prompt]: 	Test 100/190. loss: 1.991, 0.2174 s / batch. (data: 2.43e-05)max mem: 7.81213 GB 
[09/28 10:32:16 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2165, average loss: 2.1448
[09/28 10:32:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.71	top5: 95.77	
[09/28 10:32:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/28 10:32:26 visual_prompt]: Epoch 35 / 100: avg data time: 7.74e-02, avg batch time: 0.5326, average train loss: 0.9720
[09/28 10:32:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1681, average loss: 0.9616
[09/28 10:32:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 60.50	top5: 100.00	
[09/28 10:32:51 visual_prompt]: 	Test 100/190. loss: 2.167, 0.2183 s / batch. (data: 8.73e-05)max mem: 7.81213 GB 
[09/28 10:33:11 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2166, average loss: 2.2935
[09/28 10:33:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.21	top5: 95.60	
[09/28 10:33:11 visual_prompt]: Best epoch 35: best metric: 0.605
[09/28 10:33:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/28 10:33:21 visual_prompt]: Epoch 36 / 100: avg data time: 7.09e-02, avg batch time: 0.5251, average train loss: 0.7842
[09/28 10:33:23 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1684, average loss: 0.6677
[09/28 10:33:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 73.00	top5: 99.50	
[09/28 10:33:46 visual_prompt]: 	Test 100/190. loss: 1.854, 0.2166 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 10:34:06 visual_prompt]: Inference (test):avg data time: 8.40e-05, avg batch time: 0.2166, average loss: 2.0644
[09/28 10:34:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.49	top5: 96.46	
[09/28 10:34:06 visual_prompt]: Best epoch 36: best metric: 0.730
[09/28 10:34:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/28 10:34:16 visual_prompt]: Epoch 37 / 100: avg data time: 6.92e-02, avg batch time: 0.5237, average train loss: 0.8254
[09/28 10:34:18 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1681, average loss: 0.8868
[09/28 10:34:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 58.50	top5: 100.00	
[09/28 10:34:41 visual_prompt]: 	Test 100/190. loss: 2.424, 0.2160 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 10:35:01 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2165, average loss: 2.3438
[09/28 10:35:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.56	top5: 95.14	
[09/28 10:35:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/28 10:35:11 visual_prompt]: Epoch 38 / 100: avg data time: 7.86e-02, avg batch time: 0.5326, average train loss: 0.8159
[09/28 10:35:13 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1682, average loss: 0.7942
[09/28 10:35:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 69.00	top5: 100.00	
[09/28 10:35:36 visual_prompt]: 	Test 100/190. loss: 2.127, 0.2175 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 10:35:57 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2165, average loss: 2.3491
[09/28 10:35:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.26	top5: 95.70	
[09/28 10:35:57 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/28 10:36:06 visual_prompt]: Epoch 39 / 100: avg data time: 7.69e-02, avg batch time: 0.5308, average train loss: 0.8136
[09/28 10:36:09 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1679, average loss: 0.9874
[09/28 10:36:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 59.00	top5: 99.50	
[09/28 10:36:31 visual_prompt]: 	Test 100/190. loss: 2.280, 0.2170 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 10:36:52 visual_prompt]: Inference (test):avg data time: 4.22e-05, avg batch time: 0.2166, average loss: 2.3778
[09/28 10:36:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.21	top5: 93.60	
[09/28 10:36:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/28 10:37:01 visual_prompt]: Epoch 40 / 100: avg data time: 8.61e-02, avg batch time: 0.5395, average train loss: 0.7622
[09/28 10:37:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1681, average loss: 0.6930
[09/28 10:37:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 71.50	top5: 100.00	
[09/28 10:37:27 visual_prompt]: 	Test 100/190. loss: 2.399, 0.2167 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 10:37:47 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2166, average loss: 2.4298
[09/28 10:37:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.93	top5: 96.34	
[09/28 10:37:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/28 10:37:57 visual_prompt]: Epoch 41 / 100: avg data time: 8.17e-02, avg batch time: 0.5358, average train loss: 0.7158
[09/28 10:37:59 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1679, average loss: 0.5109
[09/28 10:37:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.00	top5: 100.00	
[09/28 10:38:22 visual_prompt]: 	Test 100/190. loss: 1.961, 0.2179 s / batch. (data: 6.94e-05)max mem: 7.81213 GB 
[09/28 10:38:43 visual_prompt]: Inference (test):avg data time: 3.81e-05, avg batch time: 0.2165, average loss: 2.2635
[09/28 10:38:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.58	top5: 96.91	
[09/28 10:38:43 visual_prompt]: Best epoch 41: best metric: 0.780
[09/28 10:38:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/28 10:38:52 visual_prompt]: Epoch 42 / 100: avg data time: 7.47e-02, avg batch time: 0.5288, average train loss: 0.6984
[09/28 10:38:55 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1678, average loss: 0.4499
[09/28 10:38:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 81.50	top5: 100.00	
[09/28 10:39:18 visual_prompt]: 	Test 100/190. loss: 1.864, 0.2157 s / batch. (data: 3.12e-05)max mem: 7.81213 GB 
[09/28 10:39:38 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2164, average loss: 2.1476
[09/28 10:39:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.21	top5: 96.86	
[09/28 10:39:38 visual_prompt]: Best epoch 42: best metric: 0.815
[09/28 10:39:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/28 10:39:47 visual_prompt]: Epoch 43 / 100: avg data time: 8.05e-02, avg batch time: 0.5338, average train loss: 0.6812
[09/28 10:39:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1681, average loss: 0.6531
[09/28 10:39:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.00	top5: 100.00	
[09/28 10:40:13 visual_prompt]: 	Test 100/190. loss: 2.073, 0.2163 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 10:40:33 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2167, average loss: 2.4013
[09/28 10:40:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.84	top5: 96.50	
[09/28 10:40:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/28 10:40:43 visual_prompt]: Epoch 44 / 100: avg data time: 7.42e-02, avg batch time: 0.5310, average train loss: 0.6693
[09/28 10:40:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1680, average loss: 0.5340
[09/28 10:40:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 77.00	top5: 100.00	
[09/28 10:41:08 visual_prompt]: 	Test 100/190. loss: 1.880, 0.2158 s / batch. (data: 3.55e-05)max mem: 7.81213 GB 
[09/28 10:41:29 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2165, average loss: 2.1806
[09/28 10:41:29 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.54	top5: 96.41	
[09/28 10:41:29 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/28 10:41:38 visual_prompt]: Epoch 45 / 100: avg data time: 7.51e-02, avg batch time: 0.5305, average train loss: 0.4454
[09/28 10:41:41 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1676, average loss: 0.4787
[09/28 10:41:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 82.50	top5: 100.00	
[09/28 10:42:04 visual_prompt]: 	Test 100/190. loss: 2.709, 0.2172 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 10:42:24 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2164, average loss: 2.9112
[09/28 10:42:24 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.25	top5: 96.71	
[09/28 10:42:24 visual_prompt]: Best epoch 45: best metric: 0.825
[09/28 10:42:24 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/28 10:42:33 visual_prompt]: Epoch 46 / 100: avg data time: 7.06e-02, avg batch time: 0.5243, average train loss: 0.4748
[09/28 10:42:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 0.5582
[09/28 10:42:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.00	top5: 100.00	
[09/28 10:42:59 visual_prompt]: 	Test 100/190. loss: 2.523, 0.2171 s / batch. (data: 2.91e-05)max mem: 7.81213 GB 
[09/28 10:43:19 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2164, average loss: 3.1438
[09/28 10:43:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.56	top5: 96.41	
[09/28 10:43:19 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/28 10:43:29 visual_prompt]: Epoch 47 / 100: avg data time: 7.55e-02, avg batch time: 0.5313, average train loss: 0.6092
[09/28 10:43:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1678, average loss: 0.7411
[09/28 10:43:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 71.00	top5: 100.00	
[09/28 10:43:54 visual_prompt]: 	Test 100/190. loss: 2.195, 0.2176 s / batch. (data: 8.13e-05)max mem: 7.81213 GB 
[09/28 10:44:15 visual_prompt]: Inference (test):avg data time: 7.32e-05, avg batch time: 0.2165, average loss: 2.5558
[09/28 10:44:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.18	top5: 96.43	
[09/28 10:44:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/28 10:44:24 visual_prompt]: Epoch 48 / 100: avg data time: 8.19e-02, avg batch time: 0.5351, average train loss: 0.4474
[09/28 10:44:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1681, average loss: 0.3815
[09/28 10:44:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.00	top5: 100.00	
[09/28 10:44:50 visual_prompt]: 	Test 100/190. loss: 2.984, 0.2166 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 10:45:10 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2165, average loss: 3.1267
[09/28 10:45:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.02	top5: 96.46	
[09/28 10:45:10 visual_prompt]: Best epoch 48: best metric: 0.870
[09/28 10:45:10 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/28 10:45:19 visual_prompt]: Epoch 49 / 100: avg data time: 7.06e-02, avg batch time: 0.5254, average train loss: 0.4537
[09/28 10:45:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1680, average loss: 0.2431
[09/28 10:45:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 90.50	top5: 100.00	
[09/28 10:45:45 visual_prompt]: 	Test 100/190. loss: 2.453, 0.2168 s / batch. (data: 3.05e-05)max mem: 7.81213 GB 
[09/28 10:46:05 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2167, average loss: 2.6833
[09/28 10:46:05 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.21	top5: 96.57	
[09/28 10:46:05 visual_prompt]: Best epoch 49: best metric: 0.905
[09/28 10:46:05 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/28 10:46:15 visual_prompt]: Epoch 50 / 100: avg data time: 7.88e-02, avg batch time: 0.5339, average train loss: 0.4054
[09/28 10:46:17 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1680, average loss: 0.2666
[09/28 10:46:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.00	top5: 100.00	
[09/28 10:46:40 visual_prompt]: 	Test 100/190. loss: 2.558, 0.2163 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 10:47:01 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2164, average loss: 2.8897
[09/28 10:47:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.91	top5: 96.47	
[09/28 10:47:01 visual_prompt]: Best epoch 50: best metric: 0.910
[09/28 10:47:01 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/28 10:47:10 visual_prompt]: Epoch 51 / 100: avg data time: 7.54e-02, avg batch time: 0.5309, average train loss: 0.3613
[09/28 10:47:13 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1680, average loss: 0.2742
[09/28 10:47:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.50	top5: 100.00	
[09/28 10:47:36 visual_prompt]: 	Test 100/190. loss: 2.908, 0.2163 s / batch. (data: 2.60e-05)max mem: 7.81213 GB 
[09/28 10:47:56 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2165, average loss: 3.2252
[09/28 10:47:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.01	top5: 96.61	
[09/28 10:47:56 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/28 10:48:05 visual_prompt]: Epoch 52 / 100: avg data time: 7.46e-02, avg batch time: 0.5293, average train loss: 0.2702
[09/28 10:48:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 0.2715
[09/28 10:48:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 89.50	top5: 100.00	
[09/28 10:48:31 visual_prompt]: 	Test 100/190. loss: 2.849, 0.2171 s / batch. (data: 2.46e-05)max mem: 7.81213 GB 
[09/28 10:48:51 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2165, average loss: 3.4907
[09/28 10:48:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.98	top5: 96.96	
[09/28 10:48:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/28 10:49:01 visual_prompt]: Epoch 53 / 100: avg data time: 8.60e-02, avg batch time: 0.5394, average train loss: 0.3708
[09/28 10:49:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1679, average loss: 0.4206
[09/28 10:49:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 85.50	top5: 100.00	
[09/28 10:49:26 visual_prompt]: 	Test 100/190. loss: 3.052, 0.2166 s / batch. (data: 2.53e-05)max mem: 7.81213 GB 
[09/28 10:49:47 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2166, average loss: 3.2003
[09/28 10:49:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.42	top5: 96.27	
[09/28 10:49:47 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/28 10:49:56 visual_prompt]: Epoch 54 / 100: avg data time: 8.27e-02, avg batch time: 0.5360, average train loss: 0.6640
[09/28 10:49:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1677, average loss: 0.4126
[09/28 10:49:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 83.00	top5: 100.00	
[09/28 10:50:22 visual_prompt]: 	Test 100/190. loss: 2.170, 0.2167 s / batch. (data: 7.80e-05)max mem: 7.81213 GB 
[09/28 10:50:42 visual_prompt]: Inference (test):avg data time: 1.55e-04, avg batch time: 0.2166, average loss: 2.3060
[09/28 10:50:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.87	top5: 95.80	
[09/28 10:50:42 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/28 10:50:51 visual_prompt]: Epoch 55 / 100: avg data time: 8.08e-02, avg batch time: 0.5344, average train loss: 0.3845
[09/28 10:50:54 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1681, average loss: 0.1736
[09/28 10:50:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.50	top5: 100.00	
[09/28 10:51:17 visual_prompt]: 	Test 100/190. loss: 2.837, 0.2170 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 10:51:37 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2166, average loss: 3.0052
[09/28 10:51:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.69	top5: 96.35	
[09/28 10:51:38 visual_prompt]: Best epoch 55: best metric: 0.945
[09/28 10:51:38 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/28 10:51:47 visual_prompt]: Epoch 56 / 100: avg data time: 7.40e-02, avg batch time: 0.5285, average train loss: 0.1998
[09/28 10:51:49 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1682, average loss: 0.1152
[09/28 10:51:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 10:52:12 visual_prompt]: 	Test 100/190. loss: 3.980, 0.2170 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 10:52:33 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2166, average loss: 4.0079
[09/28 10:52:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.51	top5: 96.38	
[09/28 10:52:33 visual_prompt]: Best epoch 56: best metric: 0.970
[09/28 10:52:33 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/28 10:52:42 visual_prompt]: Epoch 57 / 100: avg data time: 7.74e-02, avg batch time: 0.5318, average train loss: 0.1249
[09/28 10:52:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1679, average loss: 0.2238
[09/28 10:52:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.50	top5: 100.00	
[09/28 10:53:08 visual_prompt]: 	Test 100/190. loss: 4.650, 0.2161 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 10:53:28 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2165, average loss: 4.6995
[09/28 10:53:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.57	top5: 96.12	
[09/28 10:53:28 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/28 10:53:37 visual_prompt]: Epoch 58 / 100: avg data time: 8.03e-02, avg batch time: 0.5358, average train loss: 0.1979
[09/28 10:53:40 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1680, average loss: 0.2158
[09/28 10:53:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.00	top5: 100.00	
[09/28 10:54:03 visual_prompt]: 	Test 100/190. loss: 3.672, 0.2166 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 10:54:23 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2165, average loss: 4.1650
[09/28 10:54:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.00	top5: 95.96	
[09/28 10:54:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/28 10:54:33 visual_prompt]: Epoch 59 / 100: avg data time: 8.36e-02, avg batch time: 0.5386, average train loss: 0.1856
[09/28 10:54:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 0.1593
[09/28 10:54:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 91.50	top5: 100.00	
[09/28 10:54:58 visual_prompt]: 	Test 100/190. loss: 3.134, 0.2179 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 10:55:19 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2165, average loss: 4.1035
[09/28 10:55:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.76	top5: 95.56	
[09/28 10:55:19 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/28 10:55:28 visual_prompt]: Epoch 60 / 100: avg data time: 8.07e-02, avg batch time: 0.5341, average train loss: 0.1815
[09/28 10:55:31 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1677, average loss: 0.3742
[09/28 10:55:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 89.50	top5: 100.00	
[09/28 10:55:54 visual_prompt]: 	Test 100/190. loss: 3.684, 0.2167 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 10:56:14 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2165, average loss: 4.2504
[09/28 10:56:14 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.71	top5: 95.67	
[09/28 10:56:14 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/28 10:56:23 visual_prompt]: Epoch 61 / 100: avg data time: 7.70e-02, avg batch time: 0.5316, average train loss: 0.2521
[09/28 10:56:26 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1682, average loss: 0.2267
[09/28 10:56:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.50	top5: 100.00	
[09/28 10:56:49 visual_prompt]: 	Test 100/190. loss: 3.643, 0.2170 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 10:57:09 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2166, average loss: 3.8568
[09/28 10:57:09 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.58	top5: 96.43	
[09/28 10:57:09 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/28 10:57:19 visual_prompt]: Epoch 62 / 100: avg data time: 8.27e-02, avg batch time: 0.5366, average train loss: 0.2160
[09/28 10:57:21 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1678, average loss: 0.1627
[09/28 10:57:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 10:57:44 visual_prompt]: 	Test 100/190. loss: 3.437, 0.2162 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 10:58:04 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2167, average loss: 3.7504
[09/28 10:58:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.36	top5: 96.12	
[09/28 10:58:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/28 10:58:14 visual_prompt]: Epoch 63 / 100: avg data time: 7.68e-02, avg batch time: 0.5319, average train loss: 0.1609
[09/28 10:58:16 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1681, average loss: 0.1094
[09/28 10:58:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.00	top5: 100.00	
[09/28 10:58:39 visual_prompt]: 	Test 100/190. loss: 3.875, 0.2172 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 10:59:00 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2166, average loss: 4.3134
[09/28 10:59:00 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.35	top5: 96.53	
[09/28 10:59:00 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/28 10:59:09 visual_prompt]: Epoch 64 / 100: avg data time: 8.71e-02, avg batch time: 0.5417, average train loss: 0.1108
[09/28 10:59:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1678, average loss: 0.0559
[09/28 10:59:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 10:59:35 visual_prompt]: 	Test 100/190. loss: 4.068, 0.2169 s / batch. (data: 8.73e-05)max mem: 7.81213 GB 
[09/28 10:59:55 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2166, average loss: 4.6482
[09/28 10:59:55 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.47	top5: 96.44	
[09/28 10:59:55 visual_prompt]: Best epoch 64: best metric: 0.975
[09/28 10:59:55 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/28 11:00:04 visual_prompt]: Epoch 65 / 100: avg data time: 8.19e-02, avg batch time: 0.5360, average train loss: 0.1085
[09/28 11:00:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1681, average loss: 0.0801
[09/28 11:00:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 11:00:30 visual_prompt]: 	Test 100/190. loss: 3.930, 0.2165 s / batch. (data: 7.37e-05)max mem: 7.81213 GB 
[09/28 11:00:50 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2166, average loss: 4.7715
[09/28 11:00:50 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.09	top5: 96.23	
[09/28 11:00:50 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/28 11:01:00 visual_prompt]: Epoch 66 / 100: avg data time: 7.23e-02, avg batch time: 0.5267, average train loss: 0.0991
[09/28 11:01:02 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1679, average loss: 0.1309
[09/28 11:01:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 11:01:25 visual_prompt]: 	Test 100/190. loss: 3.992, 0.2154 s / batch. (data: 2.41e-05)max mem: 7.81213 GB 
[09/28 11:01:46 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2165, average loss: 5.0039
[09/28 11:01:46 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.65	top5: 96.40	
[09/28 11:01:46 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/28 11:01:55 visual_prompt]: Epoch 67 / 100: avg data time: 7.62e-02, avg batch time: 0.5311, average train loss: 0.1076
[09/28 11:01:58 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1681, average loss: 0.1773
[09/28 11:01:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 11:02:21 visual_prompt]: 	Test 100/190. loss: 4.587, 0.2171 s / batch. (data: 4.43e-05)max mem: 7.81213 GB 
[09/28 11:02:41 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2165, average loss: 5.0969
[09/28 11:02:41 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.53	top5: 95.85	
[09/28 11:02:41 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/28 11:02:50 visual_prompt]: Epoch 68 / 100: avg data time: 8.46e-02, avg batch time: 0.5395, average train loss: 0.1542
[09/28 11:02:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 0.1781
[09/28 11:02:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 11:03:16 visual_prompt]: 	Test 100/190. loss: 4.589, 0.2162 s / batch. (data: 2.43e-05)max mem: 7.81213 GB 
[09/28 11:03:36 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2166, average loss: 5.0214
[09/28 11:03:36 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.66	top5: 95.40	
[09/28 11:03:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/28 11:03:46 visual_prompt]: Epoch 69 / 100: avg data time: 7.96e-02, avg batch time: 0.5345, average train loss: 0.1315
[09/28 11:03:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1682, average loss: 0.2270
[09/28 11:03:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.50	top5: 100.00	
[09/28 11:04:11 visual_prompt]: 	Test 100/190. loss: 4.253, 0.2177 s / batch. (data: 1.04e-04)max mem: 7.81213 GB 
[09/28 11:04:32 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2167, average loss: 4.8093
[09/28 11:04:32 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.60	top5: 95.88	
[09/28 11:04:32 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/28 11:04:41 visual_prompt]: Epoch 70 / 100: avg data time: 6.66e-02, avg batch time: 0.5212, average train loss: 0.0820
[09/28 11:04:44 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1680, average loss: 0.0186
[09/28 11:04:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:05:07 visual_prompt]: 	Test 100/190. loss: 4.452, 0.2159 s / batch. (data: 3.31e-05)max mem: 7.81213 GB 
[09/28 11:05:27 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2165, average loss: 4.9117
[09/28 11:05:27 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.24	top5: 96.44	
[09/28 11:05:27 visual_prompt]: Best epoch 70: best metric: 0.990
[09/28 11:05:27 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/28 11:05:36 visual_prompt]: Epoch 71 / 100: avg data time: 8.53e-02, avg batch time: 0.5394, average train loss: 0.0509
[09/28 11:05:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1679, average loss: 0.0437
[09/28 11:05:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 11:06:02 visual_prompt]: 	Test 100/190. loss: 4.494, 0.2168 s / batch. (data: 3.29e-05)max mem: 7.81213 GB 
[09/28 11:06:22 visual_prompt]: Inference (test):avg data time: 1.06e-04, avg batch time: 0.2165, average loss: 5.1511
[09/28 11:06:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.16	top5: 96.07	
[09/28 11:06:23 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/28 11:06:32 visual_prompt]: Epoch 72 / 100: avg data time: 7.01e-02, avg batch time: 0.5250, average train loss: 0.0413
[09/28 11:06:34 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1682, average loss: 0.0345
[09/28 11:06:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 11:06:57 visual_prompt]: 	Test 100/190. loss: 4.283, 0.2166 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 11:07:18 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2165, average loss: 5.0772
[09/28 11:07:18 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.35	top5: 96.32	
[09/28 11:07:18 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/28 11:07:27 visual_prompt]: Epoch 73 / 100: avg data time: 8.19e-02, avg batch time: 0.5352, average train loss: 0.0359
[09/28 11:07:30 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1678, average loss: 0.0103
[09/28 11:07:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:07:53 visual_prompt]: 	Test 100/190. loss: 4.815, 0.2179 s / batch. (data: 3.10e-05)max mem: 7.81213 GB 
[09/28 11:08:13 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2165, average loss: 5.2890
[09/28 11:08:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.41	top5: 96.18	
[09/28 11:08:13 visual_prompt]: Best epoch 73: best metric: 1.000
[09/28 11:08:13 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/28 11:08:22 visual_prompt]: Epoch 74 / 100: avg data time: 7.28e-02, avg batch time: 0.5286, average train loss: 0.0244
[09/28 11:08:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1681, average loss: 0.0161
[09/28 11:08:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 11:08:48 visual_prompt]: 	Test 100/190. loss: 4.657, 0.2162 s / batch. (data: 3.22e-05)max mem: 7.81213 GB 
[09/28 11:09:08 visual_prompt]: Inference (test):avg data time: 4.47e-05, avg batch time: 0.2165, average loss: 5.4312
[09/28 11:09:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.40	top5: 96.30	
[09/28 11:09:08 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/28 11:09:18 visual_prompt]: Epoch 75 / 100: avg data time: 7.92e-02, avg batch time: 0.5333, average train loss: 0.0186
[09/28 11:09:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1679, average loss: 0.0371
[09/28 11:09:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 11:09:43 visual_prompt]: 	Test 100/190. loss: 4.732, 0.2178 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 11:10:04 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2166, average loss: 5.5310
[09/28 11:10:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.40	top5: 96.37	
[09/28 11:10:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/28 11:10:13 visual_prompt]: Epoch 76 / 100: avg data time: 8.49e-02, avg batch time: 0.5386, average train loss: 0.0256
[09/28 11:10:16 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 0.0454
[09/28 11:10:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.50	top5: 100.00	
[09/28 11:10:39 visual_prompt]: 	Test 100/190. loss: 4.746, 0.2156 s / batch. (data: 7.68e-05)max mem: 7.81213 GB 
[09/28 11:10:59 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2166, average loss: 5.5505
[09/28 11:10:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.01	top5: 96.25	
[09/28 11:10:59 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/28 11:11:08 visual_prompt]: Epoch 77 / 100: avg data time: 7.69e-02, avg batch time: 0.5308, average train loss: 0.0212
[09/28 11:11:11 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1677, average loss: 0.0243
[09/28 11:11:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:11:34 visual_prompt]: 	Test 100/190. loss: 4.854, 0.2171 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 11:11:54 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2166, average loss: 5.4508
[09/28 11:11:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.09	top5: 96.29	
[09/28 11:11:54 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/28 11:12:03 visual_prompt]: Epoch 78 / 100: avg data time: 7.69e-02, avg batch time: 0.5312, average train loss: 0.0128
[09/28 11:12:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1678, average loss: 0.0350
[09/28 11:12:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:12:29 visual_prompt]: 	Test 100/190. loss: 5.019, 0.2167 s / batch. (data: 9.23e-05)max mem: 7.81213 GB 
[09/28 11:12:49 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2165, average loss: 5.5462
[09/28 11:12:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.92	top5: 96.37	
[09/28 11:12:49 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/28 11:12:59 visual_prompt]: Epoch 79 / 100: avg data time: 8.33e-02, avg batch time: 0.5380, average train loss: 0.0104
[09/28 11:13:01 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1679, average loss: 0.0239
[09/28 11:13:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:13:24 visual_prompt]: 	Test 100/190. loss: 4.994, 0.2171 s / batch. (data: 2.57e-05)max mem: 7.81213 GB 
[09/28 11:13:45 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2165, average loss: 5.5227
[09/28 11:13:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.79	top5: 96.36	
[09/28 11:13:45 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/28 11:13:54 visual_prompt]: Epoch 80 / 100: avg data time: 7.66e-02, avg batch time: 0.5315, average train loss: 0.0099
[09/28 11:13:57 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1682, average loss: 0.0069
[09/28 11:13:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:14:20 visual_prompt]: 	Test 100/190. loss: 4.918, 0.2170 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 11:14:40 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2166, average loss: 5.5315
[09/28 11:14:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.80	top5: 96.31	
[09/28 11:14:40 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/28 11:14:49 visual_prompt]: Epoch 81 / 100: avg data time: 8.50e-02, avg batch time: 0.5388, average train loss: 0.0082
[09/28 11:14:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 0.0108
[09/28 11:14:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:15:15 visual_prompt]: 	Test 100/190. loss: 4.909, 0.2165 s / batch. (data: 2.60e-05)max mem: 7.81213 GB 
[09/28 11:15:35 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2165, average loss: 5.4875
[09/28 11:15:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.95	top5: 96.38	
[09/28 11:15:35 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/28 11:15:45 visual_prompt]: Epoch 82 / 100: avg data time: 7.75e-02, avg batch time: 0.5310, average train loss: 0.0070
[09/28 11:15:47 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1680, average loss: 0.0179
[09/28 11:15:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:16:10 visual_prompt]: 	Test 100/190. loss: 4.948, 0.2174 s / batch. (data: 7.75e-05)max mem: 7.81213 GB 
[09/28 11:16:31 visual_prompt]: Inference (test):avg data time: 4.51e-05, avg batch time: 0.2165, average loss: 5.4660
[09/28 11:16:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.98	top5: 96.41	
[09/28 11:16:31 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/28 11:16:40 visual_prompt]: Epoch 83 / 100: avg data time: 7.40e-02, avg batch time: 0.5294, average train loss: 0.0052
[09/28 11:16:43 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 0.0195
[09/28 11:16:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 11:17:06 visual_prompt]: 	Test 100/190. loss: 5.035, 0.2168 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 11:17:26 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2166, average loss: 5.4962
[09/28 11:17:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.72	top5: 96.34	
[09/28 11:17:26 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/28 11:17:35 visual_prompt]: Epoch 84 / 100: avg data time: 8.77e-02, avg batch time: 0.5418, average train loss: 0.0046
[09/28 11:17:38 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1715, average loss: 0.0147
[09/28 11:17:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 11:18:01 visual_prompt]: 	Test 100/190. loss: 4.965, 0.2163 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 11:18:21 visual_prompt]: Inference (test):avg data time: 4.36e-05, avg batch time: 0.2165, average loss: 5.4918
[09/28 11:18:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.73	top5: 96.38	
[09/28 11:18:21 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/28 11:18:31 visual_prompt]: Epoch 85 / 100: avg data time: 7.26e-02, avg batch time: 0.5287, average train loss: 0.0059
[09/28 11:18:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1680, average loss: 0.0091
[09/28 11:18:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 11:18:56 visual_prompt]: 	Test 100/190. loss: 4.922, 0.2179 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 11:19:17 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2165, average loss: 5.4691
[09/28 11:19:17 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.85	top5: 96.43	
[09/28 11:19:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/28 11:19:26 visual_prompt]: Epoch 86 / 100: avg data time: 7.36e-02, avg batch time: 0.5297, average train loss: 0.0067
[09/28 11:19:29 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1680, average loss: 0.0081
[09/28 11:19:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 11:19:51 visual_prompt]: 	Test 100/190. loss: 4.896, 0.2172 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 11:20:12 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2166, average loss: 5.4527
[09/28 11:20:12 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.10	top5: 96.46	
[09/28 11:20:12 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/28 11:20:21 visual_prompt]: Epoch 87 / 100: avg data time: 8.00e-02, avg batch time: 0.5348, average train loss: 0.0035
[09/28 11:20:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1681, average loss: 0.0071
[09/28 11:20:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 11:20:47 visual_prompt]: 	Test 100/190. loss: 4.893, 0.2168 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 11:21:07 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2165, average loss: 5.4442
[09/28 11:21:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.93	top5: 96.49	
[09/28 11:21:07 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/28 11:21:17 visual_prompt]: Epoch 88 / 100: avg data time: 8.39e-02, avg batch time: 0.5388, average train loss: 0.0065
[09/28 11:21:19 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1679, average loss: 0.0069
[09/28 11:21:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 11:21:42 visual_prompt]: 	Test 100/190. loss: 4.871, 0.2164 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 11:22:03 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2165, average loss: 5.4487
[09/28 11:22:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.81	top5: 96.58	
[09/28 11:22:03 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/28 11:22:12 visual_prompt]: Epoch 89 / 100: avg data time: 8.45e-02, avg batch time: 0.5395, average train loss: 0.0053
[09/28 11:22:15 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1681, average loss: 0.0057
[09/28 11:22:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:22:38 visual_prompt]: 	Test 100/190. loss: 4.853, 0.2163 s / batch. (data: 2.96e-05)max mem: 7.81213 GB 
[09/28 11:22:58 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2165, average loss: 5.4626
[09/28 11:22:58 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.88	top5: 96.58	
[09/28 11:22:58 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/28 11:23:07 visual_prompt]: Epoch 90 / 100: avg data time: 7.56e-02, avg batch time: 0.5292, average train loss: 0.0037
[09/28 11:23:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1684, average loss: 0.0054
[09/28 11:23:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:23:33 visual_prompt]: 	Test 100/190. loss: 4.834, 0.2164 s / batch. (data: 9.18e-05)max mem: 7.81213 GB 
[09/28 11:23:53 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2167, average loss: 5.4609
[09/28 11:23:53 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.99	top5: 96.58	
[09/28 11:23:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/28 11:24:03 visual_prompt]: Epoch 91 / 100: avg data time: 7.07e-02, avg batch time: 0.5264, average train loss: 0.0100
[09/28 11:24:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1680, average loss: 0.0031
[09/28 11:24:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:24:28 visual_prompt]: 	Test 100/190. loss: 4.826, 0.2162 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 11:24:49 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2165, average loss: 5.4575
[09/28 11:24:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.92	top5: 96.53	
[09/28 11:24:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/28 11:24:58 visual_prompt]: Epoch 92 / 100: avg data time: 8.47e-02, avg batch time: 0.5386, average train loss: 0.0071
[09/28 11:25:00 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1680, average loss: 0.0030
[09/28 11:25:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:25:23 visual_prompt]: 	Test 100/190. loss: 4.800, 0.2173 s / batch. (data: 2.91e-05)max mem: 7.81213 GB 
[09/28 11:25:44 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2165, average loss: 5.4752
[09/28 11:25:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.94	top5: 96.53	
[09/28 11:25:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/28 11:25:53 visual_prompt]: Epoch 93 / 100: avg data time: 8.09e-02, avg batch time: 0.5355, average train loss: 0.0057
[09/28 11:25:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1680, average loss: 0.0033
[09/28 11:25:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:26:19 visual_prompt]: 	Test 100/190. loss: 4.823, 0.2170 s / batch. (data: 3.03e-05)max mem: 7.81213 GB 
[09/28 11:26:39 visual_prompt]: Inference (test):avg data time: 1.20e-04, avg batch time: 0.2169, average loss: 5.4738
[09/28 11:26:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.97	top5: 96.44	
[09/28 11:26:39 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/28 11:26:49 visual_prompt]: Epoch 94 / 100: avg data time: 8.15e-02, avg batch time: 0.5366, average train loss: 0.0041
[09/28 11:26:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1681, average loss: 0.0035
[09/28 11:26:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:27:14 visual_prompt]: 	Test 100/190. loss: 4.834, 0.2158 s / batch. (data: 3.22e-05)max mem: 7.81213 GB 
[09/28 11:27:34 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2167, average loss: 5.4657
[09/28 11:27:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.95	top5: 96.50	
[09/28 11:27:34 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/28 11:27:44 visual_prompt]: Epoch 95 / 100: avg data time: 8.12e-02, avg batch time: 0.5350, average train loss: 0.0031
[09/28 11:27:46 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1677, average loss: 0.0037
[09/28 11:27:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:28:09 visual_prompt]: 	Test 100/190. loss: 4.837, 0.2162 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 11:28:30 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2164, average loss: 5.4650
[09/28 11:28:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.90	top5: 96.50	
[09/28 11:28:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/28 11:28:39 visual_prompt]: Epoch 96 / 100: avg data time: 8.21e-02, avg batch time: 0.5362, average train loss: 0.0025
[09/28 11:28:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1679, average loss: 0.0037
[09/28 11:28:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:29:05 visual_prompt]: 	Test 100/190. loss: 4.838, 0.2169 s / batch. (data: 3.22e-05)max mem: 7.81213 GB 
[09/28 11:29:25 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2164, average loss: 5.4651
[09/28 11:29:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.88	top5: 96.50	
[09/28 11:29:25 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/28 11:29:34 visual_prompt]: Epoch 97 / 100: avg data time: 7.81e-02, avg batch time: 0.5334, average train loss: 0.0041
[09/28 11:29:37 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1679, average loss: 0.0038
[09/28 11:29:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:30:00 visual_prompt]: 	Test 100/190. loss: 4.837, 0.2163 s / batch. (data: 2.60e-05)max mem: 7.81213 GB 
[09/28 11:30:20 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2167, average loss: 5.4656
[09/28 11:30:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.85	top5: 96.49	
[09/28 11:30:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/28 11:30:29 visual_prompt]: Epoch 98 / 100: avg data time: 6.89e-02, avg batch time: 0.5244, average train loss: 0.0039
[09/28 11:30:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1680, average loss: 0.0039
[09/28 11:30:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:30:55 visual_prompt]: 	Test 100/190. loss: 4.836, 0.2164 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 11:31:15 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2167, average loss: 5.4660
[09/28 11:31:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.86	top5: 96.49	
[09/28 11:31:15 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/28 11:31:24 visual_prompt]: Epoch 99 / 100: avg data time: 7.19e-02, avg batch time: 0.5270, average train loss: 0.0040
[09/28 11:31:27 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1681, average loss: 0.0039
[09/28 11:31:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:31:50 visual_prompt]: 	Test 100/190. loss: 4.835, 0.2187 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 11:32:10 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2164, average loss: 5.4658
[09/28 11:32:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.85	top5: 96.48	
[09/28 11:32:11 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/28 11:32:20 visual_prompt]: Epoch 100 / 100: avg data time: 7.44e-02, avg batch time: 0.5282, average train loss: 0.0038
[09/28 11:32:22 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1683, average loss: 0.0039
[09/28 11:32:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 11:32:45 visual_prompt]: 	Test 100/190. loss: 4.835, 0.2167 s / batch. (data: 2.96e-05)max mem: 7.81213 GB 
[09/28 11:33:06 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2165, average loss: 5.4658
[09/28 11:33:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.86	top5: 96.48	
[09/28 11:33:06 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 11:33:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 11:33:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 11:33:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 11:33:06 visual_prompt]: Training with config:
[09/28 11:33:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_elevation")/sup_vitb16_imagenet21k/prompt50/crop224/test/seed3449/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 3449, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 9, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 11:33:06 visual_prompt]: Loading training data...
[09/28 11:33:06 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800]+test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 11:33:07 visual_prompt]: Number of images: 1000
[09/28 11:33:07 visual_prompt]: Number of classes: 9 / 9
[09/28 11:33:07 visual_prompt]: Loading validation data...
[09/28 11:33:07 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 11:33:07 visual_prompt]: Number of images: 200
[09/28 11:33:07 visual_prompt]: Number of classes: 9 / 9
[09/28 11:33:07 visual_prompt]: Loading test data...
[09/28 11:33:07 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[50%:], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/28 11:33:22 visual_prompt]: Number of images: 12150
[09/28 11:33:22 visual_prompt]: Number of classes: 9 / 9
[09/28 11:33:22 visual_prompt]: Constructing models...
[09/28 11:33:24 visual_prompt]: Total Parameters: 86266377	 Gradient Parameters: 467721
[09/28 11:33:24 visual_prompt]: tuned percent:0.542
[09/28 11:33:25 visual_prompt]: Device used for model: 0
[09/28 11:33:25 visual_prompt]: Setting up Evaluator...
[09/28 11:33:25 visual_prompt]: Setting up Trainer...
[09/28 11:33:25 visual_prompt]: 	Setting up the optimizer...
[09/28 11:33:25 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 11:33:34 visual_prompt]: Epoch 1 / 100: avg data time: 9.20e-02, avg batch time: 0.5405, average train loss: 2.6563
[09/28 11:33:36 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1660, average loss: 2.6462
[09/28 11:33:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.50	top5: 57.50	
[09/28 11:33:59 visual_prompt]: 	Test 100/190. loss: 2.678, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 11:34:19 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2147, average loss: 2.6947
[09/28 11:34:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.13	top5: 56.67	
[09/28 11:34:19 visual_prompt]: Best epoch 1: best metric: 0.125
[09/28 11:34:19 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/28 11:34:29 visual_prompt]: Epoch 2 / 100: avg data time: 8.67e-02, avg batch time: 0.5386, average train loss: 2.5474
[09/28 11:34:31 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1672, average loss: 2.2031
[09/28 11:34:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.50	top5: 58.50	
[09/28 11:34:54 visual_prompt]: 	Test 100/190. loss: 2.215, 0.2156 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 11:35:15 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2156, average loss: 2.2184
[09/28 11:35:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.23	top5: 55.16	
[09/28 11:35:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/28 11:35:24 visual_prompt]: Epoch 3 / 100: avg data time: 6.90e-02, avg batch time: 0.5238, average train loss: 2.2542
[09/28 11:35:27 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 2.1853
[09/28 11:35:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 65.00	
[09/28 11:35:50 visual_prompt]: 	Test 100/190. loss: 2.225, 0.2212 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 11:36:10 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2159, average loss: 2.2414
[09/28 11:36:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.08	top5: 58.02	
[09/28 11:36:10 visual_prompt]: Best epoch 3: best metric: 0.145
[09/28 11:36:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/28 11:36:19 visual_prompt]: Epoch 4 / 100: avg data time: 8.21e-02, avg batch time: 0.5348, average train loss: 2.2255
[09/28 11:36:22 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1677, average loss: 2.1805
[09/28 11:36:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.50	top5: 64.50	
[09/28 11:36:45 visual_prompt]: 	Test 100/190. loss: 2.188, 0.2176 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 11:37:05 visual_prompt]: Inference (test):avg data time: 1.11e-04, avg batch time: 0.2160, average loss: 2.1927
[09/28 11:37:05 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.99	top5: 60.37	
[09/28 11:37:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/28 11:37:15 visual_prompt]: Epoch 5 / 100: avg data time: 8.71e-02, avg batch time: 0.5411, average train loss: 2.1699
[09/28 11:37:17 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1680, average loss: 2.1615
[09/28 11:37:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 68.00	
[09/28 11:37:40 visual_prompt]: 	Test 100/190. loss: 2.102, 0.2160 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 11:38:01 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2161, average loss: 2.1666
[09/28 11:38:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.31	top5: 62.88	
[09/28 11:38:01 visual_prompt]: Best epoch 5: best metric: 0.170
[09/28 11:38:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/28 11:38:10 visual_prompt]: Epoch 6 / 100: avg data time: 8.87e-02, avg batch time: 0.5416, average train loss: 2.1506
[09/28 11:38:13 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1677, average loss: 2.0686
[09/28 11:38:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.50	top5: 74.50	
[09/28 11:38:36 visual_prompt]: 	Test 100/190. loss: 2.177, 0.2166 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 11:38:56 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2161, average loss: 2.1201
[09/28 11:38:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.81	top5: 74.43	
[09/28 11:38:56 visual_prompt]: Best epoch 6: best metric: 0.215
[09/28 11:38:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/28 11:39:05 visual_prompt]: Epoch 7 / 100: avg data time: 8.22e-02, avg batch time: 0.5354, average train loss: 2.0286
[09/28 11:39:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1675, average loss: 2.0289
[09/28 11:39:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.00	top5: 79.50	
[09/28 11:39:31 visual_prompt]: 	Test 100/190. loss: 1.836, 0.2156 s / batch. (data: 8.18e-05)max mem: 7.81213 GB 
[09/28 11:39:51 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2161, average loss: 1.9860
[09/28 11:39:51 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.17	top5: 79.04	
[09/28 11:39:51 visual_prompt]: Best epoch 7: best metric: 0.220
[09/28 11:39:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/28 11:40:01 visual_prompt]: Epoch 8 / 100: avg data time: 6.97e-02, avg batch time: 0.5235, average train loss: 2.0606
[09/28 11:40:03 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1677, average loss: 2.0104
[09/28 11:40:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.00	top5: 80.50	
[09/28 11:40:26 visual_prompt]: 	Test 100/190. loss: 2.099, 0.2165 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 11:40:47 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2162, average loss: 2.0838
[09/28 11:40:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.77	top5: 77.11	
[09/28 11:40:47 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/28 11:40:56 visual_prompt]: Epoch 9 / 100: avg data time: 7.65e-02, avg batch time: 0.5309, average train loss: 1.9917
[09/28 11:40:58 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1675, average loss: 1.9211
[09/28 11:40:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.00	top5: 84.00	
[09/28 11:41:21 visual_prompt]: 	Test 100/190. loss: 2.002, 0.2163 s / batch. (data: 6.39e-05)max mem: 7.81213 GB 
[09/28 11:41:42 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2164, average loss: 1.9833
[09/28 11:41:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.39	top5: 83.97	
[09/28 11:41:42 visual_prompt]: Best epoch 9: best metric: 0.240
[09/28 11:41:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/28 11:41:51 visual_prompt]: Epoch 10 / 100: avg data time: 8.27e-02, avg batch time: 0.5363, average train loss: 1.8443
[09/28 11:41:54 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1710, average loss: 1.8763
[09/28 11:41:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.00	top5: 90.00	
[09/28 11:42:17 visual_prompt]: 	Test 100/190. loss: 1.999, 0.2166 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 11:42:37 visual_prompt]: Inference (test):avg data time: 2.53e-04, avg batch time: 0.2165, average loss: 1.9707
[09/28 11:42:37 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.04	top5: 90.44	
[09/28 11:42:37 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/28 11:42:47 visual_prompt]: Epoch 11 / 100: avg data time: 8.27e-02, avg batch time: 0.5366, average train loss: 1.9621
[09/28 11:42:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1678, average loss: 1.9832
[09/28 11:42:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.50	top5: 86.00	
[09/28 11:43:12 visual_prompt]: 	Test 100/190. loss: 1.974, 0.2166 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 11:43:33 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2162, average loss: 2.1575
[09/28 11:43:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.21	top5: 82.18	
[09/28 11:43:33 visual_prompt]: Best epoch 11: best metric: 0.245
[09/28 11:43:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/28 11:43:42 visual_prompt]: Epoch 12 / 100: avg data time: 7.09e-02, avg batch time: 0.5245, average train loss: 1.8329
[09/28 11:43:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1676, average loss: 1.6138
[09/28 11:43:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.50	top5: 97.00	
[09/28 11:44:07 visual_prompt]: 	Test 100/190. loss: 1.683, 0.2173 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 11:44:28 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2162, average loss: 1.8406
[09/28 11:44:28 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.74	top5: 91.67	
[09/28 11:44:28 visual_prompt]: Best epoch 12: best metric: 0.315
[09/28 11:44:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/28 11:44:37 visual_prompt]: Epoch 13 / 100: avg data time: 8.72e-02, avg batch time: 0.5404, average train loss: 1.6587
[09/28 11:44:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1678, average loss: 1.8132
[09/28 11:44:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.50	top5: 86.00	
[09/28 11:45:03 visual_prompt]: 	Test 100/190. loss: 1.987, 0.2161 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 11:45:23 visual_prompt]: Inference (test):avg data time: 3.69e-05, avg batch time: 0.2162, average loss: 1.9035
[09/28 11:45:23 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.84	top5: 88.12	
[09/28 11:45:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/28 11:45:33 visual_prompt]: Epoch 14 / 100: avg data time: 8.74e-02, avg batch time: 0.5402, average train loss: 1.6884
[09/28 11:45:35 visual_prompt]: Inference (val):avg data time: 4.34e-05, avg batch time: 0.1677, average loss: 1.5946
[09/28 11:45:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.00	top5: 96.50	
[09/28 11:45:58 visual_prompt]: 	Test 100/190. loss: 1.956, 0.2169 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 11:46:19 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2161, average loss: 1.8199
[09/28 11:46:19 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.76	top5: 95.00	
[09/28 11:46:19 visual_prompt]: Best epoch 14: best metric: 0.320
[09/28 11:46:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/28 11:46:28 visual_prompt]: Epoch 15 / 100: avg data time: 7.73e-02, avg batch time: 0.5305, average train loss: 1.5596
[09/28 11:46:31 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1679, average loss: 1.6314
[09/28 11:46:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.00	top5: 98.50	
[09/28 11:46:53 visual_prompt]: 	Test 100/190. loss: 1.994, 0.2162 s / batch. (data: 2.55e-05)max mem: 7.81213 GB 
[09/28 11:47:14 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2163, average loss: 1.9252
[09/28 11:47:14 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.53	top5: 94.86	
[09/28 11:47:14 visual_prompt]: Best epoch 15: best metric: 0.380
[09/28 11:47:14 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/28 11:47:23 visual_prompt]: Epoch 16 / 100: avg data time: 7.35e-02, avg batch time: 0.5270, average train loss: 1.5638
[09/28 11:47:26 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1680, average loss: 1.3750
[09/28 11:47:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.50	top5: 96.00	
[09/28 11:47:49 visual_prompt]: 	Test 100/190. loss: 1.562, 0.2156 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 11:48:09 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2164, average loss: 1.6862
[09/28 11:48:09 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.70	top5: 93.15	
[09/28 11:48:09 visual_prompt]: Best epoch 16: best metric: 0.415
[09/28 11:48:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/28 11:48:18 visual_prompt]: Epoch 17 / 100: avg data time: 7.39e-02, avg batch time: 0.5280, average train loss: 1.5438
[09/28 11:48:21 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1679, average loss: 1.6159
[09/28 11:48:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.50	top5: 99.50	
[09/28 11:48:44 visual_prompt]: 	Test 100/190. loss: 1.839, 0.2168 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 11:49:04 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2162, average loss: 1.9644
[09/28 11:49:04 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.33	top5: 94.14	
[09/28 11:49:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/28 11:49:14 visual_prompt]: Epoch 18 / 100: avg data time: 7.30e-02, avg batch time: 0.5259, average train loss: 1.4285
[09/28 11:49:16 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1675, average loss: 1.3791
[09/28 11:49:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 49.00	top5: 98.50	
[09/28 11:49:39 visual_prompt]: 	Test 100/190. loss: 1.682, 0.2157 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 11:50:00 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2164, average loss: 1.9654
[09/28 11:50:00 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.40	top5: 94.44	
[09/28 11:50:00 visual_prompt]: Best epoch 18: best metric: 0.490
[09/28 11:50:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/28 11:50:09 visual_prompt]: Epoch 19 / 100: avg data time: 6.98e-02, avg batch time: 0.5250, average train loss: 1.3386
[09/28 11:50:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1680, average loss: 1.2141
[09/28 11:50:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 49.00	top5: 98.50	
[09/28 11:50:34 visual_prompt]: 	Test 100/190. loss: 1.733, 0.2170 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 11:50:55 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2163, average loss: 1.8523
[09/28 11:50:55 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.70	top5: 93.89	
[09/28 11:50:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/28 11:51:04 visual_prompt]: Epoch 20 / 100: avg data time: 8.07e-02, avg batch time: 0.5337, average train loss: 1.2848
[09/28 11:51:07 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 1.3929
[09/28 11:51:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 49.50	top5: 100.00	
[09/28 11:51:29 visual_prompt]: 	Test 100/190. loss: 1.776, 0.2164 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 11:51:50 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2164, average loss: 1.9992
[09/28 11:51:50 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.39	top5: 95.66	
[09/28 11:51:50 visual_prompt]: Best epoch 20: best metric: 0.495
[09/28 11:51:50 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/28 11:51:59 visual_prompt]: Epoch 21 / 100: avg data time: 8.81e-02, avg batch time: 0.5411, average train loss: 1.3330
[09/28 11:52:02 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1677, average loss: 1.3077
[09/28 11:52:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 44.50	top5: 100.00	
[09/28 11:52:25 visual_prompt]: 	Test 100/190. loss: 1.758, 0.2171 s / batch. (data: 8.39e-05)max mem: 7.81213 GB 
[09/28 11:52:45 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2164, average loss: 1.8027
[09/28 11:52:45 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.20	top5: 95.59	
[09/28 11:52:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/28 11:52:55 visual_prompt]: Epoch 22 / 100: avg data time: 7.39e-02, avg batch time: 0.5285, average train loss: 1.3167
[09/28 11:52:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 1.2401
[09/28 11:52:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 44.50	top5: 98.50	
[09/28 11:53:20 visual_prompt]: 	Test 100/190. loss: 1.891, 0.2174 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 11:53:40 visual_prompt]: Inference (test):avg data time: 1.30e-04, avg batch time: 0.2164, average loss: 1.8405
[09/28 11:53:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.39	top5: 95.92	
[09/28 11:53:40 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/28 11:53:50 visual_prompt]: Epoch 23 / 100: avg data time: 8.10e-02, avg batch time: 0.5345, average train loss: 1.3527
[09/28 11:53:52 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1678, average loss: 1.6916
[09/28 11:53:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.00	top5: 99.00	
[09/28 11:54:15 visual_prompt]: 	Test 100/190. loss: 2.024, 0.2172 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 11:54:36 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2162, average loss: 2.1129
[09/28 11:54:36 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 31.38	top5: 94.98	
[09/28 11:54:36 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/28 11:54:45 visual_prompt]: Epoch 24 / 100: avg data time: 7.72e-02, avg batch time: 0.5322, average train loss: 1.3457
[09/28 11:54:48 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1678, average loss: 1.1833
[09/28 11:54:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 48.50	top5: 98.50	
[09/28 11:55:11 visual_prompt]: 	Test 100/190. loss: 1.631, 0.2171 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 11:55:31 visual_prompt]: Inference (test):avg data time: 3.69e-05, avg batch time: 0.2165, average loss: 1.7773
[09/28 11:55:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.03	top5: 96.45	
[09/28 11:55:31 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/28 11:55:40 visual_prompt]: Epoch 25 / 100: avg data time: 7.25e-02, avg batch time: 0.5265, average train loss: 1.1292
[09/28 11:55:43 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1678, average loss: 1.1335
[09/28 11:55:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 48.50	top5: 99.50	
[09/28 11:56:06 visual_prompt]: 	Test 100/190. loss: 1.938, 0.2164 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 11:56:26 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2163, average loss: 1.9603
[09/28 11:56:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.20	top5: 96.18	
[09/28 11:56:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/28 11:56:36 visual_prompt]: Epoch 26 / 100: avg data time: 7.82e-02, avg batch time: 0.5318, average train loss: 1.0167
[09/28 11:56:38 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1678, average loss: 0.9261
[09/28 11:56:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 61.00	top5: 99.50	
[09/28 11:57:01 visual_prompt]: 	Test 100/190. loss: 1.383, 0.2170 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 11:57:22 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2163, average loss: 1.8998
[09/28 11:57:22 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 32.12	top5: 96.28	
[09/28 11:57:22 visual_prompt]: Best epoch 26: best metric: 0.610
[09/28 11:57:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/28 11:57:31 visual_prompt]: Epoch 27 / 100: avg data time: 8.62e-02, avg batch time: 0.5391, average train loss: 1.0139
[09/28 11:57:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 0.8056
[09/28 11:57:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 67.50	top5: 100.00	
[09/28 11:57:57 visual_prompt]: 	Test 100/190. loss: 1.514, 0.2171 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 11:58:17 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2164, average loss: 1.7898
[09/28 11:58:17 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.26	top5: 96.60	
[09/28 11:58:17 visual_prompt]: Best epoch 27: best metric: 0.675
[09/28 11:58:17 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/28 11:58:27 visual_prompt]: Epoch 28 / 100: avg data time: 8.22e-02, avg batch time: 0.5362, average train loss: 0.9881
[09/28 11:58:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 0.7946
[09/28 11:58:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 68.50	top5: 99.50	
[09/28 11:58:52 visual_prompt]: 	Test 100/190. loss: 1.765, 0.2158 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 11:59:13 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2162, average loss: 1.9005
[09/28 11:59:13 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.57	top5: 96.07	
[09/28 11:59:13 visual_prompt]: Best epoch 28: best metric: 0.685
[09/28 11:59:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/28 11:59:22 visual_prompt]: Epoch 29 / 100: avg data time: 7.95e-02, avg batch time: 0.5335, average train loss: 0.8549
[09/28 11:59:25 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1675, average loss: 0.7493
[09/28 11:59:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 70.00	top5: 99.50	
[09/28 11:59:48 visual_prompt]: 	Test 100/190. loss: 1.686, 0.2170 s / batch. (data: 6.65e-05)max mem: 7.81213 GB 
[09/28 12:00:08 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2162, average loss: 1.9422
[09/28 12:00:08 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.97	top5: 96.56	
[09/28 12:00:08 visual_prompt]: Best epoch 29: best metric: 0.700
[09/28 12:00:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/28 12:00:17 visual_prompt]: Epoch 30 / 100: avg data time: 7.61e-02, avg batch time: 0.5309, average train loss: 0.8327
[09/28 12:00:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1677, average loss: 0.7716
[09/28 12:00:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 66.50	top5: 100.00	
[09/28 12:00:43 visual_prompt]: 	Test 100/190. loss: 1.658, 0.2154 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 12:01:03 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2166, average loss: 2.0212
[09/28 12:01:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.29	top5: 96.53	
[09/28 12:01:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/28 12:01:13 visual_prompt]: Epoch 31 / 100: avg data time: 8.27e-02, avg batch time: 0.5363, average train loss: 0.8266
[09/28 12:01:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 1.0589
[09/28 12:01:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 60.00	top5: 99.50	
[09/28 12:01:38 visual_prompt]: 	Test 100/190. loss: 2.159, 0.2174 s / batch. (data: 3.19e-05)max mem: 7.81213 GB 
[09/28 12:01:58 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2165, average loss: 2.4478
[09/28 12:01:59 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.26	top5: 94.40	
[09/28 12:01:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/28 12:02:08 visual_prompt]: Epoch 32 / 100: avg data time: 7.33e-02, avg batch time: 0.5270, average train loss: 0.9288
[09/28 12:02:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1680, average loss: 0.6411
[09/28 12:02:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 74.50	top5: 100.00	
[09/28 12:02:33 visual_prompt]: 	Test 100/190. loss: 1.568, 0.2174 s / batch. (data: 2.43e-05)max mem: 7.81213 GB 
[09/28 12:02:54 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2162, average loss: 1.9296
[09/28 12:02:54 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.60	top5: 96.05	
[09/28 12:02:54 visual_prompt]: Best epoch 32: best metric: 0.745
[09/28 12:02:54 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/28 12:03:03 visual_prompt]: Epoch 33 / 100: avg data time: 8.18e-02, avg batch time: 0.5367, average train loss: 0.8077
[09/28 12:03:06 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1676, average loss: 0.5235
[09/28 12:03:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 82.00	top5: 99.50	
[09/28 12:03:29 visual_prompt]: 	Test 100/190. loss: 1.703, 0.2161 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 12:03:49 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2164, average loss: 1.9965
[09/28 12:03:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.26	top5: 96.44	
[09/28 12:03:49 visual_prompt]: Best epoch 33: best metric: 0.820
[09/28 12:03:49 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/28 12:03:58 visual_prompt]: Epoch 34 / 100: avg data time: 8.08e-02, avg batch time: 0.5350, average train loss: 0.6008
[09/28 12:04:01 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1677, average loss: 0.7511
[09/28 12:04:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 73.50	top5: 100.00	
[09/28 12:04:24 visual_prompt]: 	Test 100/190. loss: 2.197, 0.2157 s / batch. (data: 3.03e-05)max mem: 7.81213 GB 
[09/28 12:04:44 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2162, average loss: 2.6660
[09/28 12:04:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.86	top5: 96.95	
[09/28 12:04:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/28 12:04:54 visual_prompt]: Epoch 35 / 100: avg data time: 7.66e-02, avg batch time: 0.5301, average train loss: 0.5915
[09/28 12:04:56 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1677, average loss: 0.6704
[09/28 12:04:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 72.00	top5: 100.00	
[09/28 12:05:19 visual_prompt]: 	Test 100/190. loss: 2.641, 0.2159 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 12:05:40 visual_prompt]: Inference (test):avg data time: 1.04e-04, avg batch time: 0.2165, average loss: 2.6219
[09/28 12:05:40 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.76	top5: 96.31	
[09/28 12:05:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/28 12:05:49 visual_prompt]: Epoch 36 / 100: avg data time: 8.48e-02, avg batch time: 0.5380, average train loss: 0.7579
[09/28 12:05:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1676, average loss: 0.8406
[09/28 12:05:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 70.50	top5: 99.00	
[09/28 12:06:15 visual_prompt]: 	Test 100/190. loss: 2.504, 0.2172 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 12:06:35 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2163, average loss: 2.5434
[09/28 12:06:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.19	top5: 95.19	
[09/28 12:06:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/28 12:06:45 visual_prompt]: Epoch 37 / 100: avg data time: 8.20e-02, avg batch time: 0.5350, average train loss: 0.6863
[09/28 12:06:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 0.6230
[09/28 12:06:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 73.50	top5: 100.00	
[09/28 12:07:10 visual_prompt]: 	Test 100/190. loss: 1.967, 0.2159 s / batch. (data: 3.08e-05)max mem: 7.81213 GB 
[09/28 12:07:31 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2163, average loss: 2.2820
[09/28 12:07:31 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.79	top5: 97.11	
[09/28 12:07:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/28 12:07:40 visual_prompt]: Epoch 38 / 100: avg data time: 6.70e-02, avg batch time: 0.5221, average train loss: 0.5592
[09/28 12:07:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1679, average loss: 0.4347
[09/28 12:07:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 82.50	top5: 100.00	
[09/28 12:08:05 visual_prompt]: 	Test 100/190. loss: 2.475, 0.2149 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 12:08:26 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2164, average loss: 2.4857
[09/28 12:08:26 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.56	top5: 96.29	
[09/28 12:08:26 visual_prompt]: Best epoch 38: best metric: 0.825
[09/28 12:08:26 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/28 12:08:35 visual_prompt]: Epoch 39 / 100: avg data time: 8.18e-02, avg batch time: 0.5352, average train loss: 0.5128
[09/28 12:08:38 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1681, average loss: 0.3501
[09/28 12:08:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 86.00	top5: 100.00	
[09/28 12:09:01 visual_prompt]: 	Test 100/190. loss: 2.729, 0.2166 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 12:09:21 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2163, average loss: 2.7485
[09/28 12:09:21 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.10	top5: 96.39	
[09/28 12:09:21 visual_prompt]: Best epoch 39: best metric: 0.860
[09/28 12:09:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/28 12:09:30 visual_prompt]: Epoch 40 / 100: avg data time: 8.49e-02, avg batch time: 0.5381, average train loss: 0.5869
[09/28 12:09:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1677, average loss: 0.5494
[09/28 12:09:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 78.00	top5: 100.00	
[09/28 12:09:56 visual_prompt]: 	Test 100/190. loss: 2.093, 0.2163 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 12:10:17 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2164, average loss: 2.5758
[09/28 12:10:17 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.88	top5: 95.84	
[09/28 12:10:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/28 12:10:26 visual_prompt]: Epoch 41 / 100: avg data time: 8.79e-02, avg batch time: 0.5424, average train loss: 0.5765
[09/28 12:10:29 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1679, average loss: 0.6515
[09/28 12:10:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.00	top5: 100.00	
[09/28 12:10:52 visual_prompt]: 	Test 100/190. loss: 2.542, 0.2164 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 12:11:12 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.2165, average loss: 2.8168
[09/28 12:11:12 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.42	top5: 96.24	
[09/28 12:11:12 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/28 12:11:21 visual_prompt]: Epoch 42 / 100: avg data time: 8.44e-02, avg batch time: 0.5380, average train loss: 0.4753
[09/28 12:11:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 0.4811
[09/28 12:11:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 80.50	top5: 100.00	
[09/28 12:11:47 visual_prompt]: 	Test 100/190. loss: 2.511, 0.2165 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 12:12:07 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2167, average loss: 2.7663
[09/28 12:12:07 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.44	top5: 95.81	
[09/28 12:12:07 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/28 12:12:17 visual_prompt]: Epoch 43 / 100: avg data time: 8.14e-02, avg batch time: 0.5354, average train loss: 0.4491
[09/28 12:12:19 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1677, average loss: 0.3392
[09/28 12:12:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 86.00	top5: 100.00	
[09/28 12:12:42 visual_prompt]: 	Test 100/190. loss: 2.196, 0.2164 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 12:13:02 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2163, average loss: 2.8672
[09/28 12:13:03 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.86	top5: 95.40	
[09/28 12:13:03 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/28 12:13:12 visual_prompt]: Epoch 44 / 100: avg data time: 8.18e-02, avg batch time: 0.5355, average train loss: 0.5132
[09/28 12:13:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1679, average loss: 0.5473
[09/28 12:13:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 79.00	top5: 100.00	
[09/28 12:13:37 visual_prompt]: 	Test 100/190. loss: 2.766, 0.2163 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 12:13:58 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2163, average loss: 3.0102
[09/28 12:13:58 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.22	top5: 95.31	
[09/28 12:13:58 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/28 12:14:07 visual_prompt]: Epoch 45 / 100: avg data time: 7.55e-02, avg batch time: 0.5300, average train loss: 0.4683
[09/28 12:14:10 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1679, average loss: 0.4295
[09/28 12:14:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 84.50	top5: 100.00	
[09/28 12:14:33 visual_prompt]: 	Test 100/190. loss: 2.562, 0.2162 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 12:14:53 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2162, average loss: 3.0762
[09/28 12:14:53 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.35	top5: 95.78	
[09/28 12:14:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/28 12:15:03 visual_prompt]: Epoch 46 / 100: avg data time: 8.22e-02, avg batch time: 0.5374, average train loss: 0.4280
[09/28 12:15:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 0.1877
[09/28 12:15:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.50	top5: 100.00	
[09/28 12:15:28 visual_prompt]: 	Test 100/190. loss: 2.436, 0.2164 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 12:15:48 visual_prompt]: Inference (test):avg data time: 3.69e-05, avg batch time: 0.2163, average loss: 2.8934
[09/28 12:15:49 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.78	top5: 95.99	
[09/28 12:15:49 visual_prompt]: Best epoch 46: best metric: 0.935
[09/28 12:15:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/28 12:15:58 visual_prompt]: Epoch 47 / 100: avg data time: 7.26e-02, avg batch time: 0.5279, average train loss: 0.3789
[09/28 12:16:00 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1677, average loss: 0.1200
[09/28 12:16:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 12:16:23 visual_prompt]: 	Test 100/190. loss: 2.391, 0.2176 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 12:16:44 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2164, average loss: 2.9368
[09/28 12:16:44 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.58	top5: 96.16	
[09/28 12:16:44 visual_prompt]: Best epoch 47: best metric: 0.965
[09/28 12:16:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/28 12:16:53 visual_prompt]: Epoch 48 / 100: avg data time: 8.20e-02, avg batch time: 0.5362, average train loss: 0.2744
[09/28 12:16:56 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1679, average loss: 0.1143
[09/28 12:16:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.00	top5: 100.00	
[09/28 12:17:19 visual_prompt]: 	Test 100/190. loss: 2.775, 0.2163 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 12:17:39 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2163, average loss: 3.3693
[09/28 12:17:39 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.24	top5: 96.12	
[09/28 12:17:39 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/28 12:17:49 visual_prompt]: Epoch 49 / 100: avg data time: 8.42e-02, avg batch time: 0.5373, average train loss: 0.2436
[09/28 12:17:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1676, average loss: 0.1836
[09/28 12:17:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 12:18:14 visual_prompt]: 	Test 100/190. loss: 3.086, 0.2161 s / batch. (data: 3.12e-05)max mem: 7.81213 GB 
[09/28 12:18:35 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2163, average loss: 3.7604
[09/28 12:18:35 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.66	top5: 94.60	
[09/28 12:18:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/28 12:18:44 visual_prompt]: Epoch 50 / 100: avg data time: 7.72e-02, avg batch time: 0.5305, average train loss: 0.2449
[09/28 12:18:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1679, average loss: 0.2023
[09/28 12:18:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 12:19:09 visual_prompt]: 	Test 100/190. loss: 2.965, 0.2158 s / batch. (data: 2.96e-05)max mem: 7.81213 GB 
[09/28 12:19:30 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2165, average loss: 3.5337
[09/28 12:19:30 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.88	top5: 95.72	
[09/28 12:19:30 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/28 12:19:39 visual_prompt]: Epoch 51 / 100: avg data time: 8.75e-02, avg batch time: 0.5402, average train loss: 0.2037
[09/28 12:19:42 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 0.1920
[09/28 12:19:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.00	top5: 100.00	
[09/28 12:20:05 visual_prompt]: 	Test 100/190. loss: 2.991, 0.2171 s / batch. (data: 6.77e-05)max mem: 7.81213 GB 
[09/28 12:20:25 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2162, average loss: 3.5813
[09/28 12:20:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.42	top5: 95.67	
[09/28 12:20:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/28 12:20:34 visual_prompt]: Epoch 52 / 100: avg data time: 7.48e-02, avg batch time: 0.5300, average train loss: 0.1914
[09/28 12:20:37 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1682, average loss: 0.1605
[09/28 12:20:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.50	top5: 100.00	
[09/28 12:21:00 visual_prompt]: 	Test 100/190. loss: 3.613, 0.2169 s / batch. (data: 2.67e-05)max mem: 7.81213 GB 
[09/28 12:21:20 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2164, average loss: 3.9976
[09/28 12:21:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.26	top5: 96.02	
[09/28 12:21:20 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/28 12:21:30 visual_prompt]: Epoch 53 / 100: avg data time: 8.13e-02, avg batch time: 0.5346, average train loss: 0.2175
[09/28 12:21:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 0.4342
[09/28 12:21:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 87.00	top5: 100.00	
[09/28 12:21:55 visual_prompt]: 	Test 100/190. loss: 3.642, 0.2160 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 12:22:16 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2165, average loss: 4.0647
[09/28 12:22:16 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.14	top5: 94.89	
[09/28 12:22:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/28 12:22:25 visual_prompt]: Epoch 54 / 100: avg data time: 7.63e-02, avg batch time: 0.5315, average train loss: 0.2665
[09/28 12:22:28 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1679, average loss: 0.1154
[09/28 12:22:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.00	top5: 100.00	
[09/28 12:22:51 visual_prompt]: 	Test 100/190. loss: 2.987, 0.2168 s / batch. (data: 2.88e-05)max mem: 7.81213 GB 
[09/28 12:23:11 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2164, average loss: 3.5523
[09/28 12:23:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.23	top5: 95.19	
[09/28 12:23:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/28 12:23:20 visual_prompt]: Epoch 55 / 100: avg data time: 7.70e-02, avg batch time: 0.5309, average train loss: 0.1633
[09/28 12:23:23 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1680, average loss: 0.1483
[09/28 12:23:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 93.50	top5: 100.00	
[09/28 12:23:46 visual_prompt]: 	Test 100/190. loss: 3.242, 0.2163 s / batch. (data: 2.57e-05)max mem: 7.81213 GB 
[09/28 12:24:06 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2166, average loss: 3.9219
[09/28 12:24:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.16	top5: 95.53	
[09/28 12:24:06 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/28 12:24:15 visual_prompt]: Epoch 56 / 100: avg data time: 7.90e-02, avg batch time: 0.5324, average train loss: 0.2518
[09/28 12:24:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 0.2213
[09/28 12:24:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 92.00	top5: 100.00	
[09/28 12:24:41 visual_prompt]: 	Test 100/190. loss: 2.946, 0.2183 s / batch. (data: 2.50e-05)max mem: 7.81213 GB 
[09/28 12:25:01 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2164, average loss: 3.7443
[09/28 12:25:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.81	top5: 95.89	
[09/28 12:25:01 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/28 12:25:11 visual_prompt]: Epoch 57 / 100: avg data time: 8.55e-02, avg batch time: 0.5395, average train loss: 0.1510
[09/28 12:25:13 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1681, average loss: 0.0578
[09/28 12:25:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 12:25:36 visual_prompt]: 	Test 100/190. loss: 3.056, 0.2173 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 12:25:57 visual_prompt]: Inference (test):avg data time: 4.48e-05, avg batch time: 0.2165, average loss: 3.9404
[09/28 12:25:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.11	top5: 95.86	
[09/28 12:25:57 visual_prompt]: Best epoch 57: best metric: 0.975
[09/28 12:25:57 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/28 12:26:06 visual_prompt]: Epoch 58 / 100: avg data time: 8.27e-02, avg batch time: 0.5364, average train loss: 0.1176
[09/28 12:26:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1679, average loss: 0.0718
[09/28 12:26:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 12:26:32 visual_prompt]: 	Test 100/190. loss: 3.153, 0.2170 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 12:26:52 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2164, average loss: 4.0933
[09/28 12:26:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.13	top5: 94.91	
[09/28 12:26:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/28 12:27:02 visual_prompt]: Epoch 59 / 100: avg data time: 8.51e-02, avg batch time: 0.5387, average train loss: 0.1186
[09/28 12:27:04 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1679, average loss: 0.0667
[09/28 12:27:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 12:27:27 visual_prompt]: 	Test 100/190. loss: 2.999, 0.2181 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 12:27:48 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2164, average loss: 4.1262
[09/28 12:27:48 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.35	top5: 95.57	
[09/28 12:27:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/28 12:27:57 visual_prompt]: Epoch 60 / 100: avg data time: 8.05e-02, avg batch time: 0.5346, average train loss: 0.1707
[09/28 12:28:00 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1677, average loss: 0.0942
[09/28 12:28:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 12:28:23 visual_prompt]: 	Test 100/190. loss: 2.987, 0.2165 s / batch. (data: 2.26e-05)max mem: 7.81213 GB 
[09/28 12:28:43 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2164, average loss: 3.9604
[09/28 12:28:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.80	top5: 94.57	
[09/28 12:28:43 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/28 12:28:52 visual_prompt]: Epoch 61 / 100: avg data time: 7.31e-02, avg batch time: 0.5282, average train loss: 0.0907
[09/28 12:28:55 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1677, average loss: 0.0861
[09/28 12:28:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.00	top5: 100.00	
[09/28 12:29:18 visual_prompt]: 	Test 100/190. loss: 3.418, 0.2158 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 12:29:38 visual_prompt]: Inference (test):avg data time: 4.03e-05, avg batch time: 0.2164, average loss: 4.3538
[09/28 12:29:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.07	top5: 95.08	
[09/28 12:29:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/28 12:29:48 visual_prompt]: Epoch 62 / 100: avg data time: 8.23e-02, avg batch time: 0.5361, average train loss: 0.0774
[09/28 12:29:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1680, average loss: 0.0148
[09/28 12:29:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 100.00	top5: 100.00	
[09/28 12:30:13 visual_prompt]: 	Test 100/190. loss: 3.712, 0.2168 s / batch. (data: 8.20e-05)max mem: 7.81213 GB 
[09/28 12:30:34 visual_prompt]: Inference (test):avg data time: 4.32e-05, avg batch time: 0.2164, average loss: 4.4812
[09/28 12:30:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.89	top5: 95.28	
[09/28 12:30:34 visual_prompt]: Best epoch 62: best metric: 1.000
[09/28 12:30:34 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/28 12:30:43 visual_prompt]: Epoch 63 / 100: avg data time: 8.78e-02, avg batch time: 0.5411, average train loss: 0.0738
[09/28 12:30:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1678, average loss: 0.1263
[09/28 12:30:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 95.50	top5: 100.00	
[09/28 12:31:09 visual_prompt]: 	Test 100/190. loss: 3.919, 0.2171 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 12:31:29 visual_prompt]: Inference (test):avg data time: 1.12e-04, avg batch time: 0.2165, average loss: 4.9251
[09/28 12:31:29 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.27	top5: 94.64	
[09/28 12:31:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/28 12:31:39 visual_prompt]: Epoch 64 / 100: avg data time: 7.83e-02, avg batch time: 0.5314, average train loss: 0.0772
[09/28 12:31:41 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1678, average loss: 0.1736
[09/28 12:31:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.00	top5: 100.00	
[09/28 12:32:04 visual_prompt]: 	Test 100/190. loss: 3.835, 0.2171 s / batch. (data: 7.30e-05)max mem: 7.81213 GB 
[09/28 12:32:25 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2162, average loss: 4.9025
[09/28 12:32:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.67	top5: 95.32	
[09/28 12:32:25 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/28 12:32:34 visual_prompt]: Epoch 65 / 100: avg data time: 8.99e-02, avg batch time: 0.5432, average train loss: 0.0800
[09/28 12:32:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1678, average loss: 0.1508
[09/28 12:32:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 94.00	top5: 100.00	
[09/28 12:33:00 visual_prompt]: 	Test 100/190. loss: 3.904, 0.2173 s / batch. (data: 2.72e-05)max mem: 7.81213 GB 
[09/28 12:33:20 visual_prompt]: Inference (test):avg data time: 4.41e-05, avg batch time: 0.2164, average loss: 4.9927
[09/28 12:33:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.72	top5: 93.65	
[09/28 12:33:20 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/28 12:33:30 visual_prompt]: Epoch 66 / 100: avg data time: 7.34e-02, avg batch time: 0.5282, average train loss: 0.0645
[09/28 12:33:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1680, average loss: 0.0738
[09/28 12:33:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 97.50	top5: 100.00	
[09/28 12:33:55 visual_prompt]: 	Test 100/190. loss: 3.448, 0.2166 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 12:34:15 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2165, average loss: 4.8197
[09/28 12:34:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.05	top5: 94.76	
[09/28 12:34:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/28 12:34:25 visual_prompt]: Epoch 67 / 100: avg data time: 7.78e-02, avg batch time: 0.5340, average train loss: 0.0759
[09/28 12:34:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1679, average loss: 0.0230
[09/28 12:34:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 12:34:50 visual_prompt]: 	Test 100/190. loss: 3.821, 0.2177 s / batch. (data: 3.36e-05)max mem: 7.81213 GB 
[09/28 12:35:11 visual_prompt]: Inference (test):avg data time: 5.31e-05, avg batch time: 0.2164, average loss: 5.1439
[09/28 12:35:11 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.92	top5: 94.63	
[09/28 12:35:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/28 12:35:20 visual_prompt]: Epoch 68 / 100: avg data time: 7.69e-02, avg batch time: 0.5318, average train loss: 0.0497
[09/28 12:35:23 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1677, average loss: 0.0154
[09/28 12:35:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:35:46 visual_prompt]: 	Test 100/190. loss: 4.401, 0.2177 s / batch. (data: 2.77e-05)max mem: 7.81213 GB 
[09/28 12:36:06 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2163, average loss: 5.2069
[09/28 12:36:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.25	top5: 94.48	
[09/28 12:36:06 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/28 12:36:15 visual_prompt]: Epoch 69 / 100: avg data time: 7.33e-02, avg batch time: 0.5283, average train loss: 0.0647
[09/28 12:36:18 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1680, average loss: 0.0809
[09/28 12:36:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 98.00	top5: 100.00	
[09/28 12:36:41 visual_prompt]: 	Test 100/190. loss: 4.390, 0.2161 s / batch. (data: 4.96e-05)max mem: 7.81213 GB 
[09/28 12:37:01 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2163, average loss: 5.4717
[09/28 12:37:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.85	top5: 95.23	
[09/28 12:37:01 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/28 12:37:11 visual_prompt]: Epoch 70 / 100: avg data time: 7.36e-02, avg batch time: 0.5287, average train loss: 0.0566
[09/28 12:37:13 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1675, average loss: 0.0403
[09/28 12:37:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 12:37:36 visual_prompt]: 	Test 100/190. loss: 4.173, 0.2171 s / batch. (data: 3.05e-05)max mem: 7.81213 GB 
[09/28 12:37:56 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2165, average loss: 5.2866
[09/28 12:37:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.94	top5: 94.67	
[09/28 12:37:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/28 12:38:06 visual_prompt]: Epoch 71 / 100: avg data time: 8.59e-02, avg batch time: 0.5392, average train loss: 0.0284
[09/28 12:38:08 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.1681, average loss: 0.1248
[09/28 12:38:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 96.50	top5: 100.00	
[09/28 12:38:31 visual_prompt]: 	Test 100/190. loss: 4.247, 0.2170 s / batch. (data: 2.96e-05)max mem: 7.81213 GB 
[09/28 12:38:52 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2163, average loss: 5.5681
[09/28 12:38:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.62	top5: 95.41	
[09/28 12:38:52 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/28 12:39:01 visual_prompt]: Epoch 72 / 100: avg data time: 8.11e-02, avg batch time: 0.5344, average train loss: 0.0144
[09/28 12:39:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1676, average loss: 0.0225
[09/28 12:39:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 12:39:27 visual_prompt]: 	Test 100/190. loss: 4.085, 0.2166 s / batch. (data: 2.43e-05)max mem: 7.81213 GB 
[09/28 12:39:47 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2164, average loss: 5.4733
[09/28 12:39:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.30	top5: 95.59	
[09/28 12:39:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/28 12:39:56 visual_prompt]: Epoch 73 / 100: avg data time: 7.97e-02, avg batch time: 0.5349, average train loss: 0.0109
[09/28 12:39:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1678, average loss: 0.0324
[09/28 12:39:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 12:40:22 visual_prompt]: 	Test 100/190. loss: 4.294, 0.2162 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 12:40:43 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2165, average loss: 5.5789
[09/28 12:40:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.58	top5: 95.52	
[09/28 12:40:43 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/28 12:40:52 visual_prompt]: Epoch 74 / 100: avg data time: 8.28e-02, avg batch time: 0.5371, average train loss: 0.0159
[09/28 12:40:55 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1680, average loss: 0.0173
[09/28 12:40:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:41:18 visual_prompt]: 	Test 100/190. loss: 4.088, 0.2172 s / batch. (data: 3.00e-05)max mem: 7.81213 GB 
[09/28 12:41:38 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2162, average loss: 5.6732
[09/28 12:41:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.10	top5: 95.51	
[09/28 12:41:38 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/28 12:41:47 visual_prompt]: Epoch 75 / 100: avg data time: 7.70e-02, avg batch time: 0.5315, average train loss: 0.0073
[09/28 12:41:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1676, average loss: 0.0409
[09/28 12:41:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.00	top5: 100.00	
[09/28 12:42:13 visual_prompt]: 	Test 100/190. loss: 4.102, 0.2164 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 12:42:33 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2165, average loss: 5.7259
[09/28 12:42:33 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.73	top5: 95.73	
[09/28 12:42:33 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/28 12:42:43 visual_prompt]: Epoch 76 / 100: avg data time: 8.11e-02, avg batch time: 0.5355, average train loss: 0.0055
[09/28 12:42:45 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1679, average loss: 0.0206
[09/28 12:42:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:43:08 visual_prompt]: 	Test 100/190. loss: 4.174, 0.2169 s / batch. (data: 3.05e-05)max mem: 7.81213 GB 
[09/28 12:43:29 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2163, average loss: 5.6849
[09/28 12:43:29 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.80	top5: 95.88	
[09/28 12:43:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/28 12:43:38 visual_prompt]: Epoch 77 / 100: avg data time: 8.06e-02, avg batch time: 0.5342, average train loss: 0.0058
[09/28 12:43:41 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1676, average loss: 0.0213
[09/28 12:43:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:44:04 visual_prompt]: 	Test 100/190. loss: 4.351, 0.2160 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 12:44:24 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2164, average loss: 5.7866
[09/28 12:44:24 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.66	top5: 95.70	
[09/28 12:44:24 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/28 12:44:34 visual_prompt]: Epoch 78 / 100: avg data time: 8.87e-02, avg batch time: 0.5419, average train loss: 0.0032
[09/28 12:44:36 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1680, average loss: 0.0236
[09/28 12:44:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:44:59 visual_prompt]: 	Test 100/190. loss: 4.316, 0.2160 s / batch. (data: 2.69e-05)max mem: 7.81213 GB 
[09/28 12:45:20 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2164, average loss: 5.8321
[09/28 12:45:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.40	top5: 95.70	
[09/28 12:45:20 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/28 12:45:29 visual_prompt]: Epoch 79 / 100: avg data time: 7.30e-02, avg batch time: 0.5276, average train loss: 0.0043
[09/28 12:45:31 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1676, average loss: 0.0208
[09/28 12:45:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:45:54 visual_prompt]: 	Test 100/190. loss: 4.200, 0.2171 s / batch. (data: 9.18e-05)max mem: 7.81213 GB 
[09/28 12:46:15 visual_prompt]: Inference (test):avg data time: 5.12e-05, avg batch time: 0.2163, average loss: 5.8122
[09/28 12:46:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.58	top5: 95.69	
[09/28 12:46:15 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/28 12:46:24 visual_prompt]: Epoch 80 / 100: avg data time: 8.84e-02, avg batch time: 0.5415, average train loss: 0.0037
[09/28 12:46:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1681, average loss: 0.0181
[09/28 12:46:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:46:50 visual_prompt]: 	Test 100/190. loss: 4.221, 0.2172 s / batch. (data: 2.93e-05)max mem: 7.81213 GB 
[09/28 12:47:10 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2163, average loss: 5.7865
[09/28 12:47:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.51	top5: 95.63	
[09/28 12:47:10 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/28 12:47:20 visual_prompt]: Epoch 81 / 100: avg data time: 7.21e-02, avg batch time: 0.5264, average train loss: 0.0028
[09/28 12:47:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 0.0269
[09/28 12:47:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:47:45 visual_prompt]: 	Test 100/190. loss: 4.263, 0.2161 s / batch. (data: 2.98e-05)max mem: 7.81213 GB 
[09/28 12:48:06 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2164, average loss: 5.8787
[09/28 12:48:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.40	top5: 95.63	
[09/28 12:48:06 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/28 12:48:15 visual_prompt]: Epoch 82 / 100: avg data time: 8.05e-02, avg batch time: 0.5345, average train loss: 0.0044
[09/28 12:48:17 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1680, average loss: 0.0294
[09/28 12:48:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:48:40 visual_prompt]: 	Test 100/190. loss: 4.331, 0.2163 s / batch. (data: 3.19e-05)max mem: 7.81213 GB 
[09/28 12:49:01 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2163, average loss: 5.9244
[09/28 12:49:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.42	top5: 95.57	
[09/28 12:49:01 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/28 12:49:10 visual_prompt]: Epoch 83 / 100: avg data time: 7.86e-02, avg batch time: 0.5352, average train loss: 0.0029
[09/28 12:49:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1678, average loss: 0.0299
[09/28 12:49:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:49:36 visual_prompt]: 	Test 100/190. loss: 4.333, 0.2167 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 12:49:56 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2164, average loss: 5.9483
[09/28 12:49:56 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.44	top5: 95.60	
[09/28 12:49:56 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/28 12:50:06 visual_prompt]: Epoch 84 / 100: avg data time: 7.20e-02, avg batch time: 0.5286, average train loss: 0.0027
[09/28 12:50:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 0.0217
[09/28 12:50:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:50:31 visual_prompt]: 	Test 100/190. loss: 4.277, 0.2172 s / batch. (data: 2.65e-05)max mem: 7.81213 GB 
[09/28 12:50:52 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2163, average loss: 5.9065
[09/28 12:50:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.58	top5: 95.62	
[09/28 12:50:52 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/28 12:51:01 visual_prompt]: Epoch 85 / 100: avg data time: 8.77e-02, avg batch time: 0.5413, average train loss: 0.0033
[09/28 12:51:04 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1680, average loss: 0.0247
[09/28 12:51:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:51:27 visual_prompt]: 	Test 100/190. loss: 4.304, 0.2167 s / batch. (data: 6.94e-05)max mem: 7.81213 GB 
[09/28 12:51:48 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2162, average loss: 5.9714
[09/28 12:51:48 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.44	top5: 95.50	
[09/28 12:51:48 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/28 12:51:57 visual_prompt]: Epoch 86 / 100: avg data time: 7.63e-02, avg batch time: 0.5295, average train loss: 0.0024
[09/28 12:51:59 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1676, average loss: 0.0274
[09/28 12:51:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:52:22 visual_prompt]: 	Test 100/190. loss: 4.320, 0.2161 s / batch. (data: 6.79e-05)max mem: 7.81213 GB 
[09/28 12:52:43 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2163, average loss: 6.0139
[09/28 12:52:43 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.26	top5: 95.47	
[09/28 12:52:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/28 12:52:52 visual_prompt]: Epoch 87 / 100: avg data time: 7.82e-02, avg batch time: 0.5320, average train loss: 0.0017
[09/28 12:52:55 visual_prompt]: Inference (val):avg data time: 4.77e-05, avg batch time: 0.1677, average loss: 0.0275
[09/28 12:52:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:53:18 visual_prompt]: 	Test 100/190. loss: 4.320, 0.2163 s / batch. (data: 2.84e-05)max mem: 7.81213 GB 
[09/28 12:53:38 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2166, average loss: 6.0131
[09/28 12:53:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.26	top5: 95.52	
[09/28 12:53:38 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/28 12:53:48 visual_prompt]: Epoch 88 / 100: avg data time: 7.81e-02, avg batch time: 0.5315, average train loss: 0.0019
[09/28 12:53:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1690, average loss: 0.0258
[09/28 12:53:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:54:13 visual_prompt]: 	Test 100/190. loss: 4.334, 0.2163 s / batch. (data: 4.84e-05)max mem: 7.81213 GB 
[09/28 12:54:34 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2165, average loss: 5.9922
[09/28 12:54:34 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.31	top5: 95.55	
[09/28 12:54:34 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/28 12:54:43 visual_prompt]: Epoch 89 / 100: avg data time: 8.75e-02, avg batch time: 0.5408, average train loss: 0.0041
[09/28 12:54:46 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1681, average loss: 0.0227
[09/28 12:54:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:55:09 visual_prompt]: 	Test 100/190. loss: 4.326, 0.2165 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 12:55:29 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2164, average loss: 5.9561
[09/28 12:55:29 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.28	top5: 95.54	
[09/28 12:55:29 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/28 12:55:39 visual_prompt]: Epoch 90 / 100: avg data time: 8.36e-02, avg batch time: 0.5385, average train loss: 0.0033
[09/28 12:55:41 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1679, average loss: 0.0222
[09/28 12:55:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:56:04 visual_prompt]: 	Test 100/190. loss: 4.342, 0.2173 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 12:56:25 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2163, average loss: 5.9428
[09/28 12:56:25 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.33	top5: 95.56	
[09/28 12:56:25 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/28 12:56:34 visual_prompt]: Epoch 91 / 100: avg data time: 7.56e-02, avg batch time: 0.5306, average train loss: 0.0031
[09/28 12:56:37 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1676, average loss: 0.0199
[09/28 12:56:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:56:59 visual_prompt]: 	Test 100/190. loss: 4.335, 0.2169 s / batch. (data: 2.79e-05)max mem: 7.81213 GB 
[09/28 12:57:20 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2164, average loss: 5.9167
[09/28 12:57:20 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.35	top5: 95.62	
[09/28 12:57:20 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/28 12:57:29 visual_prompt]: Epoch 92 / 100: avg data time: 8.60e-02, avg batch time: 0.5394, average train loss: 0.0058
[09/28 12:57:32 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1676, average loss: 0.0189
[09/28 12:57:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:57:55 visual_prompt]: 	Test 100/190. loss: 4.329, 0.2171 s / batch. (data: 2.36e-05)max mem: 7.81213 GB 
[09/28 12:58:15 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2164, average loss: 5.8953
[09/28 12:58:15 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.38	top5: 95.65	
[09/28 12:58:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/28 12:58:24 visual_prompt]: Epoch 93 / 100: avg data time: 7.42e-02, avg batch time: 0.5285, average train loss: 0.0019
[09/28 12:58:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1679, average loss: 0.0194
[09/28 12:58:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:58:50 visual_prompt]: 	Test 100/190. loss: 4.325, 0.2156 s / batch. (data: 7.13e-05)max mem: 7.81213 GB 
[09/28 12:59:10 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2164, average loss: 5.8888
[09/28 12:59:10 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.35	top5: 95.69	
[09/28 12:59:10 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/28 12:59:20 visual_prompt]: Epoch 94 / 100: avg data time: 8.78e-02, avg batch time: 0.5411, average train loss: 0.0018
[09/28 12:59:22 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1679, average loss: 0.0196
[09/28 12:59:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 12:59:45 visual_prompt]: 	Test 100/190. loss: 4.330, 0.2165 s / batch. (data: 2.57e-05)max mem: 7.81213 GB 
[09/28 13:00:06 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2162, average loss: 5.8902
[09/28 13:00:06 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.37	top5: 95.69	
[09/28 13:00:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/28 13:00:15 visual_prompt]: Epoch 95 / 100: avg data time: 7.45e-02, avg batch time: 0.5291, average train loss: 0.0020
[09/28 13:00:18 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1681, average loss: 0.0201
[09/28 13:00:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 13:00:41 visual_prompt]: 	Test 100/190. loss: 4.335, 0.2168 s / batch. (data: 4.55e-05)max mem: 7.81213 GB 
[09/28 13:01:01 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2163, average loss: 5.8909
[09/28 13:01:01 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.41	top5: 95.70	
[09/28 13:01:01 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/28 13:01:10 visual_prompt]: Epoch 96 / 100: avg data time: 8.74e-02, avg batch time: 0.5408, average train loss: 0.0018
[09/28 13:01:13 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1677, average loss: 0.0206
[09/28 13:01:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 13:01:36 visual_prompt]: 	Test 100/190. loss: 4.339, 0.2175 s / batch. (data: 2.86e-05)max mem: 7.81213 GB 
[09/28 13:01:56 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2163, average loss: 5.8937
[09/28 13:01:57 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.42	top5: 95.71	
[09/28 13:01:57 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/28 13:02:06 visual_prompt]: Epoch 97 / 100: avg data time: 6.92e-02, avg batch time: 0.5244, average train loss: 0.0015
[09/28 13:02:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1679, average loss: 0.0209
[09/28 13:02:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 13:02:31 visual_prompt]: 	Test 100/190. loss: 4.341, 0.2170 s / batch. (data: 2.74e-05)max mem: 7.81213 GB 
[09/28 13:02:52 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2163, average loss: 5.8953
[09/28 13:02:52 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.41	top5: 95.70	
[09/28 13:02:52 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/28 13:03:01 visual_prompt]: Epoch 98 / 100: avg data time: 8.69e-02, avg batch time: 0.5419, average train loss: 0.0027
[09/28 13:03:04 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 0.0207
[09/28 13:03:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 13:03:27 visual_prompt]: 	Test 100/190. loss: 4.344, 0.2158 s / batch. (data: 2.81e-05)max mem: 7.81213 GB 
[09/28 13:03:47 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2163, average loss: 5.8948
[09/28 13:03:47 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.42	top5: 95.70	
[09/28 13:03:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/28 13:03:56 visual_prompt]: Epoch 99 / 100: avg data time: 8.34e-02, avg batch time: 0.5372, average train loss: 0.0023
[09/28 13:03:59 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1680, average loss: 0.0207
[09/28 13:03:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 13:04:22 visual_prompt]: 	Test 100/190. loss: 4.344, 0.2164 s / batch. (data: 2.53e-05)max mem: 7.81213 GB 
[09/28 13:04:42 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2164, average loss: 5.8953
[09/28 13:04:42 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.40	top5: 95.70	
[09/28 13:04:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/28 13:04:52 visual_prompt]: Epoch 100 / 100: avg data time: 7.89e-02, avg batch time: 0.5333, average train loss: 0.0024
[09/28 13:04:54 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1684, average loss: 0.0207
[09/28 13:04:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 99.50	top5: 100.00	
[09/28 13:05:17 visual_prompt]: 	Test 100/190. loss: 4.344, 0.2161 s / batch. (data: 2.62e-05)max mem: 7.81213 GB 
[09/28 13:05:38 visual_prompt]: Inference (test):avg data time: 6.08e-05, avg batch time: 0.2164, average loss: 5.8955
[09/28 13:05:38 visual_prompt]: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 36.41	top5: 95.70	
