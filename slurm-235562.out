[09/16 07:15:59 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 07:15:59 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 07:15:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-patch_camelyon', 'DATA.NUMBER_CLASSES', '2', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/16 07:15:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 07:15:59 visual_prompt]: Training with config:
[09/16 07:15:59 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-patch_camelyon',
          'NO_TEST': False,
          'NUMBER_CLASSES': 2,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-patch_camelyon/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 07:15:59 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 07:15:59.997847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 07:16:00.187022: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 07:16:01.177383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 07:16:01.177456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 07:16:01.177465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 07:16:03.487640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 07:16:03.487748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 07:16:03.487762: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 07:16:03 visual_prompt]: Constructing vtab-patch_camelyon dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
2023-09-16 07:16:04.093489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 07:16:06 visual_prompt]: Number of images: 1000
[09/16 07:16:06 visual_prompt]: Number of classes: 2 / 2
[09/16 07:16:06 visual_prompt]: Loading validation data...
[09/16 07:16:06 visual_prompt]: Constructing vtab-patch_camelyon dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 07:16:06 visual_prompt]: Number of images: 200
[09/16 07:16:06 visual_prompt]: Number of classes: 2 / 2
[09/16 07:16:06 visual_prompt]: Loading test data...
[09/16 07:16:06 visual_prompt]: Constructing vtab-patch_camelyon dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split test, from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 07:16:56 visual_prompt]: Number of images: 32768
[09/16 07:16:56 visual_prompt]: Number of classes: 2 / 2
[09/16 07:16:56 visual_prompt]: Constructing models...
[09/16 07:16:59 visual_prompt]: Total Parameters: 86721794	 Gradient Parameters: 923138
[09/16 07:16:59 visual_prompt]: tuned percent:1.064
[09/16 07:17:02 visual_prompt]: Device used for model: 0
[09/16 07:17:02 visual_prompt]: Setting up Evalutator...
[09/16 07:17:02 visual_prompt]: Setting up Trainer...
[09/16 07:17:02 visual_prompt]: 	Setting up the optimizer...
[09/16 07:17:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 07:17:15 visual_prompt]: Epoch 1 / 100: avg data time: 1.85e-01, avg batch time: 0.6967, average train loss: 1.2527
[09/16 07:17:21 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1426, average loss: 1.2307
[09/16 07:17:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 23.51	
[09/16 07:17:44 visual_prompt]: 	Test 100/512. loss: 1.205, 0.1889 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 07:18:03 visual_prompt]: 	Test 200/512. loss: 1.168, 0.1836 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 07:18:23 visual_prompt]: 	Test 300/512. loss: 1.200, 0.1840 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 07:18:43 visual_prompt]: 	Test 400/512. loss: 1.055, 0.1982 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 07:19:03 visual_prompt]: 	Test 500/512. loss: 1.134, 0.2050 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 07:19:08 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1972, average loss: 1.1256
[09/16 07:19:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.78	rocauc: 33.00	
[09/16 07:19:08 visual_prompt]: Best epoch 1: best metric: 0.520
[09/16 07:19:08 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 07:19:19 visual_prompt]: Epoch 2 / 100: avg data time: 1.93e-01, avg batch time: 0.5954, average train loss: 5.0242
[09/16 07:19:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1431, average loss: 0.8953
[09/16 07:19:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 58.47	
[09/16 07:19:47 visual_prompt]: 	Test 100/512. loss: 0.953, 0.1840 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 07:20:07 visual_prompt]: 	Test 200/512. loss: 0.934, 0.1985 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 07:20:27 visual_prompt]: 	Test 300/512. loss: 1.008, 0.2036 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 07:20:47 visual_prompt]: 	Test 400/512. loss: 0.876, 0.2056 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 07:21:06 visual_prompt]: 	Test 500/512. loss: 0.892, 0.1837 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 07:21:11 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1964, average loss: 0.9210
[09/16 07:21:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 57.79	
[09/16 07:21:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 07:21:23 visual_prompt]: Epoch 3 / 100: avg data time: 1.79e-01, avg batch time: 0.5843, average train loss: 0.8352
[09/16 07:21:28 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1432, average loss: 0.6260
[09/16 07:21:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 87.49	
[09/16 07:21:50 visual_prompt]: 	Test 100/512. loss: 0.658, 0.1835 s / batch. (data: 1.71e-04)max mem: 17.22442 GB 
[09/16 07:22:10 visual_prompt]: 	Test 200/512. loss: 0.649, 0.1994 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 07:22:30 visual_prompt]: 	Test 300/512. loss: 0.671, 0.2524 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 07:22:50 visual_prompt]: 	Test 400/512. loss: 0.643, 0.2080 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 07:23:10 visual_prompt]: 	Test 500/512. loss: 0.621, 0.1888 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 07:23:15 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1972, average loss: 0.6534
[09/16 07:23:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.17	rocauc: 80.91	
[09/16 07:23:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 07:23:27 visual_prompt]: Epoch 4 / 100: avg data time: 1.82e-01, avg batch time: 0.5874, average train loss: 0.7512
[09/16 07:23:32 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1436, average loss: 0.4844
[09/16 07:23:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 88.32	
[09/16 07:23:55 visual_prompt]: 	Test 100/512. loss: 0.506, 0.1970 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 07:24:15 visual_prompt]: 	Test 200/512. loss: 0.518, 0.1856 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:24:35 visual_prompt]: 	Test 300/512. loss: 0.457, 0.2240 s / batch. (data: 2.72e-02)max mem: 17.22442 GB 
[09/16 07:24:54 visual_prompt]: 	Test 400/512. loss: 0.570, 0.1916 s / batch. (data: 7.24e-03)max mem: 17.22442 GB 
[09/16 07:25:14 visual_prompt]: 	Test 500/512. loss: 0.472, 0.1852 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 07:25:19 visual_prompt]: Inference (test):avg data time: 8.57e-03, avg batch time: 0.1969, average loss: 0.5251
[09/16 07:25:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.50	rocauc: 84.25	
[09/16 07:25:19 visual_prompt]: Best epoch 4: best metric: 0.740
[09/16 07:25:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 07:25:31 visual_prompt]: Epoch 5 / 100: avg data time: 1.98e-01, avg batch time: 0.6005, average train loss: 0.7944
[09/16 07:25:36 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1435, average loss: 0.4767
[09/16 07:25:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.00	rocauc: 89.59	
[09/16 07:25:59 visual_prompt]: 	Test 100/512. loss: 0.651, 0.1978 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 07:26:19 visual_prompt]: 	Test 200/512. loss: 0.624, 0.1982 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 07:26:39 visual_prompt]: 	Test 300/512. loss: 0.618, 0.1954 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 07:26:59 visual_prompt]: 	Test 400/512. loss: 0.665, 0.1958 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 07:27:18 visual_prompt]: 	Test 500/512. loss: 0.523, 0.1849 s / batch. (data: 9.80e-05)max mem: 17.22442 GB 
[09/16 07:27:24 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1976, average loss: 0.6208
[09/16 07:27:24 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 67.75	rocauc: 84.45	
[09/16 07:27:24 visual_prompt]: Best epoch 5: best metric: 0.820
[09/16 07:27:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 07:27:35 visual_prompt]: Epoch 6 / 100: avg data time: 1.70e-01, avg batch time: 0.5761, average train loss: 0.8684
[09/16 07:27:40 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1434, average loss: 0.5349
[09/16 07:27:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 91.32	
[09/16 07:28:03 visual_prompt]: 	Test 100/512. loss: 0.584, 0.1839 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:28:22 visual_prompt]: 	Test 200/512. loss: 0.668, 0.1958 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 07:28:42 visual_prompt]: 	Test 300/512. loss: 0.424, 0.1998 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 07:29:02 visual_prompt]: 	Test 400/512. loss: 0.731, 0.1839 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:29:22 visual_prompt]: 	Test 500/512. loss: 0.532, 0.1987 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 07:29:27 visual_prompt]: Inference (test):avg data time: 7.05e-03, avg batch time: 0.1961, average loss: 0.6114
[09/16 07:29:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.53	rocauc: 85.06	
[09/16 07:29:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 07:29:38 visual_prompt]: Epoch 7 / 100: avg data time: 1.70e-01, avg batch time: 0.5760, average train loss: 0.9705
[09/16 07:29:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1433, average loss: 0.5449
[09/16 07:29:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.50	rocauc: 91.52	
[09/16 07:30:07 visual_prompt]: 	Test 100/512. loss: 0.942, 0.1832 s / batch. (data: 2.67e-05)max mem: 17.22442 GB 
[09/16 07:30:26 visual_prompt]: 	Test 200/512. loss: 0.860, 0.1994 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 07:30:46 visual_prompt]: 	Test 300/512. loss: 0.836, 0.1842 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 07:31:06 visual_prompt]: 	Test 400/512. loss: 0.865, 0.1943 s / batch. (data: 1.05e-02)max mem: 17.22442 GB 
[09/16 07:31:26 visual_prompt]: 	Test 500/512. loss: 0.689, 0.2039 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:31:31 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1972, average loss: 0.8435
[09/16 07:31:31 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 67.92	rocauc: 84.26	
[09/16 07:31:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 07:31:42 visual_prompt]: Epoch 8 / 100: avg data time: 1.81e-01, avg batch time: 0.5863, average train loss: 2.1935
[09/16 07:31:48 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1435, average loss: 9.6077
[09/16 07:31:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 91.88	
[09/16 07:32:10 visual_prompt]: 	Test 100/512. loss: 8.898, 0.1981 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 07:32:29 visual_prompt]: 	Test 200/512. loss: 9.011, 0.2078 s / batch. (data: 1.18e-02)max mem: 17.22442 GB 
[09/16 07:32:49 visual_prompt]: 	Test 300/512. loss: 8.031, 0.1849 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 07:33:09 visual_prompt]: 	Test 400/512. loss: 9.861, 0.2008 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 07:33:29 visual_prompt]: 	Test 500/512. loss: 9.502, 0.1974 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 07:33:34 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1952, average loss: 9.2698
[09/16 07:33:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 86.74	
[09/16 07:33:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 07:33:45 visual_prompt]: Epoch 9 / 100: avg data time: 1.85e-01, avg batch time: 0.5913, average train loss: 11.3194
[09/16 07:33:50 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1435, average loss: 11.2334
[09/16 07:33:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 72.38	
[09/16 07:34:13 visual_prompt]: 	Test 100/512. loss: 10.436, 0.1987 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 07:34:32 visual_prompt]: 	Test 200/512. loss: 10.461, 0.2013 s / batch. (data: 1.80e-02)max mem: 17.22442 GB 
[09/16 07:34:52 visual_prompt]: 	Test 300/512. loss: 9.420, 0.1987 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 07:35:12 visual_prompt]: 	Test 400/512. loss: 11.443, 0.1953 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 07:35:31 visual_prompt]: 	Test 500/512. loss: 11.125, 0.1846 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:35:36 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1952, average loss: 10.8026
[09/16 07:35:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 71.69	
[09/16 07:35:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 07:35:48 visual_prompt]: Epoch 10 / 100: avg data time: 1.74e-01, avg batch time: 0.5800, average train loss: 11.1837
[09/16 07:35:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1435, average loss: 17.5423
[09/16 07:35:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 44.51	
[09/16 07:36:16 visual_prompt]: 	Test 100/512. loss: 16.340, 0.1840 s / batch. (data: 9.25e-05)max mem: 17.22442 GB 
[09/16 07:36:35 visual_prompt]: 	Test 200/512. loss: 16.327, 0.1934 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 07:36:55 visual_prompt]: 	Test 300/512. loss: 14.747, 0.2080 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 07:37:15 visual_prompt]: 	Test 400/512. loss: 17.905, 0.1853 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:37:34 visual_prompt]: 	Test 500/512. loss: 17.387, 0.1999 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 07:37:39 visual_prompt]: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1954, average loss: 16.8687
[09/16 07:37:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 46.03	
[09/16 07:37:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 07:37:51 visual_prompt]: Epoch 11 / 100: avg data time: 1.80e-01, avg batch time: 0.5814, average train loss: 9.2019
[09/16 07:37:56 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1434, average loss: 3.5405
[09/16 07:37:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 87.75	
[09/16 07:38:18 visual_prompt]: 	Test 100/512. loss: 3.285, 0.1848 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 07:38:38 visual_prompt]: 	Test 200/512. loss: 3.312, 0.1852 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 07:38:57 visual_prompt]: 	Test 300/512. loss: 2.970, 0.1848 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 07:39:17 visual_prompt]: 	Test 400/512. loss: 3.624, 0.2003 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 07:39:37 visual_prompt]: 	Test 500/512. loss: 3.513, 0.1923 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 07:39:42 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1950, average loss: 3.4112
[09/16 07:39:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 80.64	
[09/16 07:39:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 07:39:53 visual_prompt]: Epoch 12 / 100: avg data time: 1.73e-01, avg batch time: 0.5788, average train loss: 5.9288
[09/16 07:39:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1436, average loss: 14.5742
[09/16 07:39:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 82.57	
[09/16 07:40:21 visual_prompt]: 	Test 100/512. loss: 13.564, 0.1977 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 07:40:40 visual_prompt]: 	Test 200/512. loss: 13.583, 0.1848 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 07:41:00 visual_prompt]: 	Test 300/512. loss: 12.249, 0.1917 s / batch. (data: 1.07e-04)max mem: 17.22442 GB 
[09/16 07:41:20 visual_prompt]: 	Test 400/512. loss: 14.891, 0.1984 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 07:41:39 visual_prompt]: 	Test 500/512. loss: 14.451, 0.2114 s / batch. (data: 2.76e-02)max mem: 17.22442 GB 
[09/16 07:41:44 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1947, average loss: 14.0228
[09/16 07:41:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 78.16	
[09/16 07:41:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 07:41:55 visual_prompt]: Epoch 13 / 100: avg data time: 1.83e-01, avg batch time: 0.5898, average train loss: 4.7795
[09/16 07:42:00 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1459, average loss: 1.1548
[09/16 07:42:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 82.55	
[09/16 07:42:23 visual_prompt]: 	Test 100/512. loss: 1.248, 0.1961 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 07:42:42 visual_prompt]: 	Test 200/512. loss: 1.252, 0.1848 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 07:43:02 visual_prompt]: 	Test 300/512. loss: 1.384, 0.1847 s / batch. (data: 1.69e-04)max mem: 17.22442 GB 
[09/16 07:43:21 visual_prompt]: 	Test 400/512. loss: 1.174, 0.1849 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 07:43:41 visual_prompt]: 	Test 500/512. loss: 1.201, 0.1965 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 07:43:46 visual_prompt]: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1947, average loss: 1.2287
[09/16 07:43:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 75.64	
[09/16 07:43:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 07:43:58 visual_prompt]: Epoch 14 / 100: avg data time: 1.85e-01, avg batch time: 0.5873, average train loss: 9.9933
[09/16 07:44:03 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1434, average loss: 3.4336
[09/16 07:44:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 44.55	
[09/16 07:44:25 visual_prompt]: 	Test 100/512. loss: 3.693, 0.2036 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 07:44:45 visual_prompt]: 	Test 200/512. loss: 3.710, 0.2334 s / batch. (data: 5.04e-02)max mem: 17.22442 GB 
[09/16 07:45:05 visual_prompt]: 	Test 300/512. loss: 4.021, 0.1856 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 07:45:24 visual_prompt]: 	Test 400/512. loss: 3.360, 0.1849 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 07:45:44 visual_prompt]: 	Test 500/512. loss: 3.477, 0.1936 s / batch. (data: 1.03e-02)max mem: 17.22442 GB 
[09/16 07:45:49 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1950, average loss: 3.5835
[09/16 07:45:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 43.35	
[09/16 07:45:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 07:46:00 visual_prompt]: Epoch 15 / 100: avg data time: 1.88e-01, avg batch time: 0.5935, average train loss: 11.3459
[09/16 07:46:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1435, average loss: 9.2096
[09/16 07:46:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 26.85	
[09/16 07:46:28 visual_prompt]: 	Test 100/512. loss: 9.927, 0.2184 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 07:46:48 visual_prompt]: 	Test 200/512. loss: 9.900, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 07:47:07 visual_prompt]: 	Test 300/512. loss: 10.817, 0.1843 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 07:47:27 visual_prompt]: 	Test 400/512. loss: 9.013, 0.1987 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 07:47:47 visual_prompt]: 	Test 500/512. loss: 9.316, 0.1843 s / batch. (data: 8.85e-05)max mem: 17.22442 GB 
[09/16 07:47:52 visual_prompt]: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1954, average loss: 9.6087
[09/16 07:47:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 25.98	
[09/16 07:47:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 07:48:03 visual_prompt]: Epoch 16 / 100: avg data time: 1.81e-01, avg batch time: 0.5895, average train loss: 8.1922
[09/16 07:48:09 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1438, average loss: 0.6228
[09/16 07:48:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 44.50	rocauc: 59.74	
[09/16 07:48:31 visual_prompt]: 	Test 100/512. loss: 0.672, 0.1893 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 07:48:51 visual_prompt]: 	Test 200/512. loss: 0.693, 0.1921 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 07:49:10 visual_prompt]: 	Test 300/512. loss: 0.690, 0.1848 s / batch. (data: 1.65e-04)max mem: 17.22442 GB 
[09/16 07:49:30 visual_prompt]: 	Test 400/512. loss: 0.667, 0.1849 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 07:49:49 visual_prompt]: 	Test 500/512. loss: 0.652, 0.2216 s / batch. (data: 3.78e-02)max mem: 17.22442 GB 
[09/16 07:49:54 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1944, average loss: 0.6763
[09/16 07:49:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 46.36	rocauc: 57.27	
[09/16 07:49:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 07:50:06 visual_prompt]: Epoch 17 / 100: avg data time: 1.89e-01, avg batch time: 0.5915, average train loss: 5.7130
[09/16 07:50:11 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1435, average loss: 7.1103
[09/16 07:50:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 73.44	
[09/16 07:50:33 visual_prompt]: 	Test 100/512. loss: 6.535, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 07:50:53 visual_prompt]: 	Test 200/512. loss: 6.701, 0.1992 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 07:51:12 visual_prompt]: 	Test 300/512. loss: 5.845, 0.1995 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 07:51:32 visual_prompt]: 	Test 400/512. loss: 7.156, 0.1934 s / batch. (data: 9.60e-03)max mem: 17.22442 GB 
[09/16 07:51:51 visual_prompt]: 	Test 500/512. loss: 7.012, 0.1975 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 07:51:56 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1944, average loss: 6.8188
[09/16 07:51:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 62.93	
[09/16 07:51:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 07:52:08 visual_prompt]: Epoch 18 / 100: avg data time: 1.88e-01, avg batch time: 0.5920, average train loss: 8.8787
[09/16 07:52:13 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1436, average loss: 2.2277
[09/16 07:52:13 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 71.16	
[09/16 07:52:36 visual_prompt]: 	Test 100/512. loss: 3.100, 0.2054 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 07:52:55 visual_prompt]: 	Test 200/512. loss: 2.936, 0.1850 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 07:53:15 visual_prompt]: 	Test 300/512. loss: 3.520, 0.1842 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 07:53:35 visual_prompt]: 	Test 400/512. loss: 3.131, 0.2028 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 07:53:54 visual_prompt]: 	Test 500/512. loss: 2.820, 0.2050 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 07:53:59 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1954, average loss: 3.0281
[09/16 07:53:59 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 60.74	
[09/16 07:53:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 07:54:10 visual_prompt]: Epoch 19 / 100: avg data time: 1.70e-01, avg batch time: 0.5744, average train loss: 2.5265
[09/16 07:54:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1435, average loss: 1.2217
[09/16 07:54:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 63.00	rocauc: 80.03	
[09/16 07:54:39 visual_prompt]: 	Test 100/512. loss: 1.218, 0.1847 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 07:54:58 visual_prompt]: 	Test 200/512. loss: 1.257, 0.1950 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 07:55:18 visual_prompt]: 	Test 300/512. loss: 1.008, 0.1995 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 07:55:38 visual_prompt]: 	Test 400/512. loss: 1.219, 0.1848 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 07:55:57 visual_prompt]: 	Test 500/512. loss: 1.179, 0.1847 s / batch. (data: 1.01e-04)max mem: 17.22442 GB 
[09/16 07:56:02 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1954, average loss: 1.2347
[09/16 07:56:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.85	rocauc: 69.07	
[09/16 07:56:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 07:56:14 visual_prompt]: Epoch 20 / 100: avg data time: 1.91e-01, avg batch time: 0.5943, average train loss: 4.7405
[09/16 07:56:19 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1433, average loss: 10.5686
[09/16 07:56:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 74.11	
[09/16 07:56:41 visual_prompt]: 	Test 100/512. loss: 11.566, 0.1839 s / batch. (data: 1.05e-04)max mem: 17.22442 GB 
[09/16 07:57:01 visual_prompt]: 	Test 200/512. loss: 11.524, 0.1870 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 07:57:21 visual_prompt]: 	Test 300/512. loss: 12.701, 0.1838 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 07:57:40 visual_prompt]: 	Test 400/512. loss: 10.652, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 07:58:00 visual_prompt]: 	Test 500/512. loss: 10.908, 0.1847 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 07:58:05 visual_prompt]: Inference (test):avg data time: 8.61e-03, avg batch time: 0.1949, average loss: 11.2256
[09/16 07:58:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 64.95	
[09/16 07:58:05 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 07:58:16 visual_prompt]: Epoch 21 / 100: avg data time: 1.77e-01, avg batch time: 0.5840, average train loss: 8.4824
[09/16 07:58:21 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1436, average loss: 8.0262
[09/16 07:58:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 83.95	
[09/16 07:58:44 visual_prompt]: 	Test 100/512. loss: 7.412, 0.1840 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 07:59:03 visual_prompt]: 	Test 200/512. loss: 7.677, 0.1983 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 07:59:23 visual_prompt]: 	Test 300/512. loss: 6.593, 0.2041 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 07:59:42 visual_prompt]: 	Test 400/512. loss: 8.029, 0.1983 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 08:00:02 visual_prompt]: 	Test 500/512. loss: 7.920, 0.1981 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 08:00:07 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1955, average loss: 7.7471
[09/16 08:00:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 72.88	
[09/16 08:00:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 08:00:18 visual_prompt]: Epoch 22 / 100: avg data time: 1.88e-01, avg batch time: 0.5954, average train loss: 5.9648
[09/16 08:00:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1434, average loss: 2.4630
[09/16 08:00:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 60.50	rocauc: 83.58	
[09/16 08:00:46 visual_prompt]: 	Test 100/512. loss: 2.252, 0.2080 s / batch. (data: 2.53e-02)max mem: 17.22442 GB 
[09/16 08:01:06 visual_prompt]: 	Test 200/512. loss: 2.477, 0.1831 s / batch. (data: 2.98e-05)max mem: 17.22442 GB 
[09/16 08:01:26 visual_prompt]: 	Test 300/512. loss: 1.843, 0.1846 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 08:01:45 visual_prompt]: 	Test 400/512. loss: 2.258, 0.2107 s / batch. (data: 2.72e-02)max mem: 17.22442 GB 
[09/16 08:02:05 visual_prompt]: 	Test 500/512. loss: 2.323, 0.1846 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 08:02:10 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1949, average loss: 2.3782
[09/16 08:02:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.59	rocauc: 71.42	
[09/16 08:02:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 08:02:21 visual_prompt]: Epoch 23 / 100: avg data time: 1.87e-01, avg batch time: 0.5907, average train loss: 4.5166
[09/16 08:02:26 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1436, average loss: 12.0777
[09/16 08:02:26 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 84.87	
[09/16 08:02:49 visual_prompt]: 	Test 100/512. loss: 13.334, 0.1843 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 08:03:09 visual_prompt]: 	Test 200/512. loss: 13.446, 0.1985 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 08:03:28 visual_prompt]: 	Test 300/512. loss: 14.855, 0.1949 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 08:03:48 visual_prompt]: 	Test 400/512. loss: 12.414, 0.1868 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 08:04:07 visual_prompt]: 	Test 500/512. loss: 12.668, 0.1890 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 08:04:12 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1948, average loss: 13.0672
[09/16 08:04:12 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 72.73	
[09/16 08:04:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 08:04:24 visual_prompt]: Epoch 24 / 100: avg data time: 1.90e-01, avg batch time: 0.5955, average train loss: 10.9061
[09/16 08:04:29 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1438, average loss: 0.6639
[09/16 08:04:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 69.00	rocauc: 83.93	
[09/16 08:04:51 visual_prompt]: 	Test 100/512. loss: 1.053, 0.2017 s / batch. (data: 3.86e-05)max mem: 17.22442 GB 
[09/16 08:05:11 visual_prompt]: 	Test 200/512. loss: 1.166, 0.1966 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 08:05:31 visual_prompt]: 	Test 300/512. loss: 1.290, 0.2021 s / batch. (data: 1.88e-02)max mem: 17.22442 GB 
[09/16 08:05:50 visual_prompt]: 	Test 400/512. loss: 1.206, 0.1842 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 08:06:10 visual_prompt]: 	Test 500/512. loss: 1.103, 0.2079 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 08:06:15 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1952, average loss: 1.1478
[09/16 08:06:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.91	rocauc: 71.44	
[09/16 08:06:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 08:06:27 visual_prompt]: Epoch 25 / 100: avg data time: 1.89e-01, avg batch time: 0.5920, average train loss: 2.0852
[09/16 08:06:32 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1468, average loss: 6.1008
[09/16 08:06:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 84.58	
[09/16 08:06:54 visual_prompt]: 	Test 100/512. loss: 5.631, 0.1959 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 08:07:14 visual_prompt]: 	Test 200/512. loss: 5.728, 0.1955 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 08:07:33 visual_prompt]: 	Test 300/512. loss: 5.066, 0.2422 s / batch. (data: 5.44e-02)max mem: 17.22442 GB 
[09/16 08:07:53 visual_prompt]: 	Test 400/512. loss: 6.157, 0.1844 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 08:08:12 visual_prompt]: 	Test 500/512. loss: 6.020, 0.1844 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 08:08:17 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1943, average loss: 5.8638
[09/16 08:08:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 73.74	
[09/16 08:08:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 08:08:29 visual_prompt]: Epoch 26 / 100: avg data time: 1.89e-01, avg batch time: 0.5910, average train loss: 3.6719
[09/16 08:08:34 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1435, average loss: 5.1737
[09/16 08:08:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 86.23	
[09/16 08:08:56 visual_prompt]: 	Test 100/512. loss: 4.776, 0.1833 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 08:09:16 visual_prompt]: 	Test 200/512. loss: 4.861, 0.2069 s / batch. (data: 2.40e-02)max mem: 17.22442 GB 
[09/16 08:09:35 visual_prompt]: 	Test 300/512. loss: 4.314, 0.1844 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 08:09:55 visual_prompt]: 	Test 400/512. loss: 5.228, 0.1844 s / batch. (data: 3.77e-05)max mem: 17.22442 GB 
[09/16 08:10:14 visual_prompt]: 	Test 500/512. loss: 5.103, 0.1841 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 08:10:19 visual_prompt]: Inference (test):avg data time: 6.91e-03, avg batch time: 0.1937, average loss: 4.9703
[09/16 08:10:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 72.98	
[09/16 08:10:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 08:10:31 visual_prompt]: Epoch 27 / 100: avg data time: 1.92e-01, avg batch time: 0.5952, average train loss: 4.9055
[09/16 08:10:36 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1436, average loss: 0.7876
[09/16 08:10:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 65.00	rocauc: 87.58	
[09/16 08:10:59 visual_prompt]: 	Test 100/512. loss: 0.810, 0.1842 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 08:11:18 visual_prompt]: 	Test 200/512. loss: 0.915, 0.1977 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 08:11:38 visual_prompt]: 	Test 300/512. loss: 0.675, 0.1945 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 08:11:57 visual_prompt]: 	Test 400/512. loss: 0.882, 0.1993 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 08:12:17 visual_prompt]: 	Test 500/512. loss: 0.777, 0.1995 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 08:12:22 visual_prompt]: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1942, average loss: 0.8402
[09/16 08:12:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.00	rocauc: 77.80	
[09/16 08:12:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 08:12:33 visual_prompt]: Epoch 28 / 100: avg data time: 1.72e-01, avg batch time: 0.5802, average train loss: 2.9342
[09/16 08:12:38 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1437, average loss: 5.3524
[09/16 08:12:38 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 88.30	
[09/16 08:13:01 visual_prompt]: 	Test 100/512. loss: 4.820, 0.1884 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 08:13:20 visual_prompt]: 	Test 200/512. loss: 5.271, 0.1842 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 08:13:40 visual_prompt]: 	Test 300/512. loss: 4.289, 0.2059 s / batch. (data: 2.21e-02)max mem: 17.22442 GB 
[09/16 08:13:59 visual_prompt]: 	Test 400/512. loss: 5.384, 0.2081 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 08:14:19 visual_prompt]: 	Test 500/512. loss: 5.147, 0.1992 s / batch. (data: 1.02e-02)max mem: 17.22442 GB 
[09/16 08:14:24 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1946, average loss: 5.1707
[09/16 08:14:24 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 79.61	
[09/16 08:14:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 08:14:35 visual_prompt]: Epoch 29 / 100: avg data time: 1.83e-01, avg batch time: 0.5876, average train loss: 2.2177
[09/16 08:14:41 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1432, average loss: 0.4311
[09/16 08:14:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.00	rocauc: 88.49	
[09/16 08:15:04 visual_prompt]: 	Test 100/512. loss: 0.634, 0.1960 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 08:15:23 visual_prompt]: 	Test 200/512. loss: 0.693, 0.1846 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 08:15:43 visual_prompt]: 	Test 300/512. loss: 0.652, 0.1845 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 08:16:02 visual_prompt]: 	Test 400/512. loss: 0.768, 0.1848 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 08:16:22 visual_prompt]: 	Test 500/512. loss: 0.571, 0.2028 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 08:16:27 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1954, average loss: 0.6355
[09/16 08:16:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.60	rocauc: 80.79	
[09/16 08:16:27 visual_prompt]: Best epoch 29: best metric: 0.840
[09/16 08:16:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 08:16:38 visual_prompt]: Epoch 30 / 100: avg data time: 1.86e-01, avg batch time: 0.5888, average train loss: 0.8436
[09/16 08:16:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1435, average loss: 1.6928
[09/16 08:16:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 87.56	
[09/16 08:17:06 visual_prompt]: 	Test 100/512. loss: 1.971, 0.2013 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 08:17:25 visual_prompt]: 	Test 200/512. loss: 2.215, 0.1846 s / batch. (data: 9.82e-05)max mem: 17.22442 GB 
[09/16 08:17:45 visual_prompt]: 	Test 300/512. loss: 2.242, 0.1958 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 08:18:05 visual_prompt]: 	Test 400/512. loss: 1.946, 0.1854 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 08:18:24 visual_prompt]: 	Test 500/512. loss: 1.902, 0.1868 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 08:18:29 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1942, average loss: 2.0254
[09/16 08:18:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.96	rocauc: 80.94	
[09/16 08:18:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 08:18:41 visual_prompt]: Epoch 31 / 100: avg data time: 1.94e-01, avg batch time: 0.5968, average train loss: 1.0640
[09/16 08:18:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1436, average loss: 0.5714
[09/16 08:18:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 90.78	
[09/16 08:19:08 visual_prompt]: 	Test 100/512. loss: 0.763, 0.1963 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 08:19:28 visual_prompt]: 	Test 200/512. loss: 0.910, 0.2338 s / batch. (data: 5.01e-02)max mem: 17.22442 GB 
[09/16 08:19:47 visual_prompt]: 	Test 300/512. loss: 0.849, 0.1994 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 08:20:07 visual_prompt]: 	Test 400/512. loss: 0.870, 0.1843 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 08:20:27 visual_prompt]: 	Test 500/512. loss: 0.734, 0.1990 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 08:20:32 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1949, average loss: 0.8070
[09/16 08:20:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.38	rocauc: 83.79	
[09/16 08:20:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 08:20:43 visual_prompt]: Epoch 32 / 100: avg data time: 1.81e-01, avg batch time: 0.5871, average train loss: 1.2726
[09/16 08:20:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1435, average loss: 1.7412
[09/16 08:20:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 90.61	
[09/16 08:21:11 visual_prompt]: 	Test 100/512. loss: 2.092, 0.2194 s / batch. (data: 3.24e-02)max mem: 17.22442 GB 
[09/16 08:21:31 visual_prompt]: 	Test 200/512. loss: 2.283, 0.1933 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 08:21:51 visual_prompt]: 	Test 300/512. loss: 2.380, 0.1843 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 08:22:10 visual_prompt]: 	Test 400/512. loss: 2.057, 0.1849 s / batch. (data: 1.70e-04)max mem: 17.22442 GB 
[09/16 08:22:30 visual_prompt]: 	Test 500/512. loss: 2.012, 0.1841 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 08:22:35 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1954, average loss: 2.1423
[09/16 08:22:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 83.21	
[09/16 08:22:35 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 08:22:47 visual_prompt]: Epoch 33 / 100: avg data time: 1.80e-01, avg batch time: 0.5891, average train loss: 1.2971
[09/16 08:22:53 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1435, average loss: 2.2690
[09/16 08:22:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 54.00	rocauc: 91.43	
[09/16 08:23:15 visual_prompt]: 	Test 100/512. loss: 2.078, 0.1852 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 08:23:35 visual_prompt]: 	Test 200/512. loss: 2.545, 0.1868 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 08:23:55 visual_prompt]: 	Test 300/512. loss: 1.762, 0.1997 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:24:14 visual_prompt]: 	Test 400/512. loss: 2.570, 0.1984 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 08:24:34 visual_prompt]: 	Test 500/512. loss: 2.169, 0.2117 s / batch. (data: 2.82e-02)max mem: 17.22442 GB 
[09/16 08:24:39 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1960, average loss: 2.3205
[09/16 08:24:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 54.93	rocauc: 84.35	
[09/16 08:24:39 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 08:24:51 visual_prompt]: Epoch 34 / 100: avg data time: 1.90e-01, avg batch time: 0.5960, average train loss: 1.5767
[09/16 08:24:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1434, average loss: 2.0474
[09/16 08:24:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 58.00	rocauc: 92.28	
[09/16 08:25:19 visual_prompt]: 	Test 100/512. loss: 1.802, 0.2190 s / batch. (data: 3.63e-02)max mem: 17.22442 GB 
[09/16 08:25:39 visual_prompt]: 	Test 200/512. loss: 2.389, 0.2160 s / batch. (data: 1.94e-02)max mem: 17.22442 GB 
[09/16 08:25:59 visual_prompt]: 	Test 300/512. loss: 1.623, 0.1837 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 08:26:19 visual_prompt]: 	Test 400/512. loss: 2.425, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 08:26:39 visual_prompt]: 	Test 500/512. loss: 1.919, 0.1875 s / batch. (data: 9.68e-05)max mem: 17.22442 GB 
[09/16 08:26:44 visual_prompt]: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1979, average loss: 2.1593
[09/16 08:26:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.67	rocauc: 84.68	
[09/16 08:26:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 08:26:55 visual_prompt]: Epoch 35 / 100: avg data time: 1.92e-01, avg batch time: 0.5954, average train loss: 1.3213
[09/16 08:27:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1435, average loss: 0.3836
[09/16 08:27:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.00	rocauc: 92.15	
[09/16 08:27:24 visual_prompt]: 	Test 100/512. loss: 0.498, 0.1837 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 08:27:43 visual_prompt]: 	Test 200/512. loss: 0.635, 0.1962 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 08:28:03 visual_prompt]: 	Test 300/512. loss: 0.420, 0.1919 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 08:28:23 visual_prompt]: 	Test 400/512. loss: 0.662, 0.1842 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 08:28:42 visual_prompt]: 	Test 500/512. loss: 0.450, 0.1842 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 08:28:47 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1960, average loss: 0.5263
[09/16 08:28:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.67	rocauc: 84.64	
[09/16 08:28:47 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 08:28:59 visual_prompt]: Epoch 36 / 100: avg data time: 1.90e-01, avg batch time: 0.5958, average train loss: 0.7515
[09/16 08:29:05 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1437, average loss: 0.6902
[09/16 08:29:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 63.00	rocauc: 91.97	
[09/16 08:29:28 visual_prompt]: 	Test 100/512. loss: 1.005, 0.2371 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 08:29:47 visual_prompt]: 	Test 200/512. loss: 1.062, 0.1861 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 08:30:07 visual_prompt]: 	Test 300/512. loss: 1.051, 0.1849 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 08:30:26 visual_prompt]: 	Test 400/512. loss: 0.989, 0.1848 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 08:30:47 visual_prompt]: 	Test 500/512. loss: 0.944, 0.1997 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 08:30:52 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1969, average loss: 0.9937
[09/16 08:30:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 54.80	rocauc: 83.94	
[09/16 08:30:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 08:31:04 visual_prompt]: Epoch 37 / 100: avg data time: 1.92e-01, avg batch time: 0.5977, average train loss: 0.6688
[09/16 08:31:09 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1434, average loss: 0.7057
[09/16 08:31:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 59.50	rocauc: 93.03	
[09/16 08:31:32 visual_prompt]: 	Test 100/512. loss: 0.672, 0.1958 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 08:31:52 visual_prompt]: 	Test 200/512. loss: 0.824, 0.2000 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 08:32:11 visual_prompt]: 	Test 300/512. loss: 0.608, 0.1840 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 08:32:31 visual_prompt]: 	Test 400/512. loss: 0.826, 0.1845 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 08:32:51 visual_prompt]: 	Test 500/512. loss: 0.711, 0.1846 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 08:32:56 visual_prompt]: Inference (test):avg data time: 9.03e-03, avg batch time: 0.1963, average loss: 0.7506
[09/16 08:32:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.10	rocauc: 84.97	
[09/16 08:32:56 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 08:33:08 visual_prompt]: Epoch 38 / 100: avg data time: 1.90e-01, avg batch time: 0.5978, average train loss: 0.5293
[09/16 08:33:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1434, average loss: 0.3841
[09/16 08:33:13 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.50	rocauc: 92.61	
[09/16 08:33:36 visual_prompt]: 	Test 100/512. loss: 0.565, 0.1940 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 08:33:56 visual_prompt]: 	Test 200/512. loss: 0.593, 0.2096 s / batch. (data: 2.44e-02)max mem: 17.22442 GB 
[09/16 08:34:15 visual_prompt]: 	Test 300/512. loss: 0.473, 0.1848 s / batch. (data: 1.67e-04)max mem: 17.22442 GB 
[09/16 08:34:35 visual_prompt]: 	Test 400/512. loss: 0.541, 0.2147 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 08:34:55 visual_prompt]: 	Test 500/512. loss: 0.459, 0.2000 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 08:34:59 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1957, average loss: 0.5311
[09/16 08:35:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.73	rocauc: 81.40	
[09/16 08:35:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 08:35:11 visual_prompt]: Epoch 39 / 100: avg data time: 2.03e-01, avg batch time: 0.6070, average train loss: 0.6749
[09/16 08:35:17 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1434, average loss: 1.2576
[09/16 08:35:17 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 92.53	
[09/16 08:35:39 visual_prompt]: 	Test 100/512. loss: 1.617, 0.1838 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 08:36:00 visual_prompt]: 	Test 200/512. loss: 1.724, 0.1838 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 08:36:19 visual_prompt]: 	Test 300/512. loss: 1.770, 0.1997 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:36:39 visual_prompt]: 	Test 400/512. loss: 1.575, 0.1993 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 08:36:58 visual_prompt]: 	Test 500/512. loss: 1.518, 0.1940 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 08:37:04 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1964, average loss: 1.6223
[09/16 08:37:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 84.79	
[09/16 08:37:04 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 08:37:15 visual_prompt]: Epoch 40 / 100: avg data time: 1.89e-01, avg batch time: 0.5946, average train loss: 0.9668
[09/16 08:37:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1435, average loss: 1.2181
[09/16 08:37:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 57.00	rocauc: 93.12	
[09/16 08:37:43 visual_prompt]: 	Test 100/512. loss: 1.154, 0.2153 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 08:38:04 visual_prompt]: 	Test 200/512. loss: 1.510, 0.1916 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 08:38:23 visual_prompt]: 	Test 300/512. loss: 1.024, 0.1834 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 08:38:43 visual_prompt]: 	Test 400/512. loss: 1.465, 0.2002 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:39:03 visual_prompt]: 	Test 500/512. loss: 1.226, 0.2003 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 08:39:08 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1975, average loss: 1.3454
[09/16 08:39:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 58.78	rocauc: 85.89	
[09/16 08:39:08 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 08:39:20 visual_prompt]: Epoch 41 / 100: avg data time: 1.93e-01, avg batch time: 0.5974, average train loss: 0.6725
[09/16 08:39:25 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1435, average loss: 0.4278
[09/16 08:39:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 80.00	rocauc: 93.13	
[09/16 08:39:48 visual_prompt]: 	Test 100/512. loss: 0.488, 0.1941 s / batch. (data: 5.19e-03)max mem: 17.22442 GB 
[09/16 08:40:07 visual_prompt]: 	Test 200/512. loss: 0.606, 0.1846 s / batch. (data: 3.24e-04)max mem: 17.22442 GB 
[09/16 08:40:27 visual_prompt]: 	Test 300/512. loss: 0.432, 0.2001 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:40:48 visual_prompt]: 	Test 400/512. loss: 0.609, 0.1946 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 08:41:07 visual_prompt]: 	Test 500/512. loss: 0.472, 0.1965 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 08:41:12 visual_prompt]: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1974, average loss: 0.5264
[09/16 08:41:12 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.96	rocauc: 85.28	
[09/16 08:41:12 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 08:41:24 visual_prompt]: Epoch 42 / 100: avg data time: 1.85e-01, avg batch time: 0.5894, average train loss: 0.4702
[09/16 08:41:29 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1434, average loss: 0.4309
[09/16 08:41:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.00	rocauc: 94.16	
[09/16 08:41:52 visual_prompt]: 	Test 100/512. loss: 0.524, 0.2218 s / batch. (data: 3.91e-02)max mem: 17.22442 GB 
[09/16 08:42:12 visual_prompt]: 	Test 200/512. loss: 0.608, 0.2111 s / batch. (data: 2.73e-02)max mem: 17.22442 GB 
[09/16 08:42:31 visual_prompt]: 	Test 300/512. loss: 0.426, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 08:42:51 visual_prompt]: 	Test 400/512. loss: 0.617, 0.1848 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 08:43:11 visual_prompt]: 	Test 500/512. loss: 0.493, 0.1999 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:43:17 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1973, average loss: 0.5434
[09/16 08:43:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.64	rocauc: 86.20	
[09/16 08:43:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 08:43:28 visual_prompt]: Epoch 43 / 100: avg data time: 1.72e-01, avg batch time: 0.5786, average train loss: 0.4537
[09/16 08:43:34 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.4092
[09/16 08:43:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.50	rocauc: 93.91	
[09/16 08:43:57 visual_prompt]: 	Test 100/512. loss: 0.551, 0.1960 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 08:44:16 visual_prompt]: 	Test 200/512. loss: 0.585, 0.2079 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 08:44:36 visual_prompt]: 	Test 300/512. loss: 0.428, 0.1997 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:44:56 visual_prompt]: 	Test 400/512. loss: 0.592, 0.1990 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 08:45:15 visual_prompt]: 	Test 500/512. loss: 0.443, 0.2107 s / batch. (data: 2.72e-02)max mem: 17.22442 GB 
[09/16 08:45:20 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1964, average loss: 0.5160
[09/16 08:45:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.85	rocauc: 85.77	
[09/16 08:45:20 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 08:45:32 visual_prompt]: Epoch 44 / 100: avg data time: 1.97e-01, avg batch time: 0.6010, average train loss: 0.4577
[09/16 08:45:38 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1433, average loss: 0.3477
[09/16 08:45:38 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 94.46	
[09/16 08:46:01 visual_prompt]: 	Test 100/512. loss: 0.486, 0.2225 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 08:46:21 visual_prompt]: 	Test 200/512. loss: 0.526, 0.1877 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 08:46:40 visual_prompt]: 	Test 300/512. loss: 0.398, 0.1945 s / batch. (data: 1.02e-02)max mem: 17.22442 GB 
[09/16 08:47:00 visual_prompt]: 	Test 400/512. loss: 0.538, 0.2134 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 08:47:20 visual_prompt]: 	Test 500/512. loss: 0.414, 0.1995 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 08:47:25 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1980, average loss: 0.4727
[09/16 08:47:25 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.14	rocauc: 86.51	
[09/16 08:47:25 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 08:47:37 visual_prompt]: Epoch 45 / 100: avg data time: 1.90e-01, avg batch time: 0.5950, average train loss: 0.4768
[09/16 08:47:43 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1436, average loss: 0.3773
[09/16 08:47:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 94.68	
[09/16 08:48:05 visual_prompt]: 	Test 100/512. loss: 0.505, 0.2224 s / batch. (data: 3.96e-02)max mem: 17.22442 GB 
[09/16 08:48:25 visual_prompt]: 	Test 200/512. loss: 0.564, 0.1945 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 08:48:45 visual_prompt]: 	Test 300/512. loss: 0.383, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 08:49:04 visual_prompt]: 	Test 400/512. loss: 0.579, 0.1839 s / batch. (data: 8.80e-05)max mem: 17.22442 GB 
[09/16 08:49:24 visual_prompt]: 	Test 500/512. loss: 0.415, 0.1965 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 08:49:29 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1952, average loss: 0.4964
[09/16 08:49:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.42	rocauc: 86.73	
[09/16 08:49:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 08:49:41 visual_prompt]: Epoch 46 / 100: avg data time: 1.82e-01, avg batch time: 0.5855, average train loss: 0.5036
[09/16 08:49:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1435, average loss: 0.8479
[09/16 08:49:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 57.50	rocauc: 95.01	
[09/16 08:50:09 visual_prompt]: 	Test 100/512. loss: 0.854, 0.1941 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 08:50:29 visual_prompt]: 	Test 200/512. loss: 0.977, 0.2016 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 08:50:48 visual_prompt]: 	Test 300/512. loss: 0.716, 0.1853 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 08:51:08 visual_prompt]: 	Test 400/512. loss: 1.034, 0.1977 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 08:51:27 visual_prompt]: 	Test 500/512. loss: 0.858, 0.1994 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 08:51:33 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1952, average loss: 0.9265
[09/16 08:51:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.43	rocauc: 87.81	
[09/16 08:51:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 08:51:44 visual_prompt]: Epoch 47 / 100: avg data time: 2.08e-01, avg batch time: 0.6117, average train loss: 0.6232
[09/16 08:51:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 0.2896
[09/16 08:51:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 95.24	
[09/16 08:52:13 visual_prompt]: 	Test 100/512. loss: 0.483, 0.1839 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 08:52:33 visual_prompt]: 	Test 200/512. loss: 0.512, 0.1846 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 08:52:52 visual_prompt]: 	Test 300/512. loss: 0.439, 0.1879 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 08:53:12 visual_prompt]: 	Test 400/512. loss: 0.520, 0.1920 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 08:53:32 visual_prompt]: 	Test 500/512. loss: 0.422, 0.1987 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 08:53:37 visual_prompt]: Inference (test):avg data time: 9.07e-03, avg batch time: 0.1960, average loss: 0.4721
[09/16 08:53:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.12	rocauc: 87.19	
[09/16 08:53:37 visual_prompt]: Best epoch 47: best metric: 0.870
[09/16 08:53:37 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 08:53:49 visual_prompt]: Epoch 48 / 100: avg data time: 1.92e-01, avg batch time: 0.5934, average train loss: 0.5998
[09/16 08:53:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 0.4592
[09/16 08:53:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 75.50	rocauc: 94.70	
[09/16 08:54:17 visual_prompt]: 	Test 100/512. loss: 0.524, 0.1953 s / batch. (data: 8.63e-05)max mem: 17.22442 GB 
[09/16 08:54:37 visual_prompt]: 	Test 200/512. loss: 0.606, 0.1987 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 08:54:57 visual_prompt]: 	Test 300/512. loss: 0.436, 0.1946 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 08:55:16 visual_prompt]: 	Test 400/512. loss: 0.616, 0.1845 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 08:55:36 visual_prompt]: 	Test 500/512. loss: 0.501, 0.1844 s / batch. (data: 1.90e-04)max mem: 17.22442 GB 
[09/16 08:55:41 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1968, average loss: 0.5524
[09/16 08:55:41 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.28	rocauc: 86.43	
[09/16 08:55:41 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 08:55:53 visual_prompt]: Epoch 49 / 100: avg data time: 1.95e-01, avg batch time: 0.6003, average train loss: 0.4682
[09/16 08:55:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1433, average loss: 0.6009
[09/16 08:55:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 73.50	rocauc: 94.72	
[09/16 08:56:21 visual_prompt]: 	Test 100/512. loss: 0.707, 0.1886 s / batch. (data: 2.10e-04)max mem: 17.22442 GB 
[09/16 08:56:41 visual_prompt]: 	Test 200/512. loss: 0.777, 0.1847 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 08:57:00 visual_prompt]: 	Test 300/512. loss: 0.557, 0.1979 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 08:57:20 visual_prompt]: 	Test 400/512. loss: 0.835, 0.2089 s / batch. (data: 2.52e-02)max mem: 17.22442 GB 
[09/16 08:57:40 visual_prompt]: 	Test 500/512. loss: 0.627, 0.1893 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 08:57:45 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1953, average loss: 0.7104
[09/16 08:57:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.87	rocauc: 86.90	
[09/16 08:57:45 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 08:57:56 visual_prompt]: Epoch 50 / 100: avg data time: 1.98e-01, avg batch time: 0.6007, average train loss: 0.6267
[09/16 08:58:02 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1432, average loss: 0.5692
[09/16 08:58:02 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 71.50	rocauc: 93.79	
[09/16 08:58:25 visual_prompt]: 	Test 100/512. loss: 0.602, 0.1841 s / batch. (data: 1.07e-04)max mem: 17.22442 GB 
[09/16 08:58:44 visual_prompt]: 	Test 200/512. loss: 0.684, 0.2104 s / batch. (data: 2.71e-02)max mem: 17.22442 GB 
[09/16 08:59:04 visual_prompt]: 	Test 300/512. loss: 0.572, 0.2096 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 08:59:23 visual_prompt]: 	Test 400/512. loss: 0.752, 0.1845 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 08:59:44 visual_prompt]: 	Test 500/512. loss: 0.632, 0.1850 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 08:59:49 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1966, average loss: 0.6590
[09/16 08:59:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.77	rocauc: 85.88	
[09/16 08:59:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 09:00:01 visual_prompt]: Epoch 51 / 100: avg data time: 2.05e-01, avg batch time: 0.6070, average train loss: 0.4520
[09/16 09:00:06 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1434, average loss: 0.3961
[09/16 09:00:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.00	rocauc: 94.32	
[09/16 09:00:29 visual_prompt]: 	Test 100/512. loss: 0.671, 0.1836 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 09:00:49 visual_prompt]: 	Test 200/512. loss: 0.666, 0.2008 s / batch. (data: 1.76e-02)max mem: 17.22442 GB 
[09/16 09:01:09 visual_prompt]: 	Test 300/512. loss: 0.589, 0.2141 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 09:01:29 visual_prompt]: 	Test 400/512. loss: 0.571, 0.1986 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 09:01:48 visual_prompt]: 	Test 500/512. loss: 0.530, 0.2175 s / batch. (data: 3.42e-02)max mem: 17.22442 GB 
[09/16 09:01:53 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1973, average loss: 0.6082
[09/16 09:01:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.63	rocauc: 85.76	
[09/16 09:01:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 09:02:05 visual_prompt]: Epoch 52 / 100: avg data time: 1.97e-01, avg batch time: 0.6010, average train loss: 0.4910
[09/16 09:02:10 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1435, average loss: 0.4491
[09/16 09:02:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.00	rocauc: 94.92	
[09/16 09:02:33 visual_prompt]: 	Test 100/512. loss: 0.549, 0.1837 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 09:02:53 visual_prompt]: 	Test 200/512. loss: 0.619, 0.2309 s / batch. (data: 3.98e-02)max mem: 17.22442 GB 
[09/16 09:03:12 visual_prompt]: 	Test 300/512. loss: 0.428, 0.2034 s / batch. (data: 2.02e-02)max mem: 17.22442 GB 
[09/16 09:03:32 visual_prompt]: 	Test 400/512. loss: 0.638, 0.2151 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 09:03:51 visual_prompt]: 	Test 500/512. loss: 0.496, 0.1850 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 09:03:57 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1953, average loss: 0.5595
[09/16 09:03:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.26	rocauc: 87.83	
[09/16 09:03:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 09:04:08 visual_prompt]: Epoch 53 / 100: avg data time: 1.70e-01, avg batch time: 0.5774, average train loss: 0.6088
[09/16 09:04:13 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1434, average loss: 0.2728
[09/16 09:04:13 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 95.90	
[09/16 09:04:36 visual_prompt]: 	Test 100/512. loss: 0.467, 0.1957 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 09:04:56 visual_prompt]: 	Test 200/512. loss: 0.468, 0.1845 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 09:05:15 visual_prompt]: 	Test 300/512. loss: 0.362, 0.2064 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 09:05:35 visual_prompt]: 	Test 400/512. loss: 0.476, 0.1917 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 09:05:55 visual_prompt]: 	Test 500/512. loss: 0.361, 0.2037 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 09:06:00 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1952, average loss: 0.4327
[09/16 09:06:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.76	rocauc: 88.37	
[09/16 09:06:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 09:06:11 visual_prompt]: Epoch 54 / 100: avg data time: 2.03e-01, avg batch time: 0.6062, average train loss: 0.5489
[09/16 09:06:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1436, average loss: 0.2907
[09/16 09:06:17 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 96.06	
[09/16 09:06:40 visual_prompt]: 	Test 100/512. loss: 0.452, 0.1956 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 09:07:00 visual_prompt]: 	Test 200/512. loss: 0.455, 0.2148 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 09:07:19 visual_prompt]: 	Test 300/512. loss: 0.369, 0.1981 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 09:07:39 visual_prompt]: 	Test 400/512. loss: 0.443, 0.1888 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 09:07:59 visual_prompt]: 	Test 500/512. loss: 0.355, 0.2069 s / batch. (data: 2.27e-02)max mem: 17.22442 GB 
[09/16 09:08:04 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1962, average loss: 0.4300
[09/16 09:08:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.65	rocauc: 88.45	
[09/16 09:08:04 visual_prompt]: Best epoch 54: best metric: 0.875
[09/16 09:08:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 09:08:16 visual_prompt]: Epoch 55 / 100: avg data time: 1.94e-01, avg batch time: 0.5997, average train loss: 0.4305
[09/16 09:08:21 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1434, average loss: 0.3114
[09/16 09:08:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 95.63	
[09/16 09:08:44 visual_prompt]: 	Test 100/512. loss: 0.492, 0.1957 s / batch. (data: 5.31e-03)max mem: 17.22442 GB 
[09/16 09:09:04 visual_prompt]: 	Test 200/512. loss: 0.495, 0.1869 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 09:09:24 visual_prompt]: 	Test 300/512. loss: 0.336, 0.1841 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 09:09:43 visual_prompt]: 	Test 400/512. loss: 0.494, 0.2364 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 09:10:03 visual_prompt]: 	Test 500/512. loss: 0.337, 0.1961 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 09:10:08 visual_prompt]: Inference (test):avg data time: 6.63e-03, avg batch time: 0.1964, average loss: 0.4422
[09/16 09:10:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.29	rocauc: 88.70	
[09/16 09:10:08 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 09:10:20 visual_prompt]: Epoch 56 / 100: avg data time: 1.94e-01, avg batch time: 0.5973, average train loss: 0.4295
[09/16 09:10:25 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1434, average loss: 0.6675
[09/16 09:10:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 63.50	rocauc: 96.30	
[09/16 09:10:48 visual_prompt]: 	Test 100/512. loss: 0.684, 0.2077 s / batch. (data: 2.48e-02)max mem: 17.22442 GB 
[09/16 09:11:08 visual_prompt]: 	Test 200/512. loss: 0.730, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 09:11:27 visual_prompt]: 	Test 300/512. loss: 0.561, 0.1839 s / batch. (data: 3.50e-05)max mem: 17.22442 GB 
[09/16 09:11:47 visual_prompt]: 	Test 400/512. loss: 0.731, 0.1985 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 09:12:06 visual_prompt]: 	Test 500/512. loss: 0.685, 0.1995 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 09:12:11 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1952, average loss: 0.7104
[09/16 09:12:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.70	rocauc: 87.28	
[09/16 09:12:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 09:12:23 visual_prompt]: Epoch 57 / 100: avg data time: 2.00e-01, avg batch time: 0.6037, average train loss: 0.4936
[09/16 09:12:29 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1434, average loss: 0.3146
[09/16 09:12:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.00	rocauc: 95.66	
[09/16 09:12:52 visual_prompt]: 	Test 100/512. loss: 0.511, 0.1954 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 09:13:11 visual_prompt]: 	Test 200/512. loss: 0.533, 0.1840 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 09:13:31 visual_prompt]: 	Test 300/512. loss: 0.430, 0.2062 s / batch. (data: 2.30e-02)max mem: 17.22442 GB 
[09/16 09:13:50 visual_prompt]: 	Test 400/512. loss: 0.502, 0.1854 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 09:14:10 visual_prompt]: 	Test 500/512. loss: 0.403, 0.1987 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 09:14:15 visual_prompt]: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1955, average loss: 0.4821
[09/16 09:14:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.11	rocauc: 88.59	
[09/16 09:14:15 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 09:14:27 visual_prompt]: Epoch 58 / 100: avg data time: 1.89e-01, avg batch time: 0.5932, average train loss: 0.3960
[09/16 09:14:33 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.3207, average loss: 0.3031
[09/16 09:14:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 95.84	
[09/16 09:14:56 visual_prompt]: 	Test 100/512. loss: 0.536, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 09:15:15 visual_prompt]: 	Test 200/512. loss: 0.496, 0.2083 s / batch. (data: 2.49e-02)max mem: 17.22442 GB 
[09/16 09:15:34 visual_prompt]: 	Test 300/512. loss: 0.415, 0.1844 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 09:15:54 visual_prompt]: 	Test 400/512. loss: 0.467, 0.1947 s / batch. (data: 1.07e-02)max mem: 17.22442 GB 
[09/16 09:16:14 visual_prompt]: 	Test 500/512. loss: 0.391, 0.1847 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 09:16:19 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1945, average loss: 0.4926
[09/16 09:16:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.80	rocauc: 87.92	
[09/16 09:16:19 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 09:16:30 visual_prompt]: Epoch 59 / 100: avg data time: 1.75e-01, avg batch time: 0.5811, average train loss: 0.4869
[09/16 09:16:36 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1437, average loss: 0.6470
[09/16 09:16:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 67.50	rocauc: 96.33	
[09/16 09:16:58 visual_prompt]: 	Test 100/512. loss: 0.747, 0.1957 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 09:17:18 visual_prompt]: 	Test 200/512. loss: 0.793, 0.1962 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 09:17:38 visual_prompt]: 	Test 300/512. loss: 0.606, 0.1836 s / batch. (data: 3.91e-05)max mem: 17.22442 GB 
[09/16 09:17:58 visual_prompt]: 	Test 400/512. loss: 0.913, 0.1839 s / batch. (data: 8.70e-05)max mem: 17.22442 GB 
[09/16 09:18:17 visual_prompt]: 	Test 500/512. loss: 0.760, 0.1847 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 09:18:23 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1957, average loss: 0.7800
[09/16 09:18:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.59	rocauc: 88.05	
[09/16 09:18:23 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 09:18:35 visual_prompt]: Epoch 60 / 100: avg data time: 1.85e-01, avg batch time: 0.5884, average train loss: 0.4187
[09/16 09:18:40 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1436, average loss: 0.5064
[09/16 09:18:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 73.00	rocauc: 97.07	
[09/16 09:19:03 visual_prompt]: 	Test 100/512. loss: 0.598, 0.1957 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 09:19:23 visual_prompt]: 	Test 200/512. loss: 0.629, 0.2187 s / batch. (data: 3.53e-02)max mem: 17.22442 GB 
[09/16 09:19:42 visual_prompt]: 	Test 300/512. loss: 0.462, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 09:20:02 visual_prompt]: 	Test 400/512. loss: 0.672, 0.1849 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 09:20:21 visual_prompt]: 	Test 500/512. loss: 0.607, 0.1851 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 09:20:27 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1953, average loss: 0.6164
[09/16 09:20:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.36	rocauc: 88.54	
[09/16 09:20:27 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 09:20:38 visual_prompt]: Epoch 61 / 100: avg data time: 1.97e-01, avg batch time: 0.6005, average train loss: 0.3806
[09/16 09:20:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1435, average loss: 0.2466
[09/16 09:20:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.00	rocauc: 97.36	
[09/16 09:21:07 visual_prompt]: 	Test 100/512. loss: 0.476, 0.1957 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 09:21:27 visual_prompt]: 	Test 200/512. loss: 0.480, 0.1835 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 09:21:46 visual_prompt]: 	Test 300/512. loss: 0.361, 0.2187 s / batch. (data: 3.56e-02)max mem: 17.22442 GB 
[09/16 09:22:06 visual_prompt]: 	Test 400/512. loss: 0.444, 0.1862 s / batch. (data: 1.74e-04)max mem: 17.22442 GB 
[09/16 09:22:26 visual_prompt]: 	Test 500/512. loss: 0.381, 0.1868 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 09:22:31 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1966, average loss: 0.4514
[09/16 09:22:31 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.65	rocauc: 87.73	
[09/16 09:22:31 visual_prompt]: Best epoch 61: best metric: 0.920
[09/16 09:22:31 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 09:22:43 visual_prompt]: Epoch 62 / 100: avg data time: 1.80e-01, avg batch time: 0.5854, average train loss: 0.3236
[09/16 09:22:48 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1434, average loss: 0.3582
[09/16 09:22:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.00	rocauc: 97.93	
[09/16 09:23:11 visual_prompt]: 	Test 100/512. loss: 0.555, 0.2113 s / batch. (data: 2.86e-02)max mem: 17.22442 GB 
[09/16 09:23:31 visual_prompt]: 	Test 200/512. loss: 0.599, 0.1841 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 09:23:50 visual_prompt]: 	Test 300/512. loss: 0.361, 0.1967 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 09:24:10 visual_prompt]: 	Test 400/512. loss: 0.695, 0.2008 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 09:24:29 visual_prompt]: 	Test 500/512. loss: 0.548, 0.1852 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 09:24:34 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1955, average loss: 0.5615
[09/16 09:24:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.86	rocauc: 88.58	
[09/16 09:24:34 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 09:24:46 visual_prompt]: Epoch 63 / 100: avg data time: 1.86e-01, avg batch time: 0.5898, average train loss: 0.3925
[09/16 09:24:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1435, average loss: 0.2503
[09/16 09:24:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.00	rocauc: 97.75	
[09/16 09:25:14 visual_prompt]: 	Test 100/512. loss: 0.489, 0.1831 s / batch. (data: 9.44e-05)max mem: 17.22442 GB 
[09/16 09:25:33 visual_prompt]: 	Test 200/512. loss: 0.458, 0.1967 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 09:25:53 visual_prompt]: 	Test 300/512. loss: 0.320, 0.1984 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 09:26:13 visual_prompt]: 	Test 400/512. loss: 0.530, 0.1997 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 09:26:33 visual_prompt]: 	Test 500/512. loss: 0.346, 0.1968 s / batch. (data: 3.19e-05)max mem: 17.22442 GB 
[09/16 09:26:38 visual_prompt]: Inference (test):avg data time: 8.50e-03, avg batch time: 0.1964, average loss: 0.4435
[09/16 09:26:38 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.08	
[09/16 09:26:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 09:26:50 visual_prompt]: Epoch 64 / 100: avg data time: 1.95e-01, avg batch time: 0.5983, average train loss: 0.3822
[09/16 09:26:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1434, average loss: 0.3216
[09/16 09:26:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.50	rocauc: 97.73	
[09/16 09:27:18 visual_prompt]: 	Test 100/512. loss: 0.505, 0.1863 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 09:27:38 visual_prompt]: 	Test 200/512. loss: 0.543, 0.1846 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 09:27:57 visual_prompt]: 	Test 300/512. loss: 0.323, 0.1971 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 09:28:17 visual_prompt]: 	Test 400/512. loss: 0.578, 0.2263 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 09:28:37 visual_prompt]: 	Test 500/512. loss: 0.476, 0.1999 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 09:28:42 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1956, average loss: 0.4975
[09/16 09:28:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.16	rocauc: 88.83	
[09/16 09:28:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 09:28:54 visual_prompt]: Epoch 65 / 100: avg data time: 1.97e-01, avg batch time: 0.6009, average train loss: 0.3022
[09/16 09:28:59 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1436, average loss: 0.6408
[09/16 09:28:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 63.50	rocauc: 98.58	
[09/16 09:29:22 visual_prompt]: 	Test 100/512. loss: 0.820, 0.1984 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 09:29:42 visual_prompt]: 	Test 200/512. loss: 0.778, 0.2172 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 09:30:02 visual_prompt]: 	Test 300/512. loss: 0.625, 0.1846 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 09:30:21 visual_prompt]: 	Test 400/512. loss: 0.977, 0.1999 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 09:30:41 visual_prompt]: 	Test 500/512. loss: 0.828, 0.1962 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 09:30:46 visual_prompt]: Inference (test):avg data time: 8.87e-03, avg batch time: 0.1969, average loss: 0.8125
[09/16 09:30:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.25	rocauc: 89.03	
[09/16 09:30:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 09:30:58 visual_prompt]: Epoch 66 / 100: avg data time: 1.96e-01, avg batch time: 0.5992, average train loss: 0.3594
[09/16 09:31:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1445, average loss: 0.3103
[09/16 09:31:04 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 97.99	
[09/16 09:31:26 visual_prompt]: 	Test 100/512. loss: 0.507, 0.1840 s / batch. (data: 9.44e-05)max mem: 17.22442 GB 
[09/16 09:31:46 visual_prompt]: 	Test 200/512. loss: 0.534, 0.1983 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 09:32:05 visual_prompt]: 	Test 300/512. loss: 0.392, 0.1855 s / batch. (data: 5.60e-05)max mem: 17.22442 GB 
[09/16 09:32:25 visual_prompt]: 	Test 400/512. loss: 0.592, 0.2000 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 09:32:44 visual_prompt]: 	Test 500/512. loss: 0.553, 0.1845 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 09:32:49 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1952, average loss: 0.5203
[09/16 09:32:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.50	rocauc: 86.48	
[09/16 09:32:49 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 09:33:01 visual_prompt]: Epoch 67 / 100: avg data time: 2.00e-01, avg batch time: 0.6020, average train loss: 0.2857
[09/16 09:33:07 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1435, average loss: 0.8622
[09/16 09:33:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 60.00	rocauc: 98.12	
[09/16 09:33:30 visual_prompt]: 	Test 100/512. loss: 1.419, 0.2070 s / batch. (data: 2.31e-02)max mem: 17.22442 GB 
[09/16 09:33:49 visual_prompt]: 	Test 200/512. loss: 1.367, 0.1997 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 09:34:09 visual_prompt]: 	Test 300/512. loss: 1.396, 0.1923 s / batch. (data: 9.47e-05)max mem: 17.22442 GB 
[09/16 09:34:29 visual_prompt]: 	Test 400/512. loss: 1.148, 0.1895 s / batch. (data: 5.23e-03)max mem: 17.22442 GB 
[09/16 09:34:49 visual_prompt]: 	Test 500/512. loss: 1.116, 0.2053 s / batch. (data: 2.11e-02)max mem: 17.22442 GB 
[09/16 09:34:54 visual_prompt]: Inference (test):avg data time: 8.80e-03, avg batch time: 0.1970, average loss: 1.3116
[09/16 09:34:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 52.18	rocauc: 83.06	
[09/16 09:34:54 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 09:35:05 visual_prompt]: Epoch 68 / 100: avg data time: 1.95e-01, avg batch time: 0.5990, average train loss: 0.5130
[09/16 09:35:11 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1435, average loss: 0.3601
[09/16 09:35:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.50	rocauc: 97.52	
[09/16 09:35:34 visual_prompt]: 	Test 100/512. loss: 0.566, 0.2047 s / batch. (data: 3.05e-05)max mem: 17.22442 GB 
[09/16 09:35:53 visual_prompt]: 	Test 200/512. loss: 0.621, 0.1991 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 09:36:13 visual_prompt]: 	Test 300/512. loss: 0.373, 0.1963 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 09:36:32 visual_prompt]: 	Test 400/512. loss: 0.640, 0.1845 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 09:36:52 visual_prompt]: 	Test 500/512. loss: 0.490, 0.1997 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 09:36:57 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1953, average loss: 0.5649
[09/16 09:36:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.22	rocauc: 88.45	
[09/16 09:36:57 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 09:37:09 visual_prompt]: Epoch 69 / 100: avg data time: 2.03e-01, avg batch time: 0.6067, average train loss: 0.3292
[09/16 09:37:15 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1437, average loss: 0.3926
[09/16 09:37:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.50	rocauc: 97.22	
[09/16 09:37:38 visual_prompt]: 	Test 100/512. loss: 0.598, 0.2002 s / batch. (data: 1.69e-02)max mem: 17.22442 GB 
[09/16 09:37:57 visual_prompt]: 	Test 200/512. loss: 0.722, 0.1849 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 09:38:17 visual_prompt]: 	Test 300/512. loss: 0.439, 0.2115 s / batch. (data: 2.78e-02)max mem: 17.22442 GB 
[09/16 09:38:37 visual_prompt]: 	Test 400/512. loss: 0.714, 0.1849 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 09:38:57 visual_prompt]: 	Test 500/512. loss: 0.573, 0.1847 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 09:39:03 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1976, average loss: 0.6443
[09/16 09:39:03 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.21	rocauc: 85.67	
[09/16 09:39:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 09:39:14 visual_prompt]: Epoch 70 / 100: avg data time: 2.01e-01, avg batch time: 0.6049, average train loss: 0.3454
[09/16 09:39:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1504, average loss: 0.2392
[09/16 09:39:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 98.43	
[09/16 09:39:43 visual_prompt]: 	Test 100/512. loss: 0.543, 0.1839 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 09:40:03 visual_prompt]: 	Test 200/512. loss: 0.502, 0.1954 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 09:40:22 visual_prompt]: 	Test 300/512. loss: 0.328, 0.2008 s / batch. (data: 1.12e-04)max mem: 17.22442 GB 
[09/16 09:40:42 visual_prompt]: 	Test 400/512. loss: 0.533, 0.1841 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 09:41:02 visual_prompt]: 	Test 500/512. loss: 0.453, 0.1848 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 09:41:07 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1961, average loss: 0.4922
[09/16 09:41:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.88	rocauc: 87.79	
[09/16 09:41:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 09:41:18 visual_prompt]: Epoch 71 / 100: avg data time: 1.90e-01, avg batch time: 0.5955, average train loss: 0.2765
[09/16 09:41:23 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1436, average loss: 0.3535
[09/16 09:41:23 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.50	rocauc: 97.27	
[09/16 09:41:46 visual_prompt]: 	Test 100/512. loss: 0.551, 0.1968 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 09:42:06 visual_prompt]: 	Test 200/512. loss: 0.572, 0.1890 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 09:42:26 visual_prompt]: 	Test 300/512. loss: 0.423, 0.1883 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 09:42:45 visual_prompt]: 	Test 400/512. loss: 0.648, 0.1920 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 09:43:05 visual_prompt]: 	Test 500/512. loss: 0.530, 0.1971 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 09:43:10 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1961, average loss: 0.5963
[09/16 09:43:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.20	rocauc: 84.46	
[09/16 09:43:10 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 09:43:22 visual_prompt]: Epoch 72 / 100: avg data time: 1.85e-01, avg batch time: 0.5919, average train loss: 0.2481
[09/16 09:43:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1433, average loss: 0.1971
[09/16 09:43:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.50	rocauc: 98.35	
[09/16 09:43:50 visual_prompt]: 	Test 100/512. loss: 0.653, 0.2030 s / batch. (data: 5.10e-04)max mem: 17.22442 GB 
[09/16 09:44:09 visual_prompt]: 	Test 200/512. loss: 0.606, 0.1959 s / batch. (data: 1.21e-02)max mem: 17.22442 GB 
[09/16 09:44:29 visual_prompt]: 	Test 300/512. loss: 0.370, 0.1994 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 09:44:49 visual_prompt]: 	Test 400/512. loss: 0.496, 0.1999 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 09:45:08 visual_prompt]: 	Test 500/512. loss: 0.456, 0.1995 s / batch. (data: 5.41e-05)max mem: 17.22442 GB 
[09/16 09:45:13 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1957, average loss: 0.5127
[09/16 09:45:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.31	rocauc: 85.61	
[09/16 09:45:13 visual_prompt]: Best epoch 72: best metric: 0.925
[09/16 09:45:13 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 09:45:25 visual_prompt]: Epoch 73 / 100: avg data time: 1.89e-01, avg batch time: 0.5923, average train loss: 0.2935
[09/16 09:45:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1460, average loss: 0.3527
[09/16 09:45:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.50	rocauc: 97.88	
[09/16 09:45:53 visual_prompt]: 	Test 100/512. loss: 0.497, 0.1976 s / batch. (data: 1.06e-02)max mem: 17.22442 GB 
[09/16 09:46:13 visual_prompt]: 	Test 200/512. loss: 0.536, 0.2013 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 09:46:32 visual_prompt]: 	Test 300/512. loss: 0.391, 0.2025 s / batch. (data: 1.86e-02)max mem: 17.22442 GB 
[09/16 09:46:52 visual_prompt]: 	Test 400/512. loss: 0.535, 0.1844 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 09:47:11 visual_prompt]: 	Test 500/512. loss: 0.461, 0.1964 s / batch. (data: 1.18e-02)max mem: 17.22442 GB 
[09/16 09:47:17 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1949, average loss: 0.4991
[09/16 09:47:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.56	rocauc: 85.39	
[09/16 09:47:17 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 09:47:28 visual_prompt]: Epoch 74 / 100: avg data time: 1.76e-01, avg batch time: 0.5848, average train loss: 0.2551
[09/16 09:47:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1432, average loss: 0.1436
[09/16 09:47:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.00	rocauc: 99.09	
[09/16 09:47:56 visual_prompt]: 	Test 100/512. loss: 0.722, 0.1893 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 09:48:16 visual_prompt]: 	Test 200/512. loss: 0.630, 0.2256 s / batch. (data: 4.28e-02)max mem: 17.22442 GB 
[09/16 09:48:36 visual_prompt]: 	Test 300/512. loss: 0.453, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 09:48:55 visual_prompt]: 	Test 400/512. loss: 0.568, 0.2212 s / batch. (data: 3.79e-02)max mem: 17.22442 GB 
[09/16 09:49:15 visual_prompt]: 	Test 500/512. loss: 0.649, 0.1983 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 09:49:20 visual_prompt]: Inference (test):avg data time: 8.51e-03, avg batch time: 0.1959, average loss: 0.5940
[09/16 09:49:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.92	rocauc: 85.34	
[09/16 09:49:20 visual_prompt]: Best epoch 74: best metric: 0.950
[09/16 09:49:20 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 09:49:32 visual_prompt]: Epoch 75 / 100: avg data time: 1.90e-01, avg batch time: 0.5943, average train loss: 0.2729
[09/16 09:49:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1433, average loss: 0.5624
[09/16 09:49:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 70.00	rocauc: 99.32	
[09/16 09:50:00 visual_prompt]: 	Test 100/512. loss: 0.928, 0.1997 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 09:50:20 visual_prompt]: 	Test 200/512. loss: 0.942, 0.1842 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 09:50:39 visual_prompt]: 	Test 300/512. loss: 0.652, 0.1998 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 09:50:59 visual_prompt]: 	Test 400/512. loss: 1.089, 0.1963 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 09:51:18 visual_prompt]: 	Test 500/512. loss: 0.885, 0.1843 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 09:51:23 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1956, average loss: 0.8919
[09/16 09:51:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.35	rocauc: 86.93	
[09/16 09:51:23 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 09:51:36 visual_prompt]: Epoch 76 / 100: avg data time: 2.02e-01, avg batch time: 0.6069, average train loss: 0.3790
[09/16 09:51:42 visual_prompt]: Inference (val):avg data time: 3.41e-04, avg batch time: 0.2770, average loss: 0.2554
[09/16 09:51:42 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.00	rocauc: 99.32	
[09/16 09:52:04 visual_prompt]: 	Test 100/512. loss: 0.743, 0.1936 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 09:52:24 visual_prompt]: 	Test 200/512. loss: 0.737, 0.2038 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 09:52:45 visual_prompt]: 	Test 300/512. loss: 0.696, 0.2028 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 09:53:04 visual_prompt]: 	Test 400/512. loss: 0.640, 0.2004 s / batch. (data: 1.68e-02)max mem: 17.22442 GB 
[09/16 09:53:24 visual_prompt]: 	Test 500/512. loss: 0.585, 0.1995 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 09:53:29 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1972, average loss: 0.7089
[09/16 09:53:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.69	rocauc: 87.62	
[09/16 09:53:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 09:53:41 visual_prompt]: Epoch 77 / 100: avg data time: 1.90e-01, avg batch time: 0.5942, average train loss: 0.2677
[09/16 09:53:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1435, average loss: 0.1466
[09/16 09:53:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.18	
[09/16 09:54:09 visual_prompt]: 	Test 100/512. loss: 0.686, 0.1848 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 09:54:29 visual_prompt]: 	Test 200/512. loss: 0.584, 0.1961 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 09:54:48 visual_prompt]: 	Test 300/512. loss: 0.485, 0.1843 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 09:55:08 visual_prompt]: 	Test 400/512. loss: 0.576, 0.1999 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 09:55:27 visual_prompt]: 	Test 500/512. loss: 0.431, 0.1949 s / batch. (data: 1.12e-04)max mem: 17.22442 GB 
[09/16 09:55:32 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1953, average loss: 0.5723
[09/16 09:55:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.80	rocauc: 85.72	
[09/16 09:55:32 visual_prompt]: Best epoch 77: best metric: 0.955
[09/16 09:55:32 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 09:55:44 visual_prompt]: Epoch 78 / 100: avg data time: 1.86e-01, avg batch time: 0.5908, average train loss: 0.2110
[09/16 09:55:50 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1432, average loss: 0.2613
[09/16 09:55:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 99.46	
[09/16 09:56:12 visual_prompt]: 	Test 100/512. loss: 0.790, 0.1988 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 09:56:32 visual_prompt]: 	Test 200/512. loss: 0.708, 0.1988 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 09:56:52 visual_prompt]: 	Test 300/512. loss: 0.468, 0.1857 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 09:57:11 visual_prompt]: 	Test 400/512. loss: 0.844, 0.1851 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 09:57:31 visual_prompt]: 	Test 500/512. loss: 0.706, 0.1875 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 09:57:36 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1952, average loss: 0.6893
[09/16 09:57:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.10	rocauc: 85.92	
[09/16 09:57:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 09:57:47 visual_prompt]: Epoch 79 / 100: avg data time: 1.89e-01, avg batch time: 0.5921, average train loss: 0.1462
[09/16 09:57:53 visual_prompt]: Inference (val):avg data time: 1.11e-04, avg batch time: 0.2132, average loss: 0.1169
[09/16 09:57:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.69	
[09/16 09:58:16 visual_prompt]: 	Test 100/512. loss: 0.743, 0.2021 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 09:58:36 visual_prompt]: 	Test 200/512. loss: 0.629, 0.1971 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 09:58:56 visual_prompt]: 	Test 300/512. loss: 0.415, 0.1930 s / batch. (data: 1.00e-04)max mem: 17.22442 GB 
[09/16 09:59:15 visual_prompt]: 	Test 400/512. loss: 0.571, 0.1850 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 09:59:35 visual_prompt]: 	Test 500/512. loss: 0.419, 0.1847 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 09:59:40 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1954, average loss: 0.5569
[09/16 09:59:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.05	rocauc: 86.73	
[09/16 09:59:40 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 09:59:51 visual_prompt]: Epoch 80 / 100: avg data time: 2.00e-01, avg batch time: 0.6030, average train loss: 0.1144
[09/16 09:59:57 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1434, average loss: 0.2948
[09/16 09:59:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.00	rocauc: 99.68	
[09/16 10:00:20 visual_prompt]: 	Test 100/512. loss: 1.048, 0.1992 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 10:00:40 visual_prompt]: 	Test 200/512. loss: 0.873, 0.1851 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 10:00:59 visual_prompt]: 	Test 300/512. loss: 0.586, 0.1843 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 10:01:19 visual_prompt]: 	Test 400/512. loss: 0.944, 0.2159 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 10:01:38 visual_prompt]: 	Test 500/512. loss: 0.852, 0.1853 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 10:01:43 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1956, average loss: 0.8698
[09/16 10:01:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.13	rocauc: 86.31	
[09/16 10:01:43 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 10:01:55 visual_prompt]: Epoch 81 / 100: avg data time: 1.82e-01, avg batch time: 0.5858, average train loss: 0.1373
[09/16 10:02:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1436, average loss: 0.1908
[09/16 10:02:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.00	rocauc: 99.71	
[09/16 10:02:23 visual_prompt]: 	Test 100/512. loss: 0.805, 0.1965 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 10:02:43 visual_prompt]: 	Test 200/512. loss: 0.697, 0.1842 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 10:03:03 visual_prompt]: 	Test 300/512. loss: 0.489, 0.1841 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 10:03:22 visual_prompt]: 	Test 400/512. loss: 0.841, 0.1989 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 10:03:42 visual_prompt]: 	Test 500/512. loss: 0.591, 0.2021 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 10:03:47 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1959, average loss: 0.7059
[09/16 10:03:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.43	rocauc: 87.88	
[09/16 10:03:47 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 10:03:59 visual_prompt]: Epoch 82 / 100: avg data time: 1.97e-01, avg batch time: 0.5991, average train loss: 0.1236
[09/16 10:04:05 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1435, average loss: 0.1994
[09/16 10:04:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.50	rocauc: 99.62	
[09/16 10:04:28 visual_prompt]: 	Test 100/512. loss: 0.860, 0.1965 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 10:04:47 visual_prompt]: 	Test 200/512. loss: 0.759, 0.2015 s / batch. (data: 1.07e-02)max mem: 17.22442 GB 
[09/16 10:05:07 visual_prompt]: 	Test 300/512. loss: 0.576, 0.2022 s / batch. (data: 1.35e-02)max mem: 17.22442 GB 
[09/16 10:05:26 visual_prompt]: 	Test 400/512. loss: 0.771, 0.1961 s / batch. (data: 1.12e-04)max mem: 17.22442 GB 
[09/16 10:05:46 visual_prompt]: 	Test 500/512. loss: 0.678, 0.1846 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 10:05:51 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1965, average loss: 0.7200
[09/16 10:05:51 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.41	rocauc: 84.55	
[09/16 10:05:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 10:06:03 visual_prompt]: Epoch 83 / 100: avg data time: 1.98e-01, avg batch time: 0.6001, average train loss: 0.0715
[09/16 10:06:08 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1434, average loss: 0.1110
[09/16 10:06:08 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.95	
[09/16 10:06:31 visual_prompt]: 	Test 100/512. loss: 1.023, 0.1918 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 10:06:51 visual_prompt]: 	Test 200/512. loss: 0.884, 0.1839 s / batch. (data: 8.94e-05)max mem: 17.22442 GB 
[09/16 10:07:11 visual_prompt]: 	Test 300/512. loss: 0.663, 0.1859 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 10:07:30 visual_prompt]: 	Test 400/512. loss: 0.977, 0.2094 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 10:07:50 visual_prompt]: 	Test 500/512. loss: 0.806, 0.2013 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 10:07:55 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1961, average loss: 0.8217
[09/16 10:07:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.37	rocauc: 84.45	
[09/16 10:07:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 10:08:07 visual_prompt]: Epoch 84 / 100: avg data time: 1.95e-01, avg batch time: 0.5996, average train loss: 0.0746
[09/16 10:08:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1431, average loss: 0.1102
[09/16 10:08:12 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.00	rocauc: 99.93	
[09/16 10:08:35 visual_prompt]: 	Test 100/512. loss: 1.072, 0.1948 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 10:08:54 visual_prompt]: 	Test 200/512. loss: 1.059, 0.1962 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 10:09:14 visual_prompt]: 	Test 300/512. loss: 0.780, 0.2026 s / batch. (data: 1.83e-02)max mem: 17.22442 GB 
[09/16 10:09:33 visual_prompt]: 	Test 400/512. loss: 1.143, 0.1997 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 10:09:53 visual_prompt]: 	Test 500/512. loss: 0.882, 0.1987 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 10:09:58 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1951, average loss: 0.9484
[09/16 10:09:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.31	rocauc: 82.78	
[09/16 10:09:58 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 10:10:10 visual_prompt]: Epoch 85 / 100: avg data time: 1.88e-01, avg batch time: 0.5956, average train loss: 0.0629
[09/16 10:10:16 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1435, average loss: 0.0722
[09/16 10:10:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 99.94	
[09/16 10:10:38 visual_prompt]: 	Test 100/512. loss: 1.100, 0.1859 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 10:10:58 visual_prompt]: 	Test 200/512. loss: 0.855, 0.2038 s / batch. (data: 2.02e-02)max mem: 17.22442 GB 
[09/16 10:11:18 visual_prompt]: 	Test 300/512. loss: 0.731, 0.1835 s / batch. (data: 9.01e-05)max mem: 17.22442 GB 
[09/16 10:11:37 visual_prompt]: 	Test 400/512. loss: 0.933, 0.1849 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 10:11:57 visual_prompt]: 	Test 500/512. loss: 0.825, 0.1841 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 10:12:02 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1960, average loss: 0.8466
[09/16 10:12:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.44	rocauc: 83.92	
[09/16 10:12:02 visual_prompt]: Best epoch 85: best metric: 0.965
[09/16 10:12:02 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 10:12:14 visual_prompt]: Epoch 86 / 100: avg data time: 1.98e-01, avg batch time: 0.6022, average train loss: 0.0599
[09/16 10:12:20 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1433, average loss: 0.0649
[09/16 10:12:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.96	
[09/16 10:12:43 visual_prompt]: 	Test 100/512. loss: 0.958, 0.1969 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 10:13:02 visual_prompt]: 	Test 200/512. loss: 0.934, 0.1892 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 10:13:22 visual_prompt]: 	Test 300/512. loss: 0.638, 0.2111 s / batch. (data: 2.74e-02)max mem: 17.22442 GB 
[09/16 10:13:42 visual_prompt]: 	Test 400/512. loss: 0.995, 0.2270 s / batch. (data: 4.38e-02)max mem: 17.22442 GB 
[09/16 10:14:02 visual_prompt]: 	Test 500/512. loss: 0.899, 0.1851 s / batch. (data: 9.97e-05)max mem: 17.22442 GB 
[09/16 10:14:07 visual_prompt]: Inference (test):avg data time: 8.53e-03, avg batch time: 0.1968, average loss: 0.8132
[09/16 10:14:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.20	rocauc: 85.71	
[09/16 10:14:07 visual_prompt]: Best epoch 86: best metric: 0.975
[09/16 10:14:07 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 10:14:18 visual_prompt]: Epoch 87 / 100: avg data time: 1.90e-01, avg batch time: 0.5962, average train loss: 0.0523
[09/16 10:14:24 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1440, average loss: 0.0850
[09/16 10:14:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 99.97	
[09/16 10:14:47 visual_prompt]: 	Test 100/512. loss: 0.914, 0.1931 s / batch. (data: 1.06e-02)max mem: 17.22442 GB 
[09/16 10:15:06 visual_prompt]: 	Test 200/512. loss: 0.910, 0.1838 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 10:15:26 visual_prompt]: 	Test 300/512. loss: 0.767, 0.1959 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 10:15:45 visual_prompt]: 	Test 400/512. loss: 1.009, 0.1893 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 10:16:05 visual_prompt]: 	Test 500/512. loss: 0.722, 0.1848 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 10:16:10 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1946, average loss: 0.8547
[09/16 10:16:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.24	rocauc: 83.66	
[09/16 10:16:10 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 10:16:22 visual_prompt]: Epoch 88 / 100: avg data time: 1.98e-01, avg batch time: 0.6030, average train loss: 0.0271
[09/16 10:16:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1434, average loss: 0.0242
[09/16 10:16:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 10:16:50 visual_prompt]: 	Test 100/512. loss: 1.032, 0.1919 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 10:17:09 visual_prompt]: 	Test 200/512. loss: 0.918, 0.1958 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 10:17:29 visual_prompt]: 	Test 300/512. loss: 0.813, 0.1840 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 10:17:49 visual_prompt]: 	Test 400/512. loss: 1.050, 0.1999 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 10:18:08 visual_prompt]: 	Test 500/512. loss: 0.671, 0.2036 s / batch. (data: 8.49e-05)max mem: 17.22442 GB 
[09/16 10:18:13 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1954, average loss: 0.9074
[09/16 10:18:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.28	rocauc: 85.04	
[09/16 10:18:13 visual_prompt]: Best epoch 88: best metric: 0.995
[09/16 10:18:13 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 10:18:25 visual_prompt]: Epoch 89 / 100: avg data time: 1.73e-01, avg batch time: 0.5808, average train loss: 0.0319
[09/16 10:18:30 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1441, average loss: 0.1110
[09/16 10:18:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.97	
[09/16 10:18:53 visual_prompt]: 	Test 100/512. loss: 1.012, 0.1957 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 10:19:13 visual_prompt]: 	Test 200/512. loss: 0.917, 0.1852 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 10:19:32 visual_prompt]: 	Test 300/512. loss: 0.825, 0.1850 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 10:19:52 visual_prompt]: 	Test 400/512. loss: 1.272, 0.1915 s / batch. (data: 3.84e-05)max mem: 17.22442 GB 
[09/16 10:20:12 visual_prompt]: 	Test 500/512. loss: 0.894, 0.2098 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 10:20:17 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1971, average loss: 0.9453
[09/16 10:20:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.46	rocauc: 85.89	
[09/16 10:20:17 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 10:20:29 visual_prompt]: Epoch 90 / 100: avg data time: 1.95e-01, avg batch time: 0.5996, average train loss: 0.0334
[09/16 10:20:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 0.0844
[09/16 10:20:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 99.99	
[09/16 10:20:58 visual_prompt]: 	Test 100/512. loss: 1.009, 0.2528 s / batch. (data: 6.95e-02)max mem: 17.22442 GB 
[09/16 10:21:17 visual_prompt]: 	Test 200/512. loss: 0.932, 0.2006 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 10:21:37 visual_prompt]: 	Test 300/512. loss: 0.928, 0.1987 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 10:21:57 visual_prompt]: 	Test 400/512. loss: 1.109, 0.2521 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 10:22:17 visual_prompt]: 	Test 500/512. loss: 0.902, 0.2056 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 10:22:22 visual_prompt]: Inference (test):avg data time: 8.90e-03, avg batch time: 0.1971, average loss: 0.9767
[09/16 10:22:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.69	rocauc: 84.61	
[09/16 10:22:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 10:22:33 visual_prompt]: Epoch 91 / 100: avg data time: 1.82e-01, avg batch time: 0.5899, average train loss: 0.0117
[09/16 10:22:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1435, average loss: 0.0715
[09/16 10:22:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 100.00	
[09/16 10:23:02 visual_prompt]: 	Test 100/512. loss: 1.080, 0.1848 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 10:23:21 visual_prompt]: 	Test 200/512. loss: 1.031, 0.1843 s / batch. (data: 1.05e-04)max mem: 17.22442 GB 
[09/16 10:23:41 visual_prompt]: 	Test 300/512. loss: 0.959, 0.1993 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 10:24:01 visual_prompt]: 	Test 400/512. loss: 1.220, 0.1846 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 10:24:20 visual_prompt]: 	Test 500/512. loss: 0.883, 0.2063 s / batch. (data: 1.90e-02)max mem: 17.22442 GB 
[09/16 10:24:25 visual_prompt]: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1956, average loss: 1.0269
[09/16 10:24:25 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.93	rocauc: 84.77	
[09/16 10:24:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 10:24:37 visual_prompt]: Epoch 92 / 100: avg data time: 2.01e-01, avg batch time: 0.6058, average train loss: 0.0123
[09/16 10:24:43 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1437, average loss: 0.0364
[09/16 10:24:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:25:05 visual_prompt]: 	Test 100/512. loss: 1.071, 0.2076 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 10:25:25 visual_prompt]: 	Test 200/512. loss: 1.080, 0.1840 s / batch. (data: 9.23e-05)max mem: 17.22442 GB 
[09/16 10:25:45 visual_prompt]: 	Test 300/512. loss: 0.923, 0.1845 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 10:26:04 visual_prompt]: 	Test 400/512. loss: 1.177, 0.1843 s / batch. (data: 1.77e-04)max mem: 17.22442 GB 
[09/16 10:26:24 visual_prompt]: 	Test 500/512. loss: 0.860, 0.2036 s / batch. (data: 1.92e-02)max mem: 17.22442 GB 
[09/16 10:26:29 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1949, average loss: 1.0264
[09/16 10:26:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.92	rocauc: 84.60	
[09/16 10:26:29 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 10:26:41 visual_prompt]: Epoch 93 / 100: avg data time: 1.82e-01, avg batch time: 0.5893, average train loss: 0.0062
[09/16 10:26:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1433, average loss: 0.0314
[09/16 10:26:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:27:09 visual_prompt]: 	Test 100/512. loss: 1.099, 0.1879 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 10:27:29 visual_prompt]: 	Test 200/512. loss: 1.098, 0.1913 s / batch. (data: 9.68e-05)max mem: 17.22442 GB 
[09/16 10:27:48 visual_prompt]: 	Test 300/512. loss: 0.934, 0.1854 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 10:28:08 visual_prompt]: 	Test 400/512. loss: 1.188, 0.1853 s / batch. (data: 9.73e-04)max mem: 17.22442 GB 
[09/16 10:28:28 visual_prompt]: 	Test 500/512. loss: 0.892, 0.2393 s / batch. (data: 2.50e-02)max mem: 17.22442 GB 
[09/16 10:28:33 visual_prompt]: Inference (test):avg data time: 8.41e-03, avg batch time: 0.1963, average loss: 1.0433
[09/16 10:28:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.00	rocauc: 84.65	
[09/16 10:28:33 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 10:28:45 visual_prompt]: Epoch 94 / 100: avg data time: 1.90e-01, avg batch time: 0.5954, average train loss: 0.0039
[09/16 10:28:50 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1472, average loss: 0.0392
[09/16 10:28:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.00	rocauc: 100.00	
[09/16 10:29:13 visual_prompt]: 	Test 100/512. loss: 1.111, 0.1840 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 10:29:32 visual_prompt]: 	Test 200/512. loss: 1.117, 0.2046 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 10:29:52 visual_prompt]: 	Test 300/512. loss: 0.973, 0.1990 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 10:30:12 visual_prompt]: 	Test 400/512. loss: 1.226, 0.1966 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 10:30:31 visual_prompt]: 	Test 500/512. loss: 0.914, 0.1992 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 10:30:36 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1950, average loss: 1.0671
[09/16 10:30:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.11	rocauc: 84.78	
[09/16 10:30:37 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 10:30:48 visual_prompt]: Epoch 95 / 100: avg data time: 1.90e-01, avg batch time: 0.5954, average train loss: 0.0038
[09/16 10:30:54 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1436, average loss: 0.0283
[09/16 10:30:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:31:17 visual_prompt]: 	Test 100/512. loss: 1.130, 0.1840 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 10:31:37 visual_prompt]: 	Test 200/512. loss: 1.126, 0.1843 s / batch. (data: 1.71e-04)max mem: 17.22442 GB 
[09/16 10:31:56 visual_prompt]: 	Test 300/512. loss: 0.966, 0.1963 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 10:32:16 visual_prompt]: 	Test 400/512. loss: 1.215, 0.1948 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 10:32:36 visual_prompt]: 	Test 500/512. loss: 0.919, 0.2098 s / batch. (data: 2.58e-02)max mem: 17.22442 GB 
[09/16 10:32:41 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1962, average loss: 1.0723
[09/16 10:32:41 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.06	rocauc: 84.73	
[09/16 10:32:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 10:32:52 visual_prompt]: Epoch 96 / 100: avg data time: 1.93e-01, avg batch time: 0.6008, average train loss: 0.0038
[09/16 10:32:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1434, average loss: 0.0292
[09/16 10:32:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:33:21 visual_prompt]: 	Test 100/512. loss: 1.137, 0.1854 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 10:33:41 visual_prompt]: 	Test 200/512. loss: 1.131, 0.1858 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 10:34:01 visual_prompt]: 	Test 300/512. loss: 0.971, 0.1969 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 10:34:21 visual_prompt]: 	Test 400/512. loss: 1.240, 0.1991 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 10:34:40 visual_prompt]: 	Test 500/512. loss: 0.920, 0.2316 s / batch. (data: 2.57e-02)max mem: 17.22442 GB 
[09/16 10:34:45 visual_prompt]: Inference (test):avg data time: 9.29e-03, avg batch time: 0.1971, average loss: 1.0796
[09/16 10:34:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.06	rocauc: 84.79	
[09/16 10:34:45 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 10:34:57 visual_prompt]: Epoch 97 / 100: avg data time: 1.90e-01, avg batch time: 0.5955, average train loss: 0.0055
[09/16 10:35:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1435, average loss: 0.0292
[09/16 10:35:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:35:25 visual_prompt]: 	Test 100/512. loss: 1.154, 0.1930 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 10:35:45 visual_prompt]: 	Test 200/512. loss: 1.149, 0.2071 s / batch. (data: 2.35e-02)max mem: 17.22442 GB 
[09/16 10:36:05 visual_prompt]: 	Test 300/512. loss: 0.987, 0.1967 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 10:36:24 visual_prompt]: 	Test 400/512. loss: 1.239, 0.2065 s / batch. (data: 2.31e-02)max mem: 17.22442 GB 
[09/16 10:36:44 visual_prompt]: 	Test 500/512. loss: 0.938, 0.1843 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 10:36:49 visual_prompt]: Inference (test):avg data time: 8.63e-03, avg batch time: 0.1962, average loss: 1.0922
[09/16 10:36:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.93	rocauc: 84.56	
[09/16 10:36:49 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 10:37:01 visual_prompt]: Epoch 98 / 100: avg data time: 1.91e-01, avg batch time: 0.5948, average train loss: 0.0029
[09/16 10:37:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1435, average loss: 0.0319
[09/16 10:37:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:37:29 visual_prompt]: 	Test 100/512. loss: 1.160, 0.2228 s / batch. (data: 3.43e-05)max mem: 17.22442 GB 
[09/16 10:37:49 visual_prompt]: 	Test 200/512. loss: 1.161, 0.1838 s / batch. (data: 6.34e-05)max mem: 17.22442 GB 
[09/16 10:38:08 visual_prompt]: 	Test 300/512. loss: 0.999, 0.1906 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 10:38:28 visual_prompt]: 	Test 400/512. loss: 1.251, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 10:38:48 visual_prompt]: 	Test 500/512. loss: 0.939, 0.1851 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 10:38:53 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1966, average loss: 1.1006
[09/16 10:38:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.93	rocauc: 84.53	
[09/16 10:38:53 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 10:39:05 visual_prompt]: Epoch 99 / 100: avg data time: 1.97e-01, avg batch time: 0.6265, average train loss: 0.0041
[09/16 10:39:11 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1433, average loss: 0.0338
[09/16 10:39:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:39:34 visual_prompt]: 	Test 100/512. loss: 1.161, 0.1976 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 10:39:54 visual_prompt]: 	Test 200/512. loss: 1.165, 0.2058 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 10:40:13 visual_prompt]: 	Test 300/512. loss: 1.005, 0.2124 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 10:40:33 visual_prompt]: 	Test 400/512. loss: 1.258, 0.1841 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 10:40:53 visual_prompt]: 	Test 500/512. loss: 0.939, 0.1849 s / batch. (data: 9.04e-05)max mem: 17.22442 GB 
[09/16 10:40:58 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1965, average loss: 1.1039
[09/16 10:40:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.88	rocauc: 84.55	
[09/16 10:40:58 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 10:41:10 visual_prompt]: Epoch 100 / 100: avg data time: 1.96e-01, avg batch time: 0.6017, average train loss: 0.0038
[09/16 10:41:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1476, average loss: 0.0348
[09/16 10:41:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 10:41:38 visual_prompt]: 	Test 100/512. loss: 1.161, 0.2108 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 10:41:58 visual_prompt]: 	Test 200/512. loss: 1.167, 0.1948 s / batch. (data: 1.15e-02)max mem: 17.22442 GB 
[09/16 10:42:18 visual_prompt]: 	Test 300/512. loss: 1.008, 0.1864 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 10:42:37 visual_prompt]: 	Test 400/512. loss: 1.260, 0.1847 s / batch. (data: 9.11e-05)max mem: 17.22442 GB 
[09/16 10:42:57 visual_prompt]: 	Test 500/512. loss: 0.938, 0.1842 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 10:43:02 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1953, average loss: 1.1048
[09/16 10:43:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.91	rocauc: 84.56	
[09/16 10:43:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 10:43:27 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 10:43:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-patch_camelyon', 'DATA.NUMBER_CLASSES', '2', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/16 10:43:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 10:43:27 visual_prompt]: Training with config:
[09/16 10:43:27 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-patch_camelyon',
          'NO_TEST': False,
          'NUMBER_CLASSES': 2,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-patch_camelyon/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 10:43:27 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 10:43:27.974317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 10:43:28.166883: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 10:43:29.058111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 10:43:29.058189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 10:43:29.058199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 10:43:31.045832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 10:43:31.045952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 10:43:31.045967: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 10:43:31 visual_prompt]: Constructing vtab-patch_camelyon dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
2023-09-16 10:43:31.279903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 10:43:33 visual_prompt]: Number of images: 1000
[09/16 10:43:33 visual_prompt]: Number of classes: 2 / 2
[09/16 10:43:33 visual_prompt]: Loading validation data...
[09/16 10:43:33 visual_prompt]: Constructing vtab-patch_camelyon dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 10:43:33 visual_prompt]: Number of images: 200
[09/16 10:43:33 visual_prompt]: Number of classes: 2 / 2
[09/16 10:43:33 visual_prompt]: Loading test data...
[09/16 10:43:33 visual_prompt]: Constructing vtab-patch_camelyon dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split test, from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 10:44:22 visual_prompt]: Number of images: 32768
[09/16 10:44:22 visual_prompt]: Number of classes: 2 / 2
[09/16 10:44:22 visual_prompt]: Constructing models...
[09/16 10:44:25 visual_prompt]: Total Parameters: 86721794	 Gradient Parameters: 923138
[09/16 10:44:25 visual_prompt]: tuned percent:1.064
[09/16 10:44:27 visual_prompt]: Device used for model: 0
[09/16 10:44:27 visual_prompt]: Setting up Evalutator...
[09/16 10:44:27 visual_prompt]: Setting up Trainer...
[09/16 10:44:27 visual_prompt]: 	Setting up the optimizer...
[09/16 10:44:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 10:44:41 visual_prompt]: Epoch 1 / 100: avg data time: 2.08e-01, avg batch time: 0.6817, average train loss: 3.2926
[09/16 10:44:46 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1427, average loss: 3.3812
[09/16 10:44:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 33.58	
[09/16 10:45:09 visual_prompt]: 	Test 100/512. loss: 3.132, 0.1904 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 10:45:29 visual_prompt]: 	Test 200/512. loss: 3.119, 0.1836 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 10:45:48 visual_prompt]: 	Test 300/512. loss: 2.899, 0.1848 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 10:46:08 visual_prompt]: 	Test 400/512. loss: 3.391, 0.2198 s / batch. (data: 3.37e-02)max mem: 17.22442 GB 
[09/16 10:46:27 visual_prompt]: 	Test 500/512. loss: 3.353, 0.2047 s / batch. (data: 2.10e-02)max mem: 17.22442 GB 
[09/16 10:46:32 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1953, average loss: 3.2453
[09/16 10:46:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 35.22	
[09/16 10:46:32 visual_prompt]: Best epoch 1: best metric: 0.480
[09/16 10:46:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 10:46:44 visual_prompt]: Epoch 2 / 100: avg data time: 1.83e-01, avg batch time: 0.5868, average train loss: 12.2591
[09/16 10:46:49 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1434, average loss: 1.0220
[09/16 10:46:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 56.46	
[09/16 10:47:12 visual_prompt]: 	Test 100/512. loss: 1.101, 0.1999 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 10:47:31 visual_prompt]: 	Test 200/512. loss: 1.100, 0.2021 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 10:47:51 visual_prompt]: 	Test 300/512. loss: 1.196, 0.1982 s / batch. (data: 1.34e-02)max mem: 17.22442 GB 
[09/16 10:48:10 visual_prompt]: 	Test 400/512. loss: 1.013, 0.1993 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 10:48:30 visual_prompt]: 	Test 500/512. loss: 1.052, 0.1847 s / batch. (data: 1.71e-04)max mem: 17.22442 GB 
[09/16 10:48:35 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1953, average loss: 1.0720
[09/16 10:48:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 51.42	
[09/16 10:48:35 visual_prompt]: Best epoch 2: best metric: 0.520
[09/16 10:48:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 10:48:47 visual_prompt]: Epoch 3 / 100: avg data time: 1.78e-01, avg batch time: 0.5870, average train loss: 1.6320
[09/16 10:48:53 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1433, average loss: 0.9258
[09/16 10:48:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 82.62	
[09/16 10:49:16 visual_prompt]: 	Test 100/512. loss: 1.003, 0.1929 s / batch. (data: 1.66e-04)max mem: 17.22442 GB 
[09/16 10:49:36 visual_prompt]: 	Test 200/512. loss: 1.003, 0.2157 s / batch. (data: 2.72e-02)max mem: 17.22442 GB 
[09/16 10:49:55 visual_prompt]: 	Test 300/512. loss: 1.094, 0.2306 s / batch. (data: 3.53e-05)max mem: 17.22442 GB 
[09/16 10:50:15 visual_prompt]: 	Test 400/512. loss: 0.944, 0.1955 s / batch. (data: 1.66e-04)max mem: 17.22442 GB 
[09/16 10:50:34 visual_prompt]: 	Test 500/512. loss: 0.961, 0.1851 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 10:50:39 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1961, average loss: 0.9858
[09/16 10:50:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 74.15	
[09/16 10:50:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 10:50:51 visual_prompt]: Epoch 4 / 100: avg data time: 1.89e-01, avg batch time: 0.5927, average train loss: 0.8909
[09/16 10:50:56 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1433, average loss: 0.8972
[09/16 10:50:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 60.00	rocauc: 88.51	
[09/16 10:51:19 visual_prompt]: 	Test 100/512. loss: 0.776, 0.1840 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 10:51:38 visual_prompt]: 	Test 200/512. loss: 0.906, 0.1982 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 10:51:59 visual_prompt]: 	Test 300/512. loss: 0.708, 0.1848 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 10:52:18 visual_prompt]: 	Test 400/512. loss: 0.889, 0.1982 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 10:52:38 visual_prompt]: 	Test 500/512. loss: 0.862, 0.1845 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 10:52:43 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1967, average loss: 0.8923
[09/16 10:52:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.32	rocauc: 81.99	
[09/16 10:52:43 visual_prompt]: Best epoch 4: best metric: 0.600
[09/16 10:52:43 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 10:52:55 visual_prompt]: Epoch 5 / 100: avg data time: 1.87e-01, avg batch time: 0.6240, average train loss: 1.5842
[09/16 10:53:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1434, average loss: 0.6661
[09/16 10:53:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 63.50	rocauc: 88.38	
[09/16 10:53:24 visual_prompt]: 	Test 100/512. loss: 0.624, 0.2038 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 10:53:43 visual_prompt]: 	Test 200/512. loss: 0.700, 0.1850 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 10:54:03 visual_prompt]: 	Test 300/512. loss: 0.549, 0.1846 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 10:54:22 visual_prompt]: 	Test 400/512. loss: 0.708, 0.1974 s / batch. (data: 1.37e-02)max mem: 17.22442 GB 
[09/16 10:54:42 visual_prompt]: 	Test 500/512. loss: 0.642, 0.2065 s / batch. (data: 2.29e-02)max mem: 17.22442 GB 
[09/16 10:54:47 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1950, average loss: 0.6808
[09/16 10:54:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 63.31	rocauc: 80.62	
[09/16 10:54:47 visual_prompt]: Best epoch 5: best metric: 0.635
[09/16 10:54:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 10:54:59 visual_prompt]: Epoch 6 / 100: avg data time: 1.79e-01, avg batch time: 0.5872, average train loss: 1.7636
[09/16 10:55:04 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1435, average loss: 2.4104
[09/16 10:55:04 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 57.41	
[09/16 10:55:27 visual_prompt]: 	Test 100/512. loss: 2.597, 0.1983 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 10:55:46 visual_prompt]: 	Test 200/512. loss: 2.578, 0.2394 s / batch. (data: 3.06e-04)max mem: 17.22442 GB 
[09/16 10:56:06 visual_prompt]: 	Test 300/512. loss: 2.834, 0.1960 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 10:56:26 visual_prompt]: 	Test 400/512. loss: 2.378, 0.2152 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 10:56:45 visual_prompt]: 	Test 500/512. loss: 2.421, 0.2000 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 10:56:50 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1956, average loss: 2.5313
[09/16 10:56:50 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 60.32	
[09/16 10:56:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 10:57:02 visual_prompt]: Epoch 7 / 100: avg data time: 1.83e-01, avg batch time: 0.6357, average train loss: 7.8762
[09/16 10:57:08 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1435, average loss: 1.2807
[09/16 10:57:08 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 80.40	
[09/16 10:57:31 visual_prompt]: 	Test 100/512. loss: 1.195, 0.1837 s / batch. (data: 5.03e-05)max mem: 17.22442 GB 
[09/16 10:57:50 visual_prompt]: 	Test 200/512. loss: 1.207, 0.1859 s / batch. (data: 3.74e-05)max mem: 17.22442 GB 
[09/16 10:58:10 visual_prompt]: 	Test 300/512. loss: 1.079, 0.2000 s / batch. (data: 1.67e-02)max mem: 17.22442 GB 
[09/16 10:58:29 visual_prompt]: 	Test 400/512. loss: 1.316, 0.2148 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 10:58:49 visual_prompt]: 	Test 500/512. loss: 1.272, 0.1937 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 10:58:54 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1949, average loss: 1.2407
[09/16 10:58:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 73.60	
[09/16 10:58:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 10:59:06 visual_prompt]: Epoch 8 / 100: avg data time: 1.98e-01, avg batch time: 0.6025, average train loss: 6.9974
[09/16 10:59:11 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1433, average loss: 10.1276
[09/16 10:59:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 78.80	
[09/16 10:59:34 visual_prompt]: 	Test 100/512. loss: 9.424, 0.2131 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 10:59:53 visual_prompt]: 	Test 200/512. loss: 9.457, 0.1958 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 11:00:13 visual_prompt]: 	Test 300/512. loss: 8.502, 0.1835 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 11:00:32 visual_prompt]: 	Test 400/512. loss: 10.321, 0.1871 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 11:00:52 visual_prompt]: 	Test 500/512. loss: 10.034, 0.1878 s / batch. (data: 1.66e-04)max mem: 17.22442 GB 
[09/16 11:00:57 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1945, average loss: 9.7385
[09/16 11:00:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 67.97	
[09/16 11:00:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 11:01:08 visual_prompt]: Epoch 9 / 100: avg data time: 1.91e-01, avg batch time: 0.5943, average train loss: 5.2058
[09/16 11:01:14 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1434, average loss: 3.6203
[09/16 11:01:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 54.00	rocauc: 78.43	
[09/16 11:01:36 visual_prompt]: 	Test 100/512. loss: 4.183, 0.1925 s / batch. (data: 1.06e-04)max mem: 17.22442 GB 
[09/16 11:01:57 visual_prompt]: 	Test 200/512. loss: 4.105, 0.1839 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 11:02:16 visual_prompt]: 	Test 300/512. loss: 4.350, 0.1840 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 11:02:36 visual_prompt]: 	Test 400/512. loss: 3.797, 0.1983 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 11:02:55 visual_prompt]: 	Test 500/512. loss: 3.867, 0.2000 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 11:03:00 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1965, average loss: 3.8940
[09/16 11:03:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 51.30	rocauc: 76.25	
[09/16 11:03:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 11:03:12 visual_prompt]: Epoch 10 / 100: avg data time: 1.88e-01, avg batch time: 0.5917, average train loss: 8.8651
[09/16 11:03:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1435, average loss: 18.8501
[09/16 11:03:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 81.25	
[09/16 11:03:40 visual_prompt]: 	Test 100/512. loss: 17.554, 0.2030 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 11:04:00 visual_prompt]: 	Test 200/512. loss: 17.569, 0.2081 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 11:04:19 visual_prompt]: 	Test 300/512. loss: 15.851, 0.1895 s / batch. (data: 3.29e-05)max mem: 17.22442 GB 
[09/16 11:04:39 visual_prompt]: 	Test 400/512. loss: 19.262, 0.1846 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 11:04:59 visual_prompt]: 	Test 500/512. loss: 18.688, 0.2020 s / batch. (data: 1.70e-04)max mem: 17.22442 GB 
[09/16 11:05:04 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1960, average loss: 18.1336
[09/16 11:05:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 72.25	
[09/16 11:05:04 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 11:05:15 visual_prompt]: Epoch 11 / 100: avg data time: 1.90e-01, avg batch time: 0.5934, average train loss: 7.9518
[09/16 11:05:21 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1434, average loss: 8.4782
[09/16 11:05:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 78.65	
[09/16 11:05:44 visual_prompt]: 	Test 100/512. loss: 9.109, 0.2152 s / batch. (data: 3.25e-02)max mem: 17.22442 GB 
[09/16 11:06:04 visual_prompt]: 	Test 200/512. loss: 9.105, 0.2081 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 11:06:23 visual_prompt]: 	Test 300/512. loss: 9.939, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 11:06:43 visual_prompt]: 	Test 400/512. loss: 8.289, 0.1847 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 11:07:03 visual_prompt]: 	Test 500/512. loss: 8.560, 0.1974 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 11:07:08 visual_prompt]: Inference (test):avg data time: 8.58e-03, avg batch time: 0.1963, average loss: 8.8306
[09/16 11:07:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 74.21	
[09/16 11:07:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 11:07:20 visual_prompt]: Epoch 12 / 100: avg data time: 1.95e-01, avg batch time: 0.5999, average train loss: 6.0547
[09/16 11:07:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1431, average loss: 3.2389
[09/16 11:07:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 79.54	
[09/16 11:07:48 visual_prompt]: 	Test 100/512. loss: 3.480, 0.1940 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 11:08:08 visual_prompt]: 	Test 200/512. loss: 3.469, 0.2006 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 11:08:27 visual_prompt]: 	Test 300/512. loss: 3.813, 0.1957 s / batch. (data: 1.21e-02)max mem: 17.22442 GB 
[09/16 11:08:47 visual_prompt]: 	Test 400/512. loss: 3.197, 0.1982 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 11:09:06 visual_prompt]: 	Test 500/512. loss: 3.281, 0.2113 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 11:09:11 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1954, average loss: 3.3839
[09/16 11:09:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 74.47	
[09/16 11:09:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 11:09:23 visual_prompt]: Epoch 13 / 100: avg data time: 1.88e-01, avg batch time: 0.5950, average train loss: 4.4007
[09/16 11:09:29 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1433, average loss: 3.2728
[09/16 11:09:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 60.58	
[09/16 11:09:51 visual_prompt]: 	Test 100/512. loss: 3.151, 0.1956 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 11:10:11 visual_prompt]: 	Test 200/512. loss: 3.045, 0.2200 s / batch. (data: 3.65e-02)max mem: 17.22442 GB 
[09/16 11:10:30 visual_prompt]: 	Test 300/512. loss: 2.839, 0.1962 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 11:10:50 visual_prompt]: 	Test 400/512. loss: 3.366, 0.2074 s / batch. (data: 7.59e-03)max mem: 17.22442 GB 
[09/16 11:11:09 visual_prompt]: 	Test 500/512. loss: 3.245, 0.1844 s / batch. (data: 9.25e-05)max mem: 17.22442 GB 
[09/16 11:11:14 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1948, average loss: 3.1510
[09/16 11:11:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 58.94	
[09/16 11:11:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 11:11:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.93e-01, avg batch time: 0.5968, average train loss: 2.0939
[09/16 11:11:32 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1435, average loss: 1.6109
[09/16 11:11:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 82.37	
[09/16 11:11:54 visual_prompt]: 	Test 100/512. loss: 1.733, 0.1848 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 11:12:14 visual_prompt]: 	Test 200/512. loss: 1.733, 0.1831 s / batch. (data: 3.50e-05)max mem: 17.22442 GB 
[09/16 11:12:33 visual_prompt]: 	Test 300/512. loss: 1.893, 0.1835 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 11:12:53 visual_prompt]: 	Test 400/512. loss: 1.585, 0.2248 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 11:13:13 visual_prompt]: 	Test 500/512. loss: 1.635, 0.1977 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 11:13:18 visual_prompt]: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1949, average loss: 1.6836
[09/16 11:13:18 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 75.88	
[09/16 11:13:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 11:13:29 visual_prompt]: Epoch 15 / 100: avg data time: 1.86e-01, avg batch time: 0.5906, average train loss: 2.5449
[09/16 11:13:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1433, average loss: 3.7384
[09/16 11:13:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 77.76	
[09/16 11:13:58 visual_prompt]: 	Test 100/512. loss: 3.463, 0.2186 s / batch. (data: 2.45e-04)max mem: 17.22442 GB 
[09/16 11:14:17 visual_prompt]: 	Test 200/512. loss: 3.479, 0.2039 s / batch. (data: 2.06e-02)max mem: 17.22442 GB 
[09/16 11:14:38 visual_prompt]: 	Test 300/512. loss: 3.130, 0.2136 s / batch. (data: 5.32e-05)max mem: 17.22442 GB 
[09/16 11:14:57 visual_prompt]: 	Test 400/512. loss: 3.816, 0.2148 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:15:17 visual_prompt]: 	Test 500/512. loss: 3.702, 0.2079 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 11:15:22 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1972, average loss: 3.5927
[09/16 11:15:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 69.78	
[09/16 11:15:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 11:15:34 visual_prompt]: Epoch 16 / 100: avg data time: 1.95e-01, avg batch time: 0.5992, average train loss: 2.1496
[09/16 11:15:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1434, average loss: 0.8474
[09/16 11:15:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 77.85	
[09/16 11:16:02 visual_prompt]: 	Test 100/512. loss: 0.804, 0.2041 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 11:16:22 visual_prompt]: 	Test 200/512. loss: 0.810, 0.1847 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 11:16:42 visual_prompt]: 	Test 300/512. loss: 0.752, 0.1843 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 11:17:01 visual_prompt]: 	Test 400/512. loss: 0.861, 0.2060 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 11:17:21 visual_prompt]: 	Test 500/512. loss: 0.841, 0.1889 s / batch. (data: 1.07e-04)max mem: 17.22442 GB 
[09/16 11:17:26 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1951, average loss: 0.8268
[09/16 11:17:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 71.90	
[09/16 11:17:26 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 11:17:38 visual_prompt]: Epoch 17 / 100: avg data time: 1.82e-01, avg batch time: 0.5884, average train loss: 1.9908
[09/16 11:17:43 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1434, average loss: 4.7558
[09/16 11:17:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 79.68	
[09/16 11:18:06 visual_prompt]: 	Test 100/512. loss: 5.111, 0.1861 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 11:18:25 visual_prompt]: 	Test 200/512. loss: 5.107, 0.1842 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 11:18:45 visual_prompt]: 	Test 300/512. loss: 5.566, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 11:19:04 visual_prompt]: 	Test 400/512. loss: 4.645, 0.1990 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 11:19:24 visual_prompt]: 	Test 500/512. loss: 4.798, 0.1950 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 11:19:29 visual_prompt]: Inference (test):avg data time: 8.47e-03, avg batch time: 0.1946, average loss: 4.9496
[09/16 11:19:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 75.92	
[09/16 11:19:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 11:19:41 visual_prompt]: Epoch 18 / 100: avg data time: 1.97e-01, avg batch time: 0.6000, average train loss: 2.5594
[09/16 11:19:46 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1431, average loss: 0.7125
[09/16 11:19:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 68.20	
[09/16 11:20:09 visual_prompt]: 	Test 100/512. loss: 0.710, 0.1842 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 11:20:28 visual_prompt]: 	Test 200/512. loss: 0.704, 0.1869 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 11:20:48 visual_prompt]: 	Test 300/512. loss: 0.682, 0.1845 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 11:21:08 visual_prompt]: 	Test 400/512. loss: 0.722, 0.1960 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 11:21:28 visual_prompt]: 	Test 500/512. loss: 0.712, 0.1853 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 11:21:33 visual_prompt]: Inference (test):avg data time: 9.02e-03, avg batch time: 0.1962, average loss: 0.7064
[09/16 11:21:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 65.60	
[09/16 11:21:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 11:21:45 visual_prompt]: Epoch 19 / 100: avg data time: 1.98e-01, avg batch time: 0.6017, average train loss: 1.4581
[09/16 11:21:51 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1433, average loss: 2.0091
[09/16 11:21:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 68.83	
[09/16 11:22:13 visual_prompt]: 	Test 100/512. loss: 1.889, 0.2052 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 11:22:33 visual_prompt]: 	Test 200/512. loss: 1.885, 0.1997 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 11:22:52 visual_prompt]: 	Test 300/512. loss: 1.699, 0.1985 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 11:23:12 visual_prompt]: 	Test 400/512. loss: 2.068, 0.1864 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 11:23:31 visual_prompt]: 	Test 500/512. loss: 1.999, 0.1841 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 11:23:36 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1950, average loss: 1.9406
[09/16 11:23:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 66.11	
[09/16 11:23:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 11:23:48 visual_prompt]: Epoch 20 / 100: avg data time: 1.99e-01, avg batch time: 0.6019, average train loss: 1.4455
[09/16 11:23:54 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1434, average loss: 0.6962
[09/16 11:23:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 78.76	
[09/16 11:24:16 visual_prompt]: 	Test 100/512. loss: 0.719, 0.1958 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 11:24:36 visual_prompt]: 	Test 200/512. loss: 0.737, 0.1963 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 11:24:56 visual_prompt]: 	Test 300/512. loss: 0.779, 0.1994 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:25:15 visual_prompt]: 	Test 400/512. loss: 0.708, 0.2120 s / batch. (data: 2.84e-02)max mem: 17.22442 GB 
[09/16 11:25:35 visual_prompt]: 	Test 500/512. loss: 0.713, 0.1962 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 11:25:40 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1950, average loss: 0.7299
[09/16 11:25:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 68.66	
[09/16 11:25:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 11:25:52 visual_prompt]: Epoch 21 / 100: avg data time: 1.83e-01, avg batch time: 0.5853, average train loss: 0.8655
[09/16 11:25:57 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1451, average loss: 0.9005
[09/16 11:25:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 54.00	rocauc: 89.99	
[09/16 11:26:20 visual_prompt]: 	Test 100/512. loss: 0.781, 0.1838 s / batch. (data: 9.25e-05)max mem: 17.22442 GB 
[09/16 11:26:40 visual_prompt]: 	Test 200/512. loss: 0.895, 0.1962 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 11:27:00 visual_prompt]: 	Test 300/512. loss: 0.749, 0.2086 s / batch. (data: 2.48e-02)max mem: 17.22442 GB 
[09/16 11:27:20 visual_prompt]: 	Test 400/512. loss: 0.915, 0.1842 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 11:27:39 visual_prompt]: 	Test 500/512. loss: 0.876, 0.1854 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 11:27:44 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1967, average loss: 0.8808
[09/16 11:27:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 54.95	rocauc: 80.48	
[09/16 11:27:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 11:27:56 visual_prompt]: Epoch 22 / 100: avg data time: 1.90e-01, avg batch time: 0.5950, average train loss: 1.5834
[09/16 11:28:02 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1431, average loss: 0.7439
[09/16 11:28:02 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.50	rocauc: 89.29	
[09/16 11:28:24 visual_prompt]: 	Test 100/512. loss: 0.709, 0.1959 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 11:28:44 visual_prompt]: 	Test 200/512. loss: 0.729, 0.1953 s / batch. (data: 1.17e-02)max mem: 17.22442 GB 
[09/16 11:29:03 visual_prompt]: 	Test 300/512. loss: 0.681, 0.1837 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 11:29:23 visual_prompt]: 	Test 400/512. loss: 0.757, 0.1961 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 11:29:42 visual_prompt]: 	Test 500/512. loss: 0.738, 0.1844 s / batch. (data: 4.86e-05)max mem: 17.22442 GB 
[09/16 11:29:47 visual_prompt]: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1946, average loss: 0.7333
[09/16 11:29:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.30	rocauc: 80.85	
[09/16 11:29:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 11:29:59 visual_prompt]: Epoch 23 / 100: avg data time: 1.94e-01, avg batch time: 0.6006, average train loss: 0.8310
[09/16 11:30:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1434, average loss: 0.5178
[09/16 11:30:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 70.50	rocauc: 90.42	
[09/16 11:30:28 visual_prompt]: 	Test 100/512. loss: 0.562, 0.1999 s / batch. (data: 1.70e-02)max mem: 17.22442 GB 
[09/16 11:30:47 visual_prompt]: 	Test 200/512. loss: 0.627, 0.2075 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 11:31:07 visual_prompt]: 	Test 300/512. loss: 0.566, 0.1849 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 11:31:26 visual_prompt]: 	Test 400/512. loss: 0.607, 0.2103 s / batch. (data: 6.29e-05)max mem: 17.22442 GB 
[09/16 11:31:46 visual_prompt]: 	Test 500/512. loss: 0.535, 0.1942 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 11:31:51 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1943, average loss: 0.5971
[09/16 11:31:51 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 67.57	rocauc: 78.15	
[09/16 11:31:51 visual_prompt]: Best epoch 23: best metric: 0.705
[09/16 11:31:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 11:32:03 visual_prompt]: Epoch 24 / 100: avg data time: 1.93e-01, avg batch time: 0.5977, average train loss: 1.5871
[09/16 11:32:08 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1472, average loss: 0.6859
[09/16 11:32:08 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 68.00	rocauc: 88.83	
[09/16 11:32:31 visual_prompt]: 	Test 100/512. loss: 0.768, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 11:32:50 visual_prompt]: 	Test 200/512. loss: 0.914, 0.1988 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 11:33:10 visual_prompt]: 	Test 300/512. loss: 0.742, 0.1853 s / batch. (data: 9.27e-05)max mem: 17.22442 GB 
[09/16 11:33:30 visual_prompt]: 	Test 400/512. loss: 0.854, 0.1999 s / batch. (data: 1.65e-02)max mem: 17.22442 GB 
[09/16 11:33:50 visual_prompt]: 	Test 500/512. loss: 0.800, 0.1997 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 11:33:55 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1959, average loss: 0.8363
[09/16 11:33:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.73	rocauc: 77.91	
[09/16 11:33:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 11:34:07 visual_prompt]: Epoch 25 / 100: avg data time: 1.87e-01, avg batch time: 0.5906, average train loss: 1.8429
[09/16 11:34:12 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1436, average loss: 0.7125
[09/16 11:34:12 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 54.50	rocauc: 89.44	
[09/16 11:34:35 visual_prompt]: 	Test 100/512. loss: 0.667, 0.1983 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:34:55 visual_prompt]: 	Test 200/512. loss: 0.730, 0.1926 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 11:35:14 visual_prompt]: 	Test 300/512. loss: 0.623, 0.1988 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:35:34 visual_prompt]: 	Test 400/512. loss: 0.733, 0.1878 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 11:35:53 visual_prompt]: 	Test 500/512. loss: 0.697, 0.1853 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 11:35:58 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1953, average loss: 0.7121
[09/16 11:35:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 54.40	rocauc: 81.12	
[09/16 11:35:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 11:36:10 visual_prompt]: Epoch 26 / 100: avg data time: 1.97e-01, avg batch time: 0.6011, average train loss: 0.8761
[09/16 11:36:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1431, average loss: 1.0095
[09/16 11:36:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 57.00	rocauc: 90.76	
[09/16 11:36:39 visual_prompt]: 	Test 100/512. loss: 0.846, 0.2015 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 11:36:58 visual_prompt]: 	Test 200/512. loss: 1.052, 0.2238 s / batch. (data: 4.04e-02)max mem: 17.22442 GB 
[09/16 11:37:18 visual_prompt]: 	Test 300/512. loss: 0.749, 0.1845 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 11:37:37 visual_prompt]: 	Test 400/512. loss: 1.075, 0.2221 s / batch. (data: 3.88e-02)max mem: 17.22442 GB 
[09/16 11:37:57 visual_prompt]: 	Test 500/512. loss: 0.932, 0.1845 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 11:38:02 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1957, average loss: 0.9847
[09/16 11:38:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 58.36	rocauc: 82.11	
[09/16 11:38:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 11:38:14 visual_prompt]: Epoch 27 / 100: avg data time: 2.01e-01, avg batch time: 0.6034, average train loss: 0.9753
[09/16 11:38:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1433, average loss: 0.6775
[09/16 11:38:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 61.00	rocauc: 90.63	
[09/16 11:38:42 visual_prompt]: 	Test 100/512. loss: 0.604, 0.1939 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 11:39:02 visual_prompt]: 	Test 200/512. loss: 0.720, 0.1839 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 11:39:21 visual_prompt]: 	Test 300/512. loss: 0.556, 0.1917 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 11:39:41 visual_prompt]: 	Test 400/512. loss: 0.737, 0.1849 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 11:40:01 visual_prompt]: 	Test 500/512. loss: 0.649, 0.1988 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 11:40:06 visual_prompt]: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1955, average loss: 0.6836
[09/16 11:40:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 61.00	rocauc: 82.85	
[09/16 11:40:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 11:40:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.91e-01, avg batch time: 0.5941, average train loss: 1.0306
[09/16 11:40:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1434, average loss: 0.5411
[09/16 11:40:23 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 71.50	rocauc: 90.88	
[09/16 11:40:46 visual_prompt]: 	Test 100/512. loss: 0.547, 0.1865 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 11:41:06 visual_prompt]: 	Test 200/512. loss: 0.682, 0.1949 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 11:41:25 visual_prompt]: 	Test 300/512. loss: 0.457, 0.2323 s / batch. (data: 4.81e-02)max mem: 17.22442 GB 
[09/16 11:41:45 visual_prompt]: 	Test 400/512. loss: 0.718, 0.1871 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 11:42:04 visual_prompt]: 	Test 500/512. loss: 0.523, 0.1998 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 11:42:09 visual_prompt]: Inference (test):avg data time: 9.11e-03, avg batch time: 0.1954, average loss: 0.5908
[09/16 11:42:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.50	rocauc: 82.67	
[09/16 11:42:09 visual_prompt]: Best epoch 28: best metric: 0.715
[09/16 11:42:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 11:42:21 visual_prompt]: Epoch 29 / 100: avg data time: 1.92e-01, avg batch time: 0.5974, average train loss: 1.1354
[09/16 11:42:28 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3496, average loss: 1.1989
[09/16 11:42:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 62.00	rocauc: 91.44	
[09/16 11:42:50 visual_prompt]: 	Test 100/512. loss: 1.050, 0.1830 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 11:43:10 visual_prompt]: 	Test 200/512. loss: 1.278, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:43:29 visual_prompt]: 	Test 300/512. loss: 0.822, 0.1965 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 11:43:49 visual_prompt]: 	Test 400/512. loss: 1.272, 0.2309 s / batch. (data: 3.50e-02)max mem: 17.22442 GB 
[09/16 11:44:08 visual_prompt]: 	Test 500/512. loss: 1.068, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 11:44:13 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1951, average loss: 1.1802
[09/16 11:44:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.16	rocauc: 83.40	
[09/16 11:44:13 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 11:44:25 visual_prompt]: Epoch 30 / 100: avg data time: 1.91e-01, avg batch time: 0.5927, average train loss: 0.7761
[09/16 11:44:31 visual_prompt]: Inference (val):avg data time: 3.14e-04, avg batch time: 0.2435, average loss: 0.4825
[09/16 11:44:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 77.50	rocauc: 91.91	
[09/16 11:44:54 visual_prompt]: 	Test 100/512. loss: 0.675, 0.1907 s / batch. (data: 3.70e-05)max mem: 17.22442 GB 
[09/16 11:45:14 visual_prompt]: 	Test 200/512. loss: 0.728, 0.1959 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 11:45:33 visual_prompt]: 	Test 300/512. loss: 0.661, 0.1960 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 11:45:53 visual_prompt]: 	Test 400/512. loss: 0.689, 0.1849 s / batch. (data: 8.92e-05)max mem: 17.22442 GB 
[09/16 11:46:12 visual_prompt]: 	Test 500/512. loss: 0.594, 0.1989 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:46:17 visual_prompt]: Inference (test):avg data time: 8.75e-03, avg batch time: 0.1951, average loss: 0.6651
[09/16 11:46:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.00	rocauc: 83.18	
[09/16 11:46:17 visual_prompt]: Best epoch 30: best metric: 0.775
[09/16 11:46:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 11:46:29 visual_prompt]: Epoch 31 / 100: avg data time: 1.99e-01, avg batch time: 0.6030, average train loss: 0.6824
[09/16 11:46:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1431, average loss: 1.3356
[09/16 11:46:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 92.62	
[09/16 11:46:57 visual_prompt]: 	Test 100/512. loss: 1.685, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 11:47:17 visual_prompt]: 	Test 200/512. loss: 1.745, 0.1861 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 11:47:37 visual_prompt]: 	Test 300/512. loss: 1.859, 0.1976 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 11:47:57 visual_prompt]: 	Test 400/512. loss: 1.605, 0.1964 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 11:48:16 visual_prompt]: 	Test 500/512. loss: 1.579, 0.1844 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 11:48:21 visual_prompt]: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1959, average loss: 1.6820
[09/16 11:48:21 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 84.94	
[09/16 11:48:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 11:48:34 visual_prompt]: Epoch 32 / 100: avg data time: 1.99e-01, avg batch time: 0.6494, average train loss: 0.5947
[09/16 11:48:40 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1434, average loss: 0.4417
[09/16 11:48:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 92.62	
[09/16 11:49:02 visual_prompt]: 	Test 100/512. loss: 0.609, 0.1979 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 11:49:22 visual_prompt]: 	Test 200/512. loss: 0.645, 0.1984 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:49:42 visual_prompt]: 	Test 300/512. loss: 0.579, 0.1999 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 11:50:01 visual_prompt]: 	Test 400/512. loss: 0.620, 0.1998 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:50:21 visual_prompt]: 	Test 500/512. loss: 0.538, 0.1835 s / batch. (data: 3.17e-05)max mem: 17.22442 GB 
[09/16 11:50:26 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1956, average loss: 0.5975
[09/16 11:50:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.33	rocauc: 84.29	
[09/16 11:50:26 visual_prompt]: Best epoch 32: best metric: 0.825
[09/16 11:50:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 11:50:37 visual_prompt]: Epoch 33 / 100: avg data time: 1.84e-01, avg batch time: 0.5902, average train loss: 0.4965
[09/16 11:50:43 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1433, average loss: 0.3717
[09/16 11:50:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 93.07	
[09/16 11:51:06 visual_prompt]: 	Test 100/512. loss: 0.602, 0.2059 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 11:51:26 visual_prompt]: 	Test 200/512. loss: 0.627, 0.2108 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 11:51:45 visual_prompt]: 	Test 300/512. loss: 0.519, 0.1842 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 11:52:05 visual_prompt]: 	Test 400/512. loss: 0.631, 0.1926 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 11:52:24 visual_prompt]: 	Test 500/512. loss: 0.516, 0.1845 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 11:52:29 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1954, average loss: 0.5673
[09/16 11:52:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.38	rocauc: 85.10	
[09/16 11:52:29 visual_prompt]: Best epoch 33: best metric: 0.850
[09/16 11:52:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 11:52:41 visual_prompt]: Epoch 34 / 100: avg data time: 1.90e-01, avg batch time: 0.5948, average train loss: 0.5539
[09/16 11:52:46 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1436, average loss: 0.4102
[09/16 11:52:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 79.50	rocauc: 92.64	
[09/16 11:53:09 visual_prompt]: 	Test 100/512. loss: 0.486, 0.1964 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 11:53:28 visual_prompt]: 	Test 200/512. loss: 0.565, 0.1957 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 11:53:48 visual_prompt]: 	Test 300/512. loss: 0.430, 0.1852 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 11:54:08 visual_prompt]: 	Test 400/512. loss: 0.585, 0.1845 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 11:54:28 visual_prompt]: 	Test 500/512. loss: 0.444, 0.1992 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 11:54:33 visual_prompt]: Inference (test):avg data time: 8.94e-03, avg batch time: 0.1958, average loss: 0.5091
[09/16 11:54:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.31	rocauc: 84.03	
[09/16 11:54:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 11:54:44 visual_prompt]: Epoch 35 / 100: avg data time: 1.95e-01, avg batch time: 0.6000, average train loss: 1.1864
[09/16 11:54:50 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1433, average loss: 1.2268
[09/16 11:54:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 90.26	
[09/16 11:55:13 visual_prompt]: 	Test 100/512. loss: 1.329, 0.1945 s / batch. (data: 1.14e-02)max mem: 17.22442 GB 
[09/16 11:55:32 visual_prompt]: 	Test 200/512. loss: 1.336, 0.1936 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 11:55:52 visual_prompt]: 	Test 300/512. loss: 1.458, 0.1877 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 11:56:12 visual_prompt]: 	Test 400/512. loss: 1.231, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 11:56:31 visual_prompt]: 	Test 500/512. loss: 1.260, 0.1962 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 11:56:36 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1958, average loss: 1.3020
[09/16 11:56:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 79.77	
[09/16 11:56:36 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 11:56:48 visual_prompt]: Epoch 36 / 100: avg data time: 1.80e-01, avg batch time: 0.5842, average train loss: 1.1820
[09/16 11:56:53 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1436, average loss: 2.3457
[09/16 11:56:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 89.79	
[09/16 11:57:16 visual_prompt]: 	Test 100/512. loss: 2.183, 0.1917 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 11:57:35 visual_prompt]: 	Test 200/512. loss: 2.225, 0.1868 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 11:57:55 visual_prompt]: 	Test 300/512. loss: 1.956, 0.1960 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 11:58:15 visual_prompt]: 	Test 400/512. loss: 2.377, 0.1985 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 11:58:34 visual_prompt]: 	Test 500/512. loss: 2.305, 0.1844 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 11:58:39 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1949, average loss: 2.2602
[09/16 11:58:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 79.42	
[09/16 11:58:39 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 11:58:51 visual_prompt]: Epoch 37 / 100: avg data time: 1.83e-01, avg batch time: 0.5910, average train loss: 1.1560
[09/16 11:58:57 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1436, average loss: 0.5451
[09/16 11:58:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 75.00	rocauc: 90.37	
[09/16 11:59:19 visual_prompt]: 	Test 100/512. loss: 0.545, 0.1977 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 11:59:39 visual_prompt]: 	Test 200/512. loss: 0.596, 0.1960 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 11:59:58 visual_prompt]: 	Test 300/512. loss: 0.546, 0.1930 s / batch. (data: 9.28e-03)max mem: 17.22442 GB 
[09/16 12:00:18 visual_prompt]: 	Test 400/512. loss: 0.596, 0.1842 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 12:00:37 visual_prompt]: 	Test 500/512. loss: 0.559, 0.1991 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 12:00:42 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1943, average loss: 0.5821
[09/16 12:00:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.07	rocauc: 82.20	
[09/16 12:00:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 12:00:54 visual_prompt]: Epoch 38 / 100: avg data time: 1.95e-01, avg batch time: 0.5988, average train loss: 1.9050
[09/16 12:01:00 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1433, average loss: 3.1364
[09/16 12:01:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 61.27	
[09/16 12:01:22 visual_prompt]: 	Test 100/512. loss: 2.926, 0.1841 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 12:01:42 visual_prompt]: 	Test 200/512. loss: 2.923, 0.2111 s / batch. (data: 2.61e-02)max mem: 17.22442 GB 
[09/16 12:02:01 visual_prompt]: 	Test 300/512. loss: 2.641, 0.2300 s / batch. (data: 4.71e-02)max mem: 17.22442 GB 
[09/16 12:02:21 visual_prompt]: 	Test 400/512. loss: 3.209, 0.1916 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 12:02:41 visual_prompt]: 	Test 500/512. loss: 3.110, 0.2028 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 12:02:46 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1949, average loss: 3.0195
[09/16 12:02:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 60.40	
[09/16 12:02:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 12:02:58 visual_prompt]: Epoch 39 / 100: avg data time: 1.96e-01, avg batch time: 0.5990, average train loss: 2.9307
[09/16 12:03:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1435, average loss: 1.4035
[09/16 12:03:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 52.37	
[09/16 12:03:26 visual_prompt]: 	Test 100/512. loss: 1.505, 0.2003 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 12:03:45 visual_prompt]: 	Test 200/512. loss: 1.503, 0.2078 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 12:04:05 visual_prompt]: 	Test 300/512. loss: 1.640, 0.2042 s / batch. (data: 2.05e-02)max mem: 17.22442 GB 
[09/16 12:04:25 visual_prompt]: 	Test 400/512. loss: 1.376, 0.1854 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 12:04:44 visual_prompt]: 	Test 500/512. loss: 1.419, 0.1849 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 12:04:49 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1957, average loss: 1.4616
[09/16 12:04:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 53.24	
[09/16 12:04:49 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 12:05:01 visual_prompt]: Epoch 40 / 100: avg data time: 1.88e-01, avg batch time: 0.5917, average train loss: 4.2598
[09/16 12:05:07 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1435, average loss: 2.0448
[09/16 12:05:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 59.81	
[09/16 12:05:29 visual_prompt]: 	Test 100/512. loss: 2.203, 0.1986 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 12:05:49 visual_prompt]: 	Test 200/512. loss: 2.202, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 12:06:09 visual_prompt]: 	Test 300/512. loss: 2.389, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 12:06:28 visual_prompt]: 	Test 400/512. loss: 2.008, 0.1864 s / batch. (data: 1.06e-04)max mem: 17.22442 GB 
[09/16 12:06:47 visual_prompt]: 	Test 500/512. loss: 2.069, 0.1976 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 12:06:53 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1949, average loss: 2.1357
[09/16 12:06:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 53.33	
[09/16 12:06:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 12:07:04 visual_prompt]: Epoch 41 / 100: avg data time: 1.93e-01, avg batch time: 0.5969, average train loss: 1.3484
[09/16 12:07:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1433, average loss: 0.7001
[09/16 12:07:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 78.17	
[09/16 12:07:33 visual_prompt]: 	Test 100/512. loss: 0.692, 0.1979 s / batch. (data: 1.00e-04)max mem: 17.22442 GB 
[09/16 12:07:52 visual_prompt]: 	Test 200/512. loss: 0.692, 0.2080 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 12:08:12 visual_prompt]: 	Test 300/512. loss: 0.677, 0.1842 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 12:08:32 visual_prompt]: 	Test 400/512. loss: 0.705, 0.1982 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 12:08:52 visual_prompt]: 	Test 500/512. loss: 0.699, 0.1849 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 12:08:56 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1958, average loss: 0.6959
[09/16 12:08:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 73.81	
[09/16 12:08:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 12:09:09 visual_prompt]: Epoch 42 / 100: avg data time: 1.98e-01, avg batch time: 0.6037, average train loss: 1.5664
[09/16 12:09:14 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1433, average loss: 1.6658
[09/16 12:09:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 82.27	
[09/16 12:09:37 visual_prompt]: 	Test 100/512. loss: 1.549, 0.2075 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 12:09:57 visual_prompt]: 	Test 200/512. loss: 1.560, 0.1982 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 12:10:17 visual_prompt]: 	Test 300/512. loss: 1.399, 0.2112 s / batch. (data: 2.78e-02)max mem: 17.22442 GB 
[09/16 12:10:36 visual_prompt]: 	Test 400/512. loss: 1.696, 0.2030 s / batch. (data: 1.93e-02)max mem: 17.22442 GB 
[09/16 12:10:56 visual_prompt]: 	Test 500/512. loss: 1.649, 0.1840 s / batch. (data: 8.44e-05)max mem: 17.22442 GB 
[09/16 12:11:01 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1962, average loss: 1.6051
[09/16 12:11:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 74.62	
[09/16 12:11:01 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 12:11:13 visual_prompt]: Epoch 43 / 100: avg data time: 1.96e-01, avg batch time: 0.6002, average train loss: 1.4929
[09/16 12:11:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1450, average loss: 1.4796
[09/16 12:11:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 79.16	
[09/16 12:11:41 visual_prompt]: 	Test 100/512. loss: 1.595, 0.1829 s / batch. (data: 3.34e-05)max mem: 17.22442 GB 
[09/16 12:12:00 visual_prompt]: 	Test 200/512. loss: 1.597, 0.1928 s / batch. (data: 9.59e-03)max mem: 17.22442 GB 
[09/16 12:12:20 visual_prompt]: 	Test 300/512. loss: 1.748, 0.1961 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 12:12:40 visual_prompt]: 	Test 400/512. loss: 1.467, 0.1902 s / batch. (data: 9.56e-05)max mem: 17.22442 GB 
[09/16 12:13:00 visual_prompt]: 	Test 500/512. loss: 1.509, 0.1982 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 12:13:05 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1963, average loss: 1.5537
[09/16 12:13:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 70.56	
[09/16 12:13:05 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 12:13:17 visual_prompt]: Epoch 44 / 100: avg data time: 2.05e-01, avg batch time: 0.6068, average train loss: 1.0796
[09/16 12:13:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1435, average loss: 0.6728
[09/16 12:13:23 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 84.32	
[09/16 12:13:45 visual_prompt]: 	Test 100/512. loss: 0.709, 0.1955 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 12:14:05 visual_prompt]: 	Test 200/512. loss: 0.728, 0.1837 s / batch. (data: 4.39e-05)max mem: 17.22442 GB 
[09/16 12:14:25 visual_prompt]: 	Test 300/512. loss: 0.762, 0.1989 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 12:14:44 visual_prompt]: 	Test 400/512. loss: 0.693, 0.2051 s / batch. (data: 2.19e-02)max mem: 17.22442 GB 
[09/16 12:15:04 visual_prompt]: 	Test 500/512. loss: 0.699, 0.1989 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 12:15:09 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1970, average loss: 0.7142
[09/16 12:15:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 74.10	
[09/16 12:15:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 12:15:21 visual_prompt]: Epoch 45 / 100: avg data time: 1.90e-01, avg batch time: 0.6008, average train loss: 0.7776
[09/16 12:15:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1435, average loss: 1.2385
[09/16 12:15:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 87.14	
[09/16 12:15:50 visual_prompt]: 	Test 100/512. loss: 1.083, 0.2030 s / batch. (data: 3.29e-05)max mem: 17.22442 GB 
[09/16 12:16:10 visual_prompt]: 	Test 200/512. loss: 1.224, 0.1842 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 12:16:29 visual_prompt]: 	Test 300/512. loss: 0.970, 0.1853 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 12:16:49 visual_prompt]: 	Test 400/512. loss: 1.205, 0.2273 s / batch. (data: 4.40e-02)max mem: 17.22442 GB 
[09/16 12:17:09 visual_prompt]: 	Test 500/512. loss: 1.183, 0.1993 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 12:17:14 visual_prompt]: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1968, average loss: 1.2012
[09/16 12:17:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.20	rocauc: 76.94	
[09/16 12:17:14 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 12:17:26 visual_prompt]: Epoch 46 / 100: avg data time: 2.02e-01, avg batch time: 0.6062, average train loss: 0.8024
[09/16 12:17:31 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1433, average loss: 1.0627
[09/16 12:17:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 86.98	
[09/16 12:17:54 visual_prompt]: 	Test 100/512. loss: 1.155, 0.1896 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 12:18:14 visual_prompt]: 	Test 200/512. loss: 1.168, 0.1989 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 12:18:33 visual_prompt]: 	Test 300/512. loss: 1.274, 0.1969 s / batch. (data: 1.35e-02)max mem: 17.22442 GB 
[09/16 12:18:53 visual_prompt]: 	Test 400/512. loss: 1.087, 0.1975 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 12:19:13 visual_prompt]: 	Test 500/512. loss: 1.109, 0.1998 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 12:19:18 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1967, average loss: 1.1375
[09/16 12:19:18 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 77.70	
[09/16 12:19:18 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 12:19:30 visual_prompt]: Epoch 47 / 100: avg data time: 2.00e-01, avg batch time: 0.6035, average train loss: 1.0655
[09/16 12:19:36 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1433, average loss: 0.9263
[09/16 12:19:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 86.38	
[09/16 12:19:58 visual_prompt]: 	Test 100/512. loss: 1.004, 0.2126 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 12:20:18 visual_prompt]: 	Test 200/512. loss: 1.019, 0.1834 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 12:20:38 visual_prompt]: 	Test 300/512. loss: 1.105, 0.1990 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 12:20:57 visual_prompt]: 	Test 400/512. loss: 0.950, 0.2046 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 12:21:17 visual_prompt]: 	Test 500/512. loss: 0.973, 0.1847 s / batch. (data: 1.70e-04)max mem: 17.22442 GB 
[09/16 12:21:22 visual_prompt]: Inference (test):avg data time: 8.82e-03, avg batch time: 0.1964, average loss: 0.9924
[09/16 12:21:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 77.95	
[09/16 12:21:22 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 12:21:34 visual_prompt]: Epoch 48 / 100: avg data time: 1.76e-01, avg batch time: 0.5852, average train loss: 1.2552
[09/16 12:21:39 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1461, average loss: 0.7253
[09/16 12:21:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 86.45	
[09/16 12:22:02 visual_prompt]: 	Test 100/512. loss: 0.813, 0.1829 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 12:22:22 visual_prompt]: 	Test 200/512. loss: 0.840, 0.1850 s / batch. (data: 1.05e-04)max mem: 17.22442 GB 
[09/16 12:22:42 visual_prompt]: 	Test 300/512. loss: 0.909, 0.2035 s / batch. (data: 2.02e-02)max mem: 17.22442 GB 
[09/16 12:23:01 visual_prompt]: 	Test 400/512. loss: 0.804, 0.1959 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 12:23:21 visual_prompt]: 	Test 500/512. loss: 0.810, 0.2042 s / batch. (data: 2.06e-02)max mem: 17.22442 GB 
[09/16 12:23:26 visual_prompt]: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1968, average loss: 0.8231
[09/16 12:23:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 77.14	
[09/16 12:23:26 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 12:23:38 visual_prompt]: Epoch 49 / 100: avg data time: 1.97e-01, avg batch time: 0.6012, average train loss: 0.8958
[09/16 12:23:44 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1433, average loss: 0.8464
[09/16 12:23:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 60.50	rocauc: 89.65	
[09/16 12:24:06 visual_prompt]: 	Test 100/512. loss: 0.759, 0.1961 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 12:24:26 visual_prompt]: 	Test 200/512. loss: 0.868, 0.2132 s / batch. (data: 2.95e-02)max mem: 17.22442 GB 
[09/16 12:24:45 visual_prompt]: 	Test 300/512. loss: 0.686, 0.1845 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 12:25:05 visual_prompt]: 	Test 400/512. loss: 0.856, 0.1994 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 12:25:25 visual_prompt]: 	Test 500/512. loss: 0.819, 0.1844 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 12:25:30 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1950, average loss: 0.8412
[09/16 12:25:30 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.80	rocauc: 81.01	
[09/16 12:25:30 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 12:25:41 visual_prompt]: Epoch 50 / 100: avg data time: 1.91e-01, avg batch time: 0.5956, average train loss: 0.7526
[09/16 12:25:47 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1434, average loss: 0.8171
[09/16 12:25:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 88.94	
[09/16 12:26:10 visual_prompt]: 	Test 100/512. loss: 0.931, 0.2050 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 12:26:29 visual_prompt]: 	Test 200/512. loss: 0.961, 0.1860 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 12:26:49 visual_prompt]: 	Test 300/512. loss: 1.070, 0.1989 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 12:27:09 visual_prompt]: 	Test 400/512. loss: 0.941, 0.1991 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 12:27:28 visual_prompt]: 	Test 500/512. loss: 0.926, 0.1947 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 12:27:33 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1956, average loss: 0.9510
[09/16 12:27:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 80.67	
[09/16 12:27:33 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 12:27:45 visual_prompt]: Epoch 51 / 100: avg data time: 1.95e-01, avg batch time: 0.5986, average train loss: 0.7567
[09/16 12:27:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1435, average loss: 0.4967
[09/16 12:27:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 71.00	rocauc: 90.90	
[09/16 12:28:13 visual_prompt]: 	Test 100/512. loss: 0.484, 0.1834 s / batch. (data: 1.67e-04)max mem: 17.22442 GB 
[09/16 12:28:33 visual_prompt]: 	Test 200/512. loss: 0.556, 0.1960 s / batch. (data: 9.68e-05)max mem: 17.22442 GB 
[09/16 12:28:52 visual_prompt]: 	Test 300/512. loss: 0.480, 0.1890 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 12:29:12 visual_prompt]: 	Test 400/512. loss: 0.586, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 12:29:32 visual_prompt]: 	Test 500/512. loss: 0.509, 0.1849 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 12:29:37 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1949, average loss: 0.5424
[09/16 12:29:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.80	rocauc: 84.35	
[09/16 12:29:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 12:29:48 visual_prompt]: Epoch 52 / 100: avg data time: 1.94e-01, avg batch time: 0.5992, average train loss: 0.6165
[09/16 12:29:54 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1432, average loss: 0.4218
[09/16 12:29:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 91.46	
[09/16 12:30:17 visual_prompt]: 	Test 100/512. loss: 0.445, 0.1958 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 12:30:36 visual_prompt]: 	Test 200/512. loss: 0.518, 0.1932 s / batch. (data: 8.33e-03)max mem: 17.22442 GB 
[09/16 12:30:56 visual_prompt]: 	Test 300/512. loss: 0.460, 0.1851 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 12:31:16 visual_prompt]: 	Test 400/512. loss: 0.554, 0.1846 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 12:31:35 visual_prompt]: 	Test 500/512. loss: 0.456, 0.2105 s / batch. (data: 2.72e-02)max mem: 17.22442 GB 
[09/16 12:31:40 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1952, average loss: 0.4912
[09/16 12:31:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.23	rocauc: 85.28	
[09/16 12:31:40 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 12:31:52 visual_prompt]: Epoch 53 / 100: avg data time: 2.00e-01, avg batch time: 0.6039, average train loss: 0.6116
[09/16 12:31:58 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1433, average loss: 0.3975
[09/16 12:31:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 92.03	
[09/16 12:32:21 visual_prompt]: 	Test 100/512. loss: 0.471, 0.2083 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 12:32:40 visual_prompt]: 	Test 200/512. loss: 0.549, 0.1837 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 12:33:00 visual_prompt]: 	Test 300/512. loss: 0.491, 0.1957 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 12:33:19 visual_prompt]: 	Test 400/512. loss: 0.563, 0.1977 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 12:33:39 visual_prompt]: 	Test 500/512. loss: 0.475, 0.2166 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 12:33:44 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1956, average loss: 0.5081
[09/16 12:33:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.52	rocauc: 85.45	
[09/16 12:33:44 visual_prompt]: Best epoch 53: best metric: 0.870
[09/16 12:33:44 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 12:33:56 visual_prompt]: Epoch 54 / 100: avg data time: 1.95e-01, avg batch time: 0.5979, average train loss: 0.4896
[09/16 12:34:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1432, average loss: 0.3937
[09/16 12:34:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 92.62	
[09/16 12:34:24 visual_prompt]: 	Test 100/512. loss: 0.433, 0.1985 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 12:34:44 visual_prompt]: 	Test 200/512. loss: 0.536, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 12:35:04 visual_prompt]: 	Test 300/512. loss: 0.426, 0.1964 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 12:35:23 visual_prompt]: 	Test 400/512. loss: 0.553, 0.1852 s / batch. (data: 1.81e-04)max mem: 17.22442 GB 
[09/16 12:35:43 visual_prompt]: 	Test 500/512. loss: 0.432, 0.1928 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 12:35:48 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1955, average loss: 0.4839
[09/16 12:35:48 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.43	rocauc: 85.36	
[09/16 12:35:48 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 12:35:59 visual_prompt]: Epoch 55 / 100: avg data time: 1.76e-01, avg batch time: 0.5851, average train loss: 0.5142
[09/16 12:36:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1432, average loss: 0.4740
[09/16 12:36:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 73.00	rocauc: 92.67	
[09/16 12:36:28 visual_prompt]: 	Test 100/512. loss: 0.493, 0.1942 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 12:36:47 visual_prompt]: 	Test 200/512. loss: 0.563, 0.1888 s / batch. (data: 1.04e-04)max mem: 17.22442 GB 
[09/16 12:37:07 visual_prompt]: 	Test 300/512. loss: 0.419, 0.1967 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 12:37:26 visual_prompt]: 	Test 400/512. loss: 0.643, 0.2038 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 12:37:47 visual_prompt]: 	Test 500/512. loss: 0.483, 0.2034 s / batch. (data: 2.93e-05)max mem: 17.22442 GB 
[09/16 12:37:51 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1964, average loss: 0.5344
[09/16 12:37:51 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.86	rocauc: 86.28	
[09/16 12:37:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 12:38:03 visual_prompt]: Epoch 56 / 100: avg data time: 1.88e-01, avg batch time: 0.5924, average train loss: 0.5250
[09/16 12:38:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1432, average loss: 0.3788
[09/16 12:38:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 92.50	
[09/16 12:38:32 visual_prompt]: 	Test 100/512. loss: 0.458, 0.1983 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 12:38:51 visual_prompt]: 	Test 200/512. loss: 0.523, 0.1832 s / batch. (data: 2.93e-05)max mem: 17.22442 GB 
[09/16 12:39:11 visual_prompt]: 	Test 300/512. loss: 0.423, 0.2161 s / batch. (data: 2.65e-02)max mem: 17.22442 GB 
[09/16 12:39:30 visual_prompt]: 	Test 400/512. loss: 0.527, 0.2300 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 12:39:50 visual_prompt]: 	Test 500/512. loss: 0.423, 0.1958 s / batch. (data: 1.21e-02)max mem: 17.22442 GB 
[09/16 12:39:55 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1954, average loss: 0.4794
[09/16 12:39:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.79	rocauc: 85.13	
[09/16 12:39:55 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 12:40:07 visual_prompt]: Epoch 57 / 100: avg data time: 1.89e-01, avg batch time: 0.5936, average train loss: 0.5418
[09/16 12:40:13 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1435, average loss: 0.4931
[09/16 12:40:13 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 78.50	rocauc: 94.44	
[09/16 12:40:35 visual_prompt]: 	Test 100/512. loss: 0.694, 0.1829 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 12:40:55 visual_prompt]: 	Test 200/512. loss: 0.740, 0.1839 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 12:41:14 visual_prompt]: 	Test 300/512. loss: 0.754, 0.1893 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 12:41:34 visual_prompt]: 	Test 400/512. loss: 0.742, 0.1997 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 12:41:53 visual_prompt]: 	Test 500/512. loss: 0.701, 0.1847 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 12:41:58 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1950, average loss: 0.7196
[09/16 12:41:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 63.22	rocauc: 87.70	
[09/16 12:41:58 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 12:42:10 visual_prompt]: Epoch 58 / 100: avg data time: 1.95e-01, avg batch time: 0.5987, average train loss: 0.5422
[09/16 12:42:16 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 0.3408
[09/16 12:42:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.00	rocauc: 94.62	
[09/16 12:42:38 visual_prompt]: 	Test 100/512. loss: 0.462, 0.1979 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 12:42:58 visual_prompt]: 	Test 200/512. loss: 0.502, 0.1840 s / batch. (data: 9.58e-05)max mem: 17.22442 GB 
[09/16 12:43:17 visual_prompt]: 	Test 300/512. loss: 0.431, 0.1846 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 12:43:37 visual_prompt]: 	Test 400/512. loss: 0.490, 0.1903 s / batch. (data: 6.34e-03)max mem: 17.22442 GB 
[09/16 12:43:57 visual_prompt]: 	Test 500/512. loss: 0.429, 0.1948 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 12:44:02 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1959, average loss: 0.4675
[09/16 12:44:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.54	rocauc: 87.95	
[09/16 12:44:02 visual_prompt]: Best epoch 58: best metric: 0.890
[09/16 12:44:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 12:44:14 visual_prompt]: Epoch 59 / 100: avg data time: 1.92e-01, avg batch time: 0.5949, average train loss: 0.5120
[09/16 12:44:20 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 0.4482
[09/16 12:44:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 79.50	rocauc: 94.09	
[09/16 12:44:42 visual_prompt]: 	Test 100/512. loss: 0.459, 0.1831 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 12:45:02 visual_prompt]: 	Test 200/512. loss: 0.557, 0.1957 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 12:45:21 visual_prompt]: 	Test 300/512. loss: 0.397, 0.1835 s / batch. (data: 9.82e-05)max mem: 17.22442 GB 
[09/16 12:45:41 visual_prompt]: 	Test 400/512. loss: 0.586, 0.2119 s / batch. (data: 2.82e-02)max mem: 17.22442 GB 
[09/16 12:46:00 visual_prompt]: 	Test 500/512. loss: 0.451, 0.1974 s / batch. (data: 1.39e-02)max mem: 17.22442 GB 
[09/16 12:46:05 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1952, average loss: 0.5254
[09/16 12:46:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.21	rocauc: 87.20	
[09/16 12:46:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 12:46:17 visual_prompt]: Epoch 60 / 100: avg data time: 1.93e-01, avg batch time: 0.5978, average train loss: 0.4459
[09/16 12:46:22 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1435, average loss: 0.2952
[09/16 12:46:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.00	rocauc: 95.12	
[09/16 12:46:45 visual_prompt]: 	Test 100/512. loss: 0.454, 0.2059 s / batch. (data: 1.04e-04)max mem: 17.22442 GB 
[09/16 12:47:04 visual_prompt]: 	Test 200/512. loss: 0.458, 0.1844 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 12:47:24 visual_prompt]: 	Test 300/512. loss: 0.416, 0.1848 s / batch. (data: 9.11e-05)max mem: 17.22442 GB 
[09/16 12:47:44 visual_prompt]: 	Test 400/512. loss: 0.493, 0.2174 s / batch. (data: 3.44e-02)max mem: 17.22442 GB 
[09/16 12:48:04 visual_prompt]: 	Test 500/512. loss: 0.416, 0.2087 s / batch. (data: 2.48e-02)max mem: 17.22442 GB 
[09/16 12:48:09 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1957, average loss: 0.4547
[09/16 12:48:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.69	rocauc: 88.19	
[09/16 12:48:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 12:48:20 visual_prompt]: Epoch 61 / 100: avg data time: 1.92e-01, avg batch time: 0.5971, average train loss: 0.4556
[09/16 12:48:26 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1432, average loss: 0.4994
[09/16 12:48:26 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 78.00	rocauc: 95.41	
[09/16 12:48:49 visual_prompt]: 	Test 100/512. loss: 0.532, 0.1833 s / batch. (data: 2.96e-05)max mem: 17.22442 GB 
[09/16 12:49:08 visual_prompt]: 	Test 200/512. loss: 0.640, 0.1878 s / batch. (data: 4.01e-05)max mem: 17.22442 GB 
[09/16 12:49:28 visual_prompt]: 	Test 300/512. loss: 0.394, 0.1869 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 12:49:47 visual_prompt]: 	Test 400/512. loss: 0.634, 0.2186 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 12:50:07 visual_prompt]: 	Test 500/512. loss: 0.530, 0.1991 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 12:50:12 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1951, average loss: 0.5855
[09/16 12:50:12 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.05	rocauc: 88.32	
[09/16 12:50:12 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 12:50:24 visual_prompt]: Epoch 62 / 100: avg data time: 2.07e-01, avg batch time: 0.6107, average train loss: 0.5347
[09/16 12:50:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1434, average loss: 0.3313
[09/16 12:50:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.50	rocauc: 95.40	
[09/16 12:50:52 visual_prompt]: 	Test 100/512. loss: 0.521, 0.1833 s / batch. (data: 1.12e-04)max mem: 17.22442 GB 
[09/16 12:51:12 visual_prompt]: 	Test 200/512. loss: 0.555, 0.1976 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 12:51:32 visual_prompt]: 	Test 300/512. loss: 0.522, 0.1833 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 12:51:51 visual_prompt]: 	Test 400/512. loss: 0.519, 0.1966 s / batch. (data: 3.41e-05)max mem: 17.22442 GB 
[09/16 12:52:11 visual_prompt]: 	Test 500/512. loss: 0.494, 0.2024 s / batch. (data: 1.91e-02)max mem: 17.22442 GB 
[09/16 12:52:16 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1961, average loss: 0.5210
[09/16 12:52:16 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.86	rocauc: 87.37	
[09/16 12:52:16 visual_prompt]: Best epoch 62: best metric: 0.895
[09/16 12:52:16 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 12:52:28 visual_prompt]: Epoch 63 / 100: avg data time: 1.78e-01, avg batch time: 0.5844, average train loss: 0.4207
[09/16 12:52:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1434, average loss: 0.4631
[09/16 12:52:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 80.00	rocauc: 94.68	
[09/16 12:52:56 visual_prompt]: 	Test 100/512. loss: 0.485, 0.2116 s / batch. (data: 1.16e-02)max mem: 17.22442 GB 
[09/16 12:53:16 visual_prompt]: 	Test 200/512. loss: 0.629, 0.1992 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 12:53:35 visual_prompt]: 	Test 300/512. loss: 0.425, 0.1849 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 12:53:55 visual_prompt]: 	Test 400/512. loss: 0.667, 0.2348 s / batch. (data: 9.56e-05)max mem: 17.22442 GB 
[09/16 12:54:15 visual_prompt]: 	Test 500/512. loss: 0.526, 0.2121 s / batch. (data: 2.88e-02)max mem: 17.22442 GB 
[09/16 12:54:20 visual_prompt]: Inference (test):avg data time: 8.71e-03, avg batch time: 0.1956, average loss: 0.5777
[09/16 12:54:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.79	rocauc: 87.78	
[09/16 12:54:20 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 12:54:31 visual_prompt]: Epoch 64 / 100: avg data time: 1.93e-01, avg batch time: 0.5977, average train loss: 0.5012
[09/16 12:54:37 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1433, average loss: 0.3041
[09/16 12:54:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.00	rocauc: 95.04	
[09/16 12:55:00 visual_prompt]: 	Test 100/512. loss: 0.486, 0.1885 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 12:55:19 visual_prompt]: 	Test 200/512. loss: 0.533, 0.2027 s / batch. (data: 1.96e-02)max mem: 17.22442 GB 
[09/16 12:55:39 visual_prompt]: 	Test 300/512. loss: 0.420, 0.1921 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 12:55:58 visual_prompt]: 	Test 400/512. loss: 0.455, 0.1967 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 12:56:18 visual_prompt]: 	Test 500/512. loss: 0.440, 0.2076 s / batch. (data: 2.40e-02)max mem: 17.22442 GB 
[09/16 12:56:23 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1952, average loss: 0.4922
[09/16 12:56:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.50	rocauc: 87.28	
[09/16 12:56:23 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 12:56:35 visual_prompt]: Epoch 65 / 100: avg data time: 1.90e-01, avg batch time: 0.5988, average train loss: 0.4648
[09/16 12:56:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1433, average loss: 0.3009
[09/16 12:56:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 94.71	
[09/16 12:57:03 visual_prompt]: 	Test 100/512. loss: 0.467, 0.1968 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 12:57:23 visual_prompt]: 	Test 200/512. loss: 0.455, 0.1983 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 12:57:42 visual_prompt]: 	Test 300/512. loss: 0.373, 0.1924 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 12:58:02 visual_prompt]: 	Test 400/512. loss: 0.484, 0.2004 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 12:58:22 visual_prompt]: 	Test 500/512. loss: 0.393, 0.1846 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 12:58:27 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1959, average loss: 0.4368
[09/16 12:58:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.51	rocauc: 88.42	
[09/16 12:58:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 12:58:39 visual_prompt]: Epoch 66 / 100: avg data time: 1.88e-01, avg batch time: 0.5931, average train loss: 0.5913
[09/16 12:58:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1433, average loss: 0.3645
[09/16 12:58:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 93.39	
[09/16 12:59:07 visual_prompt]: 	Test 100/512. loss: 0.499, 0.2043 s / batch. (data: 2.14e-02)max mem: 17.22442 GB 
[09/16 12:59:27 visual_prompt]: 	Test 200/512. loss: 0.594, 0.1847 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 12:59:46 visual_prompt]: 	Test 300/512. loss: 0.514, 0.1983 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 13:00:06 visual_prompt]: 	Test 400/512. loss: 0.582, 0.1844 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 13:00:25 visual_prompt]: 	Test 500/512. loss: 0.516, 0.1879 s / batch. (data: 1.10e-04)max mem: 17.22442 GB 
[09/16 13:00:30 visual_prompt]: Inference (test):avg data time: 7.30e-03, avg batch time: 0.1944, average loss: 0.5398
[09/16 13:00:30 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.93	rocauc: 85.54	
[09/16 13:00:30 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 13:00:42 visual_prompt]: Epoch 67 / 100: avg data time: 1.99e-01, avg batch time: 0.6043, average train loss: 0.4694
[09/16 13:00:48 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1434, average loss: 0.3702
[09/16 13:00:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.50	rocauc: 95.02	
[09/16 13:01:10 visual_prompt]: 	Test 100/512. loss: 0.632, 0.1836 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 13:01:30 visual_prompt]: 	Test 200/512. loss: 0.647, 0.1992 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 13:01:50 visual_prompt]: 	Test 300/512. loss: 0.589, 0.2158 s / batch. (data: 3.28e-02)max mem: 17.22442 GB 
[09/16 13:02:09 visual_prompt]: 	Test 400/512. loss: 0.558, 0.1883 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 13:02:29 visual_prompt]: 	Test 500/512. loss: 0.560, 0.1908 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 13:02:34 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1953, average loss: 0.6134
[09/16 13:02:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.61	rocauc: 86.98	
[09/16 13:02:34 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 13:02:46 visual_prompt]: Epoch 68 / 100: avg data time: 1.88e-01, avg batch time: 0.5922, average train loss: 0.4093
[09/16 13:02:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1433, average loss: 0.2839
[09/16 13:02:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 95.35	
[09/16 13:03:14 visual_prompt]: 	Test 100/512. loss: 0.476, 0.2088 s / batch. (data: 2.56e-02)max mem: 17.22442 GB 
[09/16 13:03:33 visual_prompt]: 	Test 200/512. loss: 0.513, 0.1844 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 13:03:53 visual_prompt]: 	Test 300/512. loss: 0.367, 0.1846 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 13:04:12 visual_prompt]: 	Test 400/512. loss: 0.474, 0.1962 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 13:04:32 visual_prompt]: 	Test 500/512. loss: 0.403, 0.1949 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 13:04:37 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1943, average loss: 0.4645
[09/16 13:04:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.64	rocauc: 87.21	
[09/16 13:04:37 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 13:04:49 visual_prompt]: Epoch 69 / 100: avg data time: 1.89e-01, avg batch time: 0.6277, average train loss: 0.4334
[09/16 13:04:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1435, average loss: 0.4126
[09/16 13:04:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.50	rocauc: 94.68	
[09/16 13:05:17 visual_prompt]: 	Test 100/512. loss: 0.469, 0.1844 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 13:05:37 visual_prompt]: 	Test 200/512. loss: 0.548, 0.1933 s / batch. (data: 1.02e-02)max mem: 17.22442 GB 
[09/16 13:05:56 visual_prompt]: 	Test 300/512. loss: 0.390, 0.1848 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 13:06:16 visual_prompt]: 	Test 400/512. loss: 0.603, 0.1925 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 13:06:35 visual_prompt]: 	Test 500/512. loss: 0.501, 0.1954 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 13:06:40 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1949, average loss: 0.5237
[09/16 13:06:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.71	rocauc: 86.60	
[09/16 13:06:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 13:06:52 visual_prompt]: Epoch 70 / 100: avg data time: 1.96e-01, avg batch time: 0.5986, average train loss: 0.4423
[09/16 13:06:58 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1436, average loss: 0.3294
[09/16 13:06:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.50	rocauc: 95.85	
[09/16 13:07:21 visual_prompt]: 	Test 100/512. loss: 0.451, 0.1836 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 13:07:40 visual_prompt]: 	Test 200/512. loss: 0.538, 0.2008 s / batch. (data: 1.69e-02)max mem: 17.22442 GB 
[09/16 13:08:00 visual_prompt]: 	Test 300/512. loss: 0.308, 0.1986 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 13:08:20 visual_prompt]: 	Test 400/512. loss: 0.499, 0.1984 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 13:08:39 visual_prompt]: 	Test 500/512. loss: 0.398, 0.1847 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 13:08:44 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1954, average loss: 0.4626
[09/16 13:08:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.64	rocauc: 87.80	
[09/16 13:08:44 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 13:08:56 visual_prompt]: Epoch 71 / 100: avg data time: 1.87e-01, avg batch time: 0.5917, average train loss: 0.3731
[09/16 13:09:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1435, average loss: 0.3363
[09/16 13:09:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.00	rocauc: 96.28	
[09/16 13:09:24 visual_prompt]: 	Test 100/512. loss: 0.546, 0.2199 s / batch. (data: 3.73e-02)max mem: 17.22442 GB 
[09/16 13:09:44 visual_prompt]: 	Test 200/512. loss: 0.667, 0.1926 s / batch. (data: 9.10e-03)max mem: 17.22442 GB 
[09/16 13:10:03 visual_prompt]: 	Test 300/512. loss: 0.530, 0.1866 s / batch. (data: 1.10e-04)max mem: 17.22442 GB 
[09/16 13:10:23 visual_prompt]: 	Test 400/512. loss: 0.577, 0.2078 s / batch. (data: 2.38e-02)max mem: 17.22442 GB 
[09/16 13:10:43 visual_prompt]: 	Test 500/512. loss: 0.549, 0.2002 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 13:10:47 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1956, average loss: 0.5835
[09/16 13:10:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.01	rocauc: 89.03	
[09/16 13:10:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 13:10:59 visual_prompt]: Epoch 72 / 100: avg data time: 1.91e-01, avg batch time: 0.5944, average train loss: 0.3529
[09/16 13:11:05 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1434, average loss: 0.2930
[09/16 13:11:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 96.60	
[09/16 13:11:28 visual_prompt]: 	Test 100/512. loss: 0.465, 0.1962 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 13:11:48 visual_prompt]: 	Test 200/512. loss: 0.535, 0.2214 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 13:12:08 visual_prompt]: 	Test 300/512. loss: 0.307, 0.2022 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 13:12:27 visual_prompt]: 	Test 400/512. loss: 0.483, 0.2122 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 13:12:47 visual_prompt]: 	Test 500/512. loss: 0.405, 0.1999 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 13:12:52 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1955, average loss: 0.4544
[09/16 13:12:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.40	rocauc: 87.87	
[09/16 13:12:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 13:13:03 visual_prompt]: Epoch 73 / 100: avg data time: 1.74e-01, avg batch time: 0.5796, average train loss: 0.3799
[09/16 13:13:09 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1435, average loss: 0.3267
[09/16 13:13:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 97.22	
[09/16 13:13:32 visual_prompt]: 	Test 100/512. loss: 0.710, 0.1835 s / batch. (data: 3.65e-05)max mem: 17.22442 GB 
[09/16 13:13:51 visual_prompt]: 	Test 200/512. loss: 0.757, 0.1921 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 13:14:10 visual_prompt]: 	Test 300/512. loss: 0.633, 0.1851 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 13:14:30 visual_prompt]: 	Test 400/512. loss: 0.618, 0.1871 s / batch. (data: 2.47e-03)max mem: 17.22442 GB 
[09/16 13:14:50 visual_prompt]: 	Test 500/512. loss: 0.601, 0.1857 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 13:14:55 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1944, average loss: 0.6696
[09/16 13:14:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.57	rocauc: 88.13	
[09/16 13:14:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 13:15:06 visual_prompt]: Epoch 74 / 100: avg data time: 1.89e-01, avg batch time: 0.5994, average train loss: 0.3581
[09/16 13:15:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1435, average loss: 0.3476
[09/16 13:15:12 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.50	rocauc: 96.63	
[09/16 13:15:35 visual_prompt]: 	Test 100/512. loss: 0.444, 0.2034 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 13:15:54 visual_prompt]: 	Test 200/512. loss: 0.542, 0.2133 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 13:16:14 visual_prompt]: 	Test 300/512. loss: 0.313, 0.1982 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 13:16:33 visual_prompt]: 	Test 400/512. loss: 0.582, 0.1990 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 13:16:53 visual_prompt]: 	Test 500/512. loss: 0.482, 0.2002 s / batch. (data: 1.64e-02)max mem: 17.22442 GB 
[09/16 13:16:58 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1955, average loss: 0.5018
[09/16 13:16:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.64	rocauc: 88.86	
[09/16 13:16:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 13:17:10 visual_prompt]: Epoch 75 / 100: avg data time: 1.84e-01, avg batch time: 0.5886, average train loss: 0.3461
[09/16 13:17:15 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1440, average loss: 0.3344
[09/16 13:17:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.00	rocauc: 96.20	
[09/16 13:17:38 visual_prompt]: 	Test 100/512. loss: 0.728, 0.2016 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 13:17:57 visual_prompt]: 	Test 200/512. loss: 0.810, 0.1839 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 13:18:17 visual_prompt]: 	Test 300/512. loss: 0.604, 0.1997 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 13:18:37 visual_prompt]: 	Test 400/512. loss: 0.612, 0.2114 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 13:18:56 visual_prompt]: 	Test 500/512. loss: 0.647, 0.1850 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 13:19:01 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1950, average loss: 0.6933
[09/16 13:19:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.42	rocauc: 85.63	
[09/16 13:19:01 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 13:19:13 visual_prompt]: Epoch 76 / 100: avg data time: 1.93e-01, avg batch time: 0.5969, average train loss: 0.3395
[09/16 13:19:19 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1435, average loss: 0.2362
[09/16 13:19:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 97.09	
[09/16 13:19:42 visual_prompt]: 	Test 100/512. loss: 0.463, 0.1965 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 13:20:01 visual_prompt]: 	Test 200/512. loss: 0.505, 0.1962 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 13:20:21 visual_prompt]: 	Test 300/512. loss: 0.324, 0.1986 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 13:20:41 visual_prompt]: 	Test 400/512. loss: 0.546, 0.1929 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 13:21:01 visual_prompt]: 	Test 500/512. loss: 0.496, 0.1842 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 13:21:06 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1985, average loss: 0.4720
[09/16 13:21:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.75	rocauc: 87.29	
[09/16 13:21:06 visual_prompt]: Best epoch 76: best metric: 0.905
[09/16 13:21:06 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 13:21:18 visual_prompt]: Epoch 77 / 100: avg data time: 1.87e-01, avg batch time: 0.5918, average train loss: 0.3628
[09/16 13:21:24 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1441, average loss: 0.2310
[09/16 13:21:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.50	rocauc: 97.94	
[09/16 13:21:46 visual_prompt]: 	Test 100/512. loss: 0.506, 0.1839 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 13:22:06 visual_prompt]: 	Test 200/512. loss: 0.601, 0.1947 s / batch. (data: 9.11e-05)max mem: 17.22442 GB 
[09/16 13:22:25 visual_prompt]: 	Test 300/512. loss: 0.448, 0.1980 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 13:22:45 visual_prompt]: 	Test 400/512. loss: 0.551, 0.2083 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 13:23:04 visual_prompt]: 	Test 500/512. loss: 0.518, 0.1992 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 13:23:09 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1948, average loss: 0.5386
[09/16 13:23:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.53	rocauc: 87.82	
[09/16 13:23:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 13:23:21 visual_prompt]: Epoch 78 / 100: avg data time: 1.94e-01, avg batch time: 0.5994, average train loss: 0.3022
[09/16 13:23:27 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1433, average loss: 0.2047
[09/16 13:23:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 91.00	rocauc: 98.11	
[09/16 13:23:50 visual_prompt]: 	Test 100/512. loss: 0.555, 0.1956 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 13:24:10 visual_prompt]: 	Test 200/512. loss: 0.665, 0.1876 s / batch. (data: 9.44e-05)max mem: 17.22442 GB 
[09/16 13:24:30 visual_prompt]: 	Test 300/512. loss: 0.436, 0.2048 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 13:24:49 visual_prompt]: 	Test 400/512. loss: 0.577, 0.1925 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 13:25:09 visual_prompt]: 	Test 500/512. loss: 0.512, 0.1885 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 13:25:14 visual_prompt]: Inference (test):avg data time: 8.96e-03, avg batch time: 0.1971, average loss: 0.5546
[09/16 13:25:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.18	rocauc: 88.09	
[09/16 13:25:14 visual_prompt]: Best epoch 78: best metric: 0.910
[09/16 13:25:14 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 13:25:26 visual_prompt]: Epoch 79 / 100: avg data time: 1.93e-01, avg batch time: 0.5960, average train loss: 0.2872
[09/16 13:25:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1432, average loss: 0.2399
[09/16 13:25:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.00	rocauc: 97.57	
[09/16 13:25:54 visual_prompt]: 	Test 100/512. loss: 0.627, 0.1840 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 13:26:13 visual_prompt]: 	Test 200/512. loss: 0.734, 0.1995 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 13:26:33 visual_prompt]: 	Test 300/512. loss: 0.520, 0.1842 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 13:26:52 visual_prompt]: 	Test 400/512. loss: 0.679, 0.1840 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 13:27:12 visual_prompt]: 	Test 500/512. loss: 0.694, 0.1860 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 13:27:17 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1947, average loss: 0.6830
[09/16 13:27:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.35	rocauc: 84.70	
[09/16 13:27:17 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 13:27:29 visual_prompt]: Epoch 80 / 100: avg data time: 1.87e-01, avg batch time: 0.5937, average train loss: 0.2820
[09/16 13:27:35 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1441, average loss: 0.3697
[09/16 13:27:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 97.04	
[09/16 13:27:58 visual_prompt]: 	Test 100/512. loss: 0.923, 0.2095 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 13:28:17 visual_prompt]: 	Test 200/512. loss: 1.042, 0.1985 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 13:28:37 visual_prompt]: 	Test 300/512. loss: 0.745, 0.1945 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 13:28:56 visual_prompt]: 	Test 400/512. loss: 0.880, 0.1913 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 13:29:16 visual_prompt]: 	Test 500/512. loss: 0.845, 0.1978 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 13:29:21 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1958, average loss: 0.8825
[09/16 13:29:21 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 67.80	rocauc: 84.05	
[09/16 13:29:21 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 13:29:33 visual_prompt]: Epoch 81 / 100: avg data time: 1.91e-01, avg batch time: 0.5958, average train loss: 0.2770
[09/16 13:29:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1438, average loss: 0.2377
[09/16 13:29:38 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.00	rocauc: 98.68	
[09/16 13:30:01 visual_prompt]: 	Test 100/512. loss: 0.423, 0.1986 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 13:30:21 visual_prompt]: 	Test 200/512. loss: 0.571, 0.2248 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 13:30:40 visual_prompt]: 	Test 300/512. loss: 0.330, 0.1853 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 13:31:00 visual_prompt]: 	Test 400/512. loss: 0.548, 0.1986 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 13:31:19 visual_prompt]: 	Test 500/512. loss: 0.446, 0.1931 s / batch. (data: 9.23e-05)max mem: 17.22442 GB 
[09/16 13:31:25 visual_prompt]: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1946, average loss: 0.5002
[09/16 13:31:25 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.39	rocauc: 88.34	
[09/16 13:31:25 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 13:31:36 visual_prompt]: Epoch 82 / 100: avg data time: 1.92e-01, avg batch time: 0.6013, average train loss: 0.2863
[09/16 13:31:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1435, average loss: 0.2114
[09/16 13:31:42 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 98.88	
[09/16 13:32:05 visual_prompt]: 	Test 100/512. loss: 0.473, 0.1839 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 13:32:24 visual_prompt]: 	Test 200/512. loss: 0.623, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 13:32:44 visual_prompt]: 	Test 300/512. loss: 0.292, 0.1838 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 13:33:04 visual_prompt]: 	Test 400/512. loss: 0.555, 0.1850 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 13:33:23 visual_prompt]: 	Test 500/512. loss: 0.471, 0.1986 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 13:33:28 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1946, average loss: 0.5068
[09/16 13:33:28 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.89	rocauc: 88.52	
[09/16 13:33:28 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 13:33:40 visual_prompt]: Epoch 83 / 100: avg data time: 1.88e-01, avg batch time: 0.5952, average train loss: 0.2438
[09/16 13:33:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1436, average loss: 0.1610
[09/16 13:33:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.00	rocauc: 98.98	
[09/16 13:34:08 visual_prompt]: 	Test 100/512. loss: 0.595, 0.1838 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 13:34:28 visual_prompt]: 	Test 200/512. loss: 0.755, 0.1977 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 13:34:47 visual_prompt]: 	Test 300/512. loss: 0.427, 0.2135 s / batch. (data: 2.44e-02)max mem: 17.22442 GB 
[09/16 13:35:07 visual_prompt]: 	Test 400/512. loss: 0.585, 0.1996 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 13:35:27 visual_prompt]: 	Test 500/512. loss: 0.575, 0.1991 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 13:35:32 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1965, average loss: 0.5923
[09/16 13:35:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.54	rocauc: 86.64	
[09/16 13:35:32 visual_prompt]: Best epoch 83: best metric: 0.940
[09/16 13:35:32 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 13:35:44 visual_prompt]: Epoch 84 / 100: avg data time: 1.85e-01, avg batch time: 0.5890, average train loss: 0.1890
[09/16 13:35:49 visual_prompt]: Inference (val):avg data time: 4.77e-05, avg batch time: 0.1434, average loss: 0.1196
[09/16 13:35:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.50	rocauc: 99.31	
[09/16 13:36:12 visual_prompt]: 	Test 100/512. loss: 0.645, 0.1948 s / batch. (data: 1.18e-02)max mem: 17.22442 GB 
[09/16 13:36:32 visual_prompt]: 	Test 200/512. loss: 0.876, 0.1848 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 13:36:51 visual_prompt]: 	Test 300/512. loss: 0.489, 0.1959 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 13:37:11 visual_prompt]: 	Test 400/512. loss: 0.853, 0.1980 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 13:37:30 visual_prompt]: 	Test 500/512. loss: 0.663, 0.1859 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 13:37:35 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1944, average loss: 0.7092
[09/16 13:37:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.66	rocauc: 86.41	
[09/16 13:37:35 visual_prompt]: Best epoch 84: best metric: 0.945
[09/16 13:37:35 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 13:37:47 visual_prompt]: Epoch 85 / 100: avg data time: 1.96e-01, avg batch time: 0.5984, average train loss: 0.1588
[09/16 13:37:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1435, average loss: 0.1010
[09/16 13:37:52 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 99.42	
[09/16 13:38:15 visual_prompt]: 	Test 100/512. loss: 0.559, 0.2124 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 13:38:34 visual_prompt]: 	Test 200/512. loss: 0.705, 0.1846 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 13:38:54 visual_prompt]: 	Test 300/512. loss: 0.428, 0.2282 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 13:39:13 visual_prompt]: 	Test 400/512. loss: 0.904, 0.1998 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 13:39:33 visual_prompt]: 	Test 500/512. loss: 0.647, 0.1847 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 13:39:38 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1949, average loss: 0.6480
[09/16 13:39:38 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.96	rocauc: 87.88	
[09/16 13:39:38 visual_prompt]: Best epoch 85: best metric: 0.965
[09/16 13:39:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 13:39:50 visual_prompt]: Epoch 86 / 100: avg data time: 1.91e-01, avg batch time: 0.5957, average train loss: 0.1728
[09/16 13:39:56 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1434, average loss: 0.0772
[09/16 13:39:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.77	
[09/16 13:40:18 visual_prompt]: 	Test 100/512. loss: 0.623, 0.2070 s / batch. (data: 8.51e-03)max mem: 17.22442 GB 
[09/16 13:40:37 visual_prompt]: 	Test 200/512. loss: 0.985, 0.1869 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 13:40:58 visual_prompt]: 	Test 300/512. loss: 0.473, 0.1857 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 13:41:17 visual_prompt]: 	Test 400/512. loss: 0.902, 0.1898 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 13:41:37 visual_prompt]: 	Test 500/512. loss: 0.685, 0.1839 s / batch. (data: 9.11e-05)max mem: 17.22442 GB 
[09/16 13:41:42 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1961, average loss: 0.7265
[09/16 13:41:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.17	rocauc: 85.91	
[09/16 13:41:42 visual_prompt]: Best epoch 86: best metric: 0.985
[09/16 13:41:42 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 13:41:54 visual_prompt]: Epoch 87 / 100: avg data time: 1.93e-01, avg batch time: 0.5976, average train loss: 0.1464
[09/16 13:41:59 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1434, average loss: 0.1606
[09/16 13:41:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.00	rocauc: 98.66	
[09/16 13:42:22 visual_prompt]: 	Test 100/512. loss: 0.722, 0.1843 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 13:42:41 visual_prompt]: 	Test 200/512. loss: 0.937, 0.1856 s / batch. (data: 1.68e-04)max mem: 17.22442 GB 
[09/16 13:43:01 visual_prompt]: 	Test 300/512. loss: 0.524, 0.2243 s / batch. (data: 4.13e-02)max mem: 17.22442 GB 
[09/16 13:43:21 visual_prompt]: 	Test 400/512. loss: 1.077, 0.1962 s / batch. (data: 4.60e-05)max mem: 17.22442 GB 
[09/16 13:43:40 visual_prompt]: 	Test 500/512. loss: 0.895, 0.1848 s / batch. (data: 9.08e-05)max mem: 17.22442 GB 
[09/16 13:43:45 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1953, average loss: 0.8178
[09/16 13:43:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.08	rocauc: 84.33	
[09/16 13:43:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 13:43:57 visual_prompt]: Epoch 88 / 100: avg data time: 2.02e-01, avg batch time: 0.6109, average train loss: 0.1524
[09/16 13:44:03 visual_prompt]: Inference (val):avg data time: 3.65e-04, avg batch time: 0.2173, average loss: 0.2675
[09/16 13:44:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 99.41	
[09/16 13:44:26 visual_prompt]: 	Test 100/512. loss: 0.742, 0.2057 s / batch. (data: 2.26e-02)max mem: 17.22442 GB 
[09/16 13:44:45 visual_prompt]: 	Test 200/512. loss: 1.175, 0.1838 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 13:45:04 visual_prompt]: 	Test 300/512. loss: 0.563, 0.1846 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 13:45:24 visual_prompt]: 	Test 400/512. loss: 0.809, 0.1999 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 13:45:44 visual_prompt]: 	Test 500/512. loss: 0.883, 0.2036 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 13:45:49 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1946, average loss: 0.8484
[09/16 13:45:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.42	rocauc: 85.07	
[09/16 13:45:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 13:46:01 visual_prompt]: Epoch 89 / 100: avg data time: 1.92e-01, avg batch time: 0.5955, average train loss: 0.1678
[09/16 13:46:06 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1436, average loss: 0.0716
[09/16 13:46:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.95	
[09/16 13:46:29 visual_prompt]: 	Test 100/512. loss: 0.601, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 13:46:49 visual_prompt]: 	Test 200/512. loss: 0.962, 0.1963 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 13:47:08 visual_prompt]: 	Test 300/512. loss: 0.467, 0.1854 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 13:47:28 visual_prompt]: 	Test 400/512. loss: 0.731, 0.1867 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 13:47:47 visual_prompt]: 	Test 500/512. loss: 0.712, 0.2353 s / batch. (data: 5.22e-02)max mem: 17.22442 GB 
[09/16 13:47:52 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1948, average loss: 0.6847
[09/16 13:47:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.49	rocauc: 86.08	
[09/16 13:47:52 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 13:48:04 visual_prompt]: Epoch 90 / 100: avg data time: 1.91e-01, avg batch time: 0.5930, average train loss: 0.1113
[09/16 13:48:10 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1434, average loss: 0.0891
[09/16 13:48:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.00	rocauc: 99.95	
[09/16 13:48:32 visual_prompt]: 	Test 100/512. loss: 1.002, 0.1956 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 13:48:51 visual_prompt]: 	Test 200/512. loss: 1.260, 0.1841 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 13:49:12 visual_prompt]: 	Test 300/512. loss: 0.726, 0.2118 s / batch. (data: 2.66e-02)max mem: 17.22442 GB 
[09/16 13:49:31 visual_prompt]: 	Test 400/512. loss: 1.145, 0.2295 s / batch. (data: 4.59e-02)max mem: 17.22442 GB 
[09/16 13:49:51 visual_prompt]: 	Test 500/512. loss: 1.065, 0.2131 s / batch. (data: 9.04e-05)max mem: 17.22442 GB 
[09/16 13:49:56 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1958, average loss: 1.0409
[09/16 13:49:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.45	rocauc: 85.71	
[09/16 13:49:56 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 13:50:08 visual_prompt]: Epoch 91 / 100: avg data time: 1.97e-01, avg batch time: 0.6030, average train loss: 0.0920
[09/16 13:50:14 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1435, average loss: 0.0637
[09/16 13:50:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.90	
[09/16 13:50:36 visual_prompt]: 	Test 100/512. loss: 0.904, 0.1976 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 13:50:56 visual_prompt]: 	Test 200/512. loss: 1.647, 0.1986 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 13:51:16 visual_prompt]: 	Test 300/512. loss: 0.588, 0.1850 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 13:51:36 visual_prompt]: 	Test 400/512. loss: 0.981, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 13:51:55 visual_prompt]: 	Test 500/512. loss: 0.953, 0.2057 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 13:52:00 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1960, average loss: 1.0116
[09/16 13:52:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.31	rocauc: 84.80	
[09/16 13:52:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 13:52:12 visual_prompt]: Epoch 92 / 100: avg data time: 1.90e-01, avg batch time: 0.5944, average train loss: 0.0722
[09/16 13:52:18 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1434, average loss: 0.0245
[09/16 13:52:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 99.98	
[09/16 13:52:40 visual_prompt]: 	Test 100/512. loss: 0.983, 0.1955 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 13:53:00 visual_prompt]: 	Test 200/512. loss: 1.630, 0.1958 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 13:53:19 visual_prompt]: 	Test 300/512. loss: 0.655, 0.1843 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 13:53:39 visual_prompt]: 	Test 400/512. loss: 1.341, 0.2074 s / batch. (data: 2.44e-02)max mem: 17.22442 GB 
[09/16 13:53:59 visual_prompt]: 	Test 500/512. loss: 1.083, 0.2080 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 13:54:04 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1956, average loss: 1.1402
[09/16 13:54:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.60	rocauc: 85.10	
[09/16 13:54:04 visual_prompt]: Best epoch 92: best metric: 0.990
[09/16 13:54:04 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 13:54:16 visual_prompt]: Epoch 93 / 100: avg data time: 1.92e-01, avg batch time: 0.5982, average train loss: 0.0532
[09/16 13:54:22 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1432, average loss: 0.0374
[09/16 13:54:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.91	
[09/16 13:54:44 visual_prompt]: 	Test 100/512. loss: 0.741, 0.1987 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 13:55:04 visual_prompt]: 	Test 200/512. loss: 1.440, 0.1994 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 13:55:23 visual_prompt]: 	Test 300/512. loss: 0.675, 0.2105 s / batch. (data: 2.65e-02)max mem: 17.22442 GB 
[09/16 13:55:43 visual_prompt]: 	Test 400/512. loss: 1.386, 0.1843 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 13:56:02 visual_prompt]: 	Test 500/512. loss: 1.127, 0.2042 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 13:56:08 visual_prompt]: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1952, average loss: 1.0903
[09/16 13:56:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.14	rocauc: 84.99	
[09/16 13:56:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 13:56:20 visual_prompt]: Epoch 94 / 100: avg data time: 1.94e-01, avg batch time: 0.5990, average train loss: 0.0413
[09/16 13:56:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1434, average loss: 0.0150
[09/16 13:56:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 13:56:48 visual_prompt]: 	Test 100/512. loss: 1.029, 0.1875 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 13:57:08 visual_prompt]: 	Test 200/512. loss: 1.838, 0.2161 s / batch. (data: 3.32e-02)max mem: 17.22442 GB 
[09/16 13:57:28 visual_prompt]: 	Test 300/512. loss: 0.673, 0.2110 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 13:57:47 visual_prompt]: 	Test 400/512. loss: 1.525, 0.1963 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 13:58:07 visual_prompt]: 	Test 500/512. loss: 1.210, 0.2114 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 13:58:12 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1952, average loss: 1.2162
[09/16 13:58:12 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.59	rocauc: 84.35	
[09/16 13:58:12 visual_prompt]: Best epoch 94: best metric: 1.000
[09/16 13:58:12 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 13:58:24 visual_prompt]: Epoch 95 / 100: avg data time: 1.90e-01, avg batch time: 0.5964, average train loss: 0.0271
[09/16 13:58:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 0.0171
[09/16 13:58:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 13:58:52 visual_prompt]: 	Test 100/512. loss: 1.054, 0.1961 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 13:59:12 visual_prompt]: 	Test 200/512. loss: 1.928, 0.1969 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 13:59:31 visual_prompt]: 	Test 300/512. loss: 0.710, 0.1836 s / batch. (data: 3.70e-05)max mem: 17.22442 GB 
[09/16 13:59:51 visual_prompt]: 	Test 400/512. loss: 1.584, 0.1849 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 14:00:10 visual_prompt]: 	Test 500/512. loss: 1.305, 0.2037 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 14:00:15 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1941, average loss: 1.2791
[09/16 14:00:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.89	rocauc: 84.35	
[09/16 14:00:15 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 14:00:27 visual_prompt]: Epoch 96 / 100: avg data time: 1.97e-01, avg batch time: 0.6012, average train loss: 0.0311
[09/16 14:00:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1433, average loss: 0.0151
[09/16 14:00:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 14:00:55 visual_prompt]: 	Test 100/512. loss: 1.167, 0.1862 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 14:01:15 visual_prompt]: 	Test 200/512. loss: 1.983, 0.1842 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 14:01:34 visual_prompt]: 	Test 300/512. loss: 0.817, 0.2005 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 14:01:54 visual_prompt]: 	Test 400/512. loss: 1.732, 0.1840 s / batch. (data: 9.01e-05)max mem: 17.22442 GB 
[09/16 14:02:14 visual_prompt]: 	Test 500/512. loss: 1.370, 0.1841 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 14:02:19 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1948, average loss: 1.3774
[09/16 14:02:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.19	rocauc: 84.40	
[09/16 14:02:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 14:02:30 visual_prompt]: Epoch 97 / 100: avg data time: 2.03e-01, avg batch time: 0.6076, average train loss: 0.0232
[09/16 14:02:36 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1433, average loss: 0.0132
[09/16 14:02:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 100.00	
[09/16 14:02:59 visual_prompt]: 	Test 100/512. loss: 1.265, 0.1880 s / batch. (data: 1.04e-04)max mem: 17.22442 GB 
[09/16 14:03:18 visual_prompt]: 	Test 200/512. loss: 2.019, 0.1840 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 14:03:37 visual_prompt]: 	Test 300/512. loss: 0.858, 0.1846 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 14:03:57 visual_prompt]: 	Test 400/512. loss: 1.769, 0.1845 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 14:04:17 visual_prompt]: 	Test 500/512. loss: 1.437, 0.2015 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 14:04:21 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1943, average loss: 1.4005
[09/16 14:04:21 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.81	rocauc: 84.87	
[09/16 14:04:21 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 14:04:33 visual_prompt]: Epoch 98 / 100: avg data time: 1.92e-01, avg batch time: 0.5966, average train loss: 0.0188
[09/16 14:04:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1435, average loss: 0.0129
[09/16 14:04:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 100.00	
[09/16 14:05:02 visual_prompt]: 	Test 100/512. loss: 1.321, 0.1981 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 14:05:21 visual_prompt]: 	Test 200/512. loss: 2.061, 0.2005 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 14:05:41 visual_prompt]: 	Test 300/512. loss: 0.897, 0.2227 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 14:06:00 visual_prompt]: 	Test 400/512. loss: 1.813, 0.1845 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 14:06:20 visual_prompt]: 	Test 500/512. loss: 1.478, 0.1869 s / batch. (data: 1.10e-04)max mem: 17.22442 GB 
[09/16 14:06:25 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1948, average loss: 1.4379
[09/16 14:06:25 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.52	rocauc: 84.93	
[09/16 14:06:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 14:06:37 visual_prompt]: Epoch 99 / 100: avg data time: 1.98e-01, avg batch time: 0.6271, average train loss: 0.0128
[09/16 14:06:43 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1434, average loss: 0.0142
[09/16 14:06:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 100.00	
[09/16 14:07:06 visual_prompt]: 	Test 100/512. loss: 1.349, 0.2285 s / batch. (data: 3.14e-02)max mem: 17.22442 GB 
[09/16 14:07:25 visual_prompt]: 	Test 200/512. loss: 2.080, 0.1840 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 14:07:45 visual_prompt]: 	Test 300/512. loss: 0.921, 0.2003 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 14:08:04 visual_prompt]: 	Test 400/512. loss: 1.830, 0.1845 s / batch. (data: 5.10e-05)max mem: 17.22442 GB 
[09/16 14:08:24 visual_prompt]: 	Test 500/512. loss: 1.494, 0.1851 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 14:08:29 visual_prompt]: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1950, average loss: 1.4582
[09/16 14:08:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.33	rocauc: 84.87	
[09/16 14:08:29 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 14:08:41 visual_prompt]: Epoch 100 / 100: avg data time: 1.94e-01, avg batch time: 0.5965, average train loss: 0.0157
[09/16 14:08:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1434, average loss: 0.0113
[09/16 14:08:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 14:09:09 visual_prompt]: 	Test 100/512. loss: 1.326, 0.1842 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 14:09:29 visual_prompt]: 	Test 200/512. loss: 2.090, 0.2110 s / batch. (data: 2.75e-02)max mem: 17.22442 GB 
[09/16 14:09:49 visual_prompt]: 	Test 300/512. loss: 0.901, 0.1842 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 14:10:08 visual_prompt]: 	Test 400/512. loss: 1.821, 0.1963 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 14:10:28 visual_prompt]: 	Test 500/512. loss: 1.482, 0.2157 s / batch. (data: 3.23e-02)max mem: 17.22442 GB 
[09/16 14:10:33 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1950, average loss: 1.4453
[09/16 14:10:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.52	rocauc: 84.85	
[09/16 14:10:43 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 14:10:43 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 14:10:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-patch_camelyon', 'DATA.NUMBER_CLASSES', '2', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/16 14:10:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 14:10:43 visual_prompt]: Training with config:
[09/16 14:10:43 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-patch_camelyon',
          'NO_TEST': False,
          'NUMBER_CLASSES': 2,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-patch_camelyon/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 14:10:43 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 14:10:43.848100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 14:10:44.041592: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 14:10:44.945196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 14:10:44.945279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 14:10:44.945288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 14:10:47.010083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 14:10:47.010190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 14:10:47.010203: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 14:10:47 visual_prompt]: Constructing vtab-patch_camelyon dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
2023-09-16 14:10:47.027811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 14:10:48 visual_prompt]: Number of images: 1000
[09/16 14:10:48 visual_prompt]: Number of classes: 2 / 2
[09/16 14:10:48 visual_prompt]: Loading validation data...
[09/16 14:10:48 visual_prompt]: Constructing vtab-patch_camelyon dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 14:10:49 visual_prompt]: Number of images: 200
[09/16 14:10:49 visual_prompt]: Number of classes: 2 / 2
[09/16 14:10:49 visual_prompt]: Loading test data...
[09/16 14:10:49 visual_prompt]: Constructing vtab-patch_camelyon dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split test, from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 14:11:37 visual_prompt]: Number of images: 32768
[09/16 14:11:37 visual_prompt]: Number of classes: 2 / 2
[09/16 14:11:37 visual_prompt]: Constructing models...
[09/16 14:11:40 visual_prompt]: Total Parameters: 86721794	 Gradient Parameters: 923138
[09/16 14:11:40 visual_prompt]: tuned percent:1.064
[09/16 14:11:42 visual_prompt]: Device used for model: 0
[09/16 14:11:42 visual_prompt]: Setting up Evalutator...
[09/16 14:11:42 visual_prompt]: Setting up Trainer...
[09/16 14:11:42 visual_prompt]: 	Setting up the optimizer...
[09/16 14:11:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 14:11:56 visual_prompt]: Epoch 1 / 100: avg data time: 1.81e-01, avg batch time: 0.6759, average train loss: 1.3716
[09/16 14:12:02 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1428, average loss: 1.2238
[09/16 14:12:02 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 43.26	
[09/16 14:12:24 visual_prompt]: 	Test 100/512. loss: 1.245, 0.2013 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 14:12:44 visual_prompt]: 	Test 200/512. loss: 1.197, 0.1839 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 14:13:03 visual_prompt]: 	Test 300/512. loss: 1.338, 0.1958 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 14:13:23 visual_prompt]: 	Test 400/512. loss: 1.152, 0.2309 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 14:13:42 visual_prompt]: 	Test 500/512. loss: 1.199, 0.2106 s / batch. (data: 2.70e-02)max mem: 17.22442 GB 
[09/16 14:13:47 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1941, average loss: 1.2096
[09/16 14:13:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 48.18	
[09/16 14:13:47 visual_prompt]: Best epoch 1: best metric: 0.520
[09/16 14:13:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 14:13:59 visual_prompt]: Epoch 2 / 100: avg data time: 1.93e-01, avg batch time: 0.5972, average train loss: 8.7272
[09/16 14:14:05 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1435, average loss: 2.6784
[09/16 14:14:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 78.55	
[09/16 14:14:27 visual_prompt]: 	Test 100/512. loss: 2.905, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 14:14:47 visual_prompt]: 	Test 200/512. loss: 2.899, 0.2213 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 14:15:06 visual_prompt]: 	Test 300/512. loss: 3.183, 0.1938 s / batch. (data: 1.09e-02)max mem: 17.22442 GB 
[09/16 14:15:25 visual_prompt]: 	Test 400/512. loss: 2.654, 0.2163 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 14:15:45 visual_prompt]: 	Test 500/512. loss: 2.757, 0.1833 s / batch. (data: 3.08e-05)max mem: 17.22442 GB 
[09/16 14:15:50 visual_prompt]: Inference (test):avg data time: 6.93e-03, avg batch time: 0.1942, average loss: 2.8209
[09/16 14:15:50 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 72.38	
[09/16 14:15:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 14:16:01 visual_prompt]: Epoch 3 / 100: avg data time: 1.92e-01, avg batch time: 0.5956, average train loss: 1.2102
[09/16 14:16:07 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1436, average loss: 1.9228
[09/16 14:16:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 84.35	
[09/16 14:16:30 visual_prompt]: 	Test 100/512. loss: 2.094, 0.1836 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 14:16:49 visual_prompt]: 	Test 200/512. loss: 2.081, 0.2041 s / batch. (data: 1.85e-02)max mem: 17.22442 GB 
[09/16 14:17:09 visual_prompt]: 	Test 300/512. loss: 2.320, 0.1845 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 14:17:28 visual_prompt]: 	Test 400/512. loss: 1.941, 0.1834 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 14:17:49 visual_prompt]: 	Test 500/512. loss: 1.987, 0.1845 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 14:17:54 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1964, average loss: 2.0483
[09/16 14:17:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 77.53	
[09/16 14:17:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 14:18:05 visual_prompt]: Epoch 4 / 100: avg data time: 1.84e-01, avg batch time: 0.5891, average train loss: 2.3009
[09/16 14:18:11 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1435, average loss: 3.3151
[09/16 14:18:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 86.84	
[09/16 14:18:34 visual_prompt]: 	Test 100/512. loss: 3.061, 0.2052 s / batch. (data: 2.21e-02)max mem: 17.22442 GB 
[09/16 14:18:53 visual_prompt]: 	Test 200/512. loss: 3.298, 0.1939 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 14:19:12 visual_prompt]: 	Test 300/512. loss: 2.553, 0.1931 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 14:19:32 visual_prompt]: 	Test 400/512. loss: 3.282, 0.1846 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 14:19:52 visual_prompt]: 	Test 500/512. loss: 3.234, 0.2094 s / batch. (data: 2.60e-02)max mem: 17.22442 GB 
[09/16 14:19:56 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1946, average loss: 3.2149
[09/16 14:19:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 75.69	
[09/16 14:19:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 14:20:08 visual_prompt]: Epoch 5 / 100: avg data time: 1.91e-01, avg batch time: 0.5944, average train loss: 1.6756
[09/16 14:20:14 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1435, average loss: 0.5380
[09/16 14:20:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 69.50	rocauc: 88.74	
[09/16 14:20:36 visual_prompt]: 	Test 100/512. loss: 0.604, 0.1853 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 14:20:56 visual_prompt]: 	Test 200/512. loss: 0.682, 0.1878 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 14:21:16 visual_prompt]: 	Test 300/512. loss: 0.517, 0.1844 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 14:21:35 visual_prompt]: 	Test 400/512. loss: 0.710, 0.1851 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 14:21:55 visual_prompt]: 	Test 500/512. loss: 0.590, 0.1904 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 14:22:00 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1948, average loss: 0.6286
[09/16 14:22:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 67.93	rocauc: 80.29	
[09/16 14:22:00 visual_prompt]: Best epoch 5: best metric: 0.695
[09/16 14:22:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 14:22:12 visual_prompt]: Epoch 6 / 100: avg data time: 1.97e-01, avg batch time: 0.5995, average train loss: 2.7666
[09/16 14:22:18 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1457, average loss: 4.0359
[09/16 14:22:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 54.50	rocauc: 87.84	
[09/16 14:22:40 visual_prompt]: 	Test 100/512. loss: 3.479, 0.1945 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 14:23:00 visual_prompt]: 	Test 200/512. loss: 4.087, 0.2073 s / batch. (data: 1.37e-02)max mem: 17.22442 GB 
[09/16 14:23:20 visual_prompt]: 	Test 300/512. loss: 2.906, 0.2010 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 14:23:40 visual_prompt]: 	Test 400/512. loss: 3.857, 0.1987 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 14:23:59 visual_prompt]: 	Test 500/512. loss: 3.782, 0.1958 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 14:24:04 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1966, average loss: 3.8981
[09/16 14:24:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 55.47	rocauc: 78.94	
[09/16 14:24:04 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 14:24:16 visual_prompt]: Epoch 7 / 100: avg data time: 1.86e-01, avg batch time: 0.5902, average train loss: 1.9285
[09/16 14:24:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1433, average loss: 3.3120
[09/16 14:24:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 89.78	
[09/16 14:24:44 visual_prompt]: 	Test 100/512. loss: 3.781, 0.1981 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 14:25:03 visual_prompt]: 	Test 200/512. loss: 3.847, 0.1990 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 14:25:23 visual_prompt]: 	Test 300/512. loss: 4.130, 0.1837 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 14:25:42 visual_prompt]: 	Test 400/512. loss: 3.526, 0.1966 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 14:26:02 visual_prompt]: 	Test 500/512. loss: 3.512, 0.1853 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 14:26:07 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1951, average loss: 3.7108
[09/16 14:26:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 83.66	
[09/16 14:26:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 14:26:19 visual_prompt]: Epoch 8 / 100: avg data time: 1.81e-01, avg batch time: 0.5851, average train loss: 2.9120
[09/16 14:26:24 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1435, average loss: 5.4840
[09/16 14:26:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 89.41	
[09/16 14:26:47 visual_prompt]: 	Test 100/512. loss: 6.072, 0.2197 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 14:27:06 visual_prompt]: 	Test 200/512. loss: 6.166, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 14:27:26 visual_prompt]: 	Test 300/512. loss: 6.715, 0.1833 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 14:27:46 visual_prompt]: 	Test 400/512. loss: 5.673, 0.1991 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 14:28:05 visual_prompt]: 	Test 500/512. loss: 5.775, 0.1969 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 14:28:10 visual_prompt]: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1951, average loss: 5.9796
[09/16 14:28:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 81.95	
[09/16 14:28:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 14:28:22 visual_prompt]: Epoch 9 / 100: avg data time: 1.91e-01, avg batch time: 0.5950, average train loss: 6.0507
[09/16 14:28:27 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1433, average loss: 2.1438
[09/16 14:28:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 84.96	
[09/16 14:28:50 visual_prompt]: 	Test 100/512. loss: 2.376, 0.2312 s / batch. (data: 4.89e-02)max mem: 17.22442 GB 
[09/16 14:29:09 visual_prompt]: 	Test 200/512. loss: 2.386, 0.1847 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 14:29:29 visual_prompt]: 	Test 300/512. loss: 2.644, 0.2647 s / batch. (data: 9.32e-03)max mem: 17.22442 GB 
[09/16 14:29:48 visual_prompt]: 	Test 400/512. loss: 2.204, 0.1964 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 14:30:08 visual_prompt]: 	Test 500/512. loss: 2.248, 0.1960 s / batch. (data: 1.19e-02)max mem: 17.22442 GB 
[09/16 14:30:13 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1955, average loss: 2.3328
[09/16 14:30:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.80	rocauc: 79.02	
[09/16 14:30:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 14:30:25 visual_prompt]: Epoch 10 / 100: avg data time: 1.77e-01, avg batch time: 0.5815, average train loss: 7.3465
[09/16 14:30:30 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1435, average loss: 1.8827
[09/16 14:30:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 84.90	
[09/16 14:30:53 visual_prompt]: 	Test 100/512. loss: 1.731, 0.1838 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 14:31:13 visual_prompt]: 	Test 200/512. loss: 1.762, 0.1850 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 14:31:32 visual_prompt]: 	Test 300/512. loss: 1.563, 0.1966 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 14:31:52 visual_prompt]: 	Test 400/512. loss: 1.921, 0.1849 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 14:32:12 visual_prompt]: 	Test 500/512. loss: 1.862, 0.2075 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 14:32:16 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1958, average loss: 1.8179
[09/16 14:32:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 77.42	
[09/16 14:32:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 14:32:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.83e-01, avg batch time: 0.5858, average train loss: 8.9454
[09/16 14:32:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1436, average loss: 12.5252
[09/16 14:32:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 89.38	
[09/16 14:32:56 visual_prompt]: 	Test 100/512. loss: 11.631, 0.1842 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 14:33:16 visual_prompt]: 	Test 200/512. loss: 11.701, 0.2080 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 14:33:36 visual_prompt]: 	Test 300/512. loss: 10.493, 0.1879 s / batch. (data: 9.42e-05)max mem: 17.22442 GB 
[09/16 14:33:55 visual_prompt]: 	Test 400/512. loss: 12.813, 0.1903 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 14:34:15 visual_prompt]: 	Test 500/512. loss: 12.400, 0.2045 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 14:34:20 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1950, average loss: 12.0556
[09/16 14:34:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 82.20	
[09/16 14:34:20 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 14:34:31 visual_prompt]: Epoch 12 / 100: avg data time: 1.86e-01, avg batch time: 0.5949, average train loss: 8.4904
[09/16 14:34:37 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1434, average loss: 9.6732
[09/16 14:34:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 91.64	
[09/16 14:35:00 visual_prompt]: 	Test 100/512. loss: 10.514, 0.1961 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 14:35:19 visual_prompt]: 	Test 200/512. loss: 10.526, 0.1998 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 14:35:39 visual_prompt]: 	Test 300/512. loss: 11.505, 0.1847 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 14:35:59 visual_prompt]: 	Test 400/512. loss: 9.590, 0.1856 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 14:36:18 visual_prompt]: 	Test 500/512. loss: 9.869, 0.2116 s / batch. (data: 2.81e-02)max mem: 17.22442 GB 
[09/16 14:36:23 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1960, average loss: 10.2130
[09/16 14:36:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 83.34	
[09/16 14:36:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 14:36:35 visual_prompt]: Epoch 13 / 100: avg data time: 1.84e-01, avg batch time: 0.5965, average train loss: 7.3445
[09/16 14:36:41 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1433, average loss: 9.7210
[09/16 14:36:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 87.68	
[09/16 14:37:04 visual_prompt]: 	Test 100/512. loss: 8.962, 0.2074 s / batch. (data: 2.44e-02)max mem: 17.22442 GB 
[09/16 14:37:24 visual_prompt]: 	Test 200/512. loss: 9.154, 0.2084 s / batch. (data: 2.59e-02)max mem: 17.22442 GB 
[09/16 14:37:43 visual_prompt]: 	Test 300/512. loss: 8.016, 0.2103 s / batch. (data: 2.67e-02)max mem: 17.22442 GB 
[09/16 14:38:03 visual_prompt]: 	Test 400/512. loss: 9.880, 0.1994 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 14:38:22 visual_prompt]: 	Test 500/512. loss: 9.573, 0.1851 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 14:38:27 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1960, average loss: 9.3581
[09/16 14:38:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 78.81	
[09/16 14:38:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 14:38:39 visual_prompt]: Epoch 14 / 100: avg data time: 1.77e-01, avg batch time: 0.5832, average train loss: 6.5650
[09/16 14:38:44 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1436, average loss: 0.6059
[09/16 14:38:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 69.50	rocauc: 90.65	
[09/16 14:39:07 visual_prompt]: 	Test 100/512. loss: 0.645, 0.1836 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 14:39:27 visual_prompt]: 	Test 200/512. loss: 0.738, 0.1839 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 14:39:46 visual_prompt]: 	Test 300/512. loss: 0.487, 0.1972 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 14:40:07 visual_prompt]: 	Test 400/512. loss: 0.832, 0.1946 s / batch. (data: 1.05e-02)max mem: 17.22442 GB 
[09/16 14:40:26 visual_prompt]: 	Test 500/512. loss: 0.626, 0.2017 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 14:40:31 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1970, average loss: 0.6907
[09/16 14:40:31 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.58	rocauc: 81.34	
[09/16 14:40:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 14:40:44 visual_prompt]: Epoch 15 / 100: avg data time: 1.93e-01, avg batch time: 0.5993, average train loss: 4.8753
[09/16 14:40:49 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1433, average loss: 8.8459
[09/16 14:40:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 91.08	
[09/16 14:41:12 visual_prompt]: 	Test 100/512. loss: 10.543, 0.1842 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 14:41:31 visual_prompt]: 	Test 200/512. loss: 10.425, 0.1844 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 14:41:51 visual_prompt]: 	Test 300/512. loss: 11.396, 0.1848 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 14:42:10 visual_prompt]: 	Test 400/512. loss: 9.677, 0.1849 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 14:42:30 visual_prompt]: 	Test 500/512. loss: 9.709, 0.1853 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 14:42:35 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1953, average loss: 10.1087
[09/16 14:42:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 81.80	
[09/16 14:42:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 14:42:47 visual_prompt]: Epoch 16 / 100: avg data time: 1.87e-01, avg batch time: 0.5906, average train loss: 6.3597
[09/16 14:42:52 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1433, average loss: 0.4430
[09/16 14:42:52 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.50	rocauc: 90.91	
[09/16 14:43:15 visual_prompt]: 	Test 100/512. loss: 0.700, 0.2044 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 14:43:36 visual_prompt]: 	Test 200/512. loss: 0.756, 0.1963 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 14:43:55 visual_prompt]: 	Test 300/512. loss: 0.775, 0.2148 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 14:44:15 visual_prompt]: 	Test 400/512. loss: 0.800, 0.1848 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 14:44:35 visual_prompt]: 	Test 500/512. loss: 0.717, 0.2035 s / batch. (data: 1.98e-02)max mem: 17.22442 GB 
[09/16 14:44:40 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1971, average loss: 0.7275
[09/16 14:44:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.03	rocauc: 80.43	
[09/16 14:44:40 visual_prompt]: Best epoch 16: best metric: 0.865
[09/16 14:44:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 14:44:52 visual_prompt]: Epoch 17 / 100: avg data time: 1.91e-01, avg batch time: 0.5952, average train loss: 1.4049
[09/16 14:44:57 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1435, average loss: 0.5624
[09/16 14:44:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.00	rocauc: 91.65	
[09/16 14:45:20 visual_prompt]: 	Test 100/512. loss: 0.996, 0.1836 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 14:45:39 visual_prompt]: 	Test 200/512. loss: 1.018, 0.1931 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 14:45:59 visual_prompt]: 	Test 300/512. loss: 1.012, 0.1959 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 14:46:19 visual_prompt]: 	Test 400/512. loss: 1.070, 0.1995 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 14:46:38 visual_prompt]: 	Test 500/512. loss: 1.030, 0.1986 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 14:46:43 visual_prompt]: Inference (test):avg data time: 8.29e-03, avg batch time: 0.1951, average loss: 0.9921
[09/16 14:46:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.87	rocauc: 82.31	
[09/16 14:46:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 14:46:55 visual_prompt]: Epoch 18 / 100: avg data time: 2.00e-01, avg batch time: 0.6018, average train loss: 1.0437
[09/16 14:47:01 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1434, average loss: 0.9838
[09/16 14:47:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 57.00	rocauc: 92.29	
[09/16 14:47:23 visual_prompt]: 	Test 100/512. loss: 1.508, 0.1845 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 14:47:43 visual_prompt]: 	Test 200/512. loss: 1.453, 0.2280 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 14:48:02 visual_prompt]: 	Test 300/512. loss: 1.582, 0.1843 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 14:48:22 visual_prompt]: 	Test 400/512. loss: 1.440, 0.1851 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 14:48:41 visual_prompt]: 	Test 500/512. loss: 1.331, 0.1886 s / batch. (data: 1.10e-04)max mem: 17.22442 GB 
[09/16 14:48:46 visual_prompt]: Inference (test):avg data time: 6.80e-03, avg batch time: 0.1951, average loss: 1.4176
[09/16 14:48:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 52.13	rocauc: 83.40	
[09/16 14:48:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 14:48:58 visual_prompt]: Epoch 19 / 100: avg data time: 1.92e-01, avg batch time: 0.5939, average train loss: 0.8309
[09/16 14:49:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1435, average loss: 1.8074
[09/16 14:49:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 92.87	
[09/16 14:49:26 visual_prompt]: 	Test 100/512. loss: 2.473, 0.2074 s / batch. (data: 2.45e-02)max mem: 17.22442 GB 
[09/16 14:49:45 visual_prompt]: 	Test 200/512. loss: 2.525, 0.1837 s / batch. (data: 8.65e-05)max mem: 17.22442 GB 
[09/16 14:50:05 visual_prompt]: 	Test 300/512. loss: 2.710, 0.2092 s / batch. (data: 2.59e-02)max mem: 17.22442 GB 
[09/16 14:50:25 visual_prompt]: 	Test 400/512. loss: 2.350, 0.1842 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 14:50:44 visual_prompt]: 	Test 500/512. loss: 2.361, 0.1845 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 14:50:49 visual_prompt]: Inference (test):avg data time: 8.29e-03, avg batch time: 0.1957, average loss: 2.4075
[09/16 14:50:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 85.17	
[09/16 14:50:49 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 14:51:01 visual_prompt]: Epoch 20 / 100: avg data time: 1.91e-01, avg batch time: 0.6001, average train loss: 2.0982
[09/16 14:51:07 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1480, average loss: 3.1510
[09/16 14:51:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 63.00	rocauc: 67.40	
[09/16 14:51:30 visual_prompt]: 	Test 100/512. loss: 2.962, 0.1971 s / batch. (data: 7.22e-03)max mem: 17.22442 GB 
[09/16 14:51:50 visual_prompt]: 	Test 200/512. loss: 3.575, 0.2166 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 14:52:09 visual_prompt]: 	Test 300/512. loss: 1.846, 0.2076 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 14:52:29 visual_prompt]: 	Test 400/512. loss: 3.051, 0.1840 s / batch. (data: 1.71e-04)max mem: 17.22442 GB 
[09/16 14:52:49 visual_prompt]: 	Test 500/512. loss: 2.911, 0.2009 s / batch. (data: 1.73e-02)max mem: 17.22442 GB 
[09/16 14:52:54 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1961, average loss: 2.9923
[09/16 14:52:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.79	rocauc: 64.22	
[09/16 14:52:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 14:53:06 visual_prompt]: Epoch 21 / 100: avg data time: 1.95e-01, avg batch time: 0.6029, average train loss: 2.4303
[09/16 14:53:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1434, average loss: 1.9575
[09/16 14:53:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 90.68	
[09/16 14:53:34 visual_prompt]: 	Test 100/512. loss: 1.822, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 14:53:54 visual_prompt]: 	Test 200/512. loss: 1.953, 0.1835 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 14:54:13 visual_prompt]: 	Test 300/512. loss: 1.638, 0.1842 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 14:54:33 visual_prompt]: 	Test 400/512. loss: 2.114, 0.1928 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 14:54:52 visual_prompt]: 	Test 500/512. loss: 1.889, 0.2099 s / batch. (data: 2.63e-02)max mem: 17.22442 GB 
[09/16 14:54:57 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1958, average loss: 1.9409
[09/16 14:54:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 83.98	
[09/16 14:54:57 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 14:55:09 visual_prompt]: Epoch 22 / 100: avg data time: 1.88e-01, avg batch time: 0.5916, average train loss: 1.6533
[09/16 14:55:14 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1435, average loss: 0.8603
[09/16 14:55:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 71.00	rocauc: 91.78	
[09/16 14:55:37 visual_prompt]: 	Test 100/512. loss: 1.009, 0.1841 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 14:55:57 visual_prompt]: 	Test 200/512. loss: 1.194, 0.1944 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 14:56:17 visual_prompt]: 	Test 300/512. loss: 0.605, 0.2366 s / batch. (data: 3.78e-02)max mem: 17.22442 GB 
[09/16 14:56:36 visual_prompt]: 	Test 400/512. loss: 1.087, 0.1983 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 14:56:56 visual_prompt]: 	Test 500/512. loss: 0.702, 0.1843 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 14:57:01 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1964, average loss: 0.9823
[09/16 14:57:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.63	rocauc: 84.57	
[09/16 14:57:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 14:57:13 visual_prompt]: Epoch 23 / 100: avg data time: 1.86e-01, avg batch time: 0.5908, average train loss: 1.1092
[09/16 14:57:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1434, average loss: 1.6123
[09/16 14:57:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 91.42	
[09/16 14:57:41 visual_prompt]: 	Test 100/512. loss: 2.080, 0.1956 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 14:58:00 visual_prompt]: 	Test 200/512. loss: 2.192, 0.1850 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 14:58:20 visual_prompt]: 	Test 300/512. loss: 2.307, 0.1995 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 14:58:39 visual_prompt]: 	Test 400/512. loss: 1.983, 0.1846 s / batch. (data: 9.35e-05)max mem: 17.22442 GB 
[09/16 14:58:59 visual_prompt]: 	Test 500/512. loss: 1.938, 0.1847 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 14:59:04 visual_prompt]: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1945, average loss: 2.0807
[09/16 14:59:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 84.45	
[09/16 14:59:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 14:59:15 visual_prompt]: Epoch 24 / 100: avg data time: 1.91e-01, avg batch time: 0.5951, average train loss: 0.9394
[09/16 14:59:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1435, average loss: 0.4289
[09/16 14:59:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 93.09	
[09/16 14:59:43 visual_prompt]: 	Test 100/512. loss: 0.672, 0.1960 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 15:00:03 visual_prompt]: 	Test 200/512. loss: 0.634, 0.1934 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 15:00:22 visual_prompt]: 	Test 300/512. loss: 0.615, 0.1993 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 15:00:42 visual_prompt]: 	Test 400/512. loss: 0.703, 0.2027 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 15:01:02 visual_prompt]: 	Test 500/512. loss: 0.596, 0.2340 s / batch. (data: 3.28e-02)max mem: 17.22442 GB 
[09/16 15:01:06 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1949, average loss: 0.6331
[09/16 15:01:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.07	rocauc: 85.06	
[09/16 15:01:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 15:01:18 visual_prompt]: Epoch 25 / 100: avg data time: 1.98e-01, avg batch time: 0.6014, average train loss: 0.6963
[09/16 15:01:24 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1435, average loss: 0.4981
[09/16 15:01:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.50	rocauc: 93.81	
[09/16 15:01:47 visual_prompt]: 	Test 100/512. loss: 0.599, 0.1835 s / batch. (data: 3.46e-05)max mem: 17.22442 GB 
[09/16 15:02:07 visual_prompt]: 	Test 200/512. loss: 0.706, 0.2076 s / batch. (data: 2.42e-02)max mem: 17.22442 GB 
[09/16 15:02:26 visual_prompt]: 	Test 300/512. loss: 0.372, 0.1946 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 15:02:46 visual_prompt]: 	Test 400/512. loss: 0.661, 0.1845 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 15:03:06 visual_prompt]: 	Test 500/512. loss: 0.464, 0.1866 s / batch. (data: 1.76e-04)max mem: 17.22442 GB 
[09/16 15:03:11 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1963, average loss: 0.6130
[09/16 15:03:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.25	rocauc: 85.81	
[09/16 15:03:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 15:03:22 visual_prompt]: Epoch 26 / 100: avg data time: 1.80e-01, avg batch time: 0.5859, average train loss: 0.5923
[09/16 15:03:28 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1435, average loss: 0.3809
[09/16 15:03:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 94.48	
[09/16 15:03:50 visual_prompt]: 	Test 100/512. loss: 0.593, 0.1846 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 15:04:10 visual_prompt]: 	Test 200/512. loss: 0.568, 0.1847 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 15:04:30 visual_prompt]: 	Test 300/512. loss: 0.581, 0.1989 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 15:04:50 visual_prompt]: 	Test 400/512. loss: 0.578, 0.1957 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 15:05:09 visual_prompt]: 	Test 500/512. loss: 0.503, 0.2051 s / batch. (data: 2.13e-02)max mem: 17.22442 GB 
[09/16 15:05:14 visual_prompt]: Inference (test):avg data time: 9.35e-03, avg batch time: 0.1964, average loss: 0.5628
[09/16 15:05:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.30	rocauc: 86.60	
[09/16 15:05:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 15:05:26 visual_prompt]: Epoch 27 / 100: avg data time: 1.98e-01, avg batch time: 0.6002, average train loss: 0.5917
[09/16 15:05:32 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1435, average loss: 0.3237
[09/16 15:05:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.50	rocauc: 95.20	
[09/16 15:05:54 visual_prompt]: 	Test 100/512. loss: 0.507, 0.1844 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 15:06:14 visual_prompt]: 	Test 200/512. loss: 0.479, 0.1846 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 15:06:33 visual_prompt]: 	Test 300/512. loss: 0.405, 0.2093 s / batch. (data: 2.06e-02)max mem: 17.22442 GB 
[09/16 15:06:53 visual_prompt]: 	Test 400/512. loss: 0.463, 0.1843 s / batch. (data: 9.04e-05)max mem: 17.22442 GB 
[09/16 15:07:13 visual_prompt]: 	Test 500/512. loss: 0.381, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 15:07:18 visual_prompt]: Inference (test):avg data time: 8.52e-03, avg batch time: 0.1952, average loss: 0.4786
[09/16 15:07:18 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.70	rocauc: 87.32	
[09/16 15:07:18 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 15:07:30 visual_prompt]: Epoch 28 / 100: avg data time: 1.88e-01, avg batch time: 0.5926, average train loss: 0.5661
[09/16 15:07:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1436, average loss: 0.4686
[09/16 15:07:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.00	rocauc: 91.92	
[09/16 15:07:58 visual_prompt]: 	Test 100/512. loss: 0.567, 0.2038 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 15:08:17 visual_prompt]: 	Test 200/512. loss: 0.574, 0.1959 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 15:08:37 visual_prompt]: 	Test 300/512. loss: 0.362, 0.1841 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 15:08:57 visual_prompt]: 	Test 400/512. loss: 0.677, 0.1980 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 15:09:16 visual_prompt]: 	Test 500/512. loss: 0.503, 0.1954 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 15:09:22 visual_prompt]: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1954, average loss: 0.5870
[09/16 15:09:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.34	rocauc: 82.88	
[09/16 15:09:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 15:09:34 visual_prompt]: Epoch 29 / 100: avg data time: 1.95e-01, avg batch time: 0.5993, average train loss: 0.7137
[09/16 15:09:39 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1435, average loss: 0.3436
[09/16 15:09:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 94.65	
[09/16 15:10:02 visual_prompt]: 	Test 100/512. loss: 0.662, 0.1957 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 15:10:21 visual_prompt]: 	Test 200/512. loss: 0.619, 0.1847 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 15:10:42 visual_prompt]: 	Test 300/512. loss: 0.580, 0.1988 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 15:11:01 visual_prompt]: 	Test 400/512. loss: 0.581, 0.1844 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 15:11:21 visual_prompt]: 	Test 500/512. loss: 0.487, 0.1838 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 15:11:26 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1960, average loss: 0.5883
[09/16 15:11:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.89	rocauc: 86.57	
[09/16 15:11:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 15:11:37 visual_prompt]: Epoch 30 / 100: avg data time: 1.90e-01, avg batch time: 0.5947, average train loss: 0.5315
[09/16 15:11:43 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1438, average loss: 0.3374
[09/16 15:11:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 95.33	
[09/16 15:12:06 visual_prompt]: 	Test 100/512. loss: 0.467, 0.1975 s / batch. (data: 4.87e-03)max mem: 17.22442 GB 
[09/16 15:12:25 visual_prompt]: 	Test 200/512. loss: 0.499, 0.1982 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 15:12:45 visual_prompt]: 	Test 300/512. loss: 0.333, 0.1957 s / batch. (data: 1.21e-02)max mem: 17.22442 GB 
[09/16 15:13:04 visual_prompt]: 	Test 400/512. loss: 0.467, 0.1958 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 15:13:24 visual_prompt]: 	Test 500/512. loss: 0.373, 0.1964 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 15:13:29 visual_prompt]: Inference (test):avg data time: 8.78e-03, avg batch time: 0.1954, average loss: 0.4547
[09/16 15:13:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.14	rocauc: 87.10	
[09/16 15:13:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 15:13:41 visual_prompt]: Epoch 31 / 100: avg data time: 1.90e-01, avg batch time: 0.5989, average train loss: 0.6375
[09/16 15:13:47 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1434, average loss: 0.3261
[09/16 15:13:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.50	rocauc: 95.67	
[09/16 15:14:09 visual_prompt]: 	Test 100/512. loss: 0.593, 0.1982 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 15:14:29 visual_prompt]: 	Test 200/512. loss: 0.533, 0.2308 s / batch. (data: 4.01e-02)max mem: 17.22442 GB 
[09/16 15:14:49 visual_prompt]: 	Test 300/512. loss: 0.521, 0.2118 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 15:15:09 visual_prompt]: 	Test 400/512. loss: 0.548, 0.1839 s / batch. (data: 8.63e-05)max mem: 17.22442 GB 
[09/16 15:15:28 visual_prompt]: 	Test 500/512. loss: 0.441, 0.1847 s / batch. (data: 9.51e-05)max mem: 17.22442 GB 
[09/16 15:15:33 visual_prompt]: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1966, average loss: 0.5272
[09/16 15:15:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.08	rocauc: 87.93	
[09/16 15:15:33 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 15:15:45 visual_prompt]: Epoch 32 / 100: avg data time: 1.96e-01, avg batch time: 0.5988, average train loss: 0.5468
[09/16 15:15:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1433, average loss: 0.5865
[09/16 15:15:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 95.41	
[09/16 15:16:14 visual_prompt]: 	Test 100/512. loss: 1.145, 0.2117 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 15:16:33 visual_prompt]: 	Test 200/512. loss: 1.061, 0.2007 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 15:16:53 visual_prompt]: 	Test 300/512. loss: 1.097, 0.1964 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 15:17:13 visual_prompt]: 	Test 400/512. loss: 0.953, 0.1965 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 15:17:32 visual_prompt]: 	Test 500/512. loss: 0.868, 0.1848 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 15:17:37 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1962, average loss: 1.0165
[09/16 15:17:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.81	rocauc: 86.78	
[09/16 15:17:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 15:17:49 visual_prompt]: Epoch 33 / 100: avg data time: 1.95e-01, avg batch time: 0.5989, average train loss: 0.8395
[09/16 15:17:55 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1435, average loss: 1.0806
[09/16 15:17:55 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 94.37	
[09/16 15:18:18 visual_prompt]: 	Test 100/512. loss: 1.495, 0.1958 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 15:18:37 visual_prompt]: 	Test 200/512. loss: 1.484, 0.1845 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 15:18:57 visual_prompt]: 	Test 300/512. loss: 1.615, 0.2029 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 15:19:16 visual_prompt]: 	Test 400/512. loss: 1.415, 0.1852 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 15:19:36 visual_prompt]: 	Test 500/512. loss: 1.348, 0.1849 s / batch. (data: 1.67e-04)max mem: 17.22442 GB 
[09/16 15:19:41 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1964, average loss: 1.4549
[09/16 15:19:41 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 86.41	
[09/16 15:19:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 15:19:53 visual_prompt]: Epoch 34 / 100: avg data time: 1.85e-01, avg batch time: 0.5929, average train loss: 0.7156
[09/16 15:19:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1435, average loss: 0.4285
[09/16 15:19:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 93.00	
[09/16 15:20:21 visual_prompt]: 	Test 100/512. loss: 0.537, 0.2082 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 15:20:41 visual_prompt]: 	Test 200/512. loss: 0.606, 0.1852 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 15:21:00 visual_prompt]: 	Test 300/512. loss: 0.366, 0.2058 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 15:21:21 visual_prompt]: 	Test 400/512. loss: 0.571, 0.1847 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 15:21:40 visual_prompt]: 	Test 500/512. loss: 0.405, 0.1965 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 15:21:45 visual_prompt]: Inference (test):avg data time: 8.76e-03, avg batch time: 0.1973, average loss: 0.5096
[09/16 15:21:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.71	rocauc: 85.75	
[09/16 15:21:45 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 15:21:57 visual_prompt]: Epoch 35 / 100: avg data time: 1.94e-01, avg batch time: 0.6027, average train loss: 0.5456
[09/16 15:22:03 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1438, average loss: 1.7064
[09/16 15:22:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 54.00	rocauc: 87.83	
[09/16 15:22:25 visual_prompt]: 	Test 100/512. loss: 2.129, 0.1840 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 15:22:45 visual_prompt]: 	Test 200/512. loss: 2.341, 0.1930 s / batch. (data: 9.16e-05)max mem: 17.22442 GB 
[09/16 15:23:04 visual_prompt]: 	Test 300/512. loss: 2.341, 0.2167 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 15:23:24 visual_prompt]: 	Test 400/512. loss: 1.943, 0.1838 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 15:23:44 visual_prompt]: 	Test 500/512. loss: 1.922, 0.1844 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 15:23:48 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1951, average loss: 2.1503
[09/16 15:23:48 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.33	rocauc: 79.23	
[09/16 15:23:48 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 15:24:00 visual_prompt]: Epoch 36 / 100: avg data time: 1.93e-01, avg batch time: 0.5960, average train loss: 0.6596
[09/16 15:24:06 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 0.5482
[09/16 15:24:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 77.00	rocauc: 95.33	
[09/16 15:24:29 visual_prompt]: 	Test 100/512. loss: 0.570, 0.1985 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 15:24:48 visual_prompt]: 	Test 200/512. loss: 0.676, 0.1843 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 15:25:08 visual_prompt]: 	Test 300/512. loss: 0.389, 0.2119 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 15:25:28 visual_prompt]: 	Test 400/512. loss: 0.687, 0.1850 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 15:25:48 visual_prompt]: 	Test 500/512. loss: 0.562, 0.1857 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 15:25:53 visual_prompt]: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1966, average loss: 0.6305
[09/16 15:25:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.88	rocauc: 88.81	
[09/16 15:25:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 15:26:05 visual_prompt]: Epoch 37 / 100: avg data time: 1.82e-01, avg batch time: 0.5873, average train loss: 0.4273
[09/16 15:26:10 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1436, average loss: 0.3829
[09/16 15:26:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.00	rocauc: 95.22	
[09/16 15:26:33 visual_prompt]: 	Test 100/512. loss: 0.695, 0.1971 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 15:26:53 visual_prompt]: 	Test 200/512. loss: 0.678, 0.1959 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 15:27:12 visual_prompt]: 	Test 300/512. loss: 0.670, 0.2043 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 15:27:32 visual_prompt]: 	Test 400/512. loss: 0.586, 0.1987 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 15:27:52 visual_prompt]: 	Test 500/512. loss: 0.554, 0.1854 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 15:27:57 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1957, average loss: 0.6391
[09/16 15:27:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.41	rocauc: 87.12	
[09/16 15:27:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 15:28:08 visual_prompt]: Epoch 38 / 100: avg data time: 1.92e-01, avg batch time: 0.5955, average train loss: 0.4258
[09/16 15:28:14 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1435, average loss: 0.4950
[09/16 15:28:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.00	rocauc: 96.46	
[09/16 15:28:37 visual_prompt]: 	Test 100/512. loss: 0.878, 0.2046 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 15:28:56 visual_prompt]: 	Test 200/512. loss: 0.898, 0.1844 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 15:29:16 visual_prompt]: 	Test 300/512. loss: 0.932, 0.1876 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 15:29:35 visual_prompt]: 	Test 400/512. loss: 0.828, 0.2103 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 15:29:55 visual_prompt]: 	Test 500/512. loss: 0.785, 0.1853 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 15:30:00 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1939, average loss: 0.8690
[09/16 15:30:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 63.35	rocauc: 88.58	
[09/16 15:30:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 15:30:11 visual_prompt]: Epoch 39 / 100: avg data time: 2.00e-01, avg batch time: 0.6043, average train loss: 0.5754
[09/16 15:30:17 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1433, average loss: 0.2838
[09/16 15:30:17 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 96.66	
[09/16 15:30:39 visual_prompt]: 	Test 100/512. loss: 0.494, 0.2001 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 15:30:59 visual_prompt]: 	Test 200/512. loss: 0.537, 0.1844 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 15:31:18 visual_prompt]: 	Test 300/512. loss: 0.457, 0.1991 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 15:31:38 visual_prompt]: 	Test 400/512. loss: 0.486, 0.1857 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 15:31:57 visual_prompt]: 	Test 500/512. loss: 0.412, 0.1997 s / batch. (data: 2.14e-04)max mem: 17.22442 GB 
[09/16 15:32:02 visual_prompt]: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1941, average loss: 0.4930
[09/16 15:32:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.32	rocauc: 89.27	
[09/16 15:32:02 visual_prompt]: Best epoch 39: best metric: 0.900
[09/16 15:32:02 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 15:32:14 visual_prompt]: Epoch 40 / 100: avg data time: 1.92e-01, avg batch time: 0.5955, average train loss: 0.4132
[09/16 15:32:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1436, average loss: 0.2496
[09/16 15:32:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.00	rocauc: 97.03	
[09/16 15:32:42 visual_prompt]: 	Test 100/512. loss: 0.451, 0.1843 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 15:33:01 visual_prompt]: 	Test 200/512. loss: 0.472, 0.1851 s / batch. (data: 1.72e-03)max mem: 17.22442 GB 
[09/16 15:33:21 visual_prompt]: 	Test 300/512. loss: 0.284, 0.2094 s / batch. (data: 2.52e-02)max mem: 17.22442 GB 
[09/16 15:33:41 visual_prompt]: 	Test 400/512. loss: 0.450, 0.1838 s / batch. (data: 3.81e-05)max mem: 17.22442 GB 
[09/16 15:34:01 visual_prompt]: 	Test 500/512. loss: 0.329, 0.2012 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 15:34:05 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1957, average loss: 0.4177
[09/16 15:34:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.42	rocauc: 89.43	
[09/16 15:34:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 15:34:17 visual_prompt]: Epoch 41 / 100: avg data time: 1.89e-01, avg batch time: 0.5950, average train loss: 0.5401
[09/16 15:34:23 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1437, average loss: 0.3112
[09/16 15:34:23 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 96.93	
[09/16 15:34:46 visual_prompt]: 	Test 100/512. loss: 0.468, 0.1851 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 15:35:06 visual_prompt]: 	Test 200/512. loss: 0.536, 0.2038 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 15:35:26 visual_prompt]: 	Test 300/512. loss: 0.353, 0.1918 s / batch. (data: 7.75e-03)max mem: 17.22442 GB 
[09/16 15:35:46 visual_prompt]: 	Test 400/512. loss: 0.546, 0.1845 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 15:36:06 visual_prompt]: 	Test 500/512. loss: 0.438, 0.1846 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 15:36:10 visual_prompt]: Inference (test):avg data time: 8.75e-03, avg batch time: 0.1985, average loss: 0.4840
[09/16 15:36:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.89	rocauc: 87.67	
[09/16 15:36:10 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 15:36:22 visual_prompt]: Epoch 42 / 100: avg data time: 1.78e-01, avg batch time: 0.5843, average train loss: 0.4426
[09/16 15:36:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1433, average loss: 0.2387
[09/16 15:36:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.00	rocauc: 97.33	
[09/16 15:36:51 visual_prompt]: 	Test 100/512. loss: 0.434, 0.2129 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 15:37:11 visual_prompt]: 	Test 200/512. loss: 0.496, 0.2296 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 15:37:30 visual_prompt]: 	Test 300/512. loss: 0.331, 0.1842 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 15:37:50 visual_prompt]: 	Test 400/512. loss: 0.447, 0.1989 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 15:38:09 visual_prompt]: 	Test 500/512. loss: 0.337, 0.1991 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 15:38:14 visual_prompt]: Inference (test):avg data time: 8.52e-03, avg batch time: 0.1964, average loss: 0.4243
[09/16 15:38:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.85	rocauc: 88.90	
[09/16 15:38:14 visual_prompt]: Best epoch 42: best metric: 0.920
[09/16 15:38:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 15:38:26 visual_prompt]: Epoch 43 / 100: avg data time: 1.89e-01, avg batch time: 0.5917, average train loss: 0.4390
[09/16 15:38:32 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1433, average loss: 0.2797
[09/16 15:38:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.50	rocauc: 96.88	
[09/16 15:38:54 visual_prompt]: 	Test 100/512. loss: 0.379, 0.1973 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 15:39:14 visual_prompt]: 	Test 200/512. loss: 0.398, 0.2112 s / batch. (data: 2.80e-02)max mem: 17.22442 GB 
[09/16 15:39:34 visual_prompt]: 	Test 300/512. loss: 0.280, 0.2109 s / batch. (data: 2.74e-02)max mem: 17.22442 GB 
[09/16 15:39:54 visual_prompt]: 	Test 400/512. loss: 0.406, 0.1985 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 15:40:13 visual_prompt]: 	Test 500/512. loss: 0.326, 0.1963 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 15:40:18 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1969, average loss: 0.3910
[09/16 15:40:18 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.93	rocauc: 90.75	
[09/16 15:40:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 15:40:30 visual_prompt]: Epoch 44 / 100: avg data time: 1.92e-01, avg batch time: 0.5950, average train loss: 0.3700
[09/16 15:40:36 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1434, average loss: 0.2711
[09/16 15:40:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.50	rocauc: 95.74	
[09/16 15:40:58 visual_prompt]: 	Test 100/512. loss: 0.427, 0.1843 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 15:41:18 visual_prompt]: 	Test 200/512. loss: 0.360, 0.2212 s / batch. (data: 3.29e-02)max mem: 17.22442 GB 
[09/16 15:41:37 visual_prompt]: 	Test 300/512. loss: 0.418, 0.1984 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 15:41:58 visual_prompt]: 	Test 400/512. loss: 0.567, 0.1963 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 15:42:17 visual_prompt]: 	Test 500/512. loss: 0.391, 0.1837 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 15:42:22 visual_prompt]: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1960, average loss: 0.4449
[09/16 15:42:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.05	rocauc: 90.38	
[09/16 15:42:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 15:42:34 visual_prompt]: Epoch 45 / 100: avg data time: 1.93e-01, avg batch time: 0.5957, average train loss: 0.4327
[09/16 15:42:39 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1434, average loss: 0.4482
[09/16 15:42:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 75.00	rocauc: 97.50	
[09/16 15:43:02 visual_prompt]: 	Test 100/512. loss: 0.922, 0.1845 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 15:43:22 visual_prompt]: 	Test 200/512. loss: 0.963, 0.1941 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 15:43:41 visual_prompt]: 	Test 300/512. loss: 0.856, 0.1911 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 15:44:01 visual_prompt]: 	Test 400/512. loss: 0.743, 0.1842 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 15:44:20 visual_prompt]: 	Test 500/512. loss: 0.786, 0.1862 s / batch. (data: 1.05e-04)max mem: 17.22442 GB 
[09/16 15:44:25 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1952, average loss: 0.8584
[09/16 15:44:25 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 61.88	rocauc: 87.87	
[09/16 15:44:25 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 15:44:37 visual_prompt]: Epoch 46 / 100: avg data time: 1.96e-01, avg batch time: 0.6014, average train loss: 0.3384
[09/16 15:44:43 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1434, average loss: 0.4166
[09/16 15:44:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 97.41	
[09/16 15:45:06 visual_prompt]: 	Test 100/512. loss: 0.557, 0.1848 s / batch. (data: 1.68e-04)max mem: 17.22442 GB 
[09/16 15:45:25 visual_prompt]: 	Test 200/512. loss: 0.552, 0.2124 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 15:45:45 visual_prompt]: 	Test 300/512. loss: 0.229, 0.2015 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 15:46:04 visual_prompt]: 	Test 400/512. loss: 0.628, 0.1840 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 15:46:24 visual_prompt]: 	Test 500/512. loss: 0.483, 0.2068 s / batch. (data: 2.33e-02)max mem: 17.22442 GB 
[09/16 15:46:29 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1949, average loss: 0.5510
[09/16 15:46:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.95	rocauc: 91.49	
[09/16 15:46:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 15:46:41 visual_prompt]: Epoch 47 / 100: avg data time: 1.95e-01, avg batch time: 0.6016, average train loss: 0.3830
[09/16 15:46:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1434, average loss: 0.3205
[09/16 15:46:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 97.01	
[09/16 15:47:09 visual_prompt]: 	Test 100/512. loss: 0.482, 0.1843 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 15:47:30 visual_prompt]: 	Test 200/512. loss: 0.484, 0.1958 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 15:47:50 visual_prompt]: 	Test 300/512. loss: 0.212, 0.2095 s / batch. (data: 1.09e-02)max mem: 17.22442 GB 
[09/16 15:48:09 visual_prompt]: 	Test 400/512. loss: 0.472, 0.1852 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 15:48:29 visual_prompt]: 	Test 500/512. loss: 0.391, 0.1850 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 15:48:34 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1978, average loss: 0.4709
[09/16 15:48:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.55	rocauc: 90.27	
[09/16 15:48:34 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 15:48:45 visual_prompt]: Epoch 48 / 100: avg data time: 1.87e-01, avg batch time: 0.5917, average train loss: 1.2439
[09/16 15:48:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1435, average loss: 0.4473
[09/16 15:48:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 95.51	
[09/16 15:49:14 visual_prompt]: 	Test 100/512. loss: 0.548, 0.1951 s / batch. (data: 1.18e-02)max mem: 17.22442 GB 
[09/16 15:49:33 visual_prompt]: 	Test 200/512. loss: 0.566, 0.2266 s / batch. (data: 2.92e-02)max mem: 17.22442 GB 
[09/16 15:49:53 visual_prompt]: 	Test 300/512. loss: 0.444, 0.1848 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 15:50:13 visual_prompt]: 	Test 400/512. loss: 0.605, 0.1863 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 15:50:32 visual_prompt]: 	Test 500/512. loss: 0.487, 0.1846 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 15:50:37 visual_prompt]: Inference (test):avg data time: 8.67e-03, avg batch time: 0.1955, average loss: 0.5287
[09/16 15:50:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.34	rocauc: 88.00	
[09/16 15:50:37 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 15:50:49 visual_prompt]: Epoch 49 / 100: avg data time: 1.93e-01, avg batch time: 0.5969, average train loss: 0.8437
[09/16 15:50:55 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1435, average loss: 0.4526
[09/16 15:50:55 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.00	rocauc: 96.71	
[09/16 15:51:18 visual_prompt]: 	Test 100/512. loss: 0.866, 0.1959 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 15:51:37 visual_prompt]: 	Test 200/512. loss: 0.818, 0.1844 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 15:51:57 visual_prompt]: 	Test 300/512. loss: 0.965, 0.2108 s / batch. (data: 2.75e-02)max mem: 17.22442 GB 
[09/16 15:52:16 visual_prompt]: 	Test 400/512. loss: 0.953, 0.1989 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 15:52:36 visual_prompt]: 	Test 500/512. loss: 0.750, 0.2113 s / batch. (data: 2.82e-02)max mem: 17.22442 GB 
[09/16 15:52:41 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1953, average loss: 0.8345
[09/16 15:52:41 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.32	rocauc: 88.76	
[09/16 15:52:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 15:52:53 visual_prompt]: Epoch 50 / 100: avg data time: 1.78e-01, avg batch time: 0.5882, average train loss: 0.5310
[09/16 15:52:58 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1435, average loss: 0.3595
[09/16 15:52:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.00	rocauc: 95.76	
[09/16 15:53:21 visual_prompt]: 	Test 100/512. loss: 0.773, 0.1983 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 15:53:40 visual_prompt]: 	Test 200/512. loss: 0.746, 0.1846 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 15:54:01 visual_prompt]: 	Test 300/512. loss: 0.720, 0.1845 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 15:54:20 visual_prompt]: 	Test 400/512. loss: 0.688, 0.2235 s / batch. (data: 2.80e-02)max mem: 17.22442 GB 
[09/16 15:54:40 visual_prompt]: 	Test 500/512. loss: 0.645, 0.1870 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 15:54:45 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1967, average loss: 0.7086
[09/16 15:54:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.01	rocauc: 88.28	
[09/16 15:54:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 15:54:57 visual_prompt]: Epoch 51 / 100: avg data time: 1.91e-01, avg batch time: 0.5938, average train loss: 0.4507
[09/16 15:55:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1450, average loss: 0.5343
[09/16 15:55:02 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 79.00	rocauc: 97.36	
[09/16 15:55:25 visual_prompt]: 	Test 100/512. loss: 0.725, 0.1957 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 15:55:46 visual_prompt]: 	Test 200/512. loss: 0.771, 0.2180 s / batch. (data: 3.51e-02)max mem: 17.22442 GB 
[09/16 15:56:05 visual_prompt]: 	Test 300/512. loss: 0.462, 0.2281 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 15:56:25 visual_prompt]: 	Test 400/512. loss: 0.852, 0.1965 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 15:56:44 visual_prompt]: 	Test 500/512. loss: 0.628, 0.1846 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 15:56:50 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1973, average loss: 0.7112
[09/16 15:56:50 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.22	rocauc: 88.82	
[09/16 15:56:50 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 15:57:02 visual_prompt]: Epoch 52 / 100: avg data time: 1.93e-01, avg batch time: 0.5963, average train loss: 0.4973
[09/16 15:57:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1434, average loss: 0.2814
[09/16 15:57:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 96.60	
[09/16 15:57:30 visual_prompt]: 	Test 100/512. loss: 0.576, 0.2182 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 15:57:49 visual_prompt]: 	Test 200/512. loss: 0.543, 0.1948 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 15:58:08 visual_prompt]: 	Test 300/512. loss: 0.329, 0.1967 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 15:58:28 visual_prompt]: 	Test 400/512. loss: 0.480, 0.1850 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 15:58:48 visual_prompt]: 	Test 500/512. loss: 0.454, 0.2099 s / batch. (data: 2.66e-02)max mem: 17.22442 GB 
[09/16 15:58:52 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1947, average loss: 0.4924
[09/16 15:58:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.95	rocauc: 87.62	
[09/16 15:58:53 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 15:59:04 visual_prompt]: Epoch 53 / 100: avg data time: 1.88e-01, avg batch time: 0.5930, average train loss: 0.3364
[09/16 15:59:10 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1434, average loss: 0.4650
[09/16 15:59:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.00	rocauc: 98.20	
[09/16 15:59:32 visual_prompt]: 	Test 100/512. loss: 0.751, 0.1891 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 15:59:52 visual_prompt]: 	Test 200/512. loss: 0.817, 0.1954 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 16:00:12 visual_prompt]: 	Test 300/512. loss: 0.437, 0.1851 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 16:00:32 visual_prompt]: 	Test 400/512. loss: 0.821, 0.1982 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 16:00:51 visual_prompt]: 	Test 500/512. loss: 0.634, 0.1850 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 16:00:56 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1959, average loss: 0.7134
[09/16 16:00:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.92	rocauc: 88.62	
[09/16 16:00:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 16:01:08 visual_prompt]: Epoch 54 / 100: avg data time: 1.88e-01, avg batch time: 0.5924, average train loss: 0.4003
[09/16 16:01:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1435, average loss: 0.1643
[09/16 16:01:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.50	rocauc: 98.62	
[09/16 16:01:37 visual_prompt]: 	Test 100/512. loss: 0.463, 0.2113 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 16:01:56 visual_prompt]: 	Test 200/512. loss: 0.432, 0.1857 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 16:02:16 visual_prompt]: 	Test 300/512. loss: 0.350, 0.2044 s / batch. (data: 1.15e-02)max mem: 17.22442 GB 
[09/16 16:02:35 visual_prompt]: 	Test 400/512. loss: 0.516, 0.1887 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 16:02:55 visual_prompt]: 	Test 500/512. loss: 0.369, 0.1875 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 16:02:59 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1947, average loss: 0.4563
[09/16 16:02:59 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.37	rocauc: 89.62	
[09/16 16:02:59 visual_prompt]: Best epoch 54: best metric: 0.945
[09/16 16:02:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 16:03:11 visual_prompt]: Epoch 55 / 100: avg data time: 1.89e-01, avg batch time: 0.5951, average train loss: 0.2848
[09/16 16:03:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1435, average loss: 0.1895
[09/16 16:03:17 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.50	rocauc: 98.32	
[09/16 16:03:40 visual_prompt]: 	Test 100/512. loss: 0.666, 0.1870 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 16:03:59 visual_prompt]: 	Test 200/512. loss: 0.645, 0.1887 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 16:04:19 visual_prompt]: 	Test 300/512. loss: 0.726, 0.1848 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 16:04:38 visual_prompt]: 	Test 400/512. loss: 0.515, 0.1975 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 16:04:58 visual_prompt]: 	Test 500/512. loss: 0.515, 0.1970 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 16:05:03 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1954, average loss: 0.6002
[09/16 16:05:03 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.08	rocauc: 86.94	
[09/16 16:05:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 16:05:15 visual_prompt]: Epoch 56 / 100: avg data time: 2.05e-01, avg batch time: 0.6280, average train loss: 0.2639
[09/16 16:05:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1436, average loss: 0.1917
[09/16 16:05:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.00	rocauc: 98.93	
[09/16 16:05:43 visual_prompt]: 	Test 100/512. loss: 0.616, 0.2037 s / batch. (data: 9.18e-05)max mem: 17.22442 GB 
[09/16 16:06:03 visual_prompt]: 	Test 200/512. loss: 0.528, 0.2039 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 16:06:22 visual_prompt]: 	Test 300/512. loss: 0.380, 0.1883 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 16:06:42 visual_prompt]: 	Test 400/512. loss: 0.649, 0.2037 s / batch. (data: 2.00e-02)max mem: 17.22442 GB 
[09/16 16:07:01 visual_prompt]: 	Test 500/512. loss: 0.449, 0.2000 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 16:07:06 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1952, average loss: 0.5497
[09/16 16:07:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.21	rocauc: 88.60	
[09/16 16:07:06 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 16:07:18 visual_prompt]: Epoch 57 / 100: avg data time: 1.89e-01, avg batch time: 0.5952, average train loss: 0.2856
[09/16 16:07:24 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1433, average loss: 0.1576
[09/16 16:07:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.00	rocauc: 99.19	
[09/16 16:07:48 visual_prompt]: 	Test 100/512. loss: 0.809, 0.1866 s / batch. (data: 9.06e-05)max mem: 17.22442 GB 
[09/16 16:08:07 visual_prompt]: 	Test 200/512. loss: 0.702, 0.1959 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 16:08:27 visual_prompt]: 	Test 300/512. loss: 0.539, 0.1925 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 16:08:46 visual_prompt]: 	Test 400/512. loss: 0.564, 0.1841 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 16:09:06 visual_prompt]: 	Test 500/512. loss: 0.709, 0.1841 s / batch. (data: 3.53e-05)max mem: 17.22442 GB 
[09/16 16:09:11 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1973, average loss: 0.6761
[09/16 16:09:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.81	rocauc: 88.48	
[09/16 16:09:11 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 16:09:23 visual_prompt]: Epoch 58 / 100: avg data time: 1.89e-01, avg batch time: 0.5937, average train loss: 0.2944
[09/16 16:09:29 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1434, average loss: 0.2537
[09/16 16:09:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 91.00	rocauc: 98.72	
[09/16 16:09:51 visual_prompt]: 	Test 100/512. loss: 0.555, 0.2103 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 16:10:11 visual_prompt]: 	Test 200/512. loss: 0.451, 0.2339 s / batch. (data: 2.63e-02)max mem: 17.22442 GB 
[09/16 16:10:31 visual_prompt]: 	Test 300/512. loss: 0.326, 0.2137 s / batch. (data: 1.77e-02)max mem: 17.22442 GB 
[09/16 16:10:50 visual_prompt]: 	Test 400/512. loss: 0.706, 0.1982 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 16:11:10 visual_prompt]: 	Test 500/512. loss: 0.564, 0.1845 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 16:11:14 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1948, average loss: 0.5160
[09/16 16:11:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.95	rocauc: 88.29	
[09/16 16:11:14 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 16:11:26 visual_prompt]: Epoch 59 / 100: avg data time: 1.89e-01, avg batch time: 0.5939, average train loss: 0.2564
[09/16 16:11:32 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1436, average loss: 0.2162
[09/16 16:11:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 98.70	
[09/16 16:11:54 visual_prompt]: 	Test 100/512. loss: 0.563, 0.1830 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 16:12:14 visual_prompt]: 	Test 200/512. loss: 0.540, 0.1966 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 16:12:34 visual_prompt]: 	Test 300/512. loss: 0.250, 0.1974 s / batch. (data: 1.37e-02)max mem: 17.22442 GB 
[09/16 16:12:53 visual_prompt]: 	Test 400/512. loss: 0.525, 0.2006 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 16:13:13 visual_prompt]: 	Test 500/512. loss: 0.401, 0.1877 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 16:13:18 visual_prompt]: Inference (test):avg data time: 8.94e-03, avg batch time: 0.1955, average loss: 0.4841
[09/16 16:13:18 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.45	rocauc: 90.47	
[09/16 16:13:18 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 16:13:30 visual_prompt]: Epoch 60 / 100: avg data time: 2.03e-01, avg batch time: 0.6078, average train loss: 0.4373
[09/16 16:13:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1436, average loss: 0.4779
[09/16 16:13:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 75.50	rocauc: 98.01	
[09/16 16:13:58 visual_prompt]: 	Test 100/512. loss: 0.667, 0.1841 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 16:14:18 visual_prompt]: 	Test 200/512. loss: 0.723, 0.1843 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 16:14:37 visual_prompt]: 	Test 300/512. loss: 0.386, 0.1849 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 16:14:57 visual_prompt]: 	Test 400/512. loss: 0.661, 0.1850 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 16:15:17 visual_prompt]: 	Test 500/512. loss: 0.690, 0.1848 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 16:15:22 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1963, average loss: 0.6701
[09/16 16:15:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.97	rocauc: 87.04	
[09/16 16:15:22 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 16:15:34 visual_prompt]: Epoch 61 / 100: avg data time: 1.98e-01, avg batch time: 0.6006, average train loss: 0.3087
[09/16 16:15:40 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1434, average loss: 0.4273
[09/16 16:15:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.50	rocauc: 97.98	
[09/16 16:16:02 visual_prompt]: 	Test 100/512. loss: 0.690, 0.1858 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 16:16:22 visual_prompt]: 	Test 200/512. loss: 0.746, 0.1988 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 16:16:41 visual_prompt]: 	Test 300/512. loss: 0.482, 0.2088 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 16:17:01 visual_prompt]: 	Test 400/512. loss: 0.898, 0.1850 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 16:17:20 visual_prompt]: 	Test 500/512. loss: 0.662, 0.1965 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 16:17:25 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1950, average loss: 0.7404
[09/16 16:17:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.12	rocauc: 88.55	
[09/16 16:17:26 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 16:17:37 visual_prompt]: Epoch 62 / 100: avg data time: 1.87e-01, avg batch time: 0.5917, average train loss: 0.2423
[09/16 16:17:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1433, average loss: 0.1384
[09/16 16:17:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.00	rocauc: 99.44	
[09/16 16:18:06 visual_prompt]: 	Test 100/512. loss: 0.569, 0.1840 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 16:18:26 visual_prompt]: 	Test 200/512. loss: 0.565, 0.1839 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 16:18:45 visual_prompt]: 	Test 300/512. loss: 0.362, 0.1989 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 16:19:05 visual_prompt]: 	Test 400/512. loss: 0.427, 0.1972 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 16:19:24 visual_prompt]: 	Test 500/512. loss: 0.464, 0.2018 s / batch. (data: 5.94e-05)max mem: 17.22442 GB 
[09/16 16:19:29 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1950, average loss: 0.4884
[09/16 16:19:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.68	rocauc: 88.61	
[09/16 16:19:29 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 16:19:41 visual_prompt]: Epoch 63 / 100: avg data time: 1.82e-01, avg batch time: 0.5878, average train loss: 0.1968
[09/16 16:19:46 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1433, average loss: 0.1640
[09/16 16:19:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.00	rocauc: 99.31	
[09/16 16:20:09 visual_prompt]: 	Test 100/512. loss: 0.899, 0.1840 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 16:20:28 visual_prompt]: 	Test 200/512. loss: 0.815, 0.1849 s / batch. (data: 1.07e-04)max mem: 17.22442 GB 
[09/16 16:20:48 visual_prompt]: 	Test 300/512. loss: 0.886, 0.2024 s / batch. (data: 1.89e-02)max mem: 17.22442 GB 
[09/16 16:21:08 visual_prompt]: 	Test 400/512. loss: 0.858, 0.2046 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 16:21:28 visual_prompt]: 	Test 500/512. loss: 0.858, 0.1855 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 16:21:33 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1973, average loss: 0.7046
[09/16 16:21:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.81	rocauc: 89.69	
[09/16 16:21:33 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 16:21:45 visual_prompt]: Epoch 64 / 100: avg data time: 1.98e-01, avg batch time: 0.6011, average train loss: 0.1610
[09/16 16:21:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1435, average loss: 0.1620
[09/16 16:21:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.00	rocauc: 99.50	
[09/16 16:22:14 visual_prompt]: 	Test 100/512. loss: 0.851, 0.1959 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 16:22:33 visual_prompt]: 	Test 200/512. loss: 0.917, 0.1993 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 16:22:53 visual_prompt]: 	Test 300/512. loss: 0.927, 0.2084 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 16:23:13 visual_prompt]: 	Test 400/512. loss: 0.610, 0.1846 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 16:23:33 visual_prompt]: 	Test 500/512. loss: 1.043, 0.1851 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 16:23:38 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1961, average loss: 0.8569
[09/16 16:23:38 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.79	rocauc: 88.82	
[09/16 16:23:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 16:23:49 visual_prompt]: Epoch 65 / 100: avg data time: 1.87e-01, avg batch time: 0.5919, average train loss: 0.1188
[09/16 16:23:55 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1433, average loss: 0.0559
[09/16 16:23:55 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.96	
[09/16 16:24:17 visual_prompt]: 	Test 100/512. loss: 0.736, 0.1883 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 16:24:37 visual_prompt]: 	Test 200/512. loss: 0.449, 0.1960 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 16:24:56 visual_prompt]: 	Test 300/512. loss: 0.529, 0.1994 s / batch. (data: 1.70e-04)max mem: 17.22442 GB 
[09/16 16:25:16 visual_prompt]: 	Test 400/512. loss: 0.681, 0.2001 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 16:25:36 visual_prompt]: 	Test 500/512. loss: 0.711, 0.1995 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 16:25:41 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1949, average loss: 0.5756
[09/16 16:25:41 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.89	rocauc: 91.05	
[09/16 16:25:41 visual_prompt]: Best epoch 65: best metric: 0.985
[09/16 16:25:41 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 16:25:52 visual_prompt]: Epoch 66 / 100: avg data time: 1.85e-01, avg batch time: 0.5899, average train loss: 0.0841
[09/16 16:25:58 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1433, average loss: 0.5550
[09/16 16:25:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 98.49	
[09/16 16:26:20 visual_prompt]: 	Test 100/512. loss: 1.645, 0.1874 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 16:26:40 visual_prompt]: 	Test 200/512. loss: 1.690, 0.1877 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 16:27:00 visual_prompt]: 	Test 300/512. loss: 1.859, 0.1851 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 16:27:19 visual_prompt]: 	Test 400/512. loss: 1.501, 0.1843 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 16:27:39 visual_prompt]: 	Test 500/512. loss: 1.851, 0.1847 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 16:27:44 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1947, average loss: 1.6501
[09/16 16:27:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 63.37	rocauc: 84.41	
[09/16 16:27:44 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 16:27:55 visual_prompt]: Epoch 67 / 100: avg data time: 1.93e-01, avg batch time: 0.5980, average train loss: 0.6539
[09/16 16:28:01 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1435, average loss: 0.5317
[09/16 16:28:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.00	rocauc: 97.54	
[09/16 16:28:24 visual_prompt]: 	Test 100/512. loss: 0.565, 0.1930 s / batch. (data: 1.03e-02)max mem: 17.22442 GB 
[09/16 16:28:44 visual_prompt]: 	Test 200/512. loss: 0.563, 0.2078 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 16:29:03 visual_prompt]: 	Test 300/512. loss: 0.440, 0.1877 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 16:29:23 visual_prompt]: 	Test 400/512. loss: 0.680, 0.1959 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 16:29:42 visual_prompt]: 	Test 500/512. loss: 0.540, 0.1851 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 16:29:47 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1956, average loss: 0.6193
[09/16 16:29:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.97	rocauc: 90.56	
[09/16 16:29:47 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 16:29:59 visual_prompt]: Epoch 68 / 100: avg data time: 1.87e-01, avg batch time: 0.5926, average train loss: 0.3582
[09/16 16:30:05 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1434, average loss: 0.6637
[09/16 16:30:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.50	rocauc: 98.58	
[09/16 16:30:28 visual_prompt]: 	Test 100/512. loss: 1.356, 0.1958 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 16:30:47 visual_prompt]: 	Test 200/512. loss: 1.098, 0.1895 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 16:31:07 visual_prompt]: 	Test 300/512. loss: 1.384, 0.2077 s / batch. (data: 2.42e-02)max mem: 17.22442 GB 
[09/16 16:31:26 visual_prompt]: 	Test 400/512. loss: 1.004, 0.1980 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 16:31:46 visual_prompt]: 	Test 500/512. loss: 1.317, 0.2034 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 16:31:51 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1957, average loss: 1.1969
[09/16 16:31:51 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.14	rocauc: 91.63	
[09/16 16:31:51 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 16:32:03 visual_prompt]: Epoch 69 / 100: avg data time: 1.94e-01, avg batch time: 0.5971, average train loss: 0.3185
[09/16 16:32:08 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1435, average loss: 0.1715
[09/16 16:32:08 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.00	rocauc: 99.40	
[09/16 16:32:31 visual_prompt]: 	Test 100/512. loss: 0.759, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 16:32:50 visual_prompt]: 	Test 200/512. loss: 0.662, 0.1893 s / batch. (data: 9.68e-05)max mem: 17.22442 GB 
[09/16 16:33:10 visual_prompt]: 	Test 300/512. loss: 0.462, 0.1958 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 16:33:29 visual_prompt]: 	Test 400/512. loss: 0.440, 0.2127 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 16:33:49 visual_prompt]: 	Test 500/512. loss: 0.700, 0.1988 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 16:33:54 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1947, average loss: 0.6096
[09/16 16:33:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.29	rocauc: 89.44	
[09/16 16:33:54 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 16:34:06 visual_prompt]: Epoch 70 / 100: avg data time: 1.88e-01, avg batch time: 0.5946, average train loss: 0.1809
[09/16 16:34:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1435, average loss: 0.0644
[09/16 16:34:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.82	
[09/16 16:34:35 visual_prompt]: 	Test 100/512. loss: 0.784, 0.2038 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 16:34:54 visual_prompt]: 	Test 200/512. loss: 0.761, 0.1848 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 16:35:14 visual_prompt]: 	Test 300/512. loss: 0.583, 0.1839 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 16:35:34 visual_prompt]: 	Test 400/512. loss: 0.650, 0.1877 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 16:35:53 visual_prompt]: 	Test 500/512. loss: 0.611, 0.2114 s / batch. (data: 2.41e-02)max mem: 17.22442 GB 
[09/16 16:35:58 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1971, average loss: 0.6422
[09/16 16:35:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.23	rocauc: 87.96	
[09/16 16:35:58 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 16:36:10 visual_prompt]: Epoch 71 / 100: avg data time: 1.88e-01, avg batch time: 0.5942, average train loss: 0.1087
[09/16 16:36:16 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1431, average loss: 0.0400
[09/16 16:36:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.93	
[09/16 16:36:39 visual_prompt]: 	Test 100/512. loss: 0.737, 0.1855 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 16:36:59 visual_prompt]: 	Test 200/512. loss: 0.751, 0.1837 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 16:37:18 visual_prompt]: 	Test 300/512. loss: 0.464, 0.1845 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 16:37:38 visual_prompt]: 	Test 400/512. loss: 0.696, 0.1994 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 16:37:57 visual_prompt]: 	Test 500/512. loss: 0.780, 0.1857 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 16:38:02 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1952, average loss: 0.6419
[09/16 16:38:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.24	rocauc: 89.45	
[09/16 16:38:02 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 16:38:14 visual_prompt]: Epoch 72 / 100: avg data time: 1.79e-01, avg batch time: 0.5855, average train loss: 0.3488
[09/16 16:38:20 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1435, average loss: 0.5543
[09/16 16:38:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 78.50	rocauc: 98.37	
[09/16 16:38:43 visual_prompt]: 	Test 100/512. loss: 1.458, 0.1854 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 16:39:02 visual_prompt]: 	Test 200/512. loss: 1.283, 0.1844 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 16:39:22 visual_prompt]: 	Test 300/512. loss: 1.405, 0.1841 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 16:39:41 visual_prompt]: 	Test 400/512. loss: 1.106, 0.1891 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 16:40:01 visual_prompt]: 	Test 500/512. loss: 1.277, 0.1853 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 16:40:06 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1950, average loss: 1.1630
[09/16 16:40:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.46	rocauc: 85.66	
[09/16 16:40:06 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 16:40:17 visual_prompt]: Epoch 73 / 100: avg data time: 1.97e-01, avg batch time: 0.5987, average train loss: 0.4143
[09/16 16:40:23 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1437, average loss: 0.2073
[09/16 16:40:23 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.50	rocauc: 98.72	
[09/16 16:40:46 visual_prompt]: 	Test 100/512. loss: 0.769, 0.1844 s / batch. (data: 3.74e-04)max mem: 17.22442 GB 
[09/16 16:41:05 visual_prompt]: 	Test 200/512. loss: 0.654, 0.1957 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 16:41:25 visual_prompt]: 	Test 300/512. loss: 0.645, 0.1995 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 16:41:45 visual_prompt]: 	Test 400/512. loss: 0.602, 0.1844 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 16:42:05 visual_prompt]: 	Test 500/512. loss: 0.470, 0.2017 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 16:42:10 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1960, average loss: 0.6509
[09/16 16:42:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.36	rocauc: 86.22	
[09/16 16:42:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 16:42:21 visual_prompt]: Epoch 74 / 100: avg data time: 1.81e-01, avg batch time: 0.5872, average train loss: 0.1987
[09/16 16:42:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1432, average loss: 0.0968
[09/16 16:42:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.53	
[09/16 16:42:50 visual_prompt]: 	Test 100/512. loss: 0.851, 0.1966 s / batch. (data: 1.34e-02)max mem: 17.22442 GB 
[09/16 16:43:09 visual_prompt]: 	Test 200/512. loss: 0.907, 0.2080 s / batch. (data: 2.48e-02)max mem: 17.22442 GB 
[09/16 16:43:29 visual_prompt]: 	Test 300/512. loss: 0.691, 0.2034 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 16:43:48 visual_prompt]: 	Test 400/512. loss: 0.554, 0.2000 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 16:44:08 visual_prompt]: 	Test 500/512. loss: 0.613, 0.1838 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 16:44:13 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1951, average loss: 0.7123
[09/16 16:44:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.77	rocauc: 87.97	
[09/16 16:44:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 16:44:25 visual_prompt]: Epoch 75 / 100: avg data time: 2.01e-01, avg batch time: 0.6041, average train loss: 0.1298
[09/16 16:44:31 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1437, average loss: 0.0609
[09/16 16:44:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.95	
[09/16 16:44:53 visual_prompt]: 	Test 100/512. loss: 0.983, 0.2159 s / batch. (data: 3.33e-02)max mem: 17.22442 GB 
[09/16 16:45:13 visual_prompt]: 	Test 200/512. loss: 0.911, 0.1841 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 16:45:32 visual_prompt]: 	Test 300/512. loss: 0.795, 0.2116 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 16:45:52 visual_prompt]: 	Test 400/512. loss: 0.774, 0.1997 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 16:46:11 visual_prompt]: 	Test 500/512. loss: 0.703, 0.1999 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 16:46:16 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1950, average loss: 0.7483
[09/16 16:46:16 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.61	rocauc: 88.59	
[09/16 16:46:16 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 16:46:28 visual_prompt]: Epoch 76 / 100: avg data time: 1.91e-01, avg batch time: 0.5975, average train loss: 0.0907
[09/16 16:46:33 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1469, average loss: 0.1497
[09/16 16:46:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.00	rocauc: 99.70	
[09/16 16:46:56 visual_prompt]: 	Test 100/512. loss: 1.203, 0.1958 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 16:47:15 visual_prompt]: 	Test 200/512. loss: 0.906, 0.1962 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 16:47:35 visual_prompt]: 	Test 300/512. loss: 1.006, 0.1969 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 16:47:55 visual_prompt]: 	Test 400/512. loss: 1.002, 0.1889 s / batch. (data: 9.44e-05)max mem: 17.22442 GB 
[09/16 16:48:14 visual_prompt]: 	Test 500/512. loss: 0.819, 0.1843 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 16:48:19 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1946, average loss: 0.9245
[09/16 16:48:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.24	rocauc: 89.60	
[09/16 16:48:19 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 16:48:31 visual_prompt]: Epoch 77 / 100: avg data time: 1.91e-01, avg batch time: 0.5952, average train loss: 0.1204
[09/16 16:48:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1433, average loss: 0.0554
[09/16 16:48:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 99.63	
[09/16 16:49:00 visual_prompt]: 	Test 100/512. loss: 1.103, 0.1981 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 16:49:19 visual_prompt]: 	Test 200/512. loss: 0.850, 0.2052 s / batch. (data: 2.17e-02)max mem: 17.22442 GB 
[09/16 16:49:39 visual_prompt]: 	Test 300/512. loss: 0.891, 0.1847 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 16:49:58 visual_prompt]: 	Test 400/512. loss: 0.925, 0.1961 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 16:50:18 visual_prompt]: 	Test 500/512. loss: 0.606, 0.1861 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 16:50:23 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1952, average loss: 0.7975
[09/16 16:50:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.76	rocauc: 88.24	
[09/16 16:50:23 visual_prompt]: Best epoch 77: best metric: 0.990
[09/16 16:50:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 16:50:35 visual_prompt]: Epoch 78 / 100: avg data time: 1.99e-01, avg batch time: 0.6020, average train loss: 0.0904
[09/16 16:50:41 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1433, average loss: 0.0926
[09/16 16:50:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 99.64	
[09/16 16:51:03 visual_prompt]: 	Test 100/512. loss: 1.003, 0.1838 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 16:51:23 visual_prompt]: 	Test 200/512. loss: 0.631, 0.1837 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 16:51:43 visual_prompt]: 	Test 300/512. loss: 0.532, 0.1847 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 16:52:02 visual_prompt]: 	Test 400/512. loss: 0.768, 0.1931 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 16:52:22 visual_prompt]: 	Test 500/512. loss: 0.478, 0.2017 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 16:52:27 visual_prompt]: Inference (test):avg data time: 8.59e-03, avg batch time: 0.1956, average loss: 0.7002
[09/16 16:52:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.12	rocauc: 89.43	
[09/16 16:52:27 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 16:52:39 visual_prompt]: Epoch 79 / 100: avg data time: 2.08e-01, avg batch time: 0.6134, average train loss: 0.0581
[09/16 16:52:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1437, average loss: 0.0251
[09/16 16:52:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 100.00	
[09/16 16:53:08 visual_prompt]: 	Test 100/512. loss: 1.085, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 16:53:27 visual_prompt]: 	Test 200/512. loss: 0.762, 0.1966 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 16:53:47 visual_prompt]: 	Test 300/512. loss: 0.661, 0.1982 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 16:54:06 visual_prompt]: 	Test 400/512. loss: 0.808, 0.1981 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 16:54:26 visual_prompt]: 	Test 500/512. loss: 0.782, 0.2006 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 16:54:31 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1950, average loss: 0.7570
[09/16 16:54:31 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.08	rocauc: 89.11	
[09/16 16:54:31 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 16:54:43 visual_prompt]: Epoch 80 / 100: avg data time: 1.83e-01, avg batch time: 0.5880, average train loss: 0.0355
[09/16 16:54:48 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1435, average loss: 0.0285
[09/16 16:54:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.92	
[09/16 16:55:11 visual_prompt]: 	Test 100/512. loss: 1.328, 0.1847 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 16:55:30 visual_prompt]: 	Test 200/512. loss: 0.953, 0.1985 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 16:55:50 visual_prompt]: 	Test 300/512. loss: 1.062, 0.1942 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 16:56:09 visual_prompt]: 	Test 400/512. loss: 1.141, 0.1977 s / batch. (data: 1.39e-02)max mem: 17.22442 GB 
[09/16 16:56:29 visual_prompt]: 	Test 500/512. loss: 0.658, 0.1973 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 16:56:34 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1945, average loss: 0.9328
[09/16 16:56:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.83	rocauc: 88.12	
[09/16 16:56:34 visual_prompt]: Best epoch 80: best metric: 0.995
[09/16 16:56:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 16:56:46 visual_prompt]: Epoch 81 / 100: avg data time: 1.98e-01, avg batch time: 0.6011, average train loss: 0.0652
[09/16 16:56:51 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1434, average loss: 0.0289
[09/16 16:56:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 100.00	
[09/16 16:57:14 visual_prompt]: 	Test 100/512. loss: 1.191, 0.1838 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 16:57:34 visual_prompt]: 	Test 200/512. loss: 1.019, 0.1932 s / batch. (data: 1.06e-04)max mem: 17.22442 GB 
[09/16 16:57:53 visual_prompt]: 	Test 300/512. loss: 0.993, 0.1988 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 16:58:13 visual_prompt]: 	Test 400/512. loss: 0.964, 0.1850 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 16:58:32 visual_prompt]: 	Test 500/512. loss: 0.814, 0.1986 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 16:58:37 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1950, average loss: 0.8795
[09/16 16:58:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.89	rocauc: 89.31	
[09/16 16:58:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 16:58:49 visual_prompt]: Epoch 82 / 100: avg data time: 2.00e-01, avg batch time: 0.6038, average train loss: 0.0394
[09/16 16:58:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1435, average loss: 0.0075
[09/16 16:58:55 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 16:59:17 visual_prompt]: 	Test 100/512. loss: 1.264, 0.1852 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 16:59:37 visual_prompt]: 	Test 200/512. loss: 1.030, 0.2026 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 16:59:56 visual_prompt]: 	Test 300/512. loss: 1.020, 0.1841 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 17:00:16 visual_prompt]: 	Test 400/512. loss: 1.089, 0.1852 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 17:00:36 visual_prompt]: 	Test 500/512. loss: 0.840, 0.1845 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 17:00:41 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1963, average loss: 0.8932
[09/16 17:00:41 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.38	rocauc: 89.30	
[09/16 17:00:41 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 17:00:53 visual_prompt]: Epoch 83 / 100: avg data time: 1.94e-01, avg batch time: 0.5975, average train loss: 0.0252
[09/16 17:00:59 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1437, average loss: 0.0290
[09/16 17:00:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 99.99	
[09/16 17:01:21 visual_prompt]: 	Test 100/512. loss: 1.128, 0.1962 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 17:01:41 visual_prompt]: 	Test 200/512. loss: 0.991, 0.1965 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 17:02:01 visual_prompt]: 	Test 300/512. loss: 0.938, 0.2297 s / batch. (data: 3.70e-02)max mem: 17.22442 GB 
[09/16 17:02:20 visual_prompt]: 	Test 400/512. loss: 1.133, 0.1867 s / batch. (data: 8.68e-05)max mem: 17.22442 GB 
[09/16 17:02:40 visual_prompt]: 	Test 500/512. loss: 0.693, 0.1851 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 17:02:45 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1959, average loss: 0.8622
[09/16 17:02:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.89	rocauc: 89.63	
[09/16 17:02:45 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 17:02:57 visual_prompt]: Epoch 84 / 100: avg data time: 1.96e-01, avg batch time: 0.5991, average train loss: 0.0122
[09/16 17:03:03 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1436, average loss: 0.0021
[09/16 17:03:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:03:26 visual_prompt]: 	Test 100/512. loss: 1.194, 0.1844 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 17:03:45 visual_prompt]: 	Test 200/512. loss: 0.987, 0.1983 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 17:04:05 visual_prompt]: 	Test 300/512. loss: 0.931, 0.2233 s / batch. (data: 1.85e-02)max mem: 17.22442 GB 
[09/16 17:04:24 visual_prompt]: 	Test 400/512. loss: 1.117, 0.1840 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 17:04:44 visual_prompt]: 	Test 500/512. loss: 0.820, 0.1851 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 17:04:49 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1961, average loss: 0.9184
[09/16 17:04:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.47	rocauc: 89.45	
[09/16 17:04:49 visual_prompt]: Best epoch 84: best metric: 1.000
[09/16 17:04:49 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 17:05:01 visual_prompt]: Epoch 85 / 100: avg data time: 1.72e-01, avg batch time: 0.5768, average train loss: 0.0083
[09/16 17:05:07 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1433, average loss: 0.0015
[09/16 17:05:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:05:29 visual_prompt]: 	Test 100/512. loss: 1.266, 0.1922 s / batch. (data: 8.46e-03)max mem: 17.22442 GB 
[09/16 17:05:49 visual_prompt]: 	Test 200/512. loss: 1.107, 0.1945 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 17:06:08 visual_prompt]: 	Test 300/512. loss: 0.942, 0.1955 s / batch. (data: 1.20e-02)max mem: 17.22442 GB 
[09/16 17:06:28 visual_prompt]: 	Test 400/512. loss: 1.127, 0.1987 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 17:06:48 visual_prompt]: 	Test 500/512. loss: 0.857, 0.2000 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 17:06:53 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1966, average loss: 0.9571
[09/16 17:06:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.47	rocauc: 89.37	
[09/16 17:06:53 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 17:07:05 visual_prompt]: Epoch 86 / 100: avg data time: 1.93e-01, avg batch time: 0.5985, average train loss: 0.0074
[09/16 17:07:11 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1433, average loss: 0.0023
[09/16 17:07:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:07:33 visual_prompt]: 	Test 100/512. loss: 1.357, 0.1839 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 17:07:53 visual_prompt]: 	Test 200/512. loss: 1.079, 0.2048 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 17:08:12 visual_prompt]: 	Test 300/512. loss: 1.018, 0.1845 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 17:08:32 visual_prompt]: 	Test 400/512. loss: 1.160, 0.1999 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 17:08:52 visual_prompt]: 	Test 500/512. loss: 0.881, 0.1842 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 17:08:57 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1946, average loss: 0.9725
[09/16 17:08:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.55	rocauc: 89.63	
[09/16 17:08:57 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 17:09:09 visual_prompt]: Epoch 87 / 100: avg data time: 1.99e-01, avg batch time: 0.6031, average train loss: 0.0060
[09/16 17:09:15 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1435, average loss: 0.0190
[09/16 17:09:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 100.00	
[09/16 17:09:37 visual_prompt]: 	Test 100/512. loss: 1.283, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 17:09:57 visual_prompt]: 	Test 200/512. loss: 0.954, 0.2054 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 17:10:17 visual_prompt]: 	Test 300/512. loss: 0.796, 0.1948 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 17:10:36 visual_prompt]: 	Test 400/512. loss: 1.199, 0.1979 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 17:10:56 visual_prompt]: 	Test 500/512. loss: 0.920, 0.1999 s / batch. (data: 1.64e-02)max mem: 17.22442 GB 
[09/16 17:11:01 visual_prompt]: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1955, average loss: 0.9368
[09/16 17:11:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.76	rocauc: 90.09	
[09/16 17:11:01 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 17:11:12 visual_prompt]: Epoch 88 / 100: avg data time: 1.79e-01, avg batch time: 0.5886, average train loss: 0.0032
[09/16 17:11:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1437, average loss: 0.0012
[09/16 17:11:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:11:41 visual_prompt]: 	Test 100/512. loss: 1.460, 0.2170 s / batch. (data: 3.40e-02)max mem: 17.22442 GB 
[09/16 17:12:01 visual_prompt]: 	Test 200/512. loss: 1.143, 0.1842 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 17:12:21 visual_prompt]: 	Test 300/512. loss: 1.040, 0.2217 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 17:12:40 visual_prompt]: 	Test 400/512. loss: 1.233, 0.2206 s / batch. (data: 2.33e-02)max mem: 17.22442 GB 
[09/16 17:13:00 visual_prompt]: 	Test 500/512. loss: 0.939, 0.1844 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 17:13:05 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1965, average loss: 1.0217
[09/16 17:13:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.88	rocauc: 89.72	
[09/16 17:13:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 17:13:17 visual_prompt]: Epoch 89 / 100: avg data time: 1.90e-01, avg batch time: 0.5976, average train loss: 0.0015
[09/16 17:13:22 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1437, average loss: 0.0008
[09/16 17:13:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:13:45 visual_prompt]: 	Test 100/512. loss: 1.558, 0.1828 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 17:14:04 visual_prompt]: 	Test 200/512. loss: 1.237, 0.1985 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 17:14:24 visual_prompt]: 	Test 300/512. loss: 1.118, 0.2305 s / batch. (data: 4.32e-02)max mem: 17.22442 GB 
[09/16 17:14:43 visual_prompt]: 	Test 400/512. loss: 1.291, 0.2033 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 17:15:03 visual_prompt]: 	Test 500/512. loss: 0.961, 0.2110 s / batch. (data: 5.72e-05)max mem: 17.22442 GB 
[09/16 17:15:08 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1950, average loss: 1.0839
[09/16 17:15:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.44	rocauc: 89.55	
[09/16 17:15:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 17:15:20 visual_prompt]: Epoch 90 / 100: avg data time: 1.88e-01, avg batch time: 0.5932, average train loss: 0.0014
[09/16 17:15:26 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1433, average loss: 0.0006
[09/16 17:15:26 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:15:48 visual_prompt]: 	Test 100/512. loss: 1.579, 0.2071 s / batch. (data: 2.40e-02)max mem: 17.22442 GB 
[09/16 17:16:08 visual_prompt]: 	Test 200/512. loss: 1.256, 0.1961 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 17:16:28 visual_prompt]: 	Test 300/512. loss: 1.120, 0.1849 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 17:16:47 visual_prompt]: 	Test 400/512. loss: 1.317, 0.1866 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 17:17:07 visual_prompt]: 	Test 500/512. loss: 0.984, 0.1837 s / batch. (data: 1.05e-04)max mem: 17.22442 GB 
[09/16 17:17:11 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1946, average loss: 1.1012
[09/16 17:17:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.62	rocauc: 89.61	
[09/16 17:17:11 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 17:17:24 visual_prompt]: Epoch 91 / 100: avg data time: 1.94e-01, avg batch time: 0.6003, average train loss: 0.0010
[09/16 17:17:29 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1434, average loss: 0.0005
[09/16 17:17:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:17:52 visual_prompt]: 	Test 100/512. loss: 1.601, 0.2038 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 17:18:11 visual_prompt]: 	Test 200/512. loss: 1.264, 0.1845 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 17:18:31 visual_prompt]: 	Test 300/512. loss: 1.123, 0.1842 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 17:18:51 visual_prompt]: 	Test 400/512. loss: 1.339, 0.1844 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 17:19:10 visual_prompt]: 	Test 500/512. loss: 0.996, 0.1855 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 17:19:15 visual_prompt]: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1953, average loss: 1.1124
[09/16 17:19:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.74	rocauc: 89.69	
[09/16 17:19:15 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 17:19:27 visual_prompt]: Epoch 92 / 100: avg data time: 1.75e-01, avg batch time: 0.5826, average train loss: 0.0009
[09/16 17:19:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1433, average loss: 0.0004
[09/16 17:19:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:19:55 visual_prompt]: 	Test 100/512. loss: 1.604, 0.1995 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 17:20:15 visual_prompt]: 	Test 200/512. loss: 1.252, 0.2172 s / batch. (data: 2.49e-02)max mem: 17.22442 GB 
[09/16 17:20:34 visual_prompt]: 	Test 300/512. loss: 1.074, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 17:20:54 visual_prompt]: 	Test 400/512. loss: 1.354, 0.1912 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 17:21:14 visual_prompt]: 	Test 500/512. loss: 1.038, 0.1850 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 17:21:18 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1946, average loss: 1.1213
[09/16 17:21:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.86	rocauc: 89.65	
[09/16 17:21:19 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 17:21:30 visual_prompt]: Epoch 93 / 100: avg data time: 1.90e-01, avg batch time: 0.5935, average train loss: 0.0008
[09/16 17:21:36 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1436, average loss: 0.0004
[09/16 17:21:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:21:58 visual_prompt]: 	Test 100/512. loss: 1.620, 0.1971 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 17:22:18 visual_prompt]: 	Test 200/512. loss: 1.262, 0.2229 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 17:22:38 visual_prompt]: 	Test 300/512. loss: 1.074, 0.1848 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 17:22:57 visual_prompt]: 	Test 400/512. loss: 1.367, 0.2019 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 17:23:17 visual_prompt]: 	Test 500/512. loss: 1.053, 0.1963 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 17:23:22 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1953, average loss: 1.1322
[09/16 17:23:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.88	rocauc: 89.64	
[09/16 17:23:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 17:23:34 visual_prompt]: Epoch 94 / 100: avg data time: 1.95e-01, avg batch time: 0.5984, average train loss: 0.0007
[09/16 17:23:39 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1455, average loss: 0.0004
[09/16 17:23:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:24:02 visual_prompt]: 	Test 100/512. loss: 1.633, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 17:24:21 visual_prompt]: 	Test 200/512. loss: 1.271, 0.1847 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 17:24:42 visual_prompt]: 	Test 300/512. loss: 1.085, 0.2001 s / batch. (data: 1.66e-02)max mem: 17.22442 GB 
[09/16 17:25:01 visual_prompt]: 	Test 400/512. loss: 1.374, 0.1841 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 17:25:21 visual_prompt]: 	Test 500/512. loss: 1.055, 0.2056 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 17:25:26 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1963, average loss: 1.1409
[09/16 17:25:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.63	
[09/16 17:25:26 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 17:25:38 visual_prompt]: Epoch 95 / 100: avg data time: 1.93e-01, avg batch time: 0.5968, average train loss: 0.0007
[09/16 17:25:44 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1434, average loss: 0.0004
[09/16 17:25:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:26:07 visual_prompt]: 	Test 100/512. loss: 1.641, 0.2027 s / batch. (data: 1.98e-02)max mem: 17.22442 GB 
[09/16 17:26:26 visual_prompt]: 	Test 200/512. loss: 1.276, 0.1996 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 17:26:46 visual_prompt]: 	Test 300/512. loss: 1.093, 0.1841 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 17:27:05 visual_prompt]: 	Test 400/512. loss: 1.380, 0.1840 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 17:27:25 visual_prompt]: 	Test 500/512. loss: 1.058, 0.2090 s / batch. (data: 2.55e-02)max mem: 17.22442 GB 
[09/16 17:27:30 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1951, average loss: 1.1461
[09/16 17:27:30 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.64	
[09/16 17:27:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 17:27:42 visual_prompt]: Epoch 96 / 100: avg data time: 1.95e-01, avg batch time: 0.5987, average train loss: 0.0006
[09/16 17:27:48 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1433, average loss: 0.0004
[09/16 17:27:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:28:11 visual_prompt]: 	Test 100/512. loss: 1.646, 0.1838 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 17:28:30 visual_prompt]: 	Test 200/512. loss: 1.278, 0.1964 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 17:28:49 visual_prompt]: 	Test 300/512. loss: 1.098, 0.2092 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 17:29:09 visual_prompt]: 	Test 400/512. loss: 1.383, 0.1962 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 17:29:29 visual_prompt]: 	Test 500/512. loss: 1.059, 0.2154 s / batch. (data: 3.16e-02)max mem: 17.22442 GB 
[09/16 17:29:33 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1946, average loss: 1.1491
[09/16 17:29:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.82	rocauc: 89.64	
[09/16 17:29:34 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 17:29:45 visual_prompt]: Epoch 97 / 100: avg data time: 1.80e-01, avg batch time: 0.5854, average train loss: 0.0006
[09/16 17:29:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1434, average loss: 0.0004
[09/16 17:29:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:30:14 visual_prompt]: 	Test 100/512. loss: 1.650, 0.1840 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 17:30:34 visual_prompt]: 	Test 200/512. loss: 1.280, 0.2018 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 17:30:54 visual_prompt]: 	Test 300/512. loss: 1.100, 0.1936 s / batch. (data: 1.03e-02)max mem: 17.22442 GB 
[09/16 17:31:13 visual_prompt]: 	Test 400/512. loss: 1.385, 0.2033 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 17:31:33 visual_prompt]: 	Test 500/512. loss: 1.060, 0.1839 s / batch. (data: 9.99e-05)max mem: 17.22442 GB 
[09/16 17:31:38 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1966, average loss: 1.1511
[09/16 17:31:38 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.64	
[09/16 17:31:38 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 17:31:50 visual_prompt]: Epoch 98 / 100: avg data time: 1.83e-01, avg batch time: 0.5892, average train loss: 0.0007
[09/16 17:31:56 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1435, average loss: 0.0004
[09/16 17:31:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:32:19 visual_prompt]: 	Test 100/512. loss: 1.651, 0.1886 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 17:32:38 visual_prompt]: 	Test 200/512. loss: 1.282, 0.1972 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 17:32:58 visual_prompt]: 	Test 300/512. loss: 1.102, 0.1849 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 17:33:17 visual_prompt]: 	Test 400/512. loss: 1.386, 0.2010 s / batch. (data: 1.75e-02)max mem: 17.22442 GB 
[09/16 17:33:37 visual_prompt]: 	Test 500/512. loss: 1.060, 0.2186 s / batch. (data: 3.49e-02)max mem: 17.22442 GB 
[09/16 17:33:42 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1967, average loss: 1.1522
[09/16 17:33:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.64	
[09/16 17:33:42 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 17:33:54 visual_prompt]: Epoch 99 / 100: avg data time: 1.83e-01, avg batch time: 0.5852, average train loss: 0.0007
[09/16 17:34:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1432, average loss: 0.0004
[09/16 17:34:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:34:22 visual_prompt]: 	Test 100/512. loss: 1.652, 0.1844 s / batch. (data: 9.49e-05)max mem: 17.22442 GB 
[09/16 17:34:42 visual_prompt]: 	Test 200/512. loss: 1.282, 0.2102 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 17:35:02 visual_prompt]: 	Test 300/512. loss: 1.103, 0.1848 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 17:35:21 visual_prompt]: 	Test 400/512. loss: 1.387, 0.1981 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 17:35:41 visual_prompt]: 	Test 500/512. loss: 1.060, 0.1954 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 17:35:46 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1961, average loss: 1.1527
[09/16 17:35:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.64	
[09/16 17:35:46 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 17:35:58 visual_prompt]: Epoch 100 / 100: avg data time: 1.87e-01, avg batch time: 0.5911, average train loss: 0.0007
[09/16 17:36:03 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1433, average loss: 0.0004
[09/16 17:36:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 17:36:26 visual_prompt]: 	Test 100/512. loss: 1.652, 0.1841 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 17:36:46 visual_prompt]: 	Test 200/512. loss: 1.282, 0.1987 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 17:37:05 visual_prompt]: 	Test 300/512. loss: 1.103, 0.2086 s / batch. (data: 2.57e-02)max mem: 17.22442 GB 
[09/16 17:37:25 visual_prompt]: 	Test 400/512. loss: 1.387, 0.1848 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 17:37:44 visual_prompt]: 	Test 500/512. loss: 1.060, 0.1866 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 17:37:49 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1949, average loss: 1.1528
[09/16 17:37:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 89.64	
[09/16 17:38:05 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 17:38:05 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 17:38:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-patch_camelyon', 'DATA.NUMBER_CLASSES', '2', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/16 17:38:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 17:38:05 visual_prompt]: Training with config:
[09/16 17:38:05 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-patch_camelyon',
          'NO_TEST': False,
          'NUMBER_CLASSES': 2,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-patch_camelyon/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 17:38:05 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 17:38:05.904684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 17:38:06.093823: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 17:38:07.000023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 17:38:07.000103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 17:38:07.000111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 17:38:12.179422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 17:38:12.179528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 17:38:12.179542: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 17:38:12 visual_prompt]: Constructing vtab-patch_camelyon dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
2023-09-16 17:38:12.197097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 17:38:14 visual_prompt]: Number of images: 1000
[09/16 17:38:14 visual_prompt]: Number of classes: 2 / 2
[09/16 17:38:14 visual_prompt]: Loading validation data...
[09/16 17:38:14 visual_prompt]: Constructing vtab-patch_camelyon dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 17:38:14 visual_prompt]: Number of images: 200
[09/16 17:38:14 visual_prompt]: Number of classes: 2 / 2
[09/16 17:38:14 visual_prompt]: Loading test data...
[09/16 17:38:14 visual_prompt]: Constructing vtab-patch_camelyon dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split test, from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 17:39:02 visual_prompt]: Number of images: 32768
[09/16 17:39:02 visual_prompt]: Number of classes: 2 / 2
[09/16 17:39:02 visual_prompt]: Constructing models...
[09/16 17:39:05 visual_prompt]: Total Parameters: 86721794	 Gradient Parameters: 923138
[09/16 17:39:05 visual_prompt]: tuned percent:1.064
[09/16 17:39:08 visual_prompt]: Device used for model: 0
[09/16 17:39:08 visual_prompt]: Setting up Evalutator...
[09/16 17:39:08 visual_prompt]: Setting up Trainer...
[09/16 17:39:08 visual_prompt]: 	Setting up the optimizer...
[09/16 17:39:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 17:39:21 visual_prompt]: Epoch 1 / 100: avg data time: 1.86e-01, avg batch time: 0.6824, average train loss: 0.8816
[09/16 17:39:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1427, average loss: 0.7908
[09/16 17:39:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 51.50	rocauc: 65.36	
[09/16 17:39:49 visual_prompt]: 	Test 100/512. loss: 0.838, 0.1985 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 17:40:09 visual_prompt]: 	Test 200/512. loss: 0.876, 0.1961 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 17:40:28 visual_prompt]: 	Test 300/512. loss: 0.979, 0.2137 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 17:40:48 visual_prompt]: 	Test 400/512. loss: 0.822, 0.2062 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 17:41:07 visual_prompt]: 	Test 500/512. loss: 0.848, 0.1992 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 17:41:12 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1945, average loss: 0.8551
[09/16 17:41:12 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.01	rocauc: 59.50	
[09/16 17:41:12 visual_prompt]: Best epoch 1: best metric: 0.515
[09/16 17:41:12 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 17:41:24 visual_prompt]: Epoch 2 / 100: avg data time: 2.02e-01, avg batch time: 0.6043, average train loss: 4.3967
[09/16 17:41:30 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1442, average loss: 0.9941
[09/16 17:41:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 79.73	
[09/16 17:41:53 visual_prompt]: 	Test 100/512. loss: 0.922, 0.2053 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 17:42:12 visual_prompt]: 	Test 200/512. loss: 0.933, 0.1958 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 17:42:32 visual_prompt]: 	Test 300/512. loss: 0.850, 0.1865 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 17:42:51 visual_prompt]: 	Test 400/512. loss: 0.998, 0.1968 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 17:43:11 visual_prompt]: 	Test 500/512. loss: 0.981, 0.1989 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 17:43:16 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1946, average loss: 0.9609
[09/16 17:43:16 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 76.08	
[09/16 17:43:16 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 17:43:27 visual_prompt]: Epoch 3 / 100: avg data time: 1.89e-01, avg batch time: 0.5935, average train loss: 1.0631
[09/16 17:43:33 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1434, average loss: 0.6520
[09/16 17:43:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 59.00	rocauc: 88.01	
[09/16 17:43:56 visual_prompt]: 	Test 100/512. loss: 0.622, 0.1958 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 17:44:15 visual_prompt]: 	Test 200/512. loss: 0.647, 0.2127 s / batch. (data: 3.77e-05)max mem: 17.22442 GB 
[09/16 17:44:35 visual_prompt]: 	Test 300/512. loss: 0.604, 0.1841 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 17:44:54 visual_prompt]: 	Test 400/512. loss: 0.650, 0.1834 s / batch. (data: 2.84e-05)max mem: 17.22442 GB 
[09/16 17:45:14 visual_prompt]: 	Test 500/512. loss: 0.641, 0.2110 s / batch. (data: 2.78e-02)max mem: 17.22442 GB 
[09/16 17:45:19 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1950, average loss: 0.6513
[09/16 17:45:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.35	rocauc: 82.61	
[09/16 17:45:19 visual_prompt]: Best epoch 3: best metric: 0.590
[09/16 17:45:19 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 17:45:30 visual_prompt]: Epoch 4 / 100: avg data time: 1.92e-01, avg batch time: 0.5961, average train loss: 1.4530
[09/16 17:45:36 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1437, average loss: 1.3131
[09/16 17:45:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 90.16	
[09/16 17:45:59 visual_prompt]: 	Test 100/512. loss: 1.471, 0.2136 s / batch. (data: 2.10e-02)max mem: 17.22442 GB 
[09/16 17:46:19 visual_prompt]: 	Test 200/512. loss: 1.467, 0.1992 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 17:46:38 visual_prompt]: 	Test 300/512. loss: 1.627, 0.1843 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 17:46:58 visual_prompt]: 	Test 400/512. loss: 1.372, 0.1843 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 17:47:17 visual_prompt]: 	Test 500/512. loss: 1.362, 0.1991 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 17:47:22 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1963, average loss: 1.4395
[09/16 17:47:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 82.83	
[09/16 17:47:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 17:47:34 visual_prompt]: Epoch 5 / 100: avg data time: 1.94e-01, avg batch time: 0.5975, average train loss: 3.4418
[09/16 17:47:39 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1435, average loss: 0.7135
[09/16 17:47:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 49.00	rocauc: 85.34	
[09/16 17:48:02 visual_prompt]: 	Test 100/512. loss: 0.682, 0.1833 s / batch. (data: 8.54e-05)max mem: 17.22442 GB 
[09/16 17:48:22 visual_prompt]: 	Test 200/512. loss: 0.697, 0.1973 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 17:48:41 visual_prompt]: 	Test 300/512. loss: 0.642, 0.1847 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 17:49:01 visual_prompt]: 	Test 400/512. loss: 0.715, 0.1907 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 17:49:20 visual_prompt]: 	Test 500/512. loss: 0.701, 0.1846 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 17:49:25 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1952, average loss: 0.7069
[09/16 17:49:25 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 51.40	rocauc: 79.27	
[09/16 17:49:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 17:49:37 visual_prompt]: Epoch 6 / 100: avg data time: 1.97e-01, avg batch time: 0.6012, average train loss: 4.4046
[09/16 17:49:42 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1433, average loss: 3.0723
[09/16 17:49:42 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 89.25	
[09/16 17:50:05 visual_prompt]: 	Test 100/512. loss: 2.828, 0.1900 s / batch. (data: 7.20e-03)max mem: 17.22442 GB 
[09/16 17:50:25 visual_prompt]: 	Test 200/512. loss: 2.867, 0.1837 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 17:50:44 visual_prompt]: 	Test 300/512. loss: 2.529, 0.2119 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 17:51:04 visual_prompt]: 	Test 400/512. loss: 3.095, 0.1850 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 17:51:24 visual_prompt]: 	Test 500/512. loss: 3.009, 0.1999 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 17:51:28 visual_prompt]: Inference (test):avg data time: 8.41e-03, avg batch time: 0.1953, average loss: 2.9559
[09/16 17:51:28 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 84.13	
[09/16 17:51:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 17:51:40 visual_prompt]: Epoch 7 / 100: avg data time: 1.89e-01, avg batch time: 0.5933, average train loss: 1.2556
[09/16 17:51:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1434, average loss: 2.4688
[09/16 17:51:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 91.27	
[09/16 17:52:08 visual_prompt]: 	Test 100/512. loss: 2.258, 0.2244 s / batch. (data: 4.20e-02)max mem: 17.22442 GB 
[09/16 17:52:28 visual_prompt]: 	Test 200/512. loss: 2.328, 0.1845 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 17:52:48 visual_prompt]: 	Test 300/512. loss: 1.974, 0.2079 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/16 17:53:07 visual_prompt]: 	Test 400/512. loss: 2.474, 0.1847 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 17:53:27 visual_prompt]: 	Test 500/512. loss: 2.392, 0.1842 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 17:53:32 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1956, average loss: 2.3845
[09/16 17:53:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 85.22	
[09/16 17:53:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 17:53:43 visual_prompt]: Epoch 8 / 100: avg data time: 1.97e-01, avg batch time: 0.6009, average train loss: 3.9172
[09/16 17:53:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1432, average loss: 2.8430
[09/16 17:53:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 91.37	
[09/16 17:54:12 visual_prompt]: 	Test 100/512. loss: 2.581, 0.2069 s / batch. (data: 2.44e-02)max mem: 17.22442 GB 
[09/16 17:54:31 visual_prompt]: 	Test 200/512. loss: 2.680, 0.1978 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 17:54:51 visual_prompt]: 	Test 300/512. loss: 2.248, 0.1846 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 17:55:10 visual_prompt]: 	Test 400/512. loss: 2.839, 0.1847 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 17:55:30 visual_prompt]: 	Test 500/512. loss: 2.741, 0.1993 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 17:55:35 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1947, average loss: 2.7419
[09/16 17:55:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 85.66	
[09/16 17:55:35 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 17:55:47 visual_prompt]: Epoch 9 / 100: avg data time: 1.87e-01, avg batch time: 0.5901, average train loss: 3.3571
[09/16 17:55:52 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1434, average loss: 5.0555
[09/16 17:55:52 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 90.82	
[09/16 17:56:15 visual_prompt]: 	Test 100/512. loss: 5.688, 0.1887 s / batch. (data: 4.32e-05)max mem: 17.22442 GB 
[09/16 17:56:35 visual_prompt]: 	Test 200/512. loss: 5.612, 0.1849 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 17:56:54 visual_prompt]: 	Test 300/512. loss: 6.279, 0.2343 s / batch. (data: 2.63e-02)max mem: 17.22442 GB 
[09/16 17:57:14 visual_prompt]: 	Test 400/512. loss: 5.245, 0.2073 s / batch. (data: 2.38e-02)max mem: 17.22442 GB 
[09/16 17:57:34 visual_prompt]: 	Test 500/512. loss: 5.297, 0.1997 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 17:57:39 visual_prompt]: Inference (test):avg data time: 9.00e-03, avg batch time: 0.1976, average loss: 5.5247
[09/16 17:57:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 83.10	
[09/16 17:57:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 17:57:51 visual_prompt]: Epoch 10 / 100: avg data time: 1.95e-01, avg batch time: 0.5994, average train loss: 3.1459
[09/16 17:57:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1435, average loss: 0.4092
[09/16 17:57:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 84.00	rocauc: 91.11	
[09/16 17:58:20 visual_prompt]: 	Test 100/512. loss: 0.656, 0.1988 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 17:58:39 visual_prompt]: 	Test 200/512. loss: 0.591, 0.2093 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 17:58:59 visual_prompt]: 	Test 300/512. loss: 0.750, 0.2000 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 17:59:18 visual_prompt]: 	Test 400/512. loss: 0.757, 0.2001 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 17:59:38 visual_prompt]: 	Test 500/512. loss: 0.602, 0.1848 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 17:59:43 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1957, average loss: 0.6808
[09/16 17:59:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.51	rocauc: 83.32	
[09/16 17:59:43 visual_prompt]: Best epoch 10: best metric: 0.840
[09/16 17:59:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 17:59:54 visual_prompt]: Epoch 11 / 100: avg data time: 1.80e-01, avg batch time: 0.5859, average train loss: 4.8215
[09/16 18:00:00 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1436, average loss: 2.5720
[09/16 18:00:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 90.66	
[09/16 18:00:22 visual_prompt]: 	Test 100/512. loss: 2.984, 0.1984 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 18:00:42 visual_prompt]: 	Test 200/512. loss: 2.943, 0.1842 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 18:01:01 visual_prompt]: 	Test 300/512. loss: 3.340, 0.1914 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 18:01:21 visual_prompt]: 	Test 400/512. loss: 2.788, 0.2117 s / batch. (data: 2.80e-02)max mem: 17.22442 GB 
[09/16 18:01:40 visual_prompt]: 	Test 500/512. loss: 2.814, 0.1964 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 18:01:46 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1949, average loss: 2.9167
[09/16 18:01:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 84.22	
[09/16 18:01:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 18:01:57 visual_prompt]: Epoch 12 / 100: avg data time: 1.74e-01, avg batch time: 0.5841, average train loss: 0.9574
[09/16 18:02:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1434, average loss: 0.4933
[09/16 18:02:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 92.46	
[09/16 18:02:25 visual_prompt]: 	Test 100/512. loss: 0.529, 0.1850 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 18:02:45 visual_prompt]: 	Test 200/512. loss: 0.540, 0.1840 s / batch. (data: 1.12e-04)max mem: 17.22442 GB 
[09/16 18:03:04 visual_prompt]: 	Test 300/512. loss: 0.346, 0.1838 s / batch. (data: 2.93e-05)max mem: 17.22442 GB 
[09/16 18:03:24 visual_prompt]: 	Test 400/512. loss: 0.629, 0.2055 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 18:03:44 visual_prompt]: 	Test 500/512. loss: 0.463, 0.2736 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 18:03:49 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1949, average loss: 0.5501
[09/16 18:03:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.22	rocauc: 87.25	
[09/16 18:03:49 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 18:04:00 visual_prompt]: Epoch 13 / 100: avg data time: 1.89e-01, avg batch time: 0.5921, average train loss: 0.8947
[09/16 18:04:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 0.4098
[09/16 18:04:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.00	rocauc: 93.14	
[09/16 18:04:29 visual_prompt]: 	Test 100/512. loss: 0.483, 0.2150 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 18:04:48 visual_prompt]: 	Test 200/512. loss: 0.477, 0.1843 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 18:05:08 visual_prompt]: 	Test 300/512. loss: 0.308, 0.1984 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 18:05:27 visual_prompt]: 	Test 400/512. loss: 0.557, 0.1980 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 18:05:47 visual_prompt]: 	Test 500/512. loss: 0.378, 0.1856 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 18:05:52 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1952, average loss: 0.4913
[09/16 18:05:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.94	rocauc: 87.81	
[09/16 18:05:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 18:06:03 visual_prompt]: Epoch 14 / 100: avg data time: 1.86e-01, avg batch time: 0.5894, average train loss: 0.5790
[09/16 18:06:09 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1434, average loss: 0.4854
[09/16 18:06:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 79.00	rocauc: 93.85	
[09/16 18:06:32 visual_prompt]: 	Test 100/512. loss: 0.506, 0.1971 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 18:06:52 visual_prompt]: 	Test 200/512. loss: 0.562, 0.1856 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 18:07:11 visual_prompt]: 	Test 300/512. loss: 0.342, 0.1866 s / batch. (data: 3.22e-05)max mem: 17.22442 GB 
[09/16 18:07:31 visual_prompt]: 	Test 400/512. loss: 0.610, 0.1849 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 18:07:51 visual_prompt]: 	Test 500/512. loss: 0.472, 0.1991 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 18:07:55 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1961, average loss: 0.5501
[09/16 18:07:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.10	rocauc: 88.87	
[09/16 18:07:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 18:08:08 visual_prompt]: Epoch 15 / 100: avg data time: 1.92e-01, avg batch time: 0.6098, average train loss: 0.6538
[09/16 18:08:14 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1434, average loss: 0.7006
[09/16 18:08:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 73.00	rocauc: 94.01	
[09/16 18:08:36 visual_prompt]: 	Test 100/512. loss: 0.668, 0.1837 s / batch. (data: 1.67e-04)max mem: 17.22442 GB 
[09/16 18:08:56 visual_prompt]: 	Test 200/512. loss: 0.777, 0.1939 s / batch. (data: 3.43e-05)max mem: 17.22442 GB 
[09/16 18:09:15 visual_prompt]: 	Test 300/512. loss: 0.480, 0.1909 s / batch. (data: 3.70e-05)max mem: 17.22442 GB 
[09/16 18:09:35 visual_prompt]: 	Test 400/512. loss: 0.856, 0.2113 s / batch. (data: 1.44e-02)max mem: 17.22442 GB 
[09/16 18:09:54 visual_prompt]: 	Test 500/512. loss: 0.656, 0.1844 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 18:09:59 visual_prompt]: Inference (test):avg data time: 8.91e-03, avg batch time: 0.1951, average loss: 0.7765
[09/16 18:09:59 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.41	rocauc: 89.06	
[09/16 18:09:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 18:10:11 visual_prompt]: Epoch 16 / 100: avg data time: 1.88e-01, avg batch time: 0.5927, average train loss: 0.5076
[09/16 18:10:16 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1440, average loss: 0.5083
[09/16 18:10:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.00	rocauc: 94.38	
[09/16 18:10:40 visual_prompt]: 	Test 100/512. loss: 0.821, 0.2353 s / batch. (data: 5.27e-02)max mem: 17.22442 GB 
[09/16 18:11:00 visual_prompt]: 	Test 200/512. loss: 0.722, 0.1965 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 18:11:19 visual_prompt]: 	Test 300/512. loss: 0.763, 0.1988 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 18:11:39 visual_prompt]: 	Test 400/512. loss: 0.694, 0.1846 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 18:11:58 visual_prompt]: 	Test 500/512. loss: 0.656, 0.1854 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 18:12:03 visual_prompt]: Inference (test):avg data time: 8.58e-03, avg batch time: 0.1969, average loss: 0.7531
[09/16 18:12:03 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.76	rocauc: 89.20	
[09/16 18:12:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 18:12:15 visual_prompt]: Epoch 17 / 100: avg data time: 1.76e-01, avg batch time: 0.5807, average train loss: 1.0442
[09/16 18:12:20 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1435, average loss: 0.9645
[09/16 18:12:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 61.50	rocauc: 93.47	
[09/16 18:12:43 visual_prompt]: 	Test 100/512. loss: 0.925, 0.2303 s / batch. (data: 4.17e-02)max mem: 17.22442 GB 
[09/16 18:13:02 visual_prompt]: 	Test 200/512. loss: 1.005, 0.2050 s / batch. (data: 1.92e-02)max mem: 17.22442 GB 
[09/16 18:13:22 visual_prompt]: 	Test 300/512. loss: 0.759, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 18:13:42 visual_prompt]: 	Test 400/512. loss: 1.167, 0.1988 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 18:14:01 visual_prompt]: 	Test 500/512. loss: 0.983, 0.2220 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 18:14:06 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1955, average loss: 1.0359
[09/16 18:14:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 61.91	rocauc: 88.44	
[09/16 18:14:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 18:14:18 visual_prompt]: Epoch 18 / 100: avg data time: 1.95e-01, avg batch time: 0.5977, average train loss: 0.6698
[09/16 18:14:24 visual_prompt]: Inference (val):avg data time: 4.99e-05, avg batch time: 0.1582, average loss: 0.3523
[09/16 18:14:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 93.13	
[09/16 18:14:47 visual_prompt]: 	Test 100/512. loss: 0.507, 0.1889 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 18:15:06 visual_prompt]: 	Test 200/512. loss: 0.448, 0.1843 s / batch. (data: 1.04e-04)max mem: 17.22442 GB 
[09/16 18:15:26 visual_prompt]: 	Test 300/512. loss: 0.387, 0.1839 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 18:15:45 visual_prompt]: 	Test 400/512. loss: 0.482, 0.1851 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 18:16:05 visual_prompt]: 	Test 500/512. loss: 0.420, 0.2117 s / batch. (data: 2.82e-02)max mem: 17.22442 GB 
[09/16 18:16:10 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1948, average loss: 0.4696
[09/16 18:16:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.54	rocauc: 89.25	
[09/16 18:16:10 visual_prompt]: Best epoch 18: best metric: 0.850
[09/16 18:16:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 18:16:22 visual_prompt]: Epoch 19 / 100: avg data time: 1.98e-01, avg batch time: 0.6001, average train loss: 0.5078
[09/16 18:16:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1433, average loss: 0.4701
[09/16 18:16:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 78.50	rocauc: 95.28	
[09/16 18:16:50 visual_prompt]: 	Test 100/512. loss: 0.548, 0.1838 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 18:17:10 visual_prompt]: 	Test 200/512. loss: 0.562, 0.1973 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 18:17:30 visual_prompt]: 	Test 300/512. loss: 0.378, 0.1846 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 18:17:49 visual_prompt]: 	Test 400/512. loss: 0.530, 0.1850 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 18:18:09 visual_prompt]: 	Test 500/512. loss: 0.482, 0.2103 s / batch. (data: 2.67e-02)max mem: 17.22442 GB 
[09/16 18:18:13 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1955, average loss: 0.5546
[09/16 18:18:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.89	rocauc: 89.09	
[09/16 18:18:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 18:18:25 visual_prompt]: Epoch 20 / 100: avg data time: 1.88e-01, avg batch time: 0.5911, average train loss: 0.6211
[09/16 18:18:31 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 1.6036
[09/16 18:18:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 51.00	rocauc: 94.10	
[09/16 18:18:53 visual_prompt]: 	Test 100/512. loss: 1.597, 0.1960 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 18:19:13 visual_prompt]: 	Test 200/512. loss: 1.704, 0.2074 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 18:19:32 visual_prompt]: 	Test 300/512. loss: 1.208, 0.1844 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 18:19:52 visual_prompt]: 	Test 400/512. loss: 1.922, 0.2160 s / batch. (data: 3.96e-05)max mem: 17.22442 GB 
[09/16 18:20:11 visual_prompt]: 	Test 500/512. loss: 1.574, 0.1846 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 18:20:16 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1946, average loss: 1.7126
[09/16 18:20:16 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 52.19	rocauc: 90.12	
[09/16 18:20:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 18:20:28 visual_prompt]: Epoch 21 / 100: avg data time: 1.87e-01, avg batch time: 0.5898, average train loss: 0.9027
[09/16 18:20:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1434, average loss: 1.1856
[09/16 18:20:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 58.50	rocauc: 95.34	
[09/16 18:20:56 visual_prompt]: 	Test 100/512. loss: 1.167, 0.1958 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 18:21:16 visual_prompt]: 	Test 200/512. loss: 1.246, 0.1841 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 18:21:35 visual_prompt]: 	Test 300/512. loss: 0.794, 0.1846 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 18:21:55 visual_prompt]: 	Test 400/512. loss: 1.362, 0.2067 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 18:22:15 visual_prompt]: 	Test 500/512. loss: 1.092, 0.1851 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 18:22:20 visual_prompt]: Inference (test):avg data time: 8.79e-03, avg batch time: 0.1966, average loss: 1.2876
[09/16 18:22:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.25	rocauc: 90.90	
[09/16 18:22:20 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 18:22:31 visual_prompt]: Epoch 22 / 100: avg data time: 1.99e-01, avg batch time: 0.6023, average train loss: 0.6850
[09/16 18:22:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1435, average loss: 0.3151
[09/16 18:22:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.50	rocauc: 95.23	
[09/16 18:23:00 visual_prompt]: 	Test 100/512. loss: 0.529, 0.1836 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 18:23:19 visual_prompt]: 	Test 200/512. loss: 0.406, 0.1837 s / batch. (data: 3.19e-05)max mem: 17.22442 GB 
[09/16 18:23:39 visual_prompt]: 	Test 300/512. loss: 0.355, 0.1839 s / batch. (data: 1.68e-04)max mem: 17.22442 GB 
[09/16 18:23:59 visual_prompt]: 	Test 400/512. loss: 0.417, 0.1980 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 18:24:18 visual_prompt]: 	Test 500/512. loss: 0.389, 0.1996 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 18:24:24 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1952, average loss: 0.4524
[09/16 18:24:24 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.55	rocauc: 90.66	
[09/16 18:24:24 visual_prompt]: Best epoch 22: best metric: 0.855
[09/16 18:24:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 18:24:36 visual_prompt]: Epoch 23 / 100: avg data time: 1.94e-01, avg batch time: 0.5960, average train loss: 0.6549
[09/16 18:24:42 visual_prompt]: Inference (val):avg data time: 4.00e-04, avg batch time: 0.2453, average loss: 1.1773
[09/16 18:24:42 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 61.50	rocauc: 95.97	
[09/16 18:25:04 visual_prompt]: 	Test 100/512. loss: 1.213, 0.2094 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 18:25:24 visual_prompt]: 	Test 200/512. loss: 1.349, 0.1878 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 18:25:43 visual_prompt]: 	Test 300/512. loss: 0.877, 0.1843 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 18:26:03 visual_prompt]: 	Test 400/512. loss: 1.389, 0.2076 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 18:26:23 visual_prompt]: 	Test 500/512. loss: 1.233, 0.2020 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 18:26:28 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1953, average loss: 1.3395
[09/16 18:26:28 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 61.28	rocauc: 90.61	
[09/16 18:26:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 18:26:39 visual_prompt]: Epoch 24 / 100: avg data time: 1.81e-01, avg batch time: 0.5851, average train loss: 0.5539
[09/16 18:26:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1433, average loss: 0.4760
[09/16 18:26:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.50	rocauc: 96.05	
[09/16 18:27:07 visual_prompt]: 	Test 100/512. loss: 0.551, 0.1932 s / batch. (data: 9.92e-05)max mem: 17.22442 GB 
[09/16 18:27:27 visual_prompt]: 	Test 200/512. loss: 0.439, 0.1977 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 18:27:47 visual_prompt]: 	Test 300/512. loss: 0.316, 0.2309 s / batch. (data: 3.29e-02)max mem: 17.22442 GB 
[09/16 18:28:07 visual_prompt]: 	Test 400/512. loss: 0.668, 0.1996 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 18:28:27 visual_prompt]: 	Test 500/512. loss: 0.544, 0.1962 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 18:28:32 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1965, average loss: 0.5718
[09/16 18:28:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.46	rocauc: 91.57	
[09/16 18:28:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 18:28:43 visual_prompt]: Epoch 25 / 100: avg data time: 1.91e-01, avg batch time: 0.5939, average train loss: 0.4778
[09/16 18:28:49 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1435, average loss: 0.2663
[09/16 18:28:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 96.12	
[09/16 18:29:12 visual_prompt]: 	Test 100/512. loss: 0.428, 0.2149 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 18:29:31 visual_prompt]: 	Test 200/512. loss: 0.326, 0.1850 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 18:29:51 visual_prompt]: 	Test 300/512. loss: 0.273, 0.2141 s / batch. (data: 3.09e-02)max mem: 17.22442 GB 
[09/16 18:30:10 visual_prompt]: 	Test 400/512. loss: 0.395, 0.1837 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 18:30:30 visual_prompt]: 	Test 500/512. loss: 0.398, 0.1978 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 18:30:35 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1949, average loss: 0.3923
[09/16 18:30:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.30	rocauc: 91.18	
[09/16 18:30:35 visual_prompt]: Best epoch 25: best metric: 0.885
[09/16 18:30:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 18:30:46 visual_prompt]: Epoch 26 / 100: avg data time: 1.96e-01, avg batch time: 0.5996, average train loss: 0.3586
[09/16 18:30:52 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1435, average loss: 0.2639
[09/16 18:30:52 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 96.82	
[09/16 18:31:15 visual_prompt]: 	Test 100/512. loss: 0.438, 0.2006 s / batch. (data: 4.22e-05)max mem: 17.22442 GB 
[09/16 18:31:35 visual_prompt]: 	Test 200/512. loss: 0.385, 0.2346 s / batch. (data: 5.12e-02)max mem: 17.22442 GB 
[09/16 18:31:54 visual_prompt]: 	Test 300/512. loss: 0.286, 0.2190 s / batch. (data: 3.56e-02)max mem: 17.22442 GB 
[09/16 18:32:14 visual_prompt]: 	Test 400/512. loss: 0.388, 0.1978 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 18:32:34 visual_prompt]: 	Test 500/512. loss: 0.437, 0.2073 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 18:32:39 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1956, average loss: 0.4198
[09/16 18:32:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.08	rocauc: 89.24	
[09/16 18:32:39 visual_prompt]: Best epoch 26: best metric: 0.905
[09/16 18:32:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 18:32:50 visual_prompt]: Epoch 27 / 100: avg data time: 1.90e-01, avg batch time: 0.5948, average train loss: 0.4192
[09/16 18:32:56 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1435, average loss: 0.7125
[09/16 18:32:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.00	rocauc: 96.38	
[09/16 18:33:19 visual_prompt]: 	Test 100/512. loss: 1.335, 0.1962 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 18:33:39 visual_prompt]: 	Test 200/512. loss: 1.054, 0.1917 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 18:33:59 visual_prompt]: 	Test 300/512. loss: 1.071, 0.1972 s / batch. (data: 1.68e-04)max mem: 17.22442 GB 
[09/16 18:34:18 visual_prompt]: 	Test 400/512. loss: 0.929, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 18:34:38 visual_prompt]: 	Test 500/512. loss: 1.115, 0.2118 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 18:34:43 visual_prompt]: Inference (test):avg data time: 8.68e-03, avg batch time: 0.1962, average loss: 1.1439
[09/16 18:34:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.39	rocauc: 90.45	
[09/16 18:34:43 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 18:34:55 visual_prompt]: Epoch 28 / 100: avg data time: 1.95e-01, avg batch time: 0.5986, average train loss: 0.5807
[09/16 18:35:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1436, average loss: 0.5313
[09/16 18:35:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 68.00	rocauc: 94.49	
[09/16 18:35:23 visual_prompt]: 	Test 100/512. loss: 0.716, 0.1843 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 18:35:43 visual_prompt]: 	Test 200/512. loss: 0.604, 0.1984 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 18:36:03 visual_prompt]: 	Test 300/512. loss: 0.729, 0.1846 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 18:36:22 visual_prompt]: 	Test 400/512. loss: 0.657, 0.1996 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 18:36:42 visual_prompt]: 	Test 500/512. loss: 0.646, 0.1849 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 18:36:47 visual_prompt]: Inference (test):avg data time: 6.81e-03, avg batch time: 0.1958, average loss: 0.6565
[09/16 18:36:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 63.22	rocauc: 89.74	
[09/16 18:36:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 18:36:59 visual_prompt]: Epoch 29 / 100: avg data time: 1.91e-01, avg batch time: 0.5977, average train loss: 0.7104
[09/16 18:37:04 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1434, average loss: 0.3013
[09/16 18:37:04 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 96.14	
[09/16 18:37:27 visual_prompt]: 	Test 100/512. loss: 0.401, 0.2077 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 18:37:46 visual_prompt]: 	Test 200/512. loss: 0.341, 0.1962 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 18:38:06 visual_prompt]: 	Test 300/512. loss: 0.301, 0.1991 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 18:38:26 visual_prompt]: 	Test 400/512. loss: 0.438, 0.1839 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 18:38:45 visual_prompt]: 	Test 500/512. loss: 0.452, 0.1850 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 18:38:50 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1947, average loss: 0.4436
[09/16 18:38:50 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.92	rocauc: 90.15	
[09/16 18:38:50 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 18:39:02 visual_prompt]: Epoch 30 / 100: avg data time: 1.82e-01, avg batch time: 0.5916, average train loss: 0.4536
[09/16 18:39:07 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1435, average loss: 0.2383
[09/16 18:39:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.50	rocauc: 97.01	
[09/16 18:39:30 visual_prompt]: 	Test 100/512. loss: 0.541, 0.1918 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 18:39:50 visual_prompt]: 	Test 200/512. loss: 0.453, 0.2085 s / batch. (data: 2.54e-02)max mem: 17.22442 GB 
[09/16 18:40:09 visual_prompt]: 	Test 300/512. loss: 0.440, 0.1842 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 18:40:29 visual_prompt]: 	Test 400/512. loss: 0.562, 0.1987 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 18:40:48 visual_prompt]: 	Test 500/512. loss: 0.527, 0.1985 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 18:40:53 visual_prompt]: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1952, average loss: 0.5120
[09/16 18:40:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.51	rocauc: 90.81	
[09/16 18:40:53 visual_prompt]: Best epoch 30: best metric: 0.925
[09/16 18:40:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 18:41:05 visual_prompt]: Epoch 31 / 100: avg data time: 1.91e-01, avg batch time: 0.5952, average train loss: 0.7827
[09/16 18:41:10 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1433, average loss: 0.4079
[09/16 18:41:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 82.00	rocauc: 96.73	
[09/16 18:41:33 visual_prompt]: 	Test 100/512. loss: 0.801, 0.1953 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 18:41:53 visual_prompt]: 	Test 200/512. loss: 0.677, 0.2080 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 18:42:12 visual_prompt]: 	Test 300/512. loss: 0.681, 0.2034 s / batch. (data: 2.00e-02)max mem: 17.22442 GB 
[09/16 18:42:32 visual_prompt]: 	Test 400/512. loss: 0.596, 0.1856 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 18:42:51 visual_prompt]: 	Test 500/512. loss: 0.599, 0.1882 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 18:42:56 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1952, average loss: 0.6709
[09/16 18:42:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.96	rocauc: 89.20	
[09/16 18:42:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 18:43:08 visual_prompt]: Epoch 32 / 100: avg data time: 1.75e-01, avg batch time: 0.5810, average train loss: 0.9695
[09/16 18:43:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1433, average loss: 0.3100
[09/16 18:43:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.50	rocauc: 95.16	
[09/16 18:43:36 visual_prompt]: 	Test 100/512. loss: 0.420, 0.2082 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 18:43:56 visual_prompt]: 	Test 200/512. loss: 0.355, 0.1844 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 18:44:16 visual_prompt]: 	Test 300/512. loss: 0.307, 0.1848 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 18:44:35 visual_prompt]: 	Test 400/512. loss: 0.375, 0.1868 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 18:44:55 visual_prompt]: 	Test 500/512. loss: 0.316, 0.1854 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 18:45:00 visual_prompt]: Inference (test):avg data time: 7.06e-03, avg batch time: 0.1953, average loss: 0.3962
[09/16 18:45:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.68	rocauc: 90.99	
[09/16 18:45:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 18:45:12 visual_prompt]: Epoch 33 / 100: avg data time: 1.93e-01, avg batch time: 0.6255, average train loss: 0.5738
[09/16 18:45:18 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1435, average loss: 0.6039
[09/16 18:45:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 70.00	rocauc: 95.99	
[09/16 18:45:41 visual_prompt]: 	Test 100/512. loss: 0.988, 0.1958 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 18:46:00 visual_prompt]: 	Test 200/512. loss: 0.961, 0.2038 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 18:46:20 visual_prompt]: 	Test 300/512. loss: 0.928, 0.1836 s / batch. (data: 3.24e-05)max mem: 17.22442 GB 
[09/16 18:46:39 visual_prompt]: 	Test 400/512. loss: 0.808, 0.2302 s / batch. (data: 7.07e-03)max mem: 17.22442 GB 
[09/16 18:46:59 visual_prompt]: 	Test 500/512. loss: 0.906, 0.1851 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 18:47:04 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1953, average loss: 0.9408
[09/16 18:47:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 57.44	rocauc: 90.15	
[09/16 18:47:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 18:47:16 visual_prompt]: Epoch 34 / 100: avg data time: 1.71e-01, avg batch time: 0.5823, average train loss: 0.6496
[09/16 18:47:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1434, average loss: 0.4090
[09/16 18:47:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 80.50	rocauc: 96.03	
[09/16 18:47:44 visual_prompt]: 	Test 100/512. loss: 0.656, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 18:48:03 visual_prompt]: 	Test 200/512. loss: 0.586, 0.1844 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 18:48:23 visual_prompt]: 	Test 300/512. loss: 0.587, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 18:48:43 visual_prompt]: 	Test 400/512. loss: 0.534, 0.1884 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 18:49:02 visual_prompt]: 	Test 500/512. loss: 0.643, 0.1847 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 18:49:07 visual_prompt]: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1960, average loss: 0.6230
[09/16 18:49:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.46	rocauc: 89.66	
[09/16 18:49:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 18:49:19 visual_prompt]: Epoch 35 / 100: avg data time: 1.98e-01, avg batch time: 0.6027, average train loss: 0.4495
[09/16 18:49:25 visual_prompt]: Inference (val):avg data time: 3.43e-04, avg batch time: 0.2159, average loss: 0.2247
[09/16 18:49:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 97.59	
[09/16 18:49:48 visual_prompt]: 	Test 100/512. loss: 0.471, 0.1978 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 18:50:07 visual_prompt]: 	Test 200/512. loss: 0.409, 0.1901 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 18:50:27 visual_prompt]: 	Test 300/512. loss: 0.349, 0.1981 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 18:50:47 visual_prompt]: 	Test 400/512. loss: 0.453, 0.2069 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 18:51:06 visual_prompt]: 	Test 500/512. loss: 0.442, 0.1963 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 18:51:11 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1958, average loss: 0.4193
[09/16 18:51:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 83.02	rocauc: 91.52	
[09/16 18:51:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 18:51:23 visual_prompt]: Epoch 36 / 100: avg data time: 1.85e-01, avg batch time: 0.5882, average train loss: 0.3791
[09/16 18:51:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1435, average loss: 0.5207
[09/16 18:51:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 77.50	rocauc: 97.17	
[09/16 18:51:51 visual_prompt]: 	Test 100/512. loss: 0.666, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 18:52:11 visual_prompt]: 	Test 200/512. loss: 0.743, 0.1917 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 18:52:30 visual_prompt]: 	Test 300/512. loss: 0.490, 0.1945 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 18:52:50 visual_prompt]: 	Test 400/512. loss: 0.603, 0.1982 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 18:53:09 visual_prompt]: 	Test 500/512. loss: 0.654, 0.1845 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 18:53:14 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1956, average loss: 0.6694
[09/16 18:53:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.42	rocauc: 89.58	
[09/16 18:53:14 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 18:53:26 visual_prompt]: Epoch 37 / 100: avg data time: 1.87e-01, avg batch time: 0.5909, average train loss: 0.5792
[09/16 18:53:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1435, average loss: 0.2114
[09/16 18:53:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 91.50	rocauc: 98.35	
[09/16 18:53:55 visual_prompt]: 	Test 100/512. loss: 0.511, 0.1852 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 18:54:14 visual_prompt]: 	Test 200/512. loss: 0.374, 0.1837 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 18:54:34 visual_prompt]: 	Test 300/512. loss: 0.463, 0.2021 s / batch. (data: 1.86e-02)max mem: 17.22442 GB 
[09/16 18:54:54 visual_prompt]: 	Test 400/512. loss: 0.559, 0.1976 s / batch. (data: 1.39e-02)max mem: 17.22442 GB 
[09/16 18:55:13 visual_prompt]: 	Test 500/512. loss: 0.528, 0.1842 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 18:55:19 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1965, average loss: 0.4982
[09/16 18:55:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 91.08	
[09/16 18:55:19 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 18:55:31 visual_prompt]: Epoch 38 / 100: avg data time: 1.96e-01, avg batch time: 0.6012, average train loss: 0.4254
[09/16 18:55:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1441, average loss: 0.2747
[09/16 18:55:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 98.71	
[09/16 18:56:00 visual_prompt]: 	Test 100/512. loss: 0.768, 0.1939 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 18:56:19 visual_prompt]: 	Test 200/512. loss: 0.575, 0.1833 s / batch. (data: 3.48e-05)max mem: 17.22442 GB 
[09/16 18:56:39 visual_prompt]: 	Test 300/512. loss: 0.697, 0.1842 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 18:56:58 visual_prompt]: 	Test 400/512. loss: 0.687, 0.2038 s / batch. (data: 2.00e-02)max mem: 17.22442 GB 
[09/16 18:57:18 visual_prompt]: 	Test 500/512. loss: 0.798, 0.1839 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 18:57:23 visual_prompt]: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1967, average loss: 0.7015
[09/16 18:57:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.49	rocauc: 91.58	
[09/16 18:57:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 18:57:35 visual_prompt]: Epoch 39 / 100: avg data time: 1.93e-01, avg batch time: 0.5963, average train loss: 0.3136
[09/16 18:57:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1435, average loss: 0.1544
[09/16 18:57:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.50	rocauc: 98.88	
[09/16 18:58:04 visual_prompt]: 	Test 100/512. loss: 0.443, 0.1975 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 18:58:23 visual_prompt]: 	Test 200/512. loss: 0.373, 0.1955 s / batch. (data: 3.31e-05)max mem: 17.22442 GB 
[09/16 18:58:43 visual_prompt]: 	Test 300/512. loss: 0.286, 0.1842 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 18:59:02 visual_prompt]: 	Test 400/512. loss: 0.423, 0.1984 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 18:59:22 visual_prompt]: 	Test 500/512. loss: 0.447, 0.2069 s / batch. (data: 2.33e-02)max mem: 17.22442 GB 
[09/16 18:59:27 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1961, average loss: 0.4070
[09/16 18:59:27 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.19	rocauc: 90.65	
[09/16 18:59:27 visual_prompt]: Best epoch 39: best metric: 0.945
[09/16 18:59:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 18:59:39 visual_prompt]: Epoch 40 / 100: avg data time: 1.94e-01, avg batch time: 0.5995, average train loss: 0.3319
[09/16 18:59:45 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1435, average loss: 0.2434
[09/16 18:59:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 99.16	
[09/16 19:00:07 visual_prompt]: 	Test 100/512. loss: 0.512, 0.1844 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 19:00:27 visual_prompt]: 	Test 200/512. loss: 0.396, 0.2462 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 19:00:47 visual_prompt]: 	Test 300/512. loss: 0.234, 0.1957 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 19:01:06 visual_prompt]: 	Test 400/512. loss: 0.561, 0.1974 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 19:01:26 visual_prompt]: 	Test 500/512. loss: 0.470, 0.1849 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 19:01:31 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1954, average loss: 0.4904
[09/16 19:01:31 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.60	rocauc: 93.16	
[09/16 19:01:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 19:01:42 visual_prompt]: Epoch 41 / 100: avg data time: 1.85e-01, avg batch time: 0.5895, average train loss: 0.5077
[09/16 19:01:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1435, average loss: 0.9835
[09/16 19:01:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.50	rocauc: 98.82	
[09/16 19:02:11 visual_prompt]: 	Test 100/512. loss: 1.612, 0.2006 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 19:02:31 visual_prompt]: 	Test 200/512. loss: 1.594, 0.1964 s / batch. (data: 1.04e-04)max mem: 17.22442 GB 
[09/16 19:02:50 visual_prompt]: 	Test 300/512. loss: 1.694, 0.2088 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 19:03:10 visual_prompt]: 	Test 400/512. loss: 1.461, 0.2015 s / batch. (data: 8.87e-05)max mem: 17.22442 GB 
[09/16 19:03:29 visual_prompt]: 	Test 500/512. loss: 1.506, 0.1964 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 19:03:34 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1958, average loss: 1.5364
[09/16 19:03:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.03	rocauc: 89.75	
[09/16 19:03:34 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 19:03:46 visual_prompt]: Epoch 42 / 100: avg data time: 1.95e-01, avg batch time: 0.6011, average train loss: 0.4432
[09/16 19:03:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1433, average loss: 0.2981
[09/16 19:03:52 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.50	rocauc: 98.52	
[09/16 19:04:14 visual_prompt]: 	Test 100/512. loss: 0.495, 0.1841 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 19:04:34 visual_prompt]: 	Test 200/512. loss: 0.467, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 19:04:54 visual_prompt]: 	Test 300/512. loss: 0.253, 0.2145 s / batch. (data: 3.11e-02)max mem: 17.22442 GB 
[09/16 19:05:13 visual_prompt]: 	Test 400/512. loss: 0.488, 0.1995 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 19:05:33 visual_prompt]: 	Test 500/512. loss: 0.513, 0.1844 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 19:05:38 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1955, average loss: 0.4580
[09/16 19:05:38 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.37	rocauc: 91.89	
[09/16 19:05:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 19:05:50 visual_prompt]: Epoch 43 / 100: avg data time: 1.88e-01, avg batch time: 0.5922, average train loss: 0.2157
[09/16 19:05:56 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1432, average loss: 0.1135
[09/16 19:05:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.00	rocauc: 99.20	
[09/16 19:06:18 visual_prompt]: 	Test 100/512. loss: 0.464, 0.1963 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 19:06:38 visual_prompt]: 	Test 200/512. loss: 0.392, 0.2027 s / batch. (data: 1.92e-02)max mem: 17.22442 GB 
[09/16 19:06:58 visual_prompt]: 	Test 300/512. loss: 0.241, 0.1986 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 19:07:18 visual_prompt]: 	Test 400/512. loss: 0.558, 0.1843 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 19:07:37 visual_prompt]: 	Test 500/512. loss: 0.398, 0.1967 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 19:07:42 visual_prompt]: Inference (test):avg data time: 8.52e-03, avg batch time: 0.1962, average loss: 0.4133
[09/16 19:07:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 84.30	rocauc: 92.46	
[09/16 19:07:42 visual_prompt]: Best epoch 43: best metric: 0.960
[09/16 19:07:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 19:07:54 visual_prompt]: Epoch 44 / 100: avg data time: 1.90e-01, avg batch time: 0.5944, average train loss: 0.1877
[09/16 19:07:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1437, average loss: 0.1673
[09/16 19:07:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.50	rocauc: 99.25	
[09/16 19:08:22 visual_prompt]: 	Test 100/512. loss: 0.786, 0.1939 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 19:08:41 visual_prompt]: 	Test 200/512. loss: 0.550, 0.1977 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 19:09:01 visual_prompt]: 	Test 300/512. loss: 0.747, 0.1980 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 19:09:21 visual_prompt]: 	Test 400/512. loss: 0.750, 0.1976 s / batch. (data: 1.35e-02)max mem: 17.22442 GB 
[09/16 19:09:40 visual_prompt]: 	Test 500/512. loss: 0.706, 0.1965 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 19:09:45 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1960, average loss: 0.6569
[09/16 19:09:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.18	rocauc: 90.17	
[09/16 19:09:45 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 19:09:57 visual_prompt]: Epoch 45 / 100: avg data time: 1.90e-01, avg batch time: 0.5929, average train loss: 0.2405
[09/16 19:10:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1433, average loss: 0.5925
[09/16 19:10:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 78.00	rocauc: 98.97	
[09/16 19:10:26 visual_prompt]: 	Test 100/512. loss: 0.921, 0.1837 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 19:10:45 visual_prompt]: 	Test 200/512. loss: 0.801, 0.1963 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 19:11:05 visual_prompt]: 	Test 300/512. loss: 0.436, 0.1962 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 19:11:24 visual_prompt]: 	Test 400/512. loss: 1.055, 0.1845 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 19:11:44 visual_prompt]: 	Test 500/512. loss: 1.007, 0.1989 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 19:11:49 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1959, average loss: 0.9010
[09/16 19:11:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.98	rocauc: 91.97	
[09/16 19:11:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 19:12:01 visual_prompt]: Epoch 46 / 100: avg data time: 1.87e-01, avg batch time: 0.5933, average train loss: 0.3205
[09/16 19:12:07 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 0.2093
[09/16 19:12:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 91.00	rocauc: 98.71	
[09/16 19:12:29 visual_prompt]: 	Test 100/512. loss: 0.553, 0.1842 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 19:12:49 visual_prompt]: 	Test 200/512. loss: 0.348, 0.2099 s / batch. (data: 1.64e-02)max mem: 17.22442 GB 
[09/16 19:13:08 visual_prompt]: 	Test 300/512. loss: 0.273, 0.1846 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 19:13:28 visual_prompt]: 	Test 400/512. loss: 0.405, 0.2032 s / batch. (data: 1.93e-02)max mem: 17.22442 GB 
[09/16 19:13:48 visual_prompt]: 	Test 500/512. loss: 0.358, 0.2000 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 19:13:53 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1964, average loss: 0.4403
[09/16 19:13:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 83.40	rocauc: 92.23	
[09/16 19:13:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 19:14:05 visual_prompt]: Epoch 47 / 100: avg data time: 1.86e-01, avg batch time: 0.5900, average train loss: 0.2918
[09/16 19:14:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1511, average loss: 0.2124
[09/16 19:14:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.00	rocauc: 99.09	
[09/16 19:14:33 visual_prompt]: 	Test 100/512. loss: 0.585, 0.1840 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 19:14:53 visual_prompt]: 	Test 200/512. loss: 0.568, 0.2085 s / batch. (data: 2.34e-02)max mem: 17.22442 GB 
[09/16 19:15:12 visual_prompt]: 	Test 300/512. loss: 0.284, 0.1844 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 19:15:32 visual_prompt]: 	Test 400/512. loss: 0.641, 0.1871 s / batch. (data: 5.05e-05)max mem: 17.22442 GB 
[09/16 19:15:52 visual_prompt]: 	Test 500/512. loss: 0.616, 0.1956 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 19:15:56 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1956, average loss: 0.5293
[09/16 19:15:56 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.10	rocauc: 90.41	
[09/16 19:15:56 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 19:16:08 visual_prompt]: Epoch 48 / 100: avg data time: 1.95e-01, avg batch time: 0.5983, average train loss: 0.3131
[09/16 19:16:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1476, average loss: 0.1338
[09/16 19:16:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 98.73	
[09/16 19:16:37 visual_prompt]: 	Test 100/512. loss: 0.778, 0.2036 s / batch. (data: 2.07e-02)max mem: 17.22442 GB 
[09/16 19:16:56 visual_prompt]: 	Test 200/512. loss: 0.386, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 19:17:16 visual_prompt]: 	Test 300/512. loss: 0.646, 0.1848 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 19:17:35 visual_prompt]: 	Test 400/512. loss: 0.653, 0.1839 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 19:17:55 visual_prompt]: 	Test 500/512. loss: 0.626, 0.2158 s / batch. (data: 3.20e-02)max mem: 17.22442 GB 
[09/16 19:18:00 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1951, average loss: 0.5432
[09/16 19:18:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.85	rocauc: 90.51	
[09/16 19:18:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 19:18:11 visual_prompt]: Epoch 49 / 100: avg data time: 1.81e-01, avg batch time: 0.5840, average train loss: 0.2464
[09/16 19:18:17 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1435, average loss: 0.2117
[09/16 19:18:17 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.00	rocauc: 97.59	
[09/16 19:18:40 visual_prompt]: 	Test 100/512. loss: 0.700, 0.1955 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 19:18:59 visual_prompt]: 	Test 200/512. loss: 0.601, 0.1846 s / batch. (data: 1.06e-04)max mem: 17.22442 GB 
[09/16 19:19:19 visual_prompt]: 	Test 300/512. loss: 0.715, 0.1878 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 19:19:39 visual_prompt]: 	Test 400/512. loss: 0.623, 0.1912 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 19:19:59 visual_prompt]: 	Test 500/512. loss: 0.676, 0.1847 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 19:20:04 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1959, average loss: 0.6487
[09/16 19:20:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.96	rocauc: 88.15	
[09/16 19:20:04 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 19:20:15 visual_prompt]: Epoch 50 / 100: avg data time: 1.89e-01, avg batch time: 0.5929, average train loss: 0.1962
[09/16 19:20:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1435, average loss: 0.1595
[09/16 19:20:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.00	rocauc: 98.94	
[09/16 19:20:43 visual_prompt]: 	Test 100/512. loss: 0.478, 0.1841 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 19:21:03 visual_prompt]: 	Test 200/512. loss: 0.378, 0.1991 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 19:21:22 visual_prompt]: 	Test 300/512. loss: 0.437, 0.1947 s / batch. (data: 3.19e-04)max mem: 17.22442 GB 
[09/16 19:21:42 visual_prompt]: 	Test 400/512. loss: 0.724, 0.1868 s / batch. (data: 1.77e-04)max mem: 17.22442 GB 
[09/16 19:22:01 visual_prompt]: 	Test 500/512. loss: 0.670, 0.2011 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 19:22:06 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1944, average loss: 0.5008
[09/16 19:22:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.76	rocauc: 90.64	
[09/16 19:22:06 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 19:22:18 visual_prompt]: Epoch 51 / 100: avg data time: 1.90e-01, avg batch time: 0.5975, average train loss: 0.2898
[09/16 19:22:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1434, average loss: 0.1514
[09/16 19:22:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.50	rocauc: 99.15	
[09/16 19:22:46 visual_prompt]: 	Test 100/512. loss: 0.525, 0.1894 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 19:23:06 visual_prompt]: 	Test 200/512. loss: 0.390, 0.1841 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 19:23:25 visual_prompt]: 	Test 300/512. loss: 0.330, 0.1846 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 19:23:45 visual_prompt]: 	Test 400/512. loss: 0.410, 0.1950 s / batch. (data: 1.18e-02)max mem: 17.22442 GB 
[09/16 19:24:04 visual_prompt]: 	Test 500/512. loss: 0.524, 0.2009 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 19:24:09 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1947, average loss: 0.4512
[09/16 19:24:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.74	rocauc: 90.58	
[09/16 19:24:09 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 19:24:21 visual_prompt]: Epoch 52 / 100: avg data time: 1.86e-01, avg batch time: 0.5888, average train loss: 0.2889
[09/16 19:24:27 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1433, average loss: 0.2603
[09/16 19:24:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.00	rocauc: 99.38	
[09/16 19:24:49 visual_prompt]: 	Test 100/512. loss: 0.609, 0.1981 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 19:25:09 visual_prompt]: 	Test 200/512. loss: 0.382, 0.2145 s / batch. (data: 2.06e-02)max mem: 17.22442 GB 
[09/16 19:25:29 visual_prompt]: 	Test 300/512. loss: 0.362, 0.2112 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 19:25:48 visual_prompt]: 	Test 400/512. loss: 0.524, 0.1904 s / batch. (data: 2.74e-05)max mem: 17.22442 GB 
[09/16 19:26:08 visual_prompt]: 	Test 500/512. loss: 0.478, 0.1852 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 19:26:13 visual_prompt]: Inference (test):avg data time: 8.60e-03, avg batch time: 0.1956, average loss: 0.5182
[09/16 19:26:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.09	rocauc: 90.76	
[09/16 19:26:13 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 19:26:24 visual_prompt]: Epoch 53 / 100: avg data time: 1.85e-01, avg batch time: 0.5983, average train loss: 0.2608
[09/16 19:26:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1432, average loss: 0.1556
[09/16 19:26:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.00	rocauc: 99.30	
[09/16 19:26:53 visual_prompt]: 	Test 100/512. loss: 0.518, 0.1838 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 19:27:13 visual_prompt]: 	Test 200/512. loss: 0.472, 0.2089 s / batch. (data: 2.58e-02)max mem: 17.22442 GB 
[09/16 19:27:32 visual_prompt]: 	Test 300/512. loss: 0.450, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 19:27:52 visual_prompt]: 	Test 400/512. loss: 0.601, 0.1851 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 19:28:12 visual_prompt]: 	Test 500/512. loss: 0.563, 0.1990 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 19:28:17 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1960, average loss: 0.4935
[09/16 19:28:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.39	rocauc: 91.70	
[09/16 19:28:17 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 19:28:28 visual_prompt]: Epoch 54 / 100: avg data time: 1.88e-01, avg batch time: 0.5933, average train loss: 0.2341
[09/16 19:28:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1435, average loss: 0.5785
[09/16 19:28:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.00	rocauc: 99.53	
[09/16 19:28:57 visual_prompt]: 	Test 100/512. loss: 1.042, 0.1980 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 19:29:16 visual_prompt]: 	Test 200/512. loss: 1.017, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 19:29:36 visual_prompt]: 	Test 300/512. loss: 0.570, 0.2115 s / batch. (data: 2.69e-02)max mem: 17.22442 GB 
[09/16 19:29:56 visual_prompt]: 	Test 400/512. loss: 0.835, 0.2026 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 19:30:15 visual_prompt]: 	Test 500/512. loss: 1.123, 0.2032 s / batch. (data: 1.98e-02)max mem: 17.22442 GB 
[09/16 19:30:20 visual_prompt]: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1958, average loss: 0.9422
[09/16 19:30:21 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.24	rocauc: 88.36	
[09/16 19:30:21 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 19:30:32 visual_prompt]: Epoch 55 / 100: avg data time: 1.95e-01, avg batch time: 0.5999, average train loss: 0.5385
[09/16 19:30:38 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1432, average loss: 0.2048
[09/16 19:30:38 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.50	rocauc: 98.33	
[09/16 19:31:01 visual_prompt]: 	Test 100/512. loss: 0.435, 0.1984 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 19:31:20 visual_prompt]: 	Test 200/512. loss: 0.384, 0.1840 s / batch. (data: 9.11e-05)max mem: 17.22442 GB 
[09/16 19:31:40 visual_prompt]: 	Test 300/512. loss: 0.283, 0.2005 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 19:31:59 visual_prompt]: 	Test 400/512. loss: 0.407, 0.1882 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 19:32:19 visual_prompt]: 	Test 500/512. loss: 0.356, 0.2069 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 19:32:24 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1954, average loss: 0.4057
[09/16 19:32:24 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.49	rocauc: 90.64	
[09/16 19:32:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 19:32:36 visual_prompt]: Epoch 56 / 100: avg data time: 1.98e-01, avg batch time: 0.6010, average train loss: 0.2129
[09/16 19:32:41 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1434, average loss: 0.1143
[09/16 19:32:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.52	
[09/16 19:33:04 visual_prompt]: 	Test 100/512. loss: 0.797, 0.1950 s / batch. (data: 1.21e-02)max mem: 17.22442 GB 
[09/16 19:33:24 visual_prompt]: 	Test 200/512. loss: 0.517, 0.1901 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 19:33:43 visual_prompt]: 	Test 300/512. loss: 0.733, 0.2407 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 19:34:03 visual_prompt]: 	Test 400/512. loss: 0.778, 0.1853 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 19:34:22 visual_prompt]: 	Test 500/512. loss: 0.861, 0.1996 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 19:34:27 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1956, average loss: 0.6172
[09/16 19:34:28 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.69	rocauc: 89.36	
[09/16 19:34:28 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 19:34:39 visual_prompt]: Epoch 57 / 100: avg data time: 1.96e-01, avg batch time: 0.5991, average train loss: 0.2409
[09/16 19:34:45 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1436, average loss: 0.3845
[09/16 19:34:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 89.50	rocauc: 98.55	
[09/16 19:35:08 visual_prompt]: 	Test 100/512. loss: 1.355, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 19:35:27 visual_prompt]: 	Test 200/512. loss: 1.184, 0.2006 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 19:35:47 visual_prompt]: 	Test 300/512. loss: 1.409, 0.1840 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 19:36:06 visual_prompt]: 	Test 400/512. loss: 1.308, 0.1849 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 19:36:26 visual_prompt]: 	Test 500/512. loss: 1.411, 0.2069 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 19:36:31 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1952, average loss: 1.1686
[09/16 19:36:31 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.11	rocauc: 89.81	
[09/16 19:36:31 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 19:36:43 visual_prompt]: Epoch 58 / 100: avg data time: 1.92e-01, avg batch time: 0.5951, average train loss: 0.4213
[09/16 19:36:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1434, average loss: 0.6548
[09/16 19:36:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 80.00	rocauc: 97.59	
[09/16 19:37:11 visual_prompt]: 	Test 100/512. loss: 0.721, 0.1969 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 19:37:31 visual_prompt]: 	Test 200/512. loss: 0.734, 0.2054 s / batch. (data: 2.20e-02)max mem: 17.22442 GB 
[09/16 19:37:51 visual_prompt]: 	Test 300/512. loss: 0.376, 0.2133 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 19:38:10 visual_prompt]: 	Test 400/512. loss: 0.914, 0.1888 s / batch. (data: 9.70e-05)max mem: 17.22442 GB 
[09/16 19:38:30 visual_prompt]: 	Test 500/512. loss: 0.534, 0.1964 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 19:38:35 visual_prompt]: Inference (test):avg data time: 8.65e-03, avg batch time: 0.1963, average loss: 0.7552
[09/16 19:38:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.97	rocauc: 90.10	
[09/16 19:38:35 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 19:38:47 visual_prompt]: Epoch 59 / 100: avg data time: 1.93e-01, avg batch time: 0.6181, average train loss: 0.3150
[09/16 19:38:53 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1433, average loss: 0.2716
[09/16 19:38:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 99.82	
[09/16 19:39:15 visual_prompt]: 	Test 100/512. loss: 1.333, 0.1833 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 19:39:35 visual_prompt]: 	Test 200/512. loss: 1.190, 0.1844 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 19:39:55 visual_prompt]: 	Test 300/512. loss: 1.385, 0.1966 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 19:40:14 visual_prompt]: 	Test 400/512. loss: 0.974, 0.1847 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 19:40:34 visual_prompt]: 	Test 500/512. loss: 1.465, 0.2170 s / batch. (data: 3.35e-02)max mem: 17.22442 GB 
[09/16 19:40:39 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1954, average loss: 1.2027
[09/16 19:40:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.41	rocauc: 88.83	
[09/16 19:40:39 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 19:40:51 visual_prompt]: Epoch 60 / 100: avg data time: 1.90e-01, avg batch time: 0.5959, average train loss: 0.2634
[09/16 19:40:56 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1434, average loss: 0.1090
[09/16 19:40:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.59	
[09/16 19:41:19 visual_prompt]: 	Test 100/512. loss: 0.449, 0.1843 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 19:41:39 visual_prompt]: 	Test 200/512. loss: 0.492, 0.1965 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 19:41:58 visual_prompt]: 	Test 300/512. loss: 0.485, 0.1848 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 19:42:18 visual_prompt]: 	Test 400/512. loss: 0.542, 0.1889 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 19:42:37 visual_prompt]: 	Test 500/512. loss: 0.412, 0.1846 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 19:42:42 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1951, average loss: 0.5178
[09/16 19:42:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.19	rocauc: 90.02	
[09/16 19:42:42 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 19:42:54 visual_prompt]: Epoch 61 / 100: avg data time: 1.95e-01, avg batch time: 0.5991, average train loss: 0.1147
[09/16 19:43:00 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1434, average loss: 0.1350
[09/16 19:43:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.44	
[09/16 19:43:22 visual_prompt]: 	Test 100/512. loss: 0.781, 0.2208 s / batch. (data: 3.78e-02)max mem: 17.22442 GB 
[09/16 19:43:42 visual_prompt]: 	Test 200/512. loss: 0.750, 0.1957 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 19:44:02 visual_prompt]: 	Test 300/512. loss: 0.816, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 19:44:21 visual_prompt]: 	Test 400/512. loss: 0.843, 0.1858 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 19:44:40 visual_prompt]: 	Test 500/512. loss: 0.804, 0.1846 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 19:44:45 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1946, average loss: 0.7765
[09/16 19:44:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.22	rocauc: 89.54	
[09/16 19:44:45 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 19:44:57 visual_prompt]: Epoch 62 / 100: avg data time: 1.82e-01, avg batch time: 0.5863, average train loss: 0.1599
[09/16 19:45:02 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1434, average loss: 0.1161
[09/16 19:45:02 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.50	rocauc: 99.68	
[09/16 19:45:25 visual_prompt]: 	Test 100/512. loss: 0.660, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 19:45:45 visual_prompt]: 	Test 200/512. loss: 0.627, 0.1830 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 19:46:04 visual_prompt]: 	Test 300/512. loss: 0.589, 0.1930 s / batch. (data: 9.39e-03)max mem: 17.22442 GB 
[09/16 19:46:24 visual_prompt]: 	Test 400/512. loss: 0.594, 0.2058 s / batch. (data: 1.66e-04)max mem: 17.22442 GB 
[09/16 19:46:44 visual_prompt]: 	Test 500/512. loss: 0.557, 0.1846 s / batch. (data: 8.32e-05)max mem: 17.22442 GB 
[09/16 19:46:48 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1960, average loss: 0.6094
[09/16 19:46:48 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.03	rocauc: 89.62	
[09/16 19:46:48 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 19:47:00 visual_prompt]: Epoch 63 / 100: avg data time: 1.90e-01, avg batch time: 0.6155, average train loss: 0.1009
[09/16 19:47:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1436, average loss: 0.0883
[09/16 19:47:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.76	
[09/16 19:47:29 visual_prompt]: 	Test 100/512. loss: 0.690, 0.2001 s / batch. (data: 1.72e-02)max mem: 17.22442 GB 
[09/16 19:47:49 visual_prompt]: 	Test 200/512. loss: 0.726, 0.1849 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 19:48:10 visual_prompt]: 	Test 300/512. loss: 0.582, 0.2181 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 19:48:29 visual_prompt]: 	Test 400/512. loss: 0.743, 0.1993 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 19:48:49 visual_prompt]: 	Test 500/512. loss: 0.765, 0.1967 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 19:48:54 visual_prompt]: Inference (test):avg data time: 8.52e-03, avg batch time: 0.1981, average loss: 0.6447
[09/16 19:48:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.57	rocauc: 89.04	
[09/16 19:48:54 visual_prompt]: Best epoch 63: best metric: 0.975
[09/16 19:48:54 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 19:49:06 visual_prompt]: Epoch 64 / 100: avg data time: 1.96e-01, avg batch time: 0.6000, average train loss: 0.0754
[09/16 19:49:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1433, average loss: 0.0314
[09/16 19:49:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.90	
[09/16 19:49:34 visual_prompt]: 	Test 100/512. loss: 0.864, 0.1893 s / batch. (data: 1.06e-04)max mem: 17.22442 GB 
[09/16 19:49:54 visual_prompt]: 	Test 200/512. loss: 0.628, 0.1842 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 19:50:14 visual_prompt]: 	Test 300/512. loss: 0.643, 0.1849 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 19:50:33 visual_prompt]: 	Test 400/512. loss: 0.801, 0.1837 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 19:50:53 visual_prompt]: 	Test 500/512. loss: 0.895, 0.1848 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 19:50:58 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1957, average loss: 0.7487
[09/16 19:50:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.91	rocauc: 89.57	
[09/16 19:50:58 visual_prompt]: Best epoch 64: best metric: 0.995
[09/16 19:50:58 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 19:51:09 visual_prompt]: Epoch 65 / 100: avg data time: 1.87e-01, avg batch time: 0.5922, average train loss: 0.0598
[09/16 19:51:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1435, average loss: 0.0318
[09/16 19:51:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.94	
[09/16 19:51:38 visual_prompt]: 	Test 100/512. loss: 0.809, 0.1941 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 19:51:57 visual_prompt]: 	Test 200/512. loss: 0.606, 0.1965 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 19:52:17 visual_prompt]: 	Test 300/512. loss: 0.612, 0.1868 s / batch. (data: 1.07e-04)max mem: 17.22442 GB 
[09/16 19:52:37 visual_prompt]: 	Test 400/512. loss: 0.918, 0.1983 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 19:52:56 visual_prompt]: 	Test 500/512. loss: 0.812, 0.1948 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 19:53:01 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1950, average loss: 0.6899
[09/16 19:53:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.80	rocauc: 89.89	
[09/16 19:53:01 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 19:53:13 visual_prompt]: Epoch 66 / 100: avg data time: 1.91e-01, avg batch time: 0.5941, average train loss: 0.0375
[09/16 19:53:18 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1437, average loss: 0.0523
[09/16 19:53:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 99.85	
[09/16 19:53:41 visual_prompt]: 	Test 100/512. loss: 1.026, 0.1833 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 19:54:01 visual_prompt]: 	Test 200/512. loss: 0.650, 0.2028 s / batch. (data: 1.98e-02)max mem: 17.22442 GB 
[09/16 19:54:20 visual_prompt]: 	Test 300/512. loss: 0.622, 0.2133 s / batch. (data: 2.96e-02)max mem: 17.22442 GB 
[09/16 19:54:40 visual_prompt]: 	Test 400/512. loss: 1.013, 0.1985 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 19:54:59 visual_prompt]: 	Test 500/512. loss: 0.780, 0.2079 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 19:55:04 visual_prompt]: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1955, average loss: 0.7479
[09/16 19:55:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.76	rocauc: 90.36	
[09/16 19:55:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 19:55:16 visual_prompt]: Epoch 67 / 100: avg data time: 1.96e-01, avg batch time: 0.6016, average train loss: 0.0205
[09/16 19:55:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1434, average loss: 0.0218
[09/16 19:55:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 99.98	
[09/16 19:55:44 visual_prompt]: 	Test 100/512. loss: 1.266, 0.1846 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 19:56:03 visual_prompt]: 	Test 200/512. loss: 0.887, 0.1960 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 19:56:23 visual_prompt]: 	Test 300/512. loss: 0.906, 0.1923 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 19:56:43 visual_prompt]: 	Test 400/512. loss: 0.990, 0.2170 s / batch. (data: 3.41e-02)max mem: 17.22442 GB 
[09/16 19:57:02 visual_prompt]: 	Test 500/512. loss: 1.043, 0.1930 s / batch. (data: 9.13e-03)max mem: 17.22442 GB 
[09/16 19:57:07 visual_prompt]: Inference (test):avg data time: 8.42e-03, avg batch time: 0.1947, average loss: 0.9521
[09/16 19:57:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.77	rocauc: 89.71	
[09/16 19:57:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 19:57:19 visual_prompt]: Epoch 68 / 100: avg data time: 1.97e-01, avg batch time: 0.6242, average train loss: 0.0219
[09/16 19:57:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1433, average loss: 0.0754
[09/16 19:57:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.00	rocauc: 99.94	
[09/16 19:57:47 visual_prompt]: 	Test 100/512. loss: 1.243, 0.1978 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 19:58:07 visual_prompt]: 	Test 200/512. loss: 0.812, 0.1932 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 19:58:26 visual_prompt]: 	Test 300/512. loss: 0.657, 0.1991 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 19:58:46 visual_prompt]: 	Test 400/512. loss: 1.064, 0.2366 s / batch. (data: 4.23e-02)max mem: 17.22442 GB 
[09/16 19:59:06 visual_prompt]: 	Test 500/512. loss: 0.582, 0.2100 s / batch. (data: 2.66e-02)max mem: 17.22442 GB 
[09/16 19:59:10 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1948, average loss: 0.8734
[09/16 19:59:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.53	rocauc: 90.10	
[09/16 19:59:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 19:59:22 visual_prompt]: Epoch 69 / 100: avg data time: 1.95e-01, avg batch time: 0.6011, average train loss: 0.0993
[09/16 19:59:28 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1529, average loss: 0.0938
[09/16 19:59:28 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.00	rocauc: 99.50	
[09/16 19:59:50 visual_prompt]: 	Test 100/512. loss: 0.655, 0.1955 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 20:00:10 visual_prompt]: 	Test 200/512. loss: 0.637, 0.1838 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 20:00:30 visual_prompt]: 	Test 300/512. loss: 0.624, 0.2000 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 20:00:50 visual_prompt]: 	Test 400/512. loss: 0.787, 0.1975 s / batch. (data: 9.32e-05)max mem: 17.22442 GB 
[09/16 20:01:09 visual_prompt]: 	Test 500/512. loss: 0.679, 0.1881 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 20:01:14 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1958, average loss: 0.7022
[09/16 20:01:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.58	rocauc: 90.25	
[09/16 20:01:14 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 20:01:26 visual_prompt]: Epoch 70 / 100: avg data time: 1.91e-01, avg batch time: 0.5951, average train loss: 0.1279
[09/16 20:01:32 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1433, average loss: 0.0796
[09/16 20:01:32 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.81	
[09/16 20:01:54 visual_prompt]: 	Test 100/512. loss: 0.673, 0.1871 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 20:02:14 visual_prompt]: 	Test 200/512. loss: 0.719, 0.1913 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 20:02:33 visual_prompt]: 	Test 300/512. loss: 0.509, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 20:02:53 visual_prompt]: 	Test 400/512. loss: 0.592, 0.1973 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 20:03:13 visual_prompt]: 	Test 500/512. loss: 0.781, 0.1947 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 20:03:17 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1953, average loss: 0.6568
[09/16 20:03:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.33	rocauc: 88.14	
[09/16 20:03:17 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 20:03:29 visual_prompt]: Epoch 71 / 100: avg data time: 1.87e-01, avg batch time: 0.5905, average train loss: 0.0725
[09/16 20:03:35 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1434, average loss: 0.0604
[09/16 20:03:35 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.85	
[09/16 20:03:57 visual_prompt]: 	Test 100/512. loss: 0.621, 0.1995 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 20:04:17 visual_prompt]: 	Test 200/512. loss: 0.686, 0.1871 s / batch. (data: 3.18e-03)max mem: 17.22442 GB 
[09/16 20:04:36 visual_prompt]: 	Test 300/512. loss: 0.628, 0.2037 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 20:04:56 visual_prompt]: 	Test 400/512. loss: 0.774, 0.1904 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 20:05:16 visual_prompt]: 	Test 500/512. loss: 0.656, 0.2033 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 20:05:20 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1956, average loss: 0.6364
[09/16 20:05:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.47	rocauc: 91.05	
[09/16 20:05:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 20:05:32 visual_prompt]: Epoch 72 / 100: avg data time: 1.91e-01, avg batch time: 0.5954, average train loss: 0.0491
[09/16 20:05:38 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1434, average loss: 0.0300
[09/16 20:05:38 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.97	
[09/16 20:06:01 visual_prompt]: 	Test 100/512. loss: 0.870, 0.1961 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 20:06:20 visual_prompt]: 	Test 200/512. loss: 0.887, 0.2027 s / batch. (data: 1.95e-02)max mem: 17.22442 GB 
[09/16 20:06:40 visual_prompt]: 	Test 300/512. loss: 0.685, 0.1910 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 20:06:59 visual_prompt]: 	Test 400/512. loss: 0.745, 0.1991 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 20:07:19 visual_prompt]: 	Test 500/512. loss: 1.125, 0.1845 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 20:07:24 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1946, average loss: 0.8505
[09/16 20:07:24 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.13	rocauc: 87.16	
[09/16 20:07:24 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 20:07:36 visual_prompt]: Epoch 73 / 100: avg data time: 1.97e-01, avg batch time: 0.6033, average train loss: 0.0492
[09/16 20:07:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1436, average loss: 0.1297
[09/16 20:07:42 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.50	rocauc: 99.51	
[09/16 20:08:04 visual_prompt]: 	Test 100/512. loss: 0.781, 0.2170 s / batch. (data: 3.44e-02)max mem: 17.22442 GB 
[09/16 20:08:24 visual_prompt]: 	Test 200/512. loss: 0.913, 0.2007 s / batch. (data: 1.78e-02)max mem: 17.22442 GB 
[09/16 20:08:43 visual_prompt]: 	Test 300/512. loss: 0.847, 0.1843 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 20:09:03 visual_prompt]: 	Test 400/512. loss: 1.091, 0.1992 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 20:09:23 visual_prompt]: 	Test 500/512. loss: 0.846, 0.1849 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 20:09:28 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1954, average loss: 0.8316
[09/16 20:09:28 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.05	rocauc: 89.99	
[09/16 20:09:28 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 20:09:40 visual_prompt]: Epoch 74 / 100: avg data time: 1.96e-01, avg batch time: 0.6003, average train loss: 0.1028
[09/16 20:09:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1434, average loss: 0.1344
[09/16 20:09:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.86	
[09/16 20:10:08 visual_prompt]: 	Test 100/512. loss: 0.602, 0.1962 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 20:10:27 visual_prompt]: 	Test 200/512. loss: 0.585, 0.2004 s / batch. (data: 2.91e-05)max mem: 17.22442 GB 
[09/16 20:10:47 visual_prompt]: 	Test 300/512. loss: 0.463, 0.2027 s / batch. (data: 1.09e-04)max mem: 17.22442 GB 
[09/16 20:11:06 visual_prompt]: 	Test 400/512. loss: 0.633, 0.2025 s / batch. (data: 1.90e-02)max mem: 17.22442 GB 
[09/16 20:11:25 visual_prompt]: 	Test 500/512. loss: 0.852, 0.2114 s / batch. (data: 2.76e-02)max mem: 17.22442 GB 
[09/16 20:11:30 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1939, average loss: 0.6610
[09/16 20:11:30 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.93	rocauc: 89.54	
[09/16 20:11:30 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 20:11:42 visual_prompt]: Epoch 75 / 100: avg data time: 1.80e-01, avg batch time: 0.5834, average train loss: 0.0475
[09/16 20:11:47 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1451, average loss: 0.0380
[09/16 20:11:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.00	rocauc: 99.95	
[09/16 20:12:10 visual_prompt]: 	Test 100/512. loss: 0.609, 0.1839 s / batch. (data: 9.11e-05)max mem: 17.22442 GB 
[09/16 20:12:29 visual_prompt]: 	Test 200/512. loss: 0.674, 0.1890 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 20:12:48 visual_prompt]: 	Test 300/512. loss: 0.362, 0.1969 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 20:13:08 visual_prompt]: 	Test 400/512. loss: 0.837, 0.1906 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 20:13:28 visual_prompt]: 	Test 500/512. loss: 0.892, 0.2156 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 20:13:33 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1943, average loss: 0.7244
[09/16 20:13:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 82.02	rocauc: 90.49	
[09/16 20:13:33 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 20:13:44 visual_prompt]: Epoch 76 / 100: avg data time: 1.80e-01, avg batch time: 0.5861, average train loss: 0.0243
[09/16 20:13:50 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1436, average loss: 0.0262
[09/16 20:13:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.99	
[09/16 20:14:13 visual_prompt]: 	Test 100/512. loss: 0.904, 0.1834 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 20:14:32 visual_prompt]: 	Test 200/512. loss: 1.054, 0.1833 s / batch. (data: 3.03e-05)max mem: 17.22442 GB 
[09/16 20:14:52 visual_prompt]: 	Test 300/512. loss: 0.844, 0.1842 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 20:15:12 visual_prompt]: 	Test 400/512. loss: 0.915, 0.1963 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 20:15:31 visual_prompt]: 	Test 500/512. loss: 1.095, 0.2022 s / batch. (data: 1.88e-02)max mem: 17.22442 GB 
[09/16 20:15:36 visual_prompt]: Inference (test):avg data time: 8.13e-03, avg batch time: 0.1954, average loss: 0.9592
[09/16 20:15:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.81	rocauc: 89.21	
[09/16 20:15:36 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 20:15:48 visual_prompt]: Epoch 77 / 100: avg data time: 1.93e-01, avg batch time: 0.6011, average train loss: 0.0129
[09/16 20:15:54 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1435, average loss: 0.0775
[09/16 20:15:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.00	rocauc: 99.91	
[09/16 20:16:16 visual_prompt]: 	Test 100/512. loss: 1.069, 0.1840 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 20:16:36 visual_prompt]: 	Test 200/512. loss: 1.065, 0.2102 s / batch. (data: 2.01e-02)max mem: 17.22442 GB 
[09/16 20:16:55 visual_prompt]: 	Test 300/512. loss: 0.900, 0.1962 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 20:17:15 visual_prompt]: 	Test 400/512. loss: 1.350, 0.1901 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 20:17:34 visual_prompt]: 	Test 500/512. loss: 1.328, 0.1951 s / batch. (data: 1.09e-02)max mem: 17.22442 GB 
[09/16 20:17:39 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1948, average loss: 1.0815
[09/16 20:17:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.83	rocauc: 90.35	
[09/16 20:17:39 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 20:17:51 visual_prompt]: Epoch 78 / 100: avg data time: 1.88e-01, avg batch time: 0.5925, average train loss: 0.0058
[09/16 20:17:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1435, average loss: 0.0173
[09/16 20:17:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:18:20 visual_prompt]: 	Test 100/512. loss: 1.446, 0.1836 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 20:18:39 visual_prompt]: 	Test 200/512. loss: 1.348, 0.1962 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 20:18:59 visual_prompt]: 	Test 300/512. loss: 1.072, 0.2218 s / batch. (data: 3.79e-02)max mem: 17.22442 GB 
[09/16 20:19:19 visual_prompt]: 	Test 400/512. loss: 1.556, 0.1842 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 20:19:39 visual_prompt]: 	Test 500/512. loss: 1.463, 0.2017 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 20:19:43 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1969, average loss: 1.2534
[09/16 20:19:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.70	rocauc: 89.08	
[09/16 20:19:44 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 20:19:55 visual_prompt]: Epoch 79 / 100: avg data time: 1.98e-01, avg batch time: 0.6022, average train loss: 0.0129
[09/16 20:20:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1436, average loss: 0.0116
[09/16 20:20:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:20:23 visual_prompt]: 	Test 100/512. loss: 0.993, 0.2062 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 20:20:43 visual_prompt]: 	Test 200/512. loss: 1.162, 0.1965 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 20:21:02 visual_prompt]: 	Test 300/512. loss: 0.994, 0.1998 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 20:21:22 visual_prompt]: 	Test 400/512. loss: 1.346, 0.1988 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 20:21:42 visual_prompt]: 	Test 500/512. loss: 1.525, 0.2046 s / batch. (data: 2.11e-02)max mem: 17.22442 GB 
[09/16 20:21:46 visual_prompt]: Inference (test):avg data time: 8.96e-03, avg batch time: 0.1951, average loss: 1.1123
[09/16 20:21:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.27	rocauc: 89.57	
[09/16 20:21:46 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 20:21:58 visual_prompt]: Epoch 80 / 100: avg data time: 1.87e-01, avg batch time: 0.5923, average train loss: 0.0125
[09/16 20:22:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1433, average loss: 0.0138
[09/16 20:22:04 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.98	
[09/16 20:22:26 visual_prompt]: 	Test 100/512. loss: 0.985, 0.1843 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 20:22:46 visual_prompt]: 	Test 200/512. loss: 1.217, 0.2224 s / batch. (data: 3.92e-02)max mem: 17.22442 GB 
[09/16 20:23:05 visual_prompt]: 	Test 300/512. loss: 1.122, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 20:23:25 visual_prompt]: 	Test 400/512. loss: 1.131, 0.1843 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 20:23:45 visual_prompt]: 	Test 500/512. loss: 1.819, 0.1845 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 20:23:50 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1958, average loss: 1.1406
[09/16 20:23:50 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.21	rocauc: 88.46	
[09/16 20:23:50 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 20:24:02 visual_prompt]: Epoch 81 / 100: avg data time: 1.85e-01, avg batch time: 0.5886, average train loss: 0.0038
[09/16 20:24:07 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1437, average loss: 0.0119
[09/16 20:24:07 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.98	
[09/16 20:24:30 visual_prompt]: 	Test 100/512. loss: 1.075, 0.1843 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 20:24:49 visual_prompt]: 	Test 200/512. loss: 1.290, 0.2004 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 20:25:09 visual_prompt]: 	Test 300/512. loss: 1.143, 0.1855 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 20:25:29 visual_prompt]: 	Test 400/512. loss: 1.270, 0.1853 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 20:25:48 visual_prompt]: 	Test 500/512. loss: 1.842, 0.1975 s / batch. (data: 1.35e-02)max mem: 17.22442 GB 
[09/16 20:25:53 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1950, average loss: 1.1911
[09/16 20:25:53 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.31	rocauc: 88.61	
[09/16 20:25:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 20:26:06 visual_prompt]: Epoch 82 / 100: avg data time: 1.95e-01, avg batch time: 0.6008, average train loss: 0.0026
[09/16 20:26:11 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1434, average loss: 0.0085
[09/16 20:26:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:26:34 visual_prompt]: 	Test 100/512. loss: 1.139, 0.1930 s / batch. (data: 1.12e-04)max mem: 17.22442 GB 
[09/16 20:26:54 visual_prompt]: 	Test 200/512. loss: 1.331, 0.1885 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 20:27:13 visual_prompt]: 	Test 300/512. loss: 1.190, 0.1964 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 20:27:33 visual_prompt]: 	Test 400/512. loss: 1.373, 0.2194 s / batch. (data: 3.64e-02)max mem: 17.22442 GB 
[09/16 20:27:53 visual_prompt]: 	Test 500/512. loss: 1.963, 0.1977 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 20:27:58 visual_prompt]: Inference (test):avg data time: 8.95e-03, avg batch time: 0.1962, average loss: 1.2596
[09/16 20:27:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.40	rocauc: 88.58	
[09/16 20:27:58 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 20:28:10 visual_prompt]: Epoch 83 / 100: avg data time: 1.89e-01, avg batch time: 0.5923, average train loss: 0.0022
[09/16 20:28:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1433, average loss: 0.0057
[09/16 20:28:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:28:38 visual_prompt]: 	Test 100/512. loss: 1.180, 0.1842 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 20:28:58 visual_prompt]: 	Test 200/512. loss: 1.389, 0.1979 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 20:29:17 visual_prompt]: 	Test 300/512. loss: 1.211, 0.2107 s / batch. (data: 2.71e-02)max mem: 17.22442 GB 
[09/16 20:29:37 visual_prompt]: 	Test 400/512. loss: 1.377, 0.1862 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 20:29:56 visual_prompt]: 	Test 500/512. loss: 1.929, 0.2018 s / batch. (data: 1.34e-02)max mem: 17.22442 GB 
[09/16 20:30:01 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1955, average loss: 1.2868
[09/16 20:30:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.49	rocauc: 88.64	
[09/16 20:30:01 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 20:30:13 visual_prompt]: Epoch 84 / 100: avg data time: 1.84e-01, avg batch time: 0.5899, average train loss: 0.0013
[09/16 20:30:19 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1431, average loss: 0.0066
[09/16 20:30:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:30:41 visual_prompt]: 	Test 100/512. loss: 1.295, 0.1936 s / batch. (data: 9.88e-03)max mem: 17.22442 GB 
[09/16 20:31:01 visual_prompt]: 	Test 200/512. loss: 1.519, 0.1834 s / batch. (data: 6.20e-05)max mem: 17.22442 GB 
[09/16 20:31:20 visual_prompt]: 	Test 300/512. loss: 1.321, 0.2001 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 20:31:40 visual_prompt]: 	Test 400/512. loss: 1.435, 0.1951 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 20:31:59 visual_prompt]: 	Test 500/512. loss: 1.919, 0.1837 s / batch. (data: 2.67e-05)max mem: 17.22442 GB 
[09/16 20:32:04 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1951, average loss: 1.3728
[09/16 20:32:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.48	rocauc: 88.52	
[09/16 20:32:04 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 20:32:16 visual_prompt]: Epoch 85 / 100: avg data time: 1.79e-01, avg batch time: 0.5843, average train loss: 0.0010
[09/16 20:32:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1433, average loss: 0.0036
[09/16 20:32:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:32:44 visual_prompt]: 	Test 100/512. loss: 1.430, 0.1919 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 20:33:04 visual_prompt]: 	Test 200/512. loss: 1.687, 0.1990 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 20:33:24 visual_prompt]: 	Test 300/512. loss: 1.439, 0.1842 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 20:33:43 visual_prompt]: 	Test 400/512. loss: 1.528, 0.1865 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 20:34:03 visual_prompt]: 	Test 500/512. loss: 2.048, 0.1992 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 20:34:07 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1943, average loss: 1.5051
[09/16 20:34:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.54	rocauc: 88.50	
[09/16 20:34:07 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 20:34:20 visual_prompt]: Epoch 86 / 100: avg data time: 1.95e-01, avg batch time: 0.5979, average train loss: 0.0006
[09/16 20:34:25 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1434, average loss: 0.0008
[09/16 20:34:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:34:48 visual_prompt]: 	Test 100/512. loss: 1.494, 0.1841 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 20:35:08 visual_prompt]: 	Test 200/512. loss: 1.788, 0.1846 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 20:35:27 visual_prompt]: 	Test 300/512. loss: 1.488, 0.2187 s / batch. (data: 3.56e-02)max mem: 17.22442 GB 
[09/16 20:35:47 visual_prompt]: 	Test 400/512. loss: 1.612, 0.1849 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 20:36:06 visual_prompt]: 	Test 500/512. loss: 2.203, 0.1910 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 20:36:11 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1952, average loss: 1.5947
[09/16 20:36:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.61	rocauc: 88.27	
[09/16 20:36:11 visual_prompt]: Best epoch 86: best metric: 1.000
[09/16 20:36:11 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 20:36:23 visual_prompt]: Epoch 87 / 100: avg data time: 1.89e-01, avg batch time: 0.5918, average train loss: 0.0002
[09/16 20:36:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1435, average loss: 0.0001
[09/16 20:36:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:36:52 visual_prompt]: 	Test 100/512. loss: 2.449, 0.2012 s / batch. (data: 1.80e-02)max mem: 17.22442 GB 
[09/16 20:37:11 visual_prompt]: 	Test 200/512. loss: 2.622, 0.1836 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 20:37:31 visual_prompt]: 	Test 300/512. loss: 2.096, 0.2052 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 20:37:50 visual_prompt]: 	Test 400/512. loss: 2.287, 0.1849 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 20:38:10 visual_prompt]: 	Test 500/512. loss: 3.931, 0.1847 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 20:38:15 visual_prompt]: Inference (test):avg data time: 8.54e-03, avg batch time: 0.1952, average loss: 2.4469
[09/16 20:38:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.84	rocauc: 83.91	
[09/16 20:38:15 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 20:38:27 visual_prompt]: Epoch 88 / 100: avg data time: 1.96e-01, avg batch time: 0.6023, average train loss: 0.0005
[09/16 20:38:33 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1434, average loss: 0.0000
[09/16 20:38:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:38:55 visual_prompt]: 	Test 100/512. loss: 2.208, 0.1835 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 20:39:15 visual_prompt]: 	Test 200/512. loss: 2.555, 0.1959 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 20:39:35 visual_prompt]: 	Test 300/512. loss: 2.043, 0.1956 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 20:39:54 visual_prompt]: 	Test 400/512. loss: 2.223, 0.1883 s / batch. (data: 4.21e-03)max mem: 17.22442 GB 
[09/16 20:40:14 visual_prompt]: 	Test 500/512. loss: 3.306, 0.2006 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 20:40:19 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1955, average loss: 2.2681
[09/16 20:40:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.83	rocauc: 86.92	
[09/16 20:40:19 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 20:40:30 visual_prompt]: Epoch 89 / 100: avg data time: 1.91e-01, avg batch time: 0.5946, average train loss: 0.0002
[09/16 20:40:36 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1434, average loss: 0.0231
[09/16 20:40:36 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:40:59 visual_prompt]: 	Test 100/512. loss: 2.616, 0.1841 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 20:41:19 visual_prompt]: 	Test 200/512. loss: 2.903, 0.1928 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 20:41:38 visual_prompt]: 	Test 300/512. loss: 2.646, 0.2169 s / batch. (data: 1.83e-02)max mem: 17.22442 GB 
[09/16 20:41:58 visual_prompt]: 	Test 400/512. loss: 2.555, 0.1887 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 20:42:17 visual_prompt]: 	Test 500/512. loss: 3.242, 0.1882 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 20:42:22 visual_prompt]: Inference (test):avg data time: 8.63e-03, avg batch time: 0.1960, average loss: 2.5583
[09/16 20:42:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.25	rocauc: 87.52	
[09/16 20:42:22 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 20:42:34 visual_prompt]: Epoch 90 / 100: avg data time: 1.95e-01, avg batch time: 0.5972, average train loss: 0.0281
[09/16 20:42:39 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1433, average loss: 0.0077
[09/16 20:42:39 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:43:02 visual_prompt]: 	Test 100/512. loss: 1.075, 0.1844 s / batch. (data: 2.24e-04)max mem: 17.22442 GB 
[09/16 20:43:21 visual_prompt]: 	Test 200/512. loss: 1.473, 0.1978 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 20:43:41 visual_prompt]: 	Test 300/512. loss: 0.957, 0.2077 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 20:44:01 visual_prompt]: 	Test 400/512. loss: 1.351, 0.1976 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 20:44:21 visual_prompt]: 	Test 500/512. loss: 1.329, 0.1989 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 20:44:26 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1964, average loss: 1.1500
[09/16 20:44:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.60	rocauc: 88.13	
[09/16 20:44:26 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 20:44:37 visual_prompt]: Epoch 91 / 100: avg data time: 1.85e-01, avg batch time: 0.5904, average train loss: 0.0169
[09/16 20:44:43 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1437, average loss: 0.0109
[09/16 20:44:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:45:06 visual_prompt]: 	Test 100/512. loss: 0.922, 0.1836 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 20:45:25 visual_prompt]: 	Test 200/512. loss: 1.366, 0.1966 s / batch. (data: 9.13e-05)max mem: 17.22442 GB 
[09/16 20:45:45 visual_prompt]: 	Test 300/512. loss: 0.973, 0.2046 s / batch. (data: 3.10e-04)max mem: 17.22442 GB 
[09/16 20:46:05 visual_prompt]: 	Test 400/512. loss: 1.237, 0.1839 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 20:46:24 visual_prompt]: 	Test 500/512. loss: 1.282, 0.1845 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 20:46:29 visual_prompt]: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1950, average loss: 1.1041
[09/16 20:46:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.14	rocauc: 89.32	
[09/16 20:46:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 20:46:40 visual_prompt]: Epoch 92 / 100: avg data time: 1.92e-01, avg batch time: 0.5977, average train loss: 0.0034
[09/16 20:46:46 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1435, average loss: 0.0076
[09/16 20:46:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.99	
[09/16 20:47:09 visual_prompt]: 	Test 100/512. loss: 1.159, 0.2088 s / batch. (data: 2.57e-02)max mem: 17.22442 GB 
[09/16 20:47:29 visual_prompt]: 	Test 200/512. loss: 1.489, 0.1984 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 20:47:48 visual_prompt]: 	Test 300/512. loss: 1.213, 0.2146 s / batch. (data: 1.14e-02)max mem: 17.22442 GB 
[09/16 20:48:08 visual_prompt]: 	Test 400/512. loss: 1.354, 0.1836 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 20:48:27 visual_prompt]: 	Test 500/512. loss: 1.764, 0.2116 s / batch. (data: 1.32e-02)max mem: 17.22442 GB 
[09/16 20:48:32 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1949, average loss: 1.3657
[09/16 20:48:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.27	rocauc: 88.90	
[09/16 20:48:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 20:48:44 visual_prompt]: Epoch 93 / 100: avg data time: 1.93e-01, avg batch time: 0.5967, average train loss: 0.0063
[09/16 20:48:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1437, average loss: 0.0162
[09/16 20:48:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 20:49:13 visual_prompt]: 	Test 100/512. loss: 1.362, 0.1991 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 20:49:32 visual_prompt]: 	Test 200/512. loss: 2.045, 0.1978 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 20:49:52 visual_prompt]: 	Test 300/512. loss: 1.413, 0.1993 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 20:50:11 visual_prompt]: 	Test 400/512. loss: 1.540, 0.1996 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 20:50:31 visual_prompt]: 	Test 500/512. loss: 1.735, 0.1969 s / batch. (data: 1.33e-02)max mem: 17.22442 GB 
[09/16 20:50:36 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1952, average loss: 1.5022
[09/16 20:50:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.57	rocauc: 88.27	
[09/16 20:50:36 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 20:50:48 visual_prompt]: Epoch 94 / 100: avg data time: 1.96e-01, avg batch time: 0.5996, average train loss: 0.0019
[09/16 20:50:53 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1435, average loss: 0.0027
[09/16 20:50:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:51:16 visual_prompt]: 	Test 100/512. loss: 1.333, 0.1893 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 20:51:36 visual_prompt]: 	Test 200/512. loss: 1.954, 0.1835 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 20:51:55 visual_prompt]: 	Test 300/512. loss: 1.358, 0.1852 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 20:52:15 visual_prompt]: 	Test 400/512. loss: 1.464, 0.1846 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 20:52:34 visual_prompt]: 	Test 500/512. loss: 1.690, 0.1855 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 20:52:40 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1956, average loss: 1.4408
[09/16 20:52:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.90	rocauc: 88.00	
[09/16 20:52:40 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 20:52:52 visual_prompt]: Epoch 95 / 100: avg data time: 1.99e-01, avg batch time: 0.6038, average train loss: 0.0008
[09/16 20:52:57 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1436, average loss: 0.0018
[09/16 20:52:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:53:20 visual_prompt]: 	Test 100/512. loss: 1.352, 0.1845 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 20:53:39 visual_prompt]: 	Test 200/512. loss: 1.963, 0.2162 s / batch. (data: 3.31e-02)max mem: 17.22442 GB 
[09/16 20:53:59 visual_prompt]: 	Test 300/512. loss: 1.371, 0.2109 s / batch. (data: 2.76e-02)max mem: 17.22442 GB 
[09/16 20:54:18 visual_prompt]: 	Test 400/512. loss: 1.473, 0.1842 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 20:54:38 visual_prompt]: 	Test 500/512. loss: 1.689, 0.1962 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 20:54:43 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1954, average loss: 1.4507
[09/16 20:54:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.97	rocauc: 87.94	
[09/16 20:54:43 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 20:54:55 visual_prompt]: Epoch 96 / 100: avg data time: 1.88e-01, avg batch time: 0.5934, average train loss: 0.0012
[09/16 20:55:00 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1434, average loss: 0.0025
[09/16 20:55:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:55:23 visual_prompt]: 	Test 100/512. loss: 1.378, 0.1835 s / batch. (data: 3.60e-05)max mem: 17.22442 GB 
[09/16 20:55:43 visual_prompt]: 	Test 200/512. loss: 2.001, 0.2001 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 20:56:03 visual_prompt]: 	Test 300/512. loss: 1.396, 0.1842 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 20:56:22 visual_prompt]: 	Test 400/512. loss: 1.503, 0.1848 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 20:56:42 visual_prompt]: 	Test 500/512. loss: 1.720, 0.2125 s / batch. (data: 2.59e-02)max mem: 17.22442 GB 
[09/16 20:56:47 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1965, average loss: 1.4779
[09/16 20:56:47 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.94	rocauc: 88.01	
[09/16 20:56:47 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 20:56:59 visual_prompt]: Epoch 97 / 100: avg data time: 1.93e-01, avg batch time: 0.5973, average train loss: 0.0010
[09/16 20:57:04 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1437, average loss: 0.0020
[09/16 20:57:04 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:57:27 visual_prompt]: 	Test 100/512. loss: 1.388, 0.2004 s / batch. (data: 1.69e-02)max mem: 17.22442 GB 
[09/16 20:57:47 visual_prompt]: 	Test 200/512. loss: 2.012, 0.2110 s / batch. (data: 2.76e-02)max mem: 17.22442 GB 
[09/16 20:58:06 visual_prompt]: 	Test 300/512. loss: 1.405, 0.1957 s / batch. (data: 2.54e-04)max mem: 17.22442 GB 
[09/16 20:58:26 visual_prompt]: 	Test 400/512. loss: 1.510, 0.1989 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 20:58:46 visual_prompt]: 	Test 500/512. loss: 1.734, 0.2083 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 20:58:51 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1958, average loss: 1.4860
[09/16 20:58:51 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.00	rocauc: 87.98	
[09/16 20:58:51 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 20:59:03 visual_prompt]: Epoch 98 / 100: avg data time: 2.05e-01, avg batch time: 0.6102, average train loss: 0.0009
[09/16 20:59:08 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1434, average loss: 0.0022
[09/16 20:59:08 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 20:59:31 visual_prompt]: 	Test 100/512. loss: 1.397, 0.1976 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 20:59:50 visual_prompt]: 	Test 200/512. loss: 2.026, 0.1843 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/16 21:00:11 visual_prompt]: 	Test 300/512. loss: 1.414, 0.2084 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 21:00:30 visual_prompt]: 	Test 400/512. loss: 1.520, 0.2088 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 21:00:50 visual_prompt]: 	Test 500/512. loss: 1.743, 0.2003 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 21:00:55 visual_prompt]: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1956, average loss: 1.4962
[09/16 21:00:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.98	rocauc: 87.99	
[09/16 21:00:55 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 21:01:06 visual_prompt]: Epoch 99 / 100: avg data time: 1.90e-01, avg batch time: 0.5954, average train loss: 0.0013
[09/16 21:01:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1435, average loss: 0.0028
[09/16 21:01:12 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 21:01:35 visual_prompt]: 	Test 100/512. loss: 1.403, 0.1960 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/16 21:01:55 visual_prompt]: 	Test 200/512. loss: 2.037, 0.1894 s / batch. (data: 2.21e-04)max mem: 17.22442 GB 
[09/16 21:02:14 visual_prompt]: 	Test 300/512. loss: 1.418, 0.1843 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 21:02:35 visual_prompt]: 	Test 400/512. loss: 1.531, 0.1841 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:02:54 visual_prompt]: 	Test 500/512. loss: 1.746, 0.2031 s / batch. (data: 1.99e-02)max mem: 17.22442 GB 
[09/16 21:02:59 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1975, average loss: 1.5031
[09/16 21:02:59 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.89	rocauc: 88.02	
[09/16 21:02:59 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 21:03:11 visual_prompt]: Epoch 100 / 100: avg data time: 1.86e-01, avg batch time: 0.5890, average train loss: 0.0008
[09/16 21:03:17 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1432, average loss: 0.0028
[09/16 21:03:17 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 21:03:39 visual_prompt]: 	Test 100/512. loss: 1.404, 0.1848 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 21:03:59 visual_prompt]: 	Test 200/512. loss: 2.038, 0.2003 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 21:04:19 visual_prompt]: 	Test 300/512. loss: 1.419, 0.1994 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 21:04:38 visual_prompt]: 	Test 400/512. loss: 1.531, 0.1979 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 21:04:58 visual_prompt]: 	Test 500/512. loss: 1.747, 0.2148 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 21:05:03 visual_prompt]: Inference (test):avg data time: 8.59e-03, avg batch time: 0.1963, average loss: 1.5037
[09/16 21:05:03 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.90	rocauc: 88.02	
[09/16 21:05:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 21:05:27 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 21:05:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-patch_camelyon', 'DATA.NUMBER_CLASSES', '2', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/16 21:05:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 21:05:27 visual_prompt]: Training with config:
[09/16 21:05:27 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-patch_camelyon',
          'NO_TEST': False,
          'NUMBER_CLASSES': 2,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-patch_camelyon/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 21:05:27 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 21:05:27.886724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 21:05:28.076924: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 21:05:28.987678: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 21:05:28.987762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 21:05:28.987770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 21:05:30.985504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 21:05:30.985618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 21:05:30.985635: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 21:05:30 visual_prompt]: Constructing vtab-patch_camelyon dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
2023-09-16 21:05:31.090915: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 21:05:33 visual_prompt]: Number of images: 1000
[09/16 21:05:33 visual_prompt]: Number of classes: 2 / 2
[09/16 21:05:33 visual_prompt]: Loading validation data...
[09/16 21:05:33 visual_prompt]: Constructing vtab-patch_camelyon dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split validation[:200], from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 21:05:33 visual_prompt]: Number of images: 200
[09/16 21:05:33 visual_prompt]: Number of classes: 2 / 2
[09/16 21:05:33 visual_prompt]: Loading test data...
[09/16 21:05:33 visual_prompt]: Constructing vtab-patch_camelyon dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset patch_camelyon (visual_prompt_tuning/data_path/patch_camelyon/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset patch_camelyon for split test, from visual_prompt_tuning/data_path/patch_camelyon/2.0.0
[09/16 21:06:21 visual_prompt]: Number of images: 32768
[09/16 21:06:21 visual_prompt]: Number of classes: 2 / 2
[09/16 21:06:21 visual_prompt]: Constructing models...
[09/16 21:06:24 visual_prompt]: Total Parameters: 86721794	 Gradient Parameters: 923138
[09/16 21:06:24 visual_prompt]: tuned percent:1.064
[09/16 21:06:26 visual_prompt]: Device used for model: 0
[09/16 21:06:26 visual_prompt]: Setting up Evalutator...
[09/16 21:06:26 visual_prompt]: Setting up Trainer...
[09/16 21:06:26 visual_prompt]: 	Setting up the optimizer...
[09/16 21:06:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 21:06:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.95e-01, avg batch time: 0.6837, average train loss: 1.1538
[09/16 21:06:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1427, average loss: 1.2041
[09/16 21:06:45 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 61.69	
[09/16 21:07:08 visual_prompt]: 	Test 100/512. loss: 1.111, 0.1991 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 21:07:27 visual_prompt]: 	Test 200/512. loss: 1.121, 0.1837 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 21:07:47 visual_prompt]: 	Test 300/512. loss: 1.023, 0.1852 s / batch. (data: 4.32e-05)max mem: 17.22442 GB 
[09/16 21:08:06 visual_prompt]: 	Test 400/512. loss: 1.179, 0.2126 s / batch. (data: 3.72e-05)max mem: 17.22442 GB 
[09/16 21:08:26 visual_prompt]: 	Test 500/512. loss: 1.167, 0.1999 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 21:08:30 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1947, average loss: 1.1598
[09/16 21:08:30 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.97	rocauc: 60.28	
[09/16 21:08:30 visual_prompt]: Best epoch 1: best metric: 0.480
[09/16 21:08:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 21:08:43 visual_prompt]: Epoch 2 / 100: avg data time: 2.02e-01, avg batch time: 0.6059, average train loss: 9.3867
[09/16 21:08:48 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1434, average loss: 0.7455
[09/16 21:08:48 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 82.64	
[09/16 21:09:11 visual_prompt]: 	Test 100/512. loss: 0.735, 0.2115 s / batch. (data: 2.46e-02)max mem: 17.22442 GB 
[09/16 21:09:30 visual_prompt]: 	Test 200/512. loss: 0.740, 0.2000 s / batch. (data: 1.69e-02)max mem: 17.22442 GB 
[09/16 21:09:50 visual_prompt]: 	Test 300/512. loss: 0.670, 0.2110 s / batch. (data: 2.77e-02)max mem: 17.22442 GB 
[09/16 21:10:09 visual_prompt]: 	Test 400/512. loss: 0.764, 0.1962 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:10:29 visual_prompt]: 	Test 500/512. loss: 0.752, 0.2034 s / batch. (data: 1.96e-02)max mem: 17.22442 GB 
[09/16 21:10:34 visual_prompt]: Inference (test):avg data time: 9.15e-03, avg batch time: 0.1952, average loss: 0.7440
[09/16 21:10:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.97	rocauc: 74.64	
[09/16 21:10:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 21:10:45 visual_prompt]: Epoch 3 / 100: avg data time: 1.85e-01, avg batch time: 0.5926, average train loss: 1.3539
[09/16 21:10:51 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1434, average loss: 0.7741
[09/16 21:10:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 64.00	rocauc: 84.80	
[09/16 21:11:14 visual_prompt]: 	Test 100/512. loss: 0.753, 0.1994 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 21:11:33 visual_prompt]: 	Test 200/512. loss: 0.810, 0.1848 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 21:11:53 visual_prompt]: 	Test 300/512. loss: 0.657, 0.1995 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 21:12:12 visual_prompt]: 	Test 400/512. loss: 0.780, 0.1998 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 21:12:32 visual_prompt]: 	Test 500/512. loss: 0.761, 0.1995 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 21:12:37 visual_prompt]: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1942, average loss: 0.7874
[09/16 21:12:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 62.19	rocauc: 74.94	
[09/16 21:12:37 visual_prompt]: Best epoch 3: best metric: 0.640
[09/16 21:12:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 21:12:48 visual_prompt]: Epoch 4 / 100: avg data time: 1.74e-01, avg batch time: 0.5833, average train loss: 1.8060
[09/16 21:12:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1434, average loss: 0.6454
[09/16 21:12:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 65.50	rocauc: 86.44	
[09/16 21:13:16 visual_prompt]: 	Test 100/512. loss: 0.637, 0.1839 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 21:13:36 visual_prompt]: 	Test 200/512. loss: 0.709, 0.2075 s / batch. (data: 2.42e-02)max mem: 17.22442 GB 
[09/16 21:13:56 visual_prompt]: 	Test 300/512. loss: 0.604, 0.1839 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 21:14:15 visual_prompt]: 	Test 400/512. loss: 0.674, 0.1849 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 21:14:35 visual_prompt]: 	Test 500/512. loss: 0.651, 0.1849 s / batch. (data: 3.24e-05)max mem: 17.22442 GB 
[09/16 21:14:40 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1960, average loss: 0.6886
[09/16 21:14:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.26	rocauc: 77.49	
[09/16 21:14:40 visual_prompt]: Best epoch 4: best metric: 0.655
[09/16 21:14:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 21:14:52 visual_prompt]: Epoch 5 / 100: avg data time: 1.84e-01, avg batch time: 0.5878, average train loss: 2.1275
[09/16 21:14:58 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1434, average loss: 2.3030
[09/16 21:14:58 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 87.22	
[09/16 21:15:21 visual_prompt]: 	Test 100/512. loss: 2.138, 0.1999 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 21:15:40 visual_prompt]: 	Test 200/512. loss: 2.226, 0.1846 s / batch. (data: 9.35e-05)max mem: 17.22442 GB 
[09/16 21:16:00 visual_prompt]: 	Test 300/512. loss: 1.877, 0.1860 s / batch. (data: 1.06e-04)max mem: 17.22442 GB 
[09/16 21:16:19 visual_prompt]: 	Test 400/512. loss: 2.370, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:16:40 visual_prompt]: 	Test 500/512. loss: 2.267, 0.2000 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/16 21:16:45 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1963, average loss: 2.2391
[09/16 21:16:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 79.03	
[09/16 21:16:45 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 21:16:56 visual_prompt]: Epoch 6 / 100: avg data time: 1.83e-01, avg batch time: 0.5906, average train loss: 2.6438
[09/16 21:17:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1434, average loss: 5.6433
[09/16 21:17:02 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 88.23	
[09/16 21:17:25 visual_prompt]: 	Test 100/512. loss: 6.260, 0.1850 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 21:17:44 visual_prompt]: 	Test 200/512. loss: 6.285, 0.1839 s / batch. (data: 9.54e-05)max mem: 17.22442 GB 
[09/16 21:18:04 visual_prompt]: 	Test 300/512. loss: 6.997, 0.1974 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 21:18:23 visual_prompt]: 	Test 400/512. loss: 5.823, 0.1926 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:18:43 visual_prompt]: 	Test 500/512. loss: 5.963, 0.2045 s / batch. (data: 1.19e-02)max mem: 17.22442 GB 
[09/16 21:18:48 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1954, average loss: 6.1278
[09/16 21:18:48 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 78.92	
[09/16 21:18:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 21:18:59 visual_prompt]: Epoch 7 / 100: avg data time: 1.83e-01, avg batch time: 0.5871, average train loss: 2.2226
[09/16 21:19:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1433, average loss: 1.9720
[09/16 21:19:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 89.98	
[09/16 21:19:27 visual_prompt]: 	Test 100/512. loss: 1.780, 0.1874 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 21:19:47 visual_prompt]: 	Test 200/512. loss: 1.894, 0.1968 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 21:20:06 visual_prompt]: 	Test 300/512. loss: 1.615, 0.1991 s / batch. (data: 1.54e-02)max mem: 17.22442 GB 
[09/16 21:20:26 visual_prompt]: 	Test 400/512. loss: 2.011, 0.1997 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 21:20:46 visual_prompt]: 	Test 500/512. loss: 1.922, 0.1989 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 21:20:51 visual_prompt]: Inference (test):avg data time: 8.76e-03, avg batch time: 0.1952, average loss: 1.9191
[09/16 21:20:51 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.29	rocauc: 84.37	
[09/16 21:20:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 21:21:02 visual_prompt]: Epoch 8 / 100: avg data time: 2.03e-01, avg batch time: 0.6061, average train loss: 1.9486
[09/16 21:21:08 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1435, average loss: 0.5236
[09/16 21:21:08 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 66.00	rocauc: 89.39	
[09/16 21:21:31 visual_prompt]: 	Test 100/512. loss: 0.555, 0.1839 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:21:50 visual_prompt]: 	Test 200/512. loss: 0.586, 0.1846 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 21:22:10 visual_prompt]: 	Test 300/512. loss: 0.520, 0.1969 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 21:22:30 visual_prompt]: 	Test 400/512. loss: 0.608, 0.2287 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 21:22:50 visual_prompt]: 	Test 500/512. loss: 0.554, 0.1975 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 21:22:54 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1962, average loss: 0.5878
[09/16 21:22:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.84	rocauc: 82.01	
[09/16 21:22:55 visual_prompt]: Best epoch 8: best metric: 0.660
[09/16 21:22:55 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 21:23:06 visual_prompt]: Epoch 9 / 100: avg data time: 1.89e-01, avg batch time: 0.5929, average train loss: 1.2243
[09/16 21:23:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1434, average loss: 0.6750
[09/16 21:23:12 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 64.00	rocauc: 90.51	
[09/16 21:23:34 visual_prompt]: 	Test 100/512. loss: 0.671, 0.1844 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 21:23:54 visual_prompt]: 	Test 200/512. loss: 0.731, 0.1998 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 21:24:13 visual_prompt]: 	Test 300/512. loss: 0.520, 0.1838 s / batch. (data: 3.08e-05)max mem: 17.22442 GB 
[09/16 21:24:33 visual_prompt]: 	Test 400/512. loss: 0.779, 0.1965 s / batch. (data: 3.24e-05)max mem: 17.22442 GB 
[09/16 21:24:53 visual_prompt]: 	Test 500/512. loss: 0.641, 0.1852 s / batch. (data: 8.65e-05)max mem: 17.22442 GB 
[09/16 21:24:58 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1960, average loss: 0.7313
[09/16 21:24:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.19	rocauc: 84.56	
[09/16 21:24:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 21:25:10 visual_prompt]: Epoch 10 / 100: avg data time: 1.82e-01, avg batch time: 0.5869, average train loss: 7.8662
[09/16 21:25:15 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1433, average loss: 19.4635
[09/16 21:25:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 80.33	
[09/16 21:25:38 visual_prompt]: 	Test 100/512. loss: 18.127, 0.1974 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 21:25:57 visual_prompt]: 	Test 200/512. loss: 18.133, 0.1995 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/16 21:26:17 visual_prompt]: 	Test 300/512. loss: 16.359, 0.1853 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 21:26:36 visual_prompt]: 	Test 400/512. loss: 19.886, 0.1851 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 21:26:56 visual_prompt]: 	Test 500/512. loss: 19.298, 0.2194 s / batch. (data: 3.60e-02)max mem: 17.22442 GB 
[09/16 21:27:01 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1947, average loss: 18.7269
[09/16 21:27:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 76.04	
[09/16 21:27:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 21:27:13 visual_prompt]: Epoch 11 / 100: avg data time: 1.91e-01, avg batch time: 0.6178, average train loss: 14.7858
[09/16 21:27:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1435, average loss: 11.4171
[09/16 21:27:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 84.95	
[09/16 21:27:41 visual_prompt]: 	Test 100/512. loss: 10.636, 0.1957 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 21:28:01 visual_prompt]: 	Test 200/512. loss: 10.658, 0.1835 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 21:28:20 visual_prompt]: 	Test 300/512. loss: 9.593, 0.1959 s / batch. (data: 3.86e-05)max mem: 17.22442 GB 
[09/16 21:28:40 visual_prompt]: 	Test 400/512. loss: 11.677, 0.1832 s / batch. (data: 2.84e-05)max mem: 17.22442 GB 
[09/16 21:29:00 visual_prompt]: 	Test 500/512. loss: 11.316, 0.1963 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:29:04 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1952, average loss: 10.9910
[09/16 21:29:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 76.47	
[09/16 21:29:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 21:29:16 visual_prompt]: Epoch 12 / 100: avg data time: 1.76e-01, avg batch time: 0.5844, average train loss: 8.0418
[09/16 21:29:22 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1433, average loss: 4.0606
[09/16 21:29:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 85.61	
[09/16 21:29:44 visual_prompt]: 	Test 100/512. loss: 4.450, 0.2015 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 21:30:04 visual_prompt]: 	Test 200/512. loss: 4.454, 0.1840 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 21:30:23 visual_prompt]: 	Test 300/512. loss: 4.918, 0.1845 s / batch. (data: 8.75e-05)max mem: 17.22442 GB 
[09/16 21:30:43 visual_prompt]: 	Test 400/512. loss: 4.109, 0.1999 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 21:31:02 visual_prompt]: 	Test 500/512. loss: 4.220, 0.1850 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:31:08 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1949, average loss: 4.3432
[09/16 21:31:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 73.81	
[09/16 21:31:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 21:31:19 visual_prompt]: Epoch 13 / 100: avg data time: 1.81e-01, avg batch time: 0.5882, average train loss: 10.0517
[09/16 21:31:25 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1435, average loss: 4.3097
[09/16 21:31:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 86.57	
[09/16 21:31:47 visual_prompt]: 	Test 100/512. loss: 4.771, 0.1940 s / batch. (data: 8.99e-05)max mem: 17.22442 GB 
[09/16 21:32:06 visual_prompt]: 	Test 200/512. loss: 4.774, 0.1956 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 21:32:26 visual_prompt]: 	Test 300/512. loss: 5.310, 0.2078 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 21:32:46 visual_prompt]: 	Test 400/512. loss: 4.441, 0.1963 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 21:33:05 visual_prompt]: 	Test 500/512. loss: 4.521, 0.2001 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 21:33:10 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1942, average loss: 4.6740
[09/16 21:33:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 76.62	
[09/16 21:33:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 21:33:22 visual_prompt]: Epoch 14 / 100: avg data time: 1.84e-01, avg batch time: 0.5893, average train loss: 6.1009
[09/16 21:33:27 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1434, average loss: 6.6505
[09/16 21:33:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 85.78	
[09/16 21:33:50 visual_prompt]: 	Test 100/512. loss: 6.098, 0.1841 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 21:34:10 visual_prompt]: 	Test 200/512. loss: 6.255, 0.1995 s / batch. (data: 1.65e-02)max mem: 17.22442 GB 
[09/16 21:34:29 visual_prompt]: 	Test 300/512. loss: 5.670, 0.1876 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 21:34:49 visual_prompt]: 	Test 400/512. loss: 6.763, 0.2008 s / batch. (data: 1.74e-02)max mem: 17.22442 GB 
[09/16 21:35:08 visual_prompt]: 	Test 500/512. loss: 6.597, 0.1981 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 21:35:13 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1947, average loss: 6.4406
[09/16 21:35:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 78.56	
[09/16 21:35:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 21:35:25 visual_prompt]: Epoch 15 / 100: avg data time: 1.72e-01, avg batch time: 0.5767, average train loss: 4.5154
[09/16 21:35:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1437, average loss: 3.3794
[09/16 21:35:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 59.50	rocauc: 87.04	
[09/16 21:35:53 visual_prompt]: 	Test 100/512. loss: 2.909, 0.1846 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 21:36:12 visual_prompt]: 	Test 200/512. loss: 3.312, 0.1846 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 21:36:32 visual_prompt]: 	Test 300/512. loss: 2.494, 0.1851 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:36:52 visual_prompt]: 	Test 400/512. loss: 3.046, 0.1849 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 21:37:11 visual_prompt]: 	Test 500/512. loss: 3.135, 0.1850 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 21:37:16 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1960, average loss: 3.2175
[09/16 21:37:16 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.61	rocauc: 78.49	
[09/16 21:37:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 21:37:28 visual_prompt]: Epoch 16 / 100: avg data time: 1.95e-01, avg batch time: 0.6015, average train loss: 2.0559
[09/16 21:37:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1584, average loss: 4.0162
[09/16 21:37:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 89.45	
[09/16 21:37:57 visual_prompt]: 	Test 100/512. loss: 3.545, 0.1986 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 21:38:16 visual_prompt]: 	Test 200/512. loss: 3.856, 0.1981 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 21:38:36 visual_prompt]: 	Test 300/512. loss: 3.123, 0.1952 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 21:38:55 visual_prompt]: 	Test 400/512. loss: 3.866, 0.1844 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 21:39:15 visual_prompt]: 	Test 500/512. loss: 3.799, 0.1845 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 21:39:19 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1948, average loss: 3.8614
[09/16 21:39:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 81.27	
[09/16 21:39:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 21:39:32 visual_prompt]: Epoch 17 / 100: avg data time: 1.93e-01, avg batch time: 0.6194, average train loss: 2.9886
[09/16 21:39:37 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1434, average loss: 0.9555
[09/16 21:39:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 62.00	rocauc: 89.90	
[09/16 21:40:00 visual_prompt]: 	Test 100/512. loss: 0.872, 0.1856 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 21:40:19 visual_prompt]: 	Test 200/512. loss: 0.997, 0.2089 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:40:39 visual_prompt]: 	Test 300/512. loss: 0.712, 0.1842 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 21:40:58 visual_prompt]: 	Test 400/512. loss: 1.033, 0.1965 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 21:41:18 visual_prompt]: 	Test 500/512. loss: 0.893, 0.1864 s / batch. (data: 8.99e-05)max mem: 17.22442 GB 
[09/16 21:41:22 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1947, average loss: 0.9910
[09/16 21:41:22 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 63.03	rocauc: 82.68	
[09/16 21:41:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 21:41:34 visual_prompt]: Epoch 18 / 100: avg data time: 1.86e-01, avg batch time: 0.5898, average train loss: 2.0407
[09/16 21:41:40 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1434, average loss: 1.6222
[09/16 21:41:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 55.00	rocauc: 90.12	
[09/16 21:42:03 visual_prompt]: 	Test 100/512. loss: 1.416, 0.2038 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 21:42:23 visual_prompt]: 	Test 200/512. loss: 1.669, 0.1987 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 21:42:42 visual_prompt]: 	Test 300/512. loss: 1.274, 0.2046 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 21:43:02 visual_prompt]: 	Test 400/512. loss: 1.714, 0.2109 s / batch. (data: 2.75e-02)max mem: 17.22442 GB 
[09/16 21:43:21 visual_prompt]: 	Test 500/512. loss: 1.594, 0.1888 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 21:43:26 visual_prompt]: Inference (test):avg data time: 8.63e-03, avg batch time: 0.1961, average loss: 1.6079
[09/16 21:43:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 56.19	rocauc: 83.87	
[09/16 21:43:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 21:43:38 visual_prompt]: Epoch 19 / 100: avg data time: 1.70e-01, avg batch time: 0.5771, average train loss: 2.0356
[09/16 21:43:43 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1433, average loss: 1.4523
[09/16 21:43:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 57.50	rocauc: 91.32	
[09/16 21:44:06 visual_prompt]: 	Test 100/512. loss: 1.283, 0.1956 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 21:44:26 visual_prompt]: 	Test 200/512. loss: 1.543, 0.2453 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 21:44:45 visual_prompt]: 	Test 300/512. loss: 1.141, 0.1971 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 21:45:05 visual_prompt]: 	Test 400/512. loss: 1.564, 0.2123 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 21:45:24 visual_prompt]: 	Test 500/512. loss: 1.392, 0.1847 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 21:45:29 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1948, average loss: 1.4790
[09/16 21:45:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 58.07	rocauc: 84.90	
[09/16 21:45:29 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 21:45:41 visual_prompt]: Epoch 20 / 100: avg data time: 1.98e-01, avg batch time: 0.6010, average train loss: 2.1609
[09/16 21:45:47 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1436, average loss: 5.2049
[09/16 21:45:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 48.00	rocauc: 91.74	
[09/16 21:46:09 visual_prompt]: 	Test 100/512. loss: 4.538, 0.1984 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 21:46:29 visual_prompt]: 	Test 200/512. loss: 5.091, 0.1840 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 21:46:48 visual_prompt]: 	Test 300/512. loss: 4.138, 0.1844 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 21:47:08 visual_prompt]: 	Test 400/512. loss: 5.248, 0.1964 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 21:47:27 visual_prompt]: 	Test 500/512. loss: 5.086, 0.2066 s / batch. (data: 2.28e-02)max mem: 17.22442 GB 
[09/16 21:47:32 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1943, average loss: 5.0606
[09/16 21:47:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 49.98	rocauc: 84.98	
[09/16 21:47:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 21:47:44 visual_prompt]: Epoch 21 / 100: avg data time: 1.93e-01, avg batch time: 0.5963, average train loss: 1.8163
[09/16 21:47:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1435, average loss: 0.6080
[09/16 21:47:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 76.00	rocauc: 90.49	
[09/16 21:48:13 visual_prompt]: 	Test 100/512. loss: 0.828, 0.1955 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:48:32 visual_prompt]: 	Test 200/512. loss: 0.922, 0.1838 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:48:52 visual_prompt]: 	Test 300/512. loss: 0.982, 0.1957 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:49:11 visual_prompt]: 	Test 400/512. loss: 0.955, 0.1847 s / batch. (data: 1.69e-04)max mem: 17.22442 GB 
[09/16 21:49:31 visual_prompt]: 	Test 500/512. loss: 0.864, 0.1847 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 21:49:36 visual_prompt]: Inference (test):avg data time: 8.51e-03, avg batch time: 0.1972, average loss: 0.9069
[09/16 21:49:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.25	rocauc: 84.67	
[09/16 21:49:36 visual_prompt]: Best epoch 21: best metric: 0.760
[09/16 21:49:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 21:49:48 visual_prompt]: Epoch 22 / 100: avg data time: 1.85e-01, avg batch time: 0.6109, average train loss: 1.8986
[09/16 21:49:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 1.5542
[09/16 21:49:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 91.49	
[09/16 21:50:16 visual_prompt]: 	Test 100/512. loss: 2.191, 0.2156 s / batch. (data: 4.05e-05)max mem: 17.22442 GB 
[09/16 21:50:36 visual_prompt]: 	Test 200/512. loss: 2.326, 0.1979 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 21:50:55 visual_prompt]: 	Test 300/512. loss: 2.490, 0.2044 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/16 21:51:15 visual_prompt]: 	Test 400/512. loss: 2.224, 0.2177 s / batch. (data: 3.38e-02)max mem: 17.22442 GB 
[09/16 21:51:35 visual_prompt]: 	Test 500/512. loss: 2.132, 0.1977 s / batch. (data: 1.40e-02)max mem: 17.22442 GB 
[09/16 21:51:39 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1947, average loss: 2.2731
[09/16 21:51:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 84.71	
[09/16 21:51:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 21:51:51 visual_prompt]: Epoch 23 / 100: avg data time: 1.83e-01, avg batch time: 0.5906, average train loss: 2.7658
[09/16 21:51:57 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1435, average loss: 1.3232
[09/16 21:51:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 65.50	rocauc: 91.61	
[09/16 21:52:19 visual_prompt]: 	Test 100/512. loss: 1.245, 0.1840 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 21:52:38 visual_prompt]: 	Test 200/512. loss: 1.560, 0.2055 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 21:52:58 visual_prompt]: 	Test 300/512. loss: 0.948, 0.1917 s / batch. (data: 1.62e-04)max mem: 17.22442 GB 
[09/16 21:53:18 visual_prompt]: 	Test 400/512. loss: 1.481, 0.1981 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 21:53:38 visual_prompt]: 	Test 500/512. loss: 1.184, 0.2014 s / batch. (data: 1.77e-02)max mem: 17.22442 GB 
[09/16 21:53:42 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1955, average loss: 1.4372
[09/16 21:53:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.03	rocauc: 85.74	
[09/16 21:53:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 21:53:54 visual_prompt]: Epoch 24 / 100: avg data time: 1.93e-01, avg batch time: 0.5967, average train loss: 1.6296
[09/16 21:54:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1432, average loss: 0.8776
[09/16 21:54:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 68.00	rocauc: 91.08	
[09/16 21:54:23 visual_prompt]: 	Test 100/512. loss: 1.220, 0.1838 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 21:54:42 visual_prompt]: 	Test 200/512. loss: 1.311, 0.1957 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:55:02 visual_prompt]: 	Test 300/512. loss: 1.295, 0.2109 s / batch. (data: 2.73e-02)max mem: 17.22442 GB 
[09/16 21:55:21 visual_prompt]: 	Test 400/512. loss: 1.244, 0.1846 s / batch. (data: 9.23e-05)max mem: 17.22442 GB 
[09/16 21:55:41 visual_prompt]: 	Test 500/512. loss: 1.243, 0.1839 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 21:55:46 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1957, average loss: 1.2332
[09/16 21:55:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 56.17	rocauc: 86.23	
[09/16 21:55:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 21:55:57 visual_prompt]: Epoch 25 / 100: avg data time: 1.92e-01, avg batch time: 0.5951, average train loss: 0.8998
[09/16 21:56:03 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1434, average loss: 1.0606
[09/16 21:56:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 58.50	rocauc: 91.62	
[09/16 21:56:26 visual_prompt]: 	Test 100/512. loss: 1.036, 0.1843 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 21:56:45 visual_prompt]: 	Test 200/512. loss: 1.211, 0.1961 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 21:57:04 visual_prompt]: 	Test 300/512. loss: 0.879, 0.2038 s / batch. (data: 2.01e-02)max mem: 17.22442 GB 
[09/16 21:57:24 visual_prompt]: 	Test 400/512. loss: 1.222, 0.1918 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 21:57:44 visual_prompt]: 	Test 500/512. loss: 1.070, 0.1957 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 21:57:49 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1948, average loss: 1.1378
[09/16 21:57:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.11	rocauc: 86.29	
[09/16 21:57:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 21:58:00 visual_prompt]: Epoch 26 / 100: avg data time: 1.87e-01, avg batch time: 0.5925, average train loss: 0.9882
[09/16 21:58:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1434, average loss: 0.4792
[09/16 21:58:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 93.08	
[09/16 21:58:28 visual_prompt]: 	Test 100/512. loss: 0.781, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 21:58:48 visual_prompt]: 	Test 200/512. loss: 0.770, 0.1847 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 21:59:07 visual_prompt]: 	Test 300/512. loss: 0.804, 0.1848 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 21:59:27 visual_prompt]: 	Test 400/512. loss: 0.857, 0.1847 s / batch. (data: 1.67e-04)max mem: 17.22442 GB 
[09/16 21:59:47 visual_prompt]: 	Test 500/512. loss: 0.746, 0.1973 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 21:59:51 visual_prompt]: Inference (test):avg data time: 8.49e-03, avg batch time: 0.1949, average loss: 0.7939
[09/16 21:59:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.19	rocauc: 87.68	
[09/16 21:59:52 visual_prompt]: Best epoch 26: best metric: 0.850
[09/16 21:59:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 22:00:03 visual_prompt]: Epoch 27 / 100: avg data time: 1.82e-01, avg batch time: 0.5882, average train loss: 0.8334
[09/16 22:00:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1444, average loss: 0.3983
[09/16 22:00:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 80.00	rocauc: 92.01	
[09/16 22:00:32 visual_prompt]: 	Test 100/512. loss: 0.460, 0.1961 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 22:00:51 visual_prompt]: 	Test 200/512. loss: 0.541, 0.1841 s / batch. (data: 1.60e-04)max mem: 17.22442 GB 
[09/16 22:01:11 visual_prompt]: 	Test 300/512. loss: 0.398, 0.1842 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 22:01:30 visual_prompt]: 	Test 400/512. loss: 0.564, 0.2210 s / batch. (data: 3.55e-05)max mem: 17.22442 GB 
[09/16 22:01:49 visual_prompt]: 	Test 500/512. loss: 0.452, 0.2035 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 22:01:54 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1943, average loss: 0.4943
[09/16 22:01:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.62	rocauc: 85.35	
[09/16 22:01:54 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 22:02:06 visual_prompt]: Epoch 28 / 100: avg data time: 1.84e-01, avg batch time: 0.5872, average train loss: 1.1293
[09/16 22:02:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1436, average loss: 0.9529
[09/16 22:02:12 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 94.17	
[09/16 22:02:34 visual_prompt]: 	Test 100/512. loss: 0.962, 0.1836 s / batch. (data: 9.73e-05)max mem: 17.22442 GB 
[09/16 22:02:53 visual_prompt]: 	Test 200/512. loss: 1.237, 0.2110 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 22:03:13 visual_prompt]: 	Test 300/512. loss: 0.671, 0.1970 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 22:03:32 visual_prompt]: 	Test 400/512. loss: 1.154, 0.1849 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/16 22:03:52 visual_prompt]: 	Test 500/512. loss: 0.936, 0.1986 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 22:03:57 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1943, average loss: 1.1131
[09/16 22:03:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 71.24	rocauc: 87.86	
[09/16 22:03:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 22:04:09 visual_prompt]: Epoch 29 / 100: avg data time: 1.91e-01, avg batch time: 0.5948, average train loss: 0.8518
[09/16 22:04:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1434, average loss: 0.6664
[09/16 22:04:14 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 73.50	rocauc: 92.66	
[09/16 22:04:37 visual_prompt]: 	Test 100/512. loss: 1.046, 0.2073 s / batch. (data: 2.45e-02)max mem: 17.22442 GB 
[09/16 22:04:57 visual_prompt]: 	Test 200/512. loss: 1.077, 0.1847 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 22:05:16 visual_prompt]: 	Test 300/512. loss: 1.060, 0.2101 s / batch. (data: 2.73e-02)max mem: 17.22442 GB 
[09/16 22:05:36 visual_prompt]: 	Test 400/512. loss: 0.972, 0.1846 s / batch. (data: 1.58e-04)max mem: 17.22442 GB 
[09/16 22:05:55 visual_prompt]: 	Test 500/512. loss: 0.971, 0.1962 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 22:06:00 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1961, average loss: 1.0330
[09/16 22:06:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.32	rocauc: 86.77	
[09/16 22:06:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 22:06:12 visual_prompt]: Epoch 30 / 100: avg data time: 1.84e-01, avg batch time: 0.5902, average train loss: 0.5814
[09/16 22:06:18 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1434, average loss: 0.4226
[09/16 22:06:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.50	rocauc: 93.60	
[09/16 22:06:40 visual_prompt]: 	Test 100/512. loss: 0.729, 0.2160 s / batch. (data: 3.27e-02)max mem: 17.22442 GB 
[09/16 22:07:00 visual_prompt]: 	Test 200/512. loss: 0.702, 0.1841 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 22:07:19 visual_prompt]: 	Test 300/512. loss: 0.643, 0.1993 s / batch. (data: 5.22e-03)max mem: 17.22442 GB 
[09/16 22:07:39 visual_prompt]: 	Test 400/512. loss: 0.605, 0.1851 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 22:07:58 visual_prompt]: 	Test 500/512. loss: 0.577, 0.1894 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 22:08:03 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1952, average loss: 0.6471
[09/16 22:08:03 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 67.98	rocauc: 87.53	
[09/16 22:08:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 22:08:15 visual_prompt]: Epoch 31 / 100: avg data time: 1.87e-01, avg batch time: 0.5894, average train loss: 0.5375
[09/16 22:08:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1434, average loss: 0.4889
[09/16 22:08:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 81.50	rocauc: 95.15	
[09/16 22:08:43 visual_prompt]: 	Test 100/512. loss: 0.612, 0.1833 s / batch. (data: 5.77e-05)max mem: 17.22442 GB 
[09/16 22:09:03 visual_prompt]: 	Test 200/512. loss: 0.647, 0.1987 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 22:09:22 visual_prompt]: 	Test 300/512. loss: 0.361, 0.1837 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 22:09:42 visual_prompt]: 	Test 400/512. loss: 0.540, 0.1960 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 22:10:02 visual_prompt]: 	Test 500/512. loss: 0.509, 0.1847 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 22:10:07 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1961, average loss: 0.6116
[09/16 22:10:07 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.15	rocauc: 88.87	
[09/16 22:10:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 22:10:19 visual_prompt]: Epoch 32 / 100: avg data time: 1.90e-01, avg batch time: 0.5928, average train loss: 0.8304
[09/16 22:10:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1438, average loss: 2.5886
[09/16 22:10:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 88.28	
[09/16 22:10:46 visual_prompt]: 	Test 100/512. loss: 3.558, 0.1918 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 22:11:06 visual_prompt]: 	Test 200/512. loss: 3.282, 0.2120 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 22:11:26 visual_prompt]: 	Test 300/512. loss: 3.703, 0.1983 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 22:11:45 visual_prompt]: 	Test 400/512. loss: 3.269, 0.1995 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 22:12:05 visual_prompt]: 	Test 500/512. loss: 3.279, 0.1846 s / batch. (data: 8.77e-05)max mem: 17.22442 GB 
[09/16 22:12:09 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1945, average loss: 3.2761
[09/16 22:12:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.02	rocauc: 77.59	
[09/16 22:12:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 22:12:21 visual_prompt]: Epoch 33 / 100: avg data time: 1.93e-01, avg batch time: 0.5993, average train loss: 1.5690
[09/16 22:12:27 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1432, average loss: 2.2917
[09/16 22:12:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 49.50	rocauc: 92.57	
[09/16 22:12:49 visual_prompt]: 	Test 100/512. loss: 2.157, 0.2057 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/16 22:13:09 visual_prompt]: 	Test 200/512. loss: 2.394, 0.1993 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 22:13:29 visual_prompt]: 	Test 300/512. loss: 1.900, 0.1853 s / batch. (data: 1.35e-04)max mem: 17.22442 GB 
[09/16 22:13:49 visual_prompt]: 	Test 400/512. loss: 2.515, 0.2105 s / batch. (data: 2.71e-02)max mem: 17.22442 GB 
[09/16 22:14:09 visual_prompt]: 	Test 500/512. loss: 2.274, 0.1959 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 22:14:14 visual_prompt]: Inference (test):avg data time: 8.61e-03, avg batch time: 0.1983, average loss: 2.3345
[09/16 22:14:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 51.33	rocauc: 86.74	
[09/16 22:14:14 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 22:14:25 visual_prompt]: Epoch 34 / 100: avg data time: 1.90e-01, avg batch time: 0.5941, average train loss: 1.3133
[09/16 22:14:31 visual_prompt]: Inference (val):avg data time: 4.63e-05, avg batch time: 0.1438, average loss: 1.9817
[09/16 22:14:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 52.00	rocauc: 89.13	
[09/16 22:14:53 visual_prompt]: 	Test 100/512. loss: 2.727, 0.1844 s / batch. (data: 3.36e-05)max mem: 17.22442 GB 
[09/16 22:15:13 visual_prompt]: 	Test 200/512. loss: 3.032, 0.1878 s / batch. (data: 1.65e-04)max mem: 17.22442 GB 
[09/16 22:15:32 visual_prompt]: 	Test 300/512. loss: 2.982, 0.2062 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 22:15:52 visual_prompt]: 	Test 400/512. loss: 2.585, 0.1969 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 22:16:12 visual_prompt]: 	Test 500/512. loss: 2.554, 0.2005 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 22:16:16 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1948, average loss: 2.7701
[09/16 22:16:16 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 50.18	rocauc: 81.72	
[09/16 22:16:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 22:16:29 visual_prompt]: Epoch 35 / 100: avg data time: 1.82e-01, avg batch time: 0.5900, average train loss: 0.8254
[09/16 22:16:34 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 0.7197
[09/16 22:16:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 72.00	rocauc: 92.28	
[09/16 22:16:57 visual_prompt]: 	Test 100/512. loss: 1.146, 0.1850 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 22:17:16 visual_prompt]: 	Test 200/512. loss: 1.141, 0.1873 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 22:17:35 visual_prompt]: 	Test 300/512. loss: 1.135, 0.1925 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 22:17:55 visual_prompt]: 	Test 400/512. loss: 1.057, 0.1992 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 22:18:15 visual_prompt]: 	Test 500/512. loss: 1.003, 0.2076 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 22:18:20 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1943, average loss: 1.0890
[09/16 22:18:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 59.85	rocauc: 85.63	
[09/16 22:18:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 22:18:31 visual_prompt]: Epoch 36 / 100: avg data time: 1.89e-01, avg batch time: 0.5934, average train loss: 0.6050
[09/16 22:18:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1434, average loss: 0.5156
[09/16 22:18:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 79.00	rocauc: 93.95	
[09/16 22:19:00 visual_prompt]: 	Test 100/512. loss: 0.996, 0.1970 s / batch. (data: 1.30e-02)max mem: 17.22442 GB 
[09/16 22:19:19 visual_prompt]: 	Test 200/512. loss: 0.937, 0.1853 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 22:19:39 visual_prompt]: 	Test 300/512. loss: 0.791, 0.1846 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 22:19:58 visual_prompt]: 	Test 400/512. loss: 0.757, 0.1849 s / batch. (data: 1.64e-04)max mem: 17.22442 GB 
[09/16 22:20:18 visual_prompt]: 	Test 500/512. loss: 0.736, 0.2015 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 22:20:23 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1956, average loss: 0.8727
[09/16 22:20:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 68.17	rocauc: 87.86	
[09/16 22:20:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 22:20:35 visual_prompt]: Epoch 37 / 100: avg data time: 1.93e-01, avg batch time: 0.5956, average train loss: 0.4488
[09/16 22:20:40 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1435, average loss: 0.4738
[09/16 22:20:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 77.00	rocauc: 95.07	
[09/16 22:21:03 visual_prompt]: 	Test 100/512. loss: 0.818, 0.1839 s / batch. (data: 1.63e-04)max mem: 17.22442 GB 
[09/16 22:21:23 visual_prompt]: 	Test 200/512. loss: 0.800, 0.1840 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 22:21:42 visual_prompt]: 	Test 300/512. loss: 0.743, 0.1982 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 22:22:02 visual_prompt]: 	Test 400/512. loss: 0.706, 0.1999 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 22:22:21 visual_prompt]: 	Test 500/512. loss: 0.678, 0.1843 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 22:22:26 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1952, average loss: 0.7509
[09/16 22:22:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 65.15	rocauc: 88.67	
[09/16 22:22:26 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 22:22:38 visual_prompt]: Epoch 38 / 100: avg data time: 1.89e-01, avg batch time: 0.5972, average train loss: 0.5486
[09/16 22:22:44 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1433, average loss: 0.3447
[09/16 22:22:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.50	rocauc: 94.86	
[09/16 22:23:06 visual_prompt]: 	Test 100/512. loss: 0.445, 0.1864 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 22:23:25 visual_prompt]: 	Test 200/512. loss: 0.467, 0.1845 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 22:23:45 visual_prompt]: 	Test 300/512. loss: 0.269, 0.1852 s / batch. (data: 1.03e-04)max mem: 17.22442 GB 
[09/16 22:24:04 visual_prompt]: 	Test 400/512. loss: 0.413, 0.1923 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 22:24:24 visual_prompt]: 	Test 500/512. loss: 0.339, 0.1961 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 22:24:29 visual_prompt]: Inference (test):avg data time: 6.90e-03, avg batch time: 0.1940, average loss: 0.4297
[09/16 22:24:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.76	rocauc: 89.50	
[09/16 22:24:29 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 22:24:41 visual_prompt]: Epoch 39 / 100: avg data time: 1.98e-01, avg batch time: 0.6013, average train loss: 0.4605
[09/16 22:24:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1433, average loss: 0.3157
[09/16 22:24:46 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 94.05	
[09/16 22:25:09 visual_prompt]: 	Test 100/512. loss: 0.510, 0.1847 s / batch. (data: 3.86e-05)max mem: 17.22442 GB 
[09/16 22:25:29 visual_prompt]: 	Test 200/512. loss: 0.499, 0.1980 s / batch. (data: 1.34e-02)max mem: 17.22442 GB 
[09/16 22:25:48 visual_prompt]: 	Test 300/512. loss: 0.346, 0.1904 s / batch. (data: 7.13e-03)max mem: 17.22442 GB 
[09/16 22:26:08 visual_prompt]: 	Test 400/512. loss: 0.439, 0.1858 s / batch. (data: 4.65e-05)max mem: 17.22442 GB 
[09/16 22:26:28 visual_prompt]: 	Test 500/512. loss: 0.373, 0.2045 s / batch. (data: 2.05e-02)max mem: 17.22442 GB 
[09/16 22:26:33 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1973, average loss: 0.4479
[09/16 22:26:33 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.69	rocauc: 87.59	
[09/16 22:26:33 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 22:26:45 visual_prompt]: Epoch 40 / 100: avg data time: 1.91e-01, avg batch time: 0.5947, average train loss: 0.4138
[09/16 22:26:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1436, average loss: 0.3663
[09/16 22:26:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.50	rocauc: 95.11	
[09/16 22:27:13 visual_prompt]: 	Test 100/512. loss: 0.716, 0.1892 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 22:27:33 visual_prompt]: 	Test 200/512. loss: 0.708, 0.1963 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 22:27:52 visual_prompt]: 	Test 300/512. loss: 0.564, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 22:28:12 visual_prompt]: 	Test 400/512. loss: 0.550, 0.1849 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 22:28:31 visual_prompt]: 	Test 500/512. loss: 0.589, 0.1981 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 22:28:36 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1941, average loss: 0.6451
[09/16 22:28:36 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 69.61	rocauc: 89.13	
[09/16 22:28:36 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 22:28:48 visual_prompt]: Epoch 41 / 100: avg data time: 1.92e-01, avg batch time: 0.5956, average train loss: 0.3868
[09/16 22:28:53 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1464, average loss: 0.5246
[09/16 22:28:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 74.00	rocauc: 95.89	
[09/16 22:29:16 visual_prompt]: 	Test 100/512. loss: 0.555, 0.1884 s / batch. (data: 4.57e-03)max mem: 17.22442 GB 
[09/16 22:29:36 visual_prompt]: 	Test 200/512. loss: 0.596, 0.1968 s / batch. (data: 1.35e-02)max mem: 17.22442 GB 
[09/16 22:29:56 visual_prompt]: 	Test 300/512. loss: 0.387, 0.1840 s / batch. (data: 9.37e-05)max mem: 17.22442 GB 
[09/16 22:30:15 visual_prompt]: 	Test 400/512. loss: 0.734, 0.1986 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/16 22:30:35 visual_prompt]: 	Test 500/512. loss: 0.526, 0.2078 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 22:30:40 visual_prompt]: Inference (test):avg data time: 8.95e-03, avg batch time: 0.1962, average loss: 0.5954
[09/16 22:30:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.70	rocauc: 89.87	
[09/16 22:30:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 22:30:52 visual_prompt]: Epoch 42 / 100: avg data time: 1.89e-01, avg batch time: 0.5923, average train loss: 0.6521
[09/16 22:30:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1434, average loss: 0.4351
[09/16 22:30:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 83.50	rocauc: 95.14	
[09/16 22:31:20 visual_prompt]: 	Test 100/512. loss: 0.923, 0.1842 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 22:31:40 visual_prompt]: 	Test 200/512. loss: 0.887, 0.1839 s / batch. (data: 1.19e-04)max mem: 17.22442 GB 
[09/16 22:32:00 visual_prompt]: 	Test 300/512. loss: 0.760, 0.1838 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 22:32:20 visual_prompt]: 	Test 400/512. loss: 0.798, 0.1962 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 22:32:39 visual_prompt]: 	Test 500/512. loss: 0.741, 0.1927 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 22:32:44 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1970, average loss: 0.8250
[09/16 22:32:44 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 70.39	rocauc: 87.36	
[09/16 22:32:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 22:32:56 visual_prompt]: Epoch 43 / 100: avg data time: 1.83e-01, avg batch time: 0.5881, average train loss: 0.8149
[09/16 22:33:01 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1434, average loss: 1.0035
[09/16 22:33:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 64.00	rocauc: 94.95	
[09/16 22:33:24 visual_prompt]: 	Test 100/512. loss: 0.971, 0.1980 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 22:33:44 visual_prompt]: 	Test 200/512. loss: 1.158, 0.1852 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 22:34:03 visual_prompt]: 	Test 300/512. loss: 0.706, 0.1868 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 22:34:23 visual_prompt]: 	Test 400/512. loss: 1.137, 0.1850 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 22:34:43 visual_prompt]: 	Test 500/512. loss: 0.956, 0.1994 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 22:34:48 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1966, average loss: 1.0678
[09/16 22:34:48 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 64.48	rocauc: 88.81	
[09/16 22:34:48 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 22:34:59 visual_prompt]: Epoch 44 / 100: avg data time: 1.96e-01, avg batch time: 0.6009, average train loss: 0.5766
[09/16 22:35:05 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1434, average loss: 0.3295
[09/16 22:35:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 94.86	
[09/16 22:35:28 visual_prompt]: 	Test 100/512. loss: 0.462, 0.1840 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 22:35:48 visual_prompt]: 	Test 200/512. loss: 0.510, 0.1841 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 22:36:07 visual_prompt]: 	Test 300/512. loss: 0.392, 0.1841 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 22:36:28 visual_prompt]: 	Test 400/512. loss: 0.417, 0.2041 s / batch. (data: 2.05e-02)max mem: 17.22442 GB 
[09/16 22:36:47 visual_prompt]: 	Test 500/512. loss: 0.434, 0.1995 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 22:36:52 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1971, average loss: 0.4614
[09/16 22:36:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.04	rocauc: 88.90	
[09/16 22:36:52 visual_prompt]: Best epoch 44: best metric: 0.885
[09/16 22:36:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 22:37:04 visual_prompt]: Epoch 45 / 100: avg data time: 1.95e-01, avg batch time: 0.5985, average train loss: 0.4787
[09/16 22:37:10 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1435, average loss: 0.7492
[09/16 22:37:10 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 69.50	rocauc: 95.34	
[09/16 22:37:33 visual_prompt]: 	Test 100/512. loss: 1.145, 0.2040 s / batch. (data: 2.12e-02)max mem: 17.22442 GB 
[09/16 22:37:52 visual_prompt]: 	Test 200/512. loss: 1.167, 0.2336 s / batch. (data: 1.13e-04)max mem: 17.22442 GB 
[09/16 22:38:12 visual_prompt]: 	Test 300/512. loss: 1.291, 0.1842 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/16 22:38:31 visual_prompt]: 	Test 400/512. loss: 0.992, 0.1905 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 22:38:50 visual_prompt]: 	Test 500/512. loss: 1.044, 0.1859 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/16 22:38:55 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1954, average loss: 1.1163
[09/16 22:38:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 57.42	rocauc: 89.93	
[09/16 22:38:55 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 22:39:07 visual_prompt]: Epoch 46 / 100: avg data time: 1.88e-01, avg batch time: 0.5917, average train loss: 0.5090
[09/16 22:39:13 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1434, average loss: 0.3119
[09/16 22:39:13 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.50	rocauc: 96.48	
[09/16 22:39:35 visual_prompt]: 	Test 100/512. loss: 0.430, 0.1992 s / batch. (data: 1.63e-02)max mem: 17.22442 GB 
[09/16 22:39:54 visual_prompt]: 	Test 200/512. loss: 0.483, 0.2048 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 22:40:14 visual_prompt]: 	Test 300/512. loss: 0.276, 0.1838 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 22:40:34 visual_prompt]: 	Test 400/512. loss: 0.405, 0.1846 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 22:40:53 visual_prompt]: 	Test 500/512. loss: 0.377, 0.1845 s / batch. (data: 1.00e-04)max mem: 17.22442 GB 
[09/16 22:40:58 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1948, average loss: 0.4263
[09/16 22:40:58 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.78	rocauc: 89.67	
[09/16 22:40:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 22:41:10 visual_prompt]: Epoch 47 / 100: avg data time: 1.87e-01, avg batch time: 0.5911, average train loss: 0.3531
[09/16 22:41:15 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1435, average loss: 0.2800
[09/16 22:41:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 88.50	rocauc: 96.96	
[09/16 22:41:38 visual_prompt]: 	Test 100/512. loss: 0.490, 0.1997 s / batch. (data: 1.12e-02)max mem: 17.22442 GB 
[09/16 22:41:57 visual_prompt]: 	Test 200/512. loss: 0.558, 0.1836 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 22:42:17 visual_prompt]: 	Test 300/512. loss: 0.291, 0.1961 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 22:42:37 visual_prompt]: 	Test 400/512. loss: 0.464, 0.1981 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 22:42:56 visual_prompt]: 	Test 500/512. loss: 0.332, 0.2118 s / batch. (data: 2.82e-02)max mem: 17.22442 GB 
[09/16 22:43:01 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1954, average loss: 0.4789
[09/16 22:43:01 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.78	rocauc: 88.86	
[09/16 22:43:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 22:43:14 visual_prompt]: Epoch 48 / 100: avg data time: 1.89e-01, avg batch time: 0.6013, average train loss: 0.3741
[09/16 22:43:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1435, average loss: 0.2746
[09/16 22:43:19 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.00	rocauc: 97.25	
[09/16 22:43:42 visual_prompt]: 	Test 100/512. loss: 0.596, 0.1983 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 22:44:01 visual_prompt]: 	Test 200/512. loss: 0.589, 0.2098 s / batch. (data: 2.65e-02)max mem: 17.22442 GB 
[09/16 22:44:21 visual_prompt]: 	Test 300/512. loss: 0.588, 0.2006 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 22:44:40 visual_prompt]: 	Test 400/512. loss: 0.563, 0.1840 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 22:45:00 visual_prompt]: 	Test 500/512. loss: 0.483, 0.2045 s / batch. (data: 2.09e-02)max mem: 17.22442 GB 
[09/16 22:45:05 visual_prompt]: Inference (test):avg data time: 8.64e-03, avg batch time: 0.1953, average loss: 0.5884
[09/16 22:45:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.48	rocauc: 89.61	
[09/16 22:45:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 22:45:16 visual_prompt]: Epoch 49 / 100: avg data time: 1.84e-01, avg batch time: 0.5897, average train loss: 0.3589
[09/16 22:45:22 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1479, average loss: 0.2202
[09/16 22:45:22 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 98.50	
[09/16 22:45:45 visual_prompt]: 	Test 100/512. loss: 0.641, 0.2186 s / batch. (data: 3.60e-02)max mem: 17.22442 GB 
[09/16 22:46:04 visual_prompt]: 	Test 200/512. loss: 0.682, 0.1980 s / batch. (data: 3.98e-05)max mem: 17.22442 GB 
[09/16 22:46:24 visual_prompt]: 	Test 300/512. loss: 0.524, 0.1909 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 22:46:43 visual_prompt]: 	Test 400/512. loss: 0.509, 0.1835 s / batch. (data: 9.94e-05)max mem: 17.22442 GB 
[09/16 22:47:03 visual_prompt]: 	Test 500/512. loss: 0.558, 0.1844 s / batch. (data: 8.32e-05)max mem: 17.22442 GB 
[09/16 22:47:08 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1945, average loss: 0.5860
[09/16 22:47:08 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.10	rocauc: 88.08	
[09/16 22:47:08 visual_prompt]: Best epoch 49: best metric: 0.905
[09/16 22:47:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 22:47:19 visual_prompt]: Epoch 50 / 100: avg data time: 1.99e-01, avg batch time: 0.6024, average train loss: 0.2919
[09/16 22:47:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1434, average loss: 0.2617
[09/16 22:47:25 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 86.00	rocauc: 98.29	
[09/16 22:47:48 visual_prompt]: 	Test 100/512. loss: 0.624, 0.1837 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 22:48:08 visual_prompt]: 	Test 200/512. loss: 0.783, 0.2000 s / batch. (data: 1.66e-02)max mem: 17.22442 GB 
[09/16 22:48:27 visual_prompt]: 	Test 300/512. loss: 0.625, 0.2082 s / batch. (data: 2.45e-02)max mem: 17.22442 GB 
[09/16 22:48:47 visual_prompt]: 	Test 400/512. loss: 0.693, 0.2018 s / batch. (data: 1.82e-02)max mem: 17.22442 GB 
[09/16 22:49:06 visual_prompt]: 	Test 500/512. loss: 0.644, 0.2110 s / batch. (data: 2.25e-02)max mem: 17.22442 GB 
[09/16 22:49:11 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1961, average loss: 0.6901
[09/16 22:49:11 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.72	rocauc: 90.25	
[09/16 22:49:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 22:49:23 visual_prompt]: Epoch 51 / 100: avg data time: 1.97e-01, avg batch time: 0.5998, average train loss: 0.4518
[09/16 22:49:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1433, average loss: 1.4233
[09/16 22:49:29 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 56.00	rocauc: 95.77	
[09/16 22:49:51 visual_prompt]: 	Test 100/512. loss: 1.336, 0.1844 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/16 22:50:10 visual_prompt]: 	Test 200/512. loss: 1.489, 0.1882 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/16 22:50:30 visual_prompt]: 	Test 300/512. loss: 0.902, 0.2077 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/16 22:50:50 visual_prompt]: 	Test 400/512. loss: 1.492, 0.1982 s / batch. (data: 1.50e-02)max mem: 17.22442 GB 
[09/16 22:51:09 visual_prompt]: 	Test 500/512. loss: 1.364, 0.2332 s / batch. (data: 1.73e-02)max mem: 17.22442 GB 
[09/16 22:51:14 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1953, average loss: 1.4216
[09/16 22:51:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.10	rocauc: 89.46	
[09/16 22:51:14 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 22:51:26 visual_prompt]: Epoch 52 / 100: avg data time: 1.90e-01, avg batch time: 0.5928, average train loss: 0.8172
[09/16 22:51:31 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1434, average loss: 0.9573
[09/16 22:51:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 65.50	rocauc: 96.73	
[09/16 22:51:54 visual_prompt]: 	Test 100/512. loss: 1.565, 0.1968 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 22:52:13 visual_prompt]: 	Test 200/512. loss: 1.544, 0.2070 s / batch. (data: 2.41e-02)max mem: 17.22442 GB 
[09/16 22:52:32 visual_prompt]: 	Test 300/512. loss: 1.504, 0.1890 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 22:52:52 visual_prompt]: 	Test 400/512. loss: 1.235, 0.1982 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 22:53:12 visual_prompt]: 	Test 500/512. loss: 1.368, 0.2117 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 22:53:17 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1943, average loss: 1.4408
[09/16 22:53:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 53.78	rocauc: 89.91	
[09/16 22:53:17 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 22:53:29 visual_prompt]: Epoch 53 / 100: avg data time: 1.90e-01, avg batch time: 0.5951, average train loss: 0.5439
[09/16 22:53:34 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1435, average loss: 0.3116
[09/16 22:53:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 96.30	
[09/16 22:53:57 visual_prompt]: 	Test 100/512. loss: 0.564, 0.2095 s / batch. (data: 2.62e-02)max mem: 17.22442 GB 
[09/16 22:54:16 visual_prompt]: 	Test 200/512. loss: 0.664, 0.1863 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 22:54:36 visual_prompt]: 	Test 300/512. loss: 0.420, 0.1845 s / batch. (data: 1.10e-04)max mem: 17.22442 GB 
[09/16 22:54:55 visual_prompt]: 	Test 400/512. loss: 0.525, 0.1909 s / batch. (data: 6.90e-03)max mem: 17.22442 GB 
[09/16 22:55:15 visual_prompt]: 	Test 500/512. loss: 0.490, 0.1849 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 22:55:20 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1948, average loss: 0.5183
[09/16 22:55:20 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.61	rocauc: 89.54	
[09/16 22:55:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 22:55:31 visual_prompt]: Epoch 54 / 100: avg data time: 1.74e-01, avg batch time: 0.5788, average train loss: 0.3999
[09/16 22:55:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1435, average loss: 0.2332
[09/16 22:55:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 98.43	
[09/16 22:56:00 visual_prompt]: 	Test 100/512. loss: 0.596, 0.1843 s / batch. (data: 1.69e-04)max mem: 17.22442 GB 
[09/16 22:56:19 visual_prompt]: 	Test 200/512. loss: 0.720, 0.1942 s / batch. (data: 1.03e-02)max mem: 17.22442 GB 
[09/16 22:56:39 visual_prompt]: 	Test 300/512. loss: 0.539, 0.1998 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 22:56:58 visual_prompt]: 	Test 400/512. loss: 0.561, 0.1981 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 22:57:18 visual_prompt]: 	Test 500/512. loss: 0.517, 0.1963 s / batch. (data: 1.20e-02)max mem: 17.22442 GB 
[09/16 22:57:23 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1961, average loss: 0.6094
[09/16 22:57:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.58	rocauc: 89.48	
[09/16 22:57:23 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 22:57:35 visual_prompt]: Epoch 55 / 100: avg data time: 1.93e-01, avg batch time: 0.5966, average train loss: 0.3068
[09/16 22:57:41 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1435, average loss: 0.1755
[09/16 22:57:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 94.00	rocauc: 98.88	
[09/16 22:58:04 visual_prompt]: 	Test 100/512. loss: 0.597, 0.1835 s / batch. (data: 1.21e-04)max mem: 17.22442 GB 
[09/16 22:58:23 visual_prompt]: 	Test 200/512. loss: 0.761, 0.1901 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 22:58:43 visual_prompt]: 	Test 300/512. loss: 0.611, 0.1982 s / batch. (data: 3.05e-05)max mem: 17.22442 GB 
[09/16 22:59:02 visual_prompt]: 	Test 400/512. loss: 0.534, 0.1845 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 22:59:22 visual_prompt]: 	Test 500/512. loss: 0.574, 0.1850 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/16 22:59:26 visual_prompt]: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1944, average loss: 0.6436
[09/16 22:59:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.85	rocauc: 90.91	
[09/16 22:59:26 visual_prompt]: Best epoch 55: best metric: 0.940
[09/16 22:59:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 22:59:38 visual_prompt]: Epoch 56 / 100: avg data time: 1.92e-01, avg batch time: 0.5955, average train loss: 0.2849
[09/16 22:59:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1433, average loss: 0.4220
[09/16 22:59:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 85.00	rocauc: 98.52	
[09/16 23:00:06 visual_prompt]: 	Test 100/512. loss: 0.691, 0.2054 s / batch. (data: 2.23e-02)max mem: 17.22442 GB 
[09/16 23:00:26 visual_prompt]: 	Test 200/512. loss: 0.792, 0.1850 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 23:00:45 visual_prompt]: 	Test 300/512. loss: 0.404, 0.1841 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 23:01:05 visual_prompt]: 	Test 400/512. loss: 0.793, 0.2083 s / batch. (data: 2.48e-02)max mem: 17.22442 GB 
[09/16 23:01:24 visual_prompt]: 	Test 500/512. loss: 0.705, 0.1994 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/16 23:01:29 visual_prompt]: Inference (test):avg data time: 8.49e-03, avg batch time: 0.1948, average loss: 0.7077
[09/16 23:01:30 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.76	rocauc: 89.45	
[09/16 23:01:30 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 23:01:41 visual_prompt]: Epoch 57 / 100: avg data time: 1.86e-01, avg batch time: 0.5911, average train loss: 0.2898
[09/16 23:01:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1434, average loss: 0.9123
[09/16 23:01:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 68.50	rocauc: 97.68	
[09/16 23:02:09 visual_prompt]: 	Test 100/512. loss: 1.712, 0.2036 s / batch. (data: 1.76e-02)max mem: 17.22442 GB 
[09/16 23:02:28 visual_prompt]: 	Test 200/512. loss: 1.911, 0.1839 s / batch. (data: 4.86e-05)max mem: 17.22442 GB 
[09/16 23:02:48 visual_prompt]: 	Test 300/512. loss: 1.700, 0.1836 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/16 23:03:08 visual_prompt]: 	Test 400/512. loss: 1.354, 0.1838 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 23:03:27 visual_prompt]: 	Test 500/512. loss: 1.547, 0.1869 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 23:03:32 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1948, average loss: 1.6776
[09/16 23:03:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 54.85	rocauc: 85.33	
[09/16 23:03:32 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 23:03:44 visual_prompt]: Epoch 58 / 100: avg data time: 1.83e-01, avg batch time: 0.5854, average train loss: 0.3915
[09/16 23:03:49 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1436, average loss: 0.2281
[09/16 23:03:49 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 97.39	
[09/16 23:04:12 visual_prompt]: 	Test 100/512. loss: 0.493, 0.1838 s / batch. (data: 1.11e-04)max mem: 17.22442 GB 
[09/16 23:04:31 visual_prompt]: 	Test 200/512. loss: 0.623, 0.1840 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 23:04:50 visual_prompt]: 	Test 300/512. loss: 0.500, 0.1915 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 23:05:10 visual_prompt]: 	Test 400/512. loss: 0.484, 0.1999 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 23:05:30 visual_prompt]: 	Test 500/512. loss: 0.556, 0.1843 s / batch. (data: 1.56e-04)max mem: 17.22442 GB 
[09/16 23:05:34 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1944, average loss: 0.5610
[09/16 23:05:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.04	rocauc: 89.47	
[09/16 23:05:34 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 23:05:46 visual_prompt]: Epoch 59 / 100: avg data time: 1.86e-01, avg batch time: 0.5902, average train loss: 0.2901
[09/16 23:05:52 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1436, average loss: 0.3551
[09/16 23:05:52 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 87.50	rocauc: 98.49	
[09/16 23:06:14 visual_prompt]: 	Test 100/512. loss: 0.544, 0.1960 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 23:06:34 visual_prompt]: 	Test 200/512. loss: 0.582, 0.1841 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/16 23:06:53 visual_prompt]: 	Test 300/512. loss: 0.389, 0.1977 s / batch. (data: 7.10e-05)max mem: 17.22442 GB 
[09/16 23:07:13 visual_prompt]: 	Test 400/512. loss: 0.713, 0.1850 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 23:07:32 visual_prompt]: 	Test 500/512. loss: 0.656, 0.1847 s / batch. (data: 1.70e-04)max mem: 17.22442 GB 
[09/16 23:07:37 visual_prompt]: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1943, average loss: 0.6042
[09/16 23:07:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.01	rocauc: 89.83	
[09/16 23:07:37 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 23:07:49 visual_prompt]: Epoch 60 / 100: avg data time: 1.82e-01, avg batch time: 0.5849, average train loss: 0.2319
[09/16 23:07:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1434, average loss: 0.7916
[09/16 23:07:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 73.00	rocauc: 99.33	
[09/16 23:08:17 visual_prompt]: 	Test 100/512. loss: 1.853, 0.1973 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 23:08:36 visual_prompt]: 	Test 200/512. loss: 2.012, 0.2142 s / batch. (data: 3.06e-02)max mem: 17.22442 GB 
[09/16 23:08:56 visual_prompt]: 	Test 300/512. loss: 1.891, 0.1988 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 23:09:15 visual_prompt]: 	Test 400/512. loss: 1.411, 0.1846 s / batch. (data: 3.79e-05)max mem: 17.22442 GB 
[09/16 23:09:35 visual_prompt]: 	Test 500/512. loss: 1.820, 0.1983 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 23:09:40 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1944, average loss: 1.8060
[09/16 23:09:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 60.17	rocauc: 88.19	
[09/16 23:09:40 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 23:09:52 visual_prompt]: Epoch 61 / 100: avg data time: 1.94e-01, avg batch time: 0.5960, average train loss: 0.4401
[09/16 23:09:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1432, average loss: 0.1151
[09/16 23:09:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.00	rocauc: 99.65	
[09/16 23:10:20 visual_prompt]: 	Test 100/512. loss: 0.482, 0.2095 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/16 23:10:39 visual_prompt]: 	Test 200/512. loss: 0.569, 0.2027 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 23:10:59 visual_prompt]: 	Test 300/512. loss: 0.335, 0.1872 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 23:11:18 visual_prompt]: 	Test 400/512. loss: 0.400, 0.1968 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 23:11:38 visual_prompt]: 	Test 500/512. loss: 0.373, 0.1846 s / batch. (data: 1.10e-04)max mem: 17.22442 GB 
[09/16 23:11:42 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1949, average loss: 0.4800
[09/16 23:11:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.61	rocauc: 89.04	
[09/16 23:11:43 visual_prompt]: Best epoch 61: best metric: 0.960
[09/16 23:11:43 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 23:11:54 visual_prompt]: Epoch 62 / 100: avg data time: 1.92e-01, avg batch time: 0.5957, average train loss: 0.2640
[09/16 23:12:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1435, average loss: 0.2597
[09/16 23:12:00 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.00	rocauc: 99.12	
[09/16 23:12:22 visual_prompt]: 	Test 100/512. loss: 0.404, 0.2253 s / batch. (data: 3.20e-02)max mem: 17.22442 GB 
[09/16 23:12:42 visual_prompt]: 	Test 200/512. loss: 0.493, 0.1976 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 23:13:02 visual_prompt]: 	Test 300/512. loss: 0.237, 0.2136 s / batch. (data: 1.35e-02)max mem: 17.22442 GB 
[09/16 23:13:21 visual_prompt]: 	Test 400/512. loss: 0.581, 0.1842 s / batch. (data: 1.65e-04)max mem: 17.22442 GB 
[09/16 23:13:41 visual_prompt]: 	Test 500/512. loss: 0.553, 0.1859 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/16 23:13:45 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1945, average loss: 0.5268
[09/16 23:13:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.27	rocauc: 91.06	
[09/16 23:13:45 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 23:13:57 visual_prompt]: Epoch 63 / 100: avg data time: 1.89e-01, avg batch time: 0.5938, average train loss: 0.2255
[09/16 23:14:03 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1436, average loss: 0.0877
[09/16 23:14:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.00	rocauc: 99.69	
[09/16 23:14:26 visual_prompt]: 	Test 100/512. loss: 0.506, 0.1857 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/16 23:14:45 visual_prompt]: 	Test 200/512. loss: 0.625, 0.2093 s / batch. (data: 1.37e-02)max mem: 17.22442 GB 
[09/16 23:15:05 visual_prompt]: 	Test 300/512. loss: 0.430, 0.1957 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/16 23:15:24 visual_prompt]: 	Test 400/512. loss: 0.543, 0.1849 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 23:15:44 visual_prompt]: 	Test 500/512. loss: 0.575, 0.1890 s / batch. (data: 1.51e-04)max mem: 17.22442 GB 
[09/16 23:15:49 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1952, average loss: 0.5703
[09/16 23:15:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.77	rocauc: 89.90	
[09/16 23:15:49 visual_prompt]: Best epoch 63: best metric: 0.970
[09/16 23:15:49 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 23:16:00 visual_prompt]: Epoch 64 / 100: avg data time: 1.92e-01, avg batch time: 0.5963, average train loss: 0.1975
[09/16 23:16:06 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1436, average loss: 0.2017
[09/16 23:16:06 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 90.50	rocauc: 99.58	
[09/16 23:16:28 visual_prompt]: 	Test 100/512. loss: 0.530, 0.2044 s / batch. (data: 1.70e-02)max mem: 17.22442 GB 
[09/16 23:16:48 visual_prompt]: 	Test 200/512. loss: 0.621, 0.1965 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 23:17:07 visual_prompt]: 	Test 300/512. loss: 0.391, 0.2097 s / batch. (data: 2.63e-02)max mem: 17.22442 GB 
[09/16 23:17:27 visual_prompt]: 	Test 400/512. loss: 0.633, 0.1847 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/16 23:17:47 visual_prompt]: 	Test 500/512. loss: 0.599, 0.1956 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 23:17:51 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1948, average loss: 0.5335
[09/16 23:17:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.46	rocauc: 90.07	
[09/16 23:17:52 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 23:18:03 visual_prompt]: Epoch 65 / 100: avg data time: 1.76e-01, avg batch time: 0.5847, average train loss: 0.3199
[09/16 23:18:09 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1470, average loss: 0.1532
[09/16 23:18:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 93.50	rocauc: 99.27	
[09/16 23:18:32 visual_prompt]: 	Test 100/512. loss: 0.789, 0.1843 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 23:18:51 visual_prompt]: 	Test 200/512. loss: 0.842, 0.2267 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/16 23:19:11 visual_prompt]: 	Test 300/512. loss: 0.598, 0.1996 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/16 23:19:30 visual_prompt]: 	Test 400/512. loss: 0.565, 0.1983 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/16 23:19:50 visual_prompt]: 	Test 500/512. loss: 0.636, 0.1847 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 23:19:55 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1948, average loss: 0.7378
[09/16 23:19:55 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 74.00	rocauc: 88.09	
[09/16 23:19:55 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 23:20:07 visual_prompt]: Epoch 66 / 100: avg data time: 1.80e-01, avg batch time: 0.5898, average train loss: 0.1462
[09/16 23:20:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1437, average loss: 0.0404
[09/16 23:20:13 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.98	
[09/16 23:20:36 visual_prompt]: 	Test 100/512. loss: 0.568, 0.1982 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 23:20:56 visual_prompt]: 	Test 200/512. loss: 0.898, 0.1844 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 23:21:15 visual_prompt]: 	Test 300/512. loss: 0.753, 0.1837 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 23:21:34 visual_prompt]: 	Test 400/512. loss: 0.738, 0.1994 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 23:21:54 visual_prompt]: 	Test 500/512. loss: 0.710, 0.1848 s / batch. (data: 1.25e-04)max mem: 17.22442 GB 
[09/16 23:21:59 visual_prompt]: Inference (test):avg data time: 7.10e-03, avg batch time: 0.1950, average loss: 0.8117
[09/16 23:21:59 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.30	rocauc: 89.39	
[09/16 23:21:59 visual_prompt]: Best epoch 66: best metric: 0.985
[09/16 23:21:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 23:22:11 visual_prompt]: Epoch 67 / 100: avg data time: 1.72e-01, avg batch time: 0.5815, average train loss: 0.1095
[09/16 23:22:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1435, average loss: 0.0315
[09/16 23:22:16 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 99.96	
[09/16 23:22:38 visual_prompt]: 	Test 100/512. loss: 0.643, 0.1918 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 23:22:58 visual_prompt]: 	Test 200/512. loss: 0.880, 0.1858 s / batch. (data: 1.22e-03)max mem: 17.22442 GB 
[09/16 23:23:18 visual_prompt]: 	Test 300/512. loss: 0.742, 0.2124 s / batch. (data: 2.85e-02)max mem: 17.22442 GB 
[09/16 23:23:38 visual_prompt]: 	Test 400/512. loss: 0.593, 0.1841 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 23:23:57 visual_prompt]: 	Test 500/512. loss: 0.857, 0.2114 s / batch. (data: 2.78e-02)max mem: 17.22442 GB 
[09/16 23:24:02 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1957, average loss: 0.8337
[09/16 23:24:02 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.90	rocauc: 89.38	
[09/16 23:24:02 visual_prompt]: Best epoch 67: best metric: 0.995
[09/16 23:24:02 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 23:24:14 visual_prompt]: Epoch 68 / 100: avg data time: 1.84e-01, avg batch time: 0.5888, average train loss: 0.1015
[09/16 23:24:20 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1435, average loss: 0.0372
[09/16 23:24:20 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.90	
[09/16 23:24:42 visual_prompt]: 	Test 100/512. loss: 0.544, 0.1853 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 23:25:02 visual_prompt]: 	Test 200/512. loss: 0.697, 0.2088 s / batch. (data: 2.59e-02)max mem: 17.22442 GB 
[09/16 23:25:21 visual_prompt]: 	Test 300/512. loss: 0.596, 0.1843 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/16 23:25:41 visual_prompt]: 	Test 400/512. loss: 0.672, 0.2157 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 23:26:00 visual_prompt]: 	Test 500/512. loss: 0.779, 0.1941 s / batch. (data: 1.53e-04)max mem: 17.22442 GB 
[09/16 23:26:05 visual_prompt]: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1943, average loss: 0.6742
[09/16 23:26:05 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.71	rocauc: 90.08	
[09/16 23:26:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 23:26:17 visual_prompt]: Epoch 69 / 100: avg data time: 1.89e-01, avg batch time: 0.6119, average train loss: 0.0757
[09/16 23:26:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1433, average loss: 0.0884
[09/16 23:26:23 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.73	
[09/16 23:26:45 visual_prompt]: 	Test 100/512. loss: 0.829, 0.1955 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 23:27:05 visual_prompt]: 	Test 200/512. loss: 0.869, 0.1843 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 23:27:25 visual_prompt]: 	Test 300/512. loss: 0.677, 0.1976 s / batch. (data: 1.42e-02)max mem: 17.22442 GB 
[09/16 23:27:44 visual_prompt]: 	Test 400/512. loss: 0.624, 0.2000 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 23:28:04 visual_prompt]: 	Test 500/512. loss: 0.942, 0.2102 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/16 23:28:09 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1952, average loss: 0.8229
[09/16 23:28:09 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.64	rocauc: 89.14	
[09/16 23:28:09 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 23:28:21 visual_prompt]: Epoch 70 / 100: avg data time: 1.88e-01, avg batch time: 0.5921, average train loss: 0.0720
[09/16 23:28:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1434, average loss: 0.0976
[09/16 23:28:26 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 95.50	rocauc: 99.83	
[09/16 23:28:49 visual_prompt]: 	Test 100/512. loss: 0.810, 0.2097 s / batch. (data: 4.03e-05)max mem: 17.22442 GB 
[09/16 23:29:09 visual_prompt]: 	Test 200/512. loss: 0.860, 0.1956 s / batch. (data: 1.21e-02)max mem: 17.22442 GB 
[09/16 23:29:29 visual_prompt]: 	Test 300/512. loss: 0.411, 0.2304 s / batch. (data: 4.73e-02)max mem: 17.22442 GB 
[09/16 23:29:48 visual_prompt]: 	Test 400/512. loss: 0.650, 0.1844 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 23:30:08 visual_prompt]: 	Test 500/512. loss: 0.975, 0.1970 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 23:30:13 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1961, average loss: 0.7488
[09/16 23:30:13 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.58	rocauc: 88.64	
[09/16 23:30:13 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 23:30:24 visual_prompt]: Epoch 71 / 100: avg data time: 1.94e-01, avg batch time: 0.5970, average train loss: 0.0750
[09/16 23:30:30 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1435, average loss: 0.0513
[09/16 23:30:30 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 99.91	
[09/16 23:30:52 visual_prompt]: 	Test 100/512. loss: 0.993, 0.1839 s / batch. (data: 1.07e-04)max mem: 17.22442 GB 
[09/16 23:31:12 visual_prompt]: 	Test 200/512. loss: 1.433, 0.1985 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/16 23:31:31 visual_prompt]: 	Test 300/512. loss: 0.770, 0.2113 s / batch. (data: 2.80e-02)max mem: 17.22442 GB 
[09/16 23:31:51 visual_prompt]: 	Test 400/512. loss: 0.528, 0.1851 s / batch. (data: 3.31e-05)max mem: 17.22442 GB 
[09/16 23:32:10 visual_prompt]: 	Test 500/512. loss: 1.280, 0.1847 s / batch. (data: 1.39e-04)max mem: 17.22442 GB 
[09/16 23:32:15 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1942, average loss: 1.0968
[09/16 23:32:15 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 73.79	rocauc: 86.39	
[09/16 23:32:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 23:32:27 visual_prompt]: Epoch 72 / 100: avg data time: 1.93e-01, avg batch time: 0.5952, average train loss: 0.0887
[09/16 23:32:33 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1434, average loss: 0.0420
[09/16 23:32:33 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 23:32:55 visual_prompt]: 	Test 100/512. loss: 0.920, 0.1958 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 23:33:15 visual_prompt]: 	Test 200/512. loss: 1.109, 0.1837 s / batch. (data: 9.04e-05)max mem: 17.22442 GB 
[09/16 23:33:35 visual_prompt]: 	Test 300/512. loss: 0.881, 0.1846 s / batch. (data: 1.57e-04)max mem: 17.22442 GB 
[09/16 23:33:54 visual_prompt]: 	Test 400/512. loss: 0.544, 0.2039 s / batch. (data: 2.01e-02)max mem: 17.22442 GB 
[09/16 23:34:14 visual_prompt]: 	Test 500/512. loss: 1.157, 0.1982 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/16 23:34:19 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1963, average loss: 1.0074
[09/16 23:34:19 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 72.84	rocauc: 86.71	
[09/16 23:34:19 visual_prompt]: Best epoch 72: best metric: 1.000
[09/16 23:34:19 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 23:34:31 visual_prompt]: Epoch 73 / 100: avg data time: 1.90e-01, avg batch time: 0.6232, average train loss: 0.0787
[09/16 23:34:37 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.0595
[09/16 23:34:37 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.00	rocauc: 99.95	
[09/16 23:35:00 visual_prompt]: 	Test 100/512. loss: 0.482, 0.2053 s / batch. (data: 2.20e-02)max mem: 17.22442 GB 
[09/16 23:35:20 visual_prompt]: 	Test 200/512. loss: 0.836, 0.1848 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/16 23:35:39 visual_prompt]: 	Test 300/512. loss: 0.471, 0.1898 s / batch. (data: 1.26e-04)max mem: 17.22442 GB 
[09/16 23:35:58 visual_prompt]: 	Test 400/512. loss: 0.772, 0.1988 s / batch. (data: 1.49e-02)max mem: 17.22442 GB 
[09/16 23:36:18 visual_prompt]: 	Test 500/512. loss: 0.842, 0.2137 s / batch. (data: 2.79e-02)max mem: 17.22442 GB 
[09/16 23:36:23 visual_prompt]: Inference (test):avg data time: 6.82e-03, avg batch time: 0.1954, average loss: 0.6957
[09/16 23:36:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.28	rocauc: 88.99	
[09/16 23:36:23 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 23:36:35 visual_prompt]: Epoch 74 / 100: avg data time: 1.89e-01, avg batch time: 0.5942, average train loss: 0.0624
[09/16 23:36:40 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1434, average loss: 0.0114
[09/16 23:36:40 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 23:37:03 visual_prompt]: 	Test 100/512. loss: 0.705, 0.1901 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 23:37:22 visual_prompt]: 	Test 200/512. loss: 0.850, 0.2104 s / batch. (data: 2.68e-02)max mem: 17.22442 GB 
[09/16 23:37:42 visual_prompt]: 	Test 300/512. loss: 0.541, 0.1895 s / batch. (data: 1.22e-04)max mem: 17.22442 GB 
[09/16 23:38:01 visual_prompt]: 	Test 400/512. loss: 0.809, 0.1843 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/16 23:38:21 visual_prompt]: 	Test 500/512. loss: 0.704, 0.1846 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 23:38:26 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1946, average loss: 0.7616
[09/16 23:38:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.80	rocauc: 89.73	
[09/16 23:38:26 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 23:38:37 visual_prompt]: Epoch 75 / 100: avg data time: 1.87e-01, avg batch time: 0.5928, average train loss: 0.0635
[09/16 23:38:43 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1436, average loss: 0.2581
[09/16 23:38:43 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 92.50	rocauc: 99.75	
[09/16 23:39:06 visual_prompt]: 	Test 100/512. loss: 0.881, 0.2271 s / batch. (data: 1.18e-04)max mem: 17.22442 GB 
[09/16 23:39:26 visual_prompt]: 	Test 200/512. loss: 1.206, 0.2549 s / batch. (data: 1.45e-02)max mem: 17.22442 GB 
[09/16 23:39:45 visual_prompt]: 	Test 300/512. loss: 0.639, 0.1851 s / batch. (data: 1.40e-04)max mem: 17.22442 GB 
[09/16 23:40:05 visual_prompt]: 	Test 400/512. loss: 1.258, 0.1860 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/16 23:40:25 visual_prompt]: 	Test 500/512. loss: 1.210, 0.1982 s / batch. (data: 1.43e-02)max mem: 17.22442 GB 
[09/16 23:40:29 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1957, average loss: 1.0262
[09/16 23:40:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.54	rocauc: 89.79	
[09/16 23:40:29 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 23:40:41 visual_prompt]: Epoch 76 / 100: avg data time: 1.87e-01, avg batch time: 0.5903, average train loss: 0.1540
[09/16 23:40:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1433, average loss: 0.0567
[09/16 23:40:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.50	rocauc: 99.84	
[09/16 23:41:09 visual_prompt]: 	Test 100/512. loss: 0.755, 0.1848 s / batch. (data: 1.45e-04)max mem: 17.22442 GB 
[09/16 23:41:29 visual_prompt]: 	Test 200/512. loss: 0.663, 0.1859 s / batch. (data: 1.33e-04)max mem: 17.22442 GB 
[09/16 23:41:48 visual_prompt]: 	Test 300/512. loss: 0.430, 0.1962 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 23:42:08 visual_prompt]: 	Test 400/512. loss: 0.585, 0.1843 s / batch. (data: 1.30e-04)max mem: 17.22442 GB 
[09/16 23:42:27 visual_prompt]: 	Test 500/512. loss: 0.606, 0.2122 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/16 23:42:32 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1947, average loss: 0.6177
[09/16 23:42:32 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 81.31	rocauc: 89.38	
[09/16 23:42:32 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 23:42:44 visual_prompt]: Epoch 77 / 100: avg data time: 1.92e-01, avg batch time: 0.5968, average train loss: 0.0755
[09/16 23:42:50 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1433, average loss: 0.0524
[09/16 23:42:50 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.00	rocauc: 99.94	
[09/16 23:43:12 visual_prompt]: 	Test 100/512. loss: 0.946, 0.1955 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/16 23:43:32 visual_prompt]: 	Test 200/512. loss: 0.909, 0.2085 s / batch. (data: 2.47e-02)max mem: 17.22442 GB 
[09/16 23:43:51 visual_prompt]: 	Test 300/512. loss: 0.635, 0.1849 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/16 23:44:11 visual_prompt]: 	Test 400/512. loss: 0.777, 0.2025 s / batch. (data: 1.92e-02)max mem: 17.22442 GB 
[09/16 23:44:30 visual_prompt]: 	Test 500/512. loss: 0.836, 0.1964 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/16 23:44:35 visual_prompt]: Inference (test):avg data time: 8.67e-03, avg batch time: 0.1949, average loss: 0.7708
[09/16 23:44:35 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.29	rocauc: 87.56	
[09/16 23:44:35 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 23:44:47 visual_prompt]: Epoch 78 / 100: avg data time: 1.90e-01, avg batch time: 0.6155, average train loss: 0.0190
[09/16 23:44:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1433, average loss: 0.1128
[09/16 23:44:53 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 97.00	rocauc: 99.92	
[09/16 23:45:15 visual_prompt]: 	Test 100/512. loss: 1.017, 0.1958 s / batch. (data: 1.32e-04)max mem: 17.22442 GB 
[09/16 23:45:35 visual_prompt]: 	Test 200/512. loss: 1.389, 0.1846 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/16 23:45:55 visual_prompt]: 	Test 300/512. loss: 0.865, 0.1849 s / batch. (data: 1.31e-04)max mem: 17.22442 GB 
[09/16 23:46:14 visual_prompt]: 	Test 400/512. loss: 0.985, 0.1998 s / batch. (data: 1.57e-02)max mem: 17.22442 GB 
[09/16 23:46:34 visual_prompt]: 	Test 500/512. loss: 1.161, 0.1880 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/16 23:46:39 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1946, average loss: 1.0219
[09/16 23:46:39 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.70	rocauc: 87.11	
[09/16 23:46:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 23:46:50 visual_prompt]: Epoch 79 / 100: avg data time: 1.84e-01, avg batch time: 0.5894, average train loss: 0.0958
[09/16 23:46:56 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1436, average loss: 0.1103
[09/16 23:46:56 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 96.00	rocauc: 100.00	
[09/16 23:47:19 visual_prompt]: 	Test 100/512. loss: 0.729, 0.1837 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 23:47:38 visual_prompt]: 	Test 200/512. loss: 0.831, 0.1847 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/16 23:47:58 visual_prompt]: 	Test 300/512. loss: 0.397, 0.1999 s / batch. (data: 1.59e-04)max mem: 17.22442 GB 
[09/16 23:48:17 visual_prompt]: 	Test 400/512. loss: 0.759, 0.2201 s / batch. (data: 2.54e-02)max mem: 17.22442 GB 
[09/16 23:48:37 visual_prompt]: 	Test 500/512. loss: 0.882, 0.1851 s / batch. (data: 1.55e-04)max mem: 17.22442 GB 
[09/16 23:48:42 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1953, average loss: 0.7730
[09/16 23:48:42 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.48	rocauc: 88.48	
[09/16 23:48:42 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 23:48:54 visual_prompt]: Epoch 80 / 100: avg data time: 1.88e-01, avg batch time: 0.5944, average train loss: 0.1403
[09/16 23:48:59 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1434, average loss: 0.0530
[09/16 23:48:59 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 98.50	rocauc: 100.00	
[09/16 23:49:22 visual_prompt]: 	Test 100/512. loss: 0.758, 0.1918 s / batch. (data: 1.15e-04)max mem: 17.22442 GB 
[09/16 23:49:41 visual_prompt]: 	Test 200/512. loss: 1.083, 0.1991 s / batch. (data: 1.20e-04)max mem: 17.22442 GB 
[09/16 23:50:01 visual_prompt]: 	Test 300/512. loss: 0.900, 0.1958 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/16 23:50:20 visual_prompt]: 	Test 400/512. loss: 0.753, 0.2177 s / batch. (data: 1.68e-04)max mem: 17.22442 GB 
[09/16 23:50:40 visual_prompt]: 	Test 500/512. loss: 1.319, 0.1993 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/16 23:50:45 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1952, average loss: 1.0211
[09/16 23:50:45 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 75.20	rocauc: 89.34	
[09/16 23:50:45 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 23:50:57 visual_prompt]: Epoch 81 / 100: avg data time: 1.90e-01, avg batch time: 0.6285, average train loss: 0.0357
[09/16 23:51:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1436, average loss: 0.0129
[09/16 23:51:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 23:51:25 visual_prompt]: 	Test 100/512. loss: 0.501, 0.1980 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/16 23:51:45 visual_prompt]: 	Test 200/512. loss: 1.092, 0.2030 s / batch. (data: 1.97e-02)max mem: 17.22442 GB 
[09/16 23:52:04 visual_prompt]: 	Test 300/512. loss: 0.725, 0.1947 s / batch. (data: 1.11e-02)max mem: 17.22442 GB 
[09/16 23:52:24 visual_prompt]: 	Test 400/512. loss: 0.556, 0.2112 s / batch. (data: 2.78e-02)max mem: 17.22442 GB 
[09/16 23:52:43 visual_prompt]: 	Test 500/512. loss: 1.095, 0.1918 s / batch. (data: 1.52e-04)max mem: 17.22442 GB 
[09/16 23:52:48 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1945, average loss: 0.8893
[09/16 23:52:48 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.98	rocauc: 87.58	
[09/16 23:52:48 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 23:53:00 visual_prompt]: Epoch 82 / 100: avg data time: 1.92e-01, avg batch time: 0.5946, average train loss: 0.0100
[09/16 23:53:05 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1459, average loss: 0.0021
[09/16 23:53:05 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 23:53:28 visual_prompt]: 	Test 100/512. loss: 0.685, 0.1892 s / batch. (data: 1.43e-04)max mem: 17.22442 GB 
[09/16 23:53:47 visual_prompt]: 	Test 200/512. loss: 1.105, 0.1842 s / batch. (data: 1.66e-04)max mem: 17.22442 GB 
[09/16 23:54:07 visual_prompt]: 	Test 300/512. loss: 0.666, 0.2076 s / batch. (data: 2.44e-02)max mem: 17.22442 GB 
[09/16 23:54:27 visual_prompt]: 	Test 400/512. loss: 1.038, 0.2184 s / batch. (data: 3.42e-02)max mem: 17.22442 GB 
[09/16 23:54:46 visual_prompt]: 	Test 500/512. loss: 1.198, 0.1964 s / batch. (data: 1.38e-04)max mem: 17.22442 GB 
[09/16 23:54:52 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1953, average loss: 1.0264
[09/16 23:54:52 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.71	rocauc: 88.68	
[09/16 23:54:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 23:55:03 visual_prompt]: Epoch 83 / 100: avg data time: 1.81e-01, avg batch time: 0.5855, average train loss: 0.0077
[09/16 23:55:09 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1436, average loss: 0.0122
[09/16 23:55:09 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 99.50	rocauc: 100.00	
[09/16 23:55:31 visual_prompt]: 	Test 100/512. loss: 0.945, 0.2005 s / batch. (data: 1.61e-02)max mem: 17.22442 GB 
[09/16 23:55:51 visual_prompt]: 	Test 200/512. loss: 1.314, 0.1960 s / batch. (data: 1.27e-02)max mem: 17.22442 GB 
[09/16 23:56:10 visual_prompt]: 	Test 300/512. loss: 0.779, 0.1987 s / batch. (data: 1.38e-02)max mem: 17.22442 GB 
[09/16 23:56:30 visual_prompt]: 	Test 400/512. loss: 1.066, 0.1995 s / batch. (data: 1.55e-02)max mem: 17.22442 GB 
[09/16 23:56:49 visual_prompt]: 	Test 500/512. loss: 1.439, 0.1979 s / batch. (data: 1.37e-02)max mem: 17.22442 GB 
[09/16 23:56:54 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1943, average loss: 1.2019
[09/16 23:56:54 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.58	rocauc: 86.76	
[09/16 23:56:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 23:57:06 visual_prompt]: Epoch 84 / 100: avg data time: 1.85e-01, avg batch time: 0.5925, average train loss: 0.0043
[09/16 23:57:11 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1435, average loss: 0.0004
[09/16 23:57:11 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 23:57:34 visual_prompt]: 	Test 100/512. loss: 0.953, 0.1832 s / batch. (data: 3.03e-05)max mem: 17.22442 GB 
[09/16 23:57:53 visual_prompt]: 	Test 200/512. loss: 1.520, 0.1885 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/16 23:58:13 visual_prompt]: 	Test 300/512. loss: 0.786, 0.1844 s / batch. (data: 1.42e-04)max mem: 17.22442 GB 
[09/16 23:58:33 visual_prompt]: 	Test 400/512. loss: 1.111, 0.1885 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/16 23:58:52 visual_prompt]: 	Test 500/512. loss: 1.531, 0.2120 s / batch. (data: 2.80e-02)max mem: 17.22442 GB 
[09/16 23:58:57 visual_prompt]: Inference (test):avg data time: 8.49e-03, avg batch time: 0.1951, average loss: 1.2852
[09/16 23:58:57 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 77.18	rocauc: 87.81	
[09/16 23:58:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 23:59:09 visual_prompt]: Epoch 85 / 100: avg data time: 1.86e-01, avg batch time: 0.5900, average train loss: 0.0025
[09/16 23:59:15 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1436, average loss: 0.0008
[09/16 23:59:15 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/16 23:59:37 visual_prompt]: 	Test 100/512. loss: 0.975, 0.2092 s / batch. (data: 2.60e-02)max mem: 17.22442 GB 
[09/16 23:59:57 visual_prompt]: 	Test 200/512. loss: 1.492, 0.1993 s / batch. (data: 1.27e-04)max mem: 17.22442 GB 
[09/17 00:00:16 visual_prompt]: 	Test 300/512. loss: 0.602, 0.2117 s / batch. (data: 2.84e-02)max mem: 17.22442 GB 
[09/17 00:00:36 visual_prompt]: 	Test 400/512. loss: 0.846, 0.1856 s / batch. (data: 1.44e-04)max mem: 17.22442 GB 
[09/17 00:00:55 visual_prompt]: 	Test 500/512. loss: 1.094, 0.1969 s / batch. (data: 9.51e-05)max mem: 17.22442 GB 
[09/17 00:01:00 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1946, average loss: 1.1055
[09/17 00:01:00 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 80.46	rocauc: 89.05	
[09/17 00:01:00 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 00:01:12 visual_prompt]: Epoch 86 / 100: avg data time: 1.92e-01, avg batch time: 0.5957, average train loss: 0.0037
[09/17 00:01:18 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1435, average loss: 0.0005
[09/17 00:01:18 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:01:40 visual_prompt]: 	Test 100/512. loss: 1.093, 0.1846 s / batch. (data: 1.67e-04)max mem: 17.22442 GB 
[09/17 00:02:00 visual_prompt]: 	Test 200/512. loss: 1.666, 0.2078 s / batch. (data: 2.43e-02)max mem: 17.22442 GB 
[09/17 00:02:19 visual_prompt]: 	Test 300/512. loss: 0.958, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22442 GB 
[09/17 00:02:39 visual_prompt]: 	Test 400/512. loss: 1.007, 0.2095 s / batch. (data: 2.61e-02)max mem: 17.22442 GB 
[09/17 00:02:58 visual_prompt]: 	Test 500/512. loss: 1.384, 0.2056 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/17 00:03:03 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1946, average loss: 1.3501
[09/17 00:03:04 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 76.48	rocauc: 87.51	
[09/17 00:03:04 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 00:03:15 visual_prompt]: Epoch 87 / 100: avg data time: 1.88e-01, avg batch time: 0.5901, average train loss: 0.0017
[09/17 00:03:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1433, average loss: 0.0005
[09/17 00:03:21 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:03:43 visual_prompt]: 	Test 100/512. loss: 0.965, 0.1848 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/17 00:04:03 visual_prompt]: 	Test 200/512. loss: 1.514, 0.2182 s / batch. (data: 3.52e-02)max mem: 17.22442 GB 
[09/17 00:04:22 visual_prompt]: 	Test 300/512. loss: 0.703, 0.1957 s / batch. (data: 1.23e-02)max mem: 17.22442 GB 
[09/17 00:04:42 visual_prompt]: 	Test 400/512. loss: 0.996, 0.1851 s / batch. (data: 9.13e-05)max mem: 17.22442 GB 
[09/17 00:05:02 visual_prompt]: 	Test 500/512. loss: 1.252, 0.1968 s / batch. (data: 1.31e-02)max mem: 17.22442 GB 
[09/17 00:05:06 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1945, average loss: 1.2028
[09/17 00:05:06 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.30	rocauc: 88.50	
[09/17 00:05:06 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 00:05:18 visual_prompt]: Epoch 88 / 100: avg data time: 1.92e-01, avg batch time: 0.5982, average train loss: 0.0007
[09/17 00:05:24 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1436, average loss: 0.0004
[09/17 00:05:24 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:05:46 visual_prompt]: 	Test 100/512. loss: 0.959, 0.2000 s / batch. (data: 1.66e-02)max mem: 17.22442 GB 
[09/17 00:06:06 visual_prompt]: 	Test 200/512. loss: 1.525, 0.1962 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/17 00:06:25 visual_prompt]: 	Test 300/512. loss: 0.711, 0.2002 s / batch. (data: 1.58e-02)max mem: 17.22442 GB 
[09/17 00:06:45 visual_prompt]: 	Test 400/512. loss: 1.024, 0.1885 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/17 00:07:05 visual_prompt]: 	Test 500/512. loss: 1.346, 0.2000 s / batch. (data: 1.59e-02)max mem: 17.22442 GB 
[09/17 00:07:10 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1952, average loss: 1.2303
[09/17 00:07:10 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.26	rocauc: 88.55	
[09/17 00:07:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 00:07:22 visual_prompt]: Epoch 89 / 100: avg data time: 1.97e-01, avg batch time: 0.6012, average train loss: 0.0005
[09/17 00:07:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1435, average loss: 0.0003
[09/17 00:07:27 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:07:50 visual_prompt]: 	Test 100/512. loss: 0.967, 0.2049 s / batch. (data: 1.13e-02)max mem: 17.22442 GB 
[09/17 00:08:09 visual_prompt]: 	Test 200/512. loss: 1.550, 0.1948 s / batch. (data: 9.75e-05)max mem: 17.22442 GB 
[09/17 00:08:29 visual_prompt]: 	Test 300/512. loss: 0.725, 0.1974 s / batch. (data: 1.28e-02)max mem: 17.22442 GB 
[09/17 00:08:49 visual_prompt]: 	Test 400/512. loss: 1.048, 0.1845 s / batch. (data: 9.99e-05)max mem: 17.22442 GB 
[09/17 00:09:09 visual_prompt]: 	Test 500/512. loss: 1.389, 0.1845 s / batch. (data: 1.81e-04)max mem: 17.22442 GB 
[09/17 00:09:14 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1957, average loss: 1.2532
[09/17 00:09:14 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.19	rocauc: 88.48	
[09/17 00:09:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 00:09:25 visual_prompt]: Epoch 90 / 100: avg data time: 1.88e-01, avg batch time: 0.5931, average train loss: 0.0006
[09/17 00:09:31 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1434, average loss: 0.0003
[09/17 00:09:31 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:09:54 visual_prompt]: 	Test 100/512. loss: 0.981, 0.1968 s / batch. (data: 1.39e-02)max mem: 17.22442 GB 
[09/17 00:10:14 visual_prompt]: 	Test 200/512. loss: 1.575, 0.1981 s / batch. (data: 1.48e-02)max mem: 17.22442 GB 
[09/17 00:10:33 visual_prompt]: 	Test 300/512. loss: 0.744, 0.1847 s / batch. (data: 1.28e-04)max mem: 17.22442 GB 
[09/17 00:10:53 visual_prompt]: 	Test 400/512. loss: 1.067, 0.1978 s / batch. (data: 1.46e-02)max mem: 17.22442 GB 
[09/17 00:11:12 visual_prompt]: 	Test 500/512. loss: 1.430, 0.1848 s / batch. (data: 1.17e-04)max mem: 17.22442 GB 
[09/17 00:11:17 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1960, average loss: 1.2774
[09/17 00:11:17 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 79.04	rocauc: 88.39	
[09/17 00:11:17 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 00:11:29 visual_prompt]: Epoch 91 / 100: avg data time: 1.92e-01, avg batch time: 0.5952, average train loss: 0.0005
[09/17 00:11:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1434, average loss: 0.0002
[09/17 00:11:34 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:11:57 visual_prompt]: 	Test 100/512. loss: 0.993, 0.1841 s / batch. (data: 1.36e-04)max mem: 17.22442 GB 
[09/17 00:12:16 visual_prompt]: 	Test 200/512. loss: 1.591, 0.1847 s / batch. (data: 1.86e-04)max mem: 17.22442 GB 
[09/17 00:12:36 visual_prompt]: 	Test 300/512. loss: 0.761, 0.1846 s / batch. (data: 1.47e-04)max mem: 17.22442 GB 
[09/17 00:12:56 visual_prompt]: 	Test 400/512. loss: 1.090, 0.1843 s / batch. (data: 1.70e-04)max mem: 17.22442 GB 
[09/17 00:13:15 visual_prompt]: 	Test 500/512. loss: 1.474, 0.1920 s / batch. (data: 9.92e-05)max mem: 17.22442 GB 
[09/17 00:13:20 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1956, average loss: 1.3010
[09/17 00:13:21 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.79	rocauc: 88.30	
[09/17 00:13:21 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 00:13:32 visual_prompt]: Epoch 92 / 100: avg data time: 1.79e-01, avg batch time: 0.5842, average train loss: 0.0005
[09/17 00:13:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1433, average loss: 0.0002
[09/17 00:13:38 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:14:00 visual_prompt]: 	Test 100/512. loss: 1.001, 0.2300 s / batch. (data: 4.69e-02)max mem: 17.22442 GB 
[09/17 00:14:20 visual_prompt]: 	Test 200/512. loss: 1.606, 0.1841 s / batch. (data: 1.54e-04)max mem: 17.22442 GB 
[09/17 00:14:39 visual_prompt]: 	Test 300/512. loss: 0.755, 0.1986 s / batch. (data: 1.53e-02)max mem: 17.22442 GB 
[09/17 00:14:59 visual_prompt]: 	Test 400/512. loss: 1.086, 0.1982 s / batch. (data: 1.36e-02)max mem: 17.22442 GB 
[09/17 00:15:18 visual_prompt]: 	Test 500/512. loss: 1.455, 0.1988 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/17 00:15:23 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1951, average loss: 1.2997
[09/17 00:15:23 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.93	rocauc: 88.30	
[09/17 00:15:23 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 00:15:35 visual_prompt]: Epoch 93 / 100: avg data time: 1.90e-01, avg batch time: 0.5929, average train loss: 0.0004
[09/17 00:15:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1435, average loss: 0.0002
[09/17 00:15:41 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:16:03 visual_prompt]: 	Test 100/512. loss: 1.008, 0.1838 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/17 00:16:23 visual_prompt]: 	Test 200/512. loss: 1.614, 0.1850 s / batch. (data: 3.02e-04)max mem: 17.22442 GB 
[09/17 00:16:42 visual_prompt]: 	Test 300/512. loss: 0.757, 0.1841 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/17 00:17:02 visual_prompt]: 	Test 400/512. loss: 1.089, 0.1847 s / batch. (data: 1.73e-04)max mem: 17.22442 GB 
[09/17 00:17:21 visual_prompt]: 	Test 500/512. loss: 1.457, 0.1844 s / batch. (data: 1.23e-04)max mem: 17.22442 GB 
[09/17 00:17:26 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1943, average loss: 1.3039
[09/17 00:17:26 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.97	rocauc: 88.29	
[09/17 00:17:26 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 00:17:38 visual_prompt]: Epoch 94 / 100: avg data time: 1.91e-01, avg batch time: 0.5947, average train loss: 0.0004
[09/17 00:17:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1437, average loss: 0.0002
[09/17 00:17:44 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:18:06 visual_prompt]: 	Test 100/512. loss: 1.011, 0.1955 s / batch. (data: 1.26e-02)max mem: 17.22442 GB 
[09/17 00:18:26 visual_prompt]: 	Test 200/512. loss: 1.619, 0.1980 s / batch. (data: 1.41e-02)max mem: 17.22442 GB 
[09/17 00:18:45 visual_prompt]: 	Test 300/512. loss: 0.758, 0.1991 s / batch. (data: 1.56e-02)max mem: 17.22442 GB 
[09/17 00:19:05 visual_prompt]: 	Test 400/512. loss: 1.091, 0.1844 s / batch. (data: 1.61e-04)max mem: 17.22442 GB 
[09/17 00:19:25 visual_prompt]: 	Test 500/512. loss: 1.459, 0.1986 s / batch. (data: 1.51e-02)max mem: 17.22442 GB 
[09/17 00:19:29 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1953, average loss: 1.3065
[09/17 00:19:29 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.97	rocauc: 88.27	
[09/17 00:19:29 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 00:19:41 visual_prompt]: Epoch 95 / 100: avg data time: 1.92e-01, avg batch time: 0.5963, average train loss: 0.0003
[09/17 00:19:47 visual_prompt]: Inference (val):avg data time: 8.00e-05, avg batch time: 0.1766, average loss: 0.0002
[09/17 00:19:47 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:20:09 visual_prompt]: 	Test 100/512. loss: 1.014, 0.1962 s / batch. (data: 1.29e-02)max mem: 17.22442 GB 
[09/17 00:20:30 visual_prompt]: 	Test 200/512. loss: 1.623, 0.1999 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/17 00:20:49 visual_prompt]: 	Test 300/512. loss: 0.760, 0.1887 s / batch. (data: 1.98e-04)max mem: 17.22442 GB 
[09/17 00:21:09 visual_prompt]: 	Test 400/512. loss: 1.092, 0.1926 s / batch. (data: 1.49e-04)max mem: 17.22442 GB 
[09/17 00:21:29 visual_prompt]: 	Test 500/512. loss: 1.460, 0.1849 s / batch. (data: 9.39e-05)max mem: 17.22442 GB 
[09/17 00:21:34 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1966, average loss: 1.3084
[09/17 00:21:34 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.97	rocauc: 88.27	
[09/17 00:21:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 00:21:45 visual_prompt]: Epoch 96 / 100: avg data time: 1.98e-01, avg batch time: 0.6021, average train loss: 0.0004
[09/17 00:21:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1434, average loss: 0.0002
[09/17 00:21:51 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:22:14 visual_prompt]: 	Test 100/512. loss: 1.016, 0.2119 s / batch. (data: 2.89e-02)max mem: 17.22442 GB 
[09/17 00:22:33 visual_prompt]: 	Test 200/512. loss: 1.625, 0.1930 s / batch. (data: 9.41e-03)max mem: 17.22442 GB 
[09/17 00:22:53 visual_prompt]: 	Test 300/512. loss: 0.761, 0.2017 s / batch. (data: 1.24e-04)max mem: 17.22442 GB 
[09/17 00:23:12 visual_prompt]: 	Test 400/512. loss: 1.093, 0.1848 s / batch. (data: 9.99e-05)max mem: 17.22442 GB 
[09/17 00:23:32 visual_prompt]: 	Test 500/512. loss: 1.463, 0.1856 s / batch. (data: 1.16e-04)max mem: 17.22442 GB 
[09/17 00:23:37 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1945, average loss: 1.3109
[09/17 00:23:37 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.95	rocauc: 88.25	
[09/17 00:23:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 00:23:49 visual_prompt]: Epoch 97 / 100: avg data time: 1.94e-01, avg batch time: 0.6186, average train loss: 0.0004
[09/17 00:23:54 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1434, average loss: 0.0002
[09/17 00:23:54 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:24:17 visual_prompt]: 	Test 100/512. loss: 1.018, 0.1977 s / batch. (data: 1.47e-02)max mem: 17.22442 GB 
[09/17 00:24:36 visual_prompt]: 	Test 200/512. loss: 1.628, 0.2005 s / batch. (data: 1.08e-04)max mem: 17.22442 GB 
[09/17 00:24:56 visual_prompt]: 	Test 300/512. loss: 0.762, 0.2114 s / batch. (data: 2.78e-02)max mem: 17.22442 GB 
[09/17 00:25:15 visual_prompt]: 	Test 400/512. loss: 1.094, 0.2030 s / batch. (data: 1.48e-04)max mem: 17.22442 GB 
[09/17 00:25:35 visual_prompt]: 	Test 500/512. loss: 1.464, 0.1965 s / batch. (data: 1.25e-02)max mem: 17.22442 GB 
[09/17 00:25:40 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1943, average loss: 1.3119
[09/17 00:25:40 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.96	rocauc: 88.25	
[09/17 00:25:40 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 00:25:52 visual_prompt]: Epoch 98 / 100: avg data time: 1.88e-01, avg batch time: 0.5922, average train loss: 0.0004
[09/17 00:25:57 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1432, average loss: 0.0002
[09/17 00:25:57 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:26:20 visual_prompt]: 	Test 100/512. loss: 1.019, 0.1839 s / batch. (data: 1.41e-04)max mem: 17.22442 GB 
[09/17 00:26:39 visual_prompt]: 	Test 200/512. loss: 1.629, 0.2147 s / batch. (data: 8.49e-03)max mem: 17.22442 GB 
[09/17 00:26:59 visual_prompt]: 	Test 300/512. loss: 0.762, 0.2101 s / batch. (data: 2.66e-02)max mem: 17.22442 GB 
[09/17 00:27:18 visual_prompt]: 	Test 400/512. loss: 1.094, 0.1842 s / batch. (data: 1.50e-04)max mem: 17.22442 GB 
[09/17 00:27:38 visual_prompt]: 	Test 500/512. loss: 1.465, 0.1848 s / batch. (data: 1.37e-04)max mem: 17.22442 GB 
[09/17 00:27:43 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1947, average loss: 1.3125
[09/17 00:27:43 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.96	rocauc: 88.25	
[09/17 00:27:43 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 00:27:55 visual_prompt]: Epoch 99 / 100: avg data time: 1.81e-01, avg batch time: 0.5928, average train loss: 0.0004
[09/17 00:28:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1435, average loss: 0.0002
[09/17 00:28:01 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:28:23 visual_prompt]: 	Test 100/512. loss: 1.019, 0.1983 s / batch. (data: 1.52e-02)max mem: 17.22442 GB 
[09/17 00:28:43 visual_prompt]: 	Test 200/512. loss: 1.629, 0.1846 s / batch. (data: 1.14e-04)max mem: 17.22442 GB 
[09/17 00:29:02 visual_prompt]: 	Test 300/512. loss: 0.762, 0.1968 s / batch. (data: 1.24e-02)max mem: 17.22442 GB 
[09/17 00:29:22 visual_prompt]: 	Test 400/512. loss: 1.095, 0.1846 s / batch. (data: 1.34e-04)max mem: 17.22442 GB 
[09/17 00:29:41 visual_prompt]: 	Test 500/512. loss: 1.464, 0.1848 s / batch. (data: 1.29e-04)max mem: 17.22442 GB 
[09/17 00:29:46 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1945, average loss: 1.3126
[09/17 00:29:46 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.96	rocauc: 88.25	
[09/17 00:29:46 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 00:29:58 visual_prompt]: Epoch 100 / 100: avg data time: 1.91e-01, avg batch time: 0.5955, average train loss: 0.0004
[09/17 00:30:03 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1435, average loss: 0.0002
[09/17 00:30:03 visual_prompt]: Classification results with val_vtab-patch_camelyon: top1: 100.00	rocauc: 100.00	
[09/17 00:30:26 visual_prompt]: 	Test 100/512. loss: 1.019, 0.1995 s / batch. (data: 1.62e-02)max mem: 17.22442 GB 
[09/17 00:30:45 visual_prompt]: 	Test 200/512. loss: 1.630, 0.2002 s / batch. (data: 1.60e-02)max mem: 17.22442 GB 
[09/17 00:31:05 visual_prompt]: 	Test 300/512. loss: 0.762, 0.1838 s / batch. (data: 1.02e-04)max mem: 17.22442 GB 
[09/17 00:31:24 visual_prompt]: 	Test 400/512. loss: 1.095, 0.2074 s / batch. (data: 2.33e-02)max mem: 17.22442 GB 
[09/17 00:31:44 visual_prompt]: 	Test 500/512. loss: 1.465, 0.1843 s / batch. (data: 1.46e-04)max mem: 17.22442 GB 
[09/17 00:31:49 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1946, average loss: 1.3126
[09/17 00:31:49 visual_prompt]: Classification results with test_vtab-patch_camelyon: top1: 78.98	rocauc: 88.25	
