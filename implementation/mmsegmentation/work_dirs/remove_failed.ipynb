{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-29T14:14:21.195689267Z",
     "start_time": "2023-11-29T14:14:21.094264536Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from mmengine.config import Config\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "def listdir(*rel_paths):\n",
    "    return os.listdir(os.path.join(current_dir, *rel_paths))\n",
    "\n",
    "def isdir(*rel_paths):\n",
    "    return os.path.isdir(os.path.join(current_dir, *rel_paths))\n",
    "\n",
    "def join(*rel_paths):\n",
    "    return os.path.join(current_dir, *rel_paths)\n",
    "\n",
    "def isfile(*rel_paths):\n",
    "    return os.path.isfile(join(*rel_paths))\n",
    "\n",
    "def rmdir(*rel_paths):\n",
    "    return shutil.rmtree(join(*rel_paths), ignore_errors=True)\n",
    "\n",
    "def get_log_runs():\n",
    "    work_dirs = [d for d in os.listdir() if isdir(d)]\n",
    "    print(f'work dirs: {len(work_dirs)}')\n",
    "    log_runs = [(work_dir, d) for work_dir in work_dirs for d in listdir(work_dir) if isdir(work_dir,d)]\n",
    "    print(f'log runs: {len(log_runs)}')\n",
    "    return log_runs\n",
    "\n",
    "def is_train_run(work_dir, d):\n",
    "    return isfile(work_dir, d, 'vis_data', f'{d}.json')\n",
    "\n",
    "def is_test_run(work_dir, d):\n",
    "    return isfile(work_dir, d, f'{d}.json')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T14:14:21.652316256Z",
     "start_time": "2023-11-29T14:14:21.649273783Z"
    }
   },
   "id": "8b906a003906edab"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work dirs: 4\n",
      "log runs: 14\n"
     ]
    }
   ],
   "source": [
    "log_runs = get_log_runs()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T14:14:22.213804880Z",
     "start_time": "2023-11-29T14:14:22.206260384Z"
    }
   },
   "id": "985b3d7bf8b3d945"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to start: 0\n"
     ]
    }
   ],
   "source": [
    "failed_to_start = [(work_dir,d) for work_dir,d in log_runs if (not isfile(join(work_dir,d,'vis_data', f'{d}.json')) and not isfile(join(work_dir, d, f'{d}.json')))]\n",
    "print(f'failed to start: {len(failed_to_start)}')\n",
    "for work_dir, d in failed_to_start:\n",
    "    rmdir(work_dir, d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T14:14:22.752200073Z",
     "start_time": "2023-11-29T14:14:22.744822563Z"
    }
   },
   "id": "e75feeba79703798"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work dirs: 4\n",
      "log runs: 10\n"
     ]
    }
   ],
   "source": [
    "log_runs = get_log_runs()\n",
    "# there are still more runs that may have failed to complete, we can identify them by looking at the contents of the json files (does the second last line iteration count match the max_iters in the config?)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T14:17:00.703676779Z",
     "start_time": "2023-11-29T14:17:00.699991923Z"
    }
   },
   "id": "d7d4ef6ff9e495b9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to complete: 0\n"
     ]
    }
   ],
   "source": [
    "train_runs = [(work_dir, d) for work_dir, d in log_runs if isfile(work_dir, d, 'vis_data', f'{d}.json')]\n",
    "\n",
    "def load_json(work_dir, d):\n",
    "    with open(join(work_dir, d, 'vis_data', f'{d}.json')) as f:\n",
    "        data = f.readlines()\n",
    "        data = [json.loads(line) for line in data]\n",
    "        return data\n",
    "\n",
    "def completed(work_dir, d):\n",
    "    data = load_json(work_dir, d)\n",
    "    iteration = data[-2].get('iter')\n",
    "    if iteration is None:\n",
    "        return False\n",
    "    config = Config.fromfile(join(work_dir, d, 'vis_data', 'config.py'))\n",
    "    return iteration == config.train_cfg.max_iters\n",
    "\n",
    "train_runs = [train_run for train_run in train_runs if is_train_run(*train_run)]\n",
    "\n",
    "failed_to_complete = [train_run for train_run in train_runs if not completed(*train_run)]\n",
    "print(f'failed to complete: {len(failed_to_complete)}')\n",
    "for failed_train_run in failed_to_complete:\n",
    "    rmdir(*failed_train_run)\n",
    "    # print(*failed_train_run)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T14:17:02.435509790Z",
     "start_time": "2023-11-29T14:17:02.263802840Z"
    }
   },
   "id": "14df96e68f46717"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6f8cf7490e78c277"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
