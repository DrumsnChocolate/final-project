[09/16 18:46:36][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/16 18:46:36][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 18:46:36][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-svhn', 'DATA.NUMBER_CLASSES', '10', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/16 18:46:36][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 18:46:36][INFO] visual_prompt:  108: Training with config:
[09/16 18:46:36][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'IMGSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-svhn',
          'NO_TEST': False,
          'NUMBER_CLASSES': 10,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-svhn/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 18:46:36][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/16 18:46:39][INFO] visual_prompt:   69: Constructing vtab-svhn dataset trainval...
[09/16 18:46:41][INFO] visual_prompt:   88: Number of images: 1000
[09/16 18:46:41][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 18:46:41][INFO] visual_prompt:   70: Loading validation data...
[09/16 18:46:41][INFO] visual_prompt:   69: Constructing vtab-svhn dataset val...
[09/16 18:46:41][INFO] visual_prompt:   88: Number of images: 200
[09/16 18:46:41][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 18:46:41][INFO] visual_prompt:   73: Loading test data...
[09/16 18:46:41][INFO] visual_prompt:   69: Constructing vtab-svhn dataset test...
[09/16 18:47:13][INFO] visual_prompt:   88: Number of images: 26032
[09/16 18:47:13][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 18:47:13][INFO] visual_prompt:  100: Constructing models...
[09/16 18:47:16][INFO] visual_prompt:   53: Total Parameters: 86727946	 Gradient Parameters: 929290
[09/16 18:47:16][INFO] visual_prompt:   54: tuned percent:1.072
[09/16 18:47:18][INFO] visual_prompt:   40: Device used for model: 0
[09/16 18:47:18][INFO] visual_prompt:  103: Setting up Evalutator...
[09/16 18:47:18][INFO] visual_prompt:  105: Setting up Trainer...
[09/16 18:47:18][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/16 18:47:18][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/16 18:47:30][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 1.59e-01, avg batch time: 0.6378, average train loss: 2.4125
[09/16 18:47:35][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1418, average loss: 2.3973
[09/16 18:47:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 55.50	
[09/16 18:47:57][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.419, 0.1812 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 18:48:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.453, 0.2055 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 18:48:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.412, 0.2035 s / batch. (data: 2.16e-02)max mem: 17.22449 GB 
[09/16 18:48:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.506, 0.1825 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 18:48:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1937, average loss: 2.4224
[09/16 18:48:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.56	top5: 58.21	
[09/16 18:48:58][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.230
[09/16 18:48:58][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/16 18:49:09][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 1.64e-01, avg batch time: 0.5636, average train loss: 2.8168
[09/16 18:49:14][INFO] visual_prompt:  324: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1427, average loss: 2.3250
[09/16 18:49:14][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.50	
[09/16 18:49:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.419, 0.2096 s / batch. (data: 2.72e-02)max mem: 17.22449 GB 
[09/16 18:49:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.415, 0.1964 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 18:50:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.316, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 18:50:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.374, 0.1828 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 18:50:38][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1952, average loss: 2.3358
[09/16 18:50:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.19	
[09/16 18:50:38][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/16 18:50:49][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 1.55e-01, avg batch time: 0.5560, average train loss: 2.3804
[09/16 18:50:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1424, average loss: 2.3755
[09/16 18:50:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.00	
[09/16 18:51:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.409, 0.2082 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 18:51:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.498, 0.1877 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 18:51:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.226, 0.1957 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 18:52:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.293, 0.1892 s / batch. (data: 2.79e-05)max mem: 17.22449 GB 
[09/16 18:52:16][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1938, average loss: 2.3438
[09/16 18:52:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 62.23	
[09/16 18:52:17][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/16 18:52:27][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.49e-01, avg batch time: 0.5516, average train loss: 2.3622
[09/16 18:52:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1426, average loss: 2.4732
[09/16 18:52:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 49.00	
[09/16 18:52:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.380, 0.1830 s / batch. (data: 1.63e-04)max mem: 17.22449 GB 
[09/16 18:53:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.452, 0.2142 s / batch. (data: 3.26e-02)max mem: 17.22449 GB 
[09/16 18:53:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.456, 0.1918 s / batch. (data: 6.77e-05)max mem: 17.22449 GB 
[09/16 18:53:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.422, 0.1826 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 18:53:56][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1942, average loss: 2.4542
[09/16 18:53:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 49.49	
[09/16 18:53:56][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/16 18:54:07][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.44e-01, avg batch time: 0.5467, average train loss: 2.5292
[09/16 18:54:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1424, average loss: 2.5351
[09/16 18:54:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 18:54:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.884, 0.2037 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 18:54:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.911, 0.1914 s / batch. (data: 9.50e-03)max mem: 17.22449 GB 
[09/16 18:55:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.442, 0.1915 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 18:55:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.549, 0.1829 s / batch. (data: 2.48e-05)max mem: 17.22449 GB 
[09/16 18:55:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1937, average loss: 2.5700
[09/16 18:55:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 63.51	
[09/16 18:55:35][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/16 18:55:45][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 1.65e-01, avg batch time: 0.5639, average train loss: 2.8409
[09/16 18:55:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1425, average loss: 2.5586
[09/16 18:55:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 62.50	
[09/16 18:56:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.006, 0.1820 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 18:56:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.977, 0.2067 s / batch. (data: 2.54e-02)max mem: 17.22449 GB 
[09/16 18:56:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.486, 0.1821 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 18:57:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.652, 0.1827 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 18:57:14][INFO] visual_prompt:  324: Inference (test):avg data time: 8.86e-03, avg batch time: 0.1959, average loss: 2.6478
[09/16 18:57:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.11	top5: 61.05	
[09/16 18:57:14][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/16 18:57:25][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.59e-01, avg batch time: 0.5632, average train loss: 3.5154
[09/16 18:57:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1425, average loss: 3.7652
[09/16 18:57:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 47.00	
[09/16 18:57:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.453, 0.1824 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 18:58:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.958, 0.1966 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 18:58:31][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.964, 0.2127 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 18:58:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.404, 0.1821 s / batch. (data: 4.46e-05)max mem: 17.22449 GB 
[09/16 18:58:53][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1942, average loss: 3.6445
[09/16 18:58:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 48.56	
[09/16 18:58:53][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/16 18:59:04][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.49e-01, avg batch time: 0.5508, average train loss: 3.9284
[09/16 18:59:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1423, average loss: 6.4322
[09/16 18:59:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 56.00	
[09/16 18:59:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.304, 0.1822 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 18:59:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.618, 0.1819 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:00:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.100, 0.1833 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 19:00:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 6.859, 0.1819 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 19:00:32][INFO] visual_prompt:  324: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1938, average loss: 6.7342
[09/16 19:00:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 51.33	
[09/16 19:00:32][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/16 19:00:42][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.51e-01, avg batch time: 0.5517, average train loss: 11.3125
[09/16 19:00:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1426, average loss: 13.0491
[09/16 19:00:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.00	
[09/16 19:01:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 12.798, 0.1824 s / batch. (data: 1.55e-04)max mem: 17.22449 GB 
[09/16 19:01:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 13.404, 0.1825 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 19:01:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.983, 0.1877 s / batch. (data: 5.20e-03)max mem: 17.22449 GB 
[09/16 19:02:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 11.605, 0.1827 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 19:02:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1934, average loss: 12.4620
[09/16 19:02:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 64.04	
[09/16 19:02:11][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/16 19:02:21][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.53e-01, avg batch time: 0.5555, average train loss: 24.6459
[09/16 19:02:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1422, average loss: 21.6044
[09/16 19:02:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 19:02:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 26.380, 0.1823 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 19:03:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 27.289, 0.1822 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 19:03:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 20.679, 0.1851 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 19:03:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 23.122, 0.1829 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 19:03:50][INFO] visual_prompt:  324: Inference (test):avg data time: 6.59e-03, avg batch time: 0.1949, average loss: 22.9406
[09/16 19:03:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 63.51	
[09/16 19:03:50][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[09/16 19:04:00][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.58e-01, avg batch time: 0.5581, average train loss: 18.4852
[09/16 19:04:05][INFO] visual_prompt:  324: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1425, average loss: 12.5475
[09/16 19:04:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 49.00	
[09/16 19:04:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 13.451, 0.2085 s / batch. (data: 2.69e-02)max mem: 17.22449 GB 
[09/16 19:04:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 13.293, 0.1825 s / batch. (data: 8.27e-05)max mem: 17.22449 GB 
[09/16 19:05:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.276, 0.1965 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 19:05:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 10.242, 0.1831 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 19:05:28][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1915, average loss: 12.4611
[09/16 19:05:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 52.05	
[09/16 19:05:28][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 19:05:39][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 1.61e-01, avg batch time: 0.5901, average train loss: 21.8724
[09/16 19:05:43][INFO] visual_prompt:  324: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1424, average loss: 12.2111
[09/16 19:05:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.50	
[09/16 19:06:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 17.213, 0.1981 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:06:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 17.794, 0.1952 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 19:06:45][INFO] visual_prompt:  314: 	Test 300/407. loss: 9.556, 0.1863 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 19:07:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 14.435, 0.1829 s / batch. (data: 3.48e-05)max mem: 17.22449 GB 
[09/16 19:07:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1944, average loss: 13.3470
[09/16 19:07:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 51.24	
[09/16 19:07:07][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 19:07:18][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.61e-01, avg batch time: 0.5639, average train loss: 21.5759
[09/16 19:07:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1424, average loss: 16.4765
[09/16 19:07:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.50	
[09/16 19:07:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 19.303, 0.2195 s / batch. (data: 2.51e-02)max mem: 17.22449 GB 
[09/16 19:08:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 18.197, 0.1945 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 19:08:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 17.585, 0.1836 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 19:08:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 16.899, 0.1824 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 19:08:45][INFO] visual_prompt:  324: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1918, average loss: 16.5578
[09/16 19:08:45][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 58.04	
[09/16 19:08:45][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 19:08:56][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 1.54e-01, avg batch time: 0.5543, average train loss: 18.2841
[09/16 19:09:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1446, average loss: 21.4449
[09/16 19:09:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.00	
[09/16 19:09:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 22.166, 0.2037 s / batch. (data: 1.92e-02)max mem: 17.22449 GB 
[09/16 19:09:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 25.188, 0.1828 s / batch. (data: 9.06e-05)max mem: 17.22449 GB 
[09/16 19:10:01][INFO] visual_prompt:  314: 	Test 300/407. loss: 18.686, 0.1969 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 19:10:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 20.557, 0.1823 s / batch. (data: 4.24e-05)max mem: 17.22449 GB 
[09/16 19:10:24][INFO] visual_prompt:  324: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1945, average loss: 21.4891
[09/16 19:10:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.13	
[09/16 19:10:24][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 19:10:35][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.44e-01, avg batch time: 0.5450, average train loss: 20.0974
[09/16 19:10:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1424, average loss: 20.1185
[09/16 19:10:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 51.50	
[09/16 19:11:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 22.374, 0.2008 s / batch. (data: 1.94e-02)max mem: 17.22449 GB 
[09/16 19:11:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 22.239, 0.1996 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 19:11:40][INFO] visual_prompt:  314: 	Test 300/407. loss: 20.423, 0.1966 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 19:12:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 22.250, 0.1824 s / batch. (data: 4.74e-05)max mem: 17.22449 GB 
[09/16 19:12:03][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1933, average loss: 21.1774
[09/16 19:12:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 47.44	
[09/16 19:12:03][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 19:12:14][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 1.56e-01, avg batch time: 0.5564, average train loss: 18.8822
[09/16 19:12:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1461, average loss: 16.9706
[09/16 19:12:18][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 64.50	
[09/16 19:12:40][INFO] visual_prompt:  314: 	Test 100/407. loss: 17.120, 0.1826 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 19:13:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 21.362, 0.1918 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 19:13:19][INFO] visual_prompt:  314: 	Test 300/407. loss: 14.702, 0.1892 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 19:13:38][INFO] visual_prompt:  314: 	Test 400/407. loss: 17.465, 0.1824 s / batch. (data: 3.00e-05)max mem: 17.22449 GB 
[09/16 19:13:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1930, average loss: 16.8413
[09/16 19:13:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 63.51	
[09/16 19:13:42][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 19:13:52][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.53e-01, avg batch time: 0.5591, average train loss: 16.1904
[09/16 19:13:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1426, average loss: 9.8088
[09/16 19:13:57][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 60.50	
[09/16 19:14:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 10.997, 0.2067 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 19:14:38][INFO] visual_prompt:  314: 	Test 200/407. loss: 12.404, 0.2157 s / batch. (data: 1.92e-02)max mem: 17.22449 GB 
[09/16 19:14:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.606, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 19:15:17][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.952, 0.1826 s / batch. (data: 3.43e-05)max mem: 17.22449 GB 
[09/16 19:15:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.09e-03, avg batch time: 0.1934, average loss: 9.7777
[09/16 19:15:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 57.10	
[09/16 19:15:21][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 19:15:31][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.57e-01, avg batch time: 0.5558, average train loss: 14.4130
[09/16 19:15:36][INFO] visual_prompt:  324: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1475, average loss: 13.5248
[09/16 19:15:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.50	
[09/16 19:15:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 14.783, 0.1955 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 19:16:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 15.813, 0.1847 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 19:16:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.150, 0.1944 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 19:16:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 12.799, 0.1821 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 19:16:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1937, average loss: 13.3371
[09/16 19:17:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 60.48	
[09/16 19:17:00][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 19:17:10][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 1.56e-01, avg batch time: 0.5578, average train loss: 12.4957
[09/16 19:17:15][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1425, average loss: 9.9539
[09/16 19:17:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.00	
[09/16 19:17:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 13.572, 0.1867 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 19:17:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 12.480, 0.2245 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 19:18:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.814, 0.1831 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 19:18:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 9.779, 0.1822 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 19:18:38][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1928, average loss: 10.1353
[09/16 19:18:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 60.32	
[09/16 19:18:38][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 19:18:49][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.62e-01, avg batch time: 0.5628, average train loss: 8.5313
[09/16 19:18:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1425, average loss: 8.6166
[09/16 19:18:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.00	
[09/16 19:19:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 9.974, 0.1825 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 19:19:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.182, 0.1981 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 19:19:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.859, 0.1832 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 19:20:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.609, 0.1826 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 19:20:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1939, average loss: 8.7647
[09/16 19:20:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.13	
[09/16 19:20:17][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 19:20:27][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.53e-01, avg batch time: 0.5549, average train loss: 7.7299
[09/16 19:20:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1426, average loss: 6.4770
[09/16 19:20:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.00	
[09/16 19:20:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.496, 0.1851 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 19:21:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 7.382, 0.1959 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 19:21:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.053, 0.1828 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 19:21:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 6.823, 0.1825 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 19:21:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1930, average loss: 6.7575
[09/16 19:21:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.23	
[09/16 19:21:55][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 19:22:06][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 1.56e-01, avg batch time: 0.5556, average train loss: 6.0891
[09/16 19:22:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1426, average loss: 6.0550
[09/16 19:22:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 63.50	
[09/16 19:22:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.128, 0.2011 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 19:22:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.822, 0.1923 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 19:23:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 5.227, 0.1919 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:23:30][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.626, 0.1827 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 19:23:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1928, average loss: 6.1566
[09/16 19:23:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 61.95	
[09/16 19:23:34][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 19:23:44][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.59e-01, avg batch time: 0.5599, average train loss: 5.7555
[09/16 19:23:49][INFO] visual_prompt:  324: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1425, average loss: 3.2392
[09/16 19:23:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 54.50	
[09/16 19:24:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.317, 0.1827 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 19:24:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.456, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:24:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.370, 0.1828 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 19:25:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.533, 0.1826 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 19:25:13][INFO] visual_prompt:  324: Inference (test):avg data time: 8.75e-03, avg batch time: 0.1948, average loss: 3.3429
[09/16 19:25:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.41	
[09/16 19:25:13][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 19:25:24][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 1.60e-01, avg batch time: 0.5618, average train loss: 2.6478
[09/16 19:25:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1424, average loss: 2.3804
[09/16 19:25:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 13.00	top5: 49.50	
[09/16 19:25:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.399, 0.1895 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 19:26:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.382, 0.2277 s / batch. (data: 4.63e-02)max mem: 17.22449 GB 
[09/16 19:26:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.340, 0.1970 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 19:26:48][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.284, 0.1820 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 19:26:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1929, average loss: 2.3817
[09/16 19:26:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 10.46	top5: 52.08	
[09/16 19:26:52][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 19:27:03][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 1.65e-01, avg batch time: 0.5648, average train loss: 2.5245
[09/16 19:27:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1423, average loss: 2.6493
[09/16 19:27:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.00	
[09/16 19:27:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.998, 0.1933 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 19:27:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.860, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 19:28:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.838, 0.2178 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 19:28:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.907, 0.1823 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 19:28:32][INFO] visual_prompt:  324: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1948, average loss: 2.7566
[09/16 19:28:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.74	
[09/16 19:28:32][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 19:28:42][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.51e-01, avg batch time: 0.5519, average train loss: 2.7049
[09/16 19:28:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1425, average loss: 2.5122
[09/16 19:28:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 45.00	
[09/16 19:29:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.427, 0.5925 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 19:29:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.427, 0.2079 s / batch. (data: 1.91e-02)max mem: 17.22449 GB 
[09/16 19:29:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.425, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 19:30:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.344, 0.1827 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 19:30:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1950, average loss: 2.4783
[09/16 19:30:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 47.19	
[09/16 19:30:11][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 19:30:22][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 1.46e-01, avg batch time: 0.5479, average train loss: 2.6415
[09/16 19:30:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1424, average loss: 2.5330
[09/16 19:30:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.50	
[09/16 19:30:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.902, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 19:31:08][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.881, 0.1827 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:31:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.515, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 19:31:47][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.685, 0.1829 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 19:31:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1939, average loss: 2.6023
[09/16 19:31:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.67	
[09/16 19:31:50][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 19:32:01][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 1.58e-01, avg batch time: 0.5589, average train loss: 2.5957
[09/16 19:32:05][INFO] visual_prompt:  324: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1425, average loss: 3.5700
[09/16 19:32:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 60.50	
[09/16 19:32:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.239, 0.1936 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 19:32:47][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.944, 0.2102 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 19:33:07][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.853, 0.2028 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:33:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.736, 0.1823 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 19:33:29][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1953, average loss: 3.7418
[09/16 19:33:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 56.14	
[09/16 19:33:30][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 19:33:40][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.59e-01, avg batch time: 0.5597, average train loss: 3.1754
[09/16 19:33:45][INFO] visual_prompt:  324: Inference (val):avg data time: 4.31e-05, avg batch time: 0.1432, average loss: 3.4217
[09/16 19:33:45][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 58.00	
[09/16 19:34:07][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.559, 0.1833 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 19:34:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.472, 0.1829 s / batch. (data: 8.70e-05)max mem: 17.22449 GB 
[09/16 19:34:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.616, 0.1954 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 19:35:06][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.559, 0.1822 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 19:35:09][INFO] visual_prompt:  324: Inference (test):avg data time: 8.47e-03, avg batch time: 0.1938, average loss: 3.5100
[09/16 19:35:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 54.56	
[09/16 19:35:09][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 19:35:20][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 1.54e-01, avg batch time: 0.5533, average train loss: 2.8575
[09/16 19:35:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1426, average loss: 2.3713
[09/16 19:35:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 32.00	top5: 66.50	
[09/16 19:35:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.397, 0.1827 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 19:36:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.549, 0.1824 s / batch. (data: 9.37e-05)max mem: 17.22449 GB 
[09/16 19:36:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.278, 0.1820 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 19:36:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.365, 0.1826 s / batch. (data: 4.10e-05)max mem: 17.22449 GB 
[09/16 19:36:47][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1926, average loss: 2.4293
[09/16 19:36:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 31.44	top5: 67.44	
[09/16 19:36:48][INFO] visual_prompt:  246: Best epoch 30: best metric: 0.320
[09/16 19:36:48][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 19:36:58][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 1.53e-01, avg batch time: 0.5546, average train loss: 2.6576
[09/16 19:37:03][INFO] visual_prompt:  324: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1425, average loss: 2.5072
[09/16 19:37:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 25.00	top5: 63.00	
[09/16 19:37:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.978, 0.1830 s / batch. (data: 9.66e-05)max mem: 17.22449 GB 
[09/16 19:37:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.658, 0.1960 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:38:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.959, 0.1964 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:38:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.724, 0.1827 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 19:38:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1935, average loss: 2.6657
[09/16 19:38:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 20.12	top5: 55.88	
[09/16 19:38:26][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 19:38:37][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 1.57e-01, avg batch time: 0.5566, average train loss: 2.8470
[09/16 19:38:42][INFO] visual_prompt:  324: Inference (val):avg data time: 3.21e-04, avg batch time: 0.2330, average loss: 2.3454
[09/16 19:38:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 26.50	top5: 67.00	
[09/16 19:39:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.950, 0.1959 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 19:39:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.693, 0.2090 s / batch. (data: 2.74e-02)max mem: 17.22449 GB 
[09/16 19:39:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.475, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:40:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.540, 0.1971 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 19:40:05][INFO] visual_prompt:  324: Inference (test):avg data time: 6.62e-03, avg batch time: 0.1928, average loss: 2.4547
[09/16 19:40:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 21.82	top5: 63.35	
[09/16 19:40:05][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 19:40:16][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 1.50e-01, avg batch time: 0.5508, average train loss: 2.1806
[09/16 19:40:20][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1425, average loss: 1.7552
[09/16 19:40:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 43.50	top5: 82.00	
[09/16 19:40:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.220, 0.1937 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 19:41:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.160, 0.1858 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 19:41:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.807, 0.1964 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:41:41][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.890, 0.1834 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 19:41:44][INFO] visual_prompt:  324: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1939, average loss: 1.9122
[09/16 19:41:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 38.53	top5: 73.64	
[09/16 19:41:44][INFO] visual_prompt:  246: Best epoch 33: best metric: 0.435
[09/16 19:41:44][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 19:41:55][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 1.52e-01, avg batch time: 0.5541, average train loss: 1.8856
[09/16 19:41:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1424, average loss: 2.1389
[09/16 19:41:59][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.50	top5: 69.50	
[09/16 19:42:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.400, 0.2077 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 19:42:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.237, 0.1909 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 19:43:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.262, 0.1960 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 19:43:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.060, 0.1828 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 19:43:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1933, average loss: 2.3232
[09/16 19:43:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 25.41	top5: 67.84	
[09/16 19:43:23][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 19:43:33][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 1.53e-01, avg batch time: 0.5537, average train loss: 1.8900
[09/16 19:43:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1425, average loss: 1.7525
[09/16 19:43:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 40.00	top5: 86.50	
[09/16 19:44:00][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.356, 0.1819 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 19:44:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.061, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 19:44:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.066, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:44:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.217, 0.1828 s / batch. (data: 2.72e-05)max mem: 17.22449 GB 
[09/16 19:45:01][INFO] visual_prompt:  324: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1926, average loss: 2.0328
[09/16 19:45:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 33.26	top5: 80.64	
[09/16 19:45:01][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 19:45:12][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 1.55e-01, avg batch time: 0.5554, average train loss: 3.3360
[09/16 19:45:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1425, average loss: 3.8184
[09/16 19:45:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 32.00	top5: 67.00	
[09/16 19:45:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.564, 0.1955 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 19:45:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.752, 0.1828 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 19:46:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 4.282, 0.1830 s / batch. (data: 9.32e-05)max mem: 17.22449 GB 
[09/16 19:46:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 4.329, 0.1828 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 19:46:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1924, average loss: 4.0538
[09/16 19:46:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 26.20	top5: 62.35	
[09/16 19:46:39][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 19:46:50][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.48e-01, avg batch time: 0.5475, average train loss: 2.8794
[09/16 19:46:55][INFO] visual_prompt:  324: Inference (val):avg data time: 3.45e-04, avg batch time: 0.2144, average loss: 2.2933
[09/16 19:46:55][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 37.00	top5: 76.50	
[09/16 19:47:17][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.864, 0.2265 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 19:47:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.931, 0.2115 s / batch. (data: 2.97e-02)max mem: 17.22449 GB 
[09/16 19:47:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.159, 0.1918 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 19:48:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.301, 0.1827 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 19:48:19][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1958, average loss: 2.4030
[09/16 19:48:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 35.09	top5: 73.99	
[09/16 19:48:19][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 19:48:30][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 1.47e-01, avg batch time: 0.5504, average train loss: 1.9991
[09/16 19:48:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1425, average loss: 1.5338
[09/16 19:48:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 43.00	top5: 85.50	
[09/16 19:48:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.897, 0.1822 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 19:49:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.873, 0.1978 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 19:49:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.551, 0.1961 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:49:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.696, 0.1818 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 19:49:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1938, average loss: 1.6714
[09/16 19:49:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 42.52	top5: 84.62	
[09/16 19:49:58][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 19:50:09][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 1.53e-01, avg batch time: 0.5550, average train loss: 1.7989
[09/16 19:50:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1463, average loss: 1.6788
[09/16 19:50:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 38.00	top5: 85.50	
[09/16 19:50:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.866, 0.1825 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 19:50:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.845, 0.2088 s / batch. (data: 2.72e-02)max mem: 17.22449 GB 
[09/16 19:51:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.881, 0.1826 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 19:51:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.035, 0.1823 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 19:51:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1935, average loss: 1.8831
[09/16 19:51:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 32.79	top5: 83.62	
[09/16 19:51:37][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 19:51:48][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 1.59e-01, avg batch time: 0.5598, average train loss: 1.7003
[09/16 19:51:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1425, average loss: 1.3770
[09/16 19:51:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 48.50	top5: 88.50	
[09/16 19:52:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.835, 0.1882 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 19:52:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.861, 0.2119 s / batch. (data: 1.63e-02)max mem: 17.22449 GB 
[09/16 19:52:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.403, 0.1827 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 19:53:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.778, 0.1826 s / batch. (data: 3.41e-05)max mem: 17.22449 GB 
[09/16 19:53:16][INFO] visual_prompt:  324: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1938, average loss: 1.6090
[09/16 19:53:16][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 44.00	top5: 85.71	
[09/16 19:53:16][INFO] visual_prompt:  246: Best epoch 40: best metric: 0.485
[09/16 19:53:16][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 3.75
[09/16 19:53:27][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 1.53e-01, avg batch time: 0.5726, average train loss: 1.4142
[09/16 19:53:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1424, average loss: 1.3811
[09/16 19:53:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 52.50	top5: 92.00	
[09/16 19:53:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.990, 0.1823 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 19:54:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.730, 0.1824 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 19:54:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.619, 0.1824 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 19:54:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.732, 0.1825 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 19:54:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1937, average loss: 1.6486
[09/16 19:54:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 49.45	top5: 86.29	
[09/16 19:54:55][INFO] visual_prompt:  246: Best epoch 41: best metric: 0.525
[09/16 19:54:55][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 19:55:06][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 1.57e-01, avg batch time: 0.5614, average train loss: 1.2554
[09/16 19:55:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1424, average loss: 1.1154
[09/16 19:55:10][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 59.50	top5: 94.00	
[09/16 19:55:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.752, 0.1829 s / batch. (data: 1.69e-04)max mem: 17.22449 GB 
[09/16 19:55:51][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.466, 0.2098 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 19:56:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.388, 0.1968 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 19:56:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.621, 0.1832 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 19:56:34][INFO] visual_prompt:  324: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1939, average loss: 1.5067
[09/16 19:56:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 52.07	top5: 89.46	
[09/16 19:56:34][INFO] visual_prompt:  246: Best epoch 42: best metric: 0.595
[09/16 19:56:34][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 19:56:44][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 1.54e-01, avg batch time: 0.5526, average train loss: 1.0744
[09/16 19:56:49][INFO] visual_prompt:  324: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1427, average loss: 0.9259
[09/16 19:56:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 72.00	top5: 98.00	
[09/16 19:57:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.462, 0.2050 s / batch. (data: 2.33e-02)max mem: 17.22449 GB 
[09/16 19:57:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.253, 0.2122 s / batch. (data: 3.09e-02)max mem: 17.22449 GB 
[09/16 19:57:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.152, 0.1950 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 19:58:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.293, 0.1839 s / batch. (data: 4.94e-05)max mem: 17.22449 GB 
[09/16 19:58:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1949, average loss: 1.3409
[09/16 19:58:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 56.88	top5: 92.90	
[09/16 19:58:13][INFO] visual_prompt:  246: Best epoch 43: best metric: 0.720
[09/16 19:58:13][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 19:58:24][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 1.57e-01, avg batch time: 0.5583, average train loss: 0.8649
[09/16 19:58:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1426, average loss: 0.6868
[09/16 19:58:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 77.50	top5: 98.50	
[09/16 19:58:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.570, 0.1978 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 19:59:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.120, 0.1926 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 19:59:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.333, 0.2045 s / batch. (data: 2.28e-02)max mem: 17.22449 GB 
[09/16 19:59:48][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.414, 0.1825 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 19:59:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1937, average loss: 1.3052
[09/16 19:59:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 58.58	top5: 92.06	
[09/16 19:59:52][INFO] visual_prompt:  246: Best epoch 44: best metric: 0.775
[09/16 19:59:52][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 20:00:02][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.44e-01, avg batch time: 0.5475, average train loss: 0.9301
[09/16 20:00:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1427, average loss: 1.0891
[09/16 20:00:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 60.50	top5: 96.00	
[09/16 20:00:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.167, 0.1824 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 20:00:48][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.683, 0.1954 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 20:01:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.547, 0.1975 s / batch. (data: 1.62e-02)max mem: 17.22449 GB 
[09/16 20:01:27][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.830, 0.1829 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 20:01:30][INFO] visual_prompt:  324: Inference (test):avg data time: 8.47e-03, avg batch time: 0.1937, average loss: 1.6799
[09/16 20:01:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 47.84	top5: 91.29	
[09/16 20:01:30][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 20:01:41][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.50e-01, avg batch time: 0.5511, average train loss: 0.8331
[09/16 20:01:45][INFO] visual_prompt:  324: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1424, average loss: 1.1147
[09/16 20:01:45][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 60.50	top5: 98.50	
[09/16 20:02:07][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.374, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 20:02:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.911, 0.1863 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 20:02:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.133, 0.1830 s / batch. (data: 5.13e-05)max mem: 17.22449 GB 
[09/16 20:03:05][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.870, 0.1859 s / batch. (data: 4.53e-05)max mem: 17.22449 GB 
[09/16 20:03:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1926, average loss: 1.9018
[09/16 20:03:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 48.52	top5: 90.29	
[09/16 20:03:09][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 20:03:19][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 1.57e-01, avg batch time: 0.5649, average train loss: 0.7507
[09/16 20:03:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1426, average loss: 0.4204
[09/16 20:03:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 87.50	top5: 99.50	
[09/16 20:03:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.138, 0.1823 s / batch. (data: 1.04e-04)max mem: 17.22449 GB 
[09/16 20:04:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.960, 0.1822 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 20:04:24][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.791, 0.1826 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 20:04:43][INFO] visual_prompt:  314: 	Test 400/407. loss: 0.902, 0.1830 s / batch. (data: 4.43e-05)max mem: 17.22449 GB 
[09/16 20:04:47][INFO] visual_prompt:  324: Inference (test):avg data time: 6.89e-03, avg batch time: 0.1917, average loss: 0.8861
[09/16 20:04:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.59	top5: 95.77	
[09/16 20:04:47][INFO] visual_prompt:  246: Best epoch 47: best metric: 0.875
[09/16 20:04:47][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 20:04:58][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 1.48e-01, avg batch time: 0.5690, average train loss: 0.5995
[09/16 20:05:02][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1444, average loss: 0.6671
[09/16 20:05:02][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 82.50	top5: 95.50	
[09/16 20:05:24][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.556, 0.2162 s / batch. (data: 3.49e-02)max mem: 17.22449 GB 
[09/16 20:05:43][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.242, 0.2092 s / batch. (data: 2.75e-02)max mem: 17.22449 GB 
[09/16 20:06:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.171, 0.1959 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 20:06:22][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.387, 0.1826 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 20:06:25][INFO] visual_prompt:  324: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1929, average loss: 1.2745
[09/16 20:06:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 65.57	top5: 93.12	
[09/16 20:06:26][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 20:06:36][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 1.59e-01, avg batch time: 0.5625, average train loss: 0.5431
[09/16 20:06:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1426, average loss: 0.3655
[09/16 20:06:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 87.00	top5: 100.00	
[09/16 20:07:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.150, 0.1982 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:07:22][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.151, 0.1947 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 20:07:41][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.143, 0.1843 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:08:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.287, 0.1827 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 20:08:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1928, average loss: 1.0770
[09/16 20:08:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 70.45	top5: 95.18	
[09/16 20:08:04][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 20:08:15][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 1.64e-01, avg batch time: 0.5649, average train loss: 0.4585
[09/16 20:08:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1423, average loss: 0.4601
[09/16 20:08:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 84.00	top5: 99.50	
[09/16 20:08:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.208, 0.2003 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 20:09:01][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.090, 0.1974 s / batch. (data: 1.56e-02)max mem: 17.22449 GB 
[09/16 20:09:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.911, 0.1880 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:09:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.215, 0.1823 s / batch. (data: 3.70e-05)max mem: 17.22449 GB 
[09/16 20:09:43][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1931, average loss: 1.0417
[09/16 20:09:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 71.17	top5: 96.44	
[09/16 20:09:43][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 20:09:53][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.60e-01, avg batch time: 0.5612, average train loss: 0.3389
[09/16 20:09:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1427, average loss: 0.6124
[09/16 20:09:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 77.00	top5: 100.00	
[09/16 20:10:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.889, 0.1961 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 20:10:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.587, 0.1831 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 20:10:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.537, 0.1958 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 20:11:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.419, 0.1819 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 20:11:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1932, average loss: 1.4774
[09/16 20:11:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 62.39	top5: 94.56	
[09/16 20:11:22][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 20:11:32][INFO] visual_prompt:  219: Epoch 52 / 100: avg data time: 1.59e-01, avg batch time: 0.5612, average train loss: 0.4077
[09/16 20:11:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1424, average loss: 0.4046
[09/16 20:11:37][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 85.50	top5: 99.50	
[09/16 20:11:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.293, 0.2293 s / batch. (data: 1.72e-02)max mem: 17.22449 GB 
[09/16 20:12:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.151, 0.2133 s / batch. (data: 3.19e-02)max mem: 17.22449 GB 
[09/16 20:12:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.010, 0.1865 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 20:12:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 0.985, 0.1828 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 20:13:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.18e-03, avg batch time: 0.1928, average loss: 1.1451
[09/16 20:13:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 70.66	top5: 94.86	
[09/16 20:13:00][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 20:13:11][INFO] visual_prompt:  219: Epoch 53 / 100: avg data time: 1.46e-01, avg batch time: 0.5480, average train loss: 0.3606
[09/16 20:13:15][INFO] visual_prompt:  324: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1424, average loss: 0.1951
[09/16 20:13:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 92.00	top5: 100.00	
[09/16 20:13:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 0.998, 0.1955 s / batch. (data: 1.03e-04)max mem: 17.22449 GB 
[09/16 20:13:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.928, 0.1824 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 20:14:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.803, 0.1829 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 20:14:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 0.965, 0.1825 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 20:14:38][INFO] visual_prompt:  324: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1930, average loss: 0.8754
[09/16 20:14:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.53	top5: 96.85	
[09/16 20:14:38][INFO] visual_prompt:  246: Best epoch 53: best metric: 0.920
[09/16 20:14:38][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 20:14:49][INFO] visual_prompt:  219: Epoch 54 / 100: avg data time: 1.51e-01, avg batch time: 0.5545, average train loss: 0.2243
[09/16 20:14:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1425, average loss: 0.2667
[09/16 20:14:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 89.00	top5: 100.00	
[09/16 20:15:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.508, 0.1838 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 20:15:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.013, 0.1828 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 20:15:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.296, 0.1972 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 20:16:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.120, 0.1828 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 20:16:18][INFO] visual_prompt:  324: Inference (test):avg data time: 8.66e-03, avg batch time: 0.1942, average loss: 1.1784
[09/16 20:16:18][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.15	top5: 97.27	
[09/16 20:16:18][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 20:16:28][INFO] visual_prompt:  219: Epoch 55 / 100: avg data time: 1.62e-01, avg batch time: 0.5632, average train loss: 0.2608
[09/16 20:16:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1425, average loss: 0.3246
[09/16 20:16:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 90.00	top5: 99.50	
[09/16 20:16:55][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.124, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 20:17:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.921, 0.1837 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 20:17:34][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.994, 0.1935 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 20:17:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.274, 0.1832 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 20:17:56][INFO] visual_prompt:  324: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1935, average loss: 0.9214
[09/16 20:17:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.32	top5: 95.32	
[09/16 20:17:56][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 2.5
[09/16 20:18:07][INFO] visual_prompt:  219: Epoch 56 / 100: avg data time: 1.58e-01, avg batch time: 0.5816, average train loss: 0.2279
[09/16 20:18:12][INFO] visual_prompt:  324: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1424, average loss: 0.1208
[09/16 20:18:12][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 95.00	top5: 100.00	
[09/16 20:18:34][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.395, 0.1826 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 20:18:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.806, 0.1974 s / batch. (data: 1.56e-02)max mem: 17.22449 GB 
[09/16 20:19:13][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.036, 0.1971 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 20:19:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.444, 0.1920 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 20:19:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1939, average loss: 0.9844
[09/16 20:19:36][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.78	top5: 97.33	
[09/16 20:19:36][INFO] visual_prompt:  246: Best epoch 56: best metric: 0.950
[09/16 20:19:36][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 20:19:46][INFO] visual_prompt:  219: Epoch 57 / 100: avg data time: 1.61e-01, avg batch time: 0.5605, average train loss: 0.1384
[09/16 20:19:51][INFO] visual_prompt:  324: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1425, average loss: 0.2669
[09/16 20:19:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 90.50	top5: 99.50	
[09/16 20:20:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.227, 0.1962 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 20:20:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.296, 0.1934 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 20:20:52][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.500, 0.2076 s / batch. (data: 2.53e-02)max mem: 17.22449 GB 
[09/16 20:21:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.077, 0.1830 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 20:21:14][INFO] visual_prompt:  324: Inference (test):avg data time: 8.50e-03, avg batch time: 0.1935, average loss: 1.4320
[09/16 20:21:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.47	top5: 95.19	
[09/16 20:21:14][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 20:21:25][INFO] visual_prompt:  219: Epoch 58 / 100: avg data time: 1.54e-01, avg batch time: 0.5568, average train loss: 0.2494
[09/16 20:21:29][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1425, average loss: 0.1453
[09/16 20:21:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 95.50	top5: 100.00	
[09/16 20:21:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.284, 0.1882 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:22:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.914, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 20:22:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.004, 0.1958 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 20:22:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.123, 0.1916 s / batch. (data: 4.03e-05)max mem: 17.22449 GB 
[09/16 20:22:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1937, average loss: 0.9379
[09/16 20:22:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.80	top5: 96.89	
[09/16 20:22:53][INFO] visual_prompt:  246: Best epoch 58: best metric: 0.955
[09/16 20:22:53][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 20:23:03][INFO] visual_prompt:  219: Epoch 59 / 100: avg data time: 1.54e-01, avg batch time: 0.5556, average train loss: 0.2734
[09/16 20:23:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1426, average loss: 0.1617
[09/16 20:23:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 94.00	top5: 100.00	
[09/16 20:23:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.655, 0.1955 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 20:23:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.860, 0.1986 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 20:24:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.339, 0.1828 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 20:24:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.414, 0.1825 s / batch. (data: 3.53e-05)max mem: 17.22449 GB 
[09/16 20:24:31][INFO] visual_prompt:  324: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1932, average loss: 1.1789
[09/16 20:24:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.42	top5: 97.17	
[09/16 20:24:31][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 20:24:42][INFO] visual_prompt:  219: Epoch 60 / 100: avg data time: 1.46e-01, avg batch time: 0.5488, average train loss: 0.2450
[09/16 20:24:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1423, average loss: 0.1313
[09/16 20:24:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 95.50	top5: 100.00	
[09/16 20:25:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.299, 0.1937 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 20:25:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.981, 0.1954 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 20:25:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.998, 0.2178 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 20:26:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.363, 0.1824 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 20:26:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1942, average loss: 0.8982
[09/16 20:26:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 77.14	top5: 96.99	
[09/16 20:26:10][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 20:26:21][INFO] visual_prompt:  219: Epoch 61 / 100: avg data time: 1.54e-01, avg batch time: 0.5548, average train loss: 0.1419
[09/16 20:26:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1425, average loss: 0.0973
[09/16 20:26:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 96.50	top5: 100.00	
[09/16 20:26:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.734, 0.1828 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 20:27:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.949, 0.2362 s / batch. (data: 5.41e-02)max mem: 17.22449 GB 
[09/16 20:27:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.144, 0.1829 s / batch. (data: 1.67e-04)max mem: 17.22449 GB 
[09/16 20:27:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.266, 0.1826 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 20:27:49][INFO] visual_prompt:  324: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1935, average loss: 1.0786
[09/16 20:27:49][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 76.12	top5: 97.23	
[09/16 20:27:49][INFO] visual_prompt:  246: Best epoch 61: best metric: 0.965
[09/16 20:27:49][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 20:27:59][INFO] visual_prompt:  219: Epoch 62 / 100: avg data time: 1.51e-01, avg batch time: 0.5536, average train loss: 0.1715
[09/16 20:28:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1423, average loss: 0.2751
[09/16 20:28:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 92.00	top5: 100.00	
[09/16 20:28:26][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.130, 0.1826 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 20:28:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.668, 0.1820 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 20:29:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.506, 0.2080 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 20:29:25][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.321, 0.1835 s / batch. (data: 2.74e-05)max mem: 17.22449 GB 
[09/16 20:29:28][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1947, average loss: 1.4784
[09/16 20:29:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.89	top5: 95.83	
[09/16 20:29:28][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 20:29:38][INFO] visual_prompt:  219: Epoch 63 / 100: avg data time: 1.56e-01, avg batch time: 0.5565, average train loss: 0.1312
[09/16 20:29:43][INFO] visual_prompt:  324: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1423, average loss: 0.1495
[09/16 20:29:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 95.50	top5: 100.00	
[09/16 20:30:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.572, 0.1827 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 20:30:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.248, 0.2008 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 20:30:44][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.173, 0.1960 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 20:31:03][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.238, 0.1827 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 20:31:06][INFO] visual_prompt:  324: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1936, average loss: 1.1493
[09/16 20:31:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.40	top5: 96.83	
[09/16 20:31:07][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 20:31:17][INFO] visual_prompt:  219: Epoch 64 / 100: avg data time: 1.58e-01, avg batch time: 0.5584, average train loss: 0.0955
[09/16 20:31:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1426, average loss: 0.0877
[09/16 20:31:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 95.50	top5: 100.00	
[09/16 20:31:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.143, 0.1842 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 20:32:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.785, 0.1841 s / batch. (data: 1.40e-04)max mem: 17.22449 GB 
[09/16 20:32:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.853, 0.2081 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 20:32:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.678, 0.1825 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 20:32:45][INFO] visual_prompt:  324: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1939, average loss: 1.1914
[09/16 20:32:45][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 77.57	top5: 97.24	
[09/16 20:32:45][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 20:32:56][INFO] visual_prompt:  219: Epoch 65 / 100: avg data time: 1.54e-01, avg batch time: 0.5546, average train loss: 0.1348
[09/16 20:33:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1426, average loss: 0.0939
[09/16 20:33:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 96.50	top5: 100.00	
[09/16 20:33:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.968, 0.1959 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 20:33:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.405, 0.2023 s / batch. (data: 2.04e-02)max mem: 17.22449 GB 
[09/16 20:34:01][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.435, 0.1835 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 20:34:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.734, 0.1825 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 20:34:24][INFO] visual_prompt:  324: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1937, average loss: 1.3118
[09/16 20:34:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 73.66	top5: 96.35	
[09/16 20:34:24][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 20:34:35][INFO] visual_prompt:  219: Epoch 66 / 100: avg data time: 1.50e-01, avg batch time: 0.5533, average train loss: 0.1133
[09/16 20:34:40][INFO] visual_prompt:  324: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1430, average loss: 0.0530
[09/16 20:34:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 98.50	top5: 100.00	
[09/16 20:35:01][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.905, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 20:35:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.230, 0.1815 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 20:35:40][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.189, 0.1869 s / batch. (data: 8.58e-05)max mem: 17.22449 GB 
[09/16 20:36:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.713, 0.1828 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 20:36:03][INFO] visual_prompt:  324: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1937, average loss: 1.1995
[09/16 20:36:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 76.99	top5: 97.03	
[09/16 20:36:03][INFO] visual_prompt:  246: Best epoch 66: best metric: 0.985
[09/16 20:36:03][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 20:36:14][INFO] visual_prompt:  219: Epoch 67 / 100: avg data time: 1.49e-01, avg batch time: 0.5521, average train loss: 0.0567
[09/16 20:36:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1425, average loss: 0.1281
[09/16 20:36:18][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 97.00	top5: 100.00	
[09/16 20:36:40][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.472, 0.1876 s / batch. (data: 5.23e-03)max mem: 17.22449 GB 
[09/16 20:37:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.103, 0.1825 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 20:37:19][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.236, 0.2152 s / batch. (data: 1.86e-02)max mem: 17.22449 GB 
[09/16 20:37:38][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.382, 0.1821 s / batch. (data: 3.53e-05)max mem: 17.22449 GB 
[09/16 20:37:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1927, average loss: 1.6695
[09/16 20:37:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 74.58	top5: 96.37	
[09/16 20:37:42][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 20:37:52][INFO] visual_prompt:  219: Epoch 68 / 100: avg data time: 1.63e-01, avg batch time: 0.5623, average train loss: 0.0914
[09/16 20:37:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1463, average loss: 0.0732
[09/16 20:37:57][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 98.00	top5: 100.00	
[09/16 20:38:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.392, 0.2175 s / batch. (data: 3.45e-04)max mem: 17.22449 GB 
[09/16 20:38:38][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.752, 0.1826 s / batch. (data: 1.05e-04)max mem: 17.22449 GB 
[09/16 20:38:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.352, 0.1822 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 20:39:17][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.268, 0.1819 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 20:39:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1939, average loss: 1.4941
[09/16 20:39:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 74.75	top5: 96.67	
[09/16 20:39:21][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 20:39:31][INFO] visual_prompt:  219: Epoch 69 / 100: avg data time: 1.50e-01, avg batch time: 0.5543, average train loss: 0.0498
[09/16 20:39:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1423, average loss: 0.0066
[09/16 20:39:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:39:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.507, 0.2119 s / batch. (data: 3.02e-02)max mem: 17.22449 GB 
[09/16 20:40:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.104, 0.1958 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:40:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.072, 0.2171 s / batch. (data: 2.98e-02)max mem: 17.22449 GB 
[09/16 20:40:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.460, 0.1822 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 20:41:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1934, average loss: 1.0489
[09/16 20:41:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.53	top5: 97.02	
[09/16 20:41:00][INFO] visual_prompt:  246: Best epoch 69: best metric: 1.000
[09/16 20:41:00][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 20:41:11][INFO] visual_prompt:  219: Epoch 70 / 100: avg data time: 1.64e-01, avg batch time: 0.5662, average train loss: 0.0736
[09/16 20:41:15][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1425, average loss: 0.2213
[09/16 20:41:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 93.50	top5: 100.00	
[09/16 20:41:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.608, 0.1872 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 20:41:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.196, 0.1820 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:42:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.236, 0.1973 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 20:42:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.905, 0.1828 s / batch. (data: 2.96e-05)max mem: 17.22449 GB 
[09/16 20:42:38][INFO] visual_prompt:  324: Inference (test):avg data time: 6.92e-03, avg batch time: 0.1922, average loss: 1.8980
[09/16 20:42:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 74.12	top5: 96.07	
[09/16 20:42:38][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 20:42:49][INFO] visual_prompt:  219: Epoch 71 / 100: avg data time: 1.54e-01, avg batch time: 0.5564, average train loss: 0.1311
[09/16 20:42:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1426, average loss: 0.0394
[09/16 20:42:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.00	top5: 100.00	
[09/16 20:43:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.473, 0.2063 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 20:43:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.634, 0.1975 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 20:43:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.187, 0.1954 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 20:44:15][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.304, 0.1830 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 20:44:18][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1955, average loss: 0.9585
[09/16 20:44:18][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.58	top5: 98.10	
[09/16 20:44:18][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 20:44:29][INFO] visual_prompt:  219: Epoch 72 / 100: avg data time: 1.60e-01, avg batch time: 0.5596, average train loss: 0.0552
[09/16 20:44:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1425, average loss: 0.0092
[09/16 20:44:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:44:55][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.391, 0.2123 s / batch. (data: 2.58e-02)max mem: 17.22449 GB 
[09/16 20:45:15][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.082, 0.1835 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 20:45:34][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.049, 0.1992 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 20:45:54][INFO] visual_prompt:  314: 	Test 400/407. loss: 0.983, 0.1838 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 20:45:57][INFO] visual_prompt:  324: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1937, average loss: 0.9897
[09/16 20:45:57][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.89	top5: 97.59	
[09/16 20:45:57][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 20:46:08][INFO] visual_prompt:  219: Epoch 73 / 100: avg data time: 1.62e-01, avg batch time: 0.5617, average train loss: 0.0168
[09/16 20:46:12][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1426, average loss: 0.0239
[09/16 20:46:12][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.00	top5: 100.00	
[09/16 20:46:34][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.103, 0.2042 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 20:46:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.627, 0.2010 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 20:47:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.591, 0.2108 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 20:47:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.874, 0.1832 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 20:47:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1932, average loss: 1.3971
[09/16 20:47:36][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 77.81	top5: 97.10	
[09/16 20:47:36][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 20:47:46][INFO] visual_prompt:  219: Epoch 74 / 100: avg data time: 1.55e-01, avg batch time: 0.5554, average train loss: 0.0167
[09/16 20:47:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1427, average loss: 0.0292
[09/16 20:47:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.50	top5: 100.00	
[09/16 20:48:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.926, 0.1916 s / batch. (data: 1.05e-04)max mem: 17.22449 GB 
[09/16 20:48:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.566, 0.2094 s / batch. (data: 2.38e-02)max mem: 17.22449 GB 
[09/16 20:48:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.662, 0.1826 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 20:49:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.653, 0.1825 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 20:49:15][INFO] visual_prompt:  324: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1936, average loss: 1.4087
[09/16 20:49:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.52	top5: 97.28	
[09/16 20:49:15][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 20:49:25][INFO] visual_prompt:  219: Epoch 75 / 100: avg data time: 1.51e-01, avg batch time: 0.5525, average train loss: 0.0223
[09/16 20:49:30][INFO] visual_prompt:  324: Inference (val):avg data time: 4.82e-05, avg batch time: 0.1463, average loss: 0.0026
[09/16 20:49:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:49:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.679, 0.1830 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 20:50:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.682, 0.1836 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 20:50:31][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.920, 0.2097 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 20:50:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.425, 0.1854 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 20:50:54][INFO] visual_prompt:  324: Inference (test):avg data time: 6.68e-03, avg batch time: 0.1927, average loss: 1.5958
[09/16 20:50:54][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 78.73	top5: 97.35	
[09/16 20:50:54][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 20:51:05][INFO] visual_prompt:  219: Epoch 76 / 100: avg data time: 1.51e-01, avg batch time: 0.5551, average train loss: 0.0053
[09/16 20:51:09][INFO] visual_prompt:  324: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1426, average loss: 0.0162
[09/16 20:51:09][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.00	top5: 100.00	
[09/16 20:51:31][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.153, 0.1823 s / batch. (data: 3.58e-04)max mem: 17.22449 GB 
[09/16 20:51:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.419, 0.1834 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 20:52:10][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.398, 0.1844 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 20:52:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.038, 0.1820 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 20:52:33][INFO] visual_prompt:  324: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1926, average loss: 1.3360
[09/16 20:52:33][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.47	top5: 97.40	
[09/16 20:52:33][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 20:52:43][INFO] visual_prompt:  219: Epoch 77 / 100: avg data time: 1.62e-01, avg batch time: 0.5621, average train loss: 0.0099
[09/16 20:52:48][INFO] visual_prompt:  324: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1423, average loss: 0.0573
[09/16 20:52:48][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.00	top5: 100.00	
[09/16 20:53:10][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.419, 0.2117 s / batch. (data: 3.05e-02)max mem: 17.22449 GB 
[09/16 20:53:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.677, 0.1821 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 20:53:49][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.032, 0.2066 s / batch. (data: 6.34e-05)max mem: 17.22449 GB 
[09/16 20:54:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.300, 0.1833 s / batch. (data: 2.96e-05)max mem: 17.22449 GB 
[09/16 20:54:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1938, average loss: 1.6399
[09/16 20:54:12][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 78.43	top5: 97.31	
[09/16 20:54:12][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 20:54:22][INFO] visual_prompt:  219: Epoch 78 / 100: avg data time: 1.47e-01, avg batch time: 0.5478, average train loss: 0.0061
[09/16 20:54:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1437, average loss: 0.0011
[09/16 20:54:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:54:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.872, 0.1828 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 20:55:08][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.146, 0.1968 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 20:55:28][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.384, 0.1827 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 20:55:47][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.148, 0.1834 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 20:55:51][INFO] visual_prompt:  324: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1954, average loss: 1.2441
[09/16 20:55:51][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.50	top5: 97.94	
[09/16 20:55:51][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 20:56:01][INFO] visual_prompt:  219: Epoch 79 / 100: avg data time: 1.49e-01, avg batch time: 0.5520, average train loss: 0.0028
[09/16 20:56:06][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1426, average loss: 0.0005
[09/16 20:56:06][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:56:28][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.141, 0.1841 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 20:56:47][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.413, 0.1820 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 20:57:06][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.480, 0.1827 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 20:57:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.171, 0.1820 s / batch. (data: 3.96e-05)max mem: 17.22449 GB 
[09/16 20:57:29][INFO] visual_prompt:  324: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1929, average loss: 1.3316
[09/16 20:57:29][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.97	top5: 97.65	
[09/16 20:57:29][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 20:57:40][INFO] visual_prompt:  219: Epoch 80 / 100: avg data time: 1.59e-01, avg batch time: 0.5626, average train loss: 0.0018
[09/16 20:57:44][INFO] visual_prompt:  324: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1458, average loss: 0.0015
[09/16 20:57:44][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:58:06][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.313, 0.2034 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 20:58:26][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.492, 0.2098 s / batch. (data: 2.78e-02)max mem: 17.22449 GB 
[09/16 20:58:45][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.645, 0.1957 s / batch. (data: 1.31e-02)max mem: 17.22449 GB 
[09/16 20:59:05][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.225, 0.1837 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 20:59:08][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1938, average loss: 1.3887
[09/16 20:59:08][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.21	top5: 97.29	
[09/16 20:59:08][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 20:59:19][INFO] visual_prompt:  219: Epoch 81 / 100: avg data time: 1.59e-01, avg batch time: 0.5593, average train loss: 0.0010
[09/16 20:59:23][INFO] visual_prompt:  324: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1472, average loss: 0.0002
[09/16 20:59:23][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 20:59:45][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.002, 0.1832 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 21:00:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.343, 0.1916 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 21:00:24][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.524, 0.1962 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 21:00:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.218, 0.1832 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 21:00:47][INFO] visual_prompt:  324: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1955, average loss: 1.2773
[09/16 21:00:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.68	top5: 97.79	
[09/16 21:00:47][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 21:00:58][INFO] visual_prompt:  219: Epoch 82 / 100: avg data time: 1.61e-01, avg batch time: 0.5627, average train loss: 0.0004
[09/16 21:01:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:01:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:01:24][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.924, 0.2066 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 21:01:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.312, 0.1962 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 21:02:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.501, 0.2355 s / batch. (data: 2.54e-02)max mem: 17.22449 GB 
[09/16 21:02:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.208, 0.1829 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 21:02:27][INFO] visual_prompt:  324: Inference (test):avg data time: 8.53e-03, avg batch time: 0.1965, average loss: 1.2703
[09/16 21:02:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.71	top5: 97.82	
[09/16 21:02:27][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 21:02:38][INFO] visual_prompt:  219: Epoch 83 / 100: avg data time: 1.50e-01, avg batch time: 0.5520, average train loss: 0.0005
[09/16 21:02:43][INFO] visual_prompt:  324: Inference (val):avg data time: 7.26e-05, avg batch time: 0.1484, average loss: 0.0002
[09/16 21:02:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:03:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.858, 0.1948 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 21:03:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.317, 0.2174 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 21:03:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.504, 0.1825 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 21:04:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.212, 0.1829 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 21:04:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1952, average loss: 1.2577
[09/16 21:04:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.83	top5: 97.82	
[09/16 21:04:07][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 21:04:17][INFO] visual_prompt:  219: Epoch 84 / 100: avg data time: 1.37e-01, avg batch time: 0.5372, average train loss: 0.0004
[09/16 21:04:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1427, average loss: 0.0002
[09/16 21:04:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:04:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.851, 0.2149 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 21:05:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.324, 0.1959 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 21:05:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.503, 0.1946 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 21:05:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.173, 0.1829 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 21:05:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1937, average loss: 1.2523
[09/16 21:05:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.81	top5: 97.83	
[09/16 21:05:46][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 21:05:56][INFO] visual_prompt:  219: Epoch 85 / 100: avg data time: 1.59e-01, avg batch time: 0.5597, average train loss: 0.0003
[09/16 21:06:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1426, average loss: 0.0002
[09/16 21:06:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:06:23][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.853, 0.1819 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 21:06:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.317, 0.1828 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 21:07:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.503, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 21:07:22][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.145, 0.1832 s / batch. (data: 3.50e-05)max mem: 17.22449 GB 
[09/16 21:07:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1965, average loss: 1.2497
[09/16 21:07:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.73	top5: 97.84	
[09/16 21:07:26][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 21:07:36][INFO] visual_prompt:  219: Epoch 86 / 100: avg data time: 1.57e-01, avg batch time: 0.5579, average train loss: 0.0004
[09/16 21:07:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1441, average loss: 0.0002
[09/16 21:07:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:08:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.846, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 21:08:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.311, 0.1972 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 21:08:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.493, 0.1920 s / batch. (data: 9.49e-03)max mem: 17.22449 GB 
[09/16 21:09:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.150, 0.1821 s / batch. (data: 2.43e-05)max mem: 17.22449 GB 
[09/16 21:09:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1934, average loss: 1.2447
[09/16 21:09:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.74	top5: 97.85	
[09/16 21:09:05][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 21:09:15][INFO] visual_prompt:  219: Epoch 87 / 100: avg data time: 1.58e-01, avg batch time: 0.5578, average train loss: 0.0004
[09/16 21:09:20][INFO] visual_prompt:  324: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1423, average loss: 0.0002
[09/16 21:09:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:09:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.851, 0.1826 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 21:10:01][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.291, 0.1982 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 21:10:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.497, 0.1911 s / batch. (data: 1.58e-04)max mem: 17.22449 GB 
[09/16 21:10:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.136, 0.1829 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 21:10:43][INFO] visual_prompt:  324: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1920, average loss: 1.2407
[09/16 21:10:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.78	top5: 97.88	
[09/16 21:10:43][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 21:10:54][INFO] visual_prompt:  219: Epoch 88 / 100: avg data time: 1.54e-01, avg batch time: 0.5533, average train loss: 0.0004
[09/16 21:10:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1424, average loss: 0.0002
[09/16 21:10:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:11:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.848, 0.1949 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 21:11:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.270, 0.1891 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 21:11:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.495, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 21:12:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.123, 0.1823 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 21:12:21][INFO] visual_prompt:  324: Inference (test):avg data time: 6.93e-03, avg batch time: 0.1930, average loss: 1.2367
[09/16 21:12:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.89	top5: 97.91	
[09/16 21:12:22][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 21:12:32][INFO] visual_prompt:  219: Epoch 89 / 100: avg data time: 1.41e-01, avg batch time: 0.5470, average train loss: 0.0005
[09/16 21:12:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:12:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:12:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.847, 0.2754 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 21:13:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.270, 0.1819 s / batch. (data: 3.43e-05)max mem: 17.22449 GB 
[09/16 21:13:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.501, 0.1821 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 21:13:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.118, 0.1825 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 21:14:00][INFO] visual_prompt:  324: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1949, average loss: 1.2362
[09/16 21:14:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.82	top5: 97.90	
[09/16 21:14:01][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 21:14:11][INFO] visual_prompt:  219: Epoch 90 / 100: avg data time: 1.44e-01, avg batch time: 0.5469, average train loss: 0.0002
[09/16 21:14:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:14:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:14:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.846, 0.1949 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 21:14:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.270, 0.1918 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 21:15:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.507, 0.1824 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 21:15:37][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.115, 0.1823 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 21:15:40][INFO] visual_prompt:  324: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1956, average loss: 1.2363
[09/16 21:15:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.82	top5: 97.88	
[09/16 21:15:40][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 21:15:51][INFO] visual_prompt:  219: Epoch 91 / 100: avg data time: 1.64e-01, avg batch time: 0.5653, average train loss: 0.0003
[09/16 21:15:56][INFO] visual_prompt:  324: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1424, average loss: 0.0002
[09/16 21:15:56][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:16:17][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.844, 0.1819 s / batch. (data: 7.58e-05)max mem: 17.22449 GB 
[09/16 21:16:37][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.268, 0.1820 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 21:16:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.506, 0.1982 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 21:17:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.110, 0.1821 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 21:17:19][INFO] visual_prompt:  324: Inference (test):avg data time: 6.68e-03, avg batch time: 0.1940, average loss: 1.2349
[09/16 21:17:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.80	top5: 97.87	
[09/16 21:17:19][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 21:17:30][INFO] visual_prompt:  219: Epoch 92 / 100: avg data time: 1.58e-01, avg batch time: 0.5576, average train loss: 0.0004
[09/16 21:17:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1426, average loss: 0.0002
[09/16 21:17:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:17:57][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.841, 0.1947 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 21:18:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.264, 0.1979 s / batch. (data: 1.56e-02)max mem: 17.22449 GB 
[09/16 21:18:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.504, 0.1919 s / batch. (data: 9.76e-03)max mem: 17.22449 GB 
[09/16 21:18:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.110, 0.1832 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 21:18:58][INFO] visual_prompt:  324: Inference (test):avg data time: 8.72e-03, avg batch time: 0.1940, average loss: 1.2335
[09/16 21:18:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.78	top5: 97.87	
[09/16 21:18:58][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 21:19:09][INFO] visual_prompt:  219: Epoch 93 / 100: avg data time: 1.54e-01, avg batch time: 0.5561, average train loss: 0.0005
[09/16 21:19:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:19:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:19:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.839, 0.1993 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 21:19:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.265, 0.2188 s / batch. (data: 3.69e-02)max mem: 17.22449 GB 
[09/16 21:20:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.503, 0.1948 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 21:20:33][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.112, 0.1827 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 21:20:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1932, average loss: 1.2334
[09/16 21:20:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.77	top5: 97.87	
[09/16 21:20:37][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 21:20:48][INFO] visual_prompt:  219: Epoch 94 / 100: avg data time: 1.57e-01, avg batch time: 0.5616, average train loss: 0.0003
[09/16 21:20:52][INFO] visual_prompt:  324: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1426, average loss: 0.0002
[09/16 21:20:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:21:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.835, 0.2005 s / batch. (data: 1.86e-02)max mem: 17.22449 GB 
[09/16 21:21:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.267, 0.1959 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 21:21:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.503, 0.1900 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 21:22:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.118, 0.1820 s / batch. (data: 3.86e-05)max mem: 17.22449 GB 
[09/16 21:22:17][INFO] visual_prompt:  324: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1949, average loss: 1.2331
[09/16 21:22:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.77	top5: 97.87	
[09/16 21:22:17][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 21:22:27][INFO] visual_prompt:  219: Epoch 95 / 100: avg data time: 1.59e-01, avg batch time: 0.5619, average train loss: 0.0004
[09/16 21:22:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:22:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:22:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.834, 0.1951 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 21:23:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.268, 0.1829 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 21:23:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.503, 0.1831 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 21:23:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.117, 0.1832 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 21:23:55][INFO] visual_prompt:  324: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1929, average loss: 1.2326
[09/16 21:23:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.78	top5: 97.87	
[09/16 21:23:55][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 21:24:06][INFO] visual_prompt:  219: Epoch 96 / 100: avg data time: 1.66e-01, avg batch time: 0.5683, average train loss: 0.0004
[09/16 21:24:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:24:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:24:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.834, 0.1974 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 21:24:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.267, 0.2070 s / batch. (data: 2.58e-02)max mem: 17.22449 GB 
[09/16 21:25:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.502, 0.1871 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 21:25:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.116, 0.1822 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 21:25:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1937, average loss: 1.2326
[09/16 21:25:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.78	top5: 97.87	
[09/16 21:25:34][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 21:25:45][INFO] visual_prompt:  219: Epoch 97 / 100: avg data time: 1.57e-01, avg batch time: 0.5571, average train loss: 0.0003
[09/16 21:25:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1423, average loss: 0.0002
[09/16 21:25:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:26:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.834, 0.1822 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 21:26:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.266, 0.1962 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 21:26:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.502, 0.1957 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 21:27:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.115, 0.1820 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 21:27:13][INFO] visual_prompt:  324: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1947, average loss: 1.2326
[09/16 21:27:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.79	top5: 97.87	
[09/16 21:27:13][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 21:27:24][INFO] visual_prompt:  219: Epoch 98 / 100: avg data time: 1.60e-01, avg batch time: 0.5600, average train loss: 0.0005
[09/16 21:27:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:27:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:27:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.834, 0.1957 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 21:28:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.267, 0.2024 s / batch. (data: 2.06e-02)max mem: 17.22449 GB 
[09/16 21:28:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.502, 0.1827 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 21:28:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.115, 0.1822 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 21:28:52][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1939, average loss: 1.2327
[09/16 21:28:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.76	top5: 97.87	
[09/16 21:28:52][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 21:29:03][INFO] visual_prompt:  219: Epoch 99 / 100: avg data time: 1.60e-01, avg batch time: 0.5606, average train loss: 0.0003
[09/16 21:29:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1426, average loss: 0.0002
[09/16 21:29:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:29:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.834, 0.1814 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 21:29:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.267, 0.1824 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 21:30:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.502, 0.2286 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 21:30:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.115, 0.1825 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 21:30:31][INFO] visual_prompt:  324: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1933, average loss: 1.2326
[09/16 21:30:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.76	top5: 97.87	
[09/16 21:30:31][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 21:30:42][INFO] visual_prompt:  219: Epoch 100 / 100: avg data time: 1.52e-01, avg batch time: 0.5512, average train loss: 0.0003
[09/16 21:30:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1425, average loss: 0.0002
[09/16 21:30:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 21:31:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.834, 0.1962 s / batch. (data: 1.47e-02)max mem: 17.22449 GB 
[09/16 21:31:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.267, 0.2009 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 21:31:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.502, 0.1965 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 21:32:06][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.115, 0.1822 s / batch. (data: 3.00e-05)max mem: 17.22449 GB 
[09/16 21:32:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1933, average loss: 1.2326
[09/16 21:32:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.76	top5: 97.87	
