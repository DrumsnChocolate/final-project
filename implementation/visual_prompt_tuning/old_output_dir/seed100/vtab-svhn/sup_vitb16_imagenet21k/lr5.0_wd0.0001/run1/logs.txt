[09/16 16:01:17][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/16 16:01:17][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 16:01:17][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-svhn', 'DATA.NUMBER_CLASSES', '10', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/16 16:01:17][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 16:01:17][INFO] visual_prompt:  108: Training with config:
[09/16 16:01:17][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'IMGSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-svhn',
          'NO_TEST': False,
          'NUMBER_CLASSES': 10,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-svhn/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 16:01:17][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/16 16:01:20][INFO] visual_prompt:   69: Constructing vtab-svhn dataset trainval...
[09/16 16:01:22][INFO] visual_prompt:   88: Number of images: 1000
[09/16 16:01:22][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 16:01:22][INFO] visual_prompt:   70: Loading validation data...
[09/16 16:01:22][INFO] visual_prompt:   69: Constructing vtab-svhn dataset val...
[09/16 16:01:23][INFO] visual_prompt:   88: Number of images: 200
[09/16 16:01:23][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 16:01:23][INFO] visual_prompt:   73: Loading test data...
[09/16 16:01:23][INFO] visual_prompt:   69: Constructing vtab-svhn dataset test...
[09/16 16:01:55][INFO] visual_prompt:   88: Number of images: 26032
[09/16 16:01:55][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 16:01:55][INFO] visual_prompt:  100: Constructing models...
[09/16 16:01:57][INFO] visual_prompt:   53: Total Parameters: 86727946	 Gradient Parameters: 929290
[09/16 16:01:57][INFO] visual_prompt:   54: tuned percent:1.072
[09/16 16:02:00][INFO] visual_prompt:   40: Device used for model: 0
[09/16 16:02:00][INFO] visual_prompt:  103: Setting up Evalutator...
[09/16 16:02:00][INFO] visual_prompt:  105: Setting up Trainer...
[09/16 16:02:00][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/16 16:02:00][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/16 16:02:12][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 1.67e-01, avg batch time: 0.6380, average train loss: 2.6572
[09/16 16:02:17][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1417, average loss: 2.5881
[09/16 16:02:17][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.00	
[09/16 16:02:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.678, 0.1810 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 16:02:58][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.821, 0.1811 s / batch. (data: 1.05e-04)max mem: 17.22449 GB 
[09/16 16:03:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.549, 0.1824 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 16:03:37][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.783, 0.1820 s / batch. (data: 4.36e-05)max mem: 17.22449 GB 
[09/16 16:03:40][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1934, average loss: 2.6049
[09/16 16:03:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 57.77	
[09/16 16:03:40][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.230
[09/16 16:03:40][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/16 16:03:50][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 1.42e-01, avg batch time: 0.5466, average train loss: 3.0320
[09/16 16:03:55][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1425, average loss: 2.3229
[09/16 16:03:55][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.50	
[09/16 16:04:17][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.490, 0.1823 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 16:04:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.550, 0.1831 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 16:04:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.257, 0.2067 s / batch. (data: 9.99e-05)max mem: 17.22449 GB 
[09/16 16:05:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.385, 0.1825 s / batch. (data: 3.77e-05)max mem: 17.22449 GB 
[09/16 16:05:19][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1940, average loss: 2.3471
[09/16 16:05:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.22	
[09/16 16:05:19][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/16 16:05:30][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 1.56e-01, avg batch time: 0.5543, average train loss: 2.4300
[09/16 16:05:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1426, average loss: 2.2743
[09/16 16:05:34][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 62.00	
[09/16 16:05:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.318, 0.1826 s / batch. (data: 1.03e-04)max mem: 17.22449 GB 
[09/16 16:06:15][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.375, 0.1838 s / batch. (data: 1.54e-04)max mem: 17.22449 GB 
[09/16 16:06:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.211, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 16:06:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.307, 0.1823 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 16:06:58][INFO] visual_prompt:  324: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1937, average loss: 2.2664
[09/16 16:06:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 62.13	
[09/16 16:06:58][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/16 16:07:08][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.47e-01, avg batch time: 0.5475, average train loss: 2.3505
[09/16 16:07:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1424, average loss: 2.3638
[09/16 16:07:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 47.00	
[09/16 16:07:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.332, 0.1918 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 16:07:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.372, 0.1894 s / batch. (data: 5.22e-03)max mem: 17.22449 GB 
[09/16 16:08:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.360, 0.2048 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 16:08:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.325, 0.1826 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 16:08:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1949, average loss: 2.3582
[09/16 16:08:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 45.18	
[09/16 16:08:37][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/16 16:08:48][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.55e-01, avg batch time: 0.5563, average train loss: 2.5133
[09/16 16:08:52][INFO] visual_prompt:  324: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1426, average loss: 2.5764
[09/16 16:08:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 62.00	
[09/16 16:09:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.538, 0.2036 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 16:09:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.699, 0.1963 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 16:09:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.512, 0.1827 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 16:10:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.650, 0.1827 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 16:10:16][INFO] visual_prompt:  324: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1938, average loss: 2.5569
[09/16 16:10:16][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 62.13	
[09/16 16:10:16][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/16 16:10:26][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 1.40e-01, avg batch time: 0.5464, average train loss: 2.7431
[09/16 16:10:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1421, average loss: 2.7751
[09/16 16:10:31][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 63.50	
[09/16 16:10:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.893, 0.2159 s / batch. (data: 9.23e-05)max mem: 17.22449 GB 
[09/16 16:11:12][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.813, 0.1829 s / batch. (data: 1.61e-04)max mem: 17.22449 GB 
[09/16 16:11:31][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.833, 0.1822 s / batch. (data: 1.59e-04)max mem: 17.22449 GB 
[09/16 16:11:51][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.708, 0.1832 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 16:11:54][INFO] visual_prompt:  324: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1932, average loss: 2.7664
[09/16 16:11:54][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 63.88	
[09/16 16:11:54][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/16 16:12:05][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.58e-01, avg batch time: 0.5590, average train loss: 3.7773
[09/16 16:12:09][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1424, average loss: 4.0517
[09/16 16:12:09][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.50	
[09/16 16:12:31][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.826, 0.1961 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 16:12:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 4.625, 0.1995 s / batch. (data: 1.76e-02)max mem: 17.22449 GB 
[09/16 16:13:10][INFO] visual_prompt:  314: 	Test 300/407. loss: 4.206, 0.1826 s / batch. (data: 1.02e-04)max mem: 17.22449 GB 
[09/16 16:13:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 4.363, 0.1831 s / batch. (data: 4.05e-05)max mem: 17.22449 GB 
[09/16 16:13:33][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1932, average loss: 4.3051
[09/16 16:13:33][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.32	
[09/16 16:13:33][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/16 16:13:43][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.46e-01, avg batch time: 0.5454, average train loss: 4.7493
[09/16 16:13:48][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1425, average loss: 5.1254
[09/16 16:13:48][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 52.50	
[09/16 16:14:10][INFO] visual_prompt:  314: 	Test 100/407. loss: 5.939, 0.1824 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 16:14:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 5.260, 0.2095 s / batch. (data: 2.76e-02)max mem: 17.22449 GB 
[09/16 16:14:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 5.749, 0.2086 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 16:15:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.753, 0.1890 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 16:15:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.33e-03, avg batch time: 0.1936, average loss: 5.1674
[09/16 16:15:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 49.70	
[09/16 16:15:11][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/16 16:15:22][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.45e-01, avg batch time: 0.5477, average train loss: 6.3703
[09/16 16:15:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1446, average loss: 5.0434
[09/16 16:15:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.00	
[09/16 16:15:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 6.370, 0.1973 s / batch. (data: 1.56e-02)max mem: 17.22449 GB 
[09/16 16:16:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.128, 0.1973 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 16:16:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 5.289, 0.2388 s / batch. (data: 1.98e-02)max mem: 17.22449 GB 
[09/16 16:16:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.379, 0.1830 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 16:16:49][INFO] visual_prompt:  324: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1931, average loss: 5.3719
[09/16 16:16:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 53.54	
[09/16 16:16:50][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/16 16:17:00][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.50e-01, avg batch time: 0.5509, average train loss: 10.1167
[09/16 16:17:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1625, average loss: 20.4078
[09/16 16:17:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 58.50	
[09/16 16:17:26][INFO] visual_prompt:  314: 	Test 100/407. loss: 24.320, 0.1827 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 16:17:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 27.055, 0.1858 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 16:18:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 19.042, 0.2040 s / batch. (data: 1.51e-03)max mem: 17.22449 GB 
[09/16 16:18:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 23.647, 0.1829 s / batch. (data: 4.82e-05)max mem: 17.22449 GB 
[09/16 16:18:27][INFO] visual_prompt:  324: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1929, average loss: 21.3714
[09/16 16:18:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 53.70	
[09/16 16:18:27][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[09/16 16:18:38][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.52e-01, avg batch time: 0.5527, average train loss: 21.8350
[09/16 16:18:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1425, average loss: 10.2393
[09/16 16:18:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 60.00	
[09/16 16:19:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 10.542, 0.2075 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 16:19:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.256, 0.1901 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 16:19:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 9.987, 0.2020 s / batch. (data: 2.05e-02)max mem: 17.22449 GB 
[09/16 16:20:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 10.044, 0.1829 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 16:20:06][INFO] visual_prompt:  324: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1932, average loss: 10.0812
[09/16 16:20:06][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 59.67	
[09/16 16:20:06][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 16:20:16][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 1.47e-01, avg batch time: 0.5504, average train loss: 12.2669
[09/16 16:20:21][INFO] visual_prompt:  324: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1424, average loss: 6.1223
[09/16 16:20:21][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 7.00	top5: 60.50	
[09/16 16:20:43][INFO] visual_prompt:  314: 	Test 100/407. loss: 6.982, 0.1828 s / batch. (data: 1.61e-04)max mem: 17.22449 GB 
[09/16 16:21:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.765, 0.1918 s / batch. (data: 7.21e-03)max mem: 17.22449 GB 
[09/16 16:21:22][INFO] visual_prompt:  314: 	Test 300/407. loss: 6.424, 0.2073 s / batch. (data: 2.51e-02)max mem: 17.22449 GB 
[09/16 16:21:41][INFO] visual_prompt:  314: 	Test 400/407. loss: 6.370, 0.1879 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 16:21:45][INFO] visual_prompt:  324: Inference (test):avg data time: 8.93e-03, avg batch time: 0.1948, average loss: 6.3874
[09/16 16:21:45][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.70	top5: 55.54	
[09/16 16:21:45][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 16:21:55][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.54e-01, avg batch time: 0.5547, average train loss: 7.1135
[09/16 16:22:00][INFO] visual_prompt:  324: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1422, average loss: 5.8366
[09/16 16:22:00][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 55.00	
[09/16 16:22:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 6.817, 0.1959 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 16:22:41][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.196, 0.1829 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 16:23:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 6.945, 0.2027 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 16:23:20][INFO] visual_prompt:  314: 	Test 400/407. loss: 6.041, 0.1827 s / batch. (data: 2.74e-05)max mem: 17.22449 GB 
[09/16 16:23:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1945, average loss: 6.2507
[09/16 16:23:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.76	top5: 51.31	
[09/16 16:23:23][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 16:23:34][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 1.46e-01, avg batch time: 0.5493, average train loss: 4.5398
[09/16 16:23:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1422, average loss: 4.5623
[09/16 16:23:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 41.00	
[09/16 16:24:00][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.975, 0.2073 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 16:24:20][INFO] visual_prompt:  314: 	Test 200/407. loss: 4.466, 0.2014 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 16:24:39][INFO] visual_prompt:  314: 	Test 300/407. loss: 4.087, 0.1834 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 16:24:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 4.672, 0.1822 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 16:25:02][INFO] visual_prompt:  324: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1927, average loss: 4.4083
[09/16 16:25:02][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 45.21	
[09/16 16:25:02][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 16:25:12][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.44e-01, avg batch time: 0.5458, average train loss: 3.6992
[09/16 16:25:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1425, average loss: 4.6001
[09/16 16:25:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.00	
[09/16 16:25:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 5.835, 0.2379 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 16:25:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 5.547, 0.1963 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 16:26:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 4.893, 0.1829 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 16:26:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.487, 0.1828 s / batch. (data: 5.17e-05)max mem: 17.22449 GB 
[09/16 16:26:40][INFO] visual_prompt:  324: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1932, average loss: 4.9088
[09/16 16:26:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.90	
[09/16 16:26:40][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 16:26:50][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 1.44e-01, avg batch time: 0.5477, average train loss: 3.2496
[09/16 16:26:55][INFO] visual_prompt:  324: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1423, average loss: 2.3396
[09/16 16:26:55][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.00	
[09/16 16:27:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.549, 0.1955 s / batch. (data: 1.19e-02)max mem: 17.22449 GB 
[09/16 16:27:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.521, 0.2063 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 16:27:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.403, 0.1835 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 16:28:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.472, 0.1833 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 16:28:18][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1923, average loss: 2.3934
[09/16 16:28:18][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 58.70	
[09/16 16:28:18][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 16:28:28][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.59e-01, avg batch time: 0.5591, average train loss: 2.5561
[09/16 16:28:33][INFO] visual_prompt:  324: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1446, average loss: 2.6072
[09/16 16:28:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.50	top5: 58.50	
[09/16 16:28:55][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.868, 0.1959 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 16:29:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.861, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 16:29:34][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.739, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 16:29:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.823, 0.1825 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 16:29:57][INFO] visual_prompt:  324: Inference (test):avg data time: 9.22e-03, avg batch time: 0.1948, average loss: 2.7210
[09/16 16:29:57][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.67	top5: 55.89	
[09/16 16:29:57][INFO] visual_prompt:  246: Best epoch 17: best metric: 0.235
[09/16 16:29:57][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 16:30:07][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.45e-01, avg batch time: 0.5467, average train loss: 2.5612
[09/16 16:30:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1424, average loss: 2.6550
[09/16 16:30:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.50	
[09/16 16:30:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.874, 0.2095 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 16:30:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.024, 0.1829 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 16:31:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.485, 0.1965 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 16:31:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.745, 0.1821 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 16:31:35][INFO] visual_prompt:  324: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1939, average loss: 2.6713
[09/16 16:31:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 60.73	
[09/16 16:31:35][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 16:31:45][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 1.51e-01, avg batch time: 0.5530, average train loss: 2.7275
[09/16 16:31:50][INFO] visual_prompt:  324: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2016, average loss: 3.3019
[09/16 16:31:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 52.50	
[09/16 16:32:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.149, 0.1826 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 16:32:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.357, 0.2096 s / batch. (data: 2.80e-02)max mem: 17.22449 GB 
[09/16 16:32:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.549, 0.2198 s / batch. (data: 3.74e-02)max mem: 17.22449 GB 
[09/16 16:33:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.653, 0.1822 s / batch. (data: 3.77e-05)max mem: 17.22449 GB 
[09/16 16:33:13][INFO] visual_prompt:  324: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1935, average loss: 3.3894
[09/16 16:33:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 49.53	
[09/16 16:33:13][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 16:33:24][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.42e-01, avg batch time: 0.5429, average train loss: 3.6737
[09/16 16:33:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1453, average loss: 2.7508
[09/16 16:33:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 62.50	
[09/16 16:33:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.882, 0.1823 s / batch. (data: 9.73e-05)max mem: 17.22449 GB 
[09/16 16:34:09][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.844, 0.1965 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 16:34:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.785, 0.1825 s / batch. (data: 9.37e-05)max mem: 17.22449 GB 
[09/16 16:34:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.651, 0.1828 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 16:34:52][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1942, average loss: 2.6947
[09/16 16:34:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 62.99	
[09/16 16:34:52][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 16:35:02][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.51e-01, avg batch time: 0.5509, average train loss: 2.9752
[09/16 16:35:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1424, average loss: 3.1214
[09/16 16:35:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 60.00	
[09/16 16:35:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.164, 0.1825 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 16:35:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.079, 0.2066 s / batch. (data: 2.42e-02)max mem: 17.22449 GB 
[09/16 16:36:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.284, 0.1947 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 16:36:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.066, 0.1828 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 16:36:31][INFO] visual_prompt:  324: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1950, average loss: 3.1347
[09/16 16:36:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 56.57	
[09/16 16:36:31][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 16:36:41][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 1.52e-01, avg batch time: 0.5538, average train loss: 3.1688
[09/16 16:36:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1424, average loss: 3.1405
[09/16 16:36:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 50.50	
[09/16 16:37:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.395, 0.1970 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 16:37:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.340, 0.1824 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 16:37:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.436, 0.1834 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 16:38:06][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.422, 0.1828 s / batch. (data: 3.50e-05)max mem: 17.22449 GB 
[09/16 16:38:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1921, average loss: 3.1933
[09/16 16:38:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 48.48	
[09/16 16:38:09][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 16:38:19][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.51e-01, avg batch time: 0.5553, average train loss: 2.7503
[09/16 16:38:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1425, average loss: 3.1015
[09/16 16:38:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.50	
[09/16 16:38:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.640, 0.1979 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 16:39:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.626, 0.1984 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 16:39:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.143, 0.1827 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 16:39:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.382, 0.1824 s / batch. (data: 4.05e-05)max mem: 17.22449 GB 
[09/16 16:39:47][INFO] visual_prompt:  324: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1934, average loss: 3.1496
[09/16 16:39:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.67	
[09/16 16:39:47][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 16:39:58][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 1.61e-01, avg batch time: 0.5636, average train loss: 2.9283
[09/16 16:40:02][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1425, average loss: 2.7438
[09/16 16:40:02][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.50	
[09/16 16:40:24][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.503, 0.2084 s / batch. (data: 2.69e-02)max mem: 17.22449 GB 
[09/16 16:40:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.140, 0.1890 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 16:41:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.884, 0.1846 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 16:41:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.711, 0.1823 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 16:41:26][INFO] visual_prompt:  324: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1941, average loss: 2.8537
[09/16 16:41:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.94	
[09/16 16:41:26][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 16:41:37][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 1.50e-01, avg batch time: 0.5685, average train loss: 2.8010
[09/16 16:41:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1426, average loss: 2.7718
[09/16 16:41:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.50	
[09/16 16:42:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.072, 0.2111 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 16:42:22][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.120, 0.1829 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 16:42:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.704, 0.1823 s / batch. (data: 1.72e-04)max mem: 17.22449 GB 
[09/16 16:43:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.927, 0.1829 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 16:43:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1929, average loss: 2.8337
[09/16 16:43:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 56.36	
[09/16 16:43:04][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 16:43:15][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.43e-01, avg batch time: 0.5459, average train loss: 2.5458
[09/16 16:43:19][INFO] visual_prompt:  324: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1427, average loss: 2.3702
[09/16 16:43:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 63.00	
[09/16 16:43:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.693, 0.1821 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 16:44:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.663, 0.1821 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 16:44:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.336, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 16:44:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.472, 0.1820 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 16:44:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1935, average loss: 2.4230
[09/16 16:44:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 62.57	
[09/16 16:44:42][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 16:44:53][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 1.49e-01, avg batch time: 0.5569, average train loss: 2.5199
[09/16 16:44:58][INFO] visual_prompt:  324: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1425, average loss: 2.5475
[09/16 16:44:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.50	
[09/16 16:45:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.118, 0.1904 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 16:45:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.875, 0.1838 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 16:45:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.750, 0.1956 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 16:46:17][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.685, 0.1831 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 16:46:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1926, average loss: 2.6832
[09/16 16:46:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.63	
[09/16 16:46:21][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 16:46:31][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 1.52e-01, avg batch time: 0.5538, average train loss: 2.5894
[09/16 16:46:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1425, average loss: 2.6015
[09/16 16:46:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 14.00	top5: 58.00	
[09/16 16:46:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.785, 0.1863 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 16:47:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.749, 0.1825 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 16:47:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.741, 0.1864 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 16:47:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.743, 0.1877 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 16:47:59][INFO] visual_prompt:  324: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1938, average loss: 2.6877
[09/16 16:47:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 10.83	top5: 54.48	
[09/16 16:47:59][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 16:48:10][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.48e-01, avg batch time: 0.5787, average train loss: 2.4427
[09/16 16:48:15][INFO] visual_prompt:  324: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1426, average loss: 2.3305
[09/16 16:48:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.50	top5: 56.50	
[09/16 16:48:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.501, 0.2071 s / batch. (data: 1.96e-02)max mem: 17.22449 GB 
[09/16 16:48:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.406, 0.1828 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 16:49:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.473, 0.1827 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 16:49:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.372, 0.1820 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 16:49:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1930, average loss: 2.3797
[09/16 16:49:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 10.99	top5: 53.30	
[09/16 16:49:38][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 16:49:48][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 1.33e-01, avg batch time: 0.5449, average train loss: 2.5191
[09/16 16:49:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1425, average loss: 2.6437
[09/16 16:49:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 54.00	
[09/16 16:50:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.702, 0.1822 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 16:50:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.520, 0.1938 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 16:50:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.806, 0.1944 s / batch. (data: 1.48e-04)max mem: 17.22449 GB 
[09/16 16:51:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.641, 0.1830 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 16:51:16][INFO] visual_prompt:  324: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1941, average loss: 2.6490
[09/16 16:51:16][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.38	top5: 48.98	
[09/16 16:51:16][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 16:51:26][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 1.51e-01, avg batch time: 0.5521, average train loss: 2.4500
[09/16 16:51:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1426, average loss: 2.5335
[09/16 16:51:31][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 50.00	
[09/16 16:51:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.499, 0.1974 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 16:52:12][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.620, 0.1917 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 16:52:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.445, 0.1958 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 16:52:51][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.421, 0.1829 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 16:52:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1938, average loss: 2.5197
[09/16 16:52:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 53.61	
[09/16 16:52:55][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 16:53:05][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 1.45e-01, avg batch time: 0.5472, average train loss: 2.5314
[09/16 16:53:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1424, average loss: 2.5034
[09/16 16:53:10][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 7.00	top5: 53.50	
[09/16 16:53:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.508, 0.1825 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 16:53:51][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.469, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 16:54:10][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.681, 0.1823 s / batch. (data: 9.37e-05)max mem: 17.22449 GB 
[09/16 16:54:30][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.642, 0.1826 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 16:54:33][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1937, average loss: 2.5448
[09/16 16:54:33][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.70	top5: 51.51	
[09/16 16:54:33][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 16:54:44][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 1.51e-01, avg batch time: 0.5521, average train loss: 2.4091
[09/16 16:54:48][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1424, average loss: 2.3524
[09/16 16:54:48][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.00	
[09/16 16:55:10][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.710, 0.1978 s / batch. (data: 1.57e-02)max mem: 17.22449 GB 
[09/16 16:55:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.686, 0.2034 s / batch. (data: 2.17e-02)max mem: 17.22449 GB 
[09/16 16:55:49][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.366, 0.2971 s / batch. (data: 2.16e-04)max mem: 17.22449 GB 
[09/16 16:56:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.441, 0.1825 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 16:56:11][INFO] visual_prompt:  324: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1934, average loss: 2.4238
[09/16 16:56:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 63.35	
[09/16 16:56:11][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 16:56:22][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 1.51e-01, avg batch time: 0.5525, average train loss: 2.4530
[09/16 16:56:26][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1427, average loss: 2.4296
[09/16 16:56:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 60.00	
[09/16 16:56:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.445, 0.2072 s / batch. (data: 2.56e-02)max mem: 17.22449 GB 
[09/16 16:57:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.495, 0.2004 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 16:57:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.438, 0.1957 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 16:57:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.425, 0.1819 s / batch. (data: 3.48e-05)max mem: 17.22449 GB 
[09/16 16:57:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1931, average loss: 2.4130
[09/16 16:57:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 59.74	
[09/16 16:57:50][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 16:58:00][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 1.46e-01, avg batch time: 0.5500, average train loss: 2.5063
[09/16 16:58:05][INFO] visual_prompt:  324: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1427, average loss: 2.5259
[09/16 16:58:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 63.50	
[09/16 16:58:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.734, 0.1891 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 16:58:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.865, 0.1826 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 16:59:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.260, 0.1841 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 16:59:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.542, 0.1826 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 16:59:28][INFO] visual_prompt:  324: Inference (test):avg data time: 7.10e-03, avg batch time: 0.1923, average loss: 2.5736
[09/16 16:59:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.76	top5: 61.95	
[09/16 16:59:28][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 16:59:38][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 1.43e-01, avg batch time: 0.5500, average train loss: 2.4679
[09/16 16:59:43][INFO] visual_prompt:  324: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1423, average loss: 2.3304
[09/16 16:59:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 56.00	
[09/16 17:00:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.281, 0.1960 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 17:00:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.364, 0.1929 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 17:00:44][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.242, 0.2152 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 17:01:03][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.337, 0.1828 s / batch. (data: 3.41e-05)max mem: 17.22449 GB 
[09/16 17:01:07][INFO] visual_prompt:  324: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1948, average loss: 2.3160
[09/16 17:01:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 57.19	
[09/16 17:01:07][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 17:01:17][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.44e-01, avg batch time: 0.5472, average train loss: 2.4261
[09/16 17:01:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1427, average loss: 2.3411
[09/16 17:01:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 11.00	top5: 60.00	
[09/16 17:01:43][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.492, 0.1880 s / batch. (data: 6.40e-03)max mem: 17.22449 GB 
[09/16 17:02:04][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.450, 0.1918 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 17:02:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.325, 0.1823 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 17:02:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.324, 0.1973 s / batch. (data: 3.72e-05)max mem: 17.22449 GB 
[09/16 17:02:45][INFO] visual_prompt:  324: Inference (test):avg data time: 6.78e-03, avg batch time: 0.1945, average loss: 2.3884
[09/16 17:02:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 8.43	top5: 55.70	
[09/16 17:02:46][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 17:02:56][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 1.33e-01, avg batch time: 0.5388, average train loss: 2.5011
[09/16 17:03:00][INFO] visual_prompt:  324: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1426, average loss: 2.4606
[09/16 17:03:00][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.00	
[09/16 17:03:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.628, 0.1824 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 17:03:41][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.764, 0.1965 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 17:04:01][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.234, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 17:04:20][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.390, 0.1819 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 17:04:23][INFO] visual_prompt:  324: Inference (test):avg data time: 8.54e-03, avg batch time: 0.1931, average loss: 2.4773
[09/16 17:04:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 62.00	
[09/16 17:04:23][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 17:04:34][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 1.48e-01, avg batch time: 0.5836, average train loss: 2.4584
[09/16 17:04:39][INFO] visual_prompt:  324: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1463, average loss: 3.2796
[09/16 17:04:39][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.50	
[09/16 17:05:01][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.058, 0.1827 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 17:05:20][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.767, 0.1880 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 17:05:40][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.509, 0.1882 s / batch. (data: 1.61e-04)max mem: 17.22449 GB 
[09/16 17:05:59][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.589, 0.1827 s / batch. (data: 3.89e-05)max mem: 17.22449 GB 
[09/16 17:06:02][INFO] visual_prompt:  324: Inference (test):avg data time: 6.72e-03, avg batch time: 0.1932, average loss: 3.4105
[09/16 17:06:02][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 53.43	
[09/16 17:06:02][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 17:06:13][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 1.59e-01, avg batch time: 0.5604, average train loss: 3.4911
[09/16 17:06:17][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1423, average loss: 4.1397
[09/16 17:06:17][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 42.50	
[09/16 17:06:39][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.110, 0.1823 s / batch. (data: 1.00e-04)max mem: 17.22449 GB 
[09/16 17:06:59][INFO] visual_prompt:  314: 	Test 200/407. loss: 4.439, 0.1974 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 17:07:18][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.967, 0.1962 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 17:07:38][INFO] visual_prompt:  314: 	Test 400/407. loss: 4.483, 0.1835 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 17:07:41][INFO] visual_prompt:  324: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1939, average loss: 4.1818
[09/16 17:07:41][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 41.06	
[09/16 17:07:41][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 3.75
[09/16 17:07:52][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 1.51e-01, avg batch time: 0.5506, average train loss: 3.1485
[09/16 17:07:56][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1426, average loss: 2.6152
[09/16 17:07:56][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 61.00	
[09/16 17:08:18][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.711, 0.1901 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 17:08:37][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.765, 0.1825 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 17:08:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.663, 0.1982 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 17:09:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.678, 0.1828 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 17:09:19][INFO] visual_prompt:  324: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1936, average loss: 2.6849
[09/16 17:09:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 57.26	
[09/16 17:09:19][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 17:09:30][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 1.55e-01, avg batch time: 0.5559, average train loss: 2.5953
[09/16 17:09:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1425, average loss: 2.4435
[09/16 17:09:34][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.00	
[09/16 17:09:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.546, 0.1824 s / batch. (data: 4.22e-05)max mem: 17.22449 GB 
[09/16 17:10:15][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.531, 0.1968 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 17:10:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.431, 0.2022 s / batch. (data: 1.64e-02)max mem: 17.22449 GB 
[09/16 17:10:54][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.395, 0.1824 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 17:10:57][INFO] visual_prompt:  324: Inference (test):avg data time: 6.85e-03, avg batch time: 0.1932, average loss: 2.4448
[09/16 17:10:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 63.05	
[09/16 17:10:58][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 17:11:08][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 1.47e-01, avg batch time: 0.5482, average train loss: 2.4956
[09/16 17:11:13][INFO] visual_prompt:  324: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1426, average loss: 2.7379
[09/16 17:11:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 7.00	top5: 39.50	
[09/16 17:11:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.671, 0.1962 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 17:11:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.709, 0.1850 s / batch. (data: 4.67e-05)max mem: 17.22449 GB 
[09/16 17:12:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.604, 0.2077 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 17:12:33][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.669, 0.1820 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 17:12:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1941, average loss: 2.6974
[09/16 17:12:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.52	top5: 42.90	
[09/16 17:12:37][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 17:12:47][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 1.43e-01, avg batch time: 0.5458, average train loss: 2.7080
[09/16 17:12:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1427, average loss: 2.5212
[09/16 17:12:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 62.50	
[09/16 17:13:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.955, 0.2026 s / batch. (data: 2.04e-02)max mem: 17.22449 GB 
[09/16 17:13:33][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.889, 0.2066 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 17:13:52][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.417, 0.1927 s / batch. (data: 1.56e-04)max mem: 17.22449 GB 
[09/16 17:14:12][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.536, 0.1830 s / batch. (data: 3.65e-05)max mem: 17.22449 GB 
[09/16 17:14:15][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1941, average loss: 2.5643
[09/16 17:14:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 61.05	
[09/16 17:14:15][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 17:14:25][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.51e-01, avg batch time: 0.5520, average train loss: 2.5883
[09/16 17:14:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1425, average loss: 2.5911
[09/16 17:14:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 62.50	
[09/16 17:14:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.902, 0.2081 s / batch. (data: 2.64e-02)max mem: 17.22449 GB 
[09/16 17:15:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.880, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 17:15:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.590, 0.1846 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 17:15:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.626, 0.1826 s / batch. (data: 4.17e-05)max mem: 17.22449 GB 
[09/16 17:15:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1932, average loss: 2.5856
[09/16 17:15:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.50	top5: 62.99	
[09/16 17:15:53][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 17:16:04][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.56e-01, avg batch time: 0.5619, average train loss: 2.4436
[09/16 17:16:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1447, average loss: 2.5456
[09/16 17:16:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.00	
[09/16 17:16:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.041, 0.1966 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 17:16:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.964, 0.1941 s / batch. (data: 3.75e-03)max mem: 17.22449 GB 
[09/16 17:17:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.496, 0.1953 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 17:17:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.750, 0.1825 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 17:17:31][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1926, average loss: 2.6465
[09/16 17:17:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 53.79	
[09/16 17:17:31][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 17:17:42][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 1.53e-01, avg batch time: 0.5559, average train loss: 2.3785
[09/16 17:17:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1424, average loss: 2.3675
[09/16 17:17:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 59.50	
[09/16 17:18:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.624, 0.2074 s / batch. (data: 2.54e-02)max mem: 17.22449 GB 
[09/16 17:18:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.584, 0.1884 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 17:18:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.388, 0.1832 s / batch. (data: 1.48e-04)max mem: 17.22449 GB 
[09/16 17:19:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.426, 0.1822 s / batch. (data: 3.41e-05)max mem: 17.22449 GB 
[09/16 17:19:10][INFO] visual_prompt:  324: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1944, average loss: 2.4144
[09/16 17:19:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 54.33	
[09/16 17:19:10][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 17:19:20][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 1.52e-01, avg batch time: 0.5529, average train loss: 2.3244
[09/16 17:19:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1424, average loss: 2.3929
[09/16 17:19:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 62.00	
[09/16 17:19:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.634, 0.2088 s / batch. (data: 2.70e-02)max mem: 17.22449 GB 
[09/16 17:20:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.573, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 17:20:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.294, 0.1827 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 17:20:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.421, 0.1962 s / batch. (data: 4.94e-05)max mem: 17.22449 GB 
[09/16 17:20:48][INFO] visual_prompt:  324: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1932, average loss: 2.3974
[09/16 17:20:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 60.89	
[09/16 17:20:48][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 17:20:58][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 1.53e-01, avg batch time: 0.5539, average train loss: 2.4053
[09/16 17:21:03][INFO] visual_prompt:  324: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1424, average loss: 2.2986
[09/16 17:21:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 17:21:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.321, 0.1966 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 17:21:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.383, 0.2177 s / batch. (data: 3.56e-02)max mem: 17.22449 GB 
[09/16 17:22:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.186, 0.1977 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 17:22:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.229, 0.1825 s / batch. (data: 2.53e-05)max mem: 17.22449 GB 
[09/16 17:22:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1934, average loss: 2.2759
[09/16 17:22:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 65.46	
[09/16 17:22:26][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 17:22:37][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 1.50e-01, avg batch time: 0.5517, average train loss: 2.3591
[09/16 17:22:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1425, average loss: 2.3826
[09/16 17:22:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 14.00	top5: 58.50	
[09/16 17:23:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.514, 0.1955 s / batch. (data: 1.28e-02)max mem: 17.22449 GB 
[09/16 17:23:22][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.559, 0.1825 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 17:23:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.264, 0.1834 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 17:24:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.398, 0.1831 s / batch. (data: 2.96e-05)max mem: 17.22449 GB 
[09/16 17:24:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1930, average loss: 2.3996
[09/16 17:24:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 17.06	top5: 57.58	
[09/16 17:24:04][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 17:24:15][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.51e-01, avg batch time: 0.5543, average train loss: 2.3582
[09/16 17:24:19][INFO] visual_prompt:  324: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1425, average loss: 2.4110
[09/16 17:24:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 17:24:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.584, 0.1830 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 17:25:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.634, 0.1965 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 17:25:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.306, 0.1821 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 17:25:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.347, 0.1827 s / batch. (data: 4.20e-05)max mem: 17.22449 GB 
[09/16 17:25:44][INFO] visual_prompt:  324: Inference (test):avg data time: 8.74e-03, avg batch time: 0.1957, average loss: 2.4288
[09/16 17:25:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 63.51	
[09/16 17:25:44][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 17:25:54][INFO] visual_prompt:  219: Epoch 52 / 100: avg data time: 1.58e-01, avg batch time: 0.5593, average train loss: 2.3410
[09/16 17:25:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1425, average loss: 2.3231
[09/16 17:25:59][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.50	
[09/16 17:26:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.601, 0.1881 s / batch. (data: 5.95e-03)max mem: 17.22449 GB 
[09/16 17:26:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.464, 0.1832 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 17:26:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.418, 0.2080 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 17:27:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.426, 0.1826 s / batch. (data: 3.65e-05)max mem: 17.22449 GB 
[09/16 17:27:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1932, average loss: 2.3724
[09/16 17:27:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.64	
[09/16 17:27:22][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 17:27:32][INFO] visual_prompt:  219: Epoch 53 / 100: avg data time: 1.49e-01, avg batch time: 0.5520, average train loss: 2.3977
[09/16 17:27:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1426, average loss: 2.4661
[09/16 17:27:37][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 60.50	
[09/16 17:27:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.641, 0.1825 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 17:28:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.703, 0.2133 s / batch. (data: 3.17e-02)max mem: 17.22449 GB 
[09/16 17:28:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.425, 0.1968 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 17:28:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.562, 0.1826 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 17:29:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1935, average loss: 2.4823
[09/16 17:29:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 61.97	
[09/16 17:29:00][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 17:29:11][INFO] visual_prompt:  219: Epoch 54 / 100: avg data time: 1.55e-01, avg batch time: 0.5577, average train loss: 2.3889
[09/16 17:29:15][INFO] visual_prompt:  324: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1426, average loss: 2.3598
[09/16 17:29:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.50	top5: 58.00	
[09/16 17:29:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.386, 0.1865 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 17:29:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.372, 0.1826 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 17:30:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.422, 0.1951 s / batch. (data: 1.27e-02)max mem: 17.22449 GB 
[09/16 17:30:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.378, 0.1829 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 17:30:39][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1931, average loss: 2.3989
[09/16 17:30:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 8.79	top5: 54.48	
[09/16 17:30:39][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 17:30:49][INFO] visual_prompt:  219: Epoch 55 / 100: avg data time: 1.58e-01, avg batch time: 0.5574, average train loss: 2.3297
[09/16 17:30:54][INFO] visual_prompt:  324: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1491, average loss: 2.3228
[09/16 17:30:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 20.00	top5: 63.00	
[09/16 17:31:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.537, 0.1881 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 17:31:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.552, 0.1947 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 17:31:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.286, 0.1952 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 17:32:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.435, 0.1832 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 17:32:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1937, average loss: 2.3554
[09/16 17:32:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.74	top5: 62.45	
[09/16 17:32:17][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 2.5
[09/16 17:32:28][INFO] visual_prompt:  219: Epoch 56 / 100: avg data time: 1.49e-01, avg batch time: 0.5521, average train loss: 2.3825
[09/16 17:32:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1427, average loss: 2.4019
[09/16 17:32:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 55.50	
[09/16 17:32:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.538, 0.1828 s / batch. (data: 9.85e-05)max mem: 17.22449 GB 
[09/16 17:33:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.608, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 17:33:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.363, 0.1824 s / batch. (data: 3.67e-05)max mem: 17.22449 GB 
[09/16 17:33:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.563, 0.1826 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 17:33:56][INFO] visual_prompt:  324: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1932, average loss: 2.4596
[09/16 17:33:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 56.13	
[09/16 17:33:56][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 17:34:06][INFO] visual_prompt:  219: Epoch 57 / 100: avg data time: 1.52e-01, avg batch time: 0.5552, average train loss: 2.3666
[09/16 17:34:11][INFO] visual_prompt:  324: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1426, average loss: 2.2641
[09/16 17:34:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.50	
[09/16 17:34:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.567, 0.2235 s / batch. (data: 2.61e-02)max mem: 17.22449 GB 
[09/16 17:34:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.522, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 17:35:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.313, 0.2027 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 17:35:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.367, 0.1827 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 17:35:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1938, average loss: 2.3180
[09/16 17:35:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 65.45	
[09/16 17:35:35][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 17:35:45][INFO] visual_prompt:  219: Epoch 58 / 100: avg data time: 1.58e-01, avg batch time: 0.5601, average train loss: 2.3175
[09/16 17:35:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1426, average loss: 2.4838
[09/16 17:35:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.50	
[09/16 17:36:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.599, 0.1835 s / batch. (data: 1.52e-04)max mem: 17.22449 GB 
[09/16 17:36:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.675, 0.1971 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 17:36:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.480, 0.1957 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 17:37:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.518, 0.1830 s / batch. (data: 3.00e-05)max mem: 17.22449 GB 
[09/16 17:37:13][INFO] visual_prompt:  324: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1941, average loss: 2.4763
[09/16 17:37:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 61.07	
[09/16 17:37:13][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 17:37:24][INFO] visual_prompt:  219: Epoch 59 / 100: avg data time: 1.52e-01, avg batch time: 0.5557, average train loss: 2.3710
[09/16 17:37:29][INFO] visual_prompt:  324: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1426, average loss: 2.3259
[09/16 17:37:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.00	
[09/16 17:37:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.683, 0.1979 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 17:38:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.559, 0.1830 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 17:38:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.445, 0.1822 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 17:38:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.342, 0.1822 s / batch. (data: 3.96e-05)max mem: 17.22449 GB 
[09/16 17:38:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1938, average loss: 2.4048
[09/16 17:38:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.81	
[09/16 17:38:52][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 17:39:03][INFO] visual_prompt:  219: Epoch 60 / 100: avg data time: 1.43e-01, avg batch time: 0.5446, average train loss: 2.3298
[09/16 17:39:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1425, average loss: 2.2533
[09/16 17:39:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 27.50	top5: 67.00	
[09/16 17:39:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.370, 0.1983 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 17:39:48][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.408, 0.1975 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 17:40:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.187, 0.1937 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 17:40:27][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.238, 0.1830 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 17:40:31][INFO] visual_prompt:  324: Inference (test):avg data time: 8.49e-03, avg batch time: 0.1940, average loss: 2.2615
[09/16 17:40:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 25.30	top5: 65.52	
[09/16 17:40:31][INFO] visual_prompt:  246: Best epoch 60: best metric: 0.275
[09/16 17:40:31][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 17:40:41][INFO] visual_prompt:  219: Epoch 61 / 100: avg data time: 1.55e-01, avg batch time: 0.5588, average train loss: 2.3231
[09/16 17:40:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1424, average loss: 2.3634
[09/16 17:40:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 64.00	
[09/16 17:41:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.436, 0.1829 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 17:41:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.400, 0.2071 s / batch. (data: 2.24e-02)max mem: 17.22449 GB 
[09/16 17:41:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.461, 0.1829 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 17:42:05][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.382, 0.1825 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 17:42:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1922, average loss: 2.3674
[09/16 17:42:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 61.95	
[09/16 17:42:09][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 17:42:19][INFO] visual_prompt:  219: Epoch 62 / 100: avg data time: 1.45e-01, avg batch time: 0.5481, average train loss: 2.2872
[09/16 17:42:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1425, average loss: 2.2992
[09/16 17:42:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 63.00	
[09/16 17:42:45][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.723, 0.1826 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 17:43:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.614, 0.1838 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 17:43:24][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.446, 0.1829 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 17:43:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.504, 0.1823 s / batch. (data: 6.96e-05)max mem: 17.22449 GB 
[09/16 17:43:47][INFO] visual_prompt:  324: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1932, average loss: 2.4044
[09/16 17:43:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.66	top5: 56.02	
[09/16 17:43:47][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 17:43:57][INFO] visual_prompt:  219: Epoch 63 / 100: avg data time: 1.48e-01, avg batch time: 0.5519, average train loss: 2.3865
[09/16 17:44:02][INFO] visual_prompt:  324: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1427, average loss: 2.4261
[09/16 17:44:02][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 65.50	
[09/16 17:44:24][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.650, 0.1942 s / batch. (data: 1.24e-02)max mem: 17.22449 GB 
[09/16 17:44:43][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.601, 0.1834 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 17:45:02][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.378, 0.1827 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 17:45:22][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.427, 0.1824 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 17:45:25][INFO] visual_prompt:  324: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1934, average loss: 2.4823
[09/16 17:45:25][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.90	
[09/16 17:45:25][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 17:45:36][INFO] visual_prompt:  219: Epoch 64 / 100: avg data time: 1.57e-01, avg batch time: 0.5580, average train loss: 2.4772
[09/16 17:45:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1427, average loss: 2.3566
[09/16 17:45:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 63.50	
[09/16 17:46:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.421, 0.1953 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 17:46:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.474, 0.1887 s / batch. (data: 1.40e-04)max mem: 17.22449 GB 
[09/16 17:46:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.245, 0.1829 s / batch. (data: 9.80e-05)max mem: 17.22449 GB 
[09/16 17:47:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.328, 0.1825 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 17:47:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1959, average loss: 2.3842
[09/16 17:47:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.76	top5: 61.95	
[09/16 17:47:05][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 17:47:16][INFO] visual_prompt:  219: Epoch 65 / 100: avg data time: 1.58e-01, avg batch time: 0.5586, average train loss: 2.3695
[09/16 17:47:20][INFO] visual_prompt:  324: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1425, average loss: 2.2514
[09/16 17:47:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 26.00	top5: 66.50	
[09/16 17:47:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.314, 0.1822 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 17:48:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.383, 0.2075 s / batch. (data: 2.53e-02)max mem: 17.22449 GB 
[09/16 17:48:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.197, 0.1952 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 17:48:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.257, 0.1938 s / batch. (data: 3.48e-05)max mem: 17.22449 GB 
[09/16 17:48:44][INFO] visual_prompt:  324: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1931, average loss: 2.2657
[09/16 17:48:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 22.44	top5: 66.93	
[09/16 17:48:44][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 17:48:54][INFO] visual_prompt:  219: Epoch 66 / 100: avg data time: 1.60e-01, avg batch time: 0.5608, average train loss: 2.3403
[09/16 17:48:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1422, average loss: 2.2821
[09/16 17:48:59][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 17:49:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.321, 0.1966 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 17:49:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.402, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 17:50:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.167, 0.1958 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 17:50:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.216, 0.1830 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 17:50:23][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1942, average loss: 2.2825
[09/16 17:50:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.03	top5: 64.41	
[09/16 17:50:23][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 17:50:33][INFO] visual_prompt:  219: Epoch 67 / 100: avg data time: 1.59e-01, avg batch time: 0.5594, average train loss: 2.2389
[09/16 17:50:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1423, average loss: 2.1601
[09/16 17:50:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.50	top5: 62.50	
[09/16 17:50:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.371, 0.1958 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 17:51:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.380, 0.1893 s / batch. (data: 4.59e-03)max mem: 17.22449 GB 
[09/16 17:51:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.177, 0.1947 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 17:51:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.294, 0.1823 s / batch. (data: 2.79e-05)max mem: 17.22449 GB 
[09/16 17:52:01][INFO] visual_prompt:  324: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1931, average loss: 2.2330
[09/16 17:52:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 25.09	top5: 58.07	
[09/16 17:52:01][INFO] visual_prompt:  246: Best epoch 67: best metric: 0.295
[09/16 17:52:01][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 17:52:11][INFO] visual_prompt:  219: Epoch 68 / 100: avg data time: 1.58e-01, avg batch time: 0.5576, average train loss: 2.2735
[09/16 17:52:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1431, average loss: 2.1673
[09/16 17:52:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.00	top5: 66.00	
[09/16 17:52:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.380, 0.1825 s / batch. (data: 4.72e-05)max mem: 17.22449 GB 
[09/16 17:52:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.383, 0.1830 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 17:53:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.189, 0.1969 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 17:53:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.311, 0.1827 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 17:53:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1925, average loss: 2.2237
[09/16 17:53:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 25.30	top5: 64.79	
[09/16 17:53:39][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 17:53:49][INFO] visual_prompt:  219: Epoch 69 / 100: avg data time: 1.61e-01, avg batch time: 0.5608, average train loss: 2.2357
[09/16 17:53:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1424, average loss: 2.2532
[09/16 17:53:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 10.00	top5: 65.50	
[09/16 17:54:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.371, 0.1821 s / batch. (data: 9.70e-05)max mem: 17.22449 GB 
[09/16 17:54:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.338, 0.1830 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 17:54:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.335, 0.2121 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 17:55:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.304, 0.1829 s / batch. (data: 2.46e-05)max mem: 17.22449 GB 
[09/16 17:55:17][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1943, average loss: 2.2697
[09/16 17:55:18][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.24	top5: 62.26	
[09/16 17:55:18][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 17:55:28][INFO] visual_prompt:  219: Epoch 70 / 100: avg data time: 1.52e-01, avg batch time: 0.5572, average train loss: 2.2381
[09/16 17:55:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1425, average loss: 2.1100
[09/16 17:55:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 27.50	top5: 67.50	
[09/16 17:55:55][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.264, 0.1964 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 17:56:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.283, 0.1818 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 17:56:34][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.162, 0.2075 s / batch. (data: 2.58e-02)max mem: 17.22449 GB 
[09/16 17:56:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.211, 0.1826 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 17:56:56][INFO] visual_prompt:  324: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1944, average loss: 2.1557
[09/16 17:56:57][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 24.74	top5: 65.43	
[09/16 17:56:57][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 17:57:07][INFO] visual_prompt:  219: Epoch 71 / 100: avg data time: 1.52e-01, avg batch time: 0.5529, average train loss: 2.1742
[09/16 17:57:12][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1425, average loss: 2.0975
[09/16 17:57:12][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 14.50	top5: 74.00	
[09/16 17:57:34][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.261, 0.1820 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 17:57:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.183, 0.1964 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 17:58:13][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.236, 0.2297 s / batch. (data: 2.18e-04)max mem: 17.22449 GB 
[09/16 17:58:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.194, 0.1834 s / batch. (data: 4.05e-05)max mem: 17.22449 GB 
[09/16 17:58:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1948, average loss: 2.1249
[09/16 17:58:36][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 14.72	top5: 72.41	
[09/16 17:58:36][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 17:58:46][INFO] visual_prompt:  219: Epoch 72 / 100: avg data time: 1.47e-01, avg batch time: 0.5484, average train loss: 2.1042
[09/16 17:58:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1422, average loss: 1.9440
[09/16 17:58:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 35.50	top5: 76.00	
[09/16 17:59:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.214, 0.1969 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 17:59:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.268, 0.1827 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 17:59:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.923, 0.1918 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 18:00:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.076, 0.1827 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 18:00:14][INFO] visual_prompt:  324: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1931, average loss: 2.0213
[09/16 18:00:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 32.04	top5: 75.12	
[09/16 18:00:14][INFO] visual_prompt:  246: Best epoch 72: best metric: 0.355
[09/16 18:00:14][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 18:00:24][INFO] visual_prompt:  219: Epoch 73 / 100: avg data time: 1.42e-01, avg batch time: 0.5487, average train loss: 2.0031
[09/16 18:00:29][INFO] visual_prompt:  324: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1424, average loss: 2.0953
[09/16 18:00:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 26.50	top5: 69.00	
[09/16 18:00:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.276, 0.1938 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 18:01:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.246, 0.1946 s / batch. (data: 1.27e-02)max mem: 17.22449 GB 
[09/16 18:01:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.103, 0.1955 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 18:01:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.149, 0.1828 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 18:01:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1932, average loss: 2.1974
[09/16 18:01:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 23.07	top5: 64.84	
[09/16 18:01:52][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 18:02:02][INFO] visual_prompt:  219: Epoch 74 / 100: avg data time: 1.52e-01, avg batch time: 0.5509, average train loss: 1.9063
[09/16 18:02:07][INFO] visual_prompt:  324: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1424, average loss: 1.8693
[09/16 18:02:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 34.50	top5: 78.00	
[09/16 18:02:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.180, 0.1906 s / batch. (data: 1.05e-04)max mem: 17.22449 GB 
[09/16 18:02:48][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.092, 0.2063 s / batch. (data: 2.47e-02)max mem: 17.22449 GB 
[09/16 18:03:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.893, 0.1978 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 18:03:27][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.038, 0.1832 s / batch. (data: 4.43e-05)max mem: 17.22449 GB 
[09/16 18:03:30][INFO] visual_prompt:  324: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1940, average loss: 1.9237
[09/16 18:03:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 30.22	top5: 75.74	
[09/16 18:03:30][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 18:03:41][INFO] visual_prompt:  219: Epoch 75 / 100: avg data time: 1.51e-01, avg batch time: 0.5532, average train loss: 1.8664
[09/16 18:03:45][INFO] visual_prompt:  324: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1436, average loss: 1.7422
[09/16 18:03:45][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 35.00	top5: 80.50	
[09/16 18:04:07][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.232, 0.1950 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 18:04:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.224, 0.1831 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 18:04:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.972, 0.2172 s / batch. (data: 3.56e-02)max mem: 17.22449 GB 
[09/16 18:05:05][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.023, 0.1838 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 18:05:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1935, average loss: 1.9697
[09/16 18:05:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 30.45	top5: 76.07	
[09/16 18:05:09][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 18:05:19][INFO] visual_prompt:  219: Epoch 76 / 100: avg data time: 1.57e-01, avg batch time: 0.5564, average train loss: 1.7321
[09/16 18:05:24][INFO] visual_prompt:  324: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1426, average loss: 1.6291
[09/16 18:05:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 40.00	top5: 88.00	
[09/16 18:05:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.993, 0.1951 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 18:06:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.972, 0.1958 s / batch. (data: 1.31e-02)max mem: 17.22449 GB 
[09/16 18:06:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.815, 0.2226 s / batch. (data: 4.09e-02)max mem: 17.22449 GB 
[09/16 18:06:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.931, 0.1826 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 18:06:48][INFO] visual_prompt:  324: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1939, average loss: 1.8220
[09/16 18:06:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 36.04	top5: 81.83	
[09/16 18:06:48][INFO] visual_prompt:  246: Best epoch 76: best metric: 0.400
[09/16 18:06:48][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 18:06:58][INFO] visual_prompt:  219: Epoch 77 / 100: avg data time: 1.42e-01, avg batch time: 0.5424, average train loss: 1.7684
[09/16 18:07:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1420, average loss: 1.6453
[09/16 18:07:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 40.00	top5: 85.50	
[09/16 18:07:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.107, 0.2095 s / batch. (data: 2.78e-02)max mem: 17.22449 GB 
[09/16 18:07:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.186, 0.1949 s / batch. (data: 1.54e-04)max mem: 17.22449 GB 
[09/16 18:08:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.768, 0.2065 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 18:08:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.902, 0.1822 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 18:08:27][INFO] visual_prompt:  324: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1940, average loss: 1.8907
[09/16 18:08:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 35.79	top5: 77.29	
[09/16 18:08:27][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 18:08:37][INFO] visual_prompt:  219: Epoch 78 / 100: avg data time: 1.55e-01, avg batch time: 0.5555, average train loss: 1.6582
[09/16 18:08:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1423, average loss: 1.6338
[09/16 18:08:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 41.00	top5: 84.00	
[09/16 18:09:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.979, 0.1827 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 18:09:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.913, 0.1959 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 18:09:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.962, 0.1859 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 18:10:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.064, 0.1827 s / batch. (data: 3.50e-05)max mem: 17.22449 GB 
[09/16 18:10:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1930, average loss: 1.7901
[09/16 18:10:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 39.14	top5: 81.82	
[09/16 18:10:05][INFO] visual_prompt:  246: Best epoch 78: best metric: 0.410
[09/16 18:10:05][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 18:10:15][INFO] visual_prompt:  219: Epoch 79 / 100: avg data time: 1.45e-01, avg batch time: 0.5489, average train loss: 1.6856
[09/16 18:10:20][INFO] visual_prompt:  324: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1426, average loss: 1.7592
[09/16 18:10:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 34.50	top5: 77.00	
[09/16 18:10:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.148, 0.2148 s / batch. (data: 3.28e-02)max mem: 17.22449 GB 
[09/16 18:11:01][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.931, 0.1830 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 18:11:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.962, 0.2031 s / batch. (data: 1.04e-04)max mem: 17.22449 GB 
[09/16 18:11:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.053, 0.1825 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 18:11:43][INFO] visual_prompt:  324: Inference (test):avg data time: 7.00e-03, avg batch time: 0.1934, average loss: 1.8796
[09/16 18:11:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 36.26	top5: 72.65	
[09/16 18:11:44][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 18:11:54][INFO] visual_prompt:  219: Epoch 80 / 100: avg data time: 1.43e-01, avg batch time: 0.5533, average train loss: 1.6814
[09/16 18:11:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1424, average loss: 1.6855
[09/16 18:11:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 43.00	top5: 83.50	
[09/16 18:12:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.900, 0.2019 s / batch. (data: 1.98e-02)max mem: 17.22449 GB 
[09/16 18:12:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.869, 0.1889 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 18:12:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.843, 0.1823 s / batch. (data: 9.44e-05)max mem: 17.22449 GB 
[09/16 18:13:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.903, 0.1821 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 18:13:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1934, average loss: 1.8959
[09/16 18:13:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 35.10	top5: 78.63	
[09/16 18:13:22][INFO] visual_prompt:  246: Best epoch 80: best metric: 0.430
[09/16 18:13:22][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 18:13:32][INFO] visual_prompt:  219: Epoch 81 / 100: avg data time: 1.36e-01, avg batch time: 0.5404, average train loss: 1.4612
[09/16 18:13:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1424, average loss: 1.2791
[09/16 18:13:37][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 53.50	top5: 93.50	
[09/16 18:13:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.609, 0.1827 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 18:14:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.596, 0.1836 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 18:14:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.744, 0.1821 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 18:14:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.929, 0.1820 s / batch. (data: 3.65e-05)max mem: 17.22449 GB 
[09/16 18:15:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1931, average loss: 1.5847
[09/16 18:15:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 43.53	top5: 88.05	
[09/16 18:15:00][INFO] visual_prompt:  246: Best epoch 81: best metric: 0.535
[09/16 18:15:00][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 18:15:11][INFO] visual_prompt:  219: Epoch 82 / 100: avg data time: 1.50e-01, avg batch time: 0.5505, average train loss: 1.3520
[09/16 18:15:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1426, average loss: 1.2706
[09/16 18:15:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 56.50	top5: 91.50	
[09/16 18:15:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.702, 0.1861 s / batch. (data: 1.69e-04)max mem: 17.22449 GB 
[09/16 18:15:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.582, 0.1830 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 18:16:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.636, 0.1913 s / batch. (data: 9.16e-03)max mem: 17.22449 GB 
[09/16 18:16:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.786, 0.1856 s / batch. (data: 6.06e-05)max mem: 17.22449 GB 
[09/16 18:16:39][INFO] visual_prompt:  324: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1939, average loss: 1.5781
[09/16 18:16:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 46.34	top5: 86.32	
[09/16 18:16:39][INFO] visual_prompt:  246: Best epoch 82: best metric: 0.565
[09/16 18:16:39][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 18:16:50][INFO] visual_prompt:  219: Epoch 83 / 100: avg data time: 1.34e-01, avg batch time: 0.5372, average train loss: 1.2029
[09/16 18:16:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1423, average loss: 1.2210
[09/16 18:16:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 59.00	top5: 94.50	
[09/16 18:17:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.695, 0.4844 s / batch. (data: 4.78e-03)max mem: 17.22449 GB 
[09/16 18:17:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.673, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 18:17:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.839, 0.1948 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 18:18:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.179, 0.1831 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 18:18:17][INFO] visual_prompt:  324: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1938, average loss: 1.7887
[09/16 18:18:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 48.83	top5: 89.04	
[09/16 18:18:17][INFO] visual_prompt:  246: Best epoch 83: best metric: 0.590
[09/16 18:18:17][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 18:18:28][INFO] visual_prompt:  219: Epoch 84 / 100: avg data time: 1.59e-01, avg batch time: 0.5608, average train loss: 1.1607
[09/16 18:18:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1423, average loss: 1.0261
[09/16 18:18:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 60.00	top5: 96.50	
[09/16 18:18:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.523, 0.2026 s / batch. (data: 9.24e-03)max mem: 17.22449 GB 
[09/16 18:19:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.491, 0.1953 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 18:19:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.683, 0.1944 s / batch. (data: 1.12e-02)max mem: 17.22449 GB 
[09/16 18:19:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.690, 0.1954 s / batch. (data: 3.50e-05)max mem: 17.22449 GB 
[09/16 18:19:56][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1934, average loss: 1.4338
[09/16 18:19:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 47.39	top5: 90.35	
[09/16 18:19:56][INFO] visual_prompt:  246: Best epoch 84: best metric: 0.600
[09/16 18:19:56][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 18:20:06][INFO] visual_prompt:  219: Epoch 85 / 100: avg data time: 1.44e-01, avg batch time: 0.5451, average train loss: 1.0610
[09/16 18:20:11][INFO] visual_prompt:  324: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1426, average loss: 1.0859
[09/16 18:20:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 64.50	top5: 92.50	
[09/16 18:20:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.971, 0.1821 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 18:20:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.638, 0.2086 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 18:21:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.566, 0.2081 s / batch. (data: 2.58e-02)max mem: 17.22449 GB 
[09/16 18:21:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.855, 0.1821 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 18:21:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1944, average loss: 1.5913
[09/16 18:21:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 49.73	top5: 89.58	
[09/16 18:21:35][INFO] visual_prompt:  246: Best epoch 85: best metric: 0.645
[09/16 18:21:35][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 18:21:45][INFO] visual_prompt:  219: Epoch 86 / 100: avg data time: 1.46e-01, avg batch time: 0.5461, average train loss: 1.0459
[09/16 18:21:49][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1423, average loss: 0.8007
[09/16 18:21:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 71.00	top5: 98.50	
[09/16 18:22:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.449, 0.1825 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 18:22:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.315, 0.1906 s / batch. (data: 3.41e-05)max mem: 17.22449 GB 
[09/16 18:22:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.371, 0.1980 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 18:23:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.478, 0.1826 s / batch. (data: 4.17e-05)max mem: 17.22449 GB 
[09/16 18:23:14][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1955, average loss: 1.2816
[09/16 18:23:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 58.04	top5: 92.83	
[09/16 18:23:14][INFO] visual_prompt:  246: Best epoch 86: best metric: 0.710
[09/16 18:23:14][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 18:23:24][INFO] visual_prompt:  219: Epoch 87 / 100: avg data time: 1.42e-01, avg batch time: 0.5487, average train loss: 0.9132
[09/16 18:23:29][INFO] visual_prompt:  324: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1441, average loss: 0.7129
[09/16 18:23:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 75.50	top5: 98.50	
[09/16 18:23:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.245, 0.2079 s / batch. (data: 2.60e-02)max mem: 17.22449 GB 
[09/16 18:24:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.217, 0.2100 s / batch. (data: 2.80e-02)max mem: 17.22449 GB 
[09/16 18:24:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.216, 0.1978 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 18:24:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.483, 0.1836 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 18:24:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1954, average loss: 1.3029
[09/16 18:24:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 58.52	top5: 92.56	
[09/16 18:24:53][INFO] visual_prompt:  246: Best epoch 87: best metric: 0.755
[09/16 18:24:53][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 18:25:04][INFO] visual_prompt:  219: Epoch 88 / 100: avg data time: 1.56e-01, avg batch time: 0.5592, average train loss: 0.7988
[09/16 18:25:08][INFO] visual_prompt:  324: Inference (val):avg data time: 4.50e-05, avg batch time: 0.1443, average loss: 0.6806
[09/16 18:25:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 72.50	top5: 99.00	
[09/16 18:25:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.360, 0.1883 s / batch. (data: 5.90e-03)max mem: 17.22449 GB 
[09/16 18:25:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.280, 0.1830 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 18:26:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.322, 0.1829 s / batch. (data: 1.40e-04)max mem: 17.22449 GB 
[09/16 18:26:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.464, 0.1832 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 18:26:32][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1937, average loss: 1.2791
[09/16 18:26:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 56.53	top5: 92.70	
[09/16 18:26:32][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 18:26:43][INFO] visual_prompt:  219: Epoch 89 / 100: avg data time: 1.46e-01, avg batch time: 0.5485, average train loss: 0.7661
[09/16 18:26:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1423, average loss: 0.7824
[09/16 18:26:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 70.00	top5: 97.50	
[09/16 18:27:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.678, 0.2036 s / batch. (data: 9.70e-05)max mem: 17.22449 GB 
[09/16 18:27:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.508, 0.1826 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 18:27:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.334, 0.1836 s / batch. (data: 1.59e-04)max mem: 17.22449 GB 
[09/16 18:28:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.483, 0.1830 s / batch. (data: 2.77e-05)max mem: 17.22449 GB 
[09/16 18:28:11][INFO] visual_prompt:  324: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1942, average loss: 1.3985
[09/16 18:28:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 58.12	top5: 93.20	
[09/16 18:28:11][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 18:28:21][INFO] visual_prompt:  219: Epoch 90 / 100: avg data time: 1.57e-01, avg batch time: 0.5583, average train loss: 0.7379
[09/16 18:28:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1424, average loss: 0.5817
[09/16 18:28:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 76.50	top5: 99.00	
[09/16 18:28:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.183, 0.1821 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 18:29:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.272, 0.1835 s / batch. (data: 1.47e-04)max mem: 17.22449 GB 
[09/16 18:29:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.349, 0.1931 s / batch. (data: 1.07e-02)max mem: 17.22449 GB 
[09/16 18:29:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.554, 0.1821 s / batch. (data: 2.96e-05)max mem: 17.22449 GB 
[09/16 18:29:49][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1929, average loss: 1.2889
[09/16 18:29:49][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 61.10	top5: 93.37	
[09/16 18:29:49][INFO] visual_prompt:  246: Best epoch 90: best metric: 0.765
[09/16 18:29:49][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 18:30:00][INFO] visual_prompt:  219: Epoch 91 / 100: avg data time: 1.40e-01, avg batch time: 0.5430, average train loss: 0.6478
[09/16 18:30:04][INFO] visual_prompt:  324: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1427, average loss: 0.5242
[09/16 18:30:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 81.50	top5: 100.00	
[09/16 18:30:26][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.352, 0.1833 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 18:30:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.324, 0.1957 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 18:31:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.373, 0.1933 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 18:31:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.489, 0.1840 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 18:31:27][INFO] visual_prompt:  324: Inference (test):avg data time: 7.17e-03, avg batch time: 0.1925, average loss: 1.3221
[09/16 18:31:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 63.15	top5: 94.17	
[09/16 18:31:27][INFO] visual_prompt:  246: Best epoch 91: best metric: 0.815
[09/16 18:31:27][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 18:31:38][INFO] visual_prompt:  219: Epoch 92 / 100: avg data time: 1.45e-01, avg batch time: 0.5495, average train loss: 0.5909
[09/16 18:31:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1431, average loss: 0.5474
[09/16 18:31:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 81.00	top5: 100.00	
[09/16 18:32:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.548, 0.1984 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 18:32:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.331, 0.1851 s / batch. (data: 1.64e-04)max mem: 17.22449 GB 
[09/16 18:32:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.352, 0.1974 s / batch. (data: 1.28e-02)max mem: 17.22449 GB 
[09/16 18:33:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.468, 0.1907 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 18:33:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1930, average loss: 1.3689
[09/16 18:33:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 63.00	top5: 93.80	
[09/16 18:33:05][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 18:33:16][INFO] visual_prompt:  219: Epoch 93 / 100: avg data time: 1.51e-01, avg batch time: 0.5510, average train loss: 0.5164
[09/16 18:33:21][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1424, average loss: 0.4238
[09/16 18:33:21][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 82.50	top5: 100.00	
[09/16 18:33:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.509, 0.2045 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 18:34:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.423, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 18:34:22][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.542, 0.1831 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 18:34:41][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.594, 0.1823 s / batch. (data: 2.43e-05)max mem: 17.22449 GB 
[09/16 18:34:44][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1941, average loss: 1.3817
[09/16 18:34:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.49	top5: 94.30	
[09/16 18:34:44][INFO] visual_prompt:  246: Best epoch 93: best metric: 0.825
[09/16 18:34:44][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 18:34:55][INFO] visual_prompt:  219: Epoch 94 / 100: avg data time: 1.49e-01, avg batch time: 0.5492, average train loss: 0.4734
[09/16 18:34:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1424, average loss: 0.4434
[09/16 18:34:59][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 82.50	top5: 99.50	
[09/16 18:35:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.640, 0.1898 s / batch. (data: 8.87e-05)max mem: 17.22449 GB 
[09/16 18:35:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.490, 0.1834 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 18:36:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.756, 0.1973 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 18:36:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.624, 0.1830 s / batch. (data: 4.22e-05)max mem: 17.22449 GB 
[09/16 18:36:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1940, average loss: 1.5013
[09/16 18:36:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 62.82	top5: 92.97	
[09/16 18:36:23][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 18:36:33][INFO] visual_prompt:  219: Epoch 95 / 100: avg data time: 1.51e-01, avg batch time: 0.5547, average train loss: 0.4525
[09/16 18:36:38][INFO] visual_prompt:  324: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1425, average loss: 0.4200
[09/16 18:36:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 85.00	top5: 99.50	
[09/16 18:36:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.570, 0.2116 s / batch. (data: 6.77e-05)max mem: 17.22449 GB 
[09/16 18:37:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.360, 0.1962 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 18:37:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.621, 0.1837 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 18:37:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.550, 0.1827 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 18:38:01][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1927, average loss: 1.3722
[09/16 18:38:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 62.84	top5: 93.52	
[09/16 18:38:01][INFO] visual_prompt:  246: Best epoch 95: best metric: 0.850
[09/16 18:38:01][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 18:38:11][INFO] visual_prompt:  219: Epoch 96 / 100: avg data time: 1.57e-01, avg batch time: 0.5555, average train loss: 0.3887
[09/16 18:38:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1424, average loss: 0.3592
[09/16 18:38:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 86.50	top5: 100.00	
[09/16 18:38:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.736, 0.1933 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 18:38:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.478, 0.2245 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 18:39:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.569, 0.1945 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 18:39:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.568, 0.1839 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 18:39:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1932, average loss: 1.4188
[09/16 18:39:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.60	top5: 94.31	
[09/16 18:39:39][INFO] visual_prompt:  246: Best epoch 96: best metric: 0.865
[09/16 18:39:39][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 18:39:49][INFO] visual_prompt:  219: Epoch 97 / 100: avg data time: 1.55e-01, avg batch time: 0.5561, average train loss: 0.3598
[09/16 18:39:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1425, average loss: 0.3301
[09/16 18:39:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 88.50	top5: 99.50	
[09/16 18:40:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.736, 0.1955 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 18:40:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.556, 0.1994 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 18:40:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.698, 0.1832 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 18:41:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.618, 0.1823 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 18:41:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1933, average loss: 1.5143
[09/16 18:41:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.65	top5: 93.76	
[09/16 18:41:17][INFO] visual_prompt:  246: Best epoch 97: best metric: 0.885
[09/16 18:41:17][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 18:41:28][INFO] visual_prompt:  219: Epoch 98 / 100: avg data time: 1.50e-01, avg batch time: 0.5512, average train loss: 0.3321
[09/16 18:41:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1425, average loss: 0.3491
[09/16 18:41:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 88.00	top5: 99.50	
[09/16 18:41:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.846, 0.1848 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 18:42:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.680, 0.1963 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 18:42:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.699, 0.2005 s / batch. (data: 1.72e-04)max mem: 17.22449 GB 
[09/16 18:42:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.624, 0.1827 s / batch. (data: 3.48e-05)max mem: 17.22449 GB 
[09/16 18:42:56][INFO] visual_prompt:  324: Inference (test):avg data time: 7.15e-03, avg batch time: 0.1931, average loss: 1.5684
[09/16 18:42:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.70	top5: 93.74	
[09/16 18:42:56][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 18:43:06][INFO] visual_prompt:  219: Epoch 99 / 100: avg data time: 1.54e-01, avg batch time: 0.5538, average train loss: 0.3237
[09/16 18:43:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1426, average loss: 0.3203
[09/16 18:43:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 90.50	top5: 99.50	
[09/16 18:43:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.785, 0.1823 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 18:43:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.653, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 18:44:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.747, 0.1849 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 18:44:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.654, 0.1829 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 18:44:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1939, average loss: 1.5491
[09/16 18:44:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.91	top5: 93.88	
[09/16 18:44:35][INFO] visual_prompt:  246: Best epoch 99: best metric: 0.905
[09/16 18:44:35][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 18:44:45][INFO] visual_prompt:  219: Epoch 100 / 100: avg data time: 1.53e-01, avg batch time: 0.5537, average train loss: 0.3056
[09/16 18:44:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1424, average loss: 0.3167
[09/16 18:44:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 89.50	top5: 99.50	
[09/16 18:45:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.791, 0.1961 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 18:45:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.660, 0.1972 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 18:45:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.729, 0.1827 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 18:46:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.658, 0.1827 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 18:46:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1936, average loss: 1.5484
[09/16 18:46:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.94	top5: 93.91	
