[09/16 07:43:53][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/16 07:43:53][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 07:43:53][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-svhn', 'DATA.NUMBER_CLASSES', '10', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/16 07:43:53][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 07:43:53][INFO] visual_prompt:  108: Training with config:
[09/16 07:43:53][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-svhn',
          'NO_TEST': False,
          'NUMBER_CLASSES': 10,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-svhn/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 07:43:53][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/16 07:44:07][INFO] visual_prompt:   69: Constructing vtab-svhn dataset trainval...
[09/16 07:44:10][INFO] visual_prompt:   88: Number of images: 1000
[09/16 07:44:10][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 07:44:10][INFO] visual_prompt:   70: Loading validation data...
[09/16 07:44:10][INFO] visual_prompt:   69: Constructing vtab-svhn dataset val...
[09/16 07:44:10][INFO] visual_prompt:   88: Number of images: 200
[09/16 07:44:10][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 07:44:10][INFO] visual_prompt:   73: Loading test data...
[09/16 07:44:10][INFO] visual_prompt:   69: Constructing vtab-svhn dataset test...
[09/16 07:44:44][INFO] visual_prompt:   88: Number of images: 26032
[09/16 07:44:44][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 07:44:44][INFO] visual_prompt:  100: Constructing models...
[09/16 07:44:47][INFO] visual_prompt:   53: Total Parameters: 86727946	 Gradient Parameters: 929290
[09/16 07:44:47][INFO] visual_prompt:   54: tuned percent:1.072
[09/16 07:44:49][INFO] visual_prompt:   40: Device used for model: 0
[09/16 07:44:49][INFO] visual_prompt:  103: Setting up Evalutator...
[09/16 07:44:49][INFO] visual_prompt:  105: Setting up Trainer...
[09/16 07:44:49][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/16 07:44:49][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/16 07:45:01][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 1.47e-01, avg batch time: 0.6368, average train loss: 2.5931
[09/16 07:45:06][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1417, average loss: 2.5459
[09/16 07:45:06][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 15.00	top5: 56.00	
[09/16 07:45:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.922, 0.1911 s / batch. (data: 1.05e-02)max mem: 17.22449 GB 
[09/16 07:45:47][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.733, 0.1818 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 07:46:06][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.868, 0.1962 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 07:46:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.715, 0.1837 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 07:46:29][INFO] visual_prompt:  324: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1931, average loss: 2.6825
[09/16 07:46:29][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 12.12	top5: 54.22	
[09/16 07:46:29][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.150
[09/16 07:46:29][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/16 07:46:40][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 1.47e-01, avg batch time: 0.5529, average train loss: 2.9775
[09/16 07:46:44][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1422, average loss: 2.7181
[09/16 07:46:44][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.50	
[09/16 07:47:06][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.848, 0.1914 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 07:47:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.023, 0.2010 s / batch. (data: 1.92e-02)max mem: 17.22449 GB 
[09/16 07:47:45][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.586, 0.1964 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 07:48:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.798, 0.1942 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 07:48:08][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1932, average loss: 2.7636
[09/16 07:48:08][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 63.51	
[09/16 07:48:08][INFO] visual_prompt:  246: Best epoch 2: best metric: 0.230
[09/16 07:48:08][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/16 07:48:18][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 1.47e-01, avg batch time: 0.5509, average train loss: 2.5613
[09/16 07:48:23][INFO] visual_prompt:  324: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1427, average loss: 2.5932
[09/16 07:48:23][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 50.50	
[09/16 07:48:45][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.801, 0.1824 s / batch. (data: 8.27e-05)max mem: 17.22449 GB 
[09/16 07:49:04][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.731, 0.1827 s / batch. (data: 9.27e-05)max mem: 17.22449 GB 
[09/16 07:49:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.766, 0.1999 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 07:49:43][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.766, 0.1911 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 07:49:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1938, average loss: 2.6639
[09/16 07:49:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 46.55	
[09/16 07:49:47][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/16 07:49:57][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.60e-01, avg batch time: 0.5618, average train loss: 2.5420
[09/16 07:50:02][INFO] visual_prompt:  324: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1424, average loss: 2.3953
[09/16 07:50:02][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.00	
[09/16 07:50:23][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.618, 0.1819 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 07:50:43][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.550, 0.1824 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 07:51:02][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.395, 0.1826 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 07:51:22][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.327, 0.1821 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 07:51:25][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1941, average loss: 2.4109
[09/16 07:51:25][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 64.04	
[09/16 07:51:25][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/16 07:51:36][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.42e-01, avg batch time: 0.5447, average train loss: 2.5804
[09/16 07:51:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1426, average loss: 2.3444
[09/16 07:51:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 60.00	
[09/16 07:52:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.496, 0.1822 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 07:52:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.573, 0.1988 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 07:52:41][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.229, 0.1825 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 07:53:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.392, 0.1821 s / batch. (data: 2.79e-05)max mem: 17.22449 GB 
[09/16 07:53:04][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1942, average loss: 2.3544
[09/16 07:53:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 58.98	
[09/16 07:53:04][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/16 07:53:15][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 1.56e-01, avg batch time: 0.5581, average train loss: 2.6004
[09/16 07:53:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1425, average loss: 2.9080
[09/16 07:53:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 47.50	
[09/16 07:53:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.793, 0.1819 s / batch. (data: 8.77e-05)max mem: 17.22449 GB 
[09/16 07:54:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.859, 0.1912 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 07:54:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.809, 0.1977 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 07:54:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.720, 0.1830 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 07:54:43][INFO] visual_prompt:  324: Inference (test):avg data time: 6.72e-03, avg batch time: 0.1938, average loss: 2.8153
[09/16 07:54:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 51.99	
[09/16 07:54:43][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/16 07:54:54][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.58e-01, avg batch time: 0.5596, average train loss: 3.0564
[09/16 07:54:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1430, average loss: 2.9815
[09/16 07:54:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 11.50	top5: 49.00	
[09/16 07:55:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.949, 0.2038 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 07:55:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.814, 0.1967 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 07:55:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.873, 0.1986 s / batch. (data: 1.12e-02)max mem: 17.22449 GB 
[09/16 07:56:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.640, 0.1824 s / batch. (data: 4.12e-05)max mem: 17.22449 GB 
[09/16 07:56:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1933, average loss: 2.9081
[09/16 07:56:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.09	top5: 52.05	
[09/16 07:56:22][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/16 07:56:32][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.64e-01, avg batch time: 0.5645, average train loss: 3.3639
[09/16 07:56:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1426, average loss: 3.4764
[09/16 07:56:37][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 59.50	
[09/16 07:56:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.378, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 07:57:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.669, 0.1949 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 07:57:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.443, 0.1829 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 07:57:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.590, 0.1942 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 07:58:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1934, average loss: 3.4812
[09/16 07:58:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.76	top5: 58.67	
[09/16 07:58:00][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/16 07:58:11][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.54e-01, avg batch time: 0.5596, average train loss: 5.6048
[09/16 07:58:15][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1424, average loss: 7.2314
[09/16 07:58:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 55.50	
[09/16 07:58:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 6.875, 0.2035 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 07:58:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 7.384, 0.1956 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 07:59:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.161, 0.1887 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 07:59:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 7.207, 0.1829 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 07:59:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1932, average loss: 7.1209
[09/16 07:59:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.90	top5: 55.79	
[09/16 07:59:39][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/16 07:59:49][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.46e-01, avg batch time: 0.5482, average train loss: 16.9552
[09/16 07:59:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1426, average loss: 24.8077
[09/16 07:59:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.50	
[09/16 08:00:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 28.611, 0.1827 s / batch. (data: 1.41e-04)max mem: 17.22449 GB 
[09/16 08:00:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 26.663, 0.1830 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 08:00:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 24.748, 0.1969 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 08:01:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 25.370, 0.1826 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 08:01:17][INFO] visual_prompt:  324: Inference (test):avg data time: 6.83e-03, avg batch time: 0.1936, average loss: 24.5701
[09/16 08:01:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 62.67	
[09/16 08:01:17][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[09/16 08:01:28][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.53e-01, avg batch time: 0.5548, average train loss: 16.9343
[09/16 08:01:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1496, average loss: 16.8531
[09/16 08:01:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 58.00	
[09/16 08:01:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 16.958, 0.1909 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 08:02:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 17.331, 0.1973 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 08:02:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 17.577, 0.1959 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 08:02:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 18.275, 0.1827 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 08:02:56][INFO] visual_prompt:  324: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1941, average loss: 17.4735
[09/16 08:02:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 54.48	
[09/16 08:02:56][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 08:03:07][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 1.55e-01, avg batch time: 0.5572, average train loss: 17.1122
[09/16 08:03:12][INFO] visual_prompt:  324: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1424, average loss: 15.5663
[09/16 08:03:12][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 7.00	top5: 53.50	
[09/16 08:03:34][INFO] visual_prompt:  314: 	Test 100/407. loss: 16.157, 0.1823 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 08:03:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 15.534, 0.1997 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 08:04:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 17.601, 0.1900 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 08:04:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 17.289, 0.1820 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 08:04:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1941, average loss: 15.7284
[09/16 08:04:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.70	top5: 51.51	
[09/16 08:04:35][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 08:04:46][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.55e-01, avg batch time: 0.5553, average train loss: 15.7417
[09/16 08:04:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1463, average loss: 19.0948
[09/16 08:04:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 54.00	
[09/16 08:05:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 20.109, 0.1816 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 08:05:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 19.233, 0.1832 s / batch. (data: 9.35e-05)max mem: 17.22449 GB 
[09/16 08:05:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 19.392, 0.1959 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 08:06:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 20.787, 0.1825 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 08:06:14][INFO] visual_prompt:  324: Inference (test):avg data time: 6.88e-03, avg batch time: 0.1933, average loss: 18.9573
[09/16 08:06:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 49.86	
[09/16 08:06:14][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 08:06:25][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 1.59e-01, avg batch time: 0.5582, average train loss: 17.9778
[09/16 08:06:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1424, average loss: 13.9450
[09/16 08:06:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 54.50	
[09/16 08:06:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 15.008, 0.2088 s / batch. (data: 2.70e-02)max mem: 17.22449 GB 
[09/16 08:07:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 16.803, 0.1823 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 08:07:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 12.888, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 08:07:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 15.422, 0.1822 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 08:07:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1933, average loss: 14.7599
[09/16 08:07:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 50.47	
[09/16 08:07:52][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 08:08:03][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.62e-01, avg batch time: 0.5634, average train loss: 15.2416
[09/16 08:08:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1426, average loss: 9.2970
[09/16 08:08:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 57.50	
[09/16 08:08:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 10.024, 0.1827 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 08:08:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 9.704, 0.1856 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 08:09:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.834, 0.1830 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 08:09:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.604, 0.1835 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 08:09:31][INFO] visual_prompt:  324: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1939, average loss: 9.2062
[09/16 08:09:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 58.94	
[09/16 08:09:32][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 08:09:42][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 1.40e-01, avg batch time: 0.5464, average train loss: 8.2421
[09/16 08:09:46][INFO] visual_prompt:  324: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1454, average loss: 7.9869
[09/16 08:09:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 58.00	
[09/16 08:10:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.983, 0.2076 s / batch. (data: 2.61e-02)max mem: 17.22449 GB 
[09/16 08:10:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 9.392, 0.1822 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 08:10:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 6.323, 0.2145 s / batch. (data: 3.27e-02)max mem: 17.22449 GB 
[09/16 08:11:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.688, 0.1823 s / batch. (data: 2.67e-05)max mem: 17.22449 GB 
[09/16 08:11:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1940, average loss: 8.0972
[09/16 08:11:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 58.65	
[09/16 08:11:10][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 08:11:21][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.55e-01, avg batch time: 0.5576, average train loss: 8.1200
[09/16 08:11:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1426, average loss: 8.6381
[09/16 08:11:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 54.50	
[09/16 08:11:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 10.540, 0.2178 s / batch. (data: 1.70e-02)max mem: 17.22449 GB 
[09/16 08:12:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.151, 0.1953 s / batch. (data: 1.31e-02)max mem: 17.22449 GB 
[09/16 08:12:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 9.488, 0.1960 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 08:12:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.789, 0.1833 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 08:12:49][INFO] visual_prompt:  324: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1932, average loss: 9.0373
[09/16 08:12:49][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 52.16	
[09/16 08:12:49][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 08:12:59][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.43e-01, avg batch time: 0.5453, average train loss: 7.6339
[09/16 08:13:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1424, average loss: 7.8931
[09/16 08:13:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 54.50	
[09/16 08:13:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 9.118, 0.1951 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 08:13:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 8.883, 0.1967 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 08:14:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.297, 0.1825 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 08:14:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.601, 0.1830 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 08:14:27][INFO] visual_prompt:  324: Inference (test):avg data time: 8.64e-03, avg batch time: 0.1940, average loss: 8.2452
[09/16 08:14:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.41	
[09/16 08:14:27][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 08:14:37][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 1.41e-01, avg batch time: 0.5442, average train loss: 5.5115
[09/16 08:14:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1426, average loss: 4.1240
[09/16 08:14:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.00	
[09/16 08:15:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 5.198, 0.1965 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 08:15:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 5.053, 0.2083 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 08:15:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 4.469, 0.1822 s / batch. (data: 1.60e-04)max mem: 17.22449 GB 
[09/16 08:16:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 4.471, 0.1828 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 08:16:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1933, average loss: 4.4905
[09/16 08:16:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 53.54	
[09/16 08:16:05][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 08:16:16][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.56e-01, avg batch time: 0.5580, average train loss: 3.6266
[09/16 08:16:21][INFO] visual_prompt:  324: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1424, average loss: 2.5963
[09/16 08:16:21][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 58.50	
[09/16 08:16:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.019, 0.1952 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 08:17:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.902, 0.2004 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 08:17:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.655, 0.1954 s / batch. (data: 1.52e-04)max mem: 17.22449 GB 
[09/16 08:17:41][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.694, 0.1832 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 08:17:44][INFO] visual_prompt:  324: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1935, average loss: 2.7103
[09/16 08:17:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 52.71	
[09/16 08:17:44][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 08:17:55][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.52e-01, avg batch time: 0.5534, average train loss: 2.9243
[09/16 08:17:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1424, average loss: 2.6349
[09/16 08:17:59][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 7.00	top5: 60.00	
[09/16 08:18:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.929, 0.1956 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 08:18:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.813, 0.1945 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 08:19:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.672, 0.2188 s / batch. (data: 3.65e-02)max mem: 17.22449 GB 
[09/16 08:19:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.844, 0.1821 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 08:19:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1935, average loss: 2.6279
[09/16 08:19:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.70	top5: 59.67	
[09/16 08:19:23][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 08:19:34][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 1.52e-01, avg batch time: 0.5522, average train loss: 2.7841
[09/16 08:19:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1424, average loss: 2.7374
[09/16 08:19:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 63.00	
[09/16 08:20:00][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.815, 0.1942 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 08:20:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.912, 0.1831 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 08:20:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.690, 0.1827 s / batch. (data: 8.75e-05)max mem: 17.22449 GB 
[09/16 08:20:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.795, 0.1825 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 08:21:01][INFO] visual_prompt:  324: Inference (test):avg data time: 7.17e-03, avg batch time: 0.1930, average loss: 2.7384
[09/16 08:21:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 62.45	
[09/16 08:21:01][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 08:21:12][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.47e-01, avg batch time: 0.5471, average train loss: 2.6525
[09/16 08:21:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1424, average loss: 2.4720
[09/16 08:21:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 64.50	
[09/16 08:21:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.543, 0.1970 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 08:21:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.557, 0.1832 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 08:22:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.493, 0.2326 s / batch. (data: 3.78e-02)max mem: 17.22449 GB 
[09/16 08:22:37][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.413, 0.1823 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 08:22:40][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1939, average loss: 2.4630
[09/16 08:22:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 62.77	
[09/16 08:22:40][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 08:22:50][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 1.37e-01, avg batch time: 0.5426, average train loss: 2.6353
[09/16 08:22:55][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1435, average loss: 2.6524
[09/16 08:22:55][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 59.00	
[09/16 08:23:17][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.579, 0.1903 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 08:23:37][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.747, 0.1937 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 08:23:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.576, 0.1829 s / batch. (data: 1.41e-04)max mem: 17.22449 GB 
[09/16 08:24:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.779, 0.1828 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 08:24:19][INFO] visual_prompt:  324: Inference (test):avg data time: 6.53e-03, avg batch time: 0.1947, average loss: 2.6234
[09/16 08:24:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 59.15	
[09/16 08:24:19][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 08:24:30][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 1.62e-01, avg batch time: 0.5643, average train loss: 2.7074
[09/16 08:24:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1426, average loss: 2.3779
[09/16 08:24:34][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 08:24:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.664, 0.1827 s / batch. (data: 1.48e-04)max mem: 17.22449 GB 
[09/16 08:25:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.570, 0.1942 s / batch. (data: 1.24e-02)max mem: 17.22449 GB 
[09/16 08:25:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.434, 0.1832 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 08:25:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.393, 0.1823 s / batch. (data: 3.86e-05)max mem: 17.22449 GB 
[09/16 08:25:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1967, average loss: 2.4246
[09/16 08:25:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.13	top5: 64.06	
[09/16 08:25:59][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 08:26:10][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.64e-01, avg batch time: 0.5648, average train loss: 2.7946
[09/16 08:26:14][INFO] visual_prompt:  324: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1424, average loss: 2.7522
[09/16 08:26:14][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.50	top5: 57.50	
[09/16 08:26:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.649, 0.2078 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 08:26:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.798, 0.1819 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 08:27:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.656, 0.2059 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 08:27:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.759, 0.1819 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 08:27:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1941, average loss: 2.7330
[09/16 08:27:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.72	top5: 59.19	
[09/16 08:27:39][INFO] visual_prompt:  246: Best epoch 26: best metric: 0.235
[09/16 08:27:39][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 08:27:50][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 1.45e-01, avg batch time: 0.5492, average train loss: 2.7879
[09/16 08:27:54][INFO] visual_prompt:  324: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1425, average loss: 2.6354
[09/16 08:27:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.50	
[09/16 08:28:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.033, 0.1817 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 08:28:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.912, 0.1827 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 08:28:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.684, 0.1978 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 08:29:15][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.745, 0.1826 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 08:29:18][INFO] visual_prompt:  324: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1945, average loss: 2.6864
[09/16 08:29:18][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.51	
[09/16 08:29:18][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 08:29:29][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 1.48e-01, avg batch time: 0.5500, average train loss: 2.5401
[09/16 08:29:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1426, average loss: 2.4295
[09/16 08:29:34][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 63.00	
[09/16 08:29:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.816, 0.1973 s / batch. (data: 1.47e-02)max mem: 17.22449 GB 
[09/16 08:30:15][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.713, 0.2078 s / batch. (data: 2.57e-02)max mem: 17.22449 GB 
[09/16 08:30:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.509, 0.1831 s / batch. (data: 1.56e-04)max mem: 17.22449 GB 
[09/16 08:30:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.528, 0.1824 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 08:30:58][INFO] visual_prompt:  324: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1956, average loss: 2.5333
[09/16 08:30:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 56.57	
[09/16 08:30:58][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 08:31:09][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.55e-01, avg batch time: 0.5569, average train loss: 2.4570
[09/16 08:31:13][INFO] visual_prompt:  324: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1425, average loss: 2.4477
[09/16 08:31:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.00	top5: 66.50	
[09/16 08:31:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.515, 0.2065 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 08:31:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.733, 0.1957 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 08:32:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.203, 0.1957 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 08:32:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.401, 0.1825 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 08:32:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1949, average loss: 2.4795
[09/16 08:32:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 23.00	top5: 61.43	
[09/16 08:32:37][INFO] visual_prompt:  246: Best epoch 29: best metric: 0.290
[09/16 08:32:37][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 08:32:48][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 1.49e-01, avg batch time: 0.5526, average train loss: 2.4240
[09/16 08:32:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1427, average loss: 2.3430
[09/16 08:32:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.00	top5: 63.00	
[09/16 08:33:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.488, 0.1823 s / batch. (data: 3.48e-05)max mem: 17.22449 GB 
[09/16 08:33:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.655, 0.1998 s / batch. (data: 1.76e-02)max mem: 17.22449 GB 
[09/16 08:33:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.272, 0.1970 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 08:34:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.537, 0.1825 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 08:34:16][INFO] visual_prompt:  324: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1942, average loss: 2.4132
[09/16 08:34:16][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 23.73	top5: 60.76	
[09/16 08:34:16][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 08:34:27][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 1.55e-01, avg batch time: 0.5618, average train loss: 2.5516
[09/16 08:34:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1425, average loss: 3.1303
[09/16 08:34:31][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 46.00	
[09/16 08:34:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.673, 0.1990 s / batch. (data: 1.74e-02)max mem: 17.22449 GB 
[09/16 08:35:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.842, 0.1824 s / batch. (data: 1.69e-04)max mem: 17.22449 GB 
[09/16 08:35:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.899, 0.2001 s / batch. (data: 1.64e-04)max mem: 17.22449 GB 
[09/16 08:35:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.880, 0.1825 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 08:35:56][INFO] visual_prompt:  324: Inference (test):avg data time: 7.02e-03, avg batch time: 0.1942, average loss: 3.0000
[09/16 08:35:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 49.24	
[09/16 08:35:56][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 08:36:06][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 1.55e-01, avg batch time: 0.5598, average train loss: 2.5448
[09/16 08:36:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1425, average loss: 2.2774
[09/16 08:36:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 20.50	top5: 69.00	
[09/16 08:36:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.485, 0.1828 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 08:36:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.476, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 08:37:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.208, 0.1979 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 08:37:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.317, 0.1828 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 08:37:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1924, average loss: 2.3217
[09/16 08:37:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.23	top5: 66.29	
[09/16 08:37:34][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 08:37:45][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 1.55e-01, avg batch time: 0.5562, average train loss: 2.2084
[09/16 08:37:49][INFO] visual_prompt:  324: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1427, average loss: 1.7654
[09/16 08:37:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 43.00	top5: 81.50	
[09/16 08:38:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.077, 0.1977 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 08:38:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.025, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 08:38:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.749, 0.2000 s / batch. (data: 1.77e-02)max mem: 17.22449 GB 
[09/16 08:39:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.847, 0.1827 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 08:39:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1948, average loss: 1.8518
[09/16 08:39:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 38.84	top5: 76.78	
[09/16 08:39:13][INFO] visual_prompt:  246: Best epoch 33: best metric: 0.430
[09/16 08:39:13][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 08:39:24][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 1.56e-01, avg batch time: 0.5579, average train loss: 2.1953
[09/16 08:39:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1425, average loss: 3.1228
[09/16 08:39:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 16.00	top5: 53.00	
[09/16 08:39:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.358, 0.1987 s / batch. (data: 1.57e-04)max mem: 17.22449 GB 
[09/16 08:40:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.059, 0.1963 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 08:40:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.490, 0.1933 s / batch. (data: 1.64e-04)max mem: 17.22449 GB 
[09/16 08:40:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.372, 0.1822 s / batch. (data: 3.89e-05)max mem: 17.22449 GB 
[09/16 08:40:52][INFO] visual_prompt:  324: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1938, average loss: 3.2852
[09/16 08:40:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 14.60	top5: 47.60	
[09/16 08:40:52][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 08:41:02][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 1.37e-01, avg batch time: 0.5418, average train loss: 2.2548
[09/16 08:41:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1426, average loss: 2.0367
[09/16 08:41:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.00	top5: 88.50	
[09/16 08:41:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.260, 0.1956 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 08:41:48][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.166, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 08:42:07][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.140, 0.1838 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 08:42:27][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.343, 0.2123 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 08:42:30][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1939, average loss: 2.2153
[09/16 08:42:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 22.17	top5: 82.68	
[09/16 08:42:30][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 08:42:41][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 1.74e-01, avg batch time: 0.5770, average train loss: 1.8180
[09/16 08:42:46][INFO] visual_prompt:  324: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1426, average loss: 1.5637
[09/16 08:42:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 40.00	top5: 88.50	
[09/16 08:43:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.144, 0.1820 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 08:43:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.045, 0.1830 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 08:43:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.595, 0.1959 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 08:44:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.099, 0.1825 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 08:44:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1949, average loss: 1.8120
[09/16 08:44:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 33.14	top5: 85.60	
[09/16 08:44:10][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 08:44:21][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.54e-01, avg batch time: 0.5578, average train loss: 1.8928
[09/16 08:44:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1427, average loss: 1.9569
[09/16 08:44:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 38.50	top5: 87.00	
[09/16 08:44:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.652, 0.1821 s / batch. (data: 6.18e-05)max mem: 17.22449 GB 
[09/16 08:45:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.459, 0.2076 s / batch. (data: 2.57e-02)max mem: 17.22449 GB 
[09/16 08:45:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.087, 0.2302 s / batch. (data: 4.20e-02)max mem: 17.22449 GB 
[09/16 08:45:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.188, 0.1829 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 08:45:49][INFO] visual_prompt:  324: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1937, average loss: 2.2198
[09/16 08:45:49][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 31.91	top5: 81.90	
[09/16 08:45:49][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 08:46:00][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 1.58e-01, avg batch time: 0.5587, average train loss: 1.7017
[09/16 08:46:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1425, average loss: 1.2792
[09/16 08:46:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 50.00	top5: 91.50	
[09/16 08:46:26][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.914, 0.1977 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 08:46:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.711, 0.2153 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 08:47:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.409, 0.1985 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 08:47:25][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.793, 0.1825 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 08:47:28][INFO] visual_prompt:  324: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1943, average loss: 1.6065
[09/16 08:47:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 42.74	top5: 88.75	
[09/16 08:47:28][INFO] visual_prompt:  246: Best epoch 38: best metric: 0.500
[09/16 08:47:28][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 08:47:39][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 1.57e-01, avg batch time: 0.5573, average train loss: 1.5085
[09/16 08:47:43][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1426, average loss: 1.2347
[09/16 08:47:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 56.50	top5: 86.50	
[09/16 08:48:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.555, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 08:48:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.457, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 08:48:44][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.428, 0.1957 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 08:49:03][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.632, 0.1837 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 08:49:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1927, average loss: 1.4586
[09/16 08:49:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 52.03	top5: 85.69	
[09/16 08:49:07][INFO] visual_prompt:  246: Best epoch 39: best metric: 0.565
[09/16 08:49:07][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 08:49:17][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 1.63e-01, avg batch time: 0.5629, average train loss: 1.4595
[09/16 08:49:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1433, average loss: 1.1352
[09/16 08:49:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 60.00	top5: 94.00	
[09/16 08:49:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.567, 0.2274 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 08:50:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.380, 0.1971 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 08:50:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.316, 0.1834 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 08:50:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.438, 0.1826 s / batch. (data: 4.46e-05)max mem: 17.22449 GB 
[09/16 08:50:45][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1938, average loss: 1.4287
[09/16 08:50:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 49.28	top5: 89.92	
[09/16 08:50:46][INFO] visual_prompt:  246: Best epoch 40: best metric: 0.600
[09/16 08:50:46][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 3.75
[09/16 08:50:56][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 1.62e-01, avg batch time: 0.5640, average train loss: 1.2823
[09/16 08:51:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1424, average loss: 1.1884
[09/16 08:51:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 62.00	top5: 91.50	
[09/16 08:51:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.773, 0.1929 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 08:51:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.719, 0.2052 s / batch. (data: 1.26e-02)max mem: 17.22449 GB 
[09/16 08:52:01][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.378, 0.1828 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 08:52:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.587, 0.1825 s / batch. (data: 2.26e-05)max mem: 17.22449 GB 
[09/16 08:52:24][INFO] visual_prompt:  324: Inference (test):avg data time: 6.80e-03, avg batch time: 0.1930, average loss: 1.5497
[09/16 08:52:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 55.29	top5: 88.34	
[09/16 08:52:24][INFO] visual_prompt:  246: Best epoch 41: best metric: 0.620
[09/16 08:52:24][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 08:52:35][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 1.55e-01, avg batch time: 0.5554, average train loss: 1.3115
[09/16 08:52:39][INFO] visual_prompt:  324: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1425, average loss: 0.8900
[09/16 08:52:39][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 66.00	top5: 96.50	
[09/16 08:53:01][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.523, 0.1824 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 08:53:20][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.280, 0.2116 s / batch. (data: 3.00e-02)max mem: 17.22449 GB 
[09/16 08:53:39][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.085, 0.1947 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 08:53:59][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.406, 0.1824 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 08:54:03][INFO] visual_prompt:  324: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1935, average loss: 1.2616
[09/16 08:54:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 55.84	top5: 93.76	
[09/16 08:54:03][INFO] visual_prompt:  246: Best epoch 42: best metric: 0.660
[09/16 08:54:03][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 08:54:13][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 1.60e-01, avg batch time: 0.5597, average train loss: 1.3296
[09/16 08:54:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1424, average loss: 1.6602
[09/16 08:54:18][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 54.00	top5: 84.50	
[09/16 08:54:40][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.670, 0.2080 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 08:54:59][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.821, 0.1990 s / batch. (data: 1.58e-02)max mem: 17.22449 GB 
[09/16 08:55:19][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.747, 0.1934 s / batch. (data: 1.12e-02)max mem: 17.22449 GB 
[09/16 08:55:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.980, 0.1827 s / batch. (data: 3.00e-05)max mem: 17.22449 GB 
[09/16 08:55:43][INFO] visual_prompt:  324: Inference (test):avg data time: 7.09e-03, avg batch time: 0.1947, average loss: 1.7934
[09/16 08:55:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 48.97	top5: 83.49	
[09/16 08:55:43][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 08:55:53][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 1.60e-01, avg batch time: 0.5610, average train loss: 1.4563
[09/16 08:55:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1423, average loss: 1.1435
[09/16 08:55:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 64.00	top5: 93.50	
[09/16 08:56:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.712, 0.1967 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 08:56:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.562, 0.2150 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 08:56:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.587, 0.2058 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 08:57:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.732, 0.1829 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 08:57:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1932, average loss: 1.5121
[09/16 08:57:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 54.54	top5: 90.35	
[09/16 08:57:22][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 08:57:32][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.53e-01, avg batch time: 0.5559, average train loss: 1.1418
[09/16 08:57:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1428, average loss: 0.8847
[09/16 08:57:37][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 71.50	top5: 98.50	
[09/16 08:57:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.382, 0.1969 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 08:58:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.161, 0.1955 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 08:58:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.030, 0.1969 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 08:58:57][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.382, 0.1830 s / batch. (data: 3.43e-05)max mem: 17.22449 GB 
[09/16 08:59:01][INFO] visual_prompt:  324: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1943, average loss: 1.2471
[09/16 08:59:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 59.07	top5: 92.30	
[09/16 08:59:01][INFO] visual_prompt:  246: Best epoch 45: best metric: 0.715
[09/16 08:59:01][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 08:59:11][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.62e-01, avg batch time: 0.5648, average train loss: 0.7548
[09/16 08:59:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1424, average loss: 1.1249
[09/16 08:59:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 68.50	top5: 94.00	
[09/16 08:59:39][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.920, 0.1958 s / batch. (data: 1.08e-02)max mem: 17.22449 GB 
[09/16 08:59:58][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.746, 0.1904 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 09:00:18][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.488, 0.1862 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 09:00:37][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.747, 0.1833 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 09:00:40][INFO] visual_prompt:  324: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1954, average loss: 1.6603
[09/16 09:00:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 57.30	top5: 90.31	
[09/16 09:00:40][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 09:00:52][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 1.65e-01, avg batch time: 0.5909, average train loss: 0.9979
[09/16 09:00:56][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1435, average loss: 0.8079
[09/16 09:00:56][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 75.50	top5: 94.50	
[09/16 09:01:18][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.505, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 09:01:38][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.423, 0.1925 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 09:01:57][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.970, 0.1947 s / batch. (data: 1.24e-02)max mem: 17.22449 GB 
[09/16 09:02:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.223, 0.1825 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 09:02:20][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1939, average loss: 1.2306
[09/16 09:02:20][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 65.88	top5: 91.63	
[09/16 09:02:20][INFO] visual_prompt:  246: Best epoch 47: best metric: 0.755
[09/16 09:02:20][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 09:02:30][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 1.56e-01, avg batch time: 0.5580, average train loss: 0.6650
[09/16 09:02:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1424, average loss: 0.5805
[09/16 09:02:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 83.50	top5: 99.50	
[09/16 09:02:57][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.625, 0.1868 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 09:03:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.336, 0.1871 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 09:03:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.041, 0.1832 s / batch. (data: 1.56e-04)max mem: 17.22449 GB 
[09/16 09:03:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.662, 0.1825 s / batch. (data: 3.67e-05)max mem: 17.22449 GB 
[09/16 09:03:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1932, average loss: 1.2597
[09/16 09:03:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 64.54	top5: 95.39	
[09/16 09:03:58][INFO] visual_prompt:  246: Best epoch 48: best metric: 0.835
[09/16 09:03:58][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 09:04:09][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 1.58e-01, avg batch time: 0.5594, average train loss: 0.6786
[09/16 09:04:14][INFO] visual_prompt:  324: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1426, average loss: 0.6642
[09/16 09:04:14][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 83.00	top5: 95.50	
[09/16 09:04:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 0.995, 0.1955 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 09:04:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.051, 0.2029 s / batch. (data: 2.12e-02)max mem: 17.22449 GB 
[09/16 09:05:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.828, 0.2422 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 09:05:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.052, 0.1823 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 09:05:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1935, average loss: 1.0628
[09/16 09:05:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 69.34	top5: 92.92	
[09/16 09:05:37][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 09:05:48][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 1.60e-01, avg batch time: 0.5607, average train loss: 0.5161
[09/16 09:05:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1425, average loss: 0.6576
[09/16 09:05:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 79.50	top5: 98.00	
[09/16 09:06:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.635, 0.1820 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 09:06:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.391, 0.1821 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 09:06:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.986, 0.1827 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 09:07:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.612, 0.1827 s / batch. (data: 2.96e-05)max mem: 17.22449 GB 
[09/16 09:07:17][INFO] visual_prompt:  324: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1950, average loss: 1.3319
[09/16 09:07:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 65.30	top5: 92.20	
[09/16 09:07:17][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 09:07:27][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.47e-01, avg batch time: 0.5509, average train loss: 0.4704
[09/16 09:07:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1425, average loss: 0.4592
[09/16 09:07:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 85.00	top5: 100.00	
[09/16 09:07:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.333, 0.2120 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 09:08:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.979, 0.1828 s / batch. (data: 1.48e-04)max mem: 17.22449 GB 
[09/16 09:08:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.876, 0.1981 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 09:08:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.191, 0.1836 s / batch. (data: 4.32e-05)max mem: 17.22449 GB 
[09/16 09:08:56][INFO] visual_prompt:  324: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1938, average loss: 0.9395
[09/16 09:08:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.58	top5: 96.26	
[09/16 09:08:56][INFO] visual_prompt:  246: Best epoch 51: best metric: 0.850
[09/16 09:08:56][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 09:09:07][INFO] visual_prompt:  219: Epoch 52 / 100: avg data time: 1.60e-01, avg batch time: 0.5649, average train loss: 0.3840
[09/16 09:09:11][INFO] visual_prompt:  324: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1423, average loss: 0.2673
[09/16 09:09:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 91.00	top5: 99.50	
[09/16 09:09:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.375, 0.2040 s / batch. (data: 2.22e-02)max mem: 17.22449 GB 
[09/16 09:09:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.928, 0.1960 s / batch. (data: 1.03e-04)max mem: 17.22449 GB 
[09/16 09:10:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.868, 0.1832 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 09:10:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.193, 0.1826 s / batch. (data: 4.55e-05)max mem: 17.22449 GB 
[09/16 09:10:35][INFO] visual_prompt:  324: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1936, average loss: 0.9569
[09/16 09:10:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 74.69	top5: 96.24	
[09/16 09:10:35][INFO] visual_prompt:  246: Best epoch 52: best metric: 0.910
[09/16 09:10:35][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 09:10:46][INFO] visual_prompt:  219: Epoch 53 / 100: avg data time: 1.57e-01, avg batch time: 0.5582, average train loss: 0.2820
[09/16 09:10:50][INFO] visual_prompt:  324: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1425, average loss: 0.3620
[09/16 09:10:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 87.50	top5: 98.50	
[09/16 09:11:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.700, 0.1963 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 09:11:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.736, 0.2108 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 09:11:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.303, 0.1833 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 09:12:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.408, 0.1829 s / batch. (data: 3.39e-05)max mem: 17.22449 GB 
[09/16 09:12:14][INFO] visual_prompt:  324: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1936, average loss: 1.3325
[09/16 09:12:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 71.25	top5: 94.95	
[09/16 09:12:14][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 09:12:25][INFO] visual_prompt:  219: Epoch 54 / 100: avg data time: 1.55e-01, avg batch time: 0.5561, average train loss: 0.3021
[09/16 09:12:29][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1426, average loss: 0.3688
[09/16 09:12:29][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 87.50	top5: 99.50	
[09/16 09:12:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.969, 0.1931 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 09:13:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.139, 0.1818 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 09:13:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.018, 0.1957 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 09:13:49][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.711, 0.1867 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 09:13:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.06e-03, avg batch time: 0.1929, average loss: 1.2199
[09/16 09:13:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 70.24	top5: 95.49	
[09/16 09:13:53][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 09:14:03][INFO] visual_prompt:  219: Epoch 55 / 100: avg data time: 1.58e-01, avg batch time: 0.5592, average train loss: 0.3231
[09/16 09:14:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1424, average loss: 0.2152
[09/16 09:14:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 93.00	top5: 100.00	
[09/16 09:14:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.399, 0.1960 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 09:14:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.978, 0.1849 s / batch. (data: 1.40e-04)max mem: 17.22449 GB 
[09/16 09:15:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.711, 0.1826 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 09:15:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.455, 0.1834 s / batch. (data: 3.72e-05)max mem: 17.22449 GB 
[09/16 09:15:32][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1947, average loss: 0.9842
[09/16 09:15:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 76.30	top5: 96.54	
[09/16 09:15:32][INFO] visual_prompt:  246: Best epoch 55: best metric: 0.930
[09/16 09:15:32][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 2.5
[09/16 09:15:42][INFO] visual_prompt:  219: Epoch 56 / 100: avg data time: 1.57e-01, avg batch time: 0.5567, average train loss: 0.2843
[09/16 09:15:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1425, average loss: 0.2705
[09/16 09:15:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 88.50	top5: 100.00	
[09/16 09:16:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.402, 0.2131 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 09:16:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.193, 0.1926 s / batch. (data: 1.47e-04)max mem: 17.22449 GB 
[09/16 09:16:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.786, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 09:17:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.315, 0.1829 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 09:17:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1938, average loss: 1.0420
[09/16 09:17:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.58	top5: 96.25	
[09/16 09:17:11][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 09:17:21][INFO] visual_prompt:  219: Epoch 57 / 100: avg data time: 1.59e-01, avg batch time: 0.5615, average train loss: 0.2791
[09/16 09:17:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1422, average loss: 0.1847
[09/16 09:17:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 94.00	top5: 100.00	
[09/16 09:17:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.178, 0.1830 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 09:18:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.201, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 09:18:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.673, 0.1876 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 09:18:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.051, 0.1832 s / batch. (data: 3.41e-05)max mem: 17.22449 GB 
[09/16 09:18:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1938, average loss: 0.9858
[09/16 09:18:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 76.66	top5: 96.78	
[09/16 09:18:50][INFO] visual_prompt:  246: Best epoch 57: best metric: 0.940
[09/16 09:18:50][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 09:19:00][INFO] visual_prompt:  219: Epoch 58 / 100: avg data time: 1.60e-01, avg batch time: 0.5592, average train loss: 0.1977
[09/16 09:19:05][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1426, average loss: 0.1247
[09/16 09:19:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 94.00	top5: 100.00	
[09/16 09:19:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 0.936, 0.1954 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 09:19:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.767, 0.2001 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 09:20:06][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.628, 0.1983 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 09:20:25][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.027, 0.1834 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 09:20:28][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1932, average loss: 0.8478
[09/16 09:20:29][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 78.82	top5: 97.58	
[09/16 09:20:29][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 09:20:39][INFO] visual_prompt:  219: Epoch 59 / 100: avg data time: 1.58e-01, avg batch time: 0.5590, average train loss: 0.1661
[09/16 09:20:44][INFO] visual_prompt:  324: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1424, average loss: 0.1131
[09/16 09:20:44][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 97.50	top5: 100.00	
[09/16 09:21:06][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.090, 0.2076 s / batch. (data: 2.63e-02)max mem: 17.22449 GB 
[09/16 09:21:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.276, 0.1958 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 09:21:45][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.579, 0.1824 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 09:22:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.047, 0.1829 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 09:22:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1926, average loss: 0.9265
[09/16 09:22:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 77.59	top5: 97.43	
[09/16 09:22:07][INFO] visual_prompt:  246: Best epoch 59: best metric: 0.975
[09/16 09:22:07][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 09:22:18][INFO] visual_prompt:  219: Epoch 60 / 100: avg data time: 1.68e-01, avg batch time: 0.5698, average train loss: 0.1005
[09/16 09:22:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1426, average loss: 0.0952
[09/16 09:22:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 96.50	top5: 100.00	
[09/16 09:22:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.994, 0.1826 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 09:23:04][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.388, 0.1939 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 09:23:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.660, 0.2147 s / batch. (data: 1.58e-02)max mem: 17.22449 GB 
[09/16 09:23:43][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.913, 0.1873 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 09:23:46][INFO] visual_prompt:  324: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1935, average loss: 1.3576
[09/16 09:23:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.92	top5: 97.16	
[09/16 09:23:46][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 09:23:56][INFO] visual_prompt:  219: Epoch 61 / 100: avg data time: 1.56e-01, avg batch time: 0.5580, average train loss: 0.1244
[09/16 09:24:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1425, average loss: 0.1200
[09/16 09:24:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 96.00	top5: 100.00	
[09/16 09:24:23][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.903, 0.1828 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 09:24:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.191, 0.1944 s / batch. (data: 1.28e-02)max mem: 17.22449 GB 
[09/16 09:25:02][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.006, 0.1913 s / batch. (data: 9.44e-03)max mem: 17.22449 GB 
[09/16 09:25:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.879, 0.1826 s / batch. (data: 3.77e-05)max mem: 17.22449 GB 
[09/16 09:25:24][INFO] visual_prompt:  324: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1934, average loss: 1.2252
[09/16 09:25:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 78.24	top5: 96.32	
[09/16 09:25:24][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 09:25:35][INFO] visual_prompt:  219: Epoch 62 / 100: avg data time: 1.61e-01, avg batch time: 0.5617, average train loss: 0.2074
[09/16 09:25:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1426, average loss: 0.2308
[09/16 09:25:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 90.00	top5: 100.00	
[09/16 09:26:01][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.301, 0.1971 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 09:26:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.089, 0.2076 s / batch. (data: 2.56e-02)max mem: 17.22449 GB 
[09/16 09:26:41][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.085, 0.1923 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 09:27:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.530, 0.2159 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 09:27:03][INFO] visual_prompt:  324: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1940, average loss: 1.1187
[09/16 09:27:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.13	top5: 97.16	
[09/16 09:27:03][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 09:27:14][INFO] visual_prompt:  219: Epoch 63 / 100: avg data time: 1.70e-01, avg batch time: 0.5695, average train loss: 0.2132
[09/16 09:27:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1424, average loss: 0.1142
[09/16 09:27:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 97.00	top5: 100.00	
[09/16 09:27:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.020, 0.1930 s / batch. (data: 1.12e-02)max mem: 17.22449 GB 
[09/16 09:28:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.938, 0.1829 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 09:28:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.745, 0.1828 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 09:28:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 0.851, 0.1826 s / batch. (data: 3.53e-05)max mem: 17.22449 GB 
[09/16 09:28:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1937, average loss: 0.8159
[09/16 09:28:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.66	top5: 97.70	
[09/16 09:28:42][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 09:28:53][INFO] visual_prompt:  219: Epoch 64 / 100: avg data time: 1.54e-01, avg batch time: 0.5533, average train loss: 0.0955
[09/16 09:28:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1423, average loss: 0.0290
[09/16 09:28:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 98.50	top5: 100.00	
[09/16 09:29:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.979, 0.2202 s / batch. (data: 3.84e-02)max mem: 17.22449 GB 
[09/16 09:29:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.339, 0.2198 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 09:29:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.153, 0.2028 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 09:30:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.379, 0.1823 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 09:30:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1939, average loss: 1.2176
[09/16 09:30:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 77.64	top5: 96.83	
[09/16 09:30:21][INFO] visual_prompt:  246: Best epoch 64: best metric: 0.985
[09/16 09:30:21][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 09:30:32][INFO] visual_prompt:  219: Epoch 65 / 100: avg data time: 1.37e-01, avg batch time: 0.5404, average train loss: 0.1260
[09/16 09:30:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1425, average loss: 0.1714
[09/16 09:30:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 96.50	top5: 99.50	
[09/16 09:30:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.836, 0.1824 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 09:31:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.264, 0.1827 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 09:31:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.467, 0.1843 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 09:31:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.485, 0.1823 s / batch. (data: 4.01e-05)max mem: 17.22449 GB 
[09/16 09:31:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1927, average loss: 1.3177
[09/16 09:31:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 75.19	top5: 95.13	
[09/16 09:31:59][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 09:32:10][INFO] visual_prompt:  219: Epoch 66 / 100: avg data time: 1.57e-01, avg batch time: 0.5580, average train loss: 0.1487
[09/16 09:32:15][INFO] visual_prompt:  324: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1492, average loss: 0.0765
[09/16 09:32:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 97.50	top5: 100.00	
[09/16 09:32:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.532, 0.1828 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 09:32:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.728, 0.1964 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 09:33:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.050, 0.1885 s / batch. (data: 1.56e-04)max mem: 17.22449 GB 
[09/16 09:33:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.419, 0.1832 s / batch. (data: 4.77e-05)max mem: 17.22449 GB 
[09/16 09:33:38][INFO] visual_prompt:  324: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1939, average loss: 1.0179
[09/16 09:33:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 78.17	top5: 97.50	
[09/16 09:33:38][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 09:33:49][INFO] visual_prompt:  219: Epoch 67 / 100: avg data time: 1.62e-01, avg batch time: 0.5628, average train loss: 0.0898
[09/16 09:33:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1425, average loss: 0.1166
[09/16 09:33:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 95.50	top5: 100.00	
[09/16 09:34:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.007, 0.1984 s / batch. (data: 1.67e-02)max mem: 17.22449 GB 
[09/16 09:34:35][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.374, 0.1840 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 09:34:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.279, 0.2077 s / batch. (data: 2.57e-02)max mem: 17.22449 GB 
[09/16 09:35:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.436, 0.1835 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 09:35:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1928, average loss: 1.2065
[09/16 09:35:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 77.87	top5: 96.77	
[09/16 09:35:17][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 09:35:27][INFO] visual_prompt:  219: Epoch 68 / 100: avg data time: 1.49e-01, avg batch time: 0.5506, average train loss: 0.0672
[09/16 09:35:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1425, average loss: 0.0126
[09/16 09:35:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:35:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.658, 0.1827 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 09:36:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.947, 0.1830 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 09:36:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.783, 0.1825 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 09:36:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.671, 0.1827 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 09:36:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1925, average loss: 1.0440
[09/16 09:36:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.97	top5: 97.66	
[09/16 09:36:55][INFO] visual_prompt:  246: Best epoch 68: best metric: 1.000
[09/16 09:36:55][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 09:37:06][INFO] visual_prompt:  219: Epoch 69 / 100: avg data time: 1.63e-01, avg batch time: 0.5639, average train loss: 0.0443
[09/16 09:37:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1427, average loss: 0.0441
[09/16 09:37:10][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 98.50	top5: 100.00	
[09/16 09:37:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.544, 0.1961 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 09:37:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.289, 0.2040 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 09:38:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.047, 0.2370 s / batch. (data: 5.57e-02)max mem: 17.22449 GB 
[09/16 09:38:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.992, 0.1826 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 09:38:35][INFO] visual_prompt:  324: Inference (test):avg data time: 8.13e-03, avg batch time: 0.1951, average loss: 1.2092
[09/16 09:38:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.91	top5: 97.18	
[09/16 09:38:35][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 09:38:46][INFO] visual_prompt:  219: Epoch 70 / 100: avg data time: 1.66e-01, avg batch time: 0.5844, average train loss: 0.0675
[09/16 09:38:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1425, average loss: 0.0158
[09/16 09:38:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.50	top5: 100.00	
[09/16 09:39:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.696, 0.1820 s / batch. (data: 1.41e-04)max mem: 17.22449 GB 
[09/16 09:39:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.136, 0.1945 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 09:39:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.164, 0.1952 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 09:40:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.841, 0.1827 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 09:40:14][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1932, average loss: 1.2509
[09/16 09:40:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.58	top5: 96.90	
[09/16 09:40:14][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 09:40:25][INFO] visual_prompt:  219: Epoch 71 / 100: avg data time: 1.62e-01, avg batch time: 0.5638, average train loss: 0.0685
[09/16 09:40:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1425, average loss: 0.0395
[09/16 09:40:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 97.50	top5: 100.00	
[09/16 09:40:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.855, 0.2052 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 09:41:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.382, 0.1820 s / batch. (data: 1.41e-04)max mem: 17.22449 GB 
[09/16 09:41:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.052, 0.2028 s / batch. (data: 2.12e-02)max mem: 17.22449 GB 
[09/16 09:41:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.673, 0.1827 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 09:41:53][INFO] visual_prompt:  324: Inference (test):avg data time: 8.94e-03, avg batch time: 0.1933, average loss: 1.1276
[09/16 09:41:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.84	top5: 96.96	
[09/16 09:41:53][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 09:42:04][INFO] visual_prompt:  219: Epoch 72 / 100: avg data time: 1.64e-01, avg batch time: 0.5661, average train loss: 0.0485
[09/16 09:42:08][INFO] visual_prompt:  324: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1424, average loss: 0.0615
[09/16 09:42:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 98.00	top5: 100.00	
[09/16 09:42:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.995, 0.2048 s / batch. (data: 2.32e-02)max mem: 17.22449 GB 
[09/16 09:42:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.705, 0.1997 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 09:43:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.259, 0.1821 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 09:43:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.259, 0.1830 s / batch. (data: 3.46e-05)max mem: 17.22449 GB 
[09/16 09:43:32][INFO] visual_prompt:  324: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1935, average loss: 1.3564
[09/16 09:43:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 78.30	top5: 96.88	
[09/16 09:43:32][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 09:43:42][INFO] visual_prompt:  219: Epoch 73 / 100: avg data time: 1.51e-01, avg batch time: 0.5531, average train loss: 0.0335
[09/16 09:43:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1426, average loss: 0.0071
[09/16 09:43:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:44:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.794, 0.1821 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 09:44:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.221, 0.1966 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 09:44:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.959, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 09:45:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.990, 0.1826 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 09:45:10][INFO] visual_prompt:  324: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1931, average loss: 1.1967
[09/16 09:45:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.01	top5: 97.26	
[09/16 09:45:10][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 09:45:21][INFO] visual_prompt:  219: Epoch 74 / 100: avg data time: 1.59e-01, avg batch time: 0.5618, average train loss: 0.0179
[09/16 09:45:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1425, average loss: 0.0017
[09/16 09:45:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:45:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.025, 0.1956 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 09:46:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.259, 0.1827 s / batch. (data: 9.44e-05)max mem: 17.22449 GB 
[09/16 09:46:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.961, 0.1968 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 09:46:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.065, 0.1828 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 09:46:49][INFO] visual_prompt:  324: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1935, average loss: 1.3108
[09/16 09:46:49][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.98	top5: 97.34	
[09/16 09:46:49][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 09:47:00][INFO] visual_prompt:  219: Epoch 75 / 100: avg data time: 1.53e-01, avg batch time: 0.5585, average train loss: 0.0147
[09/16 09:47:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1425, average loss: 0.0247
[09/16 09:47:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.50	top5: 100.00	
[09/16 09:47:26][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.798, 0.1827 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 09:47:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.792, 0.1824 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 09:48:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.506, 0.2072 s / batch. (data: 2.60e-02)max mem: 17.22449 GB 
[09/16 09:48:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.655, 0.1823 s / batch. (data: 4.70e-05)max mem: 17.22449 GB 
[09/16 09:48:28][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1928, average loss: 1.7182
[09/16 09:48:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.02	top5: 96.98	
[09/16 09:48:28][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 09:48:38][INFO] visual_prompt:  219: Epoch 76 / 100: avg data time: 1.48e-01, avg batch time: 0.5496, average train loss: 0.0178
[09/16 09:48:43][INFO] visual_prompt:  324: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1426, average loss: 0.0061
[09/16 09:48:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.50	top5: 100.00	
[09/16 09:49:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.350, 0.1817 s / batch. (data: 9.61e-05)max mem: 17.22449 GB 
[09/16 09:49:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.620, 0.1968 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 09:49:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.375, 0.2086 s / batch. (data: 2.64e-02)max mem: 17.22449 GB 
[09/16 09:50:03][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.926, 0.1821 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 09:50:06][INFO] visual_prompt:  324: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1930, average loss: 1.5277
[09/16 09:50:06][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.87	top5: 97.27	
[09/16 09:50:06][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 09:50:17][INFO] visual_prompt:  219: Epoch 77 / 100: avg data time: 1.60e-01, avg batch time: 0.5630, average train loss: 0.0123
[09/16 09:50:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1426, average loss: 0.0013
[09/16 09:50:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:50:43][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.443, 0.1824 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 09:51:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.453, 0.1822 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 09:51:22][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.234, 0.1954 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 09:51:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.461, 0.1819 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 09:51:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1951, average loss: 1.5638
[09/16 09:51:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.84	top5: 97.43	
[09/16 09:51:46][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 09:51:56][INFO] visual_prompt:  219: Epoch 78 / 100: avg data time: 1.61e-01, avg batch time: 0.5608, average train loss: 0.0073
[09/16 09:52:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1425, average loss: 0.0068
[09/16 09:52:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 99.50	top5: 100.00	
[09/16 09:52:23][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.985, 0.1969 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 09:52:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.513, 0.2039 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 09:53:02][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.451, 0.2123 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 09:53:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.016, 0.1826 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 09:53:25][INFO] visual_prompt:  324: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1946, average loss: 1.5318
[09/16 09:53:25][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 80.29	top5: 97.38	
[09/16 09:53:25][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 09:53:36][INFO] visual_prompt:  219: Epoch 79 / 100: avg data time: 1.54e-01, avg batch time: 0.5547, average train loss: 0.0021
[09/16 09:53:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1424, average loss: 0.0017
[09/16 09:53:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:54:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.449, 0.1950 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 09:54:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.877, 0.1974 s / batch. (data: 1.57e-02)max mem: 17.22449 GB 
[09/16 09:54:41][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.621, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 09:55:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.160, 0.2376 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 09:55:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1924, average loss: 1.6252
[09/16 09:55:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 79.99	top5: 97.39	
[09/16 09:55:04][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 09:55:14][INFO] visual_prompt:  219: Epoch 80 / 100: avg data time: 1.63e-01, avg batch time: 0.5628, average train loss: 0.0025
[09/16 09:55:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1424, average loss: 0.0002
[09/16 09:55:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:55:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.417, 0.1825 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 09:56:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.753, 0.1954 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 09:56:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.387, 0.1953 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 09:56:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.265, 0.1830 s / batch. (data: 3.46e-05)max mem: 17.22449 GB 
[09/16 09:56:43][INFO] visual_prompt:  324: Inference (test):avg data time: 8.55e-03, avg batch time: 0.1937, average loss: 1.5288
[09/16 09:56:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.47	top5: 97.61	
[09/16 09:56:43][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 09:56:53][INFO] visual_prompt:  219: Epoch 81 / 100: avg data time: 1.60e-01, avg batch time: 0.5632, average train loss: 0.0010
[09/16 09:56:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1425, average loss: 0.0001
[09/16 09:56:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:57:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.187, 0.2028 s / batch. (data: 6.37e-05)max mem: 17.22449 GB 
[09/16 09:57:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.632, 0.2191 s / batch. (data: 3.71e-02)max mem: 17.22449 GB 
[09/16 09:57:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.368, 0.2182 s / batch. (data: 3.63e-02)max mem: 17.22449 GB 
[09/16 09:58:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.260, 0.1829 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 09:58:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1943, average loss: 1.5179
[09/16 09:58:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.52	top5: 97.60	
[09/16 09:58:22][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 09:58:33][INFO] visual_prompt:  219: Epoch 82 / 100: avg data time: 1.60e-01, avg batch time: 0.5817, average train loss: 0.0036
[09/16 09:58:38][INFO] visual_prompt:  324: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1438, average loss: 0.0003
[09/16 09:58:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 09:59:00][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.068, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 09:59:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.589, 0.2015 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 09:59:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.360, 0.2181 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 09:59:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.052, 0.1819 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 10:00:01][INFO] visual_prompt:  324: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1931, average loss: 1.4491
[09/16 10:00:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.67	top5: 97.72	
[09/16 10:00:01][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 10:00:12][INFO] visual_prompt:  219: Epoch 83 / 100: avg data time: 1.57e-01, avg batch time: 0.5567, average train loss: 0.0008
[09/16 10:00:16][INFO] visual_prompt:  324: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1437, average loss: 0.0005
[09/16 10:00:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:00:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.075, 0.1956 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 10:00:58][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.680, 0.1968 s / batch. (data: 1.61e-04)max mem: 17.22449 GB 
[09/16 10:01:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.326, 0.1957 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 10:01:37][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.147, 0.1825 s / batch. (data: 3.67e-05)max mem: 17.22449 GB 
[09/16 10:01:40][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1940, average loss: 1.5129
[09/16 10:01:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.18	top5: 97.61	
[09/16 10:01:40][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 10:01:51][INFO] visual_prompt:  219: Epoch 84 / 100: avg data time: 1.52e-01, avg batch time: 0.5558, average train loss: 0.0004
[09/16 10:01:55][INFO] visual_prompt:  324: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1424, average loss: 0.0002
[09/16 10:01:55][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:02:17][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.087, 0.1963 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 10:02:37][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.662, 0.1825 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 10:02:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.289, 0.2079 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 10:03:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.171, 0.1825 s / batch. (data: 3.89e-05)max mem: 17.22449 GB 
[09/16 10:03:19][INFO] visual_prompt:  324: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1939, average loss: 1.5007
[09/16 10:03:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.23	top5: 97.59	
[09/16 10:03:19][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 10:03:30][INFO] visual_prompt:  219: Epoch 85 / 100: avg data time: 1.53e-01, avg batch time: 0.5558, average train loss: 0.0004
[09/16 10:03:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1426, average loss: 0.0001
[09/16 10:03:34][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:03:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.110, 0.1825 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 10:04:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.656, 0.1827 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 10:04:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.281, 0.2377 s / batch. (data: 5.63e-02)max mem: 17.22449 GB 
[09/16 10:04:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.178, 0.1823 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 10:04:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1942, average loss: 1.4947
[09/16 10:04:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.35	top5: 97.58	
[09/16 10:04:58][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 10:05:09][INFO] visual_prompt:  219: Epoch 86 / 100: avg data time: 1.47e-01, avg batch time: 0.5547, average train loss: 0.0002
[09/16 10:05:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1426, average loss: 0.0001
[09/16 10:05:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:05:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.089, 0.1824 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 10:05:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.633, 0.2016 s / batch. (data: 1.98e-02)max mem: 17.22449 GB 
[09/16 10:06:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.273, 0.2075 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 10:06:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.159, 0.1825 s / batch. (data: 3.98e-05)max mem: 17.22449 GB 
[09/16 10:06:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1931, average loss: 1.4806
[09/16 10:06:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.41	top5: 97.60	
[09/16 10:06:37][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 10:06:48][INFO] visual_prompt:  219: Epoch 87 / 100: avg data time: 1.59e-01, avg batch time: 0.5624, average train loss: 0.0003
[09/16 10:06:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1424, average loss: 0.0001
[09/16 10:06:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:07:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.073, 0.1948 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 10:07:33][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.617, 0.1967 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 10:07:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.260, 0.1827 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 10:08:12][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.147, 0.1819 s / batch. (data: 2.48e-05)max mem: 17.22449 GB 
[09/16 10:08:15][INFO] visual_prompt:  324: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1924, average loss: 1.4687
[09/16 10:08:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.47	top5: 97.61	
[09/16 10:08:15][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 10:08:26][INFO] visual_prompt:  219: Epoch 88 / 100: avg data time: 1.65e-01, avg batch time: 0.5652, average train loss: 0.0002
[09/16 10:08:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1426, average loss: 0.0001
[09/16 10:08:31][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:08:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.057, 0.1816 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 10:09:12][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.600, 0.1828 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 10:09:31][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.242, 0.2020 s / batch. (data: 1.75e-02)max mem: 17.22449 GB 
[09/16 10:09:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.140, 0.1924 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 10:09:54][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1928, average loss: 1.4579
[09/16 10:09:54][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.54	top5: 97.62	
[09/16 10:09:54][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 10:10:05][INFO] visual_prompt:  219: Epoch 89 / 100: avg data time: 1.67e-01, avg batch time: 0.5670, average train loss: 0.0002
[09/16 10:10:09][INFO] visual_prompt:  324: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1426, average loss: 0.0000
[09/16 10:10:09][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:10:31][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.039, 0.1946 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 10:10:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.587, 0.2101 s / batch. (data: 9.16e-05)max mem: 17.22449 GB 
[09/16 10:11:10][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.229, 0.1992 s / batch. (data: 1.72e-02)max mem: 17.22449 GB 
[09/16 10:11:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.141, 0.1822 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 10:11:32][INFO] visual_prompt:  324: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1933, average loss: 1.4498
[09/16 10:11:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.60	top5: 97.62	
[09/16 10:11:32][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 10:11:43][INFO] visual_prompt:  219: Epoch 90 / 100: avg data time: 1.53e-01, avg batch time: 0.5584, average train loss: 0.0002
[09/16 10:11:48][INFO] visual_prompt:  324: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1425, average loss: 0.0000
[09/16 10:11:48][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:12:10][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.029, 0.2051 s / batch. (data: 1.05e-04)max mem: 17.22449 GB 
[09/16 10:12:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.577, 0.1828 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 10:12:49][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.223, 0.1832 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 10:13:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.140, 0.1827 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 10:13:12][INFO] visual_prompt:  324: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1946, average loss: 1.4435
[09/16 10:13:12][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.61	top5: 97.63	
[09/16 10:13:12][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 10:13:23][INFO] visual_prompt:  219: Epoch 91 / 100: avg data time: 1.64e-01, avg batch time: 0.5656, average train loss: 0.0002
[09/16 10:13:27][INFO] visual_prompt:  324: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1425, average loss: 0.0000
[09/16 10:13:27][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:13:49][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.031, 0.1820 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 10:14:08][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.573, 0.1956 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 10:14:28][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.222, 0.2010 s / batch. (data: 1.24e-02)max mem: 17.22449 GB 
[09/16 10:14:47][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.144, 0.1831 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 10:14:51][INFO] visual_prompt:  324: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1943, average loss: 1.4412
[09/16 10:14:51][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.65	top5: 97.63	
[09/16 10:14:51][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 10:15:01][INFO] visual_prompt:  219: Epoch 92 / 100: avg data time: 1.46e-01, avg batch time: 0.5488, average train loss: 0.0002
[09/16 10:15:06][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1426, average loss: 0.0000
[09/16 10:15:06][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:15:28][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.030, 0.1825 s / batch. (data: 1.48e-04)max mem: 17.22449 GB 
[09/16 10:15:47][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.573, 0.1829 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 10:16:07][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.222, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 10:16:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.140, 0.1828 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 10:16:30][INFO] visual_prompt:  324: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1929, average loss: 1.4396
[09/16 10:16:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.62	top5: 97.61	
[09/16 10:16:30][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 10:16:40][INFO] visual_prompt:  219: Epoch 93 / 100: avg data time: 1.55e-01, avg batch time: 0.5571, average train loss: 0.0002
[09/16 10:16:45][INFO] visual_prompt:  324: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1424, average loss: 0.0000
[09/16 10:16:45][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:17:07][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.033, 0.1826 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 10:17:26][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.575, 0.1829 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 10:17:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.224, 0.1950 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 10:18:05][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.139, 0.1818 s / batch. (data: 4.27e-05)max mem: 17.22449 GB 
[09/16 10:18:08][INFO] visual_prompt:  324: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1930, average loss: 1.4394
[09/16 10:18:08][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.62	top5: 97.62	
[09/16 10:18:08][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 10:18:19][INFO] visual_prompt:  219: Epoch 94 / 100: avg data time: 1.50e-01, avg batch time: 0.5515, average train loss: 0.0001
[09/16 10:18:23][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1425, average loss: 0.0000
[09/16 10:18:23][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:18:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.030, 0.1823 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 10:19:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.573, 0.1973 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 10:19:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.223, 0.2026 s / batch. (data: 1.78e-02)max mem: 17.22449 GB 
[09/16 10:19:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.137, 0.1825 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 10:19:47][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1943, average loss: 1.4374
[09/16 10:19:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.61	top5: 97.61	
[09/16 10:19:47][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 10:19:58][INFO] visual_prompt:  219: Epoch 95 / 100: avg data time: 1.55e-01, avg batch time: 0.5588, average train loss: 0.0002
[09/16 10:20:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1425, average loss: 0.0000
[09/16 10:20:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:20:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.030, 0.1820 s / batch. (data: 9.06e-05)max mem: 17.22449 GB 
[09/16 10:20:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.571, 0.1829 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 10:21:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.220, 0.1949 s / batch. (data: 1.31e-02)max mem: 17.22449 GB 
[09/16 10:21:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.138, 0.1828 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 10:21:27][INFO] visual_prompt:  324: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1958, average loss: 1.4361
[09/16 10:21:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.64	top5: 97.61	
[09/16 10:21:27][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 10:21:38][INFO] visual_prompt:  219: Epoch 96 / 100: avg data time: 1.62e-01, avg batch time: 0.5610, average train loss: 0.0001
[09/16 10:21:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1425, average loss: 0.0000
[09/16 10:21:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:22:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.029, 0.1958 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 10:22:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.570, 0.1960 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 10:22:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.219, 0.1828 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 10:23:03][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.138, 0.1826 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 10:23:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1949, average loss: 1.4355
[09/16 10:23:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.64	top5: 97.61	
[09/16 10:23:07][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 10:23:18][INFO] visual_prompt:  219: Epoch 97 / 100: avg data time: 1.62e-01, avg batch time: 0.5626, average train loss: 0.0002
[09/16 10:23:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1423, average loss: 0.0000
[09/16 10:23:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:23:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.028, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 10:24:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.569, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 10:24:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.219, 0.1961 s / batch. (data: 1.25e-04)max mem: 17.22449 GB 
[09/16 10:24:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.138, 0.1827 s / batch. (data: 4.01e-05)max mem: 17.22449 GB 
[09/16 10:24:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1936, average loss: 1.4350
[09/16 10:24:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.64	top5: 97.61	
[09/16 10:24:46][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 10:24:56][INFO] visual_prompt:  219: Epoch 98 / 100: avg data time: 1.58e-01, avg batch time: 0.5590, average train loss: 0.0002
[09/16 10:25:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1427, average loss: 0.0000
[09/16 10:25:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:25:23][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.028, 0.1825 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 10:25:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.570, 0.2107 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 10:26:02][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.219, 0.1818 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 10:26:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.138, 0.1828 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 10:26:24][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1927, average loss: 1.4346
[09/16 10:26:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.65	top5: 97.61	
[09/16 10:26:24][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 10:26:35][INFO] visual_prompt:  219: Epoch 99 / 100: avg data time: 1.45e-01, avg batch time: 0.5469, average train loss: 0.0002
[09/16 10:26:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1424, average loss: 0.0000
[09/16 10:26:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:27:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.027, 0.1930 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 10:27:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.569, 0.1834 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 10:27:41][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.218, 0.1829 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 10:28:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.137, 0.1823 s / batch. (data: 3.43e-05)max mem: 17.22449 GB 
[09/16 10:28:03][INFO] visual_prompt:  324: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1940, average loss: 1.4342
[09/16 10:28:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.65	top5: 97.61	
[09/16 10:28:03][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 10:28:14][INFO] visual_prompt:  219: Epoch 100 / 100: avg data time: 1.56e-01, avg batch time: 0.5562, average train loss: 0.0002
[09/16 10:28:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1426, average loss: 0.0000
[09/16 10:28:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 100.00	top5: 100.00	
[09/16 10:28:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.027, 0.1957 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 10:29:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.569, 0.1826 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 10:29:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.218, 0.1963 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 10:29:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.138, 0.1824 s / batch. (data: 4.20e-05)max mem: 17.22449 GB 
[09/16 10:29:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1932, average loss: 1.4342
[09/16 10:29:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 81.65	top5: 97.61	
