[11/06 17:40:58][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/06 17:40:58][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                Quadro RTX 6000
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/06 17:40:58][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/finetune/cub.yaml', train_type='finetune', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '1', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[11/06 17:40:58][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/finetune/cub.yaml:
_BASE_: "../base-finetune.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
  FEATURE: "imagenet_supervised"  # need to tune
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.00375
  WEIGHT_DECAY: 0.01

[11/06 17:40:58][INFO] visual_prompt:  108: Training with config:
[11/06 17:40:58][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/end2end/crop224/val/seed0/lr0.005_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'end2end', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'adamw', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.005, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 5, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 1, 'NUM_WORKERS': 8, 'PIN_MEMORY': True})})
[11/06 17:40:58][INFO] visual_prompt:   55: Loading training data...
[11/06 17:40:58][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/06 17:40:58][INFO] visual_prompt:   57: Loading validation data...
[11/06 17:40:58][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/06 17:40:58][INFO] visual_prompt:   38: Constructing models...
[11/06 17:41:01][INFO] visual_prompt:  153: Enable all parameters update during training
[11/06 17:41:01][INFO] visual_prompt:   52: Total Parameters: 85800194	 Gradient Parameters: 85800194
[11/06 17:41:01][INFO] visual_prompt:   54: tuned percent:100.000
[11/06 17:41:01][INFO] visual_prompt:   40: Device used for model: 0
[11/06 17:41:01][INFO] visual_prompt:   40: Setting up Evaluator...
[11/06 17:41:01][INFO] visual_prompt:   42: Setting up Trainer...
[11/06 17:41:01][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/06 17:41:01][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/06 17:41:25][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 17.0073,	0.1965 s / batch. (data: 2.57e-02). ETA=12:04:03, max mem: 1.4 GB 
[11/06 17:41:46][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 8.7706,	0.1793 s / batch. (data: 9.77e-04). ETA=11:00:28, max mem: 1.4 GB 
[11/06 17:42:06][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.0001,	0.1726 s / batch. (data: 1.08e-02). ETA=10:35:26, max mem: 1.4 GB 
[11/06 17:42:25][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 9.7364,	0.1248 s / batch. (data: 5.52e-04). ETA=7:39:18, max mem: 1.4 GB 
[11/06 17:42:46][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 9.6752,	0.1014 s / batch. (data: 1.52e-02). ETA=6:12:51, max mem: 1.4 GB 
[11/06 17:43:07][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.0000,	0.1929 s / batch. (data: 1.60e-02). ETA=11:49:22, max mem: 1.4 GB 
[11/06 17:43:28][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 10.7484,	0.1284 s / batch. (data: 1.47e-02). ETA=7:51:49, max mem: 1.4 GB 
[11/06 17:43:48][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 10.3468,	0.1992 s / batch. (data: 5.70e-03). ETA=12:11:49, max mem: 1.4 GB 
[11/06 17:44:09][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.0000,	0.1970 s / batch. (data: 4.42e-03). ETA=12:03:09, max mem: 1.4 GB 
[11/06 17:44:28][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.0001,	0.1814 s / batch. (data: 4.78e-02). ETA=11:05:42, max mem: 1.4 GB 
[11/06 17:44:48][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.0000,	0.0512 s / batch. (data: 7.36e-04). ETA=3:07:40, max mem: 1.4 GB 
[11/06 17:45:08][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.0000,	0.1525 s / batch. (data: 1.54e-02). ETA=9:19:16, max mem: 1.4 GB 
[11/06 17:45:27][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.0000,	0.1580 s / batch. (data: 1.82e-04). ETA=9:39:07, max mem: 1.4 GB 
[11/06 17:45:49][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.0027,	0.1339 s / batch. (data: 1.80e-04). ETA=8:10:36, max mem: 1.4 GB 
[11/06 17:46:09][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 5.3648,	0.1425 s / batch. (data: 3.45e-02). ETA=8:41:43, max mem: 1.4 GB 
[11/06 17:46:28][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 5.2697,	0.1756 s / batch. (data: 1.76e-04). ETA=10:42:48, max mem: 1.4 GB 
[11/06 17:46:48][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.0000,	0.1681 s / batch. (data: 1.31e-02). ETA=10:14:59, max mem: 1.4 GB 
[11/06 17:47:09][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.0000,	0.4998 s / batch. (data: 4.06e-01). ETA=1 day, 6:27:41, max mem: 1.4 GB 
[11/06 17:47:28][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 8.6260,	0.1886 s / batch. (data: 2.37e-02). ETA=11:29:12, max mem: 1.4 GB 
[11/06 17:47:49][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.0002,	0.1231 s / batch. (data: 2.48e-04). ETA=7:29:39, max mem: 1.4 GB 
[11/06 17:48:08][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 14.9015,	0.1639 s / batch. (data: 3.37e-02). ETA=9:58:35, max mem: 1.4 GB 
[11/06 17:48:27][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 7.6808,	0.0946 s / batch. (data: 7.13e-05). ETA=5:45:13, max mem: 1.4 GB 
[11/06 17:48:28][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 5.80e-02, avg batch time: 0.2020, average train loss: 5.2946
[11/06 17:48:48][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.001, 0.0572 s / batch. (data: 1.93e-05)max mem: 1.44029 GB 
[11/06 17:49:07][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.002, 0.0368 s / batch. (data: 2.53e-05)max mem: 1.44029 GB 
[11/06 17:49:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.11e-04, avg batch time: 0.0337, average loss: 4.3337
[11/06 17:49:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.86	
[11/06 17:49:14][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.001
[11/06 17:49:37][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.0110,	0.1568 s / batch. (data: 1.03e-02). ETA=9:32:06, max mem: 1.4 GB 
[11/06 17:49:57][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.0058,	0.1952 s / batch. (data: 4.64e-02). ETA=11:51:51, max mem: 1.4 GB 
[11/06 17:50:17][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.3867,	0.1659 s / batch. (data: 1.05e-02). ETA=10:04:46, max mem: 1.4 GB 
[11/06 17:50:36][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 1.3777,	0.1865 s / batch. (data: 1.54e-02). ETA=11:19:34, max mem: 1.4 GB 
[11/06 17:50:55][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.3260,	0.1961 s / batch. (data: 1.45e-02). ETA=11:54:13, max mem: 1.4 GB 
[11/06 17:51:14][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.2823,	0.2053 s / batch. (data: 3.95e-02). ETA=12:27:21, max mem: 1.4 GB 
[11/06 17:51:33][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 1.1778,	0.1542 s / batch. (data: 2.25e-02). ETA=9:20:53, max mem: 1.4 GB 
[11/06 17:51:54][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.2036,	0.1317 s / batch. (data: 1.67e-04). ETA=7:58:58, max mem: 1.4 GB 
[11/06 17:52:14][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.3994,	0.1787 s / batch. (data: 1.04e-02). ETA=10:49:33, max mem: 1.4 GB 
[11/06 17:52:35][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 1.7676,	0.1689 s / batch. (data: 5.33e-03). ETA=10:13:33, max mem: 1.4 GB 
[11/06 17:52:55][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.0406,	0.1981 s / batch. (data: 3.61e-02). ETA=11:59:14, max mem: 1.4 GB 
[11/06 17:53:14][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.8795,	0.1856 s / batch. (data: 1.49e-02). ETA=11:13:47, max mem: 1.4 GB 
[11/06 17:53:36][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 1.6760,	0.9187 s / batch. (data: 7.72e-01). ETA=2 days, 7:33:10, max mem: 1.4 GB 
[11/06 17:53:56][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 1.4970,	0.6038 s / batch. (data: 4.60e-01). ETA=1 day, 12:29:29, max mem: 1.4 GB 
[11/06 17:54:16][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.9697,	0.1986 s / batch. (data: 2.09e-02). ETA=12:00:00, max mem: 1.4 GB 
[11/06 17:54:36][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 1.3313,	0.2046 s / batch. (data: 1.08e-02). ETA=12:21:18, max mem: 1.4 GB 
[11/06 17:54:55][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.3226,	0.1521 s / batch. (data: 4.66e-04). ETA=9:10:41, max mem: 1.4 GB 
[11/06 17:55:15][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.4831,	0.1350 s / batch. (data: 2.03e-04). ETA=8:08:50, max mem: 1.4 GB 
[11/06 17:55:35][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.1575,	0.0877 s / batch. (data: 1.76e-04). ETA=5:17:28, max mem: 1.4 GB 
[11/06 17:55:54][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.6884,	0.1528 s / batch. (data: 5.34e-03). ETA=9:12:37, max mem: 1.4 GB 
[11/06 17:56:13][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.1138,	0.2040 s / batch. (data: 2.13e-03). ETA=12:17:17, max mem: 1.4 GB 
[11/06 17:56:33][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.4864,	0.0478 s / batch. (data: 7.37e-05). ETA=2:52:52, max mem: 1.4 GB 
[11/06 17:56:33][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.91e-02, avg batch time: 0.1985, average train loss: 1.4344
[11/06 17:56:53][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.152, 0.0561 s / batch. (data: 1.93e-05)max mem: 1.44029 GB 
[11/06 17:57:11][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.149, 0.0627 s / batch. (data: 2.05e-05)max mem: 1.44029 GB 
[11/06 17:57:19][INFO] visual_prompt:  316: Inference (val):avg data time: 8.42e-04, avg batch time: 0.0410, average loss: 1.1422
[11/06 17:57:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.83	
[11/06 17:57:19][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.002
[11/06 17:57:40][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.4078,	0.1850 s / batch. (data: 5.53e-04). ETA=11:08:07, max mem: 1.4 GB 
[11/06 17:58:00][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 3.2550,	0.1843 s / batch. (data: 4.50e-02). ETA=11:05:14, max mem: 1.4 GB 
[11/06 17:58:20][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 2.6896,	0.1335 s / batch. (data: 5.29e-03). ETA=8:01:48, max mem: 1.4 GB 
[11/06 17:58:41][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 1.0970,	0.1720 s / batch. (data: 3.71e-02). ETA=10:20:21, max mem: 1.4 GB 
[11/06 17:59:00][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 2.0802,	0.1702 s / batch. (data: 1.65e-02). ETA=10:13:19, max mem: 1.4 GB 
[11/06 17:59:21][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 1.2381,	0.1572 s / batch. (data: 7.12e-03). ETA=9:26:23, max mem: 1.4 GB 
[11/06 17:59:41][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.2807,	0.2688 s / batch. (data: 1.43e-01). ETA=16:08:06, max mem: 1.4 GB 
[11/06 18:00:01][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 1.7275,	0.1687 s / batch. (data: 1.07e-02). ETA=10:07:16, max mem: 1.4 GB 
[11/06 18:00:21][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 1.1637,	0.2015 s / batch. (data: 2.05e-02). ETA=12:04:52, max mem: 1.4 GB 
[11/06 18:00:40][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.1545,	0.2080 s / batch. (data: 3.95e-02). ETA=12:28:09, max mem: 1.4 GB 
[11/06 18:01:00][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.3338,	0.1128 s / batch. (data: 1.66e-04). ETA=6:45:19, max mem: 1.4 GB 
[11/06 18:01:18][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 1.1778,	0.1212 s / batch. (data: 2.69e-04). ETA=7:15:27, max mem: 1.4 GB 
[11/06 18:01:39][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 1.6652,	0.0875 s / batch. (data: 1.56e-04). ETA=5:14:20, max mem: 1.4 GB 
[11/06 18:01:59][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.5532,	0.1238 s / batch. (data: 1.03e-02). ETA=7:24:19, max mem: 1.4 GB 
[11/06 18:02:18][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.0957,	0.1718 s / batch. (data: 1.04e-02). ETA=10:16:34, max mem: 1.4 GB 
[11/06 18:02:37][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.1149,	0.1804 s / batch. (data: 7.82e-03). ETA=10:47:07, max mem: 1.4 GB 
[11/06 18:02:57][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.9551,	0.1505 s / batch. (data: 2.11e-04). ETA=8:59:37, max mem: 1.4 GB 
[11/06 18:03:17][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.3133,	0.1607 s / batch. (data: 5.28e-03). ETA=9:35:44, max mem: 1.4 GB 
[11/06 18:03:36][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.2022,	0.1656 s / batch. (data: 6.64e-03). ETA=9:52:59, max mem: 1.4 GB 
[11/06 18:03:55][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 1.7955,	0.1804 s / batch. (data: 5.28e-03). ETA=10:45:40, max mem: 1.4 GB 
[11/06 18:04:17][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 3.6632,	0.1840 s / batch. (data: 1.07e-02). ETA=10:58:16, max mem: 1.4 GB 
[11/06 18:04:36][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5762,	0.6233 s / batch. (data: 5.41e-01). ETA=1 day, 13:08:57, max mem: 1.4 GB 
[11/06 18:04:37][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 4.89e-02, avg batch time: 0.1981, average train loss: 1.0003
[11/06 18:04:57][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.710, 0.0556 s / batch. (data: 1.93e-05)max mem: 1.44029 GB 
[11/06 18:05:15][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.706, 0.0595 s / batch. (data: 2.43e-05)max mem: 1.44029 GB 
[11/06 18:05:23][INFO] visual_prompt:  316: Inference (val):avg data time: 5.73e-04, avg batch time: 0.0408, average loss: 0.6914
[11/06 18:05:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 53.00	
[11/06 18:05:23][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.003
[11/06 18:05:46][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 1.9716,	0.1493 s / batch. (data: 1.07e-02). ETA=8:53:42, max mem: 1.4 GB 
[11/06 18:06:04][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.6584,	0.1828 s / batch. (data: 1.54e-02). ETA=10:53:10, max mem: 1.4 GB 
[11/06 18:06:24][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.3780,	0.1783 s / batch. (data: 1.55e-02). ETA=10:36:38, max mem: 1.4 GB 
[11/06 18:06:44][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 1.4136,	0.2033 s / batch. (data: 6.99e-03). ETA=12:05:35, max mem: 1.4 GB 
[11/06 18:07:03][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.4189,	0.1439 s / batch. (data: 6.16e-04). ETA=8:33:25, max mem: 1.4 GB 
[11/06 18:07:22][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.3889,	0.1579 s / batch. (data: 6.16e-03). ETA=9:23:04, max mem: 1.4 GB 
[11/06 18:07:42][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.8303,	0.1929 s / batch. (data: 1.55e-02). ETA=11:27:33, max mem: 1.4 GB 
[11/06 18:08:03][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 1.9113,	0.1919 s / batch. (data: 1.45e-02). ETA=11:23:43, max mem: 1.4 GB 
[11/06 18:08:22][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.4549,	0.1949 s / batch. (data: 1.07e-03). ETA=11:34:02, max mem: 1.4 GB 
[11/06 18:08:41][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.8969,	0.1391 s / batch. (data: 1.54e-02). ETA=8:15:10, max mem: 1.4 GB 
[11/06 18:09:01][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 2.6368,	0.1997 s / batch. (data: 1.04e-02). ETA=11:50:33, max mem: 1.4 GB 
[11/06 18:09:21][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.4055,	0.1291 s / batch. (data: 7.44e-03). ETA=7:38:54, max mem: 1.4 GB 
[11/06 18:09:41][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.8095,	0.1625 s / batch. (data: 1.04e-02). ETA=9:37:30, max mem: 1.4 GB 
[11/06 18:10:01][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.6338,	0.2033 s / batch. (data: 5.74e-03). ETA=12:02:12, max mem: 1.4 GB 
[11/06 18:10:21][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.5614,	0.1683 s / batch. (data: 1.95e-04). ETA=9:57:49, max mem: 1.4 GB 
[11/06 18:10:41][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.2994,	0.1328 s / batch. (data: 1.03e-02). ETA=7:51:31, max mem: 1.4 GB 
[11/06 18:11:01][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.0828,	0.1482 s / batch. (data: 1.03e-02). ETA=8:45:46, max mem: 1.4 GB 
[11/06 18:11:19][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.9597,	0.1337 s / batch. (data: 1.54e-02). ETA=7:53:58, max mem: 1.4 GB 
[11/06 18:11:40][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6607,	0.1610 s / batch. (data: 5.40e-03). ETA=9:30:41, max mem: 1.4 GB 
[11/06 18:12:00][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 1.0044,	0.1931 s / batch. (data: 1.58e-02). ETA=11:24:05, max mem: 1.4 GB 
[11/06 18:12:20][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.9435,	0.1556 s / batch. (data: 5.26e-03). ETA=9:10:52, max mem: 1.4 GB 
[11/06 18:12:40][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.3127,	0.1280 s / batch. (data: 9.68e-05). ETA=7:33:01, max mem: 1.4 GB 
[11/06 18:12:41][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.81e-02, avg batch time: 0.1982, average train loss: 0.8940
[11/06 18:13:00][INFO] visual_prompt:  303: 	Test 100/246. loss: 1.190, 0.0617 s / batch. (data: 2.12e-05)max mem: 1.44029 GB 
[11/06 18:13:19][INFO] visual_prompt:  303: 	Test 200/246. loss: 1.188, 0.0631 s / batch. (data: 1.98e-05)max mem: 1.44029 GB 
[11/06 18:13:26][INFO] visual_prompt:  316: Inference (val):avg data time: 9.23e-04, avg batch time: 0.0409, average loss: 0.7343
[11/06 18:13:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.18	
[11/06 18:13:26][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.004
[11/06 18:13:48][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 2.0024,	0.1536 s / batch. (data: 2.24e-02). ETA=9:03:24, max mem: 1.4 GB 
[11/06 18:14:08][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 1.0589,	0.1428 s / batch. (data: 6.14e-04). ETA=8:24:50, max mem: 1.4 GB 
[11/06 18:14:28][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 1.5058,	0.1896 s / batch. (data: 2.10e-02). ETA=11:10:12, max mem: 1.4 GB 
[11/06 18:14:48][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 2.6446,	0.1342 s / batch. (data: 2.10e-04). ETA=7:54:12, max mem: 1.4 GB 
[11/06 18:15:08][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6108,	0.1639 s / batch. (data: 2.04e-04). ETA=9:38:33, max mem: 1.4 GB 
[11/06 18:15:28][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.6044,	0.1743 s / batch. (data: 1.05e-02). ETA=10:15:15, max mem: 1.4 GB 
[11/06 18:15:46][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 1.1370,	0.1918 s / batch. (data: 1.04e-02). ETA=11:16:44, max mem: 1.4 GB 
[11/06 18:16:07][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.5491,	0.1804 s / batch. (data: 5.69e-03). ETA=10:36:11, max mem: 1.4 GB 
[11/06 18:16:27][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.4044,	0.1775 s / batch. (data: 5.27e-03). ETA=10:25:23, max mem: 1.4 GB 
[11/06 18:16:47][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.8233,	0.8368 s / batch. (data: 7.09e-01). ETA=2 days, 1:07:33, max mem: 1.4 GB 
[11/06 18:17:06][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.5330,	0.1697 s / batch. (data: 2.00e-02). ETA=9:57:35, max mem: 1.4 GB 
[11/06 18:17:25][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.9785,	0.1514 s / batch. (data: 5.28e-03). ETA=8:52:46, max mem: 1.4 GB 
[11/06 18:17:45][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.3873,	0.1259 s / batch. (data: 1.54e-02). ETA=7:22:49, max mem: 1.4 GB 
[11/06 18:18:05][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.6895,	0.1292 s / batch. (data: 5.29e-03). ETA=7:34:09, max mem: 1.4 GB 
[11/06 18:18:25][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 1.2190,	1.1382 s / batch. (data: 1.03e+00). ETA=2 days, 18:39:53, max mem: 1.4 GB 
[11/06 18:18:45][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.7691,	0.1830 s / batch. (data: 5.87e-04). ETA=10:42:40, max mem: 1.4 GB 
[11/06 18:19:05][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.6337,	0.1794 s / batch. (data: 1.49e-04). ETA=10:29:54, max mem: 1.4 GB 
[11/06 18:19:26][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.7414,	0.1886 s / batch. (data: 5.48e-04). ETA=11:01:41, max mem: 1.4 GB 
[11/06 18:19:46][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.7196,	0.1596 s / batch. (data: 5.60e-03). ETA=9:19:54, max mem: 1.4 GB 
[11/06 18:20:05][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.6091,	0.1734 s / batch. (data: 2.05e-02). ETA=10:07:46, max mem: 1.4 GB 
[11/06 18:20:24][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.6745,	0.1639 s / batch. (data: 1.54e-02). ETA=9:34:26, max mem: 1.4 GB 
[11/06 18:20:44][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.7071,	0.0971 s / batch. (data: 7.77e-05). ETA=5:40:03, max mem: 1.4 GB 
[11/06 18:20:45][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.83e-02, avg batch time: 0.1981, average train loss: 0.7450
[11/06 18:21:04][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.748, 0.0454 s / batch. (data: 2.05e-05)max mem: 1.44029 GB 
[11/06 18:21:23][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.748, 0.0369 s / batch. (data: 2.43e-05)max mem: 1.44029 GB 
[11/06 18:21:30][INFO] visual_prompt:  316: Inference (val):avg data time: 5.20e-04, avg batch time: 0.0399, average loss: 0.6893
[11/06 18:21:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.04	
[11/06 18:21:30][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.005
[11/06 18:21:52][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 2.2765,	0.1563 s / batch. (data: 1.87e-04). ETA=9:07:02, max mem: 1.4 GB 
[11/06 18:22:12][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.6401,	0.1669 s / batch. (data: 1.03e-02). ETA=9:44:03, max mem: 1.4 GB 
[11/06 18:22:32][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.4012,	0.1749 s / batch. (data: 1.04e-02). ETA=10:11:44, max mem: 1.4 GB 
[11/06 18:22:51][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.6135,	0.1267 s / batch. (data: 1.83e-04). ETA=7:22:57, max mem: 1.4 GB 
[11/06 18:23:11][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.5928,	0.1613 s / batch. (data: 1.59e-02). ETA=9:23:26, max mem: 1.4 GB 
[11/06 18:23:31][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.6834,	0.1848 s / batch. (data: 1.69e-02). ETA=10:45:29, max mem: 1.4 GB 
[11/06 18:23:52][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.5909,	0.1835 s / batch. (data: 2.31e-02). ETA=10:40:25, max mem: 1.4 GB 
[11/06 18:24:12][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7881,	0.1641 s / batch. (data: 1.04e-02). ETA=9:32:33, max mem: 1.4 GB 
[11/06 18:24:31][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7856,	0.1719 s / batch. (data: 1.04e-02). ETA=9:59:20, max mem: 1.4 GB 
[11/06 18:24:52][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.7910,	0.1519 s / batch. (data: 1.04e-02). ETA=8:49:31, max mem: 1.4 GB 
[11/06 18:25:11][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.5982,	0.1200 s / batch. (data: 1.82e-04). ETA=6:58:12, max mem: 1.4 GB 
[11/06 18:25:29][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.6075,	0.1651 s / batch. (data: 1.04e-02). ETA=9:34:59, max mem: 1.4 GB 
[11/06 18:25:49][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.5702,	0.1903 s / batch. (data: 1.55e-02). ETA=11:02:23, max mem: 1.4 GB 
[11/06 18:26:10][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.4948,	0.1928 s / batch. (data: 2.27e-02). ETA=11:10:51, max mem: 1.4 GB 
[11/06 18:26:30][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.6284,	0.1439 s / batch. (data: 6.21e-04). ETA=8:20:27, max mem: 1.4 GB 
[11/06 18:26:50][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.7654,	0.1765 s / batch. (data: 1.58e-02). ETA=10:13:37, max mem: 1.4 GB 
[11/06 18:27:10][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.9046,	0.1670 s / batch. (data: 1.03e-02). ETA=9:40:14, max mem: 1.4 GB 
[11/06 18:27:31][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.6844,	0.1727 s / batch. (data: 5.72e-03). ETA=9:59:34, max mem: 1.4 GB 
[11/06 18:27:50][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.5398,	0.1690 s / batch. (data: 1.04e-02). ETA=9:46:34, max mem: 1.4 GB 
[11/06 18:28:09][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.9050,	0.1344 s / batch. (data: 2.15e-04). ETA=7:46:11, max mem: 1.4 GB 
[11/06 18:28:28][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.8501,	0.4406 s / batch. (data: 3.07e-01). ETA=1 day, 1:27:46, max mem: 1.4 GB 
[11/06 18:28:48][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.6358,	0.0957 s / batch. (data: 8.68e-05). ETA=5:31:44, max mem: 1.4 GB 
[11/06 18:28:49][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.80e-02, avg batch time: 0.1982, average train loss: 0.7096
[11/06 18:29:08][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.761, 0.0608 s / batch. (data: 2.03e-05)max mem: 1.44029 GB 
[11/06 18:29:26][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.761, 0.0387 s / batch. (data: 2.03e-05)max mem: 1.44029 GB 
[11/06 18:29:34][INFO] visual_prompt:  316: Inference (val):avg data time: 5.06e-04, avg batch time: 0.0408, average loss: 0.6889
[11/06 18:29:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.95	
[11/06 18:29:34][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.004998633143352315
[11/06 18:29:55][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.4900,	0.1691 s / batch. (data: 5.67e-03). ETA=9:45:45, max mem: 1.4 GB 
[11/06 18:30:17][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.3997,	0.1650 s / batch. (data: 2.05e-02). ETA=9:31:12, max mem: 1.4 GB 
[11/06 18:30:39][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.8664,	0.1529 s / batch. (data: 1.58e-02). ETA=8:49:02, max mem: 1.4 GB 
[11/06 18:30:59][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.8413,	0.1081 s / batch. (data: 8.59e-03). ETA=6:13:45, max mem: 1.4 GB 
[11/06 18:31:19][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.7022,	0.1734 s / batch. (data: 1.72e-02). ETA=9:59:27, max mem: 1.4 GB 
[11/06 18:31:38][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.6897,	0.1544 s / batch. (data: 1.65e-02). ETA=8:53:27, max mem: 1.4 GB 
[11/06 18:31:58][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.6029,	0.1715 s / batch. (data: 1.54e-02). ETA=9:52:11, max mem: 1.4 GB 
[11/06 18:32:17][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.6255,	0.1678 s / batch. (data: 1.54e-02). ETA=9:39:20, max mem: 1.4 GB 
[11/06 18:32:37][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7247,	0.1709 s / batch. (data: 1.45e-02). ETA=9:49:31, max mem: 1.4 GB 
[11/06 18:32:57][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.6855,	0.1735 s / batch. (data: 8.40e-03). ETA=9:58:13, max mem: 1.4 GB 
[11/06 18:33:16][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.7812,	0.1760 s / batch. (data: 5.34e-03). ETA=10:06:36, max mem: 1.4 GB 
[11/06 18:33:34][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.5800,	0.1294 s / batch. (data: 2.05e-02). ETA=7:25:47, max mem: 1.4 GB 
[11/06 18:33:55][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.6494,	0.1163 s / batch. (data: 5.65e-03). ETA=6:40:23, max mem: 1.4 GB 
[11/06 18:34:14][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.6007,	0.1662 s / batch. (data: 5.27e-03). ETA=9:32:12, max mem: 1.4 GB 
[11/06 18:34:33][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.9692,	0.2148 s / batch. (data: 2.60e-02). ETA=12:18:56, max mem: 1.4 GB 
[11/06 18:34:53][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.5862,	0.3438 s / batch. (data: 2.15e-01). ETA=19:42:12, max mem: 1.4 GB 
[11/06 18:35:13][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.9012,	0.1602 s / batch. (data: 1.03e-02). ETA=9:10:28, max mem: 1.4 GB 
[11/06 18:35:32][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.5723,	0.1907 s / batch. (data: 1.08e-02). ETA=10:55:01, max mem: 1.4 GB 
[11/06 18:35:52][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.8254,	0.1845 s / batch. (data: 5.31e-03). ETA=10:33:41, max mem: 1.4 GB 
[11/06 18:36:12][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.7260,	0.1634 s / batch. (data: 1.04e-02). ETA=9:20:40, max mem: 1.4 GB 
[11/06 18:36:32][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.9467,	0.2043 s / batch. (data: 1.68e-04). ETA=11:40:42, max mem: 1.4 GB 
[11/06 18:36:51][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5506,	0.0908 s / batch. (data: 8.34e-05). ETA=5:11:22, max mem: 1.4 GB 
[11/06 18:36:52][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.59e-02, avg batch time: 0.1982, average train loss: 0.7028
[11/06 18:37:12][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.838, 0.0397 s / batch. (data: 1.50e-05)max mem: 1.44029 GB 
[11/06 18:37:30][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.838, 0.0471 s / batch. (data: 1.88e-05)max mem: 1.44029 GB 
[11/06 18:37:38][INFO] visual_prompt:  316: Inference (val):avg data time: 1.08e-04, avg batch time: 0.0400, average loss: 0.6891
[11/06 18:37:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[11/06 18:37:38][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.004994534068046936
[11/06 18:38:00][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.5098,	0.1303 s / batch. (data: 1.04e-02). ETA=7:26:36, max mem: 1.4 GB 
[11/06 18:38:20][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.6621,	0.1862 s / batch. (data: 1.08e-02). ETA=10:37:54, max mem: 1.4 GB 
[11/06 18:38:39][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.9167,	0.1653 s / batch. (data: 1.54e-02). ETA=9:25:47, max mem: 1.4 GB 
[11/06 18:38:59][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.5255,	0.1845 s / batch. (data: 5.31e-03). ETA=10:31:21, max mem: 1.4 GB 
[11/06 18:39:21][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.5267,	0.4257 s / batch. (data: 2.64e-01). ETA=1 day, 0:16:00, max mem: 1.4 GB 
[11/06 18:39:40][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.8026,	0.1760 s / batch. (data: 1.56e-02). ETA=10:01:38, max mem: 1.4 GB 
[11/06 18:39:59][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.9116,	0.1454 s / batch. (data: 2.00e-04). ETA=8:16:41, max mem: 1.4 GB 
[11/06 18:40:19][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.4800,	0.1571 s / batch. (data: 1.62e-02). ETA=8:56:34, max mem: 1.4 GB 
[11/06 18:40:39][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.5827,	0.1584 s / batch. (data: 1.04e-02). ETA=9:00:45, max mem: 1.4 GB 
[11/06 18:40:59][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.9213,	0.1445 s / batch. (data: 1.54e-02). ETA=8:13:05, max mem: 1.4 GB 
[11/06 18:41:18][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.5811,	0.1286 s / batch. (data: 1.54e-02). ETA=7:18:42, max mem: 1.4 GB 
[11/06 18:41:39][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.6265,	0.1767 s / batch. (data: 1.54e-02). ETA=10:02:26, max mem: 1.4 GB 
[11/06 18:41:59][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.7631,	0.2252 s / batch. (data: 2.15e-02). ETA=12:47:10, max mem: 1.4 GB 
[11/06 18:42:18][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.7888,	0.2036 s / batch. (data: 1.54e-02). ETA=11:33:18, max mem: 1.4 GB 
[11/06 18:42:39][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.5911,	0.3685 s / batch. (data: 2.72e-01). ETA=20:54:22, max mem: 1.4 GB 
[11/06 18:42:59][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.8908,	0.1648 s / batch. (data: 2.61e-02). ETA=9:20:35, max mem: 1.4 GB 
[11/06 18:43:19][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.7768,	0.1649 s / batch. (data: 5.31e-03). ETA=9:20:49, max mem: 1.4 GB 
[11/06 18:43:38][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.5397,	0.0816 s / batch. (data: 1.77e-04). ETA=4:37:16, max mem: 1.4 GB 
[11/06 18:43:57][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6120,	0.1785 s / batch. (data: 5.98e-04). ETA=10:06:19, max mem: 1.4 GB 
[11/06 18:44:18][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 1.7032,	0.1637 s / batch. (data: 2.01e-04). ETA=9:15:54, max mem: 1.4 GB 
[11/06 18:44:38][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.5217,	0.1641 s / batch. (data: 6.57e-03). ETA=9:16:44, max mem: 1.4 GB 
[11/06 18:44:56][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.7590,	0.1300 s / batch. (data: 7.77e-05). ETA=7:20:54, max mem: 1.4 GB 
[11/06 18:44:57][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.63e-02, avg batch time: 0.1983, average train loss: 0.7053
[11/06 18:45:16][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.766, 0.0372 s / batch. (data: 2.24e-05)max mem: 1.44029 GB 
[11/06 18:45:35][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.766, 0.0617 s / batch. (data: 2.07e-05)max mem: 1.44029 GB 
[11/06 18:45:42][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-04, avg batch time: 0.0402, average loss: 0.6888
[11/06 18:45:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.01	
[11/06 18:45:42][INFO] visual_prompt:   36: Best epoch 8: best metric: -0.689
[11/06 18:45:42][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.0049877072563625285
[11/06 18:46:05][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.6648,	0.0960 s / batch. (data: 9.49e-03). ETA=5:25:21, max mem: 1.4 GB 
[11/06 18:46:26][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.6465,	0.2025 s / batch. (data: 2.05e-02). ETA=11:26:07, max mem: 1.4 GB 
[11/06 18:46:47][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.8666,	0.1440 s / batch. (data: 1.54e-02). ETA=8:07:43, max mem: 1.4 GB 
[11/06 18:47:07][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.7803,	0.2299 s / batch. (data: 3.73e-02). ETA=12:58:18, max mem: 1.4 GB 
[11/06 18:47:28][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.7996,	0.1258 s / batch. (data: 5.27e-03). ETA=7:05:40, max mem: 1.4 GB 
[11/06 18:47:47][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.5202,	0.1538 s / batch. (data: 2.08e-02). ETA=8:40:04, max mem: 1.4 GB 
[11/06 18:48:07][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.3972,	0.1566 s / batch. (data: 1.04e-02). ETA=8:49:28, max mem: 1.4 GB 
[11/06 18:48:26][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7254,	0.2024 s / batch. (data: 1.03e-02). ETA=11:23:45, max mem: 1.4 GB 
[11/06 18:48:45][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.6554,	0.1742 s / batch. (data: 1.54e-02). ETA=9:48:05, max mem: 1.4 GB 
[11/06 18:49:05][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.8025,	0.1618 s / batch. (data: 6.89e-03). ETA=9:05:59, max mem: 1.4 GB 
[11/06 18:49:25][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.5062,	0.8903 s / batch. (data: 7.49e-01). ETA=2 days, 2:03:16, max mem: 1.4 GB 
[11/06 18:49:45][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 1.0264,	0.1249 s / batch. (data: 1.95e-04). ETA=7:01:16, max mem: 1.4 GB 
[11/06 18:50:03][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.7627,	0.1637 s / batch. (data: 1.03e-02). ETA=9:11:36, max mem: 1.4 GB 
[11/06 18:50:22][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.7527,	0.1919 s / batch. (data: 3.11e-02). ETA=10:46:28, max mem: 1.4 GB 
[11/06 18:50:42][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.9318,	0.1818 s / batch. (data: 2.82e-02). ETA=10:12:04, max mem: 1.4 GB 
[11/06 18:51:01][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.6495,	0.1291 s / batch. (data: 5.33e-03). ETA=7:14:22, max mem: 1.4 GB 
[11/06 18:51:21][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 1.4395,	0.1817 s / batch. (data: 6.05e-04). ETA=10:11:02, max mem: 1.4 GB 
[11/06 18:51:40][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.7318,	0.9247 s / batch. (data: 8.41e-01). ETA=2 days, 3:48:35, max mem: 1.4 GB 
[11/06 18:51:58][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.7979,	0.1450 s / batch. (data: 3.82e-03). ETA=8:07:21, max mem: 1.4 GB 
[11/06 18:52:18][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.8055,	0.1831 s / batch. (data: 1.51e-02). ETA=10:14:49, max mem: 1.4 GB 
[11/06 18:52:38][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.8031,	0.2045 s / batch. (data: 2.56e-02). ETA=11:26:32, max mem: 1.4 GB 
[11/06 18:53:00][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5406,	0.1612 s / batch. (data: 1.24e-04). ETA=9:00:45, max mem: 1.4 GB 
[11/06 18:53:01][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.89e-02, avg batch time: 0.1984, average train loss: 0.7082
[11/06 18:53:20][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.927, 0.0717 s / batch. (data: 2.05e-05)max mem: 1.44029 GB 
[11/06 18:53:39][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.927, 0.0825 s / batch. (data: 2.19e-05)max mem: 1.44029 GB 
[11/06 18:53:46][INFO] visual_prompt:  316: Inference (val):avg data time: 4.13e-04, avg batch time: 0.0407, average loss: 0.6947
[11/06 18:53:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.05	
[11/06 18:53:46][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.004978160173317438
[11/06 18:54:09][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.5736,	0.1855 s / batch. (data: 2.05e-02). ETA=10:22:05, max mem: 1.4 GB 
[11/06 18:54:29][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.8301,	0.5223 s / batch. (data: 4.23e-01). ETA=1 day, 5:10:24, max mem: 1.4 GB 
[11/06 18:54:49][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.9691,	0.1868 s / batch. (data: 6.42e-04). ETA=10:25:39, max mem: 1.4 GB 
[11/06 18:55:08][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.7929,	0.1558 s / batch. (data: 1.58e-02). ETA=8:41:45, max mem: 1.4 GB 
[11/06 18:55:27][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.4732,	0.1797 s / batch. (data: 1.55e-02). ETA=10:01:18, max mem: 1.4 GB 
[11/06 18:55:47][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.9828,	0.1298 s / batch. (data: 5.19e-04). ETA=7:14:12, max mem: 1.4 GB 
[11/06 18:56:08][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.5239,	0.2090 s / batch. (data: 5.31e-03). ETA=11:38:49, max mem: 1.4 GB 
[11/06 18:56:28][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7443,	0.1959 s / batch. (data: 1.08e-02). ETA=10:54:39, max mem: 1.4 GB 
[11/06 18:56:48][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.2362,	1.0981 s / batch. (data: 1.02e+00). ETA=2 days, 13:07:24, max mem: 1.4 GB 
[11/06 18:57:07][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.6700,	0.1531 s / batch. (data: 5.32e-03). ETA=8:30:57, max mem: 1.4 GB 
[11/06 18:57:28][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.7570,	0.1776 s / batch. (data: 5.80e-04). ETA=9:52:32, max mem: 1.4 GB 
[11/06 18:57:47][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.7626,	0.1767 s / batch. (data: 1.54e-02). ETA=9:49:08, max mem: 1.4 GB 
[11/06 18:58:07][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.7817,	0.1550 s / batch. (data: 1.54e-02). ETA=8:36:39, max mem: 1.4 GB 
[11/06 18:58:26][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 1.9742,	0.0887 s / batch. (data: 1.77e-04). ETA=4:55:33, max mem: 1.4 GB 
[11/06 18:58:46][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.6086,	0.1280 s / batch. (data: 1.04e-02). ETA=7:06:18, max mem: 1.4 GB 
[11/06 18:59:05][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.6166,	0.1800 s / batch. (data: 1.54e-02). ETA=9:59:12, max mem: 1.4 GB 
[11/06 18:59:25][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.5784,	0.1315 s / batch. (data: 1.97e-04). ETA=7:17:22, max mem: 1.4 GB 
[11/06 18:59:45][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.9025,	0.1296 s / batch. (data: 7.29e-03). ETA=7:10:53, max mem: 1.4 GB 
[11/06 19:00:04][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6273,	0.1623 s / batch. (data: 1.04e-02). ETA=8:59:31, max mem: 1.4 GB 
[11/06 19:00:24][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.6165,	0.1723 s / batch. (data: 2.25e-04). ETA=9:32:15, max mem: 1.4 GB 
[11/06 19:00:45][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.7117,	0.1702 s / batch. (data: 2.00e-04). ETA=9:24:52, max mem: 1.4 GB 
[11/06 19:01:04][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.6600,	0.1200 s / batch. (data: 1.03e-04). ETA=6:38:16, max mem: 1.4 GB 
[11/06 19:01:05][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.78e-02, avg batch time: 0.1983, average train loss: 0.7021
[11/06 19:01:25][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.641, 0.0463 s / batch. (data: 2.31e-05)max mem: 1.44029 GB 
[11/06 19:01:43][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.641, 0.0387 s / batch. (data: 2.34e-05)max mem: 1.44029 GB 
[11/06 19:01:51][INFO] visual_prompt:  316: Inference (val):avg data time: 5.86e-04, avg batch time: 0.0399, average loss: 0.6998
[11/06 19:01:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.95	
[11/06 19:01:51][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.004965903258506806
[11/06 19:02:12][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.5598,	0.1598 s / batch. (data: 1.03e-02). ETA=8:50:03, max mem: 1.4 GB 
[11/06 19:02:33][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.6380,	0.2048 s / batch. (data: 1.58e-02). ETA=11:18:56, max mem: 1.4 GB 
[11/06 19:02:54][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.8742,	0.1554 s / batch. (data: 5.29e-03). ETA=8:34:47, max mem: 1.4 GB 
[11/06 19:03:14][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.8680,	0.1814 s / batch. (data: 1.03e-02). ETA=10:00:46, max mem: 1.4 GB 
[11/06 19:03:34][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6961,	0.1117 s / batch. (data: 6.25e-04). ETA=6:09:37, max mem: 1.4 GB 
[11/06 19:03:53][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.7149,	0.0941 s / batch. (data: 1.35e-02). ETA=5:11:08, max mem: 1.4 GB 
[11/06 19:04:14][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 1.0688,	0.7666 s / batch. (data: 6.83e-01). ETA=1 day, 18:14:34, max mem: 1.4 GB 
[11/06 19:04:32][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.6716,	0.1578 s / batch. (data: 1.54e-02). ETA=8:41:26, max mem: 1.4 GB 
[11/06 19:04:51][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.9117,	0.1533 s / batch. (data: 5.30e-03). ETA=8:26:11, max mem: 1.4 GB 
[11/06 19:05:10][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.6506,	0.1866 s / batch. (data: 2.52e-02). ETA=10:15:57, max mem: 1.4 GB 
[11/06 19:05:31][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.5555,	0.1487 s / batch. (data: 2.06e-04). ETA=8:10:39, max mem: 1.4 GB 
[11/06 19:05:50][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.7581,	0.1415 s / batch. (data: 1.03e-02). ETA=7:46:36, max mem: 1.4 GB 
[11/06 19:06:10][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.6278,	0.1787 s / batch. (data: 5.63e-04). ETA=9:49:07, max mem: 1.4 GB 
[11/06 19:06:30][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 2.1061,	0.1085 s / batch. (data: 2.29e-04). ETA=5:57:32, max mem: 1.4 GB 
[11/06 19:06:50][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.3091,	0.1848 s / batch. (data: 1.07e-02). ETA=10:08:26, max mem: 1.4 GB 
[11/06 19:07:10][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 1.0879,	0.1885 s / batch. (data: 2.92e-02). ETA=10:20:16, max mem: 1.4 GB 
[11/06 19:07:29][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.4020,	0.1633 s / batch. (data: 1.54e-02). ETA=8:57:05, max mem: 1.4 GB 
[11/06 19:07:49][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.4553,	0.1735 s / batch. (data: 1.95e-02). ETA=9:30:36, max mem: 1.4 GB 
[11/06 19:08:09][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.5299,	0.1642 s / batch. (data: 1.04e-02). ETA=8:59:42, max mem: 1.4 GB 
[11/06 19:08:29][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.7184,	0.1955 s / batch. (data: 1.04e-02). ETA=10:42:05, max mem: 1.4 GB 
[11/06 19:08:48][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.4503,	0.1960 s / batch. (data: 1.04e-02). ETA=10:43:29, max mem: 1.4 GB 
[11/06 19:09:08][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.8330,	0.0898 s / batch. (data: 7.15e-05). ETA=4:54:36, max mem: 1.4 GB 
[11/06 19:09:09][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.78e-02, avg batch time: 0.1982, average train loss: 0.7126
[11/06 19:09:29][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.767, 0.0687 s / batch. (data: 2.41e-02)max mem: 1.44029 GB 
[11/06 19:09:47][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.767, 0.0635 s / batch. (data: 1.98e-05)max mem: 1.44029 GB 
[11/06 19:09:54][INFO] visual_prompt:  316: Inference (val):avg data time: 8.57e-04, avg batch time: 0.0410, average loss: 0.6887
[11/06 19:09:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.33	
[11/06 19:09:54][INFO] visual_prompt:   36: Best epoch 11: best metric: -0.689
[11/06 19:09:54][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.004950949914687024
[11/06 19:10:15][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.5227,	0.1699 s / batch. (data: 1.11e-02). ETA=9:17:01, max mem: 1.4 GB 
[11/06 19:10:34][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.2015,	0.1348 s / batch. (data: 5.65e-03). ETA=7:21:54, max mem: 1.4 GB 
[11/06 19:10:54][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.7183,	0.1885 s / batch. (data: 2.60e-02). ETA=10:17:33, max mem: 1.4 GB 
[11/06 19:11:14][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.3812,	0.1434 s / batch. (data: 3.01e-02). ETA=7:49:36, max mem: 1.4 GB 
[11/06 19:11:35][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6161,	0.1915 s / batch. (data: 6.17e-04). ETA=10:26:39, max mem: 1.4 GB 
[11/06 19:11:55][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.8490,	0.1654 s / batch. (data: 5.51e-03). ETA=9:01:03, max mem: 1.4 GB 
[11/06 19:12:16][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.7026,	0.1623 s / batch. (data: 5.69e-03). ETA=8:50:44, max mem: 1.4 GB 
[11/06 19:12:36][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 1.1023,	0.1538 s / batch. (data: 1.54e-02). ETA=8:22:35, max mem: 1.4 GB 
[11/06 19:12:56][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7598,	1.0625 s / batch. (data: 9.40e-01). ETA=2 days, 9:50:22, max mem: 1.4 GB 
[11/06 19:13:16][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.5182,	0.1016 s / batch. (data: 1.71e-04). ETA=5:31:46, max mem: 1.4 GB 
[11/06 19:13:35][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.7913,	0.4085 s / batch. (data: 2.81e-01). ETA=22:12:58, max mem: 1.4 GB 
[11/06 19:13:54][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 1.1663,	0.1892 s / batch. (data: 1.08e-02). ETA=10:17:02, max mem: 1.4 GB 
[11/06 19:14:13][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.4215,	0.1747 s / batch. (data: 2.05e-02). ETA=9:29:25, max mem: 1.4 GB 
[11/06 19:14:33][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.5854,	0.1593 s / batch. (data: 1.04e-02). ETA=8:38:50, max mem: 1.4 GB 
[11/06 19:14:54][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.4297,	0.4275 s / batch. (data: 2.98e-01). ETA=23:12:01, max mem: 1.4 GB 
[11/06 19:15:13][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.5904,	0.1687 s / batch. (data: 1.62e-02). ETA=9:09:10, max mem: 1.4 GB 
[11/06 19:15:34][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.8420,	0.1921 s / batch. (data: 2.31e-02). ETA=10:24:48, max mem: 1.4 GB 
[11/06 19:15:54][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.8315,	0.1404 s / batch. (data: 1.03e-02). ETA=7:36:19, max mem: 1.4 GB 
[11/06 19:16:13][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6329,	0.2013 s / batch. (data: 2.22e-02). ETA=10:54:01, max mem: 1.4 GB 
[11/06 19:16:32][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.9280,	0.1490 s / batch. (data: 1.10e-02). ETA=8:03:52, max mem: 1.4 GB 
[11/06 19:16:53][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.7737,	0.6810 s / batch. (data: 5.89e-01). ETA=1 day, 12:50:30, max mem: 1.4 GB 
[11/06 19:17:12][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.2947,	0.0915 s / batch. (data: 7.77e-05). ETA=4:56:47, max mem: 1.4 GB 
[11/06 19:17:13][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 4.70e-02, avg batch time: 0.1983, average train loss: 0.7091
[11/06 19:17:33][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.608, 0.0721 s / batch. (data: 2.88e-05)max mem: 1.44029 GB 
[11/06 19:17:51][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.608, 0.0675 s / batch. (data: 2.24e-05)max mem: 1.44029 GB 
[11/06 19:17:59][INFO] visual_prompt:  316: Inference (val):avg data time: 2.68e-04, avg batch time: 0.0407, average loss: 0.7057
[11/06 19:17:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.49	
[11/06 19:17:59][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.0049333164931200145
[11/06 19:18:21][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.6781,	0.1592 s / batch. (data: 1.58e-02). ETA=8:36:10, max mem: 1.4 GB 
[11/06 19:18:41][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.5952,	0.1999 s / batch. (data: 1.58e-02). ETA=10:48:01, max mem: 1.4 GB 
[11/06 19:19:01][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.6473,	0.0520 s / batch. (data: 1.70e-04). ETA=2:48:17, max mem: 1.4 GB 
[11/06 19:19:19][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 1.0364,	0.1123 s / batch. (data: 1.67e-04). ETA=6:03:29, max mem: 1.4 GB 
[11/06 19:19:38][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6946,	0.1859 s / batch. (data: 1.63e-02). ETA=10:01:28, max mem: 1.4 GB 
[11/06 19:19:59][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.5273,	0.1806 s / batch. (data: 6.78e-03). ETA=9:44:01, max mem: 1.4 GB 
[11/06 19:20:20][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.8498,	0.1329 s / batch. (data: 7.29e-03). ETA=7:09:34, max mem: 1.4 GB 
[11/06 19:20:41][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7060,	0.1227 s / batch. (data: 1.91e-04). ETA=6:36:29, max mem: 1.4 GB 
[11/06 19:21:00][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.5326,	0.1370 s / batch. (data: 1.54e-02). ETA=7:22:24, max mem: 1.4 GB 
[11/06 19:21:19][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.5190,	0.1496 s / batch. (data: 6.47e-03). ETA=8:02:45, max mem: 1.4 GB 
[11/06 19:21:39][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.7932,	0.1998 s / batch. (data: 1.07e-02). ETA=10:44:33, max mem: 1.4 GB 
[11/06 19:22:00][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.6742,	0.1970 s / batch. (data: 1.59e-02). ETA=10:35:14, max mem: 1.4 GB 
[11/06 19:22:20][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.9948,	0.1612 s / batch. (data: 4.35e-03). ETA=8:39:33, max mem: 1.4 GB 
[11/06 19:22:39][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.4940,	0.1108 s / batch. (data: 1.83e-04). ETA=5:56:52, max mem: 1.4 GB 
[11/06 19:23:00][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.4261,	0.2003 s / batch. (data: 4.67e-02). ETA=10:44:54, max mem: 1.4 GB 
[11/06 19:23:19][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.6757,	0.1695 s / batch. (data: 1.54e-02). ETA=9:05:28, max mem: 1.4 GB 
[11/06 19:23:39][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.6922,	0.1943 s / batch. (data: 3.02e-02). ETA=10:24:49, max mem: 1.4 GB 
[11/06 19:23:57][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 1.0629,	0.1621 s / batch. (data: 6.49e-03). ETA=8:41:01, max mem: 1.4 GB 
[11/06 19:24:19][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6008,	0.1607 s / batch. (data: 5.38e-03). ETA=8:36:07, max mem: 1.4 GB 
[11/06 19:24:38][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.5681,	0.1914 s / batch. (data: 4.01e-02). ETA=10:14:31, max mem: 1.4 GB 
[11/06 19:24:57][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.7812,	0.1522 s / batch. (data: 1.03e-02). ETA=8:08:31, max mem: 1.4 GB 
[11/06 19:25:16][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.6901,	0.0898 s / batch. (data: 8.39e-05). ETA=4:48:03, max mem: 1.4 GB 
[11/06 19:25:17][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.76e-02, avg batch time: 0.1982, average train loss: 0.7063
[11/06 19:25:37][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.841, 0.0624 s / batch. (data: 1.96e-05)max mem: 1.44029 GB 
[11/06 19:25:55][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.841, 0.0393 s / batch. (data: 2.03e-05)max mem: 1.44029 GB 
[11/06 19:26:03][INFO] visual_prompt:  316: Inference (val):avg data time: 5.79e-04, avg batch time: 0.0402, average loss: 0.6892
[11/06 19:26:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.50	
[11/06 19:26:03][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.004913022275693372
[11/06 19:26:24][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.9179,	0.1481 s / batch. (data: 1.03e-02). ETA=7:54:55, max mem: 1.4 GB 
[11/06 19:26:45][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.7964,	0.1399 s / batch. (data: 5.72e-03). ETA=7:28:14, max mem: 1.4 GB 
[11/06 19:27:06][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.6403,	0.1465 s / batch. (data: 2.20e-04). ETA=7:49:05, max mem: 1.4 GB 
[11/06 19:27:25][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.7959,	0.0986 s / batch. (data: 1.51e-02). ETA=5:15:39, max mem: 1.4 GB 
[11/06 19:27:45][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.8063,	0.1814 s / batch. (data: 9.00e-03). ETA=9:40:16, max mem: 1.4 GB 
[11/06 19:28:06][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.4153,	0.2080 s / batch. (data: 1.07e-02). ETA=11:05:08, max mem: 1.4 GB 
[11/06 19:28:27][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.7547,	0.1751 s / batch. (data: 1.04e-02). ETA=9:19:40, max mem: 1.4 GB 
[11/06 19:28:47][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.6737,	0.2001 s / batch. (data: 3.23e-02). ETA=10:39:00, max mem: 1.4 GB 
[11/06 19:29:06][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7794,	0.1693 s / batch. (data: 1.90e-04). ETA=9:00:20, max mem: 1.4 GB 
[11/06 19:29:25][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.5906,	0.1960 s / batch. (data: 2.47e-02). ETA=10:25:20, max mem: 1.4 GB 
[11/06 19:29:44][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 1.3446,	0.2057 s / batch. (data: 2.05e-02). ETA=10:56:07, max mem: 1.4 GB 
[11/06 19:30:04][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 1.1575,	0.1218 s / batch. (data: 9.43e-03). ETA=6:28:21, max mem: 1.4 GB 
[11/06 19:30:23][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.4896,	0.1476 s / batch. (data: 5.29e-03). ETA=7:50:04, max mem: 1.4 GB 
[11/06 19:30:43][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 1.2204,	0.3453 s / batch. (data: 2.13e-01). ETA=18:19:23, max mem: 1.4 GB 
[11/06 19:31:03][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.5909,	0.1893 s / batch. (data: 2.59e-02). ETA=10:02:27, max mem: 1.4 GB 
[11/06 19:31:23][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.3325,	0.1478 s / batch. (data: 5.30e-03). ETA=7:50:11, max mem: 1.4 GB 
[11/06 19:31:42][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.3346,	0.1932 s / batch. (data: 5.08e-03). ETA=10:14:07, max mem: 1.4 GB 
[11/06 19:32:03][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.9730,	0.1630 s / batch. (data: 1.04e-02). ETA=8:37:55, max mem: 1.4 GB 
[11/06 19:32:22][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.8770,	0.1838 s / batch. (data: 1.58e-02). ETA=9:43:38, max mem: 1.4 GB 
[11/06 19:32:41][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.6216,	0.1704 s / batch. (data: 1.07e-02). ETA=9:01:00, max mem: 1.4 GB 
[11/06 19:33:01][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.7338,	0.1537 s / batch. (data: 5.33e-03). ETA=8:07:45, max mem: 1.4 GB 
[11/06 19:33:20][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.9485,	0.1069 s / batch. (data: 9.13e-05). ETA=5:39:05, max mem: 1.4 GB 
[11/06 19:33:21][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.78e-02, avg batch time: 0.1982, average train loss: 0.7135
[11/06 19:33:41][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.796, 0.0555 s / batch. (data: 1.91e-05)max mem: 1.44029 GB 
[11/06 19:33:59][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.796, 0.0412 s / batch. (data: 2.53e-05)max mem: 1.44029 GB 
[11/06 19:34:07][INFO] visual_prompt:  316: Inference (val):avg data time: 5.47e-04, avg batch time: 0.0413, average loss: 0.6884
[11/06 19:34:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.01	
[11/06 19:34:07][INFO] visual_prompt:   36: Best epoch 14: best metric: -0.688
[11/06 19:34:07][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.0048900894538358945
[11/06 19:34:29][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.9827,	0.8566 s / batch. (data: 7.61e-01). ETA=1 day, 21:14:26, max mem: 1.4 GB 
[11/06 19:34:50][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.9674,	0.8671 s / batch. (data: 7.78e-01). ETA=1 day, 21:46:25, max mem: 1.4 GB 
[11/06 19:35:09][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.4364,	0.1813 s / batch. (data: 3.92e-02). ETA=9:33:46, max mem: 1.4 GB 
[11/06 19:35:30][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.8346,	0.1811 s / batch. (data: 2.08e-02). ETA=9:32:57, max mem: 1.4 GB 
[11/06 19:35:51][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6326,	0.1016 s / batch. (data: 5.28e-03). ETA=5:21:24, max mem: 1.4 GB 
[11/06 19:36:12][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.7905,	0.1585 s / batch. (data: 2.33e-02). ETA=8:20:51, max mem: 1.4 GB 
[11/06 19:36:32][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.8404,	0.2063 s / batch. (data: 6.55e-02). ETA=10:51:35, max mem: 1.4 GB 
[11/06 19:36:50][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7943,	0.1858 s / batch. (data: 1.59e-02). ETA=9:46:36, max mem: 1.4 GB 
[11/06 19:37:10][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7568,	0.1789 s / batch. (data: 5.28e-03). ETA=9:24:35, max mem: 1.4 GB 
[11/06 19:37:30][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.7058,	0.0990 s / batch. (data: 1.61e-02). ETA=5:12:18, max mem: 1.4 GB 
[11/06 19:37:50][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.6971,	0.1308 s / batch. (data: 5.27e-03). ETA=6:52:13, max mem: 1.4 GB 
[11/06 19:38:09][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.7374,	0.1872 s / batch. (data: 2.23e-02). ETA=9:49:42, max mem: 1.4 GB 
[11/06 19:38:30][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.5946,	0.1659 s / batch. (data: 2.03e-04). ETA=8:42:17, max mem: 1.4 GB 
[11/06 19:38:49][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.7423,	0.1737 s / batch. (data: 1.04e-02). ETA=9:06:47, max mem: 1.4 GB 
[11/06 19:39:10][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.7588,	0.4412 s / batch. (data: 3.04e-01). ETA=23:07:47, max mem: 1.4 GB 
[11/06 19:39:30][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.4084,	0.1914 s / batch. (data: 2.05e-02). ETA=10:01:50, max mem: 1.4 GB 
[11/06 19:39:49][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.9098,	0.1886 s / batch. (data: 5.70e-03). ETA=9:52:44, max mem: 1.4 GB 
[11/06 19:40:08][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.1303,	0.1733 s / batch. (data: 2.04e-02). ETA=9:04:22, max mem: 1.4 GB 
[11/06 19:40:28][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.3608,	0.1695 s / batch. (data: 1.46e-02). ETA=8:52:08, max mem: 1.4 GB 
[11/06 19:40:48][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.6531,	0.3999 s / batch. (data: 2.65e-01). ETA=20:54:42, max mem: 1.4 GB 
[11/06 19:41:06][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.4810,	0.1951 s / batch. (data: 5.75e-03). ETA=10:11:37, max mem: 1.4 GB 
[11/06 19:41:24][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5046,	0.1521 s / batch. (data: 8.11e-05). ETA=7:56:34, max mem: 1.4 GB 
[11/06 19:41:25][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.86e-02, avg batch time: 0.1984, average train loss: 0.7081
[11/06 19:41:45][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.982, 0.0636 s / batch. (data: 1.57e-05)max mem: 1.44029 GB 
[11/06 19:42:03][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.982, 0.0512 s / batch. (data: 2.00e-05)max mem: 1.44029 GB 
[11/06 19:42:11][INFO] visual_prompt:  316: Inference (val):avg data time: 8.72e-04, avg batch time: 0.0411, average loss: 0.7007
[11/06 19:42:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.52	
[11/06 19:42:11][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.004864543104251586
[11/06 19:42:33][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.4627,	0.1509 s / batch. (data: 1.80e-02). ETA=7:52:44, max mem: 1.4 GB 
[11/06 19:42:53][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.9713,	0.2456 s / batch. (data: 9.52e-02). ETA=12:48:41, max mem: 1.4 GB 
[11/06 19:43:14][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.5494,	0.1916 s / batch. (data: 2.56e-02). ETA=9:59:25, max mem: 1.4 GB 
[11/06 19:43:35][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.8426,	0.1990 s / batch. (data: 1.59e-02). ETA=10:22:15, max mem: 1.4 GB 
[11/06 19:43:55][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.7331,	0.1124 s / batch. (data: 2.52e-04). ETA=5:51:21, max mem: 1.4 GB 
[11/06 19:44:15][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.2765,	0.2078 s / batch. (data: 1.58e-02). ETA=10:49:14, max mem: 1.4 GB 
[11/06 19:44:37][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.7017,	0.1733 s / batch. (data: 7.73e-03). ETA=9:01:09, max mem: 1.4 GB 
[11/06 19:45:00][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7397,	0.1642 s / batch. (data: 5.33e-03). ETA=8:32:17, max mem: 1.4 GB 
[11/06 19:45:21][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.6238,	0.3844 s / batch. (data: 2.35e-01). ETA=19:58:50, max mem: 1.4 GB 
[11/06 19:45:44][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.8348,	0.5469 s / batch. (data: 4.27e-01). ETA=1 day, 4:24:47, max mem: 1.4 GB 
[11/06 19:46:05][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.6684,	0.1855 s / batch. (data: 1.55e-02). ETA=9:37:54, max mem: 1.4 GB 
[11/06 19:46:27][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.7489,	0.2172 s / batch. (data: 2.28e-02). ETA=11:16:08, max mem: 1.4 GB 
[11/06 19:46:49][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.7815,	0.1939 s / batch. (data: 1.04e-02). ETA=10:03:29, max mem: 1.4 GB 
[11/06 19:47:12][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.8815,	0.0882 s / batch. (data: 1.97e-04). ETA=4:34:16, max mem: 1.4 GB 
[11/06 19:47:33][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.6301,	0.1723 s / batch. (data: 5.96e-04). ETA=8:55:29, max mem: 1.4 GB 
[11/06 19:47:55][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.7592,	0.0601 s / batch. (data: 1.85e-04). ETA=3:06:43, max mem: 1.4 GB 
[11/06 19:48:15][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.6397,	0.1703 s / batch. (data: 6.71e-03). ETA=8:48:41, max mem: 1.4 GB 
[11/06 19:48:36][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.7558,	0.2032 s / batch. (data: 1.04e-02). ETA=10:30:42, max mem: 1.4 GB 
[11/06 19:48:56][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6205,	0.1950 s / batch. (data: 1.65e-02). ETA=10:04:46, max mem: 1.4 GB 
[11/06 19:49:17][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.7808,	0.1810 s / batch. (data: 1.04e-02). ETA=9:21:01, max mem: 1.4 GB 
[11/06 19:49:40][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.5883,	0.1438 s / batch. (data: 6.09e-04). ETA=7:25:41, max mem: 1.4 GB 
[11/06 19:50:02][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5178,	0.1781 s / batch. (data: 9.06e-05). ETA=9:11:39, max mem: 1.4 GB 
[11/06 19:50:03][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 5.75e-02, avg batch time: 0.2134, average train loss: 0.6977
[11/06 19:50:24][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.991, 0.0376 s / batch. (data: 2.17e-05)max mem: 1.44029 GB 
[11/06 19:50:44][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.991, 0.0393 s / batch. (data: 2.17e-05)max mem: 1.44029 GB 
[11/06 19:50:53][INFO] visual_prompt:  316: Inference (val):avg data time: 2.84e-04, avg batch time: 0.0376, average loss: 0.7017
[11/06 19:50:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[11/06 19:50:53][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.004836411161498653
[11/06 19:51:16][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.7785,	0.2016 s / batch. (data: 1.08e-02). ETA=10:23:52, max mem: 1.4 GB 
[11/06 19:51:37][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.7107,	0.1117 s / batch. (data: 2.10e-04). ETA=5:45:37, max mem: 1.4 GB 
[11/06 19:51:58][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.6778,	0.1531 s / batch. (data: 5.33e-03). ETA=7:53:25, max mem: 1.4 GB 
[11/06 19:52:18][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.6544,	0.2055 s / batch. (data: 4.55e-02). ETA=10:34:56, max mem: 1.4 GB 
[11/06 19:52:40][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6068,	0.2114 s / batch. (data: 1.55e-02). ETA=10:52:45, max mem: 1.4 GB 
[11/06 19:53:03][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 1.0049,	0.1351 s / batch. (data: 1.57e-02). ETA=6:56:56, max mem: 1.4 GB 
[11/06 19:53:23][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.5563,	0.1719 s / batch. (data: 2.42e-04). ETA=8:50:12, max mem: 1.4 GB 
[11/06 19:53:44][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.2006,	0.5355 s / batch. (data: 4.59e-01). ETA=1 day, 3:31:11, max mem: 1.4 GB 
[11/06 19:54:04][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.5483,	0.2215 s / batch. (data: 5.76e-03). ETA=11:22:41, max mem: 1.4 GB 
[11/06 19:54:25][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.7298,	0.1709 s / batch. (data: 7.38e-03). ETA=8:46:26, max mem: 1.4 GB 
[11/06 19:54:47][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.6831,	0.1616 s / batch. (data: 2.06e-04). ETA=8:17:32, max mem: 1.4 GB 
[11/06 19:55:07][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.8113,	0.1710 s / batch. (data: 2.04e-04). ETA=8:46:00, max mem: 1.4 GB 
[11/06 19:55:29][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.6625,	0.1767 s / batch. (data: 7.37e-03). ETA=9:03:20, max mem: 1.4 GB 
[11/06 19:55:51][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.5984,	0.1729 s / batch. (data: 2.05e-02). ETA=8:51:15, max mem: 1.4 GB 
[11/06 19:56:14][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.5696,	0.1687 s / batch. (data: 2.32e-04). ETA=8:38:19, max mem: 1.4 GB 
[11/06 19:56:36][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.8443,	0.1502 s / batch. (data: 2.00e-04). ETA=7:41:16, max mem: 1.4 GB 
[11/06 19:56:56][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.9127,	0.1837 s / batch. (data: 8.76e-03). ETA=9:23:37, max mem: 1.4 GB 
[11/06 19:57:17][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 1.0271,	0.2437 s / batch. (data: 2.05e-02). ETA=12:27:14, max mem: 1.4 GB 
[11/06 19:57:39][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6181,	0.1747 s / batch. (data: 1.58e-02). ETA=8:55:25, max mem: 1.4 GB 
[11/06 19:58:02][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.4726,	0.2038 s / batch. (data: 3.23e-02). ETA=10:24:26, max mem: 1.4 GB 
[11/06 19:58:23][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.5086,	0.1973 s / batch. (data: 1.59e-02). ETA=10:03:57, max mem: 1.4 GB 
[11/06 19:58:45][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.9925,	0.1310 s / batch. (data: 9.39e-05). ETA=6:40:50, max mem: 1.4 GB 
[11/06 19:58:46][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.91e-02, avg batch time: 0.2139, average train loss: 0.7059
[11/06 19:59:07][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.937, 0.0461 s / batch. (data: 2.07e-05)max mem: 1.44029 GB 
[11/06 19:59:27][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.937, 0.0648 s / batch. (data: 2.03e-05)max mem: 1.44029 GB 
[11/06 19:59:35][INFO] visual_prompt:  316: Inference (val):avg data time: 2.95e-04, avg batch time: 0.0452, average loss: 0.6957
[11/06 19:59:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.78	
[11/06 19:59:35][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.004805724387443462
[11/06 19:59:59][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.8682,	0.1811 s / batch. (data: 5.32e-03). ETA=9:13:48, max mem: 1.4 GB 
[11/06 20:00:21][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.5353,	0.1566 s / batch. (data: 1.59e-02). ETA=7:58:39, max mem: 1.4 GB 
[11/06 20:00:42][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.5404,	0.2015 s / batch. (data: 1.55e-02). ETA=10:15:39, max mem: 1.4 GB 
[11/06 20:01:06][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.5664,	0.1654 s / batch. (data: 2.79e-04). ETA=8:25:05, max mem: 1.4 GB 
[11/06 20:01:28][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.7738,	1.3962 s / batch. (data: 1.32e+00). ETA=2 days, 23:00:38, max mem: 1.4 GB 
[11/06 20:01:49][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.7251,	0.1983 s / batch. (data: 2.08e-02). ETA=10:04:54, max mem: 1.4 GB 
[11/06 20:02:12][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.8341,	0.2616 s / batch. (data: 5.78e-03). ETA=13:17:20, max mem: 1.4 GB 
[11/06 20:02:34][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.7486,	0.1693 s / batch. (data: 5.34e-03). ETA=8:35:55, max mem: 1.4 GB 
[11/06 20:02:56][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7135,	0.2266 s / batch. (data: 1.04e-02). ETA=11:29:54, max mem: 1.4 GB 
[11/06 20:03:19][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.8818,	0.1866 s / batch. (data: 1.04e-02). ETA=9:27:44, max mem: 1.4 GB 
[11/06 20:03:40][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.6277,	0.1076 s / batch. (data: 1.38e-02). ETA=5:27:18, max mem: 1.4 GB 
[11/06 20:04:01][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.8052,	0.1279 s / batch. (data: 2.20e-04). ETA=6:28:41, max mem: 1.4 GB 
[11/06 20:04:23][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.5989,	0.2081 s / batch. (data: 5.78e-03). ETA=10:32:10, max mem: 1.4 GB 
[11/06 20:04:45][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.7587,	0.1936 s / batch. (data: 5.34e-03). ETA=9:47:45, max mem: 1.4 GB 
[11/06 20:05:08][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.8765,	0.2185 s / batch. (data: 6.08e-03). ETA=11:03:12, max mem: 1.4 GB 
[11/06 20:05:30][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.6073,	0.2071 s / batch. (data: 1.02e-02). ETA=10:28:17, max mem: 1.4 GB 
[11/06 20:05:52][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.6059,	0.2234 s / batch. (data: 3.46e-02). ETA=11:17:10, max mem: 1.4 GB 
[11/06 20:06:15][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.8174,	0.2383 s / batch. (data: 5.78e-03). ETA=12:01:53, max mem: 1.4 GB 
[11/06 20:06:36][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.5963,	0.2044 s / batch. (data: 2.94e-03). ETA=10:18:59, max mem: 1.4 GB 
[11/06 20:06:57][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.8074,	0.2344 s / batch. (data: 1.08e-02). ETA=11:49:21, max mem: 1.4 GB 
[11/06 20:07:19][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.5862,	0.2159 s / batch. (data: 2.74e-02). ETA=10:53:10, max mem: 1.4 GB 
[11/06 20:07:41][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5618,	0.1641 s / batch. (data: 9.30e-05). ETA=8:16:01, max mem: 1.4 GB 
[11/06 20:07:42][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.98e-02, avg batch time: 0.2200, average train loss: 0.6982
[11/06 20:08:04][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.844, 0.0706 s / batch. (data: 2.43e-05)max mem: 1.44029 GB 
[11/06 20:08:24][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.844, 0.0735 s / batch. (data: 2.29e-05)max mem: 1.44029 GB 
[11/06 20:08:32][INFO] visual_prompt:  316: Inference (val):avg data time: 1.95e-04, avg batch time: 0.0476, average loss: 0.6893
[11/06 20:08:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.95	
[11/06 20:08:32][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.004772516337622906
[11/06 20:08:56][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.9035,	0.1933 s / batch. (data: 5.31e-03). ETA=9:43:54, max mem: 1.4 GB 
[11/06 20:09:18][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.5679,	0.1737 s / batch. (data: 2.50e-04). ETA=8:44:23, max mem: 1.4 GB 
[11/06 20:09:39][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 1.1631,	0.1659 s / batch. (data: 1.03e-02). ETA=8:20:33, max mem: 1.4 GB 
[11/06 20:10:01][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.5566,	0.7950 s / batch. (data: 6.91e-01). ETA=1 day, 15:58:07, max mem: 1.4 GB 
[11/06 20:10:21][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.6033,	0.2094 s / batch. (data: 5.75e-03). ETA=10:31:19, max mem: 1.4 GB 
[11/06 20:10:44][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.8827,	0.1393 s / batch. (data: 1.87e-02). ETA=6:59:45, max mem: 1.4 GB 
[11/06 20:11:05][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.8296,	0.2065 s / batch. (data: 1.08e-02). ETA=10:21:42, max mem: 1.4 GB 
[11/06 20:11:27][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.5638,	0.1993 s / batch. (data: 2.34e-04). ETA=9:59:48, max mem: 1.4 GB 
[11/06 20:11:48][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.5569,	0.3764 s / batch. (data: 2.40e-01). ETA=18:52:08, max mem: 1.4 GB 
[11/06 20:12:09][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.5466,	0.2103 s / batch. (data: 2.05e-02). ETA=10:32:19, max mem: 1.4 GB 
[11/06 20:12:32][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.9052,	0.1790 s / batch. (data: 5.31e-03). ETA=8:57:48, max mem: 1.4 GB 
[11/06 20:12:52][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 1.3848,	0.1812 s / batch. (data: 1.04e-02). ETA=9:04:15, max mem: 1.4 GB 
[11/06 20:13:16][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.8316,	0.1255 s / batch. (data: 5.31e-03). ETA=6:16:39, max mem: 1.4 GB 
[11/06 20:13:35][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.7402,	0.1859 s / batch. (data: 1.04e-02). ETA=9:17:43, max mem: 1.4 GB 
[11/06 20:13:57][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.7360,	0.2150 s / batch. (data: 3.20e-02). ETA=10:44:38, max mem: 1.4 GB 
[11/06 20:14:19][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.8149,	0.3605 s / batch. (data: 2.79e-01). ETA=18:00:20, max mem: 1.4 GB 
[11/06 20:14:40][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.4888,	0.1556 s / batch. (data: 7.05e-03). ETA=7:45:58, max mem: 1.4 GB 
[11/06 20:15:01][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.6148,	0.1621 s / batch. (data: 9.38e-03). ETA=8:05:09, max mem: 1.4 GB 
[11/06 20:15:22][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.5154,	0.2100 s / batch. (data: 1.54e-02). ETA=10:28:05, max mem: 1.4 GB 
[11/06 20:15:43][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.6448,	0.1397 s / batch. (data: 2.36e-04). ETA=6:57:41, max mem: 1.4 GB 
[11/06 20:16:05][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.5808,	0.1705 s / batch. (data: 1.59e-02). ETA=8:29:26, max mem: 1.4 GB 
[11/06 20:16:26][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.3812,	0.1206 s / batch. (data: 9.78e-05). ETA=6:00:04, max mem: 1.4 GB 
[11/06 20:16:27][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.91e-02, avg batch time: 0.2144, average train loss: 0.7023
[11/06 20:16:48][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.432, 0.0796 s / batch. (data: 2.36e-05)max mem: 1.44029 GB 
[11/06 20:17:07][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.432, 0.0793 s / batch. (data: 2.41e-05)max mem: 1.44029 GB 
[11/06 20:17:15][INFO] visual_prompt:  316: Inference (val):avg data time: 6.46e-04, avg batch time: 0.0440, average loss: 0.7701
[11/06 20:17:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.02	
[11/06 20:17:15][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.004736823324551909
[11/06 20:17:38][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.5124,	0.2194 s / batch. (data: 1.55e-02). ETA=10:54:48, max mem: 1.4 GB 
[11/06 20:18:01][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 1.0433,	0.1030 s / batch. (data: 2.31e-04). ETA=5:07:12, max mem: 1.4 GB 
[11/06 20:18:23][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 0.5681,	0.1891 s / batch. (data: 1.40e-02). ETA=9:23:49, max mem: 1.4 GB 
[11/06 20:18:45][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.6607,	0.3676 s / batch. (data: 2.40e-01). ETA=18:15:17, max mem: 1.4 GB 
[11/06 20:19:06][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.4971,	0.2347 s / batch. (data: 1.83e-02). ETA=11:38:52, max mem: 1.4 GB 
[11/06 20:19:28][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.8525,	0.2119 s / batch. (data: 4.84e-03). ETA=10:30:33, max mem: 1.4 GB 
[11/06 20:19:49][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.6120,	0.1675 s / batch. (data: 2.25e-04). ETA=8:18:06, max mem: 1.4 GB 
[11/06 20:20:09][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.5183,	0.2260 s / batch. (data: 1.59e-02). ETA=11:11:55, max mem: 1.4 GB 
[11/06 20:20:31][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7786,	0.1561 s / batch. (data: 1.17e-02). ETA=7:43:51, max mem: 1.4 GB 
[11/06 20:20:52][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.9230,	0.2126 s / batch. (data: 2.60e-02). ETA=10:31:14, max mem: 1.4 GB 
[11/06 20:21:13][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.4839,	0.2032 s / batch. (data: 2.43e-02). ETA=10:02:55, max mem: 1.4 GB 
[11/06 20:21:35][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.7820,	0.2150 s / batch. (data: 1.55e-02). ETA=10:37:50, max mem: 1.4 GB 
[11/06 20:21:57][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.8541,	0.1301 s / batch. (data: 2.37e-04). ETA=6:25:34, max mem: 1.4 GB 
[11/06 20:22:19][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.4822,	0.1580 s / batch. (data: 6.45e-04). ETA=7:48:05, max mem: 1.4 GB 
[11/06 20:22:41][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.6898,	0.1793 s / batch. (data: 1.80e-02). ETA=8:50:55, max mem: 1.4 GB 
[11/06 20:23:02][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.8665,	0.1875 s / batch. (data: 1.24e-03). ETA=9:14:56, max mem: 1.4 GB 
[11/06 20:23:23][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.8411,	0.1943 s / batch. (data: 1.04e-02). ETA=9:34:47, max mem: 1.4 GB 
[11/06 20:23:44][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.6116,	0.1797 s / batch. (data: 7.70e-03). ETA=8:51:08, max mem: 1.4 GB 
[11/06 20:24:06][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.8567,	0.1391 s / batch. (data: 1.61e-02). ETA=6:51:02, max mem: 1.4 GB 
[11/06 20:24:27][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.5968,	0.2402 s / batch. (data: 3.27e-02). ETA=11:49:11, max mem: 1.4 GB 
[11/06 20:24:50][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.6830,	0.1927 s / batch. (data: 8.23e-03). ETA=9:28:39, max mem: 1.4 GB 
[11/06 20:25:11][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.5685,	0.0987 s / batch. (data: 1.02e-04). ETA=4:51:06, max mem: 1.4 GB 
[11/06 20:25:12][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.69e-02, avg batch time: 0.2153, average train loss: 0.7037
[11/06 20:25:33][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.688, 0.0417 s / batch. (data: 2.07e-05)max mem: 1.44029 GB 
[11/06 20:25:53][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.688, 0.0728 s / batch. (data: 2.43e-05)max mem: 1.44029 GB 
[11/06 20:26:01][INFO] visual_prompt:  316: Inference (val):avg data time: 5.80e-04, avg batch time: 0.0459, average loss: 0.6937
[11/06 20:26:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/06 20:26:01][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.004698684378016222
[11/06 20:26:26][INFO] visual_prompt:  204: 	Training 100/2212. train loss: 0.5834,	1.5881 s / batch. (data: 1.50e+00). ETA=3 days, 6:01:09, max mem: 1.4 GB 
[11/06 20:26:46][INFO] visual_prompt:  204: 	Training 200/2212. train loss: 0.6685,	0.1853 s / batch. (data: 2.05e-04). ETA=9:05:49, max mem: 1.4 GB 
[11/06 20:27:09][INFO] visual_prompt:  204: 	Training 300/2212. train loss: 1.0859,	0.1584 s / batch. (data: 1.53e-02). ETA=7:46:24, max mem: 1.4 GB 
[11/06 20:27:31][INFO] visual_prompt:  204: 	Training 400/2212. train loss: 0.8037,	0.1692 s / batch. (data: 6.60e-04). ETA=8:17:52, max mem: 1.4 GB 
[11/06 20:27:51][INFO] visual_prompt:  204: 	Training 500/2212. train loss: 0.7896,	0.1309 s / batch. (data: 2.40e-04). ETA=6:25:01, max mem: 1.4 GB 
[11/06 20:28:13][INFO] visual_prompt:  204: 	Training 600/2212. train loss: 0.8306,	0.1770 s / batch. (data: 4.51e-04). ETA=8:40:07, max mem: 1.4 GB 
[11/06 20:28:35][INFO] visual_prompt:  204: 	Training 700/2212. train loss: 0.5770,	0.1997 s / batch. (data: 5.33e-03). ETA=9:46:33, max mem: 1.4 GB 
[11/06 20:28:57][INFO] visual_prompt:  204: 	Training 800/2212. train loss: 0.6874,	0.2277 s / batch. (data: 6.25e-04). ETA=11:08:26, max mem: 1.4 GB 
[11/06 20:29:19][INFO] visual_prompt:  204: 	Training 900/2212. train loss: 0.7887,	0.1800 s / batch. (data: 1.37e-02). ETA=8:48:19, max mem: 1.4 GB 
[11/06 20:29:39][INFO] visual_prompt:  204: 	Training 1000/2212. train loss: 0.6271,	0.2111 s / batch. (data: 1.04e-02). ETA=10:19:07, max mem: 1.4 GB 
[11/06 20:29:59][INFO] visual_prompt:  204: 	Training 1100/2212. train loss: 0.7528,	0.1959 s / batch. (data: 3.63e-02). ETA=9:34:05, max mem: 1.4 GB 
[11/06 20:30:21][INFO] visual_prompt:  204: 	Training 1200/2212. train loss: 0.7071,	0.1807 s / batch. (data: 1.55e-02). ETA=8:49:11, max mem: 1.4 GB 
[11/06 20:30:43][INFO] visual_prompt:  204: 	Training 1300/2212. train loss: 0.6523,	0.6334 s / batch. (data: 4.95e-01). ETA=1 day, 6:54:19, max mem: 1.4 GB 
[11/06 20:31:04][INFO] visual_prompt:  204: 	Training 1400/2212. train loss: 0.6152,	0.2014 s / batch. (data: 2.47e-02). ETA=9:49:24, max mem: 1.4 GB 
[11/06 20:31:26][INFO] visual_prompt:  204: 	Training 1500/2212. train loss: 0.5682,	0.2129 s / batch. (data: 1.39e-02). ETA=10:22:27, max mem: 1.4 GB 
[11/06 20:31:46][INFO] visual_prompt:  204: 	Training 1600/2212. train loss: 0.5715,	0.1925 s / batch. (data: 6.54e-04). ETA=9:22:40, max mem: 1.4 GB 
[11/06 20:32:07][INFO] visual_prompt:  204: 	Training 1700/2212. train loss: 0.7787,	0.1285 s / batch. (data: 5.32e-03). ETA=6:15:22, max mem: 1.4 GB 
[11/06 20:32:28][INFO] visual_prompt:  204: 	Training 1800/2212. train loss: 0.6419,	0.1267 s / batch. (data: 1.04e-02). ETA=6:09:48, max mem: 1.4 GB 
[11/06 20:32:49][INFO] visual_prompt:  204: 	Training 1900/2212. train loss: 0.6088,	0.2008 s / batch. (data: 2.05e-02). ETA=9:45:44, max mem: 1.4 GB 
[11/06 20:33:10][INFO] visual_prompt:  204: 	Training 2000/2212. train loss: 0.7846,	0.2570 s / batch. (data: 1.31e-01). ETA=12:29:24, max mem: 1.4 GB 
[11/06 20:33:31][INFO] visual_prompt:  204: 	Training 2100/2212. train loss: 0.9442,	0.1882 s / batch. (data: 1.04e-02). ETA=9:08:37, max mem: 1.4 GB 
[11/06 20:33:51][INFO] visual_prompt:  204: 	Training 2200/2212. train loss: 0.7141,	0.1627 s / batch. (data: 1.31e-04). ETA=7:54:01, max mem: 1.4 GB 
[11/06 20:33:52][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.74e-02, avg batch time: 0.2130, average train loss: 0.6952
[11/06 20:34:13][INFO] visual_prompt:  303: 	Test 100/246. loss: 0.909, 0.0470 s / batch. (data: 2.34e-05)max mem: 1.44029 GB 
[11/06 20:34:33][INFO] visual_prompt:  303: 	Test 200/246. loss: 0.909, 0.0549 s / batch. (data: 2.31e-05)max mem: 1.44029 GB 
[11/06 20:34:41][INFO] visual_prompt:  316: Inference (val):avg data time: 4.91e-04, avg batch time: 0.0450, average loss: 0.6931
[11/06 20:34:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.09	
[11/06 20:34:41][INFO] visual_prompt:   42: Stopping early.
