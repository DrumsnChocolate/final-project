[11/25 01:36:28][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/25 01:36:28][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 01:36:28][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/finetune/cub.yaml', train_type='finetune', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/25 01:36:28][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/finetune/cub.yaml:
_BASE_: "../base-finetune.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
  FEATURE: "imagenet_supervised"  # need to tune
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.00375
  WEIGHT_DECAY: 0.01

[11/25 01:36:28][INFO] visual_prompt:  108: Training with config:
[11/25 01:36:28][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/end2end/size800/test/seed8393/lr0.0001_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8393, 'MODEL': CfgNode({'TRANSFER_TYPE': 'end2end', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'adamw', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.0001, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 5, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 8, 'PIN_MEMORY': True})})
[11/25 01:36:28][INFO] visual_prompt:   55: Loading training data...
[11/25 01:36:28][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/25 01:36:28][INFO] visual_prompt:   57: Loading validation data...
[11/25 01:36:28][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/25 01:36:28][INFO] visual_prompt:   61: Loading test data...
[11/25 01:36:28][INFO] visual_prompt:   28: Constructing mammo-cbis dataset test...
[11/25 01:36:28][INFO] visual_prompt:   38: Constructing models...
[11/25 01:36:35][INFO] visual_prompt:  153: Enable all parameters update during training
[11/25 01:36:35][INFO] visual_prompt:   52: Total Parameters: 87569666	 Gradient Parameters: 87569666
[11/25 01:36:35][INFO] visual_prompt:   54: tuned percent:100.000
[11/25 01:36:35][INFO] visual_prompt:   40: Device used for model: 0
[11/25 01:36:35][INFO] visual_prompt:   40: Setting up Evaluator...
[11/25 01:36:35][INFO] visual_prompt:   42: Setting up Trainer...
[11/25 01:36:35][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/25 01:36:35][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/25 01:38:18][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0285,	0.9027 s / batch. (data: 2.37e-04). ETA=13:50:31, max mem: 30.7 GB 
[11/25 01:39:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.4493,	0.9120 s / batch. (data: 2.58e-04). ETA=13:57:32, max mem: 30.7 GB 
[11/25 01:41:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.6621,	0.9733 s / batch. (data: 5.83e-03). ETA=14:52:11, max mem: 30.7 GB 
[11/25 01:42:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.3399,	0.9250 s / batch. (data: 9.72e-03). ETA=14:06:21, max mem: 30.7 GB 
[11/25 01:44:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.1827,	0.9577 s / batch. (data: 1.85e-02). ETA=14:34:43, max mem: 30.7 GB 
[11/25 01:45:23][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 2.38e-02, avg batch time: 0.9535, average train loss: 2.1069
[11/25 01:46:17][INFO] visual_prompt:  316: Inference (val):avg data time: 1.23e-04, avg batch time: 0.3057, average loss: 2.0883
[11/25 01:46:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 56.45	
[11/25 01:47:49][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.147, 0.3198 s / batch. (data: 4.60e-05)max mem: 30.66532 GB 
[11/25 01:48:36][INFO] visual_prompt:  316: Inference (test):avg data time: 3.17e-05, avg batch time: 0.3053, average loss: 2.1041
[11/25 01:48:36][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 51.47	rocauc: 50.78	
[11/25 01:48:36][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 2e-05
[11/25 01:50:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1122,	0.9560 s / batch. (data: 2.63e-04). ETA=14:30:42, max mem: 30.7 GB 
[11/25 01:51:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6878,	0.9149 s / batch. (data: 5.43e-03). ETA=13:51:45, max mem: 30.7 GB 
[11/25 01:53:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0865,	0.9319 s / batch. (data: 4.28e-04). ETA=14:05:40, max mem: 30.7 GB 
[11/25 01:54:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1567,	0.9254 s / batch. (data: 7.77e-04). ETA=13:58:10, max mem: 30.7 GB 
[11/25 01:56:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3822,	0.9324 s / batch. (data: 2.88e-04). ETA=14:02:58, max mem: 30.7 GB 
[11/25 01:57:20][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 1.65e-02, avg batch time: 0.9481, average train loss: 0.9040
[11/25 01:58:15][INFO] visual_prompt:  316: Inference (val):avg data time: 2.96e-05, avg batch time: 0.3063, average loss: 0.6799
[11/25 01:58:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 58.49	
[11/25 01:59:48][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.514, 0.2950 s / batch. (data: 3.74e-05)max mem: 30.66532 GB 
[11/25 02:00:35][INFO] visual_prompt:  316: Inference (test):avg data time: 3.22e-05, avg batch time: 0.3055, average loss: 0.6712
[11/25 02:00:35][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 60.74	
[11/25 02:00:35][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 4e-05
[11/25 02:02:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8776,	0.9305 s / batch. (data: 7.17e-04). ETA=13:58:55, max mem: 30.7 GB 
[11/25 02:03:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4771,	0.9520 s / batch. (data: 7.51e-04). ETA=14:16:42, max mem: 30.7 GB 
[11/25 02:05:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0598,	0.9360 s / batch. (data: 8.08e-04). ETA=14:00:43, max mem: 30.7 GB 
[11/25 02:07:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7800,	0.9137 s / batch. (data: 2.72e-04). ETA=13:39:10, max mem: 30.7 GB 
[11/25 02:08:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5935,	0.9310 s / batch. (data: 7.48e-04). ETA=13:53:11, max mem: 30.7 GB 
[11/25 02:09:23][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 2.62e-02, avg batch time: 0.9554, average train loss: 0.7843
[11/25 02:10:19][INFO] visual_prompt:  316: Inference (val):avg data time: 1.92e-04, avg batch time: 0.3060, average loss: 0.7525
[11/25 02:10:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.26	
[11/25 02:11:52][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.670, 0.3034 s / batch. (data: 3.17e-05)max mem: 30.66532 GB 
[11/25 02:12:39][INFO] visual_prompt:  316: Inference (test):avg data time: 1.62e-04, avg batch time: 0.3078, average loss: 0.7007
[11/25 02:12:39][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 62.30	
[11/25 02:12:39][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 6e-05
[11/25 02:14:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9210,	0.9440 s / batch. (data: 2.81e-04). ETA=14:02:22, max mem: 30.7 GB 
[11/25 02:15:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2606,	0.9300 s / batch. (data: 2.50e-04). ETA=13:48:22, max mem: 30.7 GB 
[11/25 02:17:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9073,	0.9457 s / batch. (data: 7.57e-04). ETA=14:00:46, max mem: 30.7 GB 
[11/25 02:19:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7808,	0.9331 s / batch. (data: 2.40e-04). ETA=13:48:01, max mem: 30.7 GB 
[11/25 02:20:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8568,	0.9282 s / batch. (data: 7.45e-04). ETA=13:42:05, max mem: 30.7 GB 
[11/25 02:21:26][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 2.09e-02, avg batch time: 0.9524, average train loss: 0.7385
[11/25 02:22:21][INFO] visual_prompt:  316: Inference (val):avg data time: 4.73e-04, avg batch time: 0.3201, average loss: 0.6824
[11/25 02:22:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.17	
[11/25 02:23:54][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.591, 0.2947 s / batch. (data: 4.22e-05)max mem: 30.66532 GB 
[11/25 02:24:40][INFO] visual_prompt:  316: Inference (test):avg data time: 3.26e-05, avg batch time: 0.3070, average loss: 0.6486
[11/25 02:24:40][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 61.09	rocauc: 65.90	
[11/25 02:24:40][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 8e-05
[11/25 02:26:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6383,	0.9640 s / batch. (data: 2.45e-04). ETA=14:11:19, max mem: 30.7 GB 
[11/25 02:27:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6074,	0.9394 s / batch. (data: 5.86e-03). ETA=13:48:04, max mem: 30.7 GB 
[11/25 02:29:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8359,	0.9296 s / batch. (data: 1.04e-02). ETA=13:37:51, max mem: 30.7 GB 
[11/25 02:31:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7694,	0.9406 s / batch. (data: 6.97e-04). ETA=13:45:57, max mem: 30.7 GB 
[11/25 02:32:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3580,	0.9332 s / batch. (data: 5.37e-03). ETA=13:37:56, max mem: 30.7 GB 
[11/25 02:33:27][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 2.20e-02, avg batch time: 0.9524, average train loss: 0.7194
[11/25 02:34:22][INFO] visual_prompt:  316: Inference (val):avg data time: 1.48e-04, avg batch time: 0.3075, average loss: 0.6084
[11/25 02:34:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.28	
[11/25 02:35:55][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.584, 0.2951 s / batch. (data: 3.27e-05)max mem: 30.66532 GB 
[11/25 02:36:41][INFO] visual_prompt:  316: Inference (test):avg data time: 3.22e-05, avg batch time: 0.3056, average loss: 0.6212
[11/25 02:36:41][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 64.50	rocauc: 68.33	
[11/25 02:36:41][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.0001
[11/25 02:38:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0505,	0.9030 s / batch. (data: 2.72e-04). ETA=13:09:09, max mem: 30.7 GB 
[11/25 02:39:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7419,	0.9426 s / batch. (data: 2.87e-02). ETA=13:42:09, max mem: 30.7 GB 
[11/25 02:41:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8604,	0.9572 s / batch. (data: 8.33e-04). ETA=13:53:21, max mem: 30.7 GB 
[11/25 02:43:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2515,	0.9721 s / batch. (data: 1.09e-02). ETA=14:04:38, max mem: 30.7 GB 
[11/25 02:44:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9458,	0.9298 s / batch. (data: 2.63e-04). ETA=13:26:21, max mem: 30.7 GB 
[11/25 02:45:31][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 2.62e-02, avg batch time: 0.9566, average train loss: 0.7042
[11/25 02:46:25][INFO] visual_prompt:  316: Inference (val):avg data time: 2.98e-05, avg batch time: 0.3031, average loss: 0.6180
[11/25 02:46:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.05	
[11/25 02:47:58][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.525, 0.3022 s / batch. (data: 3.67e-05)max mem: 30.66532 GB 
[11/25 02:48:45][INFO] visual_prompt:  316: Inference (test):avg data time: 2.19e-04, avg batch time: 0.3050, average loss: 0.6170
[11/25 02:48:45][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 65.74	rocauc: 69.36	
[11/25 02:48:45][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 9.997266286704631e-05
[11/25 02:50:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4082,	0.9280 s / batch. (data: 2.50e-04). ETA=13:22:25, max mem: 30.7 GB 
[11/25 02:52:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5940,	0.9308 s / batch. (data: 2.03e-02). ETA=13:23:17, max mem: 30.7 GB 
[11/25 02:53:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5503,	0.9576 s / batch. (data: 1.55e-02). ETA=13:44:50, max mem: 30.7 GB 
[11/25 02:55:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6449,	0.9325 s / batch. (data: 7.50e-04). ETA=13:21:39, max mem: 30.7 GB 
[11/25 02:56:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0192,	0.9510 s / batch. (data: 9.65e-03). ETA=13:36:00, max mem: 30.7 GB 
[11/25 02:57:31][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.95e-02, avg batch time: 0.9499, average train loss: 0.6502
[11/25 02:58:26][INFO] visual_prompt:  316: Inference (val):avg data time: 1.47e-04, avg batch time: 0.3069, average loss: 0.6465
[11/25 02:58:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 74.35	
[11/25 02:59:59][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.565, 0.3003 s / batch. (data: 3.17e-05)max mem: 30.66532 GB 
[11/25 03:00:45][INFO] visual_prompt:  316: Inference (test):avg data time: 3.20e-05, avg batch time: 0.3058, average loss: 0.6456
[11/25 03:00:45][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 63.10	rocauc: 69.05	
[11/25 03:00:45][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 9.989068136093873e-05
[11/25 03:02:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8893,	0.9188 s / batch. (data: 4.39e-03). ETA=13:05:58, max mem: 30.7 GB 
[11/25 03:04:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4031,	0.9200 s / batch. (data: 7.93e-04). ETA=13:05:30, max mem: 30.7 GB 
[11/25 03:05:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6574,	0.9376 s / batch. (data: 7.00e-04). ETA=13:18:57, max mem: 30.7 GB 
[11/25 03:07:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6082,	0.9424 s / batch. (data: 5.40e-03). ETA=13:21:29, max mem: 30.7 GB 
[11/25 03:08:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5372,	0.9444 s / batch. (data: 8.23e-04). ETA=13:21:37, max mem: 30.7 GB 
[11/25 03:09:33][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 2.42e-02, avg batch time: 0.9538, average train loss: 0.7074
[11/25 03:10:28][INFO] visual_prompt:  316: Inference (val):avg data time: 2.96e-05, avg batch time: 0.3054, average loss: 0.6664
[11/25 03:10:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 66.12	
[11/25 03:12:02][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.441, 0.3129 s / batch. (data: 3.58e-05)max mem: 30.66532 GB 
[11/25 03:12:48][INFO] visual_prompt:  316: Inference (test):avg data time: 8.61e-05, avg batch time: 0.3066, average loss: 0.6438
[11/25 03:12:48][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 61.71	rocauc: 65.97	
[11/25 03:12:48][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 9.975414512725057e-05
[11/25 03:14:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8953,	0.9560 s / batch. (data: 7.99e-03). ETA=13:29:02, max mem: 30.7 GB 
[11/25 03:16:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9220,	0.9299 s / batch. (data: 2.96e-04). ETA=13:05:22, max mem: 30.7 GB 
[11/25 03:17:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8403,	0.9186 s / batch. (data: 2.73e-04). ETA=12:54:19, max mem: 30.7 GB 
[11/25 03:19:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8433,	0.9262 s / batch. (data: 8.89e-03). ETA=12:59:12, max mem: 30.7 GB 
[11/25 03:20:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6647,	0.9348 s / batch. (data: 5.34e-03). ETA=13:04:49, max mem: 30.7 GB 
[11/25 03:21:34][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 2.19e-02, avg batch time: 0.9507, average train loss: 0.6539
[11/25 03:22:29][INFO] visual_prompt:  316: Inference (val):avg data time: 5.52e-05, avg batch time: 0.3082, average loss: 0.6385
[11/25 03:22:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.70	
[11/25 03:24:02][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.498, 0.3124 s / batch. (data: 3.81e-05)max mem: 30.66532 GB 
[11/25 03:24:49][INFO] visual_prompt:  316: Inference (test):avg data time: 3.27e-05, avg batch time: 0.3076, average loss: 0.6488
[11/25 03:24:49][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 66.49	
[11/25 03:24:49][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 9.956320346634876e-05
[11/25 03:26:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8726,	0.9150 s / batch. (data: 2.72e-04). ETA=12:45:52, max mem: 30.7 GB 
[11/25 03:28:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0205,	0.9442 s / batch. (data: 5.36e-03). ETA=13:08:47, max mem: 30.7 GB 
[11/25 03:29:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9012,	0.9116 s / batch. (data: 2.78e-04). ETA=12:40:02, max mem: 30.7 GB 
[11/25 03:31:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8488,	0.9526 s / batch. (data: 1.09e-02). ETA=13:12:36, max mem: 30.7 GB 
[11/25 03:32:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7606,	0.9265 s / batch. (data: 5.37e-03). ETA=12:49:18, max mem: 30.7 GB 
[11/25 03:33:35][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 2.11e-02, avg batch time: 0.9522, average train loss: 0.6509
[11/25 03:34:30][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-05, avg batch time: 0.3059, average loss: 0.7864
[11/25 03:34:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 66.90	
[11/25 03:36:04][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.558, 0.3005 s / batch. (data: 5.05e-05)max mem: 30.66532 GB 
[11/25 03:36:50][INFO] visual_prompt:  316: Inference (test):avg data time: 3.14e-05, avg batch time: 0.3040, average loss: 0.7227
[11/25 03:36:50][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 64.77	
[11/25 03:36:50][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 9.931806517013612e-05
[11/25 03:38:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4861,	0.9321 s / batch. (data: 1.76e-02). ETA=12:51:36, max mem: 30.7 GB 
[11/25 03:40:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3156,	0.9399 s / batch. (data: 2.41e-04). ETA=12:56:30, max mem: 30.7 GB 
[11/25 03:41:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3993,	0.9579 s / batch. (data: 7.57e-04). ETA=13:09:46, max mem: 30.7 GB 
[11/25 03:43:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6629,	0.9440 s / batch. (data: 7.93e-04). ETA=12:56:47, max mem: 30.7 GB 
[11/25 03:44:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8258,	0.9594 s / batch. (data: 5.85e-03). ETA=13:07:51, max mem: 30.7 GB 
[11/25 03:45:39][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 2.55e-02, avg batch time: 0.9562, average train loss: 0.6281
[11/25 03:46:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.05e-05, avg batch time: 0.3047, average loss: 0.6573
[11/25 03:46:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.62	
[11/25 03:48:08][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.533, 0.3135 s / batch. (data: 5.01e-05)max mem: 30.66532 GB 
[11/25 03:48:54][INFO] visual_prompt:  316: Inference (test):avg data time: 2.84e-04, avg batch time: 0.3077, average loss: 0.7028
[11/25 03:48:54][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 67.39	
[11/25 03:48:54][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 9.901899829374047e-05
[11/25 03:50:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2144,	0.9280 s / batch. (data: 2.89e-04). ETA=12:39:39, max mem: 30.7 GB 
[11/25 03:52:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2417,	0.9402 s / batch. (data: 8.28e-03). ETA=12:48:06, max mem: 30.7 GB 
[11/25 03:53:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0868,	0.9274 s / batch. (data: 4.83e-04). ETA=12:36:03, max mem: 30.7 GB 
[11/25 03:55:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5936,	0.9305 s / batch. (data: 6.82e-04). ETA=12:37:06, max mem: 30.7 GB 
[11/25 03:56:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7357,	0.9347 s / batch. (data: 7.40e-04). ETA=12:38:57, max mem: 30.7 GB 
[11/25 03:57:42][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 2.38e-02, avg batch time: 0.9543, average train loss: 0.6142
[11/25 03:58:37][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-05, avg batch time: 0.3061, average loss: 0.6877
[11/25 03:58:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.05	
[11/25 04:00:10][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.456, 0.3061 s / batch. (data: 6.56e-05)max mem: 30.66532 GB 
[11/25 04:00:56][INFO] visual_prompt:  316: Inference (test):avg data time: 1.55e-04, avg batch time: 0.3042, average loss: 0.6614
[11/25 04:00:56][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 66.54	
[11/25 04:00:56][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 9.86663298624003e-05
[11/25 04:02:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4972,	0.9337 s / batch. (data: 2.40e-04). ETA=12:35:45, max mem: 30.7 GB 
[11/25 04:04:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3323,	0.9358 s / batch. (data: 8.57e-03). ETA=12:35:51, max mem: 30.7 GB 
[11/25 04:05:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5848,	0.9387 s / batch. (data: 5.82e-03). ETA=12:36:40, max mem: 30.7 GB 
[11/25 04:07:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5360,	0.9808 s / batch. (data: 1.04e-02). ETA=13:08:59, max mem: 30.7 GB 
[11/25 04:08:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6494,	0.9355 s / batch. (data: 5.35e-03). ETA=12:30:56, max mem: 30.7 GB 
[11/25 04:09:44][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 2.46e-02, avg batch time: 0.9546, average train loss: 0.6010
[11/25 04:10:39][INFO] visual_prompt:  316: Inference (val):avg data time: 4.21e-04, avg batch time: 0.3076, average loss: 0.7572
[11/25 04:10:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.53	
[11/25 04:12:12][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.645, 0.3040 s / batch. (data: 4.63e-05)max mem: 30.66532 GB 
[11/25 04:12:59][INFO] visual_prompt:  316: Inference (test):avg data time: 1.06e-04, avg batch time: 0.3064, average loss: 0.8462
[11/25 04:12:59][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 55.35	rocauc: 63.93	
[11/25 04:12:59][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 9.826044551386744e-05
[11/25 04:14:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5017,	0.9481 s / batch. (data: 1.04e-02). ETA=12:38:40, max mem: 30.7 GB 
[11/25 04:16:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6561,	0.9431 s / batch. (data: 7.02e-04). ETA=12:33:02, max mem: 30.7 GB 
[11/25 04:17:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8638,	0.9222 s / batch. (data: 2.46e-04). ETA=12:14:49, max mem: 30.7 GB 
[11/25 04:19:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6052,	0.9604 s / batch. (data: 2.68e-04). ETA=12:43:40, max mem: 30.7 GB 
[11/25 04:20:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4583,	0.9177 s / batch. (data: 2.60e-04). ETA=12:08:14, max mem: 30.7 GB 
[11/25 04:21:44][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 2.09e-02, avg batch time: 0.9504, average train loss: 0.5790
[11/25 04:22:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.05e-05, avg batch time: 0.3064, average loss: 0.7271
[11/25 04:22:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 65.32	
[11/25 04:24:13][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.638, 0.2972 s / batch. (data: 4.82e-05)max mem: 30.66532 GB 
[11/25 04:24:59][INFO] visual_prompt:  316: Inference (test):avg data time: 3.26e-05, avg batch time: 0.3073, average loss: 0.7557
[11/25 04:24:59][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 62.98	
[11/25 04:24:59][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 9.780178907671789e-05
[11/25 04:26:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6478,	0.9295 s / batch. (data: 2.71e-04). ETA=12:15:09, max mem: 30.7 GB 
[11/25 04:28:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3736,	0.9520 s / batch. (data: 2.65e-04). ETA=12:31:24, max mem: 30.7 GB 
[11/25 04:29:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6833,	0.9308 s / batch. (data: 7.04e-04). ETA=12:13:07, max mem: 30.7 GB 
[11/25 04:31:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2432,	0.9310 s / batch. (data: 2.60e-04). ETA=12:11:42, max mem: 30.7 GB 
[11/25 04:32:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4072,	0.9193 s / batch. (data: 8.02e-03). ETA=12:01:00, max mem: 30.7 GB 
[11/25 04:33:46][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 2.23e-02, avg batch time: 0.9532, average train loss: 0.5405
[11/25 04:34:41][INFO] visual_prompt:  316: Inference (val):avg data time: 1.59e-04, avg batch time: 0.3056, average loss: 0.7022
[11/25 04:34:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.35	
[11/25 04:36:14][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.676, 0.2952 s / batch. (data: 4.91e-05)max mem: 30.66532 GB 
[11/25 04:37:01][INFO] visual_prompt:  316: Inference (test):avg data time: 3.10e-05, avg batch time: 0.3042, average loss: 0.7078
[11/25 04:37:01][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 62.82	
[11/25 04:37:01][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 9.729086208503174e-05
[11/25 04:38:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6139,	0.9164 s / batch. (data: 3.20e-04). ETA=11:56:24, max mem: 30.7 GB 
[11/25 04:40:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2752,	0.9393 s / batch. (data: 9.35e-04). ETA=12:12:44, max mem: 30.7 GB 
[11/25 04:41:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2953,	0.9575 s / batch. (data: 1.59e-02). ETA=12:25:21, max mem: 30.7 GB 
[11/25 04:43:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2899,	0.9243 s / batch. (data: 2.85e-04). ETA=11:57:57, max mem: 30.7 GB 
[11/25 04:44:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8063,	0.9517 s / batch. (data: 2.53e-04). ETA=12:17:38, max mem: 30.7 GB 
[11/25 04:45:48][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 2.17e-02, avg batch time: 0.9533, average train loss: 0.5091
[11/25 04:46:43][INFO] visual_prompt:  316: Inference (val):avg data time: 2.91e-05, avg batch time: 0.3058, average loss: 0.7680
[11/25 04:46:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.87	
[11/25 04:48:17][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.343, 0.3049 s / batch. (data: 3.48e-05)max mem: 30.66532 GB 
[11/25 04:49:03][INFO] visual_prompt:  316: Inference (test):avg data time: 9.25e-05, avg batch time: 0.3054, average loss: 0.7824
[11/25 04:49:03][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.29	rocauc: 62.66	
[11/25 04:49:03][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 9.672822322997305e-05
[11/25 04:50:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3020,	0.9280 s / batch. (data: 2.70e-04). ETA=11:56:52, max mem: 30.7 GB 
[11/25 04:52:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7762,	0.9089 s / batch. (data: 2.53e-04). ETA=11:40:39, max mem: 30.7 GB 
[11/25 04:53:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0866,	0.9191 s / batch. (data: 8.78e-03). ETA=11:47:00, max mem: 30.7 GB 
[11/25 04:55:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7933,	0.9432 s / batch. (data: 7.48e-04). ETA=12:03:55, max mem: 30.7 GB 
[11/25 04:57:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.1610,	0.9308 s / batch. (data: 2.42e-04). ETA=11:52:54, max mem: 30.7 GB 
[11/25 04:57:51][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 2.30e-02, avg batch time: 0.9535, average train loss: 0.5002
[11/25 04:58:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.16e-05, avg batch time: 0.3059, average loss: 0.8472
[11/25 04:58:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.71	
[11/25 05:00:19][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.423, 0.2954 s / batch. (data: 3.08e-05)max mem: 30.66532 GB 
[11/25 05:01:05][INFO] visual_prompt:  316: Inference (test):avg data time: 3.22e-05, avg batch time: 0.3068, average loss: 0.8346
[11/25 05:01:05][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 60.85	
[11/25 05:01:05][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 9.611448774886924e-05
[11/25 05:02:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3718,	0.9509 s / batch. (data: 7.52e-03). ETA=12:05:48, max mem: 30.7 GB 
[11/25 05:04:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7473,	0.9511 s / batch. (data: 7.36e-04). ETA=12:04:25, max mem: 30.7 GB 
[11/25 05:05:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2020,	0.9244 s / batch. (data: 7.24e-04). ETA=11:42:32, max mem: 30.7 GB 
[11/25 05:07:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4772,	0.9401 s / batch. (data: 5.86e-03). ETA=11:52:55, max mem: 30.7 GB 
[11/25 05:09:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3220,	0.9345 s / batch. (data: 1.55e-02). ETA=11:47:04, max mem: 30.7 GB 
[11/25 05:09:51][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 1.94e-02, avg batch time: 0.9498, average train loss: 0.4489
[11/25 05:10:46][INFO] visual_prompt:  316: Inference (val):avg data time: 8.31e-05, avg batch time: 0.3062, average loss: 0.7681
[11/25 05:10:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.03	
[11/25 05:12:19][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.484, 0.3163 s / batch. (data: 3.79e-05)max mem: 30.66532 GB 
[11/25 05:13:05][INFO] visual_prompt:  316: Inference (test):avg data time: 7.73e-05, avg batch time: 0.3065, average loss: 0.8385
[11/25 05:13:05][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.29	rocauc: 60.28	
[11/25 05:13:05][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 9.545032675245813e-05
[11/25 05:14:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7818,	0.9220 s / batch. (data: 2.75e-04). ETA=11:35:17, max mem: 30.7 GB 
[11/25 05:16:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2450,	0.9680 s / batch. (data: 7.50e-04). ETA=12:08:22, max mem: 30.7 GB 
[11/25 05:17:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7224,	0.9247 s / batch. (data: 2.90e-04). ETA=11:34:14, max mem: 30.7 GB 
[11/25 05:19:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2889,	0.9184 s / batch. (data: 3.04e-04). ETA=11:28:00, max mem: 30.7 GB 
[11/25 05:21:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0376,	0.9390 s / batch. (data: 5.36e-03). ETA=11:41:48, max mem: 30.7 GB 
[11/25 05:21:53][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 2.10e-02, avg batch time: 0.9537, average train loss: 0.4153
[11/25 05:22:48][INFO] visual_prompt:  316: Inference (val):avg data time: 2.98e-05, avg batch time: 0.3053, average loss: 0.8815
[11/25 05:22:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.63	
[11/25 05:24:21][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.124, 0.2988 s / batch. (data: 3.41e-05)max mem: 30.66532 GB 
[11/25 05:25:08][INFO] visual_prompt:  316: Inference (test):avg data time: 1.27e-04, avg batch time: 0.3062, average loss: 0.9274
[11/25 05:25:08][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.60	rocauc: 59.08	
[11/25 05:25:08][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 9.473646649103818e-05
[11/25 05:26:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.1945,	0.9440 s / batch. (data: 2.55e-04). ETA=11:43:10, max mem: 30.7 GB 
[11/25 05:28:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3420,	0.9429 s / batch. (data: 7.61e-04). ETA=11:40:44, max mem: 30.7 GB 
[11/25 05:29:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0946,	0.9079 s / batch. (data: 2.22e-04). ETA=11:13:15, max mem: 30.7 GB 
[11/25 05:31:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4003,	0.9498 s / batch. (data: 1.48e-02). ETA=11:42:45, max mem: 30.7 GB 
[11/25 05:33:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2833,	0.9581 s / batch. (data: 7.33e-04). ETA=11:47:19, max mem: 30.7 GB 
[11/25 05:33:54][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 2.16e-02, avg batch time: 0.9509, average train loss: 0.3953
[11/25 05:34:49][INFO] visual_prompt:  316: Inference (val):avg data time: 2.51e-04, avg batch time: 0.3064, average loss: 1.0277
[11/25 05:34:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.22	
[11/25 05:36:22][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.893, 0.3184 s / batch. (data: 3.19e-05)max mem: 30.66532 GB 
[11/25 05:37:09][INFO] visual_prompt:  316: Inference (test):avg data time: 3.07e-05, avg batch time: 0.3060, average loss: 0.9058
[11/25 05:37:09][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 62.02	rocauc: 63.10	
[11/25 05:37:09][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 9.397368756032445e-05
[11/25 05:38:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.1892,	0.9346 s / batch. (data: 7.62e-04). ETA=11:27:32, max mem: 30.7 GB 
[11/25 05:40:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2588,	0.9531 s / batch. (data: 1.88e-02). ETA=11:39:34, max mem: 30.7 GB 
[11/25 05:41:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4180,	0.9246 s / batch. (data: 2.62e-04). ETA=11:17:08, max mem: 30.7 GB 
[11/25 05:43:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7452,	0.9198 s / batch. (data: 1.04e-02). ETA=11:12:03, max mem: 30.7 GB 
[11/25 05:45:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0300,	0.9593 s / batch. (data: 1.04e-02). ETA=11:39:21, max mem: 30.7 GB 
[11/25 05:45:57][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 2.35e-02, avg batch time: 0.9543, average train loss: 0.3758
[11/25 05:46:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.15e-05, avg batch time: 0.3064, average loss: 0.8517
[11/25 05:46:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.73	
[11/25 05:48:26][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.606, 0.3110 s / batch. (data: 3.24e-05)max mem: 30.66532 GB 
[11/25 05:49:13][INFO] visual_prompt:  316: Inference (test):avg data time: 7.69e-05, avg batch time: 0.3051, average loss: 0.9112
[11/25 05:49:13][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 63.82	
[11/25 05:49:13][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 9.316282404787871e-05
[11/25 05:50:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8431,	0.9559 s / batch. (data: 7.82e-04). ETA=11:34:25, max mem: 30.7 GB 
[11/25 05:52:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6009,	0.9339 s / batch. (data: 6.95e-04). ETA=11:16:54, max mem: 30.7 GB 
[11/25 05:54:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0878,	0.9313 s / batch. (data: 2.72e-04). ETA=11:13:25, max mem: 30.7 GB 
[11/25 05:55:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5728,	0.9137 s / batch. (data: 2.91e-04). ETA=10:59:11, max mem: 30.7 GB 
[11/25 05:57:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.1088,	0.9231 s / batch. (data: 2.74e-04). ETA=11:04:27, max mem: 30.7 GB 
[11/25 05:57:59][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 2.06e-02, avg batch time: 0.9509, average train loss: 0.3174
[11/25 05:58:54][INFO] visual_prompt:  316: Inference (val):avg data time: 4.22e-04, avg batch time: 0.3080, average loss: 0.9235
[11/25 05:58:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 65.51	
[11/25 06:00:27][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.267, 0.3076 s / batch. (data: 3.62e-05)max mem: 30.66532 GB 
[11/25 06:01:14][INFO] visual_prompt:  316: Inference (test):avg data time: 1.22e-04, avg batch time: 0.3064, average loss: 0.9685
[11/25 06:01:14][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 63.21	
[11/25 06:01:14][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 9.230476262104677e-05
[11/25 06:02:55][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0084,	0.9186 s / batch. (data: 3.00e-04). ETA=10:58:49, max mem: 30.7 GB 
[11/25 06:04:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0183,	0.9280 s / batch. (data: 7.69e-04). ETA=11:04:04, max mem: 30.7 GB 
[11/25 06:06:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3595,	0.9590 s / batch. (data: 7.21e-04). ETA=11:24:39, max mem: 30.7 GB 
[11/25 06:07:37][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6494,	0.9400 s / batch. (data: 8.00e-03). ETA=11:09:29, max mem: 30.7 GB 
[11/25 06:09:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3001,	0.9556 s / batch. (data: 1.06e-02). ETA=11:19:02, max mem: 30.7 GB 
[11/25 06:10:01][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 2.07e-02, avg batch time: 0.9521, average train loss: 0.2687
[11/25 06:10:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.04e-05, avg batch time: 0.3070, average loss: 1.0969
[11/25 06:10:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.87	
[11/25 06:12:29][INFO] visual_prompt:  303: 	Test 100/162. loss: 2.078, 0.2947 s / batch. (data: 3.91e-05)max mem: 30.66532 GB 
[11/25 06:13:16][INFO] visual_prompt:  316: Inference (test):avg data time: 7.70e-05, avg batch time: 0.3066, average loss: 1.2505
[11/25 06:13:16][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 61.09	rocauc: 63.02	
[11/25 06:13:16][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 9.140044155740101e-05
[11/25 06:14:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2801,	0.9094 s / batch. (data: 7.95e-03). ETA=10:43:53, max mem: 30.7 GB 
[11/25 06:16:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0424,	0.9070 s / batch. (data: 2.69e-04). ETA=10:40:40, max mem: 30.7 GB 
[11/25 06:18:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0343,	0.9404 s / batch. (data: 5.38e-03). ETA=11:02:41, max mem: 30.7 GB 
[11/25 06:19:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0001,	0.9290 s / batch. (data: 6.90e-04). ETA=10:53:04, max mem: 30.7 GB 
[11/25 06:21:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7233,	0.9114 s / batch. (data: 2.69e-04). ETA=10:39:13, max mem: 30.7 GB 
[11/25 06:22:02][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 2.23e-02, avg batch time: 0.9510, average train loss: 0.2457
[11/25 06:22:57][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-04, avg batch time: 0.3057, average loss: 1.0592
[11/25 06:22:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.50	
[11/25 06:24:30][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.717, 0.3178 s / batch. (data: 3.12e-05)max mem: 30.66532 GB 
[11/25 06:25:17][INFO] visual_prompt:  316: Inference (test):avg data time: 3.42e-05, avg batch time: 0.3060, average loss: 1.1891
[11/25 06:25:17][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.45	rocauc: 61.02	
[11/25 06:25:17][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 9.045084971874738e-05
[11/25 06:27:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0817,	0.9240 s / batch. (data: 2.48e-04). ETA=10:45:41, max mem: 30.7 GB 
[11/25 06:28:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2228,	0.9395 s / batch. (data: 7.31e-04). ETA=10:54:59, max mem: 30.7 GB 
[11/25 06:30:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0504,	0.9340 s / batch. (data: 9.80e-04). ETA=10:49:32, max mem: 30.7 GB 
[11/25 06:31:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.1186,	0.9301 s / batch. (data: 3.47e-04). ETA=10:45:16, max mem: 30.7 GB 
[11/25 06:33:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0639,	0.9465 s / batch. (data: 5.85e-03). ETA=10:55:04, max mem: 30.7 GB 
[11/25 06:34:04][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 2.33e-02, avg batch time: 0.9530, average train loss: 0.1961
[11/25 06:34:59][INFO] visual_prompt:  316: Inference (val):avg data time: 1.22e-04, avg batch time: 0.3056, average loss: 2.8177
[11/25 06:34:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.18	
[11/25 06:36:32][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.854, 0.3115 s / batch. (data: 5.20e-05)max mem: 30.66532 GB 
[11/25 06:37:19][INFO] visual_prompt:  316: Inference (test):avg data time: 3.18e-05, avg batch time: 0.3060, average loss: 1.9514
[11/25 06:37:19][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.76	rocauc: 62.84	
[11/25 06:37:19][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 8.945702546981969e-05
[11/25 06:39:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2919,	0.9405 s / batch. (data: 3.95e-03). ETA=10:48:32, max mem: 30.7 GB 
[11/25 06:40:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4927,	0.9165 s / batch. (data: 5.60e-03). ETA=10:30:30, max mem: 30.7 GB 
[11/25 06:42:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0793,	0.9471 s / batch. (data: 2.13e-02). ETA=10:49:57, max mem: 30.7 GB 
[11/25 06:43:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.1180,	0.9164 s / batch. (data: 2.18e-04). ETA=10:27:19, max mem: 30.7 GB 
[11/25 06:45:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0327,	0.9241 s / batch. (data: 2.62e-04). ETA=10:31:03, max mem: 30.7 GB 
[11/25 06:46:07][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 2.52e-02, avg batch time: 0.9551, average train loss: 0.2213
[11/25 06:47:02][INFO] visual_prompt:  316: Inference (val):avg data time: 2.99e-05, avg batch time: 0.3056, average loss: 1.6074
[11/25 06:47:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.11	
[11/25 06:48:36][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.406, 0.3079 s / batch. (data: 3.36e-05)max mem: 30.66532 GB 
[11/25 06:49:22][INFO] visual_prompt:  316: Inference (test):avg data time: 3.18e-05, avg batch time: 0.3070, average loss: 1.5070
[11/25 06:49:22][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 64.40	
[11/25 06:49:22][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 8.842005554284296e-05
[11/25 06:51:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0075,	0.9315 s / batch. (data: 1.04e-02). ETA=10:33:45, max mem: 30.7 GB 
[11/25 06:52:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.1589,	0.9371 s / batch. (data: 7.28e-04). ETA=10:35:58, max mem: 30.7 GB 
[11/25 06:54:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.1494,	0.9473 s / batch. (data: 5.36e-03). ETA=10:41:23, max mem: 30.7 GB 
[11/25 06:55:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6905,	0.9303 s / batch. (data: 2.62e-04). ETA=10:28:17, max mem: 30.7 GB 
[11/25 06:57:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0194,	0.9483 s / batch. (data: 2.10e-02). ETA=10:38:50, max mem: 30.7 GB 
[11/25 06:58:12][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 2.90e-02, avg batch time: 0.9567, average train loss: 0.1772
[11/25 06:59:07][INFO] visual_prompt:  316: Inference (val):avg data time: 2.96e-05, avg batch time: 0.3069, average loss: 1.2528
[11/25 06:59:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 63.29	
[11/25 07:00:40][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.571, 0.3168 s / batch. (data: 4.03e-05)max mem: 30.66532 GB 
[11/25 07:01:26][INFO] visual_prompt:  316: Inference (test):avg data time: 5.23e-05, avg batch time: 0.3067, average loss: 1.4934
[11/25 07:01:26][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 55.50	rocauc: 58.54	
[11/25 07:01:27][INFO] visual_prompt:   42: Stopping early.
