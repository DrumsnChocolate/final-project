[10/30 21:07:11][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/30 21:07:11][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/30 21:07:11][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/30 21:07:11][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/30 21:07:11][INFO] visual_prompt:  108: Training with config:
[10/30 21:07:11][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/30 21:07:11][INFO] visual_prompt:   55: Loading training data...
[10/30 21:07:11][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/30 21:07:11][INFO] visual_prompt:   57: Loading validation data...
[10/30 21:07:11][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/30 21:07:11][INFO] visual_prompt:   38: Constructing models...
[10/30 21:07:14][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/30 21:07:14][INFO] visual_prompt:   54: tuned percent:0.522
[10/30 21:07:14][INFO] visual_prompt:   40: Device used for model: 0
[10/30 21:07:14][INFO] visual_prompt:   40: Setting up Evaluator...
[10/30 21:07:14][INFO] visual_prompt:   42: Setting up Trainer...
[10/30 21:07:14][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/30 21:07:14][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/30 21:08:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6241 s / batch. (data: 3.15e-04). ETA=19:09:22, max mem: 15.9 GB 
[10/30 21:09:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6326 s / batch. (data: 7.43e-04). ETA=19:24:01, max mem: 15.9 GB 
[10/30 21:10:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6189 s / batch. (data: 2.95e-04). ETA=18:57:42, max mem: 15.9 GB 
[10/30 21:11:29][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6322 s / batch. (data: 3.03e-04). ETA=19:21:11, max mem: 15.9 GB 
[10/30 21:12:32][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6360 s / batch. (data: 1.20e-02). ETA=19:27:00, max mem: 15.9 GB 
[10/30 21:13:36][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6327 s / batch. (data: 7.98e-04). ETA=19:19:54, max mem: 15.9 GB 
[10/30 21:14:39][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6568 s / batch. (data: 1.51e-02). ETA=20:02:57, max mem: 15.9 GB 
[10/30 21:15:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6452 s / batch. (data: 8.20e-04). ETA=19:40:48, max mem: 15.9 GB 
[10/30 21:16:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6560 s / batch. (data: 3.10e-04). ETA=19:59:25, max mem: 15.9 GB 
[10/30 21:17:49][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6329 s / batch. (data: 1.01e-03). ETA=19:16:01, max mem: 15.9 GB 
[10/30 21:18:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6185 s / batch. (data: 1.42e-04). ETA=18:48:46, max mem: 15.9 GB 
[10/30 21:18:56][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.97e-03, avg batch time: 0.6348, average train loss: 1.4028
[10/30 21:19:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2252 s / batch. (data: 3.55e-05)max mem: 15.94594 GB 
[10/30 21:19:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.2331, average loss: 1.3505
[10/30 21:19:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/30 21:19:57][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/30 21:21:01][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6855,	0.6542 s / batch. (data: 8.24e-04). ETA=19:52:43, max mem: 15.9 GB 
[10/30 21:22:05][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6756,	0.6189 s / batch. (data: 2.95e-04). ETA=18:47:21, max mem: 15.9 GB 
[10/30 21:23:08][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9982,	0.6308 s / batch. (data: 2.91e-04). ETA=19:08:00, max mem: 15.9 GB 
[10/30 21:24:11][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1167,	0.6440 s / batch. (data: 7.35e-04). ETA=19:31:00, max mem: 15.9 GB 
[10/30 21:25:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6787,	0.6371 s / batch. (data: 1.73e-03). ETA=19:17:20, max mem: 15.9 GB 
[10/30 21:26:18][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5638,	0.6446 s / batch. (data: 7.93e-04). ETA=19:29:48, max mem: 15.9 GB 
[10/30 21:27:21][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9454,	0.6486 s / batch. (data: 2.81e-04). ETA=19:36:08, max mem: 15.9 GB 
[10/30 21:28:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7623,	0.6610 s / batch. (data: 3.30e-02). ETA=19:57:25, max mem: 15.9 GB 
[10/30 21:29:28][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5964,	0.6367 s / batch. (data: 8.21e-04). ETA=19:12:17, max mem: 15.9 GB 
[10/30 21:30:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5809,	0.6281 s / batch. (data: 9.62e-03). ETA=18:55:46, max mem: 15.9 GB 
[10/30 21:31:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6076,	0.6194 s / batch. (data: 1.38e-04). ETA=18:38:57, max mem: 15.9 GB 
[10/30 21:31:39][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.92e-03, avg batch time: 0.6345, average train loss: 0.7977
[10/30 21:32:28][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.129, 0.2254 s / batch. (data: 3.96e-05)max mem: 15.94594 GB 
[10/30 21:32:39][INFO] visual_prompt:  316: Inference (val):avg data time: 1.31e-04, avg batch time: 0.2317, average loss: 1.0331
[10/30 21:32:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.55	
[10/30 21:32:39][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/30 21:33:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7161,	0.6390 s / batch. (data: 8.84e-04). ETA=19:13:15, max mem: 15.9 GB 
[10/30 21:34:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.2293,	0.6489 s / batch. (data: 7.97e-04). ETA=19:30:02, max mem: 15.9 GB 
[10/30 21:35:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4003,	0.6423 s / batch. (data: 1.10e-02). ETA=19:17:05, max mem: 15.9 GB 
[10/30 21:36:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8524,	0.6404 s / batch. (data: 3.51e-04). ETA=19:12:35, max mem: 15.9 GB 
[10/30 21:37:59][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.1041,	0.6305 s / batch. (data: 7.84e-04). ETA=18:53:43, max mem: 15.9 GB 
[10/30 21:39:02][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6818,	0.6317 s / batch. (data: 8.43e-04). ETA=18:54:54, max mem: 15.9 GB 
[10/30 21:40:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0658,	0.6436 s / batch. (data: 7.56e-04). ETA=19:15:10, max mem: 15.9 GB 
[10/30 21:41:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.8221,	0.6433 s / batch. (data: 3.16e-04). ETA=19:13:33, max mem: 15.9 GB 
[10/30 21:42:12][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.4064,	0.6279 s / batch. (data: 2.97e-04). ETA=18:44:49, max mem: 15.9 GB 
[10/30 21:43:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6584,	0.6341 s / batch. (data: 1.43e-02). ETA=18:54:50, max mem: 15.9 GB 
[10/30 21:44:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5332,	0.6189 s / batch. (data: 1.54e-04). ETA=18:26:39, max mem: 15.9 GB 
[10/30 21:44:22][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.08e-03, avg batch time: 0.6355, average train loss: 0.8002
[10/30 21:45:12][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.835, 0.2434 s / batch. (data: 3.72e-05)max mem: 15.94594 GB 
[10/30 21:45:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.82e-05, avg batch time: 0.2330, average loss: 0.8335
[10/30 21:45:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.56	
[10/30 21:45:22][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.03
[10/30 21:46:28][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1685,	0.6305 s / batch. (data: 8.05e-04). ETA=18:46:19, max mem: 15.9 GB 
[10/30 21:47:31][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.0986,	0.6287 s / batch. (data: 3.15e-04). ETA=18:42:07, max mem: 15.9 GB 
[10/30 21:48:34][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9981,	0.6192 s / batch. (data: 3.50e-04). ETA=18:24:05, max mem: 15.9 GB 
[10/30 21:49:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7798,	0.6436 s / batch. (data: 1.56e-02). ETA=19:06:29, max mem: 15.9 GB 
[10/30 21:50:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.8343,	0.6480 s / batch. (data: 7.81e-04). ETA=19:13:14, max mem: 15.9 GB 
[10/30 21:51:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2169,	0.6205 s / batch. (data: 3.50e-04). ETA=18:23:16, max mem: 15.9 GB 
[10/30 21:52:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3361,	0.6508 s / batch. (data: 4.40e-04). ETA=19:15:59, max mem: 15.9 GB 
[10/30 21:53:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0443,	0.6479 s / batch. (data: 8.08e-04). ETA=19:09:50, max mem: 15.9 GB 
[10/30 21:54:54][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1524,	0.6465 s / batch. (data: 3.36e-04). ETA=19:06:16, max mem: 15.9 GB 
[10/30 21:55:58][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6598,	0.6520 s / batch. (data: 7.81e-04). ETA=19:14:54, max mem: 15.9 GB 
[10/30 21:57:01][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0819,	0.6188 s / batch. (data: 1.60e-04). ETA=18:15:02, max mem: 15.9 GB 
[10/30 21:57:05][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 3.77e-03, avg batch time: 0.6353, average train loss: 0.8239
[10/30 21:57:55][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.124, 0.2384 s / batch. (data: 2.72e-05)max mem: 15.94594 GB 
[10/30 21:58:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2323, average loss: 1.0091
[10/30 21:58:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.70	
[10/30 21:58:06][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/30 21:59:11][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4224,	0.6330 s / batch. (data: 4.41e-04). ETA=18:39:09, max mem: 15.9 GB 
[10/30 22:00:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2425,	0.6307 s / batch. (data: 8.14e-04). ETA=18:33:58, max mem: 15.9 GB 
[10/30 22:01:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7895,	0.6303 s / batch. (data: 7.90e-04). ETA=18:32:16, max mem: 15.9 GB 
[10/30 22:02:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1068,	0.6587 s / batch. (data: 7.89e-04). ETA=19:21:19, max mem: 15.9 GB 
[10/30 22:03:25][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0884,	0.6342 s / batch. (data: 3.27e-04). ETA=18:37:04, max mem: 15.9 GB 
[10/30 22:04:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.1983,	0.6187 s / batch. (data: 2.99e-04). ETA=18:08:41, max mem: 15.9 GB 
[10/30 22:05:31][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6296,	0.6330 s / batch. (data: 8.01e-04). ETA=18:32:48, max mem: 15.9 GB 
[10/30 22:06:34][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.7421,	0.6326 s / batch. (data: 7.75e-04). ETA=18:31:05, max mem: 15.9 GB 
[10/30 22:07:38][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6868,	0.6362 s / batch. (data: 7.23e-04). ETA=18:36:15, max mem: 15.9 GB 
[10/30 22:08:41][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3081,	0.6336 s / batch. (data: 7.96e-04). ETA=18:30:40, max mem: 15.9 GB 
[10/30 22:09:45][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7838,	0.6185 s / batch. (data: 1.44e-04). ETA=18:03:07, max mem: 15.9 GB 
[10/30 22:09:49][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.00e-03, avg batch time: 0.6352, average train loss: 0.8385
[10/30 22:10:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.052, 0.2317 s / batch. (data: 2.93e-05)max mem: 15.94594 GB 
[10/30 22:10:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.2338, average loss: 1.0916
[10/30 22:10:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.83	
[10/30 22:10:49][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.05
[10/30 22:11:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1543,	0.6297 s / batch. (data: 3.27e-04). ETA=18:21:44, max mem: 15.9 GB 
[10/30 22:12:58][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4207,	0.6480 s / batch. (data: 8.03e-04). ETA=18:52:36, max mem: 15.9 GB 
[10/30 22:14:01][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0548,	0.6198 s / batch. (data: 3.20e-04). ETA=18:02:17, max mem: 15.9 GB 
[10/30 22:15:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.8222,	0.6195 s / batch. (data: 3.06e-04). ETA=18:00:39, max mem: 15.9 GB 
[10/30 22:16:07][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6965,	0.6345 s / batch. (data: 3.20e-04). ETA=18:25:45, max mem: 15.9 GB 
[10/30 22:17:11][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.2315,	0.6475 s / batch. (data: 8.32e-04). ETA=18:47:29, max mem: 15.9 GB 
[10/30 22:18:14][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9676,	0.6438 s / batch. (data: 3.21e-04). ETA=18:39:52, max mem: 15.9 GB 
[10/30 22:19:18][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7702,	0.6249 s / batch. (data: 4.60e-03). ETA=18:06:00, max mem: 15.9 GB 
[10/30 22:20:21][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8281,	0.6317 s / batch. (data: 7.28e-04). ETA=18:16:43, max mem: 15.9 GB 
[10/30 22:21:25][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.6296,	0.6306 s / batch. (data: 7.89e-04). ETA=18:13:48, max mem: 15.9 GB 
[10/30 22:22:28][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.1940,	0.6194 s / batch. (data: 1.59e-04). ETA=17:53:14, max mem: 15.9 GB 
[10/30 22:22:32][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.17e-03, avg batch time: 0.6353, average train loss: 0.8784
[10/30 22:23:22][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.901, 0.2337 s / batch. (data: 2.81e-05)max mem: 15.94594 GB 
[10/30 22:23:32][INFO] visual_prompt:  316: Inference (val):avg data time: 4.39e-05, avg batch time: 0.2343, average loss: 0.8299
[10/30 22:23:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.61	
[10/30 22:23:32][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.06
[10/30 22:24:37][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7484,	0.6374 s / batch. (data: 3.50e-04). ETA=18:23:19, max mem: 15.9 GB 
[10/30 22:25:40][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.3123,	0.6315 s / batch. (data: 7.67e-04). ETA=18:12:10, max mem: 15.9 GB 
[10/30 22:26:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1308,	0.6477 s / batch. (data: 8.22e-04). ETA=18:39:04, max mem: 15.9 GB 
[10/30 22:27:47][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0706,	0.6295 s / batch. (data: 3.35e-04). ETA=18:06:36, max mem: 15.9 GB 
[10/30 22:28:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8292,	0.6332 s / batch. (data: 7.95e-04). ETA=18:11:52, max mem: 15.9 GB 
[10/30 22:29:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7807,	0.6191 s / batch. (data: 3.00e-04). ETA=17:46:30, max mem: 15.9 GB 
[10/30 22:30:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6807,	0.6531 s / batch. (data: 8.35e-04). ETA=18:44:03, max mem: 15.9 GB 
[10/30 22:32:01][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2565,	0.6305 s / batch. (data: 1.12e-03). ETA=18:04:08, max mem: 15.9 GB 
[10/30 22:33:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7633,	0.6266 s / batch. (data: 3.20e-04). ETA=17:56:22, max mem: 15.9 GB 
[10/30 22:34:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8348,	0.6195 s / batch. (data: 3.42e-04). ETA=17:43:01, max mem: 15.9 GB 
[10/30 22:35:10][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5043,	0.6182 s / batch. (data: 1.53e-04). ETA=17:39:49, max mem: 15.9 GB 
[10/30 22:35:14][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.19e-03, avg batch time: 0.6348, average train loss: 0.8592
[10/30 22:36:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.745, 0.2255 s / batch. (data: 6.06e-05)max mem: 15.94594 GB 
[10/30 22:36:15][INFO] visual_prompt:  316: Inference (val):avg data time: 1.29e-04, avg batch time: 0.2317, average loss: 0.7024
[10/30 22:36:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.73	
[10/30 22:36:15][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/30 22:37:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6356,	0.6428 s / batch. (data: 2.00e-02). ETA=18:20:56, max mem: 15.9 GB 
[10/30 22:38:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2391,	0.6392 s / batch. (data: 2.81e-04). ETA=18:13:35, max mem: 15.9 GB 
[10/30 22:39:27][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2608,	0.6293 s / batch. (data: 5.43e-03). ETA=17:55:43, max mem: 15.9 GB 
[10/30 22:40:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6617,	0.6190 s / batch. (data: 2.39e-04). ETA=17:37:00, max mem: 15.9 GB 
[10/30 22:41:34][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1442,	0.6312 s / batch. (data: 3.32e-04). ETA=17:56:44, max mem: 15.9 GB 
[10/30 22:42:37][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0520,	0.6287 s / batch. (data: 3.15e-04). ETA=17:51:31, max mem: 15.9 GB 
[10/30 22:43:40][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8254,	0.6306 s / batch. (data: 3.16e-04). ETA=17:53:42, max mem: 15.9 GB 
[10/30 22:44:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8242,	0.6461 s / batch. (data: 1.32e-02). ETA=18:18:59, max mem: 15.9 GB 
[10/30 22:45:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0951,	0.6566 s / batch. (data: 8.10e-04). ETA=18:35:48, max mem: 15.9 GB 
[10/30 22:46:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.6390,	0.6322 s / batch. (data: 3.31e-04). ETA=17:53:11, max mem: 15.9 GB 
[10/30 22:47:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.5727,	0.6182 s / batch. (data: 1.43e-04). ETA=17:28:29, max mem: 15.9 GB 
[10/30 22:47:57][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 3.99e-03, avg batch time: 0.6349, average train loss: 0.9482
[10/30 22:48:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.698, 0.2256 s / batch. (data: 2.53e-05)max mem: 15.94594 GB 
[10/30 22:48:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2322, average loss: 0.6984
[10/30 22:48:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 58.07	
[10/30 22:48:58][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/30 22:50:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7863,	0.6263 s / batch. (data: 2.98e-04). ETA=17:41:06, max mem: 15.9 GB 
[10/30 22:51:07][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.1103,	0.6468 s / batch. (data: 2.79e-02). ETA=18:14:39, max mem: 15.9 GB 
[10/30 22:52:10][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.1674,	0.6332 s / batch. (data: 8.25e-04). ETA=17:50:35, max mem: 15.9 GB 
[10/30 22:53:13][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.5722,	0.6410 s / batch. (data: 7.43e-04). ETA=18:02:47, max mem: 15.9 GB 
[10/30 22:54:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2297,	0.6328 s / batch. (data: 3.29e-04). ETA=17:47:55, max mem: 15.9 GB 
[10/30 22:55:20][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6234,	0.6300 s / batch. (data: 2.71e-04). ETA=17:42:04, max mem: 15.9 GB 
[10/30 22:56:23][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2051,	0.6189 s / batch. (data: 3.30e-04). ETA=17:22:16, max mem: 15.9 GB 
[10/30 22:57:26][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8410,	0.6209 s / batch. (data: 2.77e-04). ETA=17:24:38, max mem: 15.9 GB 
[10/30 22:58:30][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6052,	0.6335 s / batch. (data: 7.41e-04). ETA=17:44:50, max mem: 15.9 GB 
[10/30 22:59:33][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8159,	0.6192 s / batch. (data: 2.80e-04). ETA=17:19:42, max mem: 15.9 GB 
[10/30 23:00:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7697,	0.6175 s / batch. (data: 1.40e-04). ETA=17:15:50, max mem: 15.9 GB 
[10/30 23:00:40][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.35e-03, avg batch time: 0.6344, average train loss: 0.8327
[10/30 23:01:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.811, 0.2257 s / batch. (data: 2.72e-05)max mem: 15.94594 GB 
[10/30 23:01:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.68e-05, avg batch time: 0.2313, average loss: 0.7595
[10/30 23:01:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.28	
[10/30 23:01:40][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/30 23:02:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8311,	0.6303 s / batch. (data: 9.08e-04). ETA=17:36:17, max mem: 15.9 GB 
[10/30 23:03:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.0745,	0.6751 s / batch. (data: 7.89e-04). ETA=18:50:10, max mem: 15.9 GB 
[10/30 23:04:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9716,	0.6389 s / batch. (data: 7.27e-04). ETA=17:48:27, max mem: 15.9 GB 
[10/30 23:05:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9122,	0.6367 s / batch. (data: 7.30e-04). ETA=17:43:47, max mem: 15.9 GB 
[10/30 23:06:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7416,	0.6172 s / batch. (data: 3.22e-04). ETA=17:10:11, max mem: 15.9 GB 
[10/30 23:08:00][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5121,	0.6356 s / batch. (data: 7.69e-04). ETA=17:39:47, max mem: 15.9 GB 
[10/30 23:09:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3996,	0.6340 s / batch. (data: 3.11e-04). ETA=17:36:07, max mem: 15.9 GB 
[10/30 23:10:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6631,	0.6480 s / batch. (data: 7.61e-04). ETA=17:58:21, max mem: 15.9 GB 
[10/30 23:11:10][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5291,	0.6426 s / batch. (data: 1.14e-03). ETA=17:48:14, max mem: 15.9 GB 
[10/30 23:12:13][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4459,	0.6627 s / batch. (data: 5.86e-03). ETA=18:20:36, max mem: 15.9 GB 
[10/30 23:13:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7413,	0.6182 s / batch. (data: 1.43e-04). ETA=17:05:39, max mem: 15.9 GB 
[10/30 23:13:20][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.54e-03, avg batch time: 0.6336, average train loss: 0.9990
[10/30 23:14:10][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.673, 0.2420 s / batch. (data: 4.98e-05)max mem: 15.94594 GB 
[10/30 23:14:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.67e-05, avg batch time: 0.2322, average loss: 0.6849
[10/30 23:14:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 57.48	
[10/30 23:14:20][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.1
[10/30 23:15:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.1390,	0.6351 s / batch. (data: 7.47e-04). ETA=17:32:36, max mem: 15.9 GB 
[10/30 23:16:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8951,	0.6190 s / batch. (data: 3.35e-04). ETA=17:04:49, max mem: 15.9 GB 
[10/30 23:17:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6487,	0.6305 s / batch. (data: 4.39e-04). ETA=17:22:47, max mem: 15.9 GB 
[10/30 23:18:36][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8871,	0.6173 s / batch. (data: 3.42e-04). ETA=16:59:56, max mem: 15.9 GB 
[10/30 23:19:39][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2963,	0.6301 s / batch. (data: 3.08e-04). ETA=17:20:05, max mem: 15.9 GB 
[10/30 23:20:42][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1661,	0.6373 s / batch. (data: 8.90e-04). ETA=17:30:54, max mem: 15.9 GB 
[10/30 23:21:46][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.4732,	0.6191 s / batch. (data: 2.73e-04). ETA=16:59:53, max mem: 15.9 GB 
[10/30 23:22:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7055,	0.6423 s / batch. (data: 7.43e-04). ETA=17:37:03, max mem: 15.9 GB 
[10/30 23:23:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3115,	0.6382 s / batch. (data: 8.13e-04). ETA=17:29:12, max mem: 15.9 GB 
[10/30 23:24:55][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3230,	0.6347 s / batch. (data: 2.97e-04). ETA=17:22:24, max mem: 15.9 GB 
[10/30 23:25:58][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8983,	0.6178 s / batch. (data: 1.41e-04). ETA=16:53:31, max mem: 15.9 GB 
[10/30 23:26:02][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.10e-03, avg batch time: 0.6343, average train loss: 0.8584
[10/30 23:26:52][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.812, 0.2263 s / batch. (data: 2.93e-05)max mem: 15.94594 GB 
[10/30 23:27:02][INFO] visual_prompt:  316: Inference (val):avg data time: 9.73e-05, avg batch time: 0.2327, average loss: 0.7864
[10/30 23:27:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[10/30 23:27:02][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/30 23:28:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.1941,	0.6257 s / batch. (data: 2.89e-04). ETA=17:05:31, max mem: 15.9 GB 
[10/30 23:29:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7910,	0.6188 s / batch. (data: 3.24e-04). ETA=16:53:05, max mem: 15.9 GB 
[10/30 23:30:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1369,	0.6320 s / batch. (data: 3.20e-04). ETA=17:13:38, max mem: 15.9 GB 
[10/30 23:31:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6074,	0.6178 s / batch. (data: 2.93e-04). ETA=16:49:29, max mem: 15.9 GB 
[10/30 23:32:22][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 3.4560,	0.6190 s / batch. (data: 2.52e-04). ETA=16:50:20, max mem: 15.9 GB 
[10/30 23:33:25][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1937,	0.6193 s / batch. (data: 3.05e-04). ETA=16:49:45, max mem: 15.9 GB 
[10/30 23:34:28][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7053,	0.6344 s / batch. (data: 7.41e-04). ETA=17:13:22, max mem: 15.9 GB 
[10/30 23:35:32][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2037,	0.6318 s / batch. (data: 7.66e-04). ETA=17:08:02, max mem: 15.9 GB 
[10/30 23:36:35][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1786,	0.6339 s / batch. (data: 9.53e-04). ETA=17:10:24, max mem: 15.9 GB 
[10/30 23:37:38][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.9686,	0.6174 s / batch. (data: 3.18e-04). ETA=16:42:38, max mem: 15.9 GB 
[10/30 23:38:41][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.1436,	0.6181 s / batch. (data: 1.25e-04). ETA=16:42:38, max mem: 15.9 GB 
[10/30 23:38:45][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 4.98e-03, avg batch time: 0.6352, average train loss: 0.9301
[10/30 23:39:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.863, 0.2250 s / batch. (data: 2.26e-05)max mem: 15.94594 GB 
[10/30 23:39:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.2316, average loss: 2.0481
[10/30 23:39:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.56	
[10/30 23:39:45][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/30 23:40:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.1208,	0.6172 s / batch. (data: 3.12e-04). ETA=16:40:12, max mem: 15.9 GB 
[10/30 23:41:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9931,	0.6179 s / batch. (data: 3.63e-04). ETA=16:40:15, max mem: 15.9 GB 
[10/30 23:42:57][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2030,	0.6302 s / batch. (data: 7.88e-04). ETA=16:59:05, max mem: 15.9 GB 
[10/30 23:44:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.5621,	0.6185 s / batch. (data: 3.12e-04). ETA=16:39:07, max mem: 15.9 GB 
[10/30 23:45:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2974,	0.6396 s / batch. (data: 2.73e-04). ETA=17:12:06, max mem: 15.9 GB 
[10/30 23:46:06][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.0059,	0.6367 s / batch. (data: 7.65e-04). ETA=17:06:26, max mem: 15.9 GB 
[10/30 23:47:09][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0406,	0.6281 s / batch. (data: 7.04e-04). ETA=16:51:33, max mem: 15.9 GB 
[10/30 23:48:12][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.3138,	0.6279 s / batch. (data: 2.80e-04). ETA=16:50:07, max mem: 15.9 GB 
[10/30 23:49:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.4885,	0.6276 s / batch. (data: 3.13e-04). ETA=16:48:37, max mem: 15.9 GB 
[10/30 23:50:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1013,	0.6286 s / batch. (data: 3.16e-04). ETA=16:49:16, max mem: 15.9 GB 
[10/30 23:51:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2977,	0.6183 s / batch. (data: 2.24e-04). ETA=16:31:42, max mem: 15.9 GB 
[10/30 23:51:26][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.73e-03, avg batch time: 0.6339, average train loss: 0.9177
[10/30 23:52:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.654, 0.2280 s / batch. (data: 2.22e-05)max mem: 15.94594 GB 
[10/30 23:52:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.59e-05, avg batch time: 0.2332, average loss: 0.6796
[10/30 23:52:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.53	
[10/30 23:52:26][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.680
[10/30 23:52:26][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/30 23:53:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2182,	0.6462 s / batch. (data: 7.51e-04). ETA=17:15:11, max mem: 15.9 GB 
[10/30 23:54:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1795,	0.6178 s / batch. (data: 3.34e-04). ETA=16:28:43, max mem: 15.9 GB 
[10/30 23:55:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7228,	0.6183 s / batch. (data: 3.48e-04). ETA=16:28:25, max mem: 15.9 GB 
[10/30 23:56:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1471,	0.6335 s / batch. (data: 3.09e-04). ETA=16:51:42, max mem: 15.9 GB 
[10/30 23:57:44][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7264,	0.6333 s / batch. (data: 9.72e-04). ETA=16:50:21, max mem: 15.9 GB 
[10/30 23:58:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5788,	0.6405 s / batch. (data: 8.68e-04). ETA=17:00:45, max mem: 15.9 GB 
[10/30 23:59:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3693,	0.6320 s / batch. (data: 7.88e-04). ETA=16:46:06, max mem: 15.9 GB 
[10/31 00:00:54][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8148,	0.6331 s / batch. (data: 7.81e-04). ETA=16:46:51, max mem: 15.9 GB 
[10/31 00:01:57][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.0012,	0.6311 s / batch. (data: 7.92e-04). ETA=16:42:41, max mem: 15.9 GB 
[10/31 00:03:00][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1823,	0.6360 s / batch. (data: 7.67e-04). ETA=16:49:24, max mem: 15.9 GB 
[10/31 00:04:03][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7471,	0.6180 s / batch. (data: 1.45e-04). ETA=16:19:49, max mem: 15.9 GB 
[10/31 00:04:07][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 3.99e-03, avg batch time: 0.6338, average train loss: 0.8564
[10/31 00:04:56][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.659, 0.2397 s / batch. (data: 2.31e-05)max mem: 15.94594 GB 
[10/31 00:05:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.2327, average loss: 0.7059
[10/31 00:05:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 60.72	
[10/31 00:05:07][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/31 00:06:12][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2887,	0.6381 s / batch. (data: 2.83e-04). ETA=16:50:27, max mem: 15.9 GB 
[10/31 00:07:15][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9216,	0.6231 s / batch. (data: 4.39e-04). ETA=16:25:44, max mem: 15.9 GB 
[10/31 00:08:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9298,	0.6349 s / batch. (data: 9.15e-03). ETA=16:43:22, max mem: 15.9 GB 
[10/31 00:09:22][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.3810,	0.6338 s / batch. (data: 3.12e-04). ETA=16:40:29, max mem: 15.9 GB 
[10/31 00:10:25][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.4307,	0.6684 s / batch. (data: 3.82e-02). ETA=17:34:05, max mem: 15.9 GB 
[10/31 00:11:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.2293,	0.6187 s / batch. (data: 3.09e-04). ETA=16:14:33, max mem: 15.9 GB 
[10/31 00:12:31][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.4398,	0.6293 s / batch. (data: 1.06e-02). ETA=16:30:13, max mem: 15.9 GB 
[10/31 00:13:34][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5383,	0.6400 s / batch. (data: 7.80e-04). ETA=16:46:00, max mem: 15.9 GB 
[10/31 00:14:38][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.4963,	0.6178 s / batch. (data: 3.48e-04). ETA=16:10:07, max mem: 15.9 GB 
[10/31 00:15:41][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8549,	0.6332 s / batch. (data: 7.64e-04). ETA=16:33:16, max mem: 15.9 GB 
[10/31 00:16:44][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.6767,	0.6181 s / batch. (data: 1.50e-04). ETA=16:08:34, max mem: 15.9 GB 
[10/31 00:16:48][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.10e-03, avg batch time: 0.6336, average train loss: 0.9188
[10/31 00:17:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.660, 0.2248 s / batch. (data: 3.03e-05)max mem: 15.94594 GB 
[10/31 00:17:48][INFO] visual_prompt:  316: Inference (val):avg data time: 2.17e-04, avg batch time: 0.2321, average loss: 0.6781
[10/31 00:17:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 60.70	
[10/31 00:17:48][INFO] visual_prompt:   36: Best epoch 15: best metric: -0.678
[10/31 00:17:48][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/31 00:18:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4630,	0.6169 s / batch. (data: 3.16e-04). ETA=16:05:32, max mem: 15.9 GB 
[10/31 00:19:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7618,	0.6606 s / batch. (data: 2.91e-02). ETA=17:12:53, max mem: 15.9 GB 
[10/31 00:21:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3432,	0.6315 s / batch. (data: 7.38e-04). ETA=16:26:18, max mem: 15.9 GB 
[10/31 00:22:03][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8702,	0.6313 s / batch. (data: 8.22e-04). ETA=16:24:53, max mem: 15.9 GB 
[10/31 00:23:06][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8594,	0.6403 s / batch. (data: 3.80e-04). ETA=16:37:54, max mem: 15.9 GB 
[10/31 00:24:09][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.6710,	0.6320 s / batch. (data: 1.15e-03). ETA=16:23:57, max mem: 15.9 GB 
[10/31 00:25:13][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2883,	0.6186 s / batch. (data: 2.80e-04). ETA=16:01:59, max mem: 15.9 GB 
[10/31 00:26:16][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2048,	0.6230 s / batch. (data: 3.63e-04). ETA=16:07:49, max mem: 15.9 GB 
[10/31 00:27:19][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5415,	0.6352 s / batch. (data: 8.14e-04). ETA=16:25:44, max mem: 15.9 GB 
[10/31 00:28:23][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5593,	0.6284 s / batch. (data: 8.10e-04). ETA=16:14:10, max mem: 15.9 GB 
[10/31 00:29:26][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2551,	0.6189 s / batch. (data: 1.46e-04). ETA=15:58:25, max mem: 15.9 GB 
[10/31 00:29:30][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.90e-03, avg batch time: 0.6345, average train loss: 0.8367
[10/31 00:30:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.656, 0.2355 s / batch. (data: 3.10e-05)max mem: 15.94594 GB 
[10/31 00:30:30][INFO] visual_prompt:  316: Inference (val):avg data time: 1.28e-04, avg batch time: 0.2330, average loss: 0.6679
[10/31 00:30:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 61.23	
[10/31 00:30:30][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.668
[10/31 00:30:30][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/31 00:31:35][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.6550,	0.6220 s / batch. (data: 2.88e-04). ETA=16:02:02, max mem: 15.9 GB 
[10/31 00:32:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4927,	0.6302 s / batch. (data: 3.28e-04). ETA=16:13:39, max mem: 15.9 GB 
[10/31 00:33:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0356,	0.6292 s / batch. (data: 1.20e-02). ETA=16:11:09, max mem: 15.9 GB 
[10/31 00:34:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 3.3631,	0.6435 s / batch. (data: 7.56e-04). ETA=16:32:02, max mem: 15.9 GB 
[10/31 00:35:48][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0786,	0.6318 s / batch. (data: 8.41e-04). ETA=16:12:58, max mem: 15.9 GB 
[10/31 00:36:52][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0833,	0.6280 s / batch. (data: 2.63e-04). ETA=16:06:09, max mem: 15.9 GB 
[10/31 00:37:55][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8057,	0.6463 s / batch. (data: 7.66e-04). ETA=16:33:08, max mem: 15.9 GB 
[10/31 00:38:58][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7279,	0.6319 s / batch. (data: 7.80e-04). ETA=16:09:59, max mem: 15.9 GB 
[10/31 00:40:02][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.0594,	0.6439 s / batch. (data: 7.80e-04). ETA=16:27:19, max mem: 15.9 GB 
[10/31 00:41:05][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0369,	0.6310 s / batch. (data: 7.65e-04). ETA=16:06:29, max mem: 15.9 GB 
[10/31 00:42:08][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2138,	0.6186 s / batch. (data: 1.41e-04). ETA=15:46:26, max mem: 15.9 GB 
[10/31 00:42:12][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 3.56e-03, avg batch time: 0.6346, average train loss: 0.8726
[10/31 00:43:02][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.684, 0.2250 s / batch. (data: 2.50e-05)max mem: 15.94594 GB 
[10/31 00:43:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.2330, average loss: 0.6888
[10/31 00:43:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 60.57	
[10/31 00:43:12][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/31 00:44:18][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3419,	0.6318 s / batch. (data: 7.58e-04). ETA=16:05:31, max mem: 15.9 GB 
[10/31 00:45:21][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.3434,	0.6182 s / batch. (data: 3.05e-04). ETA=15:43:48, max mem: 15.9 GB 
[10/31 00:46:24][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.1430,	0.6327 s / batch. (data: 3.29e-04). ETA=16:04:46, max mem: 15.9 GB 
[10/31 00:47:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6366,	0.6396 s / batch. (data: 5.84e-03). ETA=16:14:17, max mem: 15.9 GB 
[10/31 00:48:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2622,	0.6441 s / batch. (data: 1.20e-02). ETA=16:20:01, max mem: 15.9 GB 
[10/31 00:49:34][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.4932,	0.6312 s / batch. (data: 3.86e-04). ETA=15:59:20, max mem: 15.9 GB 
[10/31 00:50:37][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6587,	0.6281 s / batch. (data: 2.10e-04). ETA=15:53:34, max mem: 15.9 GB 
[10/31 00:51:40][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5178,	0.6190 s / batch. (data: 3.24e-04). ETA=15:38:45, max mem: 15.9 GB 
[10/31 00:52:43][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9802,	0.6348 s / batch. (data: 7.13e-04). ETA=16:01:39, max mem: 15.9 GB 
[10/31 00:53:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8745,	0.6425 s / batch. (data: 8.02e-04). ETA=16:12:13, max mem: 15.9 GB 
[10/31 00:54:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7686,	0.6179 s / batch. (data: 2.35e-04). ETA=15:34:03, max mem: 15.9 GB 
[10/31 00:54:53][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.29e-03, avg batch time: 0.6340, average train loss: 0.8586
[10/31 00:55:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.698, 0.2259 s / batch. (data: 2.55e-05)max mem: 15.94594 GB 
[10/31 00:55:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.59e-05, avg batch time: 0.2330, average loss: 0.7412
[10/31 00:55:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 61.07	
[10/31 00:55:53][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/31 00:56:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3924,	0.6302 s / batch. (data: 8.03e-04). ETA=15:51:30, max mem: 15.9 GB 
[10/31 00:58:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9411,	0.6433 s / batch. (data: 7.49e-04). ETA=16:10:14, max mem: 15.9 GB 
[10/31 00:59:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3754,	0.6474 s / batch. (data: 3.06e-04). ETA=16:15:20, max mem: 15.9 GB 
[10/31 01:00:09][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7465,	0.6361 s / batch. (data: 7.47e-04). ETA=15:57:12, max mem: 15.9 GB 
[10/31 01:01:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7220,	0.6179 s / batch. (data: 3.42e-04). ETA=15:28:52, max mem: 15.9 GB 
[10/31 01:02:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0315,	0.6442 s / batch. (data: 7.88e-04). ETA=16:07:20, max mem: 15.9 GB 
[10/31 01:03:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6385,	0.6305 s / batch. (data: 7.93e-04). ETA=15:45:43, max mem: 15.9 GB 
[10/31 01:04:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2465,	0.6363 s / batch. (data: 7.54e-04). ETA=15:53:19, max mem: 15.9 GB 
[10/31 01:05:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3604,	0.6184 s / batch. (data: 3.15e-04). ETA=15:25:26, max mem: 15.9 GB 
[10/31 01:06:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5316,	0.6342 s / batch. (data: 7.19e-04). ETA=15:48:02, max mem: 15.9 GB 
[10/31 01:07:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.1079,	0.6189 s / batch. (data: 1.68e-04). ETA=15:24:10, max mem: 15.9 GB 
[10/31 01:07:36][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.02e-03, avg batch time: 0.6349, average train loss: 0.7975
[10/31 01:08:25][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.330, 0.2319 s / batch. (data: 2.15e-05)max mem: 15.94594 GB 
[10/31 01:08:36][INFO] visual_prompt:  316: Inference (val):avg data time: 1.07e-04, avg batch time: 0.2322, average loss: 1.3301
[10/31 01:08:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.62	
[10/31 01:08:36][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/31 01:09:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7506,	0.6334 s / batch. (data: 7.66e-04). ETA=15:44:37, max mem: 15.9 GB 
[10/31 01:10:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5610,	0.6438 s / batch. (data: 2.52e-02). ETA=15:59:03, max mem: 15.9 GB 
[10/31 01:11:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9327,	0.6458 s / batch. (data: 7.10e-04). ETA=16:01:00, max mem: 15.9 GB 
[10/31 01:12:52][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.5452,	0.6758 s / batch. (data: 3.43e-02). ETA=16:44:34, max mem: 15.9 GB 
[10/31 01:13:55][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.4352,	0.6200 s / batch. (data: 2.70e-04). ETA=15:20:33, max mem: 15.9 GB 
[10/31 01:14:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8925,	0.6202 s / batch. (data: 3.68e-04). ETA=15:19:46, max mem: 15.9 GB 
[10/31 01:16:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3893,	0.6209 s / batch. (data: 3.29e-04). ETA=15:19:46, max mem: 15.9 GB 
[10/31 01:17:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6823,	0.6184 s / batch. (data: 2.80e-04). ETA=15:15:08, max mem: 15.9 GB 
[10/31 01:18:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3693,	0.6234 s / batch. (data: 2.83e-04). ETA=15:21:25, max mem: 15.9 GB 
[10/31 01:19:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4770,	0.6520 s / batch. (data: 7.72e-04). ETA=16:02:37, max mem: 15.9 GB 
[10/31 01:20:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2225,	0.6191 s / batch. (data: 1.42e-04). ETA=15:13:06, max mem: 15.9 GB 
[10/31 01:20:18][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.59e-03, avg batch time: 0.6351, average train loss: 0.8105
[10/31 01:21:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.941, 0.2436 s / batch. (data: 3.03e-05)max mem: 15.94594 GB 
[10/31 01:21:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.2320, average loss: 1.0073
[10/31 01:21:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.16	
[10/31 01:21:18][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/31 01:22:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5460,	0.6470 s / batch. (data: 1.09e-02). ETA=15:53:01, max mem: 15.9 GB 
[10/31 01:23:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1963,	0.6455 s / batch. (data: 5.92e-03). ETA=15:49:45, max mem: 15.9 GB 
[10/31 01:24:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9199,	0.6310 s / batch. (data: 1.41e-02). ETA=15:27:22, max mem: 15.9 GB 
[10/31 01:25:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8157,	0.6329 s / batch. (data: 1.47e-02). ETA=15:29:08, max mem: 15.9 GB 
[10/31 01:26:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.9483,	0.6304 s / batch. (data: 3.21e-04). ETA=15:24:18, max mem: 15.9 GB 
[10/31 01:27:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.6483,	0.6322 s / batch. (data: 9.84e-04). ETA=15:25:56, max mem: 15.9 GB 
[10/31 01:28:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0271,	0.6509 s / batch. (data: 7.84e-04). ETA=15:52:19, max mem: 15.9 GB 
[10/31 01:29:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7841,	0.6380 s / batch. (data: 7.77e-04). ETA=15:32:19, max mem: 15.9 GB 
[10/31 01:30:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0627,	0.6401 s / batch. (data: 3.14e-04). ETA=15:34:21, max mem: 15.9 GB 
[10/31 01:31:53][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6198,	0.6302 s / batch. (data: 3.52e-04). ETA=15:18:49, max mem: 15.9 GB 
[10/31 01:32:56][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8494,	0.6317 s / batch. (data: 1.24e-02). ETA=15:19:53, max mem: 15.9 GB 
[10/31 01:33:00][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.46e-03, avg batch time: 0.6339, average train loss: 0.8008
[10/31 01:33:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.628, 0.2260 s / batch. (data: 3.98e-05)max mem: 15.94594 GB 
[10/31 01:34:04][INFO] visual_prompt:  316: Inference (val):avg data time: 4.04e-05, avg batch time: 0.2307, average loss: 0.6814
[10/31 01:34:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 62.86	
[10/31 01:34:04][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/31 01:35:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.9987,	0.6246 s / batch. (data: 3.24e-04). ETA=15:08:29, max mem: 15.9 GB 
[10/31 01:36:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5625,	0.6362 s / batch. (data: 8.06e-04). ETA=15:24:16, max mem: 15.9 GB 
[10/31 01:37:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8499,	0.6388 s / batch. (data: 5.92e-03). ETA=15:27:03, max mem: 15.9 GB 
[10/31 01:38:20][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3374,	0.6317 s / batch. (data: 7.97e-04). ETA=15:15:43, max mem: 15.9 GB 
[10/31 01:39:23][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2161,	0.6314 s / batch. (data: 8.75e-04). ETA=15:14:10, max mem: 15.9 GB 
[10/31 01:40:27][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1487,	0.6192 s / batch. (data: 3.22e-04). ETA=14:55:30, max mem: 15.9 GB 
[10/31 01:41:30][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0199,	0.6207 s / batch. (data: 1.07e-03). ETA=14:56:40, max mem: 15.9 GB 
[10/31 01:42:33][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8568,	0.6332 s / batch. (data: 8.00e-04). ETA=15:13:42, max mem: 15.9 GB 
[10/31 01:43:37][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9090,	0.6206 s / batch. (data: 3.50e-04). ETA=14:54:29, max mem: 15.9 GB 
[10/31 01:44:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.9826,	0.6239 s / batch. (data: 8.09e-04). ETA=14:58:09, max mem: 15.9 GB 
[10/31 01:45:44][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8829,	0.6183 s / batch. (data: 2.13e-04). ETA=14:48:59, max mem: 15.9 GB 
[10/31 01:45:47][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 5.58e-03, avg batch time: 0.6356, average train loss: 0.7715
[10/31 01:46:40][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.677, 0.2263 s / batch. (data: 3.00e-05)max mem: 15.94594 GB 
[10/31 01:46:52][INFO] visual_prompt:  316: Inference (val):avg data time: 1.11e-04, avg batch time: 0.2314, average loss: 0.7511
[10/31 01:46:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 61.51	
[10/31 01:46:52][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/31 01:47:58][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2235,	0.6377 s / batch. (data: 2.96e-04). ETA=15:15:48, max mem: 15.9 GB 
[10/31 01:49:01][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9333,	0.6255 s / batch. (data: 3.20e-04). ETA=14:57:17, max mem: 15.9 GB 
[10/31 01:50:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5403,	0.6326 s / batch. (data: 1.34e-02). ETA=15:06:27, max mem: 15.9 GB 
[10/31 01:51:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8287,	0.6310 s / batch. (data: 8.22e-04). ETA=15:02:59, max mem: 15.9 GB 
[10/31 01:52:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7827,	0.6482 s / batch. (data: 3.42e-04). ETA=15:26:37, max mem: 15.9 GB 
[10/31 01:53:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8098,	0.6285 s / batch. (data: 3.31e-04). ETA=14:57:25, max mem: 15.9 GB 
[10/31 01:54:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5954,	0.6189 s / batch. (data: 3.33e-04). ETA=14:42:37, max mem: 15.9 GB 
[10/31 01:55:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9031,	0.6329 s / batch. (data: 7.22e-04). ETA=15:01:36, max mem: 15.9 GB 
[10/31 01:56:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7329,	0.6326 s / batch. (data: 6.56e-04). ETA=15:00:00, max mem: 15.9 GB 
[10/31 01:57:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4097,	0.6346 s / batch. (data: 8.25e-04). ETA=15:01:51, max mem: 15.9 GB 
[10/31 01:58:31][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5810,	0.6180 s / batch. (data: 1.17e-04). ETA=14:37:15, max mem: 15.9 GB 
[10/31 01:58:35][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 5.57e-03, avg batch time: 0.6360, average train loss: 0.7852
[10/31 01:59:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.734, 0.2258 s / batch. (data: 3.98e-05)max mem: 15.94594 GB 
[10/31 01:59:38][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-05, avg batch time: 0.2328, average loss: 0.6939
[10/31 01:59:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 61.50	
[10/31 01:59:38][INFO] visual_prompt:   42: Stopping early.
