[10/30 15:10:58][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/30 15:10:58][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/30 15:10:58][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/30 15:10:58][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/30 15:10:58][INFO] visual_prompt:  108: Training with config:
[10/30 15:10:58][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/30 15:10:58][INFO] visual_prompt:   55: Loading training data...
[10/30 15:10:58][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/30 15:10:58][INFO] visual_prompt:   57: Loading validation data...
[10/30 15:10:58][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/30 15:10:58][INFO] visual_prompt:   38: Constructing models...
[10/30 15:11:01][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/30 15:11:01][INFO] visual_prompt:   54: tuned percent:0.522
[10/30 15:11:01][INFO] visual_prompt:   40: Device used for model: 0
[10/30 15:11:01][INFO] visual_prompt:   40: Setting up Evaluator...
[10/30 15:11:01][INFO] visual_prompt:   42: Setting up Trainer...
[10/30 15:11:01][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/30 15:11:01][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/30 15:12:07][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6330 s / batch. (data: 1.47e-02). ETA=19:25:48, max mem: 15.9 GB 
[10/30 15:13:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6464 s / batch. (data: 8.61e-04). ETA=19:49:25, max mem: 15.9 GB 
[10/30 15:14:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6335 s / batch. (data: 3.19e-04). ETA=19:24:32, max mem: 15.9 GB 
[10/30 15:15:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6203 s / batch. (data: 3.14e-04). ETA=18:59:15, max mem: 15.9 GB 
[10/30 15:16:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6504 s / batch. (data: 5.43e-03). ETA=19:53:24, max mem: 15.9 GB 
[10/30 15:17:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6309 s / batch. (data: 8.08e-04). ETA=19:16:37, max mem: 15.9 GB 
[10/30 15:18:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6312 s / batch. (data: 7.84e-04). ETA=19:16:09, max mem: 15.9 GB 
[10/30 15:19:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6254 s / batch. (data: 5.45e-03). ETA=19:04:28, max mem: 15.9 GB 
[10/30 15:20:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6436 s / batch. (data: 7.72e-04). ETA=19:36:43, max mem: 15.9 GB 
[10/30 15:21:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6303 s / batch. (data: 3.32e-04). ETA=19:11:22, max mem: 15.9 GB 
[10/30 15:22:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6187 s / batch. (data: 1.46e-04). ETA=18:49:04, max mem: 15.9 GB 
[10/30 15:22:44][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.88e-03, avg batch time: 0.6354, average train loss: 1.4028
[10/30 15:23:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2489 s / batch. (data: 3.70e-05)max mem: 15.94594 GB 
[10/30 15:23:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2331, average loss: 1.3505
[10/30 15:23:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/30 15:23:45][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/30 15:24:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6856,	0.6307 s / batch. (data: 3.03e-04). ETA=19:09:55, max mem: 15.9 GB 
[10/30 15:25:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6748,	0.6307 s / batch. (data: 3.91e-04). ETA=19:08:55, max mem: 15.9 GB 
[10/30 15:26:57][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9994,	0.6329 s / batch. (data: 5.44e-03). ETA=19:11:48, max mem: 15.9 GB 
[10/30 15:28:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1167,	0.6192 s / batch. (data: 3.20e-04). ETA=18:45:55, max mem: 15.9 GB 
[10/30 15:29:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6836,	0.6185 s / batch. (data: 3.31e-04). ETA=18:43:35, max mem: 15.9 GB 
[10/30 15:30:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5571,	0.6342 s / batch. (data: 8.30e-04). ETA=19:11:05, max mem: 15.9 GB 
[10/30 15:31:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9479,	0.6241 s / batch. (data: 3.28e-04). ETA=18:51:42, max mem: 15.9 GB 
[10/30 15:32:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7632,	0.6487 s / batch. (data: 5.94e-03). ETA=19:35:06, max mem: 15.9 GB 
[10/30 15:33:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6069,	0.6243 s / batch. (data: 3.08e-04). ETA=18:49:54, max mem: 15.9 GB 
[10/30 15:34:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5743,	0.6179 s / batch. (data: 2.84e-04). ETA=18:37:23, max mem: 15.9 GB 
[10/30 15:35:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6026,	0.6188 s / batch. (data: 1.49e-04). ETA=18:37:54, max mem: 15.9 GB 
[10/30 15:35:26][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.02e-03, avg batch time: 0.6339, average train loss: 0.7981
[10/30 15:36:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.128, 0.2399 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/30 15:36:27][INFO] visual_prompt:  316: Inference (val):avg data time: 4.03e-05, avg batch time: 0.2334, average loss: 1.0368
[10/30 15:36:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.75	
[10/30 15:36:27][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/30 15:37:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7159,	0.6167 s / batch. (data: 3.33e-04). ETA=18:32:59, max mem: 15.9 GB 
[10/30 15:38:36][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.2301,	0.6178 s / batch. (data: 8.08e-04). ETA=18:33:56, max mem: 15.9 GB 
[10/30 15:39:40][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4013,	0.6207 s / batch. (data: 3.55e-04). ETA=18:38:04, max mem: 15.9 GB 
[10/30 15:40:43][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8445,	0.6396 s / batch. (data: 8.02e-04). ETA=19:11:12, max mem: 15.9 GB 
[10/30 15:41:47][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.0925,	0.6336 s / batch. (data: 1.06e-03). ETA=18:59:18, max mem: 15.9 GB 
[10/30 15:42:50][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6772,	0.6196 s / batch. (data: 3.30e-04). ETA=18:33:09, max mem: 15.9 GB 
[10/30 15:43:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0648,	0.6423 s / batch. (data: 8.13e-04). ETA=19:12:44, max mem: 15.9 GB 
[10/30 15:44:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.8124,	0.6476 s / batch. (data: 8.01e-04). ETA=19:21:12, max mem: 15.9 GB 
[10/30 15:46:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.4019,	0.6328 s / batch. (data: 1.05e-02). ETA=18:53:41, max mem: 15.9 GB 
[10/30 15:47:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6594,	0.6295 s / batch. (data: 7.23e-04). ETA=18:46:44, max mem: 15.9 GB 
[10/30 15:48:06][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5393,	0.6182 s / batch. (data: 1.43e-04). ETA=18:25:29, max mem: 15.9 GB 
[10/30 15:48:10][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 4.96e-03, avg batch time: 0.6355, average train loss: 0.7993
[10/30 15:49:00][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.833, 0.2372 s / batch. (data: 5.60e-05)max mem: 15.94594 GB 
[10/30 15:49:11][INFO] visual_prompt:  316: Inference (val):avg data time: 4.46e-05, avg batch time: 0.2324, average loss: 0.8317
[10/30 15:49:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.59	
[10/30 15:49:11][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.03
[10/30 15:50:16][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1998,	0.6212 s / batch. (data: 7.85e-04). ETA=18:29:41, max mem: 15.9 GB 
[10/30 15:51:19][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1017,	0.6357 s / batch. (data: 5.45e-03). ETA=18:54:29, max mem: 15.9 GB 
[10/30 15:52:22][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9857,	0.6183 s / batch. (data: 3.35e-04). ETA=18:22:23, max mem: 15.9 GB 
[10/30 15:53:26][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7679,	0.6491 s / batch. (data: 8.17e-04). ETA=19:16:21, max mem: 15.9 GB 
[10/30 15:54:29][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.8117,	0.6229 s / batch. (data: 3.38e-04). ETA=18:28:38, max mem: 15.9 GB 
[10/30 15:55:32][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2116,	0.6400 s / batch. (data: 8.16e-04). ETA=18:57:55, max mem: 15.9 GB 
[10/30 15:56:36][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3647,	0.6200 s / batch. (data: 8.67e-04). ETA=18:21:22, max mem: 15.9 GB 
[10/30 15:57:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0443,	0.6442 s / batch. (data: 8.21e-04). ETA=19:03:19, max mem: 15.9 GB 
[10/30 15:58:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1425,	0.6439 s / batch. (data: 3.45e-04). ETA=19:01:38, max mem: 15.9 GB 
[10/30 15:59:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6139,	0.6296 s / batch. (data: 1.20e-02). ETA=18:35:19, max mem: 15.9 GB 
[10/30 16:00:49][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0688,	0.6187 s / batch. (data: 1.22e-04). ETA=18:14:51, max mem: 15.9 GB 
[10/30 16:00:53][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.34e-03, avg batch time: 0.6345, average train loss: 0.8215
[10/30 16:01:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.118, 0.2286 s / batch. (data: 3.70e-05)max mem: 15.94594 GB 
[10/30 16:01:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2321, average loss: 1.0080
[10/30 16:01:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.96	
[10/30 16:01:53][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/30 16:02:58][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0794,	0.6319 s / batch. (data: 8.18e-04). ETA=18:37:04, max mem: 15.9 GB 
[10/30 16:04:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.5603,	0.6560 s / batch. (data: 1.20e-02). ETA=19:18:38, max mem: 15.9 GB 
[10/30 16:05:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7757,	0.6190 s / batch. (data: 3.33e-04). ETA=18:12:14, max mem: 15.9 GB 
[10/30 16:06:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1135,	0.6335 s / batch. (data: 2.96e-04). ETA=18:36:44, max mem: 15.9 GB 
[10/30 16:07:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0871,	0.6346 s / batch. (data: 8.00e-04). ETA=18:37:43, max mem: 15.9 GB 
[10/30 16:08:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.1797,	0.6318 s / batch. (data: 8.19e-04). ETA=18:31:39, max mem: 15.9 GB 
[10/30 16:09:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6263,	0.6239 s / batch. (data: 3.43e-04). ETA=18:16:51, max mem: 15.9 GB 
[10/30 16:10:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.7336,	0.6180 s / batch. (data: 2.83e-04). ETA=18:05:24, max mem: 15.9 GB 
[10/30 16:11:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7050,	0.6187 s / batch. (data: 3.12e-04). ETA=18:05:30, max mem: 15.9 GB 
[10/30 16:12:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3110,	0.6215 s / batch. (data: 2.84e-04). ETA=18:09:23, max mem: 15.9 GB 
[10/30 16:13:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7715,	0.6178 s / batch. (data: 1.81e-04). ETA=18:01:52, max mem: 15.9 GB 
[10/30 16:13:35][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.31e-03, avg batch time: 0.6348, average train loss: 0.8295
[10/30 16:14:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.026, 0.2438 s / batch. (data: 3.05e-05)max mem: 15.94594 GB 
[10/30 16:14:36][INFO] visual_prompt:  316: Inference (val):avg data time: 4.00e-05, avg batch time: 0.2319, average loss: 1.0640
[10/30 16:14:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.63	
[10/30 16:14:36][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.05
[10/30 16:15:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1580,	0.6332 s / batch. (data: 8.24e-04). ETA=18:27:44, max mem: 15.9 GB 
[10/30 16:16:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4128,	0.6196 s / batch. (data: 3.35e-04). ETA=18:03:00, max mem: 15.9 GB 
[10/30 16:17:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0651,	0.6196 s / batch. (data: 3.17e-04). ETA=18:01:59, max mem: 15.9 GB 
[10/30 16:18:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.7235,	0.6294 s / batch. (data: 1.05e-02). ETA=18:17:56, max mem: 15.9 GB 
[10/30 16:19:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6799,	0.6487 s / batch. (data: 7.42e-04). ETA=18:50:32, max mem: 15.9 GB 
[10/30 16:20:57][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.2148,	0.6440 s / batch. (data: 3.33e-04). ETA=18:41:20, max mem: 15.9 GB 
[10/30 16:22:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9815,	0.6560 s / batch. (data: 8.38e-04). ETA=19:01:05, max mem: 15.9 GB 
[10/30 16:23:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7753,	0.6340 s / batch. (data: 7.90e-04). ETA=18:21:42, max mem: 15.9 GB 
[10/30 16:24:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8058,	0.6433 s / batch. (data: 7.92e-04). ETA=18:36:53, max mem: 15.9 GB 
[10/30 16:25:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.6943,	0.6370 s / batch. (data: 8.81e-04). ETA=18:24:57, max mem: 15.9 GB 
[10/30 16:26:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2127,	0.6180 s / batch. (data: 1.59e-04). ETA=17:50:49, max mem: 15.9 GB 
[10/30 16:26:18][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 3.96e-03, avg batch time: 0.6346, average train loss: 0.8718
[10/30 16:27:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.884, 0.2406 s / batch. (data: 4.32e-05)max mem: 15.94594 GB 
[10/30 16:27:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.98e-05, avg batch time: 0.2328, average loss: 0.8242
[10/30 16:27:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[10/30 16:27:19][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.06
[10/30 16:28:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7203,	0.6403 s / batch. (data: 8.26e-04). ETA=18:28:26, max mem: 15.9 GB 
[10/30 16:29:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.4923,	0.6193 s / batch. (data: 3.32e-04). ETA=17:51:00, max mem: 15.9 GB 
[10/30 16:30:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1635,	0.6403 s / batch. (data: 7.83e-04). ETA=18:26:20, max mem: 15.9 GB 
[10/30 16:31:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0979,	0.6300 s / batch. (data: 8.20e-04). ETA=18:07:25, max mem: 15.9 GB 
[10/30 16:32:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7623,	0.6281 s / batch. (data: 2.88e-04). ETA=18:03:02, max mem: 15.9 GB 
[10/30 16:33:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7588,	0.6469 s / batch. (data: 8.30e-04). ETA=18:34:29, max mem: 15.9 GB 
[10/30 16:34:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6283,	0.6253 s / batch. (data: 3.42e-04). ETA=17:56:12, max mem: 15.9 GB 
[10/30 16:35:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2804,	0.6192 s / batch. (data: 3.22e-04). ETA=17:44:42, max mem: 15.9 GB 
[10/30 16:36:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7579,	0.6202 s / batch. (data: 3.00e-04). ETA=17:45:25, max mem: 15.9 GB 
[10/30 16:37:53][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8351,	0.6397 s / batch. (data: 7.75e-04). ETA=18:17:44, max mem: 15.9 GB 
[10/30 16:38:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4420,	0.6169 s / batch. (data: 1.44e-04). ETA=17:37:40, max mem: 15.9 GB 
[10/30 16:39:01][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 3.95e-03, avg batch time: 0.6345, average train loss: 0.8544
[10/30 16:39:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.735, 0.2265 s / batch. (data: 5.96e-05)max mem: 15.94594 GB 
[10/30 16:40:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-05, avg batch time: 0.2321, average loss: 0.6939
[10/30 16:40:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.67	
[10/30 16:40:01][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/30 16:41:07][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7106,	0.6185 s / batch. (data: 2.94e-04). ETA=17:39:18, max mem: 15.9 GB 
[10/30 16:42:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2271,	0.6218 s / batch. (data: 3.09e-04). ETA=17:43:51, max mem: 15.9 GB 
[10/30 16:43:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2416,	0.6592 s / batch. (data: 2.32e-02). ETA=18:46:46, max mem: 15.9 GB 
[10/30 16:44:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6685,	0.6185 s / batch. (data: 3.33e-04). ETA=17:36:06, max mem: 15.9 GB 
[10/30 16:45:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1585,	0.6194 s / batch. (data: 3.16e-04). ETA=17:36:44, max mem: 15.9 GB 
[10/30 16:46:23][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0946,	0.6530 s / batch. (data: 7.93e-04). ETA=18:32:58, max mem: 15.9 GB 
[10/30 16:47:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7978,	0.6452 s / batch. (data: 7.47e-04). ETA=18:18:28, max mem: 15.9 GB 
[10/30 16:48:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8930,	0.6188 s / batch. (data: 3.32e-04). ETA=17:32:35, max mem: 15.9 GB 
[10/30 16:49:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1122,	0.6184 s / batch. (data: 3.09e-04). ETA=17:30:47, max mem: 15.9 GB 
[10/30 16:50:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.5286,	0.6417 s / batch. (data: 7.72e-04). ETA=18:09:26, max mem: 15.9 GB 
[10/30 16:51:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4003,	0.6191 s / batch. (data: 1.61e-04). ETA=17:29:55, max mem: 15.9 GB 
[10/30 16:51:44][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.09e-03, avg batch time: 0.6351, average train loss: 0.9376
[10/30 16:52:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.703, 0.2333 s / batch. (data: 4.96e-05)max mem: 15.94594 GB 
[10/30 16:52:45][INFO] visual_prompt:  316: Inference (val):avg data time: 1.24e-04, avg batch time: 0.2315, average loss: 0.6944
[10/30 16:52:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 55.46	
[10/30 16:52:45][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/30 16:53:51][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.9524,	0.6404 s / batch. (data: 8.22e-04). ETA=18:05:00, max mem: 15.9 GB 
[10/30 16:54:54][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.1179,	0.6351 s / batch. (data: 1.51e-02). ETA=17:54:53, max mem: 15.9 GB 
[10/30 16:55:57][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0534,	0.6343 s / batch. (data: 8.21e-04). ETA=17:52:27, max mem: 15.9 GB 
[10/30 16:57:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6591,	0.6332 s / batch. (data: 7.72e-04). ETA=17:49:35, max mem: 15.9 GB 
[10/30 16:58:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.1580,	0.6320 s / batch. (data: 3.09e-04). ETA=17:46:31, max mem: 15.9 GB 
[10/30 16:59:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6707,	0.6196 s / batch. (data: 3.06e-04). ETA=17:24:35, max mem: 15.9 GB 
[10/30 17:00:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1361,	0.6234 s / batch. (data: 3.16e-04). ETA=17:29:53, max mem: 15.9 GB 
[10/30 17:01:14][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8133,	0.6205 s / batch. (data: 3.18e-04). ETA=17:24:00, max mem: 15.9 GB 
[10/30 17:02:17][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6352,	0.6425 s / batch. (data: 7.71e-04). ETA=18:00:02, max mem: 15.9 GB 
[10/30 17:03:21][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.0038,	0.6185 s / batch. (data: 3.06e-04). ETA=17:18:30, max mem: 15.9 GB 
[10/30 17:04:24][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7678,	0.6192 s / batch. (data: 1.37e-04). ETA=17:18:47, max mem: 15.9 GB 
[10/30 17:04:28][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 5.00e-03, avg batch time: 0.6356, average train loss: 0.8291
[10/30 17:05:18][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.770, 0.2388 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/30 17:05:29][INFO] visual_prompt:  316: Inference (val):avg data time: 3.80e-05, avg batch time: 0.2330, average loss: 0.7072
[10/30 17:05:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.09	
[10/30 17:05:29][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/30 17:06:34][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7673,	0.6188 s / batch. (data: 3.54e-04). ETA=17:16:54, max mem: 15.9 GB 
[10/30 17:07:37][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.8319,	0.6275 s / batch. (data: 3.19e-04). ETA=17:30:24, max mem: 15.9 GB 
[10/30 17:08:41][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9251,	0.6303 s / batch. (data: 7.90e-04). ETA=17:34:12, max mem: 15.9 GB 
[10/30 17:09:44][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1329,	0.6402 s / batch. (data: 3.09e-04). ETA=17:49:33, max mem: 15.9 GB 
[10/30 17:10:47][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7253,	0.6569 s / batch. (data: 3.87e-02). ETA=18:16:25, max mem: 15.9 GB 
[10/30 17:11:50][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.4371,	0.6476 s / batch. (data: 3.36e-04). ETA=17:59:53, max mem: 15.9 GB 
[10/30 17:12:54][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5905,	0.6452 s / batch. (data: 1.02e-03). ETA=17:54:42, max mem: 15.9 GB 
[10/30 17:13:57][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7004,	0.6197 s / batch. (data: 3.02e-04). ETA=17:11:11, max mem: 15.9 GB 
[10/30 17:15:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.0629,	0.6310 s / batch. (data: 1.20e-02). ETA=17:29:02, max mem: 15.9 GB 
[10/30 17:16:04][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4201,	0.6289 s / batch. (data: 5.45e-03). ETA=17:24:31, max mem: 15.9 GB 
[10/30 17:17:07][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7833,	0.6176 s / batch. (data: 1.64e-04). ETA=17:04:37, max mem: 15.9 GB 
[10/30 17:17:11][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.21e-03, avg batch time: 0.6350, average train loss: 0.9725
[10/30 17:18:01][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.706, 0.2296 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/30 17:18:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2325, average loss: 0.6861
[10/30 17:18:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.40	
[10/30 17:18:12][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.1
[10/30 17:19:17][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.5751,	0.6411 s / batch. (data: 8.13e-04). ETA=17:42:27, max mem: 15.9 GB 
[10/30 17:20:21][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7790,	0.6527 s / batch. (data: 1.49e-02). ETA=18:00:42, max mem: 15.9 GB 
[10/30 17:21:24][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6649,	0.6334 s / batch. (data: 1.23e-03). ETA=17:27:35, max mem: 15.9 GB 
[10/30 17:22:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0431,	0.6289 s / batch. (data: 8.01e-04). ETA=17:19:11, max mem: 15.9 GB 
[10/30 17:23:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3804,	0.6178 s / batch. (data: 2.81e-04). ETA=16:59:48, max mem: 15.9 GB 
[10/30 17:24:34][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1545,	0.6188 s / batch. (data: 3.10e-04). ETA=17:00:22, max mem: 15.9 GB 
[10/30 17:25:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5047,	0.6340 s / batch. (data: 7.32e-04). ETA=17:24:21, max mem: 15.9 GB 
[10/30 17:26:41][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7700,	0.6327 s / batch. (data: 2.95e-04). ETA=17:21:16, max mem: 15.9 GB 
[10/30 17:27:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3289,	0.6301 s / batch. (data: 8.12e-04). ETA=17:15:50, max mem: 15.9 GB 
[10/30 17:28:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3277,	0.6250 s / batch. (data: 7.73e-04). ETA=17:06:28, max mem: 15.9 GB 
[10/30 17:29:51][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0478,	0.6180 s / batch. (data: 1.97e-04). ETA=16:53:53, max mem: 15.9 GB 
[10/30 17:29:54][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 5.07e-03, avg batch time: 0.6352, average train loss: 0.8418
[10/30 17:30:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.918, 0.2449 s / batch. (data: 2.86e-05)max mem: 15.94594 GB 
[10/30 17:30:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2324, average loss: 0.8205
[10/30 17:30:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.83	
[10/30 17:30:55][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/30 17:32:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.1816,	0.6198 s / batch. (data: 3.49e-04). ETA=16:55:43, max mem: 15.9 GB 
[10/30 17:33:05][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7611,	0.6332 s / batch. (data: 7.93e-04). ETA=17:16:43, max mem: 15.9 GB 
[10/30 17:34:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1759,	0.6291 s / batch. (data: 3.22e-04). ETA=17:08:56, max mem: 15.9 GB 
[10/30 17:35:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.4384,	0.6592 s / batch. (data: 1.61e-02). ETA=17:57:00, max mem: 15.9 GB 
[10/30 17:36:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.8987,	0.6348 s / batch. (data: 7.72e-04). ETA=17:16:06, max mem: 15.9 GB 
[10/30 17:37:19][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8857,	0.6304 s / batch. (data: 3.12e-04). ETA=17:07:58, max mem: 15.9 GB 
[10/30 17:38:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7385,	0.6523 s / batch. (data: 7.50e-04). ETA=17:42:32, max mem: 15.9 GB 
[10/30 17:39:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9474,	0.6310 s / batch. (data: 7.10e-04). ETA=17:06:44, max mem: 15.9 GB 
[10/30 17:40:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1523,	0.6192 s / batch. (data: 3.00e-04). ETA=16:46:36, max mem: 15.9 GB 
[10/30 17:41:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.1044,	0.6360 s / batch. (data: 8.14e-04). ETA=17:12:48, max mem: 15.9 GB 
[10/30 17:42:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8794,	0.6179 s / batch. (data: 1.66e-04). ETA=16:42:17, max mem: 15.9 GB 
[10/30 17:42:39][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.38e-03, avg batch time: 0.6359, average train loss: 0.8861
[10/30 17:43:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.605, 0.2257 s / batch. (data: 3.93e-05)max mem: 15.94594 GB 
[10/30 17:43:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2318, average loss: 1.7767
[10/30 17:43:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.75	
[10/30 17:43:40][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/30 17:44:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.9748,	0.6181 s / batch. (data: 3.34e-04). ETA=16:41:37, max mem: 15.9 GB 
[10/30 17:45:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6739,	0.6493 s / batch. (data: 1.04e-03). ETA=17:31:02, max mem: 15.9 GB 
[10/30 17:46:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2771,	0.6318 s / batch. (data: 7.51e-04). ETA=17:01:38, max mem: 15.9 GB 
[10/30 17:47:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7545,	0.6336 s / batch. (data: 9.09e-04). ETA=17:03:32, max mem: 15.9 GB 
[10/30 17:48:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2363,	0.6194 s / batch. (data: 2.78e-04). ETA=16:39:36, max mem: 15.9 GB 
[10/30 17:50:02][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.4227,	0.6390 s / batch. (data: 7.60e-04). ETA=17:10:13, max mem: 15.9 GB 
[10/30 17:51:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9133,	0.6589 s / batch. (data: 3.89e-02). ETA=17:41:10, max mem: 15.9 GB 
[10/30 17:52:09][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.5273,	0.6409 s / batch. (data: 8.34e-04). ETA=17:11:03, max mem: 15.9 GB 
[10/30 17:53:12][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1645,	0.6594 s / batch. (data: 4.03e-02). ETA=17:39:42, max mem: 15.9 GB 
[10/30 17:54:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.2312,	0.6281 s / batch. (data: 3.39e-04). ETA=16:48:24, max mem: 15.9 GB 
[10/30 17:55:19][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8662,	0.6186 s / batch. (data: 1.92e-04). ETA=16:32:08, max mem: 15.9 GB 
[10/30 17:55:23][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.62e-03, avg batch time: 0.6358, average train loss: 0.8365
[10/30 17:56:13][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.894, 0.2433 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/30 17:56:24][INFO] visual_prompt:  316: Inference (val):avg data time: 4.33e-05, avg batch time: 0.2322, average loss: 0.8242
[10/30 17:56:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.93	
[10/30 17:56:24][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/30 17:57:30][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4071,	0.6397 s / batch. (data: 8.21e-04). ETA=17:04:51, max mem: 15.9 GB 
[10/30 17:58:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9544,	0.6208 s / batch. (data: 3.34e-04). ETA=16:33:27, max mem: 15.9 GB 
[10/30 17:59:37][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7229,	0.6651 s / batch. (data: 8.30e-04). ETA=17:43:18, max mem: 15.9 GB 
[10/30 18:00:40][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1318,	0.6359 s / batch. (data: 7.78e-04). ETA=16:55:29, max mem: 15.9 GB 
[10/30 18:01:44][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7287,	0.6328 s / batch. (data: 8.16e-04). ETA=16:49:33, max mem: 15.9 GB 
[10/30 18:02:47][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6469,	0.6378 s / batch. (data: 3.17e-04). ETA=16:56:31, max mem: 15.9 GB 
[10/30 18:03:50][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3386,	0.6682 s / batch. (data: 2.44e-02). ETA=17:43:52, max mem: 15.9 GB 
[10/30 18:04:54][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7370,	0.6190 s / batch. (data: 3.43e-04). ETA=16:24:25, max mem: 15.9 GB 
[10/30 18:05:57][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8077,	0.6346 s / batch. (data: 1.64e-02). ETA=16:48:13, max mem: 15.9 GB 
[10/30 18:07:00][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1705,	0.6325 s / batch. (data: 2.99e-04). ETA=16:43:47, max mem: 15.9 GB 
[10/30 18:08:03][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8356,	0.6183 s / batch. (data: 1.74e-04). ETA=16:20:17, max mem: 15.9 GB 
[10/30 18:08:07][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 5.41e-03, avg batch time: 0.6360, average train loss: 0.8366
[10/30 18:08:57][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.661, 0.2249 s / batch. (data: 4.41e-05)max mem: 15.94594 GB 
[10/30 18:09:08][INFO] visual_prompt:  316: Inference (val):avg data time: 1.31e-04, avg batch time: 0.2330, average loss: 0.6725
[10/30 18:09:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.60	
[10/30 18:09:08][INFO] visual_prompt:   36: Best epoch 14: best metric: -0.673
[10/30 18:09:08][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/30 18:10:13][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1108,	0.6318 s / batch. (data: 3.10e-04). ETA=16:40:33, max mem: 15.9 GB 
[10/30 18:11:17][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9046,	0.6303 s / batch. (data: 6.98e-04). ETA=16:37:07, max mem: 15.9 GB 
[10/30 18:12:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7211,	0.6187 s / batch. (data: 3.08e-04). ETA=16:17:42, max mem: 15.9 GB 
[10/30 18:13:23][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2004,	0.6183 s / batch. (data: 3.25e-04). ETA=16:16:04, max mem: 15.9 GB 
[10/30 18:14:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2119,	0.6441 s / batch. (data: 8.08e-04). ETA=16:55:38, max mem: 15.9 GB 
[10/30 18:15:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0562,	0.6302 s / batch. (data: 3.21e-04). ETA=16:32:48, max mem: 15.9 GB 
[10/30 18:16:34][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.4559,	0.6271 s / batch. (data: 7.46e-04). ETA=16:26:51, max mem: 15.9 GB 
[10/30 18:17:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5685,	0.6360 s / batch. (data: 4.52e-04). ETA=16:39:44, max mem: 15.9 GB 
[10/30 18:18:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8647,	0.6435 s / batch. (data: 5.48e-03). ETA=16:50:31, max mem: 15.9 GB 
[10/30 18:19:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6817,	0.6189 s / batch. (data: 3.22e-04). ETA=16:10:45, max mem: 15.9 GB 
[10/30 18:20:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2066,	0.6190 s / batch. (data: 1.54e-04). ETA=16:09:58, max mem: 15.9 GB 
[10/30 18:20:51][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.29e-03, avg batch time: 0.6349, average train loss: 0.8475
[10/30 18:21:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.916, 0.2318 s / batch. (data: 2.38e-05)max mem: 15.94594 GB 
[10/30 18:21:52][INFO] visual_prompt:  316: Inference (val):avg data time: 4.03e-05, avg batch time: 0.2329, average loss: 0.8344
[10/30 18:21:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.90	
[10/30 18:21:52][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/30 18:22:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3138,	0.6256 s / batch. (data: 3.05e-04). ETA=16:19:08, max mem: 15.9 GB 
[10/30 18:24:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8628,	0.6280 s / batch. (data: 3.21e-04). ETA=16:21:51, max mem: 15.9 GB 
[10/30 18:25:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3605,	0.6322 s / batch. (data: 8.50e-04). ETA=16:27:23, max mem: 15.9 GB 
[10/30 18:26:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8534,	0.6194 s / batch. (data: 3.20e-04). ETA=16:06:18, max mem: 15.9 GB 
[10/30 18:27:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7460,	0.6191 s / batch. (data: 3.32e-04). ETA=16:04:53, max mem: 15.9 GB 
[10/30 18:28:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.2885,	0.6336 s / batch. (data: 7.44e-04). ETA=16:26:21, max mem: 15.9 GB 
[10/30 18:29:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1893,	0.6182 s / batch. (data: 3.11e-04). ETA=16:01:27, max mem: 15.9 GB 
[10/30 18:30:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8964,	0.6194 s / batch. (data: 3.76e-04). ETA=16:02:15, max mem: 15.9 GB 
[10/30 18:31:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5882,	0.6326 s / batch. (data: 8.25e-04). ETA=16:21:45, max mem: 15.9 GB 
[10/30 18:32:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8532,	0.6322 s / batch. (data: 1.41e-02). ETA=16:19:57, max mem: 15.9 GB 
[10/30 18:33:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.3463,	0.6188 s / batch. (data: 1.60e-04). ETA=15:58:12, max mem: 15.9 GB 
[10/30 18:33:34][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.89e-03, avg batch time: 0.6350, average train loss: 0.7915
[10/30 18:34:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.696, 0.2478 s / batch. (data: 3.36e-05)max mem: 15.94594 GB 
[10/30 18:34:35][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2313, average loss: 0.6853
[10/30 18:34:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.69	
[10/30 18:34:35][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/30 18:35:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.7639,	0.6451 s / batch. (data: 8.12e-04). ETA=16:37:50, max mem: 15.9 GB 
[10/30 18:36:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9439,	0.6481 s / batch. (data: 8.49e-04). ETA=16:41:22, max mem: 15.9 GB 
[10/30 18:37:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.2084,	0.6273 s / batch. (data: 7.93e-04). ETA=16:08:09, max mem: 15.9 GB 
[10/30 18:38:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 4.1002,	0.6388 s / batch. (data: 7.94e-04). ETA=16:24:48, max mem: 15.9 GB 
[10/30 18:39:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0819,	0.6261 s / batch. (data: 3.18e-04). ETA=16:04:17, max mem: 15.9 GB 
[10/30 18:40:57][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9892,	0.6336 s / batch. (data: 7.76e-04). ETA=16:14:47, max mem: 15.9 GB 
[10/30 18:42:00][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8027,	0.6280 s / batch. (data: 3.21e-04). ETA=16:04:59, max mem: 15.9 GB 
[10/30 18:43:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8694,	0.6205 s / batch. (data: 3.45e-04). ETA=15:52:31, max mem: 15.9 GB 
[10/30 18:44:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.6820,	0.6337 s / batch. (data: 8.11e-04). ETA=16:11:43, max mem: 15.9 GB 
[10/30 18:45:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0402,	0.6303 s / batch. (data: 3.22e-04). ETA=16:05:28, max mem: 15.9 GB 
[10/30 18:46:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2325,	0.6196 s / batch. (data: 1.35e-04). ETA=15:47:57, max mem: 15.9 GB 
[10/30 18:46:18][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.54e-03, avg batch time: 0.6355, average train loss: 0.9052
[10/30 18:47:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.657, 0.2318 s / batch. (data: 3.03e-05)max mem: 15.94594 GB 
[10/30 18:47:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2332, average loss: 0.6967
[10/30 18:47:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 59.70	
[10/30 18:47:18][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/30 18:48:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3205,	0.6573 s / batch. (data: 4.11e-02). ETA=16:44:33, max mem: 15.9 GB 
[10/30 18:49:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.0463,	0.6339 s / batch. (data: 7.49e-04). ETA=16:07:43, max mem: 15.9 GB 
[10/30 18:50:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.6331,	0.6339 s / batch. (data: 2.59e-04). ETA=16:06:41, max mem: 15.9 GB 
[10/30 18:51:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6761,	0.6433 s / batch. (data: 8.05e-04). ETA=16:19:59, max mem: 15.9 GB 
[10/30 18:52:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2108,	0.6440 s / batch. (data: 7.72e-04). ETA=16:19:56, max mem: 15.9 GB 
[10/30 18:53:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5886,	0.6187 s / batch. (data: 3.04e-04). ETA=15:40:22, max mem: 15.9 GB 
[10/30 18:54:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5369,	0.6318 s / batch. (data: 1.48e-02). ETA=15:59:15, max mem: 15.9 GB 
[10/30 18:55:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.4945,	0.6258 s / batch. (data: 3.30e-04). ETA=15:49:05, max mem: 15.9 GB 
[10/30 18:56:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.2338,	0.6566 s / batch. (data: 3.76e-02). ETA=16:34:42, max mem: 15.9 GB 
[10/30 18:57:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8639,	0.6419 s / batch. (data: 8.97e-04). ETA=16:11:25, max mem: 15.9 GB 
[10/30 18:58:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4733,	0.6182 s / batch. (data: 1.40e-04). ETA=15:34:33, max mem: 15.9 GB 
[10/30 18:59:01][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.54e-03, avg batch time: 0.6352, average train loss: 0.8467
[10/30 18:59:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.659, 0.2251 s / batch. (data: 3.86e-05)max mem: 15.94594 GB 
[10/30 19:00:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2340, average loss: 0.6813
[10/30 19:00:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 59.12	
[10/30 19:00:01][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/30 19:01:07][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2476,	0.6256 s / batch. (data: 7.70e-04). ETA=15:44:30, max mem: 15.9 GB 
[10/30 19:02:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7527,	0.6348 s / batch. (data: 7.48e-04). ETA=15:57:23, max mem: 15.9 GB 
[10/30 19:03:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3999,	0.6400 s / batch. (data: 3.43e-04). ETA=16:04:10, max mem: 15.9 GB 
[10/30 19:04:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9023,	0.6277 s / batch. (data: 8.19e-04). ETA=15:44:34, max mem: 15.9 GB 
[10/30 19:05:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5839,	0.6633 s / batch. (data: 7.92e-04). ETA=16:37:03, max mem: 15.9 GB 
[10/30 19:06:23][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3060,	0.6321 s / batch. (data: 8.07e-04). ETA=15:49:04, max mem: 15.9 GB 
[10/30 19:07:26][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7587,	0.6197 s / batch. (data: 2.95e-04). ETA=15:29:26, max mem: 15.9 GB 
[10/30 19:08:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1525,	0.6455 s / batch. (data: 8.02e-04). ETA=16:07:05, max mem: 15.9 GB 
[10/30 19:09:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.4153,	0.6441 s / batch. (data: 9.01e-04). ETA=16:03:59, max mem: 15.9 GB 
[10/30 19:10:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6715,	0.6453 s / batch. (data: 7.83e-04). ETA=16:04:35, max mem: 15.9 GB 
[10/30 19:11:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0950,	0.6188 s / batch. (data: 1.92e-04). ETA=15:23:56, max mem: 15.9 GB 
[10/30 19:11:43][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.33e-03, avg batch time: 0.6345, average train loss: 0.7732
[10/30 19:12:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.315, 0.2432 s / batch. (data: 4.65e-05)max mem: 15.94594 GB 
[10/30 19:12:44][INFO] visual_prompt:  316: Inference (val):avg data time: 4.35e-05, avg batch time: 0.2324, average loss: 1.2171
[10/30 19:12:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.29	
[10/30 19:12:44][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/30 19:13:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6097,	0.6444 s / batch. (data: 8.25e-04). ETA=16:01:05, max mem: 15.9 GB 
[10/30 19:14:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4648,	0.6521 s / batch. (data: 2.76e-02). ETA=16:11:32, max mem: 15.9 GB 
[10/30 19:15:56][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5809,	0.6560 s / batch. (data: 8.29e-04). ETA=16:16:10, max mem: 15.9 GB 
[10/30 19:17:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.4863,	0.6324 s / batch. (data: 3.26e-04). ETA=15:39:59, max mem: 15.9 GB 
[10/30 19:18:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5821,	0.6184 s / batch. (data: 7.18e-04). ETA=15:18:14, max mem: 15.9 GB 
[10/30 19:19:06][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1582,	0.6184 s / batch. (data: 2.83e-04). ETA=15:17:06, max mem: 15.9 GB 
[10/30 19:20:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.4371,	0.6687 s / batch. (data: 3.82e-02). ETA=16:30:40, max mem: 15.9 GB 
[10/30 19:21:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6124,	0.6177 s / batch. (data: 2.93e-04). ETA=15:14:06, max mem: 15.9 GB 
[10/30 19:22:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7276,	0.6460 s / batch. (data: 7.95e-04). ETA=15:54:49, max mem: 15.9 GB 
[10/30 19:23:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7143,	0.6250 s / batch. (data: 3.04e-04). ETA=15:22:49, max mem: 15.9 GB 
[10/30 19:24:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.3007,	0.6177 s / batch. (data: 1.40e-04). ETA=15:10:57, max mem: 15.9 GB 
[10/30 19:24:26][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.55e-03, avg batch time: 0.6351, average train loss: 0.7891
[10/30 19:25:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.887, 0.2259 s / batch. (data: 3.00e-05)max mem: 15.94594 GB 
[10/30 19:25:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.75e-05, avg batch time: 0.2328, average loss: 1.0459
[10/30 19:25:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.87	
[10/30 19:25:27][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/30 19:26:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5358,	0.6520 s / batch. (data: 8.15e-04). ETA=16:00:22, max mem: 15.9 GB 
[10/30 19:27:36][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9801,	0.6693 s / batch. (data: 1.56e-02). ETA=16:24:49, max mem: 15.9 GB 
[10/30 19:28:39][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5579,	0.6341 s / batch. (data: 3.73e-04). ETA=15:31:56, max mem: 15.9 GB 
[10/30 19:29:43][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7658,	0.6331 s / batch. (data: 3.00e-04). ETA=15:29:20, max mem: 15.9 GB 
[10/30 19:30:46][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.4404,	0.6194 s / batch. (data: 3.15e-04). ETA=15:08:17, max mem: 15.9 GB 
[10/30 19:31:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.3896,	0.6335 s / batch. (data: 7.96e-04). ETA=15:27:53, max mem: 15.9 GB 
[10/30 19:32:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8318,	0.6330 s / batch. (data: 8.12e-04). ETA=15:26:08, max mem: 15.9 GB 
[10/30 19:33:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7310,	0.6344 s / batch. (data: 7.54e-04). ETA=15:27:06, max mem: 15.9 GB 
[10/30 19:34:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0577,	0.6232 s / batch. (data: 5.44e-03). ETA=15:09:43, max mem: 15.9 GB 
[10/30 19:36:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6760,	0.6330 s / batch. (data: 8.22e-04). ETA=15:22:57, max mem: 15.9 GB 
[10/30 19:37:06][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.9440,	0.6186 s / batch. (data: 1.29e-04). ETA=15:00:55, max mem: 15.9 GB 
[10/30 19:37:10][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.59e-03, avg batch time: 0.6354, average train loss: 0.7905
[10/30 19:38:00][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.600, 0.2293 s / batch. (data: 2.96e-05)max mem: 15.94594 GB 
[10/30 19:38:10][INFO] visual_prompt:  316: Inference (val):avg data time: 9.74e-05, avg batch time: 0.2329, average loss: 0.6683
[10/30 19:38:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 63.36	
[10/30 19:38:10][INFO] visual_prompt:   36: Best epoch 21: best metric: -0.668
[10/30 19:38:10][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/30 19:39:15][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1903,	0.6262 s / batch. (data: 3.03e-04). ETA=15:10:47, max mem: 15.9 GB 
[10/30 19:40:19][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.3918,	0.6440 s / batch. (data: 1.20e-02). ETA=15:35:40, max mem: 15.9 GB 
[10/30 19:41:22][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9573,	0.6237 s / batch. (data: 2.95e-04). ETA=15:05:07, max mem: 15.9 GB 
[10/30 19:42:25][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1678,	0.6250 s / batch. (data: 7.74e-04). ETA=15:05:56, max mem: 15.9 GB 
[10/30 19:43:28][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2835,	0.6193 s / batch. (data: 3.35e-04). ETA=14:56:38, max mem: 15.9 GB 
[10/30 19:44:32][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2129,	0.6330 s / batch. (data: 4.11e-04). ETA=15:15:30, max mem: 15.9 GB 
[10/30 19:45:35][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1442,	0.6311 s / batch. (data: 3.12e-04). ETA=15:11:38, max mem: 15.9 GB 
[10/30 19:46:38][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7948,	0.6366 s / batch. (data: 8.26e-04). ETA=15:18:29, max mem: 15.9 GB 
[10/30 19:47:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7085,	0.6345 s / batch. (data: 8.48e-04). ETA=15:14:29, max mem: 15.9 GB 
[10/30 19:48:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7322,	0.6284 s / batch. (data: 3.02e-04). ETA=15:04:39, max mem: 15.9 GB 
[10/30 19:49:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7694,	0.6175 s / batch. (data: 1.60e-04). ETA=14:47:51, max mem: 15.9 GB 
[10/30 19:49:52][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 4.03e-03, avg batch time: 0.6344, average train loss: 0.7676
[10/30 19:50:42][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.664, 0.2256 s / batch. (data: 2.79e-05)max mem: 15.94594 GB 
[10/30 19:50:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2336, average loss: 0.7632
[10/30 19:50:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.69	
[10/30 19:50:53][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/30 19:51:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4967,	0.6344 s / batch. (data: 3.28e-04). ETA=15:11:09, max mem: 15.9 GB 
[10/30 19:53:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8599,	0.6430 s / batch. (data: 8.73e-04). ETA=15:22:20, max mem: 15.9 GB 
[10/30 19:54:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5978,	0.6337 s / batch. (data: 7.83e-04). ETA=15:08:00, max mem: 15.9 GB 
[10/30 19:55:09][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7331,	0.6174 s / batch. (data: 3.38e-04). ETA=14:43:37, max mem: 15.9 GB 
[10/30 19:56:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8270,	0.6315 s / batch. (data: 7.83e-04). ETA=15:02:40, max mem: 15.9 GB 
[10/30 19:57:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7044,	0.6195 s / batch. (data: 3.49e-04). ETA=14:44:35, max mem: 15.9 GB 
[10/30 19:58:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6400,	0.6472 s / batch. (data: 8.04e-04). ETA=15:22:57, max mem: 15.9 GB 
[10/30 19:59:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9015,	0.6181 s / batch. (data: 3.36e-04). ETA=14:40:24, max mem: 15.9 GB 
[10/30 20:00:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8094,	0.6331 s / batch. (data: 7.93e-04). ETA=15:00:45, max mem: 15.9 GB 
[10/30 20:01:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6845,	0.6566 s / batch. (data: 8.30e-04). ETA=15:33:02, max mem: 15.9 GB 
[10/30 20:02:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7055,	0.6185 s / batch. (data: 1.53e-04). ETA=14:37:56, max mem: 15.9 GB 
[10/30 20:02:36][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 5.13e-03, avg batch time: 0.6356, average train loss: 0.7795
[10/30 20:03:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.739, 0.2253 s / batch. (data: 4.24e-05)max mem: 15.94594 GB 
[10/30 20:03:36][INFO] visual_prompt:  316: Inference (val):avg data time: 9.82e-05, avg batch time: 0.2323, average loss: 0.7031
[10/30 20:03:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[10/30 20:03:36][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/30 20:04:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6236,	0.6319 s / batch. (data: 8.50e-04). ETA=14:55:54, max mem: 15.9 GB 
[10/30 20:05:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9975,	0.6190 s / batch. (data: 3.46e-04). ETA=14:36:35, max mem: 15.9 GB 
[10/30 20:06:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0020,	0.6176 s / batch. (data: 3.19e-04). ETA=14:33:29, max mem: 15.9 GB 
[10/30 20:07:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7531,	0.6188 s / batch. (data: 3.53e-04). ETA=14:34:07, max mem: 15.9 GB 
[10/30 20:08:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8222,	0.6497 s / batch. (data: 7.37e-04). ETA=15:16:45, max mem: 15.9 GB 
[10/30 20:09:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6995,	0.6305 s / batch. (data: 7.37e-04). ETA=14:48:36, max mem: 15.9 GB 
[10/30 20:11:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7788,	0.6192 s / batch. (data: 3.44e-04). ETA=14:31:42, max mem: 15.9 GB 
[10/30 20:12:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7993,	0.6490 s / batch. (data: 8.04e-04). ETA=15:12:26, max mem: 15.9 GB 
[10/30 20:13:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5100,	0.6228 s / batch. (data: 3.20e-04). ETA=14:34:34, max mem: 15.9 GB 
[10/30 20:14:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7122,	0.6250 s / batch. (data: 7.37e-04). ETA=14:36:44, max mem: 15.9 GB 
[10/30 20:15:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7351,	0.6191 s / batch. (data: 1.43e-04). ETA=14:27:24, max mem: 15.9 GB 
[10/30 20:15:19][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 4.97e-03, avg batch time: 0.6348, average train loss: 0.7990
[10/30 20:16:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.786, 0.2341 s / batch. (data: 3.74e-05)max mem: 15.94594 GB 
[10/30 20:16:19][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2324, average loss: 0.9178
[10/30 20:16:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.43	
[10/30 20:16:19][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/30 20:17:25][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0248,	0.6360 s / batch. (data: 8.18e-04). ETA=14:49:54, max mem: 15.9 GB 
[10/30 20:18:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5950,	0.6311 s / batch. (data: 4.24e-04). ETA=14:42:04, max mem: 15.9 GB 
[10/30 20:19:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0028,	0.6338 s / batch. (data: 5.43e-03). ETA=14:44:41, max mem: 15.9 GB 
[10/30 20:20:35][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9398,	0.6183 s / batch. (data: 3.04e-04). ETA=14:22:06, max mem: 15.9 GB 
[10/30 20:21:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9589,	0.6191 s / batch. (data: 2.74e-04). ETA=14:22:07, max mem: 15.9 GB 
[10/30 20:22:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0622,	0.6447 s / batch. (data: 7.73e-04). ETA=14:56:45, max mem: 15.9 GB 
[10/30 20:23:45][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7745,	0.6294 s / batch. (data: 1.05e-02). ETA=14:34:25, max mem: 15.9 GB 
[10/30 20:24:48][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6726,	0.6197 s / batch. (data: 7.94e-04). ETA=14:19:55, max mem: 15.9 GB 
[10/30 20:25:51][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6902,	0.6355 s / batch. (data: 8.16e-04). ETA=14:40:45, max mem: 15.9 GB 
[10/30 20:26:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8038,	0.6463 s / batch. (data: 8.55e-04). ETA=14:54:40, max mem: 15.9 GB 
[10/30 20:27:58][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8771,	0.6193 s / batch. (data: 1.49e-04). ETA=14:16:12, max mem: 15.9 GB 
[10/30 20:28:01][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 4.38e-03, avg batch time: 0.6349, average train loss: 0.7839
[10/30 20:28:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.110, 0.2245 s / batch. (data: 3.03e-05)max mem: 15.94594 GB 
[10/30 20:29:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2326, average loss: 1.3260
[10/30 20:29:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.26	
[10/30 20:29:02][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/30 20:30:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7897,	0.6305 s / batch. (data: 3.22e-04). ETA=14:30:35, max mem: 15.9 GB 
[10/30 20:31:11][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5865,	0.6318 s / batch. (data: 7.85e-04). ETA=14:31:20, max mem: 15.9 GB 
[10/30 20:32:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4654,	0.6301 s / batch. (data: 1.13e-02). ETA=14:27:56, max mem: 15.9 GB 
[10/30 20:33:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9629,	0.6339 s / batch. (data: 9.49e-04). ETA=14:32:06, max mem: 15.9 GB 
[10/30 20:34:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7269,	0.6379 s / batch. (data: 5.93e-03). ETA=14:36:36, max mem: 15.9 GB 
[10/30 20:35:25][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.4982,	0.6461 s / batch. (data: 2.08e-02). ETA=14:46:42, max mem: 15.9 GB 
[10/30 20:36:28][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.5551,	0.6474 s / batch. (data: 8.46e-04). ETA=14:47:29, max mem: 15.9 GB 
[10/30 20:37:32][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0300,	0.6347 s / batch. (data: 3.13e-04). ETA=14:28:58, max mem: 15.9 GB 
[10/30 20:38:35][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.3289,	0.6260 s / batch. (data: 3.01e-04). ETA=14:16:00, max mem: 15.9 GB 
[10/30 20:39:38][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8508,	0.6300 s / batch. (data: 8.07e-04). ETA=14:20:25, max mem: 15.9 GB 
[10/30 20:40:41][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4567,	0.6182 s / batch. (data: 1.56e-04). ETA=14:03:23, max mem: 15.9 GB 
[10/30 20:40:45][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 4.39e-03, avg batch time: 0.6352, average train loss: 0.7737
[10/30 20:41:35][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.642, 0.2278 s / batch. (data: 2.53e-05)max mem: 15.94594 GB 
[10/30 20:41:46][INFO] visual_prompt:  316: Inference (val):avg data time: 1.66e-04, avg batch time: 0.2317, average loss: 0.6895
[10/30 20:41:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 62.35	
[10/30 20:41:46][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/30 20:42:51][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.1169,	0.6318 s / batch. (data: 8.13e-04). ETA=14:20:48, max mem: 15.9 GB 
[10/30 20:43:54][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.2374,	0.6400 s / batch. (data: 2.82e-04). ETA=14:30:50, max mem: 15.9 GB 
[10/30 20:44:58][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.3515,	0.6313 s / batch. (data: 8.38e-04). ETA=14:18:02, max mem: 15.9 GB 
[10/30 20:46:01][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.8459,	0.6237 s / batch. (data: 2.92e-04). ETA=14:06:39, max mem: 15.9 GB 
[10/30 20:47:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.5995,	0.6447 s / batch. (data: 7.92e-04). ETA=14:34:04, max mem: 15.9 GB 
[10/30 20:48:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8835,	0.6339 s / batch. (data: 1.61e-02). ETA=14:18:22, max mem: 15.9 GB 
[10/30 20:49:11][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0690,	0.6177 s / batch. (data: 3.25e-04). ETA=13:55:25, max mem: 15.9 GB 
[10/30 20:50:14][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8166,	0.6343 s / batch. (data: 1.02e-03). ETA=14:16:42, max mem: 15.9 GB 
[10/30 20:51:17][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8952,	0.6225 s / batch. (data: 7.41e-04). ETA=13:59:46, max mem: 15.9 GB 
[10/30 20:52:21][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5381,	0.6177 s / batch. (data: 3.18e-04). ETA=13:52:19, max mem: 15.9 GB 
[10/30 20:53:24][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5614,	0.6183 s / batch. (data: 1.41e-04). ETA=13:52:02, max mem: 15.9 GB 
[10/30 20:53:28][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 4.63e-03, avg batch time: 0.6345, average train loss: 0.7726
[10/30 20:54:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.649, 0.2273 s / batch. (data: 3.81e-05)max mem: 15.94594 GB 
[10/30 20:54:28][INFO] visual_prompt:  316: Inference (val):avg data time: 4.10e-05, avg batch time: 0.2336, average loss: 0.7430
[10/30 20:54:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.08	
[10/30 20:54:28][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/30 20:55:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8808,	0.6324 s / batch. (data: 8.32e-04). ETA=14:09:52, max mem: 15.9 GB 
[10/30 20:56:37][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.3613,	0.6195 s / batch. (data: 5.45e-04). ETA=13:51:31, max mem: 15.9 GB 
[10/30 20:57:40][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5529,	0.6195 s / batch. (data: 3.08e-04). ETA=13:50:33, max mem: 15.9 GB 
[10/30 20:58:43][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.5316,	0.6197 s / batch. (data: 2.78e-04). ETA=13:49:43, max mem: 15.9 GB 
[10/30 20:59:47][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.1694,	0.6317 s / batch. (data: 7.56e-04). ETA=14:04:46, max mem: 15.9 GB 
[10/30 21:00:50][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7200,	0.6262 s / batch. (data: 3.09e-04). ETA=13:56:22, max mem: 15.9 GB 
[10/30 21:01:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2313,	0.6540 s / batch. (data: 8.23e-04). ETA=14:32:25, max mem: 15.9 GB 
[10/30 21:02:57][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2071,	0.6554 s / batch. (data: 8.24e-04). ETA=14:33:11, max mem: 15.9 GB 
[10/30 21:04:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6939,	0.6188 s / batch. (data: 2.94e-04). ETA=13:43:21, max mem: 15.9 GB 
[10/30 21:05:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8470,	0.6520 s / batch. (data: 8.23e-04). ETA=14:26:27, max mem: 15.9 GB 
[10/30 21:06:06][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5900,	0.6173 s / batch. (data: 1.34e-04). ETA=13:39:23, max mem: 15.9 GB 
[10/30 21:06:10][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 4.23e-03, avg batch time: 0.6347, average train loss: 0.7808
[10/30 21:07:00][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.626, 0.2256 s / batch. (data: 3.00e-05)max mem: 15.94594 GB 
[10/30 21:07:11][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2326, average loss: 0.7103
[10/30 21:07:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 62.88	
[10/30 21:07:11][INFO] visual_prompt:   42: Stopping early.
