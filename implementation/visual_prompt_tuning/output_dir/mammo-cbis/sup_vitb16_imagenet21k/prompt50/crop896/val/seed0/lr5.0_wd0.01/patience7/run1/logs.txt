[10/26 06:40:57][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/26 06:40:57][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/26 06:40:57][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/26 06:40:57][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/26 06:40:57][INFO] visual_prompt:  108: Training with config:
[10/26 06:40:57][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/26 06:40:57][INFO] visual_prompt:   55: Loading training data...
[10/26 06:40:57][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/26 06:40:57][INFO] visual_prompt:   57: Loading validation data...
[10/26 06:40:57][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/26 06:40:57][INFO] visual_prompt:   38: Constructing models...
[10/26 06:41:00][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/26 06:41:00][INFO] visual_prompt:   54: tuned percent:0.522
[10/26 06:41:00][INFO] visual_prompt:   40: Device used for model: 0
[10/26 06:41:00][INFO] visual_prompt:   40: Setting up Evaluator...
[10/26 06:41:00][INFO] visual_prompt:   42: Setting up Trainer...
[10/26 06:41:00][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/26 06:41:00][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/26 06:42:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6476 s / batch. (data: 8.55e-04). ETA=19:52:37, max mem: 15.9 GB 
[10/26 06:43:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6176 s / batch. (data: 3.03e-04). ETA=18:56:26, max mem: 15.9 GB 
[10/26 06:44:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6310 s / batch. (data: 8.23e-04). ETA=19:19:59, max mem: 15.9 GB 
[10/26 06:45:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6392 s / batch. (data: 8.12e-04). ETA=19:34:02, max mem: 15.9 GB 
[10/26 06:46:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6240 s / batch. (data: 2.82e-04). ETA=19:05:00, max mem: 15.9 GB 
[10/26 06:47:23][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6322 s / batch. (data: 3.25e-04). ETA=19:18:59, max mem: 15.9 GB 
[10/26 06:48:26][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6286 s / batch. (data: 3.45e-04). ETA=19:11:28, max mem: 15.9 GB 
[10/26 06:49:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6230 s / batch. (data: 5.43e-03). ETA=19:00:04, max mem: 15.9 GB 
[10/26 06:50:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6470 s / batch. (data: 8.02e-04). ETA=19:42:52, max mem: 15.9 GB 
[10/26 06:51:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6338 s / batch. (data: 3.48e-04). ETA=19:17:39, max mem: 15.9 GB 
[10/26 06:52:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6189 s / batch. (data: 1.60e-04). ETA=18:49:32, max mem: 15.9 GB 
[10/26 06:52:43][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.90e-03, avg batch time: 0.6357, average train loss: 1.4028
[10/26 06:53:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2252 s / batch. (data: 5.32e-05)max mem: 15.92958 GB 
[10/26 06:53:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.2321, average loss: 1.3505
[10/26 06:53:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/26 06:53:44][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[10/26 06:54:49][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.2406,	0.6320 s / batch. (data: 2.73e-04). ETA=19:12:19, max mem: 15.9 GB 
[10/26 06:55:52][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6176,	0.6170 s / batch. (data: 3.28e-04). ETA=18:43:50, max mem: 15.9 GB 
[10/26 06:56:55][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0947,	0.6219 s / batch. (data: 3.25e-04). ETA=18:51:50, max mem: 15.9 GB 
[10/26 06:57:58][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0011,	0.6295 s / batch. (data: 8.19e-04). ETA=19:04:29, max mem: 15.9 GB 
[10/26 06:59:02][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 4.1370,	0.6280 s / batch. (data: 3.26e-04). ETA=19:00:43, max mem: 15.9 GB 
[10/26 07:00:05][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0633,	0.6317 s / batch. (data: 1.20e-02). ETA=19:06:30, max mem: 15.9 GB 
[10/26 07:01:08][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0101,	0.6193 s / batch. (data: 3.02e-04). ETA=18:43:00, max mem: 15.9 GB 
[10/26 07:02:11][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7556,	0.6431 s / batch. (data: 8.02e-04). ETA=19:25:03, max mem: 15.9 GB 
[10/26 07:03:14][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7456,	0.6346 s / batch. (data: 7.76e-04). ETA=19:08:37, max mem: 15.9 GB 
[10/26 07:04:18][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6344 s / batch. (data: 2.87e-04). ETA=19:07:04, max mem: 15.9 GB 
[10/26 07:05:21][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0006,	0.6183 s / batch. (data: 2.60e-04). ETA=18:36:56, max mem: 15.9 GB 
[10/26 07:05:25][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.84e-03, avg batch time: 0.6338, average train loss: 2.2289
[10/26 07:06:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.311, 0.2399 s / batch. (data: 2.93e-05)max mem: 15.92958 GB 
[10/26 07:06:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.76e-05, avg batch time: 0.2328, average loss: 1.4139
[10/26 07:06:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.97	
[10/26 07:06:25][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[10/26 07:07:31][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6285 s / batch. (data: 8.24e-04). ETA=18:54:19, max mem: 15.9 GB 
[10/26 07:08:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 10.7556,	0.6288 s / batch. (data: 7.94e-04). ETA=18:53:53, max mem: 15.9 GB 
[10/26 07:09:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1069,	0.6468 s / batch. (data: 8.27e-04). ETA=19:25:06, max mem: 15.9 GB 
[10/26 07:10:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.8768,	0.6402 s / batch. (data: 1.29e-02). ETA=19:12:12, max mem: 15.9 GB 
[10/26 07:11:45][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 15.1369,	0.6174 s / batch. (data: 3.21e-04). ETA=18:30:05, max mem: 15.9 GB 
[10/26 07:12:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0001,	0.6431 s / batch. (data: 1.23e-03). ETA=19:15:15, max mem: 15.9 GB 
[10/26 07:13:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.1363,	0.6182 s / batch. (data: 3.08e-04). ETA=18:29:38, max mem: 15.9 GB 
[10/26 07:14:55][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0001,	0.6298 s / batch. (data: 1.20e-02). ETA=18:49:16, max mem: 15.9 GB 
[10/26 07:15:58][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0115,	0.6394 s / batch. (data: 7.99e-03). ETA=19:05:24, max mem: 15.9 GB 
[10/26 07:17:01][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 6.7192,	0.6332 s / batch. (data: 1.39e-02). ETA=18:53:15, max mem: 15.9 GB 
[10/26 07:18:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6812,	0.6184 s / batch. (data: 1.41e-04). ETA=18:25:50, max mem: 15.9 GB 
[10/26 07:18:08][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.12e-03, avg batch time: 0.6354, average train loss: 4.5529
[10/26 07:18:57][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.595, 0.2400 s / batch. (data: 4.03e-05)max mem: 15.92958 GB 
[10/26 07:19:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.2326, average loss: 2.8363
[10/26 07:19:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.96	
[10/26 07:19:09][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[10/26 07:20:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6373 s / batch. (data: 1.33e-02). ETA=18:58:29, max mem: 15.9 GB 
[10/26 07:21:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 3.4988,	0.6190 s / batch. (data: 3.02e-04). ETA=18:24:45, max mem: 15.9 GB 
[10/26 07:22:21][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 6.6139,	0.6329 s / batch. (data: 8.39e-04). ETA=18:48:26, max mem: 15.9 GB 
[10/26 07:23:24][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7837,	0.6218 s / batch. (data: 3.02e-04). ETA=18:27:43, max mem: 15.9 GB 
[10/26 07:24:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0102,	0.6303 s / batch. (data: 3.00e-04). ETA=18:41:42, max mem: 15.9 GB 
[10/26 07:25:31][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.5675,	0.6191 s / batch. (data: 3.21e-04). ETA=18:20:43, max mem: 15.9 GB 
[10/26 07:26:34][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 13.2336,	0.6278 s / batch. (data: 3.03e-04). ETA=18:35:11, max mem: 15.9 GB 
[10/26 07:27:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 10.8948,	0.6311 s / batch. (data: 8.43e-04). ETA=18:40:01, max mem: 15.9 GB 
[10/26 07:28:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 25.0584,	0.6443 s / batch. (data: 5.92e-03). ETA=19:02:22, max mem: 15.9 GB 
[10/26 07:29:43][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6185 s / batch. (data: 3.19e-04). ETA=18:15:40, max mem: 15.9 GB 
[10/26 07:30:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 3.7494,	0.6191 s / batch. (data: 1.60e-04). ETA=18:15:41, max mem: 15.9 GB 
[10/26 07:30:51][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.40e-03, avg batch time: 0.6349, average train loss: 7.3553
[10/26 07:31:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.933, 0.2316 s / batch. (data: 3.19e-05)max mem: 15.92958 GB 
[10/26 07:31:51][INFO] visual_prompt:  316: Inference (val):avg data time: 1.30e-04, avg batch time: 0.2322, average loss: 7.1564
[10/26 07:31:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.56	
[10/26 07:31:51][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[10/26 07:32:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8702,	0.6463 s / batch. (data: 7.86e-04). ETA=19:02:41, max mem: 15.9 GB 
[10/26 07:34:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0030,	0.6438 s / batch. (data: 1.30e-02). ETA=18:57:04, max mem: 15.9 GB 
[10/26 07:35:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 13.9467,	0.6349 s / batch. (data: 8.18e-04). ETA=18:40:17, max mem: 15.9 GB 
[10/26 07:36:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 10.4277,	0.6174 s / batch. (data: 2.72e-04). ETA=18:08:26, max mem: 15.9 GB 
[10/26 07:37:09][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6192 s / batch. (data: 3.37e-04). ETA=18:10:37, max mem: 15.9 GB 
[10/26 07:38:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 21.4637,	0.6407 s / batch. (data: 3.10e-04). ETA=18:47:27, max mem: 15.9 GB 
[10/26 07:39:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.0277,	0.6189 s / batch. (data: 3.28e-04). ETA=18:08:02, max mem: 15.9 GB 
[10/26 07:40:19][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 12.2891,	0.6325 s / batch. (data: 3.04e-04). ETA=18:30:46, max mem: 15.9 GB 
[10/26 07:41:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 8.9119,	0.6461 s / batch. (data: 7.59e-04). ETA=18:53:39, max mem: 15.9 GB 
[10/26 07:42:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0003,	0.6316 s / batch. (data: 1.20e-02). ETA=18:27:07, max mem: 15.9 GB 
[10/26 07:43:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 5.4157,	0.6187 s / batch. (data: 1.86e-04). ETA=18:03:30, max mem: 15.9 GB 
[10/26 07:43:33][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 3.90e-03, avg batch time: 0.6342, average train loss: 9.4194
[10/26 07:44:23][INFO] visual_prompt:  303: 	Test 100/123. loss: 24.913, 0.2406 s / batch. (data: 4.72e-05)max mem: 15.92958 GB 
[10/26 07:44:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2321, average loss: 20.7072
[10/26 07:44:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.14	
[10/26 07:44:33][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[10/26 07:45:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4448,	0.6300 s / batch. (data: 3.38e-04). ETA=18:22:07, max mem: 15.9 GB 
[10/26 07:46:42][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.1432,	0.6308 s / batch. (data: 7.86e-04). ETA=18:22:31, max mem: 15.9 GB 
[10/26 07:47:45][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0338,	0.6281 s / batch. (data: 2.94e-04). ETA=18:16:47, max mem: 15.9 GB 
[10/26 07:48:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 20.8656,	0.6169 s / batch. (data: 2.88e-04). ETA=17:56:08, max mem: 15.9 GB 
[10/26 07:49:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 5.6694,	0.6417 s / batch. (data: 7.92e-04). ETA=18:38:24, max mem: 15.9 GB 
[10/26 07:50:55][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.6492,	0.6281 s / batch. (data: 8.01e-04). ETA=18:13:42, max mem: 15.9 GB 
[10/26 07:51:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 31.9857,	0.6320 s / batch. (data: 3.12e-04). ETA=18:19:22, max mem: 15.9 GB 
[10/26 07:53:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 42.8978,	0.6330 s / batch. (data: 7.84e-04). ETA=18:19:58, max mem: 15.9 GB 
[10/26 07:54:05][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6371 s / batch. (data: 8.26e-04). ETA=18:26:06, max mem: 15.9 GB 
[10/26 07:55:08][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 23.0910,	0.6368 s / batch. (data: 8.14e-04). ETA=18:24:30, max mem: 15.9 GB 
[10/26 07:56:12][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 13.9964,	0.6188 s / batch. (data: 1.60e-04). ETA=17:52:17, max mem: 15.9 GB 
[10/26 07:56:15][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.19e-03, avg batch time: 0.6348, average train loss: 13.2756
[10/26 07:57:06][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.297, 0.2433 s / batch. (data: 4.08e-05)max mem: 15.92958 GB 
[10/26 07:57:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.2320, average loss: 5.6727
[10/26 07:57:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.18	
[10/26 07:57:16][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[10/26 07:58:21][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 14.0470,	0.6319 s / batch. (data: 8.06e-04). ETA=18:13:56, max mem: 15.9 GB 
[10/26 07:59:24][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 6.0405,	0.6499 s / batch. (data: 7.51e-04). ETA=18:43:58, max mem: 15.9 GB 
[10/26 08:00:28][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 43.2260,	0.6486 s / batch. (data: 4.51e-03). ETA=18:40:39, max mem: 15.9 GB 
[10/26 08:01:31][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 6.5111,	0.6372 s / batch. (data: 8.21e-04). ETA=18:19:48, max mem: 15.9 GB 
[10/26 08:02:34][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 10.0573,	0.6298 s / batch. (data: 3.09e-04). ETA=18:06:00, max mem: 15.9 GB 
[10/26 08:03:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 58.1189,	0.6187 s / batch. (data: 2.85e-04). ETA=17:45:49, max mem: 15.9 GB 
[10/26 08:04:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0020,	0.6560 s / batch. (data: 8.01e-04). ETA=18:49:05, max mem: 15.9 GB 
[10/26 08:05:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6313 s / batch. (data: 8.08e-04). ETA=18:05:23, max mem: 15.9 GB 
[10/26 08:06:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 8.2975,	0.6256 s / batch. (data: 3.18e-04). ETA=17:54:38, max mem: 15.9 GB 
[10/26 08:07:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 8.1334,	0.6494 s / batch. (data: 1.56e-02). ETA=18:34:28, max mem: 15.9 GB 
[10/26 08:08:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6180 s / batch. (data: 1.46e-04). ETA=17:39:29, max mem: 15.9 GB 
[10/26 08:08:57][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.29e-03, avg batch time: 0.6338, average train loss: 14.4410
[10/26 08:09:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 18.104, 0.2388 s / batch. (data: 3.77e-05)max mem: 15.92958 GB 
[10/26 08:09:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2322, average loss: 16.3547
[10/26 08:09:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.97	
[10/26 08:09:57][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[10/26 08:11:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 76.0945,	0.6309 s / batch. (data: 8.27e-04). ETA=18:00:29, max mem: 15.9 GB 
[10/26 08:12:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 11.1630,	0.6323 s / batch. (data: 3.04e-04). ETA=18:01:47, max mem: 15.9 GB 
[10/26 08:13:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6203 s / batch. (data: 3.21e-04). ETA=17:40:18, max mem: 15.9 GB 
[10/26 08:14:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6190 s / batch. (data: 2.34e-04). ETA=17:37:04, max mem: 15.9 GB 
[10/26 08:15:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6472 s / batch. (data: 8.91e-04). ETA=18:24:05, max mem: 15.9 GB 
[10/26 08:16:19][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0095,	0.6488 s / batch. (data: 8.08e-04). ETA=18:25:47, max mem: 15.9 GB 
[10/26 08:17:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3715,	0.6183 s / batch. (data: 3.86e-04). ETA=17:32:42, max mem: 15.9 GB 
[10/26 08:18:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 15.5092,	0.6357 s / batch. (data: 1.59e-02). ETA=18:01:23, max mem: 15.9 GB 
[10/26 08:19:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6386 s / batch. (data: 9.70e-04). ETA=18:05:11, max mem: 15.9 GB 
[10/26 08:20:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6570 s / batch. (data: 8.37e-04). ETA=18:35:22, max mem: 15.9 GB 
[10/26 08:21:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 37.1057,	0.6179 s / batch. (data: 1.58e-04). ETA=17:27:52, max mem: 15.9 GB 
[10/26 08:21:39][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.20e-03, avg batch time: 0.6345, average train loss: 16.1246
[10/26 08:22:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 34.051, 0.2317 s / batch. (data: 3.24e-05)max mem: 15.92958 GB 
[10/26 08:22:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.82e-05, avg batch time: 0.2324, average loss: 31.1657
[10/26 08:22:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.08	
[10/26 08:22:40][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[10/26 08:23:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 5.5842,	0.6179 s / batch. (data: 2.87e-04). ETA=17:26:50, max mem: 15.9 GB 
[10/26 08:24:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6338 s / batch. (data: 3.19e-04). ETA=17:52:43, max mem: 15.9 GB 
[10/26 08:25:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 3.1105,	0.6400 s / batch. (data: 8.69e-04). ETA=18:02:07, max mem: 15.9 GB 
[10/26 08:26:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6464 s / batch. (data: 7.70e-04). ETA=18:11:54, max mem: 15.9 GB 
[10/26 08:27:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6470 s / batch. (data: 8.39e-04). ETA=18:11:45, max mem: 15.9 GB 
[10/26 08:29:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 18.3902,	0.6233 s / batch. (data: 3.01e-04). ETA=17:30:44, max mem: 15.9 GB 
[10/26 08:30:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6201 s / batch. (data: 3.14e-04). ETA=17:24:26, max mem: 15.9 GB 
[10/26 08:31:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 29.8246,	0.6362 s / batch. (data: 7.22e-04). ETA=17:50:30, max mem: 15.9 GB 
[10/26 08:32:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.3795,	0.6333 s / batch. (data: 7.95e-04). ETA=17:44:24, max mem: 15.9 GB 
[10/26 08:33:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 16.9385,	0.6234 s / batch. (data: 3.20e-04). ETA=17:26:47, max mem: 15.9 GB 
[10/26 08:34:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 7.0503,	0.6192 s / batch. (data: 1.50e-04). ETA=17:18:42, max mem: 15.9 GB 
[10/26 08:34:21][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.50e-03, avg batch time: 0.6341, average train loss: 18.8005
[10/26 08:35:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.613, 0.2315 s / batch. (data: 3.17e-05)max mem: 15.92958 GB 
[10/26 08:35:22][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2336, average loss: 4.8314
[10/26 08:35:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 57.11	
[10/26 08:35:22][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[10/26 08:36:27][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 9.3858,	0.6169 s / batch. (data: 2.92e-04). ETA=17:13:48, max mem: 15.9 GB 
[10/26 08:37:30][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 9.4387,	0.6329 s / batch. (data: 7.96e-04). ETA=17:39:27, max mem: 15.9 GB 
[10/26 08:38:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 37.9919,	0.6416 s / batch. (data: 9.01e-04). ETA=17:52:59, max mem: 15.9 GB 
[10/26 08:39:37][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6191 s / batch. (data: 2.91e-04). ETA=17:14:26, max mem: 15.9 GB 
[10/26 08:40:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 27.6280,	0.6211 s / batch. (data: 3.48e-04). ETA=17:16:41, max mem: 15.9 GB 
[10/26 08:41:43][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 14.9935,	0.6321 s / batch. (data: 8.10e-04). ETA=17:33:54, max mem: 15.9 GB 
[10/26 08:42:46][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 68.9370,	0.6349 s / batch. (data: 9.54e-04). ETA=17:37:35, max mem: 15.9 GB 
[10/26 08:43:50][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 4.8872,	0.6412 s / batch. (data: 8.31e-04). ETA=17:46:56, max mem: 15.9 GB 
[10/26 08:44:53][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 29.8595,	0.6371 s / batch. (data: 8.22e-04). ETA=17:39:06, max mem: 15.9 GB 
[10/26 08:45:56][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1396,	0.6496 s / batch. (data: 5.90e-03). ETA=17:58:47, max mem: 15.9 GB 
[10/26 08:46:59][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0001,	0.6189 s / batch. (data: 1.56e-04). ETA=17:06:51, max mem: 15.9 GB 
[10/26 08:47:03][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.26e-03, avg batch time: 0.6338, average train loss: 22.8349
[10/26 08:47:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 11.104, 0.2250 s / batch. (data: 4.63e-05)max mem: 15.92958 GB 
[10/26 08:48:03][INFO] visual_prompt:  316: Inference (val):avg data time: 4.11e-05, avg batch time: 0.2321, average loss: 12.1263
[10/26 08:48:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.38	
[10/26 08:48:03][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[10/26 08:49:09][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6320 s / batch. (data: 1.42e-03). ETA=17:27:26, max mem: 15.9 GB 
[10/26 08:50:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 24.0985,	0.6352 s / batch. (data: 3.04e-04). ETA=17:31:45, max mem: 15.9 GB 
[10/26 08:51:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 46.2775,	0.6273 s / batch. (data: 8.24e-04). ETA=17:17:35, max mem: 15.9 GB 
[10/26 08:52:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6319 s / batch. (data: 3.17e-04). ETA=17:24:08, max mem: 15.9 GB 
[10/26 08:53:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 47.1233,	0.6273 s / batch. (data: 8.10e-04). ETA=17:15:23, max mem: 15.9 GB 
[10/26 08:54:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6190 s / batch. (data: 7.72e-04). ETA=17:00:39, max mem: 15.9 GB 
[10/26 08:55:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 15.8533,	0.6191 s / batch. (data: 3.15e-04). ETA=16:59:50, max mem: 15.9 GB 
[10/26 08:56:31][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 15.9077,	0.6336 s / batch. (data: 7.55e-04). ETA=17:22:38, max mem: 15.9 GB 
[10/26 08:57:34][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 19.5621,	0.6340 s / batch. (data: 8.12e-04). ETA=17:22:19, max mem: 15.9 GB 
[10/26 08:58:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0006,	0.6181 s / batch. (data: 4.14e-04). ETA=16:55:06, max mem: 15.9 GB 
[10/26 08:59:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.3865,	0.6186 s / batch. (data: 3.67e-04). ETA=16:54:51, max mem: 15.9 GB 
[10/26 08:59:44][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.29e-03, avg batch time: 0.6337, average train loss: 25.2499
[10/26 09:00:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 42.351, 0.2366 s / batch. (data: 4.67e-05)max mem: 15.92958 GB 
[10/26 09:00:45][INFO] visual_prompt:  316: Inference (val):avg data time: 7.38e-05, avg batch time: 0.2336, average loss: 37.4735
[10/26 09:00:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.87	
[10/26 09:00:45][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[10/26 09:01:51][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 14.2227,	0.6183 s / batch. (data: 2.79e-04). ETA=16:53:22, max mem: 15.9 GB 
[10/26 09:02:55][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 22.9261,	0.6189 s / batch. (data: 2.75e-04). ETA=16:53:12, max mem: 15.9 GB 
[10/26 09:03:58][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 15.4363,	0.6190 s / batch. (data: 2.94e-04). ETA=16:52:24, max mem: 15.9 GB 
[10/26 09:05:01][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 64.0146,	0.6464 s / batch. (data: 8.31e-04). ETA=17:36:08, max mem: 15.9 GB 
[10/26 09:06:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6367 s / batch. (data: 8.30e-04). ETA=17:19:14, max mem: 15.9 GB 
[10/26 09:07:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6507 s / batch. (data: 3.17e-02). ETA=17:40:59, max mem: 15.9 GB 
[10/26 09:08:11][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 7.9172,	0.6380 s / batch. (data: 7.08e-04). ETA=17:19:14, max mem: 15.9 GB 
[10/26 09:09:14][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6320 s / batch. (data: 8.16e-04). ETA=17:08:24, max mem: 15.9 GB 
[10/26 09:10:17][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6187 s / batch. (data: 2.83e-04). ETA=16:45:40, max mem: 15.9 GB 
[10/26 09:11:20][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 16.8266,	0.6425 s / batch. (data: 7.87e-04). ETA=17:23:20, max mem: 15.9 GB 
[10/26 09:12:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 14.6532,	0.6194 s / batch. (data: 1.47e-04). ETA=16:44:53, max mem: 15.9 GB 
[10/26 09:12:27][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.01e-03, avg batch time: 0.6346, average train loss: 23.8922
[10/26 09:13:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 15.766, 0.2287 s / batch. (data: 4.32e-05)max mem: 15.92958 GB 
[10/26 09:13:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2318, average loss: 14.2569
[10/26 09:13:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.96	
[10/26 09:13:27][INFO] visual_prompt:   36: Best epoch 12: best metric: -14.257
[10/26 09:13:27][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[10/26 09:14:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 25.8221,	0.6178 s / batch. (data: 3.19e-04). ETA=16:41:11, max mem: 15.9 GB 
[10/26 09:15:36][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 71.3405,	0.6380 s / batch. (data: 7.53e-04). ETA=17:12:43, max mem: 15.9 GB 
[10/26 09:16:39][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 36.6485,	0.6181 s / batch. (data: 3.26e-04). ETA=16:39:33, max mem: 15.9 GB 
[10/26 09:17:42][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 52.9177,	0.6187 s / batch. (data: 3.20e-04). ETA=16:39:30, max mem: 15.9 GB 
[10/26 09:18:45][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6532 s / batch. (data: 7.71e-04). ETA=17:34:03, max mem: 15.9 GB 
[10/26 09:19:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 17.1948,	0.6291 s / batch. (data: 7.79e-04). ETA=16:54:15, max mem: 15.9 GB 
[10/26 09:20:52][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6524 s / batch. (data: 8.23e-04). ETA=17:30:44, max mem: 15.9 GB 
[10/26 09:21:55][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.9832,	0.6372 s / batch. (data: 3.30e-04). ETA=17:05:03, max mem: 15.9 GB 
[10/26 09:22:58][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.9549,	0.6437 s / batch. (data: 8.12e-04). ETA=17:14:29, max mem: 15.9 GB 
[10/26 09:24:01][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6141 s / batch. (data: 3.00e-04). ETA=16:25:53, max mem: 15.9 GB 
[10/26 09:25:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 33.8615,	0.6143 s / batch. (data: 1.83e-04). ETA=16:25:08, max mem: 15.9 GB 
[10/26 09:25:09][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.48e-03, avg batch time: 0.6339, average train loss: 24.5644
[10/26 09:25:58][INFO] visual_prompt:  303: 	Test 100/123. loss: 16.690, 0.2303 s / batch. (data: 2.46e-05)max mem: 15.92958 GB 
[10/26 09:26:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.72e-05, avg batch time: 0.2321, average loss: 15.0015
[10/26 09:26:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.86	
[10/26 09:26:09][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[10/26 09:27:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 31.1614,	0.6331 s / batch. (data: 3.13e-04). ETA=16:54:11, max mem: 15.9 GB 
[10/26 09:28:17][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 90.7292,	0.6289 s / batch. (data: 8.35e-04). ETA=16:46:25, max mem: 15.9 GB 
[10/26 09:29:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 77.6375,	0.6280 s / batch. (data: 3.29e-04). ETA=16:43:58, max mem: 15.9 GB 
[10/26 09:30:23][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6216 s / batch. (data: 2.74e-03). ETA=16:32:38, max mem: 15.9 GB 
[10/26 09:31:26][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 15.9432,	0.6267 s / batch. (data: 3.31e-04). ETA=16:39:44, max mem: 15.9 GB 
[10/26 09:32:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0001,	0.6315 s / batch. (data: 8.15e-04). ETA=16:46:28, max mem: 15.9 GB 
[10/26 09:33:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 21.2760,	0.6459 s / batch. (data: 1.20e-02). ETA=17:08:18, max mem: 15.9 GB 
[10/26 09:34:36][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 16.6131,	0.6361 s / batch. (data: 5.89e-03). ETA=16:51:41, max mem: 15.9 GB 
[10/26 09:35:39][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 26.8644,	0.6186 s / batch. (data: 2.82e-04). ETA=16:22:43, max mem: 15.9 GB 
[10/26 09:36:43][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 13.0943,	0.6454 s / batch. (data: 8.22e-04). ETA=17:04:18, max mem: 15.9 GB 
[10/26 09:37:46][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 18.9799,	0.6187 s / batch. (data: 1.54e-04). ETA=16:20:53, max mem: 15.9 GB 
[10/26 09:37:50][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.19e-03, avg batch time: 0.6334, average train loss: 22.4876
[10/26 09:38:39][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.172, 0.2255 s / batch. (data: 3.55e-05)max mem: 15.92958 GB 
[10/26 09:38:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.82e-05, avg batch time: 0.2326, average loss: 6.5076
[10/26 09:38:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.78	
[10/26 09:38:50][INFO] visual_prompt:   36: Best epoch 14: best metric: -6.508
[10/26 09:38:50][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[10/26 09:39:55][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 61.6858,	0.6266 s / batch. (data: 7.04e-04). ETA=16:32:17, max mem: 15.9 GB 
[10/26 09:40:58][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 44.3951,	0.6264 s / batch. (data: 7.80e-04). ETA=16:30:56, max mem: 15.9 GB 
[10/26 09:42:01][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 11.2201,	0.6233 s / batch. (data: 5.41e-03). ETA=16:24:59, max mem: 15.9 GB 
[10/26 09:43:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6184 s / batch. (data: 2.96e-04). ETA=16:16:14, max mem: 15.9 GB 
[10/26 09:44:07][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6207 s / batch. (data: 3.16e-04). ETA=16:18:50, max mem: 15.9 GB 
[10/26 09:45:10][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 16.0911,	0.6306 s / batch. (data: 7.57e-04). ETA=16:33:19, max mem: 15.9 GB 
[10/26 09:46:14][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 25.7904,	0.6189 s / batch. (data: 3.03e-04). ETA=16:13:51, max mem: 15.9 GB 
[10/26 09:47:17][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 58.5798,	0.6338 s / batch. (data: 1.05e-02). ETA=16:36:20, max mem: 15.9 GB 
[10/26 09:48:20][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 41.5765,	0.6288 s / batch. (data: 3.04e-04). ETA=16:27:19, max mem: 15.9 GB 
[10/26 09:49:23][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 37.2364,	0.6253 s / batch. (data: 7.16e-04). ETA=16:20:46, max mem: 15.9 GB 
[10/26 09:50:26][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 62.9422,	0.6123 s / batch. (data: 1.60e-04). ETA=15:59:27, max mem: 15.9 GB 
[10/26 09:50:30][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.23e-03, avg batch time: 0.6329, average train loss: 26.4998
[10/26 09:51:20][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.353, 0.2253 s / batch. (data: 5.08e-05)max mem: 15.92958 GB 
[10/26 09:51:31][INFO] visual_prompt:  316: Inference (val):avg data time: 4.26e-05, avg batch time: 0.2311, average loss: 5.6921
[10/26 09:51:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.76	
[10/26 09:51:31][INFO] visual_prompt:   36: Best epoch 15: best metric: -5.692
[10/26 09:51:31][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[10/26 09:52:35][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6279 s / batch. (data: 8.61e-04). ETA=16:22:47, max mem: 15.9 GB 
[10/26 09:53:38][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 15.3368,	0.6436 s / batch. (data: 7.37e-04). ETA=16:46:15, max mem: 15.9 GB 
[10/26 09:54:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 87.0681,	0.6168 s / batch. (data: 3.04e-04). ETA=16:03:20, max mem: 15.9 GB 
[10/26 09:55:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 9.9831,	0.6324 s / batch. (data: 7.78e-04). ETA=16:26:39, max mem: 15.9 GB 
[10/26 09:56:48][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 44.3811,	0.6368 s / batch. (data: 5.49e-03). ETA=16:32:26, max mem: 15.9 GB 
[10/26 09:57:51][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 11.6146,	0.6188 s / batch. (data: 2.51e-04). ETA=16:03:19, max mem: 15.9 GB 
[10/26 09:58:54][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 17.4192,	0.6357 s / batch. (data: 7.95e-04). ETA=16:28:32, max mem: 15.9 GB 
[10/26 09:59:58][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 13.4359,	0.6191 s / batch. (data: 4.38e-04). ETA=16:01:43, max mem: 15.9 GB 
[10/26 10:01:01][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 18.4484,	0.6306 s / batch. (data: 7.80e-04). ETA=16:18:36, max mem: 15.9 GB 
[10/26 10:02:04][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 124.1317,	0.6175 s / batch. (data: 3.62e-04). ETA=15:57:17, max mem: 15.9 GB 
[10/26 10:03:07][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 34.5811,	0.6184 s / batch. (data: 1.41e-04). ETA=15:57:35, max mem: 15.9 GB 
[10/26 10:03:11][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.13e-03, avg batch time: 0.6332, average train loss: 22.1471
[10/26 10:04:01][INFO] visual_prompt:  303: 	Test 100/123. loss: 28.191, 0.2396 s / batch. (data: 4.29e-05)max mem: 15.92958 GB 
[10/26 10:04:11][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.2331, average loss: 31.3873
[10/26 10:04:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.55	
[10/26 10:04:11][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[10/26 10:05:17][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4292,	0.6171 s / batch. (data: 3.24e-04). ETA=15:54:29, max mem: 15.9 GB 
[10/26 10:06:20][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 28.0556,	0.6405 s / batch. (data: 8.44e-04). ETA=16:29:33, max mem: 15.9 GB 
[10/26 10:07:23][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0388,	0.6190 s / batch. (data: 2.94e-04). ETA=15:55:17, max mem: 15.9 GB 
[10/26 10:08:26][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6341 s / batch. (data: 2.97e-04). ETA=16:17:33, max mem: 15.9 GB 
[10/26 10:09:29][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6194 s / batch. (data: 2.78e-04). ETA=15:53:58, max mem: 15.9 GB 
[10/26 10:10:33][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7488,	0.6684 s / batch. (data: 7.98e-04). ETA=17:08:11, max mem: 15.9 GB 
[10/26 10:11:36][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0001,	0.6458 s / batch. (data: 2.75e-04). ETA=16:32:26, max mem: 15.9 GB 
[10/26 10:12:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 14.8107,	0.6196 s / batch. (data: 2.88e-04). ETA=15:51:08, max mem: 15.9 GB 
[10/26 10:13:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6349 s / batch. (data: 2.99e-04). ETA=16:13:37, max mem: 15.9 GB 
[10/26 10:14:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6187 s / batch. (data: 3.24e-04). ETA=15:47:45, max mem: 15.9 GB 
[10/26 10:15:49][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6149 s / batch. (data: 1.57e-04). ETA=15:40:49, max mem: 15.9 GB 
[10/26 10:15:52][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.66e-03, avg batch time: 0.6338, average train loss: 22.9359
[10/26 10:16:42][INFO] visual_prompt:  303: 	Test 100/123. loss: 13.702, 0.2478 s / batch. (data: 2.88e-05)max mem: 15.92958 GB 
[10/26 10:16:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2333, average loss: 15.0274
[10/26 10:16:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.24	
[10/26 10:16:53][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[10/26 10:17:58][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6426 s / batch. (data: 8.16e-04). ETA=16:22:09, max mem: 15.9 GB 
[10/26 10:19:01][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 34.7333,	0.6419 s / batch. (data: 7.77e-04). ETA=16:19:57, max mem: 15.9 GB 
[10/26 10:20:04][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 69.5090,	0.6440 s / batch. (data: 3.18e-04). ETA=16:22:07, max mem: 15.9 GB 
[10/26 10:21:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 49.1877,	0.6280 s / batch. (data: 2.82e-04). ETA=15:56:39, max mem: 15.9 GB 
[10/26 10:22:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 52.6302,	0.6195 s / batch. (data: 3.00e-04). ETA=15:42:40, max mem: 15.9 GB 
[10/26 10:23:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6184 s / batch. (data: 3.19e-04). ETA=15:39:54, max mem: 15.9 GB 
[10/26 10:24:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6215 s / batch. (data: 7.99e-04). ETA=15:43:40, max mem: 15.9 GB 
[10/26 10:25:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.0266,	0.6171 s / batch. (data: 3.10e-04). ETA=15:35:54, max mem: 15.9 GB 
[10/26 10:26:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 36.5181,	0.6475 s / batch. (data: 7.52e-04). ETA=16:21:00, max mem: 15.9 GB 
[10/26 10:27:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 6.0849,	0.6313 s / batch. (data: 2.98e-04). ETA=15:55:21, max mem: 15.9 GB 
[10/26 10:28:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6165 s / batch. (data: 1.51e-04). ETA=15:31:56, max mem: 15.9 GB 
[10/26 10:28:34][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.58e-03, avg batch time: 0.6336, average train loss: 24.7325
[10/26 10:29:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 18.610, 0.2441 s / batch. (data: 2.96e-05)max mem: 15.92958 GB 
[10/26 10:29:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2324, average loss: 16.9870
[10/26 10:29:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.41	
[10/26 10:29:34][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[10/26 10:30:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0006,	0.6304 s / batch. (data: 2.64e-04). ETA=15:51:49, max mem: 15.9 GB 
[10/26 10:31:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 4.2506,	0.6420 s / batch. (data: 1.45e-02). ETA=16:08:14, max mem: 15.9 GB 
[10/26 10:32:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6722 s / batch. (data: 5.86e-03). ETA=16:52:43, max mem: 15.9 GB 
[10/26 10:33:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 41.5267,	0.6202 s / batch. (data: 7.72e-04). ETA=15:33:22, max mem: 15.9 GB 
[10/26 10:34:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 15.5257,	0.6184 s / batch. (data: 3.02e-04). ETA=15:29:33, max mem: 15.9 GB 
[10/26 10:35:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6316 s / batch. (data: 7.92e-04). ETA=15:48:21, max mem: 15.9 GB 
[10/26 10:36:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.4806,	0.6311 s / batch. (data: 3.12e-04). ETA=15:46:35, max mem: 15.9 GB 
[10/26 10:38:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.3312,	0.6422 s / batch. (data: 8.42e-04). ETA=16:02:09, max mem: 15.9 GB 
[10/26 10:39:05][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6327 s / batch. (data: 8.35e-04). ETA=15:46:53, max mem: 15.9 GB 
[10/26 10:40:08][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6407 s / batch. (data: 2.30e-02). ETA=15:57:42, max mem: 15.9 GB 
[10/26 10:41:12][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6120 s / batch. (data: 1.62e-04). ETA=15:13:54, max mem: 15.9 GB 
[10/26 10:41:16][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.12e-03, avg batch time: 0.6340, average train loss: 23.8041
[10/26 10:42:06][INFO] visual_prompt:  303: 	Test 100/123. loss: 72.448, 0.2520 s / batch. (data: 2.19e-05)max mem: 15.92958 GB 
[10/26 10:42:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2315, average loss: 65.4076
[10/26 10:42:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[10/26 10:42:17][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[10/26 10:43:22][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 27.1226,	0.6337 s / batch. (data: 2.68e-04). ETA=15:45:05, max mem: 15.9 GB 
[10/26 10:44:25][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 124.0142,	0.6314 s / batch. (data: 8.06e-04). ETA=15:40:39, max mem: 15.9 GB 
[10/26 10:45:28][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 13.0434,	0.6600 s / batch. (data: 4.08e-02). ETA=16:22:05, max mem: 15.9 GB 
[10/26 10:46:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.9355,	0.6334 s / batch. (data: 7.36e-04). ETA=15:41:33, max mem: 15.9 GB 
[10/26 10:47:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 40.1564,	0.6287 s / batch. (data: 3.46e-04). ETA=15:33:28, max mem: 15.9 GB 
[10/26 10:48:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.9608,	0.6605 s / batch. (data: 1.48e-02). ETA=16:19:38, max mem: 15.9 GB 
[10/26 10:49:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6735 s / batch. (data: 4.64e-02). ETA=16:37:40, max mem: 15.9 GB 
[10/26 10:50:45][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 8.0862,	0.6263 s / batch. (data: 2.71e-04). ETA=15:26:49, max mem: 15.9 GB 
[10/26 10:51:48][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 82.6544,	0.6312 s / batch. (data: 3.39e-04). ETA=15:32:57, max mem: 15.9 GB 
[10/26 10:52:51][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6517 s / batch. (data: 3.44e-02). ETA=16:02:14, max mem: 15.9 GB 
[10/26 10:53:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 26.9470,	0.6181 s / batch. (data: 1.54e-04). ETA=15:11:35, max mem: 15.9 GB 
[10/26 10:53:58][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 5.10e-03, avg batch time: 0.6343, average train loss: 23.1170
[10/26 10:54:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 20.464, 0.2259 s / batch. (data: 3.72e-05)max mem: 15.92958 GB 
[10/26 10:54:59][INFO] visual_prompt:  316: Inference (val):avg data time: 3.77e-05, avg batch time: 0.2315, average loss: 23.6988
[10/26 10:54:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.48	
[10/26 10:54:59][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[10/26 10:56:04][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 74.8250,	0.6491 s / batch. (data: 8.29e-04). ETA=15:56:05, max mem: 15.9 GB 
[10/26 10:57:08][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6505 s / batch. (data: 1.10e-02). ETA=15:57:05, max mem: 15.9 GB 
[10/26 10:58:11][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 88.0989,	0.6537 s / batch. (data: 5.29e-03). ETA=16:00:45, max mem: 15.9 GB 
[10/26 10:59:14][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 8.2914,	0.6211 s / batch. (data: 3.53e-04). ETA=15:11:43, max mem: 15.9 GB 
[10/26 11:00:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6206 s / batch. (data: 3.21e-04). ETA=15:10:01, max mem: 15.9 GB 
[10/26 11:01:20][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 41.9779,	0.6179 s / batch. (data: 3.26e-04). ETA=15:05:04, max mem: 15.9 GB 
[10/26 11:02:23][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 9.5028,	0.6197 s / batch. (data: 3.10e-04). ETA=15:06:41, max mem: 15.9 GB 
[10/26 11:03:26][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 69.0435,	0.6197 s / batch. (data: 5.44e-03). ETA=15:05:32, max mem: 15.9 GB 
[10/26 11:04:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6391 s / batch. (data: 7.39e-04). ETA=15:32:55, max mem: 15.9 GB 
[10/26 11:05:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 3.6043,	0.6308 s / batch. (data: 7.85e-04). ETA=15:19:43, max mem: 15.9 GB 
[10/26 11:06:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6176 s / batch. (data: 1.53e-04). ETA=14:59:24, max mem: 15.9 GB 
[10/26 11:06:39][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.52e-03, avg batch time: 0.6335, average train loss: 24.0992
[10/26 11:07:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 14.427, 0.2437 s / batch. (data: 3.29e-05)max mem: 15.92958 GB 
[10/26 11:07:40][INFO] visual_prompt:  316: Inference (val):avg data time: 1.28e-04, avg batch time: 0.2324, average loss: 13.0136
[10/26 11:07:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.24	
[10/26 11:07:40][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[10/26 11:08:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 64.5476,	0.6392 s / batch. (data: 8.34e-04). ETA=15:29:47, max mem: 15.9 GB 
[10/26 11:09:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 46.9345,	0.6245 s / batch. (data: 5.44e-03). ETA=15:07:19, max mem: 15.9 GB 
[10/26 11:10:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 11.7546,	0.6176 s / batch. (data: 2.83e-04). ETA=14:56:20, max mem: 15.9 GB 
[10/26 11:11:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 13.1395,	0.6195 s / batch. (data: 7.57e-04). ETA=14:57:59, max mem: 15.9 GB 
[10/26 11:12:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 18.6276,	0.6324 s / batch. (data: 7.96e-04). ETA=15:15:39, max mem: 15.9 GB 
[10/26 11:14:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6469 s / batch. (data: 8.01e-04). ETA=15:35:30, max mem: 15.9 GB 
[10/26 11:15:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7016,	0.6199 s / batch. (data: 3.18e-04). ETA=14:55:30, max mem: 15.9 GB 
[10/26 11:16:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 17.9643,	0.6204 s / batch. (data: 7.47e-04). ETA=14:55:12, max mem: 15.9 GB 
[10/26 11:17:10][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 22.7545,	0.6485 s / batch. (data: 3.61e-04). ETA=15:34:39, max mem: 15.9 GB 
[10/26 11:18:14][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 13.3095,	0.6370 s / batch. (data: 3.12e-04). ETA=15:16:56, max mem: 15.9 GB 
[10/26 11:19:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 104.7452,	0.6189 s / batch. (data: 1.37e-04). ETA=14:49:50, max mem: 15.9 GB 
[10/26 11:19:21][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 4.49e-03, avg batch time: 0.6337, average train loss: 21.1787
[10/26 11:20:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 24.200, 0.2299 s / batch. (data: 2.96e-05)max mem: 15.92958 GB 
[10/26 11:20:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.98e-05, avg batch time: 0.2319, average loss: 21.9451
[10/26 11:20:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.42	
[10/26 11:20:21][INFO] visual_prompt:   42: Stopping early.
