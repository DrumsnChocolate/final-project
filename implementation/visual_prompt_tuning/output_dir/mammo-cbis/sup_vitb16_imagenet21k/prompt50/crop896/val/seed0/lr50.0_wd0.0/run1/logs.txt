[10/24 10:39:17][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/24 10:39:17][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/24 10:39:17][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/24 10:39:17][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/24 10:39:17][INFO] visual_prompt:  108: Training with config:
[10/24 10:39:17][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/24 10:39:17][INFO] visual_prompt:   55: Loading training data...
[10/24 10:39:17][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/24 10:39:17][INFO] visual_prompt:   57: Loading validation data...
[10/24 10:39:17][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/24 10:39:17][INFO] visual_prompt:   38: Constructing models...
[10/24 10:39:19][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/24 10:39:19][INFO] visual_prompt:   54: tuned percent:0.522
[10/24 10:39:19][INFO] visual_prompt:   40: Device used for model: 0
[10/24 10:39:19][INFO] visual_prompt:   40: Setting up Evaluator...
[10/24 10:39:19][INFO] visual_prompt:   42: Setting up Trainer...
[10/24 10:39:19][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/24 10:39:19][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/24 10:40:25][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6327 s / batch. (data: 1.55e-02). ETA=19:25:16, max mem: 15.9 GB 
[10/24 10:41:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6192 s / batch. (data: 3.02e-04). ETA=18:59:16, max mem: 15.9 GB 
[10/24 10:42:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6561 s / batch. (data: 8.21e-04). ETA=20:06:12, max mem: 15.9 GB 
[10/24 10:43:35][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6444 s / batch. (data: 7.98e-04). ETA=19:43:38, max mem: 15.9 GB 
[10/24 10:44:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6396 s / batch. (data: 1.05e-02). ETA=19:33:42, max mem: 15.9 GB 
[10/24 10:45:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6516 s / batch. (data: 7.88e-04). ETA=19:54:40, max mem: 15.9 GB 
[10/24 10:46:45][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6338 s / batch. (data: 8.15e-04). ETA=19:20:57, max mem: 15.9 GB 
[10/24 10:47:48][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6196 s / batch. (data: 3.14e-04). ETA=18:53:50, max mem: 15.9 GB 
[10/24 10:48:51][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6245 s / batch. (data: 3.21e-04). ETA=19:01:47, max mem: 15.9 GB 
[10/24 10:49:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6325 s / batch. (data: 8.03e-04). ETA=19:15:25, max mem: 15.9 GB 
[10/24 10:50:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6191 s / batch. (data: 1.57e-04). ETA=18:49:49, max mem: 15.9 GB 
[10/24 10:51:01][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.68e-03, avg batch time: 0.6345, average train loss: 1.4028
[10/24 10:51:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2342 s / batch. (data: 2.86e-05)max mem: 15.90529 GB 
[10/24 10:52:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2333, average loss: 1.3505
[10/24 10:52:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/24 10:52:02][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 5.0
[10/24 10:53:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 158.6233,	0.6287 s / batch. (data: 7.82e-04). ETA=19:06:14, max mem: 15.9 GB 
[10/24 10:54:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 44.8116,	0.6416 s / batch. (data: 7.94e-04). ETA=19:28:40, max mem: 15.9 GB 
[10/24 10:55:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 85.6117,	0.6370 s / batch. (data: 8.08e-04). ETA=19:19:13, max mem: 15.9 GB 
[10/24 10:56:15][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6074 s / batch. (data: 3.14e-04). ETA=18:24:27, max mem: 15.9 GB 
[10/24 10:57:18][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 14.8512,	0.6479 s / batch. (data: 7.41e-04). ETA=19:36:59, max mem: 15.9 GB 
[10/24 10:58:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 16.2388,	0.6232 s / batch. (data: 7.40e-04). ETA=18:50:57, max mem: 15.9 GB 
[10/24 10:59:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6157 s / batch. (data: 7.55e-04). ETA=18:36:29, max mem: 15.9 GB 
[10/24 11:00:28][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 40.7202,	0.6303 s / batch. (data: 3.39e-04). ETA=19:01:54, max mem: 15.9 GB 
[10/24 11:01:31][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 27.2108,	0.6474 s / batch. (data: 7.89e-04). ETA=19:31:41, max mem: 15.9 GB 
[10/24 11:02:34][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6170 s / batch. (data: 2.62e-04). ETA=18:35:37, max mem: 15.9 GB 
[10/24 11:03:37][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6191 s / batch. (data: 1.46e-04). ETA=18:38:22, max mem: 15.9 GB 
[10/24 11:03:41][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.85e-03, avg batch time: 0.6322, average train loss: 34.1237
[10/24 11:04:31][INFO] visual_prompt:  303: 	Test 100/123. loss: 135.334, 0.2316 s / batch. (data: 3.77e-05)max mem: 15.90529 GB 
[10/24 11:04:42][INFO] visual_prompt:  316: Inference (val):avg data time: 4.33e-05, avg batch time: 0.2311, average loss: 121.9094
[10/24 11:04:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.81	
[10/24 11:04:42][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 10.0
[10/24 11:05:48][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 83.5547,	0.6283 s / batch. (data: 8.40e-04). ETA=18:54:02, max mem: 15.9 GB 
[10/24 11:06:51][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 28.6865,	0.6586 s / batch. (data: 7.88e-04). ETA=19:47:37, max mem: 15.9 GB 
[10/24 11:07:54][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6193 s / batch. (data: 4.47e-04). ETA=18:35:41, max mem: 15.9 GB 
[10/24 11:08:56][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0542,	0.6486 s / batch. (data: 5.89e-03). ETA=19:27:17, max mem: 15.9 GB 
[10/24 11:10:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 189.6586,	0.6181 s / batch. (data: 3.25e-04). ETA=18:31:28, max mem: 15.9 GB 
[10/24 11:11:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6197 s / batch. (data: 3.71e-04). ETA=18:33:15, max mem: 15.9 GB 
[10/24 11:12:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 16.3731,	0.6456 s / batch. (data: 8.79e-04). ETA=19:18:43, max mem: 15.9 GB 
[10/24 11:13:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 39.9350,	0.6443 s / batch. (data: 3.59e-04). ETA=19:15:22, max mem: 15.9 GB 
[10/24 11:14:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 132.9415,	0.6284 s / batch. (data: 3.05e-04). ETA=18:45:50, max mem: 15.9 GB 
[10/24 11:15:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 89.7862,	0.6178 s / batch. (data: 3.26e-04). ETA=18:25:47, max mem: 15.9 GB 
[10/24 11:16:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 94.7405,	0.6132 s / batch. (data: 1.37e-04). ETA=18:16:33, max mem: 15.9 GB 
[10/24 11:16:25][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 8.92e-03, avg batch time: 0.6360, average train loss: 53.9144
[10/24 11:17:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 104.770, 0.2255 s / batch. (data: 3.86e-05)max mem: 15.90529 GB 
[10/24 11:17:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2322, average loss: 116.6702
[10/24 11:17:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.32	
[10/24 11:17:26][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 15.0
[10/24 11:18:31][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6171 s / batch. (data: 2.67e-04). ETA=18:22:27, max mem: 15.9 GB 
[10/24 11:19:34][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 321.9269,	0.6288 s / batch. (data: 8.07e-04). ETA=18:42:08, max mem: 15.9 GB 
[10/24 11:20:37][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 90.8264,	0.6131 s / batch. (data: 8.07e-04). ETA=18:13:13, max mem: 15.9 GB 
[10/24 11:21:40][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 76.6674,	0.6374 s / batch. (data: 1.21e-03). ETA=18:55:25, max mem: 15.9 GB 
[10/24 11:22:43][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6453 s / batch. (data: 3.21e-04). ETA=19:08:31, max mem: 15.9 GB 
[10/24 11:23:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6092 s / batch. (data: 3.18e-04). ETA=18:03:15, max mem: 15.9 GB 
[10/24 11:24:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 295.6277,	0.6400 s / batch. (data: 8.05e-04). ETA=18:56:48, max mem: 15.9 GB 
[10/24 11:25:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 119.9365,	0.6320 s / batch. (data: 3.18e-04). ETA=18:41:35, max mem: 15.9 GB 
[10/24 11:26:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 366.4704,	0.6329 s / batch. (data: 8.04e-04). ETA=18:42:13, max mem: 15.9 GB 
[10/24 11:27:58][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 153.5802,	0.6374 s / batch. (data: 1.07e-02). ETA=18:49:04, max mem: 15.9 GB 
[10/24 11:29:01][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 219.8590,	0.6124 s / batch. (data: 1.78e-04). ETA=18:03:49, max mem: 15.9 GB 
[10/24 11:29:05][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.37e-03, avg batch time: 0.6315, average train loss: 64.5602
[10/24 11:29:55][INFO] visual_prompt:  303: 	Test 100/123. loss: 86.875, 0.2247 s / batch. (data: 4.46e-05)max mem: 15.90529 GB 
[10/24 11:30:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2330, average loss: 96.1257
[10/24 11:30:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.41	
[10/24 11:30:05][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 20.0
[10/24 11:31:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 184.3729,	0.6348 s / batch. (data: 9.05e-04). ETA=18:42:22, max mem: 15.9 GB 
[10/24 11:32:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6134 s / batch. (data: 5.46e-03). ETA=18:03:30, max mem: 15.9 GB 
[10/24 11:33:16][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 146.6105,	0.6237 s / batch. (data: 3.47e-04). ETA=18:20:38, max mem: 15.9 GB 
[10/24 11:34:19][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 71.9173,	0.6271 s / batch. (data: 1.54e-02). ETA=18:25:33, max mem: 15.9 GB 
[10/24 11:35:22][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6082 s / batch. (data: 3.04e-04). ETA=17:51:07, max mem: 15.9 GB 
[10/24 11:36:25][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6195 s / batch. (data: 3.33e-04). ETA=18:10:06, max mem: 15.9 GB 
[10/24 11:37:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 35.9653,	0.6250 s / batch. (data: 3.13e-04). ETA=18:18:40, max mem: 15.9 GB 
[10/24 11:38:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 139.8474,	0.6175 s / batch. (data: 3.04e-04). ETA=18:04:29, max mem: 15.9 GB 
[10/24 11:39:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 45.0045,	0.6171 s / batch. (data: 3.06e-04). ETA=18:02:43, max mem: 15.9 GB 
[10/24 11:40:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 15.5035,	0.6328 s / batch. (data: 3.36e-04). ETA=18:29:17, max mem: 15.9 GB 
[10/24 11:41:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 44.9550,	0.6114 s / batch. (data: 1.41e-04). ETA=17:50:42, max mem: 15.9 GB 
[10/24 11:41:43][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.37e-03, avg batch time: 0.6305, average train loss: 90.1691
[10/24 11:42:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 94.938, 0.2357 s / batch. (data: 3.03e-05)max mem: 15.90529 GB 
[10/24 11:42:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2334, average loss: 84.3313
[10/24 11:42:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.25	
[10/24 11:42:44][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 25.0
[10/24 11:43:48][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 376.6224,	0.6452 s / batch. (data: 5.97e-03). ETA=18:48:43, max mem: 15.9 GB 
[10/24 11:44:51][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 185.7617,	0.6334 s / batch. (data: 3.09e-04). ETA=18:27:02, max mem: 15.9 GB 
[10/24 11:45:54][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 4.9385,	0.6301 s / batch. (data: 7.81e-04). ETA=18:20:18, max mem: 15.9 GB 
[10/24 11:46:57][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 19.5695,	0.6186 s / batch. (data: 2.72e-04). ETA=17:59:13, max mem: 15.9 GB 
[10/24 11:47:59][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 42.4241,	0.6216 s / batch. (data: 3.71e-04). ETA=18:03:16, max mem: 15.9 GB 
[10/24 11:49:03][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6180 s / batch. (data: 3.20e-04). ETA=17:56:04, max mem: 15.9 GB 
[10/24 11:50:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 204.6333,	0.6455 s / batch. (data: 5.86e-03). ETA=18:42:52, max mem: 15.9 GB 
[10/24 11:51:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 334.7636,	0.6119 s / batch. (data: 3.14e-04). ETA=17:43:21, max mem: 15.9 GB 
[10/24 11:52:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 522.8630,	0.6388 s / batch. (data: 1.60e-02). ETA=18:29:06, max mem: 15.9 GB 
[10/24 11:53:14][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 66.2373,	0.6462 s / batch. (data: 1.82e-02). ETA=18:40:51, max mem: 15.9 GB 
[10/24 11:54:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6077 s / batch. (data: 1.57e-04). ETA=17:33:07, max mem: 15.9 GB 
[10/24 11:54:21][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.36e-03, avg batch time: 0.6302, average train loss: 111.4558
[10/24 11:55:10][INFO] visual_prompt:  303: 	Test 100/123. loss: 154.139, 0.2247 s / batch. (data: 3.10e-05)max mem: 15.90529 GB 
[10/24 11:55:21][INFO] visual_prompt:  316: Inference (val):avg data time: 4.08e-05, avg batch time: 0.2322, average loss: 174.2375
[10/24 11:55:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.27	
[10/24 11:55:21][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 30.0
[10/24 11:56:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 7.2124,	0.6305 s / batch. (data: 2.99e-04). ETA=18:11:23, max mem: 15.9 GB 
[10/24 11:57:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 249.1403,	0.6191 s / batch. (data: 3.65e-04). ETA=17:50:45, max mem: 15.9 GB 
[10/24 11:58:32][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 5.6131,	0.6281 s / batch. (data: 7.51e-04). ETA=18:05:11, max mem: 15.9 GB 
[10/24 11:59:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 29.8362,	0.6281 s / batch. (data: 1.27e-03). ETA=18:04:05, max mem: 15.9 GB 
[10/24 12:00:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 482.9820,	0.6304 s / batch. (data: 5.40e-03). ETA=18:07:02, max mem: 15.9 GB 
[10/24 12:01:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 371.9716,	0.6266 s / batch. (data: 7.36e-04). ETA=17:59:27, max mem: 15.9 GB 
[10/24 12:02:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 239.6512,	0.6399 s / batch. (data: 8.62e-04). ETA=18:21:23, max mem: 15.9 GB 
[10/24 12:03:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 26.3824,	0.6176 s / batch. (data: 3.18e-04). ETA=17:41:51, max mem: 15.9 GB 
[10/24 12:04:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 66.2758,	0.6403 s / batch. (data: 7.41e-04). ETA=18:19:55, max mem: 15.9 GB 
[10/24 12:05:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 85.1982,	0.6440 s / batch. (data: 8.64e-04). ETA=18:25:08, max mem: 15.9 GB 
[10/24 12:06:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6062 s / batch. (data: 1.47e-04). ETA=17:19:15, max mem: 15.9 GB 
[10/24 12:06:58][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.00e-03, avg batch time: 0.6297, average train loss: 124.1007
[10/24 12:07:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 123.880, 0.2286 s / batch. (data: 4.05e-05)max mem: 15.90529 GB 
[10/24 12:07:59][INFO] visual_prompt:  316: Inference (val):avg data time: 4.03e-05, avg batch time: 0.2315, average loss: 109.4972
[10/24 12:07:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.28	
[10/24 12:07:59][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 35.0
[10/24 12:09:04][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 182.6709,	0.6222 s / batch. (data: 7.69e-04). ETA=17:45:32, max mem: 15.9 GB 
[10/24 12:10:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 96.0887,	0.6249 s / batch. (data: 7.92e-04). ETA=17:49:13, max mem: 15.9 GB 
[10/24 12:11:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6386 s / batch. (data: 7.48e-04). ETA=18:11:37, max mem: 15.9 GB 
[10/24 12:12:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6185 s / batch. (data: 2.29e-04). ETA=17:36:12, max mem: 15.9 GB 
[10/24 12:13:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6160 s / batch. (data: 3.84e-04). ETA=17:30:49, max mem: 15.9 GB 
[10/24 12:14:17][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 37.4180,	0.6449 s / batch. (data: 1.78e-02). ETA=18:19:09, max mem: 15.9 GB 
[10/24 12:15:20][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 26.8237,	0.6181 s / batch. (data: 2.80e-04). ETA=17:32:23, max mem: 15.9 GB 
[10/24 12:16:23][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.6422,	0.6380 s / batch. (data: 7.50e-04). ETA=18:05:14, max mem: 15.9 GB 
[10/24 12:17:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6353 s / batch. (data: 1.01e-03). ETA=17:59:37, max mem: 15.9 GB 
[10/24 12:18:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6309 s / batch. (data: 7.87e-04). ETA=17:50:57, max mem: 15.9 GB 
[10/24 12:19:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 112.6568,	0.6164 s / batch. (data: 1.54e-04). ETA=17:25:27, max mem: 15.9 GB 
[10/24 12:19:35][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.49e-03, avg batch time: 0.6296, average train loss: 149.5069
[10/24 12:20:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 9.368, 0.2435 s / batch. (data: 4.12e-05)max mem: 15.90529 GB 
[10/24 12:20:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2327, average loss: 7.9082
[10/24 12:20:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 54.30	
[10/24 12:20:36][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 40.0
[10/24 12:21:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 534.1885,	0.6538 s / batch. (data: 9.06e-04). ETA=18:27:44, max mem: 15.9 GB 
[10/24 12:22:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6134 s / batch. (data: 3.13e-04). ETA=17:18:15, max mem: 15.9 GB 
[10/24 12:23:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 275.9615,	0.6314 s / batch. (data: 3.91e-04). ETA=17:47:33, max mem: 15.9 GB 
[10/24 12:24:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6078 s / batch. (data: 3.30e-04). ETA=17:06:40, max mem: 15.9 GB 
[10/24 12:25:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 594.6730,	0.6404 s / batch. (data: 3.13e-04). ETA=18:00:46, max mem: 15.9 GB 
[10/24 12:26:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6214 s / batch. (data: 3.55e-04). ETA=17:27:40, max mem: 15.9 GB 
[10/24 12:27:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6357 s / batch. (data: 8.10e-04). ETA=17:50:37, max mem: 15.9 GB 
[10/24 12:29:01][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 103.9929,	0.6323 s / batch. (data: 7.68e-04). ETA=17:43:53, max mem: 15.9 GB 
[10/24 12:30:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6313 s / batch. (data: 1.14e-03). ETA=17:41:11, max mem: 15.9 GB 
[10/24 12:31:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 421.2297,	0.6181 s / batch. (data: 3.13e-04). ETA=17:17:58, max mem: 15.9 GB 
[10/24 12:32:10][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 52.8612,	0.6128 s / batch. (data: 1.61e-04). ETA=17:07:55, max mem: 15.9 GB 
[10/24 12:32:13][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.92e-03, avg batch time: 0.6303, average train loss: 138.0690
[10/24 12:33:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 35.817, 0.2384 s / batch. (data: 5.39e-05)max mem: 15.90529 GB 
[10/24 12:33:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.10e-05, avg batch time: 0.2320, average loss: 45.1639
[10/24 12:33:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.12	
[10/24 12:33:14][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 45.0
[10/24 12:34:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 118.3580,	0.6400 s / batch. (data: 2.69e-02). ETA=17:52:26, max mem: 15.9 GB 
[10/24 12:35:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 21.6111,	0.6184 s / batch. (data: 3.23e-04). ETA=17:15:17, max mem: 15.9 GB 
[10/24 12:36:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 156.2450,	0.6180 s / batch. (data: 3.28e-04). ETA=17:13:28, max mem: 15.9 GB 
[10/24 12:37:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.7912,	0.6329 s / batch. (data: 8.14e-04). ETA=17:37:27, max mem: 15.9 GB 
[10/24 12:38:30][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 262.5918,	0.6259 s / batch. (data: 8.08e-04). ETA=17:24:37, max mem: 15.9 GB 
[10/24 12:39:33][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 734.5026,	0.6355 s / batch. (data: 1.20e-02). ETA=17:39:40, max mem: 15.9 GB 
[10/24 12:40:36][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 413.6193,	0.6308 s / batch. (data: 3.40e-04). ETA=17:30:47, max mem: 15.9 GB 
[10/24 12:41:38][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 150.2146,	0.6246 s / batch. (data: 3.31e-04). ETA=17:19:26, max mem: 15.9 GB 
[10/24 12:42:41][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 149.4984,	0.6453 s / batch. (data: 1.66e-02). ETA=17:52:43, max mem: 15.9 GB 
[10/24 12:43:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6325 s / batch. (data: 1.19e-03). ETA=17:30:21, max mem: 15.9 GB 
[10/24 12:44:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 242.1559,	0.6186 s / batch. (data: 1.55e-04). ETA=17:06:15, max mem: 15.9 GB 
[10/24 12:44:51][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.08e-03, avg batch time: 0.6295, average train loss: 207.3335
[10/24 12:45:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 207.565, 0.2526 s / batch. (data: 4.36e-05)max mem: 15.90529 GB 
[10/24 12:45:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-04, avg batch time: 0.2320, average loss: 185.6399
[10/24 12:45:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.36	
[10/24 12:45:52][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 50.0
[10/24 12:46:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6422 s / batch. (data: 1.82e-02). ETA=17:44:23, max mem: 15.9 GB 
[10/24 12:48:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 95.1102,	0.6368 s / batch. (data: 8.61e-04). ETA=17:34:15, max mem: 15.9 GB 
[10/24 12:49:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 238.3183,	0.6266 s / batch. (data: 7.72e-04). ETA=17:16:24, max mem: 15.9 GB 
[10/24 12:50:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 380.7223,	0.6293 s / batch. (data: 7.90e-04). ETA=17:19:45, max mem: 15.9 GB 
[10/24 12:51:08][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 7.4665,	0.6250 s / batch. (data: 1.98e-04). ETA=17:11:41, max mem: 15.9 GB 
[10/24 12:52:11][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6210 s / batch. (data: 8.24e-04). ETA=17:04:01, max mem: 15.9 GB 
[10/24 12:53:14][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6107 s / batch. (data: 2.70e-04). ETA=16:46:05, max mem: 15.9 GB 
[10/24 12:54:17][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 288.0156,	0.6184 s / batch. (data: 2.93e-04). ETA=16:57:39, max mem: 15.9 GB 
[10/24 12:55:20][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6289 s / batch. (data: 3.28e-04). ETA=17:13:54, max mem: 15.9 GB 
[10/24 12:56:23][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6354 s / batch. (data: 7.99e-04). ETA=17:23:33, max mem: 15.9 GB 
[10/24 12:57:25][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 87.1272,	0.6176 s / batch. (data: 2.42e-04). ETA=16:53:17, max mem: 15.9 GB 
[10/24 12:57:29][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.62e-03, avg batch time: 0.6302, average train loss: 186.0429
[10/24 12:58:20][INFO] visual_prompt:  303: 	Test 100/123. loss: 25.772, 0.2517 s / batch. (data: 4.74e-05)max mem: 15.90529 GB 
[10/24 12:58:31][INFO] visual_prompt:  316: Inference (val):avg data time: 1.31e-04, avg batch time: 0.2310, average loss: 32.3011
[10/24 12:58:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.63	
[10/24 12:58:31][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 49.9847706754774
[10/24 12:59:37][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 373.7473,	0.6170 s / batch. (data: 3.30e-04). ETA=16:51:09, max mem: 15.9 GB 
[10/24 13:00:40][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 46.2624,	0.6132 s / batch. (data: 3.22e-04). ETA=16:43:53, max mem: 15.9 GB 
[10/24 13:01:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 140.1855,	0.6300 s / batch. (data: 3.18e-04). ETA=17:10:20, max mem: 15.9 GB 
[10/24 13:02:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6269 s / batch. (data: 4.25e-04). ETA=17:04:15, max mem: 15.9 GB 
[10/24 13:03:48][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6624 s / batch. (data: 4.05e-02). ETA=18:01:13, max mem: 15.9 GB 
[10/24 13:04:51][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6346 s / batch. (data: 7.15e-04). ETA=17:14:50, max mem: 15.9 GB 
[10/24 13:05:54][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 418.5621,	0.6282 s / batch. (data: 3.58e-04). ETA=17:03:16, max mem: 15.9 GB 
[10/24 13:06:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 405.6432,	0.6373 s / batch. (data: 7.31e-04). ETA=17:17:04, max mem: 15.9 GB 
[10/24 13:07:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 206.5704,	0.6323 s / batch. (data: 8.11e-04). ETA=17:07:51, max mem: 15.9 GB 
[10/24 13:09:02][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 396.8335,	0.6259 s / batch. (data: 7.84e-04). ETA=16:56:27, max mem: 15.9 GB 
[10/24 13:10:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 508.1508,	0.6121 s / batch. (data: 1.49e-04). ETA=16:32:57, max mem: 15.9 GB 
[10/24 13:10:09][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.16e-03, avg batch time: 0.6307, average train loss: 189.6536
[10/24 13:10:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 136.455, 0.2355 s / batch. (data: 3.10e-05)max mem: 15.90529 GB 
[10/24 13:11:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-04, avg batch time: 0.2327, average loss: 154.7266
[10/24 13:11:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.27	
[10/24 13:11:10][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 49.939101256495604
[10/24 13:12:15][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6062 s / batch. (data: 3.44e-04). ETA=16:22:19, max mem: 15.9 GB 
[10/24 13:13:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 93.7713,	0.6200 s / batch. (data: 2.95e-04). ETA=16:43:38, max mem: 15.9 GB 
[10/24 13:14:21][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6068 s / batch. (data: 3.25e-04). ETA=16:21:19, max mem: 15.9 GB 
[10/24 13:15:24][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 419.5318,	0.6167 s / batch. (data: 3.42e-04). ETA=16:36:14, max mem: 15.9 GB 
[10/24 13:16:26][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6071 s / batch. (data: 2.80e-04). ETA=16:19:40, max mem: 15.9 GB 
[10/24 13:17:29][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 723.1934,	0.6294 s / batch. (data: 1.19e-02). ETA=16:54:39, max mem: 15.9 GB 
[10/24 13:18:32][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6337 s / batch. (data: 7.98e-04). ETA=17:00:34, max mem: 15.9 GB 
[10/24 13:19:35][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 559.3708,	0.6276 s / batch. (data: 7.91e-04). ETA=16:49:41, max mem: 15.9 GB 
[10/24 13:20:37][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 284.0591,	0.6234 s / batch. (data: 3.05e-04). ETA=16:41:49, max mem: 15.9 GB 
[10/24 13:21:41][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6220 s / batch. (data: 3.10e-04). ETA=16:38:38, max mem: 15.9 GB 
[10/24 13:22:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 45.0481,	0.6123 s / batch. (data: 1.75e-04). ETA=16:22:00, max mem: 15.9 GB 
[10/24 13:22:47][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.84e-03, avg batch time: 0.6303, average train loss: 216.8842
[10/24 13:23:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 134.730, 0.2249 s / batch. (data: 3.12e-05)max mem: 15.90529 GB 
[10/24 13:23:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2330, average loss: 119.6923
[10/24 13:23:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[10/24 13:23:48][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 49.86304738420683
[10/24 13:24:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 267.8510,	0.6181 s / batch. (data: 3.49e-04). ETA=16:30:15, max mem: 15.9 GB 
[10/24 13:25:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 349.1639,	0.6126 s / batch. (data: 3.50e-04). ETA=16:20:23, max mem: 15.9 GB 
[10/24 13:26:59][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 274.6419,	0.6126 s / batch. (data: 3.15e-04). ETA=16:19:21, max mem: 15.9 GB 
[10/24 13:28:02][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6268 s / batch. (data: 3.31e-04). ETA=16:40:57, max mem: 15.9 GB 
[10/24 13:29:05][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 142.8098,	0.6275 s / batch. (data: 2.78e-04). ETA=16:41:01, max mem: 15.9 GB 
[10/24 13:30:08][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 41.3904,	0.6267 s / batch. (data: 8.05e-04). ETA=16:38:47, max mem: 15.9 GB 
[10/24 13:31:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 460.6404,	0.6178 s / batch. (data: 7.63e-04). ETA=16:23:36, max mem: 15.9 GB 
[10/24 13:32:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 159.2545,	0.6260 s / batch. (data: 7.61e-04). ETA=16:35:36, max mem: 15.9 GB 
[10/24 13:33:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 131.0771,	0.6130 s / batch. (data: 3.15e-04). ETA=16:13:51, max mem: 15.9 GB 
[10/24 13:34:18][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 126.8285,	0.6545 s / batch. (data: 1.05e-02). ETA=17:18:44, max mem: 15.9 GB 
[10/24 13:35:21][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 108.3563,	0.6123 s / batch. (data: 2.11e-04). ETA=16:10:44, max mem: 15.9 GB 
[10/24 13:35:25][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.60e-03, avg batch time: 0.6297, average train loss: 203.6600
[10/24 13:36:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 178.731, 0.2246 s / batch. (data: 4.91e-05)max mem: 15.90529 GB 
[10/24 13:36:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.2315, average loss: 156.0849
[10/24 13:36:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.27	
[10/24 13:36:26][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 49.75670171853926
[10/24 13:37:30][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 370.8721,	0.6374 s / batch. (data: 7.77e-04). ETA=16:49:24, max mem: 15.9 GB 
[10/24 13:38:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 133.4857,	0.6381 s / batch. (data: 7.68e-04). ETA=16:49:25, max mem: 15.9 GB 
[10/24 13:39:35][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 142.7001,	0.6220 s / batch. (data: 5.93e-03). ETA=16:22:59, max mem: 15.9 GB 
[10/24 13:40:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1423.8342,	0.6391 s / batch. (data: 8.03e-04). ETA=16:48:49, max mem: 15.9 GB 
[10/24 13:41:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6255 s / batch. (data: 8.56e-04). ETA=16:26:17, max mem: 15.9 GB 
[10/24 13:42:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 338.2378,	0.6522 s / batch. (data: 3.74e-02). ETA=17:07:27, max mem: 15.9 GB 
[10/24 13:43:47][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 171.3831,	0.6450 s / batch. (data: 8.06e-04). ETA=16:54:59, max mem: 15.9 GB 
[10/24 13:44:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 12.1590,	0.6176 s / batch. (data: 3.13e-04). ETA=16:10:48, max mem: 15.9 GB 
[10/24 13:45:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 461.5442,	0.6176 s / batch. (data: 7.69e-04). ETA=16:09:48, max mem: 15.9 GB 
[10/24 13:46:55][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 168.6863,	0.6262 s / batch. (data: 2.85e-04). ETA=16:22:13, max mem: 15.9 GB 
[10/24 13:47:58][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 113.0247,	0.6120 s / batch. (data: 1.54e-04). ETA=15:58:57, max mem: 15.9 GB 
[10/24 13:48:02][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.10e-03, avg batch time: 0.6296, average train loss: 214.5515
[10/24 13:48:52][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.901, 0.2247 s / batch. (data: 4.67e-05)max mem: 15.90529 GB 
[10/24 13:49:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2333, average loss: 10.4807
[10/24 13:49:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 56.27	
[10/24 13:49:03][INFO] visual_prompt:   36: Best epoch 15: best metric: -10.481
[10/24 13:49:03][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 49.6201938253052
[10/24 13:50:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6293 s / batch. (data: 7.40e-04). ETA=16:24:55, max mem: 15.9 GB 
[10/24 13:51:11][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 335.9509,	0.6278 s / batch. (data: 3.21e-04). ETA=16:21:36, max mem: 15.9 GB 
[10/24 13:52:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6081 s / batch. (data: 3.27e-04). ETA=15:49:48, max mem: 15.9 GB 
[10/24 13:53:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 409.9231,	0.6320 s / batch. (data: 3.30e-04). ETA=16:26:04, max mem: 15.9 GB 
[10/24 13:54:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 169.9318,	0.6203 s / batch. (data: 3.52e-04). ETA=16:06:44, max mem: 15.9 GB 
[10/24 13:55:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 339.9310,	0.6312 s / batch. (data: 7.84e-04). ETA=16:22:39, max mem: 15.9 GB 
[10/24 13:56:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 246.7124,	0.6151 s / batch. (data: 3.01e-04). ETA=15:56:34, max mem: 15.9 GB 
[10/24 13:57:28][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 329.5035,	0.6528 s / batch. (data: 5.92e-03). ETA=16:54:07, max mem: 15.9 GB 
[10/24 13:58:30][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 65.4670,	0.6122 s / batch. (data: 7.60e-04). ETA=15:50:06, max mem: 15.9 GB 
[10/24 13:59:33][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 214.1169,	0.6256 s / batch. (data: 2.93e-04). ETA=16:09:48, max mem: 15.9 GB 
[10/24 14:00:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6067 s / batch. (data: 1.54e-04). ETA=15:39:30, max mem: 15.9 GB 
[10/24 14:00:40][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.49e-03, avg batch time: 0.6302, average train loss: 149.2674
[10/24 14:01:30][INFO] visual_prompt:  303: 	Test 100/123. loss: 97.855, 0.2301 s / batch. (data: 2.91e-05)max mem: 15.90529 GB 
[10/24 14:01:41][INFO] visual_prompt:  316: Inference (val):avg data time: 9.70e-05, avg batch time: 0.2315, average loss: 86.3813
[10/24 14:01:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.36	
[10/24 14:01:41][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 49.45369001834514
[10/24 14:02:46][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6194 s / batch. (data: 7.73e-04). ETA=15:58:06, max mem: 15.9 GB 
[10/24 14:03:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 98.6884,	0.6123 s / batch. (data: 3.34e-04). ETA=15:46:00, max mem: 15.9 GB 
[10/24 14:04:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6363 s / batch. (data: 7.76e-04). ETA=16:22:06, max mem: 15.9 GB 
[10/24 14:05:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1251.2004,	0.6393 s / batch. (data: 7.40e-04). ETA=16:25:38, max mem: 15.9 GB 
[10/24 14:06:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6220 s / batch. (data: 7.59e-04). ETA=15:57:58, max mem: 15.9 GB 
[10/24 14:08:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 196.2970,	0.6372 s / batch. (data: 5.99e-03). ETA=16:20:20, max mem: 15.9 GB 
[10/24 14:09:03][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 82.7629,	0.6238 s / batch. (data: 2.60e-04). ETA=15:58:38, max mem: 15.9 GB 
[10/24 14:10:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6470 s / batch. (data: 7.96e-04). ETA=16:33:13, max mem: 15.9 GB 
[10/24 14:11:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 492.7748,	0.6320 s / batch. (data: 2.76e-04). ETA=16:09:09, max mem: 15.9 GB 
[10/24 14:12:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 244.7960,	0.6462 s / batch. (data: 1.46e-02). ETA=16:29:48, max mem: 15.9 GB 
[10/24 14:13:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6073 s / batch. (data: 1.51e-04). ETA=15:29:09, max mem: 15.9 GB 
[10/24 14:13:19][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.72e-03, avg batch time: 0.6311, average train loss: 152.1178
[10/24 14:14:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 42.446, 0.2473 s / batch. (data: 4.36e-05)max mem: 15.90529 GB 
[10/24 14:14:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2328, average loss: 40.1196
[10/24 14:14:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.38	
[10/24 14:14:20][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 49.25739315689991
[10/24 14:15:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 215.1428,	0.6405 s / batch. (data: 8.41e-04). ETA=16:18:48, max mem: 15.9 GB 
[10/24 14:16:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 451.4674,	0.6185 s / batch. (data: 3.25e-04). ETA=15:44:13, max mem: 15.9 GB 
[10/24 14:17:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 215.8709,	0.6320 s / batch. (data: 2.78e-04). ETA=16:03:48, max mem: 15.9 GB 
[10/24 14:18:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 254.3704,	0.6242 s / batch. (data: 5.54e-03). ETA=15:50:52, max mem: 15.9 GB 
[10/24 14:19:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6081 s / batch. (data: 7.18e-04). ETA=15:25:15, max mem: 15.9 GB 
[10/24 14:20:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 210.3066,	0.6362 s / batch. (data: 9.28e-04). ETA=16:06:58, max mem: 15.9 GB 
[10/24 14:21:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6205 s / batch. (data: 3.20e-04). ETA=15:42:02, max mem: 15.9 GB 
[10/24 14:22:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 42.1388,	0.6293 s / batch. (data: 8.82e-04). ETA=15:54:28, max mem: 15.9 GB 
[10/24 14:23:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 345.2985,	0.6148 s / batch. (data: 3.37e-04). ETA=15:31:20, max mem: 15.9 GB 
[10/24 14:24:49][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 27.0605,	0.6174 s / batch. (data: 2.92e-04). ETA=15:34:14, max mem: 15.9 GB 
[10/24 14:25:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6057 s / batch. (data: 1.60e-04). ETA=15:15:34, max mem: 15.9 GB 
[10/24 14:25:56][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.38e-03, avg batch time: 0.6295, average train loss: 150.4878
[10/24 14:26:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 149.712, 0.2249 s / batch. (data: 3.10e-05)max mem: 15.90529 GB 
[10/24 14:26:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2320, average loss: 127.0792
[10/24 14:26:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.77	
[10/24 14:26:57][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 49.03154239845797
[10/24 14:28:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 21.6577,	0.6172 s / batch. (data: 7.14e-04). ETA=15:31:54, max mem: 15.9 GB 
[10/24 14:29:05][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 198.8299,	0.6248 s / batch. (data: 4.51e-04). ETA=15:42:23, max mem: 15.9 GB 
[10/24 14:30:08][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6154 s / batch. (data: 2.99e-04). ETA=15:27:06, max mem: 15.9 GB 
[10/24 14:31:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 9.6503,	0.6358 s / batch. (data: 5.93e-03). ETA=15:56:52, max mem: 15.9 GB 
[10/24 14:32:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 15.4476,	0.6219 s / batch. (data: 1.05e-02). ETA=15:34:46, max mem: 15.9 GB 
[10/24 14:33:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6241 s / batch. (data: 1.10e-03). ETA=15:37:02, max mem: 15.9 GB 
[10/24 14:34:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 148.6887,	0.6267 s / batch. (data: 4.46e-04). ETA=15:39:59, max mem: 15.9 GB 
[10/24 14:35:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 146.2982,	0.6301 s / batch. (data: 4.18e-04). ETA=15:43:58, max mem: 15.9 GB 
[10/24 14:36:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6136 s / batch. (data: 3.40e-04). ETA=15:18:16, max mem: 15.9 GB 
[10/24 14:37:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6186 s / batch. (data: 8.40e-04). ETA=15:24:44, max mem: 15.9 GB 
[10/24 14:38:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 503.0664,	0.6338 s / batch. (data: 1.72e-04). ETA=15:46:25, max mem: 15.9 GB 
[10/24 14:38:34][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.50e-03, avg batch time: 0.6303, average train loss: 134.0912
[10/24 14:39:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 711.233, 0.2318 s / batch. (data: 3.08e-05)max mem: 15.90529 GB 
[10/24 14:39:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2321, average loss: 636.2055
[10/24 14:39:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.58	
[10/24 14:39:35][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 48.77641290737884
[10/24 14:40:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 33.5879,	0.6276 s / batch. (data: 3.13e-04). ETA=15:35:57, max mem: 15.9 GB 
[10/24 14:41:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6129 s / batch. (data: 9.11e-04). ETA=15:13:06, max mem: 15.9 GB 
[10/24 14:42:45][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 67.9599,	0.6413 s / batch. (data: 7.45e-04). ETA=15:54:19, max mem: 15.9 GB 
[10/24 14:43:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 222.0287,	0.6232 s / batch. (data: 2.72e-04). ETA=15:26:19, max mem: 15.9 GB 
[10/24 14:44:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 279.9847,	0.6331 s / batch. (data: 8.15e-04). ETA=15:40:01, max mem: 15.9 GB 
[10/24 14:45:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 308.9604,	0.6406 s / batch. (data: 1.08e-03). ETA=15:50:01, max mem: 15.9 GB 
[10/24 14:46:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 160.1700,	0.6304 s / batch. (data: 7.94e-04). ETA=15:33:51, max mem: 15.9 GB 
[10/24 14:48:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 26.0823,	0.6312 s / batch. (data: 5.45e-04). ETA=15:34:00, max mem: 15.9 GB 
[10/24 14:49:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 527.2388,	0.6272 s / batch. (data: 2.90e-04). ETA=15:27:00, max mem: 15.9 GB 
[10/24 14:50:05][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6218 s / batch. (data: 3.13e-04). ETA=15:18:00, max mem: 15.9 GB 
[10/24 14:51:08][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 68.6914,	0.6183 s / batch. (data: 2.15e-04). ETA=15:11:47, max mem: 15.9 GB 
[10/24 14:51:12][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.76e-03, avg batch time: 0.6308, average train loss: 118.8811
[10/24 14:52:02][INFO] visual_prompt:  303: 	Test 100/123. loss: 73.575, 0.2406 s / batch. (data: 4.27e-05)max mem: 15.90529 GB 
[10/24 14:52:13][INFO] visual_prompt:  316: Inference (val):avg data time: 4.21e-05, avg batch time: 0.2333, average loss: 58.8075
[10/24 14:52:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[10/24 14:52:13][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 48.49231551964771
[10/24 14:53:18][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6388 s / batch. (data: 1.05e-02). ETA=15:40:54, max mem: 15.9 GB 
[10/24 14:54:21][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 273.2705,	0.6395 s / batch. (data: 3.06e-04). ETA=15:40:52, max mem: 15.9 GB 
[10/24 14:55:24][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 82.9776,	0.6203 s / batch. (data: 3.14e-04). ETA=15:11:34, max mem: 15.9 GB 
[10/24 14:56:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 192.9847,	0.6141 s / batch. (data: 2.95e-04). ETA=15:01:26, max mem: 15.9 GB 
[10/24 14:57:30][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 768.8600,	0.6322 s / batch. (data: 3.12e-04). ETA=15:26:57, max mem: 15.9 GB 
[10/24 14:58:33][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 200.4777,	0.6311 s / batch. (data: 8.08e-04). ETA=15:24:25, max mem: 15.9 GB 
[10/24 14:59:36][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 525.6021,	0.6141 s / batch. (data: 3.35e-04). ETA=14:58:29, max mem: 15.9 GB 
[10/24 15:00:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 26.0290,	0.6267 s / batch. (data: 5.40e-03). ETA=15:15:52, max mem: 15.9 GB 
[10/24 15:01:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6363 s / batch. (data: 7.45e-04). ETA=15:28:44, max mem: 15.9 GB 
[10/24 15:02:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 98.0629,	0.6217 s / batch. (data: 3.20e-04). ETA=15:06:24, max mem: 15.9 GB 
[10/24 15:03:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 395.8929,	0.6186 s / batch. (data: 1.70e-04). ETA=15:00:54, max mem: 15.9 GB 
[10/24 15:03:51][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.88e-03, avg batch time: 0.6312, average train loss: 138.9669
[10/24 15:04:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 52.758, 0.2252 s / batch. (data: 3.08e-05)max mem: 15.90529 GB 
[10/24 15:04:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2326, average loss: 37.5159
[10/24 15:04:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 54.53	
[10/24 15:04:52][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 48.17959636416968
[10/24 15:05:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 201.9927,	0.6303 s / batch. (data: 3.22e-04). ETA=15:16:45, max mem: 15.9 GB 
[10/24 15:07:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 215.0100,	0.6330 s / batch. (data: 1.57e-02). ETA=15:19:45, max mem: 15.9 GB 
[10/24 15:08:02][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 263.0182,	0.6316 s / batch. (data: 8.00e-04). ETA=15:16:33, max mem: 15.9 GB 
[10/24 15:09:05][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 42.6809,	0.6330 s / batch. (data: 7.53e-04). ETA=15:17:34, max mem: 15.9 GB 
[10/24 15:10:08][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 51.1411,	0.6180 s / batch. (data: 2.81e-04). ETA=14:54:48, max mem: 15.9 GB 
[10/24 15:11:11][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6281 s / batch. (data: 7.69e-04). ETA=15:08:24, max mem: 15.9 GB 
[10/24 15:12:13][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 530.6969,	0.6312 s / batch. (data: 3.09e-04). ETA=15:11:49, max mem: 15.9 GB 
[10/24 15:13:16][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 634.6000,	0.6244 s / batch. (data: 3.28e-04). ETA=15:01:00, max mem: 15.9 GB 
[10/24 15:14:19][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 87.9417,	0.6166 s / batch. (data: 2.70e-04). ETA=14:48:41, max mem: 15.9 GB 
[10/24 15:15:22][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 8.1747,	0.6617 s / batch. (data: 3.20e-02). ETA=15:52:36, max mem: 15.9 GB 
[10/24 15:16:25][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 132.4765,	0.6170 s / batch. (data: 1.39e-04). ETA=14:47:10, max mem: 15.9 GB 
[10/24 15:16:29][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 4.40e-03, avg batch time: 0.6298, average train loss: 137.9557
[10/24 15:17:18][INFO] visual_prompt:  303: 	Test 100/123. loss: 114.293, 0.2398 s / batch. (data: 3.03e-05)max mem: 15.90529 GB 
[10/24 15:17:29][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2343, average loss: 103.6007
[10/24 15:17:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.14	
[10/24 15:17:29][INFO] visual_prompt:   42: Stopping early.
