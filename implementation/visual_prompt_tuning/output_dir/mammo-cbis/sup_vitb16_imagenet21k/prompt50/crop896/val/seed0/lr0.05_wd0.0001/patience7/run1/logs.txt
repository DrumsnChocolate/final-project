[10/31 10:09:26][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/31 10:09:26][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/31 10:09:26][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/31 10:09:26][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/31 10:09:26][INFO] visual_prompt:  108: Training with config:
[10/31 10:09:26][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/31 10:09:26][INFO] visual_prompt:   55: Loading training data...
[10/31 10:09:26][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/31 10:09:26][INFO] visual_prompt:   57: Loading validation data...
[10/31 10:09:26][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/31 10:09:26][INFO] visual_prompt:   38: Constructing models...
[10/31 10:09:29][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/31 10:09:29][INFO] visual_prompt:   54: tuned percent:0.522
[10/31 10:09:29][INFO] visual_prompt:   40: Device used for model: 0
[10/31 10:09:29][INFO] visual_prompt:   40: Setting up Evaluator...
[10/31 10:09:29][INFO] visual_prompt:   42: Setting up Trainer...
[10/31 10:09:29][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/31 10:09:29][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/31 10:10:35][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6572 s / batch. (data: 1.13e-03). ETA=20:10:23, max mem: 15.9 GB 
[10/31 10:11:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6204 s / batch. (data: 3.77e-04). ETA=19:01:35, max mem: 15.9 GB 
[10/31 10:12:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6523 s / batch. (data: 8.67e-04). ETA=19:59:12, max mem: 15.9 GB 
[10/31 10:13:46][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6308 s / batch. (data: 8.82e-04). ETA=19:18:32, max mem: 15.9 GB 
[10/31 10:14:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6560 s / batch. (data: 1.61e-02). ETA=20:03:49, max mem: 15.9 GB 
[10/31 10:15:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6376 s / batch. (data: 6.02e-03). ETA=19:28:57, max mem: 15.9 GB 
[10/31 10:16:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6477 s / batch. (data: 9.18e-04). ETA=19:46:23, max mem: 15.9 GB 
[10/31 10:18:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6301 s / batch. (data: 1.06e-02). ETA=19:13:03, max mem: 15.9 GB 
[10/31 10:19:05][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6360 s / batch. (data: 3.48e-04). ETA=19:22:51, max mem: 15.9 GB 
[10/31 10:20:09][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6337 s / batch. (data: 8.43e-04). ETA=19:17:35, max mem: 15.9 GB 
[10/31 10:21:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6190 s / batch. (data: 2.12e-04). ETA=18:49:39, max mem: 15.9 GB 
[10/31 10:21:17][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 6.14e-03, avg batch time: 0.6400, average train loss: 1.4028
[10/31 10:22:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2451 s / batch. (data: 4.29e-05)max mem: 15.94594 GB 
[10/31 10:22:23][INFO] visual_prompt:  316: Inference (val):avg data time: 4.67e-05, avg batch time: 0.2325, average loss: 1.3505
[10/31 10:22:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/31 10:22:23][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[10/31 10:23:29][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6521,	0.6360 s / batch. (data: 3.55e-04). ETA=19:19:33, max mem: 15.9 GB 
[10/31 10:24:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7177,	0.6296 s / batch. (data: 1.06e-02). ETA=19:06:52, max mem: 15.9 GB 
[10/31 10:25:36][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9955,	0.6352 s / batch. (data: 1.06e-02). ETA=19:16:02, max mem: 15.9 GB 
[10/31 10:26:40][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1142,	0.6316 s / batch. (data: 1.28e-02). ETA=19:08:24, max mem: 15.9 GB 
[10/31 10:27:44][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7279,	0.6321 s / batch. (data: 7.97e-03). ETA=19:08:16, max mem: 15.9 GB 
[10/31 10:28:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5402,	0.6422 s / batch. (data: 3.85e-04). ETA=19:25:36, max mem: 15.9 GB 
[10/31 10:29:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7548,	0.6353 s / batch. (data: 9.64e-04). ETA=19:12:01, max mem: 15.9 GB 
[10/31 10:30:55][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7634,	0.6280 s / batch. (data: 3.65e-04). ETA=18:57:41, max mem: 15.9 GB 
[10/31 10:31:58][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6604,	0.6288 s / batch. (data: 8.47e-04). ETA=18:57:59, max mem: 15.9 GB 
[10/31 10:33:02][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4841,	0.6309 s / batch. (data: 3.56e-04). ETA=19:00:53, max mem: 15.9 GB 
[10/31 10:34:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7329,	0.6173 s / batch. (data: 1.94e-04). ETA=18:35:14, max mem: 15.9 GB 
[10/31 10:34:09][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 5.82e-03, avg batch time: 0.6386, average train loss: 0.7723
[10/31 10:35:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.046, 0.2357 s / batch. (data: 3.60e-05)max mem: 15.94594 GB 
[10/31 10:35:15][INFO] visual_prompt:  316: Inference (val):avg data time: 4.62e-05, avg batch time: 0.2334, average loss: 0.9228
[10/31 10:35:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.84	
[10/31 10:35:15][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[10/31 10:36:22][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6736,	0.6177 s / batch. (data: 3.53e-04). ETA=18:34:50, max mem: 15.9 GB 
[10/31 10:37:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.3152,	0.6549 s / batch. (data: 1.12e-02). ETA=19:40:47, max mem: 15.9 GB 
[10/31 10:38:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3381,	0.6400 s / batch. (data: 8.38e-04). ETA=19:12:56, max mem: 15.9 GB 
[10/31 10:39:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7652,	0.6334 s / batch. (data: 5.66e-03). ETA=19:00:00, max mem: 15.9 GB 
[10/31 10:40:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3852,	0.6384 s / batch. (data: 8.89e-04). ETA=19:07:59, max mem: 15.9 GB 
[10/31 10:41:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6544,	0.6340 s / batch. (data: 3.63e-04). ETA=18:58:58, max mem: 15.9 GB 
[10/31 10:42:45][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8252,	0.6461 s / batch. (data: 9.24e-04). ETA=19:19:40, max mem: 15.9 GB 
[10/31 10:43:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.3520,	0.6200 s / batch. (data: 8.51e-04). ETA=18:31:43, max mem: 15.9 GB 
[10/31 10:44:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.2172,	0.6466 s / batch. (data: 3.27e-04). ETA=19:18:19, max mem: 15.9 GB 
[10/31 10:45:56][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6742,	0.6281 s / batch. (data: 7.98e-03). ETA=18:44:12, max mem: 15.9 GB 
[10/31 10:47:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5525,	0.6183 s / batch. (data: 2.06e-04). ETA=18:25:38, max mem: 15.9 GB 
[10/31 10:47:04][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 6.59e-03, avg batch time: 0.6402, average train loss: 0.7684
[10/31 10:47:58][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.820, 0.2277 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/31 10:48:10][INFO] visual_prompt:  316: Inference (val):avg data time: 4.96e-05, avg batch time: 0.2328, average loss: 0.7891
[10/31 10:48:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.60	
[10/31 10:48:10][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.015
[10/31 10:49:16][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2430,	0.6387 s / batch. (data: 8.74e-04). ETA=19:00:59, max mem: 15.9 GB 
[10/31 10:50:20][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.0770,	0.6403 s / batch. (data: 3.89e-04). ETA=19:02:44, max mem: 15.9 GB 
[10/31 10:51:23][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6870,	0.6248 s / batch. (data: 5.54e-03). ETA=18:34:03, max mem: 15.9 GB 
[10/31 10:52:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6441,	0.6500 s / batch. (data: 1.59e-02). ETA=19:17:56, max mem: 15.9 GB 
[10/31 10:53:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.2655,	0.6576 s / batch. (data: 3.74e-02). ETA=19:30:18, max mem: 15.9 GB 
[10/31 10:54:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1533,	0.6607 s / batch. (data: 6.05e-03). ETA=19:34:42, max mem: 15.9 GB 
[10/31 10:55:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2892,	0.6396 s / batch. (data: 4.09e-04). ETA=18:56:06, max mem: 15.9 GB 
[10/31 10:56:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1292,	0.6405 s / batch. (data: 8.71e-04). ETA=18:56:45, max mem: 15.9 GB 
[10/31 10:57:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9255,	0.6249 s / batch. (data: 3.66e-04). ETA=18:27:57, max mem: 15.9 GB 
[10/31 10:58:49][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5610,	0.6345 s / batch. (data: 7.92e-03). ETA=18:43:53, max mem: 15.9 GB 
[10/31 10:59:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7328,	0.6193 s / batch. (data: 1.60e-04). ETA=18:15:58, max mem: 15.9 GB 
[10/31 10:59:57][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 5.75e-03, avg batch time: 0.6396, average train loss: 0.7869
[10/31 11:00:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.959, 0.2287 s / batch. (data: 5.65e-05)max mem: 15.94594 GB 
[10/31 11:01:03][INFO] visual_prompt:  316: Inference (val):avg data time: 4.87e-05, avg batch time: 0.2325, average loss: 0.8548
[10/31 11:01:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.17	
[10/31 11:01:03][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[10/31 11:02:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2507,	0.6305 s / batch. (data: 9.83e-04). ETA=18:34:41, max mem: 15.9 GB 
[10/31 11:03:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1092,	0.6660 s / batch. (data: 3.79e-02). ETA=19:36:17, max mem: 15.9 GB 
[10/31 11:04:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7349,	0.6435 s / batch. (data: 9.02e-04). ETA=18:55:31, max mem: 15.9 GB 
[10/31 11:05:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9216,	0.6400 s / batch. (data: 3.70e-04). ETA=18:48:19, max mem: 15.9 GB 
[10/31 11:06:24][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1116,	0.6331 s / batch. (data: 8.56e-04). ETA=18:35:08, max mem: 15.9 GB 
[10/31 11:07:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.7718,	0.6178 s / batch. (data: 3.64e-04). ETA=18:07:02, max mem: 15.9 GB 
[10/31 11:08:32][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6548,	0.6495 s / batch. (data: 6.18e-03). ETA=19:01:50, max mem: 15.9 GB 
[10/31 11:09:35][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.1618,	0.6280 s / batch. (data: 3.55e-04). ETA=18:22:56, max mem: 15.9 GB 
[10/31 11:10:39][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8091,	0.6449 s / batch. (data: 6.04e-03). ETA=18:51:31, max mem: 15.9 GB 
[10/31 11:11:43][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3136,	0.6512 s / batch. (data: 8.62e-04). ETA=19:01:30, max mem: 15.9 GB 
[10/31 11:12:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.9312,	0.6195 s / batch. (data: 2.32e-04). ETA=18:04:50, max mem: 15.9 GB 
[10/31 11:12:51][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 6.37e-03, avg batch time: 0.6394, average train loss: 0.7965
[10/31 11:13:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.954, 0.2345 s / batch. (data: 5.56e-05)max mem: 15.94594 GB 
[10/31 11:13:56][INFO] visual_prompt:  316: Inference (val):avg data time: 4.91e-05, avg batch time: 0.2336, average loss: 0.9521
[10/31 11:13:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.05	
[10/31 11:13:56][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.025
[10/31 11:15:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8128,	0.6331 s / batch. (data: 3.77e-04). ETA=18:27:31, max mem: 15.9 GB 
[10/31 11:16:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4556,	0.6225 s / batch. (data: 3.44e-04). ETA=18:08:00, max mem: 15.9 GB 
[10/31 11:17:10][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0977,	0.6360 s / batch. (data: 1.11e-03). ETA=18:30:29, max mem: 15.9 GB 
[10/31 11:18:13][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8158,	0.6368 s / batch. (data: 3.79e-04). ETA=18:30:49, max mem: 15.9 GB 
[10/31 11:19:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7895,	0.6280 s / batch. (data: 3.81e-04). ETA=18:14:31, max mem: 15.9 GB 
[10/31 11:20:21][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5924,	0.6498 s / batch. (data: 1.59e-02). ETA=18:51:20, max mem: 15.9 GB 
[10/31 11:21:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7618,	0.6193 s / batch. (data: 3.43e-04). ETA=17:57:14, max mem: 15.9 GB 
[10/31 11:22:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7726,	0.6280 s / batch. (data: 3.68e-04). ETA=18:11:21, max mem: 15.9 GB 
[10/31 11:23:32][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3919,	0.6572 s / batch. (data: 3.56e-04). ETA=19:01:05, max mem: 15.9 GB 
[10/31 11:24:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.1374,	0.6440 s / batch. (data: 8.85e-04). ETA=18:36:59, max mem: 15.9 GB 
[10/31 11:25:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6128,	0.6191 s / batch. (data: 2.44e-04). ETA=17:52:47, max mem: 15.9 GB 
[10/31 11:25:44][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 5.54e-03, avg batch time: 0.6392, average train loss: 0.7776
[10/31 11:26:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.860, 0.2267 s / batch. (data: 5.13e-05)max mem: 15.94594 GB 
[10/31 11:26:49][INFO] visual_prompt:  316: Inference (val):avg data time: 5.00e-05, avg batch time: 0.2324, average loss: 0.7722
[10/31 11:26:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.76	
[10/31 11:26:50][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.03
[10/31 11:27:55][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6730,	0.6228 s / batch. (data: 5.58e-03). ETA=17:58:07, max mem: 15.9 GB 
[10/31 11:28:59][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9190,	0.6459 s / batch. (data: 1.11e-02). ETA=18:37:02, max mem: 15.9 GB 
[10/31 11:30:02][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7803,	0.6360 s / batch. (data: 3.53e-04). ETA=18:18:49, max mem: 15.9 GB 
[10/31 11:31:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0611,	0.6507 s / batch. (data: 6.03e-03). ETA=18:43:07, max mem: 15.9 GB 
[10/31 11:32:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6466,	0.6444 s / batch. (data: 5.52e-03). ETA=18:31:15, max mem: 15.9 GB 
[10/31 11:33:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6907,	0.6429 s / batch. (data: 8.64e-04). ETA=18:27:35, max mem: 15.9 GB 
[10/31 11:34:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3743,	0.6262 s / batch. (data: 5.53e-03). ETA=17:57:43, max mem: 15.9 GB 
[10/31 11:35:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2990,	0.6309 s / batch. (data: 8.83e-04). ETA=18:04:41, max mem: 15.9 GB 
[10/31 11:36:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7203,	0.6337 s / batch. (data: 8.98e-04). ETA=18:08:33, max mem: 15.9 GB 
[10/31 11:37:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8429,	0.6472 s / batch. (data: 8.73e-04). ETA=18:30:39, max mem: 15.9 GB 
[10/31 11:38:33][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4272,	0.6178 s / batch. (data: 2.24e-04). ETA=17:39:04, max mem: 15.9 GB 
[10/31 11:38:37][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 5.22e-03, avg batch time: 0.6393, average train loss: 0.7703
[10/31 11:39:31][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.786, 0.2348 s / batch. (data: 6.89e-05)max mem: 15.94594 GB 
[10/31 11:39:43][INFO] visual_prompt:  316: Inference (val):avg data time: 4.82e-05, avg batch time: 0.2331, average loss: 0.7213
[10/31 11:39:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.49	
[10/31 11:39:43][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[10/31 11:40:49][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6948,	0.6531 s / batch. (data: 1.31e-02). ETA=18:38:28, max mem: 15.9 GB 
[10/31 11:41:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8170,	0.6178 s / batch. (data: 5.22e-04). ETA=17:37:01, max mem: 15.9 GB 
[10/31 11:42:56][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2462,	0.6519 s / batch. (data: 2.90e-02). ETA=18:34:13, max mem: 15.9 GB 
[10/31 11:44:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.3872,	0.6337 s / batch. (data: 5.57e-03). ETA=18:02:10, max mem: 15.9 GB 
[10/31 11:45:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.3694,	0.6324 s / batch. (data: 8.56e-04). ETA=17:58:48, max mem: 15.9 GB 
[10/31 11:46:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1452,	0.6510 s / batch. (data: 6.03e-03). ETA=18:29:26, max mem: 15.9 GB 
[10/31 11:47:11][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9829,	0.6639 s / batch. (data: 4.08e-02). ETA=18:50:25, max mem: 15.9 GB 
[10/31 11:48:15][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9251,	0.6238 s / batch. (data: 3.43e-04). ETA=17:41:01, max mem: 15.9 GB 
[10/31 11:49:18][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.2230,	0.6313 s / batch. (data: 3.69e-04). ETA=17:52:42, max mem: 15.9 GB 
[10/31 11:50:22][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.4853,	0.6314 s / batch. (data: 8.83e-04). ETA=17:51:57, max mem: 15.9 GB 
[10/31 11:51:26][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6046,	0.6195 s / batch. (data: 1.91e-04). ETA=17:30:37, max mem: 15.9 GB 
[10/31 11:51:30][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 6.35e-03, avg batch time: 0.6394, average train loss: 0.8200
[10/31 11:52:25][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.879, 0.2251 s / batch. (data: 3.15e-05)max mem: 15.94594 GB 
[10/31 11:52:36][INFO] visual_prompt:  316: Inference (val):avg data time: 4.78e-05, avg batch time: 0.2327, average loss: 0.8663
[10/31 11:52:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.40	
[10/31 11:52:36][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[10/31 11:53:43][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2897,	0.6262 s / batch. (data: 6.07e-03). ETA=17:40:50, max mem: 15.9 GB 
[10/31 11:54:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.2177,	0.6480 s / batch. (data: 5.50e-03). ETA=18:16:45, max mem: 15.9 GB 
[10/31 11:55:50][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0373,	0.6187 s / batch. (data: 3.40e-04). ETA=17:26:07, max mem: 15.9 GB 
[10/31 11:56:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7067,	0.6359 s / batch. (data: 3.51e-04). ETA=17:54:07, max mem: 15.9 GB 
[10/31 11:57:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7300,	0.6211 s / batch. (data: 3.49e-04). ETA=17:28:09, max mem: 15.9 GB 
[10/31 11:59:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6693,	0.6468 s / batch. (data: 6.06e-03). ETA=18:10:24, max mem: 15.9 GB 
[10/31 12:00:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.4163,	0.6216 s / batch. (data: 3.66e-04). ETA=17:26:50, max mem: 15.9 GB 
[10/31 12:01:09][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8188,	0.6439 s / batch. (data: 3.38e-04). ETA=18:03:27, max mem: 15.9 GB 
[10/31 12:02:13][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8848,	0.6440 s / batch. (data: 3.88e-04). ETA=18:02:28, max mem: 15.9 GB 
[10/31 12:03:17][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8661,	0.6368 s / batch. (data: 3.14e-04). ETA=17:49:20, max mem: 15.9 GB 
[10/31 12:04:20][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7573,	0.6178 s / batch. (data: 1.72e-04). ETA=17:16:18, max mem: 15.9 GB 
[10/31 12:04:24][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 7.49e-03, avg batch time: 0.6401, average train loss: 0.7698
[10/31 12:05:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.751, 0.2290 s / batch. (data: 5.15e-05)max mem: 15.94594 GB 
[10/31 12:05:30][INFO] visual_prompt:  316: Inference (val):avg data time: 2.64e-04, avg batch time: 0.2333, average loss: 0.7103
[10/31 12:05:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 56.40	
[10/31 12:05:30][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[10/31 12:06:37][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8053,	0.6421 s / batch. (data: 1.19e-02). ETA=17:56:01, max mem: 15.9 GB 
[10/31 12:07:40][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1989,	0.6537 s / batch. (data: 1.06e-02). ETA=18:14:21, max mem: 15.9 GB 
[10/31 12:08:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0055,	0.6535 s / batch. (data: 2.09e-02). ETA=18:12:52, max mem: 15.9 GB 
[10/31 12:09:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6311,	0.6320 s / batch. (data: 1.20e-02). ETA=17:35:56, max mem: 15.9 GB 
[10/31 12:10:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7410,	0.6182 s / batch. (data: 3.69e-04). ETA=17:11:54, max mem: 15.9 GB 
[10/31 12:11:55][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5529,	0.6278 s / batch. (data: 4.06e-04). ETA=17:26:46, max mem: 15.9 GB 
[10/31 12:12:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1195,	0.6439 s / batch. (data: 8.79e-04). ETA=17:52:31, max mem: 15.9 GB 
[10/31 12:14:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7949,	0.6332 s / batch. (data: 8.64e-04). ETA=17:33:46, max mem: 15.9 GB 
[10/31 12:15:06][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6271,	0.6197 s / batch. (data: 3.42e-04). ETA=17:10:14, max mem: 15.9 GB 
[10/31 12:16:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7992,	0.6338 s / batch. (data: 3.51e-04). ETA=17:32:40, max mem: 15.9 GB 
[10/31 12:17:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2767,	0.6168 s / batch. (data: 1.70e-04). ETA=17:03:16, max mem: 15.9 GB 
[10/31 12:17:18][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 6.35e-03, avg batch time: 0.6395, average train loss: 0.8650
[10/31 12:18:12][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.719, 0.2263 s / batch. (data: 3.08e-05)max mem: 15.94594 GB 
[10/31 12:18:24][INFO] visual_prompt:  316: Inference (val):avg data time: 1.36e-04, avg batch time: 0.2314, average loss: 0.6837
[10/31 12:18:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 56.83	
[10/31 12:18:24][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.05
[10/31 12:19:31][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5624,	0.6497 s / batch. (data: 6.09e-03). ETA=17:56:47, max mem: 15.9 GB 
[10/31 12:20:34][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1968,	0.6360 s / batch. (data: 3.45e-04). ETA=17:32:57, max mem: 15.9 GB 
[10/31 12:21:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8948,	0.6488 s / batch. (data: 1.85e-02). ETA=17:53:03, max mem: 15.9 GB 
[10/31 12:22:42][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2578,	0.6240 s / batch. (data: 3.30e-04). ETA=17:11:01, max mem: 15.9 GB 
[10/31 12:23:45][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2248,	0.6312 s / batch. (data: 3.86e-04). ETA=17:21:55, max mem: 15.9 GB 
[10/31 12:24:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1888,	0.6341 s / batch. (data: 1.24e-03). ETA=17:25:37, max mem: 15.9 GB 
[10/31 12:25:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1638,	0.6388 s / batch. (data: 3.98e-04). ETA=17:32:16, max mem: 15.9 GB 
[10/31 12:26:57][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2628,	0.6360 s / batch. (data: 8.26e-04). ETA=17:26:38, max mem: 15.9 GB 
[10/31 12:28:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3986,	0.6400 s / batch. (data: 8.77e-04). ETA=17:32:09, max mem: 15.9 GB 
[10/31 12:29:04][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3073,	0.6369 s / batch. (data: 1.89e-02). ETA=17:25:57, max mem: 15.9 GB 
[10/31 12:30:08][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0317,	0.6183 s / batch. (data: 2.11e-04). ETA=16:54:25, max mem: 15.9 GB 
[10/31 12:30:12][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 6.66e-03, avg batch time: 0.6403, average train loss: 0.7896
[10/31 12:31:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.692, 0.2414 s / batch. (data: 5.46e-05)max mem: 15.94594 GB 
[10/31 12:31:18][INFO] visual_prompt:  316: Inference (val):avg data time: 5.34e-05, avg batch time: 0.2332, average loss: 0.6810
[10/31 12:31:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.61	
[10/31 12:31:18][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[10/31 12:32:25][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3649,	0.6375 s / batch. (data: 1.08e-02). ETA=17:24:49, max mem: 15.9 GB 
[10/31 12:33:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7479,	0.6308 s / batch. (data: 8.90e-04). ETA=17:12:49, max mem: 15.9 GB 
[10/31 12:34:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1063,	0.6305 s / batch. (data: 4.14e-04). ETA=17:11:15, max mem: 15.9 GB 
[10/31 12:35:36][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6878,	0.6480 s / batch. (data: 1.38e-02). ETA=17:38:42, max mem: 15.9 GB 
[10/31 12:36:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.5399,	0.6423 s / batch. (data: 8.57e-04). ETA=17:28:24, max mem: 15.9 GB 
[10/31 12:37:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6292,	0.6289 s / batch. (data: 4.22e-04). ETA=17:05:23, max mem: 15.9 GB 
[10/31 12:38:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5914,	0.6440 s / batch. (data: 5.50e-03). ETA=17:29:02, max mem: 15.9 GB 
[10/31 12:39:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7755,	0.6275 s / batch. (data: 3.59e-04). ETA=17:01:05, max mem: 15.9 GB 
[10/31 12:40:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1518,	0.6320 s / batch. (data: 3.56e-04). ETA=17:07:20, max mem: 15.9 GB 
[10/31 12:41:59][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.9895,	0.6344 s / batch. (data: 8.66e-04). ETA=17:10:07, max mem: 15.9 GB 
[10/31 12:43:02][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7311,	0.6188 s / batch. (data: 2.54e-04). ETA=16:43:46, max mem: 15.9 GB 
[10/31 12:43:06][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 7.04e-03, avg batch time: 0.6405, average train loss: 0.8030
[10/31 12:44:01][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.742, 0.2353 s / batch. (data: 5.15e-05)max mem: 15.94594 GB 
[10/31 12:44:12][INFO] visual_prompt:  316: Inference (val):avg data time: 4.89e-05, avg batch time: 0.2327, average loss: 1.8261
[10/31 12:44:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.82	
[10/31 12:44:12][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[10/31 12:45:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1701,	0.6178 s / batch. (data: 3.69e-04). ETA=16:41:03, max mem: 15.9 GB 
[10/31 12:46:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6845,	0.6248 s / batch. (data: 5.52e-03). ETA=16:51:27, max mem: 15.9 GB 
[10/31 12:47:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3759,	0.6443 s / batch. (data: 9.58e-04). ETA=17:21:57, max mem: 15.9 GB 
[10/31 12:48:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7352,	0.6340 s / batch. (data: 8.67e-04). ETA=17:04:15, max mem: 15.9 GB 
[10/31 12:49:33][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1710,	0.6317 s / batch. (data: 8.73e-04). ETA=16:59:23, max mem: 15.9 GB 
[10/31 12:50:37][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9917,	0.6392 s / batch. (data: 8.33e-04). ETA=17:10:30, max mem: 15.9 GB 
[10/31 12:51:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8888,	0.6462 s / batch. (data: 8.76e-04). ETA=17:20:43, max mem: 15.9 GB 
[10/31 12:52:45][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.3509,	0.6335 s / batch. (data: 8.98e-04). ETA=16:59:14, max mem: 15.9 GB 
[10/31 12:53:48][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.0239,	0.6198 s / batch. (data: 4.00e-04). ETA=16:36:05, max mem: 15.9 GB 
[10/31 12:54:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3088,	0.6189 s / batch. (data: 3.49e-04). ETA=16:33:33, max mem: 15.9 GB 
[10/31 12:55:56][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7253,	0.6334 s / batch. (data: 2.23e-04). ETA=16:55:47, max mem: 15.9 GB 
[10/31 12:55:59][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 6.08e-03, avg batch time: 0.6397, average train loss: 0.8028
[10/31 12:56:54][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.834, 0.2270 s / batch. (data: 5.10e-05)max mem: 15.94594 GB 
[10/31 12:57:06][INFO] visual_prompt:  316: Inference (val):avg data time: 1.36e-04, avg batch time: 0.2332, average loss: 0.7972
[10/31 12:57:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[10/31 12:57:06][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[10/31 12:58:12][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7349,	0.6275 s / batch. (data: 3.54e-04). ETA=16:45:14, max mem: 15.9 GB 
[10/31 12:59:16][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9165,	0.6245 s / batch. (data: 5.53e-03). ETA=16:39:28, max mem: 15.9 GB 
[10/31 13:00:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7024,	0.6493 s / batch. (data: 8.74e-04). ETA=17:17:58, max mem: 15.9 GB 
[10/31 13:01:24][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.4414,	0.6399 s / batch. (data: 2.07e-02). ETA=17:01:54, max mem: 15.9 GB 
[10/31 13:02:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7071,	0.6446 s / batch. (data: 9.01e-04). ETA=17:08:18, max mem: 15.9 GB 
[10/31 13:03:31][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5861,	0.6390 s / batch. (data: 3.46e-04). ETA=16:58:26, max mem: 15.9 GB 
[10/31 13:04:35][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.2033,	0.6477 s / batch. (data: 8.61e-04). ETA=17:11:08, max mem: 15.9 GB 
[10/31 13:05:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6309,	0.6341 s / batch. (data: 9.22e-04). ETA=16:48:30, max mem: 15.9 GB 
[10/31 13:06:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9055,	0.6280 s / batch. (data: 4.53e-04). ETA=16:37:43, max mem: 15.9 GB 
[10/31 13:07:46][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0596,	0.6485 s / batch. (data: 5.53e-03). ETA=17:09:11, max mem: 15.9 GB 
[10/31 13:08:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0850,	0.6186 s / batch. (data: 1.60e-04). ETA=16:20:39, max mem: 15.9 GB 
[10/31 13:08:54][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 6.65e-03, avg batch time: 0.6402, average train loss: 0.7701
[10/31 13:09:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.974, 0.2386 s / batch. (data: 3.79e-05)max mem: 15.94594 GB 
[10/31 13:10:00][INFO] visual_prompt:  316: Inference (val):avg data time: 5.16e-05, avg batch time: 0.2330, average loss: 0.9046
[10/31 13:10:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.01	
[10/31 13:10:00][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[10/31 13:11:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7595,	0.6459 s / batch. (data: 8.71e-04). ETA=17:02:53, max mem: 15.9 GB 
[10/31 13:12:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8524,	0.6589 s / batch. (data: 8.69e-04). ETA=17:22:16, max mem: 15.9 GB 
[10/31 13:13:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6416,	0.6360 s / batch. (data: 4.01e-04). ETA=16:44:58, max mem: 15.9 GB 
[10/31 13:14:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8867,	0.6272 s / batch. (data: 3.52e-04). ETA=16:30:02, max mem: 15.9 GB 
[10/31 13:15:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2716,	0.6602 s / batch. (data: 3.22e-02). ETA=17:21:05, max mem: 15.9 GB 
[10/31 13:16:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0923,	0.6400 s / batch. (data: 8.40e-04). ETA=16:48:10, max mem: 15.9 GB 
[10/31 13:17:28][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5568,	0.6480 s / batch. (data: 3.40e-04). ETA=16:59:43, max mem: 15.9 GB 
[10/31 13:18:32][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5644,	0.6375 s / batch. (data: 6.12e-03). ETA=16:42:06, max mem: 15.9 GB 
[10/31 13:19:36][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7652,	0.6517 s / batch. (data: 6.07e-03). ETA=17:03:20, max mem: 15.9 GB 
[10/31 13:20:39][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5747,	0.6313 s / batch. (data: 3.72e-04). ETA=16:30:12, max mem: 15.9 GB 
[10/31 13:21:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.9030,	0.6196 s / batch. (data: 2.34e-04). ETA=16:10:54, max mem: 15.9 GB 
[10/31 13:21:47][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 5.85e-03, avg batch time: 0.6391, average train loss: 0.8073
[10/31 13:22:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.896, 0.2258 s / batch. (data: 5.58e-05)max mem: 15.94594 GB 
[10/31 13:22:53][INFO] visual_prompt:  316: Inference (val):avg data time: 5.08e-05, avg batch time: 0.2327, average loss: 0.8356
[10/31 13:22:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[10/31 13:22:53][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[10/31 13:23:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4105,	0.6474 s / batch. (data: 1.70e-02). ETA=16:53:19, max mem: 15.9 GB 
[10/31 13:25:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7036,	0.6174 s / batch. (data: 3.47e-04). ETA=16:05:19, max mem: 15.9 GB 
[10/31 13:26:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7002,	0.6488 s / batch. (data: 1.05e-03). ETA=16:53:21, max mem: 15.9 GB 
[10/31 13:27:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7176,	0.6380 s / batch. (data: 3.91e-04). ETA=16:35:25, max mem: 15.9 GB 
[10/31 13:28:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7944,	0.6600 s / batch. (data: 1.11e-03). ETA=17:08:36, max mem: 15.9 GB 
[10/31 13:29:17][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.4158,	0.6294 s / batch. (data: 1.07e-02). ETA=16:19:48, max mem: 15.9 GB 
[10/31 13:30:21][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0836,	0.6400 s / batch. (data: 3.55e-04). ETA=16:35:16, max mem: 15.9 GB 
[10/31 13:31:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7482,	0.6280 s / batch. (data: 3.75e-04). ETA=16:15:35, max mem: 15.9 GB 
[10/31 13:32:28][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5697,	0.6353 s / batch. (data: 8.61e-04). ETA=16:25:50, max mem: 15.9 GB 
[10/31 13:33:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.0199,	0.6400 s / batch. (data: 3.53e-04). ETA=16:32:06, max mem: 15.9 GB 
[10/31 13:34:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2683,	0.6176 s / batch. (data: 2.01e-04). ETA=15:56:22, max mem: 15.9 GB 
[10/31 13:34:40][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 5.70e-03, avg batch time: 0.6392, average train loss: 0.7641
[10/31 13:35:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.696, 0.2288 s / batch. (data: 5.13e-05)max mem: 15.94594 GB 
[10/31 13:35:46][INFO] visual_prompt:  316: Inference (val):avg data time: 7.65e-05, avg batch time: 0.2327, average loss: 0.6691
[10/31 13:35:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 62.18	
[10/31 13:35:46][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.669
[10/31 13:35:46][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[10/31 13:36:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4815,	0.6605 s / batch. (data: 1.11e-02). ETA=17:01:34, max mem: 15.9 GB 
[10/31 13:37:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6240,	0.6321 s / batch. (data: 9.71e-04). ETA=16:16:37, max mem: 15.9 GB 
[10/31 13:39:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7965,	0.6717 s / batch. (data: 3.56e-02). ETA=17:16:40, max mem: 15.9 GB 
[10/31 13:40:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.7708,	0.6784 s / batch. (data: 3.23e-02). ETA=17:25:50, max mem: 15.9 GB 
[10/31 13:41:07][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2242,	0.6614 s / batch. (data: 2.53e-02). ETA=16:58:31, max mem: 15.9 GB 
[10/31 13:42:11][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0333,	0.6413 s / batch. (data: 6.03e-03). ETA=16:26:35, max mem: 15.9 GB 
[10/31 13:43:14][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7510,	0.6603 s / batch. (data: 1.11e-02). ETA=16:54:39, max mem: 15.9 GB 
[10/31 13:44:18][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8543,	0.6321 s / batch. (data: 3.46e-04). ETA=16:10:16, max mem: 15.9 GB 
[10/31 13:45:22][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9477,	0.6317 s / batch. (data: 3.44e-04). ETA=16:08:41, max mem: 15.9 GB 
[10/31 13:46:25][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0472,	0.6582 s / batch. (data: 3.83e-02). ETA=16:48:13, max mem: 15.9 GB 
[10/31 13:47:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2036,	0.6184 s / batch. (data: 2.10e-04). ETA=15:46:09, max mem: 15.9 GB 
[10/31 13:47:33][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 5.93e-03, avg batch time: 0.6391, average train loss: 0.8111
[10/31 13:48:28][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.697, 0.2359 s / batch. (data: 5.20e-05)max mem: 15.94594 GB 
[10/31 13:48:39][INFO] visual_prompt:  316: Inference (val):avg data time: 4.79e-05, avg batch time: 0.2317, average loss: 0.7078
[10/31 13:48:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.47	
[10/31 13:48:39][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[10/31 13:49:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2871,	0.6380 s / batch. (data: 1.01e-03). ETA=16:15:02, max mem: 15.9 GB 
[10/31 13:50:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9365,	0.6491 s / batch. (data: 1.92e-02). ETA=16:30:58, max mem: 15.9 GB 
[10/31 13:51:53][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.0739,	0.6490 s / batch. (data: 5.52e-03). ETA=16:29:44, max mem: 15.9 GB 
[10/31 13:52:56][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6916,	0.6552 s / batch. (data: 6.02e-03). ETA=16:38:06, max mem: 15.9 GB 
[10/31 13:54:00][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1344,	0.6370 s / batch. (data: 8.66e-04). ETA=16:09:19, max mem: 15.9 GB 
[10/31 13:55:04][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6563,	0.6280 s / batch. (data: 3.27e-04). ETA=15:54:31, max mem: 15.9 GB 
[10/31 13:56:07][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8053,	0.6572 s / batch. (data: 8.95e-04). ETA=16:37:51, max mem: 15.9 GB 
[10/31 13:57:11][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7315,	0.6222 s / batch. (data: 3.39e-04). ETA=15:43:41, max mem: 15.9 GB 
[10/31 13:58:15][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1157,	0.6614 s / batch. (data: 1.74e-02). ETA=16:42:02, max mem: 15.9 GB 
[10/31 13:59:18][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7631,	0.6579 s / batch. (data: 1.19e-03). ETA=16:35:32, max mem: 15.9 GB 
[10/31 14:00:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5626,	0.6193 s / batch. (data: 2.21e-04). ETA=15:36:06, max mem: 15.9 GB 
[10/31 14:00:26][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 5.88e-03, avg batch time: 0.6390, average train loss: 0.8585
[10/31 14:01:21][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.664, 0.2250 s / batch. (data: 2.91e-05)max mem: 15.94594 GB 
[10/31 14:01:32][INFO] visual_prompt:  316: Inference (val):avg data time: 2.66e-04, avg batch time: 0.2331, average loss: 0.6768
[10/31 14:01:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 59.80	
[10/31 14:01:32][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[10/31 14:02:39][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2455,	0.6425 s / batch. (data: 1.45e-02). ETA=16:10:05, max mem: 15.9 GB 
[10/31 14:03:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7967,	0.6248 s / batch. (data: 3.71e-04). ETA=15:42:23, max mem: 15.9 GB 
[10/31 14:04:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3311,	0.6400 s / batch. (data: 5.68e-04). ETA=16:04:08, max mem: 15.9 GB 
[10/31 14:05:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7202,	0.6180 s / batch. (data: 3.72e-04). ETA=15:29:57, max mem: 15.9 GB 
[10/31 14:06:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6471,	0.6190 s / batch. (data: 3.59e-04). ETA=15:30:27, max mem: 15.9 GB 
[10/31 14:07:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1389,	0.6276 s / batch. (data: 4.64e-04). ETA=15:42:19, max mem: 15.9 GB 
[10/31 14:09:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6700,	0.6401 s / batch. (data: 8.89e-04). ETA=16:00:05, max mem: 15.9 GB 
[10/31 14:10:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1543,	0.6210 s / batch. (data: 3.57e-04). ETA=15:30:26, max mem: 15.9 GB 
[10/31 14:11:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5137,	0.6369 s / batch. (data: 1.84e-02). ETA=15:53:07, max mem: 15.9 GB 
[10/31 14:12:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.9625,	0.6440 s / batch. (data: 8.62e-04). ETA=16:02:38, max mem: 15.9 GB 
[10/31 14:13:16][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8794,	0.6235 s / batch. (data: 2.13e-04). ETA=15:31:00, max mem: 15.9 GB 
[10/31 14:13:20][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 6.58e-03, avg batch time: 0.6402, average train loss: 0.7508
[10/31 14:14:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.195, 0.2287 s / batch. (data: 5.29e-05)max mem: 15.94594 GB 
[10/31 14:14:26][INFO] visual_prompt:  316: Inference (val):avg data time: 4.90e-05, avg batch time: 0.2323, average loss: 1.0782
[10/31 14:14:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.91	
[10/31 14:14:26][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[10/31 14:15:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7162,	0.6435 s / batch. (data: 8.85e-04). ETA=15:59:46, max mem: 15.9 GB 
[10/31 14:16:37][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.3318,	0.6208 s / batch. (data: 3.42e-04). ETA=15:24:51, max mem: 15.9 GB 
[10/31 14:17:41][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5189,	0.6530 s / batch. (data: 9.15e-04). ETA=16:11:40, max mem: 15.9 GB 
[10/31 14:18:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.4939,	0.6438 s / batch. (data: 5.30e-04). ETA=15:56:54, max mem: 15.9 GB 
[10/31 14:19:49][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.4824,	0.6233 s / batch. (data: 5.52e-03). ETA=15:25:26, max mem: 15.9 GB 
[10/31 14:20:53][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9348,	0.6400 s / batch. (data: 9.14e-04). ETA=15:49:09, max mem: 15.9 GB 
[10/31 14:21:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5502,	0.6600 s / batch. (data: 1.20e-02). ETA=16:17:44, max mem: 15.9 GB 
[10/31 14:23:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6194,	0.6421 s / batch. (data: 8.70e-04). ETA=15:50:11, max mem: 15.9 GB 
[10/31 14:24:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5597,	0.6187 s / batch. (data: 3.98e-04). ETA=15:14:34, max mem: 15.9 GB 
[10/31 14:25:08][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6247,	0.6288 s / batch. (data: 3.55e-04). ETA=15:28:25, max mem: 15.9 GB 
[10/31 14:26:11][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.3928,	0.6195 s / batch. (data: 1.89e-04). ETA=15:13:37, max mem: 15.9 GB 
[10/31 14:26:15][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 7.08e-03, avg batch time: 0.6407, average train loss: 0.7649
[10/31 14:27:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.911, 0.2395 s / batch. (data: 5.39e-05)max mem: 15.94594 GB 
[10/31 14:27:21][INFO] visual_prompt:  316: Inference (val):avg data time: 1.37e-04, avg batch time: 0.2331, average loss: 1.0182
[10/31 14:27:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.41	
[10/31 14:27:21][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[10/31 14:28:28][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5561,	0.6400 s / batch. (data: 7.97e-03). ETA=15:42:43, max mem: 15.9 GB 
[10/31 14:29:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5786,	0.6310 s / batch. (data: 3.72e-04). ETA=15:28:25, max mem: 15.9 GB 
[10/31 14:30:37][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4490,	0.6312 s / batch. (data: 3.54e-04). ETA=15:27:36, max mem: 15.9 GB 
[10/31 14:31:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9038,	0.6297 s / batch. (data: 5.55e-03). ETA=15:24:21, max mem: 15.9 GB 
[10/31 14:32:44][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2516,	0.6606 s / batch. (data: 3.91e-04). ETA=16:08:36, max mem: 15.9 GB 
[10/31 14:33:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.7614,	0.6560 s / batch. (data: 9.27e-04). ETA=16:00:48, max mem: 15.9 GB 
[10/31 14:34:52][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7938,	0.6187 s / batch. (data: 8.70e-04). ETA=15:05:11, max mem: 15.9 GB 
[10/31 14:35:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7954,	0.6560 s / batch. (data: 8.42e-04). ETA=15:58:38, max mem: 15.9 GB 
[10/31 14:36:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0692,	0.6320 s / batch. (data: 3.55e-04). ETA=15:22:28, max mem: 15.9 GB 
[10/31 14:38:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6712,	0.6205 s / batch. (data: 4.63e-04). ETA=15:04:43, max mem: 15.9 GB 
[10/31 14:39:07][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6999,	0.6201 s / batch. (data: 1.86e-04). ETA=15:03:06, max mem: 15.9 GB 
[10/31 14:39:10][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 6.70e-03, avg batch time: 0.6413, average train loss: 0.7676
[10/31 14:40:05][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.623, 0.2325 s / batch. (data: 5.17e-05)max mem: 15.94594 GB 
[10/31 14:40:17][INFO] visual_prompt:  316: Inference (val):avg data time: 1.05e-04, avg batch time: 0.2323, average loss: 0.7015
[10/31 14:40:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 61.83	
[10/31 14:40:17][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[10/31 14:41:23][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2195,	0.6540 s / batch. (data: 8.32e-04). ETA=15:51:13, max mem: 15.9 GB 
[10/31 14:42:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.3997,	0.6418 s / batch. (data: 3.79e-04). ETA=15:32:26, max mem: 15.9 GB 
[10/31 14:43:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8213,	0.6304 s / batch. (data: 5.50e-03). ETA=15:14:52, max mem: 15.9 GB 
[10/31 14:44:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1859,	0.6278 s / batch. (data: 6.75e-04). ETA=15:09:58, max mem: 15.9 GB 
[10/31 14:45:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.3183,	0.6366 s / batch. (data: 8.97e-04). ETA=15:21:47, max mem: 15.9 GB 
[10/31 14:46:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.3142,	0.6185 s / batch. (data: 3.82e-04). ETA=14:54:31, max mem: 15.9 GB 
[10/31 14:47:45][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.4522,	0.6199 s / batch. (data: 3.73e-04). ETA=14:55:24, max mem: 15.9 GB 
[10/31 14:48:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8042,	0.6204 s / batch. (data: 3.77e-04). ETA=14:55:08, max mem: 15.9 GB 
[10/31 14:49:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8736,	0.6320 s / batch. (data: 1.20e-02). ETA=15:10:54, max mem: 15.9 GB 
[10/31 14:50:56][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6518,	0.6481 s / batch. (data: 3.55e-04). ETA=15:32:54, max mem: 15.9 GB 
[10/31 14:52:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4167,	0.6196 s / batch. (data: 2.01e-04). ETA=14:50:53, max mem: 15.9 GB 
[10/31 14:52:04][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 6.11e-03, avg batch time: 0.6391, average train loss: 0.7399
[10/31 14:52:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.610, 0.2249 s / batch. (data: 5.94e-05)max mem: 15.94594 GB 
[10/31 14:53:10][INFO] visual_prompt:  316: Inference (val):avg data time: 1.23e-04, avg batch time: 0.2334, average loss: 0.7382
[10/31 14:53:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.27	
[10/31 14:53:10][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[10/31 14:54:17][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5677,	0.6293 s / batch. (data: 3.75e-04). ETA=15:03:49, max mem: 15.9 GB 
[10/31 14:55:21][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7651,	0.6569 s / batch. (data: 1.06e-02). ETA=15:42:18, max mem: 15.9 GB 
[10/31 14:56:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7823,	0.6330 s / batch. (data: 3.72e-04). ETA=15:06:53, max mem: 15.9 GB 
[10/31 14:57:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7551,	0.6480 s / batch. (data: 9.07e-04). ETA=15:27:24, max mem: 15.9 GB 
[10/31 14:58:32][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6764,	0.6414 s / batch. (data: 8.95e-04). ETA=15:16:49, max mem: 15.9 GB 
[10/31 14:59:36][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6478,	0.6416 s / batch. (data: 8.77e-04). ETA=15:16:08, max mem: 15.9 GB 
[10/31 15:00:39][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6489,	0.6309 s / batch. (data: 3.59e-04). ETA=14:59:43, max mem: 15.9 GB 
[10/31 15:01:43][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7414,	0.6331 s / batch. (data: 3.96e-04). ETA=15:01:49, max mem: 15.9 GB 
[10/31 15:02:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7897,	0.6320 s / batch. (data: 3.66e-04). ETA=14:59:10, max mem: 15.9 GB 
[10/31 15:03:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6041,	0.6280 s / batch. (data: 5.51e-03). ETA=14:52:27, max mem: 15.9 GB 
[10/31 15:04:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6611,	0.6186 s / batch. (data: 1.83e-04). ETA=14:38:01, max mem: 15.9 GB 
[10/31 15:04:58][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 6.61e-03, avg batch time: 0.6399, average train loss: 0.7506
[10/31 15:05:52][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.693, 0.2253 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/31 15:06:04][INFO] visual_prompt:  316: Inference (val):avg data time: 4.83e-05, avg batch time: 0.2319, average loss: 0.6790
[10/31 15:06:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.20	
[10/31 15:06:04][INFO] visual_prompt:   42: Stopping early.
