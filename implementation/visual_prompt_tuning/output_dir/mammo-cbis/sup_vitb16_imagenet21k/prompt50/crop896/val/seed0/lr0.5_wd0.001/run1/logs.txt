[10/28 19:41:35][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/28 19:41:35][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/28 19:41:35][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/28 19:41:35][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/28 19:41:35][INFO] visual_prompt:  108: Training with config:
[10/28 19:41:35][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/28 19:41:35][INFO] visual_prompt:   55: Loading training data...
[10/28 19:41:35][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/28 19:41:35][INFO] visual_prompt:   57: Loading validation data...
[10/28 19:41:35][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/28 19:41:35][INFO] visual_prompt:   38: Constructing models...
[10/28 19:41:38][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/28 19:41:38][INFO] visual_prompt:   54: tuned percent:0.522
[10/28 19:41:38][INFO] visual_prompt:   40: Device used for model: 0
[10/28 19:41:38][INFO] visual_prompt:   40: Setting up Evaluator...
[10/28 19:41:38][INFO] visual_prompt:   42: Setting up Trainer...
[10/28 19:41:38][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/28 19:41:38][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/28 19:42:43][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6313 s / batch. (data: 9.55e-04). ETA=19:22:40, max mem: 15.9 GB 
[10/28 19:43:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6323 s / batch. (data: 2.95e-04). ETA=19:23:27, max mem: 15.9 GB 
[10/28 19:44:50][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6179 s / batch. (data: 3.28e-04). ETA=18:55:51, max mem: 15.9 GB 
[10/28 19:45:53][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6418 s / batch. (data: 8.21e-04). ETA=19:38:48, max mem: 15.9 GB 
[10/28 19:46:56][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6526 s / batch. (data: 1.26e-02). ETA=19:57:32, max mem: 15.9 GB 
[10/28 19:48:00][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6401 s / batch. (data: 7.34e-04). ETA=19:33:30, max mem: 15.9 GB 
[10/28 19:49:03][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6312 s / batch. (data: 6.98e-04). ETA=19:16:12, max mem: 15.9 GB 
[10/28 19:50:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6182 s / batch. (data: 3.36e-04). ETA=18:51:19, max mem: 15.9 GB 
[10/28 19:51:10][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6404 s / batch. (data: 1.05e-02). ETA=19:30:49, max mem: 15.9 GB 
[10/28 19:52:13][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6314 s / batch. (data: 3.12e-04). ETA=19:13:26, max mem: 15.9 GB 
[10/28 19:53:16][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6183 s / batch. (data: 1.50e-04). ETA=18:48:20, max mem: 15.9 GB 
[10/28 19:53:20][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.49e-03, avg batch time: 0.6351, average train loss: 1.4028
[10/28 19:54:10][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2251 s / batch. (data: 2.88e-05)max mem: 15.94594 GB 
[10/28 19:54:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.80e-05, avg batch time: 0.2321, average loss: 1.3505
[10/28 19:54:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/28 19:54:21][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.05
[10/28 19:55:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0409,	0.6214 s / batch. (data: 5.79e-03). ETA=18:52:53, max mem: 15.9 GB 
[10/28 19:56:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8547,	0.6371 s / batch. (data: 3.43e-04). ETA=19:20:26, max mem: 15.9 GB 
[10/28 19:57:32][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4551,	0.6481 s / batch. (data: 6.95e-03). ETA=19:39:29, max mem: 15.9 GB 
[10/28 19:58:35][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0774,	0.6305 s / batch. (data: 7.92e-04). ETA=19:06:27, max mem: 15.9 GB 
[10/28 19:59:39][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.0522,	0.6200 s / batch. (data: 3.34e-04). ETA=18:46:14, max mem: 15.9 GB 
[10/28 20:00:42][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6129,	0.6352 s / batch. (data: 7.87e-04). ETA=19:12:47, max mem: 15.9 GB 
[10/28 20:01:45][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9307,	0.6189 s / batch. (data: 3.38e-04). ETA=18:42:17, max mem: 15.9 GB 
[10/28 20:02:48][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7900,	0.6352 s / batch. (data: 8.44e-04). ETA=19:10:41, max mem: 15.9 GB 
[10/28 20:03:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1241,	0.6449 s / batch. (data: 7.10e-04). ETA=19:27:17, max mem: 15.9 GB 
[10/28 20:04:55][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.2410,	0.6266 s / batch. (data: 3.09e-04). ETA=18:52:57, max mem: 15.9 GB 
[10/28 20:05:58][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.3170,	0.6173 s / batch. (data: 1.44e-04). ETA=18:35:09, max mem: 15.9 GB 
[10/28 20:06:02][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.18e-03, avg batch time: 0.6341, average train loss: 0.9030
[10/28 20:06:52][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.499, 0.2359 s / batch. (data: 2.50e-05)max mem: 15.94594 GB 
[10/28 20:07:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.78e-05, avg batch time: 0.2331, average loss: 1.3666
[10/28 20:07:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.49	
[10/28 20:07:02][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.1
[10/28 20:08:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7806,	0.6311 s / batch. (data: 7.64e-04). ETA=18:58:55, max mem: 15.9 GB 
[10/28 20:09:11][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.2744,	0.6211 s / batch. (data: 3.28e-04). ETA=18:40:00, max mem: 15.9 GB 
[10/28 20:10:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2995,	0.6325 s / batch. (data: 7.38e-04). ETA=18:59:26, max mem: 15.9 GB 
[10/28 20:11:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8756,	0.6536 s / batch. (data: 7.89e-04). ETA=19:36:18, max mem: 15.9 GB 
[10/28 20:12:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2498,	0.6184 s / batch. (data: 3.31e-04). ETA=18:31:53, max mem: 15.9 GB 
[10/28 20:13:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7401,	0.6298 s / batch. (data: 3.65e-04). ETA=18:51:29, max mem: 15.9 GB 
[10/28 20:14:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.0586,	0.6260 s / batch. (data: 3.15e-04). ETA=18:43:34, max mem: 15.9 GB 
[10/28 20:15:31][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.4488,	0.6403 s / batch. (data: 2.11e-02). ETA=19:08:05, max mem: 15.9 GB 
[10/28 20:16:34][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 3.1224,	0.6407 s / batch. (data: 1.05e-02). ETA=19:07:46, max mem: 15.9 GB 
[10/28 20:17:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6949,	0.6322 s / batch. (data: 7.94e-04). ETA=18:51:31, max mem: 15.9 GB 
[10/28 20:18:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7988,	0.6171 s / batch. (data: 1.67e-04). ETA=18:23:29, max mem: 15.9 GB 
[10/28 20:18:44][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 4.86e-03, avg batch time: 0.6345, average train loss: 0.9878
[10/28 20:19:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.072, 0.2473 s / batch. (data: 4.22e-05)max mem: 15.94594 GB 
[10/28 20:19:44][INFO] visual_prompt:  316: Inference (val):avg data time: 4.28e-05, avg batch time: 0.2318, average loss: 1.1680
[10/28 20:19:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.84	
[10/28 20:19:44][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.15
[10/28 20:20:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6887,	0.6400 s / batch. (data: 7.95e-04). ETA=19:03:19, max mem: 15.9 GB 
[10/28 20:21:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.7138,	0.6460 s / batch. (data: 1.61e-02). ETA=19:12:55, max mem: 15.9 GB 
[10/28 20:22:56][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0625,	0.6189 s / batch. (data: 3.18e-04). ETA=18:23:32, max mem: 15.9 GB 
[10/28 20:24:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0373,	0.6206 s / batch. (data: 3.27e-04). ETA=18:25:36, max mem: 15.9 GB 
[10/28 20:25:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.1465,	0.6395 s / batch. (data: 7.85e-04). ETA=18:58:09, max mem: 15.9 GB 
[10/28 20:26:06][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1836,	0.6418 s / batch. (data: 8.12e-04). ETA=19:01:10, max mem: 15.9 GB 
[10/28 20:27:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.7855,	0.6330 s / batch. (data: 7.75e-04). ETA=18:44:23, max mem: 15.9 GB 
[10/28 20:28:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6371,	0.6468 s / batch. (data: 7.76e-04). ETA=19:07:47, max mem: 15.9 GB 
[10/28 20:29:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.3757,	0.6204 s / batch. (data: 7.85e-04). ETA=18:19:54, max mem: 15.9 GB 
[10/28 20:30:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.9166,	0.6340 s / batch. (data: 7.80e-04). ETA=18:42:57, max mem: 15.9 GB 
[10/28 20:31:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.6229,	0.6176 s / batch. (data: 1.39e-04). ETA=18:12:59, max mem: 15.9 GB 
[10/28 20:31:27][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.17e-03, avg batch time: 0.6349, average train loss: 0.9442
[10/28 20:32:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.697, 0.2318 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/28 20:32:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2324, average loss: 0.7063
[10/28 20:32:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.92	
[10/28 20:32:27][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.2
[10/28 20:33:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7217,	0.6290 s / batch. (data: 8.03e-04). ETA=18:32:04, max mem: 15.9 GB 
[10/28 20:34:36][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4393,	0.6208 s / batch. (data: 3.15e-04). ETA=18:16:27, max mem: 15.9 GB 
[10/28 20:35:39][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6716,	0.6190 s / batch. (data: 3.25e-04). ETA=18:12:14, max mem: 15.9 GB 
[10/28 20:36:42][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 3.1893,	0.6379 s / batch. (data: 8.37e-04). ETA=18:44:32, max mem: 15.9 GB 
[10/28 20:37:46][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0454,	0.6338 s / batch. (data: 7.79e-04). ETA=18:36:17, max mem: 15.9 GB 
[10/28 20:38:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.5443,	0.6291 s / batch. (data: 3.42e-04). ETA=18:26:53, max mem: 15.9 GB 
[10/28 20:39:52][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2619,	0.6340 s / batch. (data: 8.12e-04). ETA=18:34:27, max mem: 15.9 GB 
[10/28 20:40:55][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5549,	0.6439 s / batch. (data: 7.85e-04). ETA=18:50:50, max mem: 15.9 GB 
[10/28 20:41:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.0285,	0.6388 s / batch. (data: 5.38e-03). ETA=18:40:52, max mem: 15.9 GB 
[10/28 20:43:02][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.1815,	0.6189 s / batch. (data: 3.18e-04). ETA=18:04:57, max mem: 15.9 GB 
[10/28 20:44:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0890,	0.6181 s / batch. (data: 2.12e-04). ETA=18:02:24, max mem: 15.9 GB 
[10/28 20:44:09][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.46e-03, avg batch time: 0.6345, average train loss: 1.1823
[10/28 20:44:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.693, 0.2620 s / batch. (data: 3.62e-05)max mem: 15.94594 GB 
[10/28 20:45:09][INFO] visual_prompt:  316: Inference (val):avg data time: 9.64e-05, avg batch time: 0.2324, average loss: 0.6898
[10/28 20:45:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.39	
[10/28 20:45:09][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.25
[10/28 20:46:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.3769,	0.6242 s / batch. (data: 3.26e-04). ETA=18:12:03, max mem: 15.9 GB 
[10/28 20:47:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0328,	0.6244 s / batch. (data: 4.38e-04). ETA=18:11:25, max mem: 15.9 GB 
[10/28 20:48:21][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0149,	0.6440 s / batch. (data: 8.14e-04). ETA=18:44:32, max mem: 15.9 GB 
[10/28 20:49:24][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2280,	0.6245 s / batch. (data: 5.46e-03). ETA=18:09:22, max mem: 15.9 GB 
[10/28 20:50:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7141,	0.6523 s / batch. (data: 8.01e-04). ETA=18:56:54, max mem: 15.9 GB 
[10/28 20:51:31][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2746,	0.6383 s / batch. (data: 8.33e-04). ETA=18:31:18, max mem: 15.9 GB 
[10/28 20:52:34][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7854,	0.6652 s / batch. (data: 8.02e-04). ETA=19:17:09, max mem: 15.9 GB 
[10/28 20:53:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.3779,	0.6281 s / batch. (data: 3.17e-04). ETA=18:11:29, max mem: 15.9 GB 
[10/28 20:54:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.0538,	0.6560 s / batch. (data: 7.72e-04). ETA=18:58:54, max mem: 15.9 GB 
[10/28 20:55:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1240,	0.6407 s / batch. (data: 1.27e-02). ETA=18:31:19, max mem: 15.9 GB 
[10/28 20:56:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0491,	0.6177 s / batch. (data: 1.55e-04). ETA=17:50:17, max mem: 15.9 GB 
[10/28 20:56:51][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.08e-03, avg batch time: 0.6342, average train loss: 1.2710
[10/28 20:57:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.103, 0.2248 s / batch. (data: 2.65e-05)max mem: 15.94594 GB 
[10/28 20:57:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2319, average loss: 1.2005
[10/28 20:57:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.47	
[10/28 20:57:51][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.3
[10/28 20:58:56][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2018,	0.6373 s / batch. (data: 8.51e-04). ETA=18:23:12, max mem: 15.9 GB 
[10/28 21:00:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.3613,	0.6248 s / batch. (data: 2.66e-04). ETA=18:00:30, max mem: 15.9 GB 
[10/28 21:01:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1169,	0.6184 s / batch. (data: 2.66e-04). ETA=17:48:27, max mem: 15.9 GB 
[10/28 21:02:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9336,	0.6193 s / batch. (data: 3.42e-04). ETA=17:48:57, max mem: 15.9 GB 
[10/28 21:03:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.6928,	0.6306 s / batch. (data: 1.34e-02). ETA=18:07:23, max mem: 15.9 GB 
[10/28 21:04:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 3.0232,	0.6241 s / batch. (data: 3.28e-04). ETA=17:55:09, max mem: 15.9 GB 
[10/28 21:05:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.4158,	0.6590 s / batch. (data: 4.09e-02). ETA=18:54:09, max mem: 15.9 GB 
[10/28 21:06:19][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0339,	0.6179 s / batch. (data: 3.25e-04). ETA=17:42:25, max mem: 15.9 GB 
[10/28 21:07:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9512,	0.6488 s / batch. (data: 7.60e-04). ETA=18:34:31, max mem: 15.9 GB 
[10/28 21:08:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.1110,	0.6176 s / batch. (data: 3.47e-04). ETA=17:39:52, max mem: 15.9 GB 
[10/28 21:09:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.0817,	0.6179 s / batch. (data: 1.49e-04). ETA=17:39:21, max mem: 15.9 GB 
[10/28 21:09:33][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 3.77e-03, avg batch time: 0.6338, average train loss: 1.3029
[10/28 21:10:22][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.553, 0.2397 s / batch. (data: 3.00e-05)max mem: 15.94594 GB 
[10/28 21:10:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.76e-05, avg batch time: 0.2328, average loss: 1.4063
[10/28 21:10:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.37	
[10/28 21:10:33][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.35
[10/28 21:11:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4127,	0.6305 s / batch. (data: 7.82e-04). ETA=17:59:53, max mem: 15.9 GB 
[10/28 21:12:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9483,	0.6350 s / batch. (data: 8.15e-04). ETA=18:06:28, max mem: 15.9 GB 
[10/28 21:13:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0647,	0.6346 s / batch. (data: 3.07e-04). ETA=18:04:46, max mem: 15.9 GB 
[10/28 21:14:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 8.5907,	0.6179 s / batch. (data: 2.24e-04). ETA=17:35:09, max mem: 15.9 GB 
[10/28 21:15:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0974,	0.6447 s / batch. (data: 5.89e-03). ETA=18:19:47, max mem: 15.9 GB 
[10/28 21:16:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0299,	0.6489 s / batch. (data: 5.93e-03). ETA=18:25:54, max mem: 15.9 GB 
[10/28 21:17:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0372,	0.6461 s / batch. (data: 7.99e-04). ETA=18:20:01, max mem: 15.9 GB 
[10/28 21:19:01][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.0352,	0.6370 s / batch. (data: 7.63e-04). ETA=18:03:29, max mem: 15.9 GB 
[10/28 21:20:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0647,	0.6492 s / batch. (data: 7.10e-04). ETA=18:23:12, max mem: 15.9 GB 
[10/28 21:21:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8620,	0.6190 s / batch. (data: 3.33e-04). ETA=17:30:54, max mem: 15.9 GB 
[10/28 21:22:11][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.5163,	0.6176 s / batch. (data: 1.49e-04). ETA=17:27:22, max mem: 15.9 GB 
[10/28 21:22:14][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.22e-03, avg batch time: 0.6343, average train loss: 1.4351
[10/28 21:23:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.788, 0.2504 s / batch. (data: 2.88e-05)max mem: 15.94594 GB 
[10/28 21:23:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2316, average loss: 0.7460
[10/28 21:23:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.77	
[10/28 21:23:15][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.4
[10/28 21:24:21][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.7750,	0.6372 s / batch. (data: 7.66e-04). ETA=17:59:36, max mem: 15.9 GB 
[10/28 21:25:24][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0066,	0.6720 s / batch. (data: 7.90e-04). ETA=18:57:21, max mem: 15.9 GB 
[10/28 21:26:27][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8247,	0.6194 s / batch. (data: 3.27e-04). ETA=17:27:24, max mem: 15.9 GB 
[10/28 21:27:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0715,	0.6367 s / batch. (data: 5.41e-03). ETA=17:55:27, max mem: 15.9 GB 
[10/28 21:28:34][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 6.0167,	0.6519 s / batch. (data: 8.30e-04). ETA=18:20:10, max mem: 15.9 GB 
[10/28 21:29:37][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9354,	0.6393 s / batch. (data: 7.70e-04). ETA=17:57:48, max mem: 15.9 GB 
[10/28 21:30:40][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.1988,	0.6445 s / batch. (data: 8.36e-04). ETA=18:05:25, max mem: 15.9 GB 
[10/28 21:31:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9805,	0.6402 s / batch. (data: 3.23e-04). ETA=17:57:12, max mem: 15.9 GB 
[10/28 21:32:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0146,	0.6573 s / batch. (data: 2.53e-02). ETA=18:24:45, max mem: 15.9 GB 
[10/28 21:33:51][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.2548,	0.6185 s / batch. (data: 3.20e-04). ETA=17:18:34, max mem: 15.9 GB 
[10/28 21:34:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6895,	0.6177 s / batch. (data: 1.70e-04). ETA=17:16:13, max mem: 15.9 GB 
[10/28 21:34:58][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.71e-03, avg batch time: 0.6354, average train loss: 1.2667
[10/28 21:35:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.153, 0.2252 s / batch. (data: 2.48e-05)max mem: 15.94594 GB 
[10/28 21:35:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2331, average loss: 1.0548
[10/28 21:35:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[10/28 21:35:58][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.45
[10/28 21:37:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.7076,	0.6353 s / batch. (data: 7.71e-04). ETA=17:44:39, max mem: 15.9 GB 
[10/28 21:38:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 13.2166,	0.6512 s / batch. (data: 8.26e-04). ETA=18:10:08, max mem: 15.9 GB 
[10/28 21:39:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.8747,	0.6317 s / batch. (data: 3.17e-04). ETA=17:36:28, max mem: 15.9 GB 
[10/28 21:40:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1393,	0.6320 s / batch. (data: 7.64e-04). ETA=17:35:53, max mem: 15.9 GB 
[10/28 21:41:16][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2922,	0.6672 s / batch. (data: 3.10e-02). ETA=18:33:33, max mem: 15.9 GB 
[10/28 21:42:19][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 6.0538,	0.6566 s / batch. (data: 1.65e-02). ETA=18:14:45, max mem: 15.9 GB 
[10/28 21:43:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 4.2101,	0.6350 s / batch. (data: 8.40e-04). ETA=17:37:40, max mem: 15.9 GB 
[10/28 21:44:26][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.2905,	0.6447 s / batch. (data: 8.03e-04). ETA=17:52:48, max mem: 15.9 GB 
[10/28 21:45:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.5111,	0.6347 s / batch. (data: 2.90e-04). ETA=17:35:12, max mem: 15.9 GB 
[10/28 21:46:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0005,	0.6316 s / batch. (data: 9.94e-03). ETA=17:28:59, max mem: 15.9 GB 
[10/28 21:47:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6183 s / batch. (data: 1.37e-04). ETA=17:05:49, max mem: 15.9 GB 
[10/28 21:47:40][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.93e-03, avg batch time: 0.6344, average train loss: 2.2191
[10/28 21:48:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.717, 0.2251 s / batch. (data: 5.46e-05)max mem: 15.94594 GB 
[10/28 21:48:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2329, average loss: 4.2373
[10/28 21:48:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.88	
[10/28 21:48:40][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.5
[10/28 21:49:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0032,	0.6415 s / batch. (data: 7.96e-04). ETA=17:43:13, max mem: 15.9 GB 
[10/28 21:50:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.0482,	0.6172 s / batch. (data: 2.68e-04). ETA=17:01:49, max mem: 15.9 GB 
[10/28 21:51:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 5.6663,	0.6302 s / batch. (data: 8.28e-04). ETA=17:22:18, max mem: 15.9 GB 
[10/28 21:52:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.2083,	0.6395 s / batch. (data: 8.02e-04). ETA=17:36:36, max mem: 15.9 GB 
[10/28 21:53:59][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6669,	0.6184 s / batch. (data: 3.07e-04). ETA=17:00:45, max mem: 15.9 GB 
[10/28 21:55:02][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6545 s / batch. (data: 7.84e-04). ETA=17:59:21, max mem: 15.9 GB 
[10/28 21:56:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.6377,	0.6632 s / batch. (data: 3.35e-02). ETA=18:12:35, max mem: 15.9 GB 
[10/28 21:57:09][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 6.2017,	0.6360 s / batch. (data: 8.07e-04). ETA=17:26:38, max mem: 15.9 GB 
[10/28 21:58:12][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1047,	0.6344 s / batch. (data: 3.33e-04). ETA=17:22:59, max mem: 15.9 GB 
[10/28 21:59:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0007,	0.6325 s / batch. (data: 8.23e-04). ETA=17:18:51, max mem: 15.9 GB 
[10/28 22:00:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2528,	0.6177 s / batch. (data: 1.36e-04). ETA=16:53:30, max mem: 15.9 GB 
[10/28 22:00:22][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.34e-03, avg batch time: 0.6347, average train loss: 2.0673
[10/28 22:01:12][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.783, 0.2400 s / batch. (data: 4.34e-05)max mem: 15.94594 GB 
[10/28 22:01:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.76e-05, avg batch time: 0.2316, average loss: 0.7404
[10/28 22:01:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.34	
[10/28 22:01:22][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[10/28 22:02:29][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6058,	0.6436 s / batch. (data: 8.62e-04). ETA=17:34:46, max mem: 15.9 GB 
[10/28 22:03:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7149,	0.6340 s / batch. (data: 8.30e-04). ETA=17:17:58, max mem: 15.9 GB 
[10/28 22:04:36][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.8198,	0.6355 s / batch. (data: 1.58e-02). ETA=17:19:23, max mem: 15.9 GB 
[10/28 22:05:39][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0540,	0.6202 s / batch. (data: 3.11e-04). ETA=16:53:20, max mem: 15.9 GB 
[10/28 22:06:43][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1358,	0.6364 s / batch. (data: 7.88e-04). ETA=17:18:48, max mem: 15.9 GB 
[10/28 22:07:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2335,	0.6352 s / batch. (data: 2.83e-04). ETA=17:15:42, max mem: 15.9 GB 
[10/28 22:08:50][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.7902,	0.6207 s / batch. (data: 2.21e-04). ETA=16:51:00, max mem: 15.9 GB 
[10/28 22:09:53][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.8791,	0.6185 s / batch. (data: 3.15e-04). ETA=16:46:30, max mem: 15.9 GB 
[10/28 22:10:56][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.1756,	0.6812 s / batch. (data: 5.00e-02). ETA=18:27:18, max mem: 15.9 GB 
[10/28 22:11:59][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.5349,	0.6326 s / batch. (data: 8.16e-04). ETA=17:07:21, max mem: 15.9 GB 
[10/28 22:13:03][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 7.2217,	0.6187 s / batch. (data: 1.25e-04). ETA=16:43:44, max mem: 15.9 GB 
[10/28 22:13:07][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.82e-03, avg batch time: 0.6368, average train loss: 2.1015
[10/28 22:13:56][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.033, 0.2261 s / batch. (data: 2.72e-05)max mem: 15.94594 GB 
[10/28 22:14:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2318, average loss: 0.9461
[10/28 22:14:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[10/28 22:14:07][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[10/28 22:15:12][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3523,	0.6319 s / batch. (data: 3.14e-04). ETA=17:03:53, max mem: 15.9 GB 
[10/28 22:16:16][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7034,	0.6292 s / batch. (data: 2.68e-04). ETA=16:58:32, max mem: 15.9 GB 
[10/28 22:17:19][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 3.1854,	0.6190 s / batch. (data: 3.32e-04). ETA=16:40:57, max mem: 15.9 GB 
[10/28 22:18:22][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 3.0419,	0.6294 s / batch. (data: 8.23e-04). ETA=16:56:43, max mem: 15.9 GB 
[10/28 22:19:25][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0503,	0.6317 s / batch. (data: 2.93e-04). ETA=16:59:30, max mem: 15.9 GB 
[10/28 22:20:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 5.1426,	0.6445 s / batch. (data: 8.75e-04). ETA=17:19:01, max mem: 15.9 GB 
[10/28 22:21:32][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.1257,	0.6181 s / batch. (data: 3.32e-04). ETA=16:35:23, max mem: 15.9 GB 
[10/28 22:22:35][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.2278,	0.6332 s / batch. (data: 3.22e-04). ETA=16:58:41, max mem: 15.9 GB 
[10/28 22:23:38][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0013,	0.6312 s / batch. (data: 1.27e-02). ETA=16:54:23, max mem: 15.9 GB 
[10/28 22:24:41][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0004,	0.6329 s / batch. (data: 7.97e-04). ETA=16:56:04, max mem: 15.9 GB 
[10/28 22:25:45][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.7218,	0.6189 s / batch. (data: 2.56e-04). ETA=16:32:32, max mem: 15.9 GB 
[10/28 22:25:49][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.31e-03, avg batch time: 0.6342, average train loss: 1.8972
[10/28 22:26:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.720, 0.2277 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/28 22:26:49][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-05, avg batch time: 0.2324, average loss: 0.6996
[10/28 22:26:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.26	
[10/28 22:26:49][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.700
[10/28 22:26:49][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[10/28 22:27:55][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.3153,	0.6167 s / batch. (data: 3.32e-04). ETA=16:28:00, max mem: 15.9 GB 
[10/28 22:28:58][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 6.3511,	0.6184 s / batch. (data: 3.46e-04). ETA=16:29:42, max mem: 15.9 GB 
[10/28 22:30:01][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 3.1502,	0.6341 s / batch. (data: 3.85e-04). ETA=16:53:44, max mem: 15.9 GB 
[10/28 22:31:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0003,	0.6304 s / batch. (data: 7.28e-04). ETA=16:46:49, max mem: 15.9 GB 
[10/28 22:32:08][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.8850,	0.6204 s / batch. (data: 1.04e-03). ETA=16:29:42, max mem: 15.9 GB 
[10/28 22:33:11][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6341,	0.6324 s / batch. (data: 4.89e-04). ETA=16:47:49, max mem: 15.9 GB 
[10/28 22:34:15][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.2914,	0.6529 s / batch. (data: 1.29e-02). ETA=17:19:27, max mem: 15.9 GB 
[10/28 22:35:18][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.3590,	0.6336 s / batch. (data: 8.17e-04). ETA=16:47:35, max mem: 15.9 GB 
[10/28 22:36:21][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.4958,	0.6332 s / batch. (data: 8.29e-04). ETA=16:45:56, max mem: 15.9 GB 
[10/28 22:37:24][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.3134,	0.6181 s / batch. (data: 3.19e-04). ETA=16:20:52, max mem: 15.9 GB 
[10/28 22:38:27][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.1257,	0.6190 s / batch. (data: 1.49e-04). ETA=16:21:20, max mem: 15.9 GB 
[10/28 22:38:31][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.27e-03, avg batch time: 0.6347, average train loss: 2.1789
[10/28 22:39:21][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.530, 0.2316 s / batch. (data: 5.08e-05)max mem: 15.94594 GB 
[10/28 22:39:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2320, average loss: 1.3824
[10/28 22:39:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.44	
[10/28 22:39:31][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[10/28 22:40:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.7171,	0.6335 s / batch. (data: 2.99e-04). ETA=16:43:17, max mem: 15.9 GB 
[10/28 22:41:40][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.9904,	0.6245 s / batch. (data: 3.12e-04). ETA=16:27:55, max mem: 15.9 GB 
[10/28 22:42:43][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 5.3345,	0.6524 s / batch. (data: 8.03e-04). ETA=17:10:57, max mem: 15.9 GB 
[10/28 22:43:46][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 22.2763,	0.6420 s / batch. (data: 7.46e-04). ETA=16:53:30, max mem: 15.9 GB 
[10/28 22:44:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.5346,	0.6269 s / batch. (data: 3.28e-04). ETA=16:28:37, max mem: 15.9 GB 
[10/28 22:45:53][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3442,	0.6317 s / batch. (data: 7.76e-04). ETA=16:35:06, max mem: 15.9 GB 
[10/28 22:46:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.7923,	0.6272 s / batch. (data: 2.91e-04). ETA=16:26:56, max mem: 15.9 GB 
[10/28 22:47:59][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6523,	0.6193 s / batch. (data: 3.33e-04). ETA=16:13:32, max mem: 15.9 GB 
[10/28 22:49:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.4683,	0.6476 s / batch. (data: 3.51e-04). ETA=16:56:51, max mem: 15.9 GB 
[10/28 22:50:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.6101,	0.6331 s / batch. (data: 1.52e-02). ETA=16:33:04, max mem: 15.9 GB 
[10/28 22:51:10][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 4.1407,	0.6186 s / batch. (data: 1.36e-04). ETA=16:09:18, max mem: 15.9 GB 
[10/28 22:51:13][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 3.48e-03, avg batch time: 0.6347, average train loss: 2.5590
[10/28 22:52:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.617, 0.2254 s / batch. (data: 4.22e-05)max mem: 15.94594 GB 
[10/28 22:52:14][INFO] visual_prompt:  316: Inference (val):avg data time: 9.28e-05, avg batch time: 0.2324, average loss: 1.7767
[10/28 22:52:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.84	
[10/28 22:52:14][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[10/28 22:53:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0045,	0.6240 s / batch. (data: 3.08e-04). ETA=16:16:40, max mem: 15.9 GB 
[10/28 22:54:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.0416,	0.6192 s / batch. (data: 3.12e-04). ETA=16:08:05, max mem: 15.9 GB 
[10/28 22:55:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0032,	0.6683 s / batch. (data: 8.23e-04). ETA=17:23:44, max mem: 15.9 GB 
[10/28 22:56:29][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 6.2225,	0.6309 s / batch. (data: 8.40e-04). ETA=16:24:22, max mem: 15.9 GB 
[10/28 22:57:32][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 3.7405,	0.6348 s / batch. (data: 3.09e-04). ETA=16:29:21, max mem: 15.9 GB 
[10/28 22:58:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9931,	0.6389 s / batch. (data: 9.20e-04). ETA=16:34:36, max mem: 15.9 GB 
[10/28 22:59:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.7807,	0.6187 s / batch. (data: 3.40e-04). ETA=16:02:10, max mem: 15.9 GB 
[10/28 23:00:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.9996,	0.6338 s / batch. (data: 2.64e-04). ETA=16:24:35, max mem: 15.9 GB 
[10/28 23:01:45][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8242,	0.6377 s / batch. (data: 7.85e-04). ETA=16:29:33, max mem: 15.9 GB 
[10/28 23:02:48][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 4.9615,	0.6382 s / batch. (data: 4.10e-03). ETA=16:29:15, max mem: 15.9 GB 
[10/28 23:03:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0337,	0.6182 s / batch. (data: 1.44e-04). ETA=15:57:19, max mem: 15.9 GB 
[10/28 23:03:56][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.91e-03, avg batch time: 0.6343, average train loss: 2.2271
[10/28 23:04:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.567, 0.2258 s / batch. (data: 3.27e-05)max mem: 15.94594 GB 
[10/28 23:04:56][INFO] visual_prompt:  316: Inference (val):avg data time: 4.03e-05, avg batch time: 0.2313, average loss: 1.4114
[10/28 23:04:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.57	
[10/28 23:04:56][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[10/28 23:06:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0982,	0.6575 s / batch. (data: 1.34e-02). ETA=16:56:54, max mem: 15.9 GB 
[10/28 23:07:05][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6638,	0.6325 s / batch. (data: 3.21e-04). ETA=16:17:13, max mem: 15.9 GB 
[10/28 23:08:08][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3807,	0.6208 s / batch. (data: 7.79e-04). ETA=15:58:08, max mem: 15.9 GB 
[10/28 23:09:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0943,	0.6305 s / batch. (data: 8.47e-04). ETA=16:12:07, max mem: 15.9 GB 
[10/28 23:10:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0079,	0.6370 s / batch. (data: 7.93e-04). ETA=16:20:57, max mem: 15.9 GB 
[10/28 23:11:18][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.6207,	0.6631 s / batch. (data: 3.19e-02). ETA=17:00:08, max mem: 15.9 GB 
[10/28 23:12:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2343,	0.6239 s / batch. (data: 2.99e-04). ETA=15:58:45, max mem: 15.9 GB 
[10/28 23:13:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.0629,	0.6291 s / batch. (data: 3.51e-04). ETA=16:05:44, max mem: 15.9 GB 
[10/28 23:14:28][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 3.2783,	0.6379 s / batch. (data: 1.39e-02). ETA=16:18:08, max mem: 15.9 GB 
[10/28 23:15:31][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0500,	0.6459 s / batch. (data: 7.82e-04). ETA=16:29:17, max mem: 15.9 GB 
[10/28 23:16:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0044,	0.6193 s / batch. (data: 1.52e-04). ETA=15:47:30, max mem: 15.9 GB 
[10/28 23:16:39][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.39e-03, avg batch time: 0.6351, average train loss: 1.9155
[10/28 23:17:28][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.272, 0.2389 s / batch. (data: 5.29e-05)max mem: 15.94594 GB 
[10/28 23:17:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.82e-05, avg batch time: 0.2329, average loss: 2.4930
[10/28 23:17:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.01	
[10/28 23:17:39][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[10/28 23:18:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6302 s / batch. (data: 3.25e-04). ETA=16:03:06, max mem: 15.9 GB 
[10/28 23:19:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 9.5798,	0.6317 s / batch. (data: 8.02e-04). ETA=16:04:24, max mem: 15.9 GB 
[10/28 23:20:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 11.1166,	0.6270 s / batch. (data: 3.44e-04). ETA=15:56:12, max mem: 15.9 GB 
[10/28 23:21:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 4.9663,	0.6314 s / batch. (data: 7.69e-04). ETA=16:01:48, max mem: 15.9 GB 
[10/28 23:22:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6243 s / batch. (data: 3.21e-04). ETA=15:49:58, max mem: 15.9 GB 
[10/28 23:24:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0947,	0.6497 s / batch. (data: 4.50e-04). ETA=16:27:32, max mem: 15.9 GB 
[10/28 23:25:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0293,	0.6290 s / batch. (data: 3.27e-04). ETA=15:55:01, max mem: 15.9 GB 
[10/28 23:26:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.3220,	0.6307 s / batch. (data: 9.59e-04). ETA=15:56:35, max mem: 15.9 GB 
[10/28 23:27:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.4184,	0.6246 s / batch. (data: 5.46e-03). ETA=15:46:13, max mem: 15.9 GB 
[10/28 23:28:14][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.6034,	0.6197 s / batch. (data: 3.36e-04). ETA=15:37:49, max mem: 15.9 GB 
[10/28 23:29:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0001,	0.6185 s / batch. (data: 1.44e-04). ETA=15:35:01, max mem: 15.9 GB 
[10/28 23:29:21][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.28e-03, avg batch time: 0.6348, average train loss: 2.5334
[10/28 23:30:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.311, 0.2264 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/28 23:30:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2333, average loss: 1.4359
[10/28 23:30:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.28	
[10/28 23:30:21][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[10/28 23:31:27][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.1340,	0.6292 s / batch. (data: 3.16e-04). ETA=15:50:01, max mem: 15.9 GB 
[10/28 23:32:30][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.5637,	0.6413 s / batch. (data: 8.14e-04). ETA=16:07:11, max mem: 15.9 GB 
[10/28 23:33:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0384,	0.6341 s / batch. (data: 3.21e-04). ETA=15:55:17, max mem: 15.9 GB 
[10/28 23:34:37][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0045,	0.6331 s / batch. (data: 7.83e-04). ETA=15:52:42, max mem: 15.9 GB 
[10/28 23:35:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8133,	0.6514 s / batch. (data: 7.50e-04). ETA=16:19:12, max mem: 15.9 GB 
[10/28 23:36:43][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.3121,	0.6192 s / batch. (data: 3.17e-04). ETA=15:29:41, max mem: 15.9 GB 
[10/28 23:37:47][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0269,	0.6373 s / batch. (data: 7.86e-04). ETA=15:55:51, max mem: 15.9 GB 
[10/28 23:38:50][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0080,	0.6332 s / batch. (data: 2.81e-04). ETA=15:48:39, max mem: 15.9 GB 
[10/28 23:39:53][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.2401,	0.6298 s / batch. (data: 3.15e-04). ETA=15:42:32, max mem: 15.9 GB 
[10/28 23:40:56][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0002,	0.6479 s / batch. (data: 7.52e-04). ETA=16:08:35, max mem: 15.9 GB 
[10/28 23:42:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 7.9721,	0.6185 s / batch. (data: 1.74e-04). ETA=15:23:30, max mem: 15.9 GB 
[10/28 23:42:04][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.32e-03, avg batch time: 0.6349, average train loss: 2.2048
[10/28 23:42:54][INFO] visual_prompt:  303: 	Test 100/123. loss: 11.016, 0.2325 s / batch. (data: 4.29e-05)max mem: 15.94594 GB 
[10/28 23:43:04][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2331, average loss: 9.9366
[10/28 23:43:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.58	
[10/28 23:43:04][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[10/28 23:44:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.2060,	0.6364 s / batch. (data: 5.89e-03). ETA=15:49:09, max mem: 15.9 GB 
[10/28 23:45:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.6018,	0.6193 s / batch. (data: 3.26e-04). ETA=15:22:35, max mem: 15.9 GB 
[10/28 23:46:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.2353,	0.6469 s / batch. (data: 3.36e-04). ETA=16:02:39, max mem: 15.9 GB 
[10/28 23:47:20][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6808,	0.6186 s / batch. (data: 3.29e-04). ETA=15:19:26, max mem: 15.9 GB 
[10/28 23:48:23][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7397,	0.6319 s / batch. (data: 5.00e-04). ETA=15:38:16, max mem: 15.9 GB 
[10/28 23:49:26][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.6039,	0.6181 s / batch. (data: 3.11e-04). ETA=15:16:43, max mem: 15.9 GB 
[10/28 23:50:30][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.5588,	0.6666 s / batch. (data: 3.74e-02). ETA=16:27:32, max mem: 15.9 GB 
[10/28 23:51:33][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1803,	0.6206 s / batch. (data: 7.51e-04). ETA=15:18:21, max mem: 15.9 GB 
[10/28 23:52:36][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.5478,	0.6454 s / batch. (data: 7.87e-04). ETA=15:53:56, max mem: 15.9 GB 
[10/28 23:53:39][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1848,	0.6471 s / batch. (data: 8.82e-04). ETA=15:55:23, max mem: 15.9 GB 
[10/28 23:54:42][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.7854,	0.6179 s / batch. (data: 1.39e-04). ETA=15:11:11, max mem: 15.9 GB 
[10/28 23:54:46][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.48e-03, avg batch time: 0.6343, average train loss: 1.5617
[10/28 23:55:36][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.692, 0.2326 s / batch. (data: 4.67e-05)max mem: 15.94594 GB 
[10/28 23:55:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-05, avg batch time: 0.2331, average loss: 0.7107
[10/28 23:55:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.23	
[10/28 23:55:46][INFO] visual_prompt:   42: Stopping early.
