[10/27 05:33:05][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/27 05:33:05][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/27 05:33:05][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/27 05:33:05][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/27 05:33:05][INFO] visual_prompt:  108: Training with config:
[10/27 05:33:05][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/27 05:33:05][INFO] visual_prompt:   55: Loading training data...
[10/27 05:33:05][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/27 05:33:05][INFO] visual_prompt:   57: Loading validation data...
[10/27 05:33:05][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/27 05:33:05][INFO] visual_prompt:   38: Constructing models...
[10/27 05:33:08][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/27 05:33:08][INFO] visual_prompt:   54: tuned percent:0.522
[10/27 05:33:08][INFO] visual_prompt:   40: Device used for model: 0
[10/27 05:33:08][INFO] visual_prompt:   40: Setting up Evaluator...
[10/27 05:33:08][INFO] visual_prompt:   42: Setting up Trainer...
[10/27 05:33:08][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/27 05:33:08][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/27 05:34:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6326 s / batch. (data: 5.45e-03). ETA=19:25:03, max mem: 15.9 GB 
[10/27 05:35:17][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6433 s / batch. (data: 7.61e-04). ETA=19:43:40, max mem: 15.9 GB 
[10/27 05:36:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6434 s / batch. (data: 7.49e-04). ETA=19:42:49, max mem: 15.9 GB 
[10/27 05:37:23][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6335 s / batch. (data: 8.18e-04). ETA=19:23:36, max mem: 15.9 GB 
[10/27 05:38:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6235 s / batch. (data: 5.42e-03). ETA=19:04:12, max mem: 15.9 GB 
[10/27 05:39:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6189 s / batch. (data: 3.08e-04). ETA=18:54:43, max mem: 15.9 GB 
[10/27 05:40:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6197 s / batch. (data: 3.29e-04). ETA=18:55:03, max mem: 15.9 GB 
[10/27 05:41:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6199 s / batch. (data: 3.19e-04). ETA=18:54:20, max mem: 15.9 GB 
[10/27 05:42:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6642 s / batch. (data: 1.69e-02). ETA=20:14:24, max mem: 15.9 GB 
[10/27 05:43:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6338 s / batch. (data: 8.14e-04). ETA=19:17:45, max mem: 15.9 GB 
[10/27 05:44:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6177 s / batch. (data: 1.38e-04). ETA=18:47:18, max mem: 15.9 GB 
[10/27 05:44:51][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.68e-03, avg batch time: 0.6352, average train loss: 1.4028
[10/27 05:45:40][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2263 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/27 05:45:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2319, average loss: 1.3505
[10/27 05:45:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/27 05:45:51][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.25
[10/27 05:46:56][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 5.2396,	0.6405 s / batch. (data: 7.71e-04). ETA=19:27:51, max mem: 15.9 GB 
[10/27 05:47:59][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7736,	0.6258 s / batch. (data: 3.26e-04). ETA=18:59:52, max mem: 15.9 GB 
[10/27 05:49:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4808,	0.6378 s / batch. (data: 7.75e-04). ETA=19:20:47, max mem: 15.9 GB 
[10/27 05:50:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0004,	0.6321 s / batch. (data: 3.97e-04). ETA=19:09:16, max mem: 15.9 GB 
[10/27 05:51:09][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 4.9177,	0.6395 s / batch. (data: 1.58e-02). ETA=19:21:36, max mem: 15.9 GB 
[10/27 05:52:12][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9580,	0.6471 s / batch. (data: 7.86e-04). ETA=19:34:20, max mem: 15.9 GB 
[10/27 05:53:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0820,	0.6434 s / batch. (data: 7.72e-04). ETA=19:26:43, max mem: 15.9 GB 
[10/27 05:54:19][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.0474,	0.6240 s / batch. (data: 3.23e-04). ETA=18:50:20, max mem: 15.9 GB 
[10/27 05:55:22][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5201,	0.6188 s / batch. (data: 3.05e-04). ETA=18:40:00, max mem: 15.9 GB 
[10/27 05:56:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1747,	0.6201 s / batch. (data: 7.31e-04). ETA=18:41:17, max mem: 15.9 GB 
[10/27 05:57:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0034,	0.6187 s / batch. (data: 1.48e-04). ETA=18:37:47, max mem: 15.9 GB 
[10/27 05:57:32][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.71e-03, avg batch time: 0.6341, average train loss: 1.5923
[10/27 05:58:23][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.989, 0.2399 s / batch. (data: 3.15e-05)max mem: 15.94594 GB 
[10/27 05:58:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2325, average loss: 2.6904
[10/27 05:58:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.78	
[10/27 05:58:33][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.5
[10/27 05:59:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6002,	0.6174 s / batch. (data: 2.92e-04). ETA=18:34:11, max mem: 15.9 GB 
[10/27 06:00:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.2850,	0.6389 s / batch. (data: 8.26e-04). ETA=19:11:56, max mem: 15.9 GB 
[10/27 06:01:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1288,	0.6388 s / batch. (data: 7.78e-04). ETA=19:10:45, max mem: 15.9 GB 
[10/27 06:02:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6985,	0.6195 s / batch. (data: 3.23e-04). ETA=18:34:54, max mem: 15.9 GB 
[10/27 06:03:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 4.3420,	0.6196 s / batch. (data: 3.30e-04). ETA=18:34:04, max mem: 15.9 GB 
[10/27 06:04:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0475,	0.6332 s / batch. (data: 3.32e-04). ETA=18:57:34, max mem: 15.9 GB 
[10/27 06:05:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.1210,	0.6197 s / batch. (data: 3.15e-04). ETA=18:32:11, max mem: 15.9 GB 
[10/27 06:07:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.3861,	0.6364 s / batch. (data: 8.36e-04). ETA=19:01:10, max mem: 15.9 GB 
[10/27 06:08:06][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.9469,	0.6414 s / batch. (data: 1.01e-02). ETA=19:08:57, max mem: 15.9 GB 
[10/27 06:09:09][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 4.3715,	0.6298 s / batch. (data: 3.96e-04). ETA=18:47:08, max mem: 15.9 GB 
[10/27 06:10:12][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8755,	0.6171 s / batch. (data: 1.34e-04). ETA=18:23:31, max mem: 15.9 GB 
[10/27 06:10:16][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.40e-03, avg batch time: 0.6356, average train loss: 1.8476
[10/27 06:11:06][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.020, 0.2429 s / batch. (data: 3.89e-05)max mem: 15.94594 GB 
[10/27 06:11:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.69e-05, avg batch time: 0.2335, average loss: 1.1137
[10/27 06:11:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.22	
[10/27 06:11:17][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.75
[10/27 06:12:22][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8307,	0.6176 s / batch. (data: 3.39e-04). ETA=18:23:14, max mem: 15.9 GB 
[10/27 06:13:25][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 11.7521,	0.6291 s / batch. (data: 3.13e-04). ETA=18:42:47, max mem: 15.9 GB 
[10/27 06:14:29][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.2787,	0.6330 s / batch. (data: 7.46e-04). ETA=18:48:38, max mem: 15.9 GB 
[10/27 06:15:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.0792,	0.6322 s / batch. (data: 3.47e-04). ETA=18:46:06, max mem: 15.9 GB 
[10/27 06:16:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6464 s / batch. (data: 8.08e-04). ETA=19:10:23, max mem: 15.9 GB 
[10/27 06:17:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.7204,	0.6320 s / batch. (data: 2.84e-04). ETA=18:43:40, max mem: 15.9 GB 
[10/27 06:18:42][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 13.0674,	0.6365 s / batch. (data: 5.42e-03). ETA=18:50:38, max mem: 15.9 GB 
[10/27 06:19:45][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.8205,	0.6272 s / batch. (data: 3.53e-04). ETA=18:33:04, max mem: 15.9 GB 
[10/27 06:20:48][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 6.5498,	0.6407 s / batch. (data: 7.68e-04). ETA=18:55:57, max mem: 15.9 GB 
[10/27 06:21:51][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 4.0092,	0.6454 s / batch. (data: 5.93e-03). ETA=19:03:17, max mem: 15.9 GB 
[10/27 06:22:55][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 8.9345,	0.6185 s / batch. (data: 1.39e-04). ETA=18:14:34, max mem: 15.9 GB 
[10/27 06:22:58][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.11e-03, avg batch time: 0.6343, average train loss: 3.2116
[10/27 06:23:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.948, 0.2381 s / batch. (data: 4.17e-05)max mem: 15.94594 GB 
[10/27 06:23:59][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2325, average loss: 2.1410
[10/27 06:23:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.52	
[10/27 06:23:59][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 1.0
[10/27 06:25:04][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.6320,	0.6371 s / batch. (data: 8.03e-04). ETA=18:46:20, max mem: 15.9 GB 
[10/27 06:26:07][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0001,	0.6275 s / batch. (data: 2.98e-04). ETA=18:28:20, max mem: 15.9 GB 
[10/27 06:27:10][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.4970,	0.6484 s / batch. (data: 8.62e-04). ETA=19:04:15, max mem: 15.9 GB 
[10/27 06:28:14][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 24.3011,	0.6338 s / batch. (data: 7.72e-04). ETA=18:37:16, max mem: 15.9 GB 
[10/27 06:29:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6219 s / batch. (data: 3.29e-04). ETA=18:15:22, max mem: 15.9 GB 
[10/27 06:30:21][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1725,	0.6306 s / batch. (data: 8.19e-04). ETA=18:29:38, max mem: 15.9 GB 
[10/27 06:31:24][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 5.5896,	0.6392 s / batch. (data: 8.25e-04). ETA=18:43:36, max mem: 15.9 GB 
[10/27 06:32:27][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 7.5344,	0.6325 s / batch. (data: 7.86e-04). ETA=18:30:51, max mem: 15.9 GB 
[10/27 06:33:31][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.7514,	0.6406 s / batch. (data: 5.83e-03). ETA=18:43:58, max mem: 15.9 GB 
[10/27 06:34:34][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.2456,	0.6335 s / batch. (data: 8.09e-04). ETA=18:30:27, max mem: 15.9 GB 
[10/27 06:35:37][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 8.4644,	0.6175 s / batch. (data: 1.49e-04). ETA=18:01:28, max mem: 15.9 GB 
[10/27 06:35:41][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.24e-03, avg batch time: 0.6349, average train loss: 4.5412
[10/27 06:36:31][INFO] visual_prompt:  303: 	Test 100/123. loss: 13.698, 0.2451 s / batch. (data: 2.55e-05)max mem: 15.94594 GB 
[10/27 06:36:42][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2327, average loss: 15.0713
[10/27 06:36:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.77	
[10/27 06:36:42][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 1.25
[10/27 06:37:47][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 5.2147,	0.6164 s / batch. (data: 2.91e-04). ETA=17:58:20, max mem: 15.9 GB 
[10/27 06:38:50][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0010,	0.6190 s / batch. (data: 3.46e-04). ETA=18:01:59, max mem: 15.9 GB 
[10/27 06:39:53][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2269,	0.6323 s / batch. (data: 7.89e-04). ETA=18:24:03, max mem: 15.9 GB 
[10/27 06:40:57][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 7.5901,	0.6334 s / batch. (data: 2.83e-04). ETA=18:25:00, max mem: 15.9 GB 
[10/27 06:42:00][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 7.2185,	0.6409 s / batch. (data: 7.96e-04). ETA=18:37:01, max mem: 15.9 GB 
[10/27 06:43:03][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 12.1529,	0.6440 s / batch. (data: 7.96e-04). ETA=18:41:18, max mem: 15.9 GB 
[10/27 06:44:06][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 3.2702,	0.6378 s / batch. (data: 5.43e-03). ETA=18:29:22, max mem: 15.9 GB 
[10/27 06:45:10][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 14.6436,	0.6188 s / batch. (data: 3.33e-04). ETA=17:55:23, max mem: 15.9 GB 
[10/27 06:46:13][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 8.8585,	0.6438 s / batch. (data: 7.10e-04). ETA=18:37:48, max mem: 15.9 GB 
[10/27 06:47:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3267,	0.6177 s / batch. (data: 2.85e-04). ETA=17:51:19, max mem: 15.9 GB 
[10/27 06:48:19][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0410,	0.6182 s / batch. (data: 1.71e-04). ETA=17:51:16, max mem: 15.9 GB 
[10/27 06:48:23][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.28e-03, avg batch time: 0.6341, average train loss: 5.3803
[10/27 06:49:13][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.693, 0.2617 s / batch. (data: 3.15e-05)max mem: 15.94594 GB 
[10/27 06:49:24][INFO] visual_prompt:  316: Inference (val):avg data time: 1.59e-04, avg batch time: 0.2339, average loss: 0.6908
[10/27 06:49:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.92	
[10/27 06:49:24][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 1.5
[10/27 06:50:29][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 23.8195,	0.6250 s / batch. (data: 3.17e-04). ETA=18:01:51, max mem: 15.9 GB 
[10/27 06:51:32][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2297,	0.6592 s / batch. (data: 1.71e-02). ETA=19:00:00, max mem: 15.9 GB 
[10/27 06:52:35][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 9.3941,	0.6428 s / batch. (data: 1.26e-03). ETA=18:30:30, max mem: 15.9 GB 
[10/27 06:53:39][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9005,	0.6412 s / batch. (data: 9.59e-04). ETA=18:26:50, max mem: 15.9 GB 
[10/27 06:54:42][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 13.3733,	0.6364 s / batch. (data: 7.59e-04). ETA=18:17:24, max mem: 15.9 GB 
[10/27 06:55:45][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.1323,	0.6403 s / batch. (data: 7.98e-04). ETA=18:23:00, max mem: 15.9 GB 
[10/27 06:56:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 38.5075,	0.6198 s / batch. (data: 2.90e-04). ETA=17:46:40, max mem: 15.9 GB 
[10/27 06:57:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 5.2256,	0.6363 s / batch. (data: 8.21e-04). ETA=18:14:00, max mem: 15.9 GB 
[10/27 06:58:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5875,	0.6468 s / batch. (data: 7.49e-04). ETA=18:30:57, max mem: 15.9 GB 
[10/27 06:59:59][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 15.4756,	0.6335 s / batch. (data: 2.19e-04). ETA=18:07:12, max mem: 15.9 GB 
[10/27 07:01:02][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 17.5795,	0.6187 s / batch. (data: 1.40e-04). ETA=17:40:38, max mem: 15.9 GB 
[10/27 07:01:06][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.19e-03, avg batch time: 0.6346, average train loss: 6.6078
[10/27 07:01:56][INFO] visual_prompt:  303: 	Test 100/123. loss: 12.498, 0.2399 s / batch. (data: 3.03e-05)max mem: 15.94594 GB 
[10/27 07:02:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.2324, average loss: 11.2886
[10/27 07:02:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.43	
[10/27 07:02:07][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 1.75
[10/27 07:03:12][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 7.8947,	0.6310 s / batch. (data: 1.32e-02). ETA=18:00:40, max mem: 15.9 GB 
[10/27 07:04:15][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.6395,	0.6303 s / batch. (data: 7.98e-04). ETA=17:58:30, max mem: 15.9 GB 
[10/27 07:05:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6349 s / batch. (data: 2.92e-04). ETA=18:05:17, max mem: 15.9 GB 
[10/27 07:06:22][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6183 s / batch. (data: 2.66e-04). ETA=17:35:51, max mem: 15.9 GB 
[10/27 07:07:26][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0179,	0.6470 s / batch. (data: 1.90e-02). ETA=18:23:42, max mem: 15.9 GB 
[10/27 07:08:29][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0001,	0.6323 s / batch. (data: 1.53e-02). ETA=17:57:37, max mem: 15.9 GB 
[10/27 07:09:32][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 12.3409,	0.6405 s / batch. (data: 8.01e-04). ETA=18:10:33, max mem: 15.9 GB 
[10/27 07:10:35][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.3891,	0.6301 s / batch. (data: 1.07e-02). ETA=17:51:49, max mem: 15.9 GB 
[10/27 07:11:38][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6179 s / batch. (data: 4.50e-04). ETA=17:30:00, max mem: 15.9 GB 
[10/27 07:12:42][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.6940,	0.6196 s / batch. (data: 3.16e-04). ETA=17:31:54, max mem: 15.9 GB 
[10/27 07:13:45][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.7011,	0.6187 s / batch. (data: 1.34e-04). ETA=17:29:21, max mem: 15.9 GB 
[10/27 07:13:49][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.39e-03, avg batch time: 0.6347, average train loss: 8.8708
[10/27 07:14:39][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.936, 0.2259 s / batch. (data: 3.24e-05)max mem: 15.94594 GB 
[10/27 07:14:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2312, average loss: 4.4373
[10/27 07:14:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.34	
[10/27 07:14:50][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 2.0
[10/27 07:15:55][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 46.6247,	0.6256 s / batch. (data: 5.51e-03). ETA=17:39:53, max mem: 15.9 GB 
[10/27 07:16:58][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6413 s / batch. (data: 3.19e-04). ETA=18:05:21, max mem: 15.9 GB 
[10/27 07:18:01][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 9.0121,	0.6175 s / batch. (data: 3.19e-04). ETA=17:24:01, max mem: 15.9 GB 
[10/27 07:19:05][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6263 s / batch. (data: 2.72e-04). ETA=17:37:55, max mem: 15.9 GB 
[10/27 07:20:08][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 10.8746,	0.6295 s / batch. (data: 3.31e-04). ETA=17:42:19, max mem: 15.9 GB 
[10/27 07:21:11][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.5742,	0.6328 s / batch. (data: 7.35e-04). ETA=17:46:46, max mem: 15.9 GB 
[10/27 07:22:14][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6217 s / batch. (data: 3.26e-04). ETA=17:27:00, max mem: 15.9 GB 
[10/27 07:23:18][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.3731,	0.6309 s / batch. (data: 3.17e-04). ETA=17:41:34, max mem: 15.9 GB 
[10/27 07:24:21][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 14.9465,	0.6312 s / batch. (data: 8.39e-04). ETA=17:40:58, max mem: 15.9 GB 
[10/27 07:25:24][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9772,	0.6188 s / batch. (data: 3.55e-04). ETA=17:19:03, max mem: 15.9 GB 
[10/27 07:26:28][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 4.3048,	0.6176 s / batch. (data: 1.46e-04). ETA=17:15:57, max mem: 15.9 GB 
[10/27 07:26:31][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.20e-03, avg batch time: 0.6343, average train loss: 8.7254
[10/27 07:27:21][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.623, 0.2357 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/27 07:27:32][INFO] visual_prompt:  316: Inference (val):avg data time: 4.33e-05, avg batch time: 0.2321, average loss: 4.1531
[10/27 07:27:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.89	
[10/27 07:27:32][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 2.25
[10/27 07:28:37][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 7.2335,	0.6420 s / batch. (data: 1.10e-02). ETA=17:55:50, max mem: 15.9 GB 
[10/27 07:29:40][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 19.5659,	0.6201 s / batch. (data: 5.46e-03). ETA=17:18:02, max mem: 15.9 GB 
[10/27 07:30:43][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6461,	0.6190 s / batch. (data: 7.08e-04). ETA=17:15:18, max mem: 15.9 GB 
[10/27 07:31:46][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1213,	0.6281 s / batch. (data: 2.85e-04). ETA=17:29:23, max mem: 15.9 GB 
[10/27 07:32:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.1262,	0.6586 s / batch. (data: 1.62e-02). ETA=18:19:14, max mem: 15.9 GB 
[10/27 07:33:53][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 30.6861,	0.6413 s / batch. (data: 3.36e-04). ETA=17:49:18, max mem: 15.9 GB 
[10/27 07:34:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 27.0467,	0.6344 s / batch. (data: 3.06e-04). ETA=17:36:43, max mem: 15.9 GB 
[10/27 07:36:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.1302,	0.6255 s / batch. (data: 2.64e-04). ETA=17:20:51, max mem: 15.9 GB 
[10/27 07:37:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.3225,	0.6478 s / batch. (data: 7.84e-04). ETA=17:56:50, max mem: 15.9 GB 
[10/27 07:38:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0024,	0.6429 s / batch. (data: 7.63e-04). ETA=17:47:38, max mem: 15.9 GB 
[10/27 07:39:10][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0004,	0.6182 s / batch. (data: 1.55e-04). ETA=17:05:41, max mem: 15.9 GB 
[10/27 07:39:14][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.71e-03, avg batch time: 0.6347, average train loss: 9.1604
[10/27 07:40:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 3.479, 0.2414 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/27 07:40:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2334, average loss: 4.5740
[10/27 07:40:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.41	
[10/27 07:40:14][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 2.5
[10/27 07:41:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 10.5608,	0.6190 s / batch. (data: 7.53e-04). ETA=17:05:53, max mem: 15.9 GB 
[10/27 07:42:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 17.7607,	0.6327 s / batch. (data: 8.52e-04). ETA=17:27:34, max mem: 15.9 GB 
[10/27 07:43:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 20.5473,	0.6406 s / batch. (data: 7.46e-04). ETA=17:39:28, max mem: 15.9 GB 
[10/27 07:44:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3650,	0.6170 s / batch. (data: 3.09e-04). ETA=16:59:28, max mem: 15.9 GB 
[10/27 07:45:33][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 14.8114,	0.6437 s / batch. (data: 8.00e-04). ETA=17:42:35, max mem: 15.9 GB 
[10/27 07:46:36][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6611 s / batch. (data: 8.02e-04). ETA=18:10:10, max mem: 15.9 GB 
[10/27 07:47:39][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6197 s / batch. (data: 3.23e-04). ETA=17:00:51, max mem: 15.9 GB 
[10/27 07:48:43][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 8.5823,	0.6529 s / batch. (data: 7.55e-04). ETA=17:54:23, max mem: 15.9 GB 
[10/27 07:49:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5806,	0.6256 s / batch. (data: 3.30e-04). ETA=17:08:28, max mem: 15.9 GB 
[10/27 07:50:49][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6441 s / batch. (data: 1.61e-02). ETA=17:37:49, max mem: 15.9 GB 
[10/27 07:51:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 3.4057,	0.6198 s / batch. (data: 1.67e-04). ETA=16:56:48, max mem: 15.9 GB 
[10/27 07:51:56][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.24e-03, avg batch time: 0.6345, average train loss: 11.0960
[10/27 07:52:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.582, 0.2250 s / batch. (data: 3.19e-05)max mem: 15.94594 GB 
[10/27 07:52:57][INFO] visual_prompt:  316: Inference (val):avg data time: 4.11e-05, avg batch time: 0.2340, average loss: 4.9674
[10/27 07:52:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.62	
[10/27 07:52:57][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[10/27 07:54:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0001,	0.6186 s / batch. (data: 2.98e-04). ETA=16:53:51, max mem: 15.9 GB 
[10/27 07:55:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 8.6317,	0.6230 s / batch. (data: 3.09e-04). ETA=16:59:58, max mem: 15.9 GB 
[10/27 07:56:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 6.1529,	0.6307 s / batch. (data: 3.18e-04). ETA=17:11:30, max mem: 15.9 GB 
[10/27 07:57:13][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0003,	0.6416 s / batch. (data: 7.94e-04). ETA=17:28:15, max mem: 15.9 GB 
[10/27 07:58:16][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 45.3220,	0.6317 s / batch. (data: 7.56e-04). ETA=17:11:03, max mem: 15.9 GB 
[10/27 07:59:19][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6182 s / batch. (data: 3.36e-04). ETA=16:48:00, max mem: 15.9 GB 
[10/27 08:00:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 3.2136,	0.6191 s / batch. (data: 2.58e-04). ETA=16:48:27, max mem: 15.9 GB 
[10/27 08:01:26][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 11.3921,	0.6335 s / batch. (data: 7.80e-04). ETA=17:10:48, max mem: 15.9 GB 
[10/27 08:02:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.2638,	0.6190 s / batch. (data: 2.94e-04). ETA=16:46:13, max mem: 15.9 GB 
[10/27 08:03:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 5.0389,	0.6254 s / batch. (data: 3.25e-04). ETA=16:55:36, max mem: 15.9 GB 
[10/27 08:04:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0668,	0.6182 s / batch. (data: 1.46e-04). ETA=16:42:51, max mem: 15.9 GB 
[10/27 08:04:39][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.37e-03, avg batch time: 0.6353, average train loss: 11.9346
[10/27 08:05:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.240, 0.2256 s / batch. (data: 2.79e-05)max mem: 15.94594 GB 
[10/27 08:05:40][INFO] visual_prompt:  316: Inference (val):avg data time: 1.02e-04, avg batch time: 0.2323, average loss: 4.6327
[10/27 08:05:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.89	
[10/27 08:05:40][INFO] visual_prompt:   36: Best epoch 12: best metric: -4.633
[10/27 08:05:40][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[10/27 08:06:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 14.8987,	0.6370 s / batch. (data: 7.75e-04). ETA=17:12:14, max mem: 15.9 GB 
[10/27 08:07:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 3.2098,	0.6176 s / batch. (data: 3.24e-04). ETA=16:39:45, max mem: 15.9 GB 
[10/27 08:08:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6180 s / batch. (data: 3.16e-04). ETA=16:39:25, max mem: 15.9 GB 
[10/27 08:09:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 12.8398,	0.6337 s / batch. (data: 7.78e-04). ETA=17:03:41, max mem: 15.9 GB 
[10/27 08:10:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 5.3849,	0.6308 s / batch. (data: 3.22e-04). ETA=16:58:02, max mem: 15.9 GB 
[10/27 08:12:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.8287,	0.6247 s / batch. (data: 3.17e-04). ETA=16:47:03, max mem: 15.9 GB 
[10/27 08:13:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6520 s / batch. (data: 8.15e-04). ETA=17:30:00, max mem: 15.9 GB 
[10/27 08:14:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 18.0266,	0.6281 s / batch. (data: 3.16e-04). ETA=16:50:24, max mem: 15.9 GB 
[10/27 08:15:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0838,	0.6194 s / batch. (data: 7.62e-04). ETA=16:35:29, max mem: 15.9 GB 
[10/27 08:16:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 34.4354,	0.6186 s / batch. (data: 3.24e-04). ETA=16:33:13, max mem: 15.9 GB 
[10/27 08:17:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 13.2828,	0.6194 s / batch. (data: 1.74e-04). ETA=16:33:27, max mem: 15.9 GB 
[10/27 08:17:22][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.44e-03, avg batch time: 0.6347, average train loss: 11.3820
[10/27 08:18:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.979, 0.2266 s / batch. (data: 4.15e-05)max mem: 15.94594 GB 
[10/27 08:18:22][INFO] visual_prompt:  316: Inference (val):avg data time: 9.81e-05, avg batch time: 0.2327, average loss: 2.1754
[10/27 08:18:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.39	
[10/27 08:18:22][INFO] visual_prompt:   36: Best epoch 13: best metric: -2.175
[10/27 08:18:22][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[10/27 08:19:27][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 22.6359,	0.6285 s / batch. (data: 3.35e-04). ETA=16:46:51, max mem: 15.9 GB 
[10/27 08:20:31][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 13.7534,	0.6245 s / batch. (data: 3.49e-04). ETA=16:39:22, max mem: 15.9 GB 
[10/27 08:21:34][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 3.7371,	0.6289 s / batch. (data: 7.69e-04). ETA=16:45:21, max mem: 15.9 GB 
[10/27 08:22:37][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6342 s / batch. (data: 1.64e-02). ETA=16:52:53, max mem: 15.9 GB 
[10/27 08:23:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 5.3861,	0.6182 s / batch. (data: 3.10e-04). ETA=16:26:15, max mem: 15.9 GB 
[10/27 08:24:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 6.5675,	0.6345 s / batch. (data: 9.24e-04). ETA=16:51:11, max mem: 15.9 GB 
[10/27 08:25:47][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3682,	0.6560 s / batch. (data: 8.11e-04). ETA=17:24:21, max mem: 15.9 GB 
[10/27 08:26:50][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 8.5574,	0.6304 s / batch. (data: 7.66e-04). ETA=16:42:35, max mem: 15.9 GB 
[10/27 08:27:53][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 10.7043,	0.6289 s / batch. (data: 1.05e-02). ETA=16:39:10, max mem: 15.9 GB 
[10/27 08:28:57][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 20.9667,	0.6869 s / batch. (data: 5.09e-02). ETA=18:10:03, max mem: 15.9 GB 
[10/27 08:30:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 7.4472,	0.6185 s / batch. (data: 1.47e-04). ETA=16:20:28, max mem: 15.9 GB 
[10/27 08:30:04][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.50e-03, avg batch time: 0.6345, average train loss: 9.1081
[10/27 08:30:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 21.656, 0.2246 s / batch. (data: 3.89e-05)max mem: 15.94594 GB 
[10/27 08:31:04][INFO] visual_prompt:  316: Inference (val):avg data time: 1.26e-04, avg batch time: 0.2327, average loss: 19.4705
[10/27 08:31:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.84	
[10/27 08:31:04][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 2.487835085926963
[10/27 08:32:09][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 37.7890,	0.6276 s / batch. (data: 7.16e-04). ETA=16:33:48, max mem: 15.9 GB 
[10/27 08:33:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 12.2016,	0.6464 s / batch. (data: 2.91e-02). ETA=17:02:35, max mem: 15.9 GB 
[10/27 08:34:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 5.8683,	0.6643 s / batch. (data: 1.60e-02). ETA=17:29:48, max mem: 15.9 GB 
[10/27 08:35:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 7.5176,	0.6338 s / batch. (data: 3.23e-04). ETA=16:40:35, max mem: 15.9 GB 
[10/27 08:36:22][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6560 s / batch. (data: 8.18e-04). ETA=17:14:27, max mem: 15.9 GB 
[10/27 08:37:25][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.4101,	0.6314 s / batch. (data: 3.00e-04). ETA=16:34:38, max mem: 15.9 GB 
[10/27 08:38:28][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 17.4826,	0.6188 s / batch. (data: 2.71e-04). ETA=16:13:41, max mem: 15.9 GB 
[10/27 08:39:31][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 5.6265,	0.6511 s / batch. (data: 3.14e-04). ETA=17:03:33, max mem: 15.9 GB 
[10/27 08:40:34][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 10.6534,	0.6355 s / batch. (data: 7.66e-04). ETA=16:37:49, max mem: 15.9 GB 
[10/27 08:41:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 3.7164,	0.6273 s / batch. (data: 2.87e-04). ETA=16:24:02, max mem: 15.9 GB 
[10/27 08:42:41][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 53.6548,	0.6130 s / batch. (data: 1.49e-04). ETA=16:00:31, max mem: 15.9 GB 
[10/27 08:42:44][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.08e-03, avg batch time: 0.6330, average train loss: 17.6230
[10/27 08:43:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.660, 0.2317 s / batch. (data: 3.67e-05)max mem: 15.94594 GB 
[10/27 08:43:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.2310, average loss: 2.5869
[10/27 08:43:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.26	
[10/27 08:43:45][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[10/27 08:44:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8172,	0.6483 s / batch. (data: 7.67e-04). ETA=16:54:38, max mem: 15.9 GB 
[10/27 08:45:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 3.8961,	0.6309 s / batch. (data: 3.22e-04). ETA=16:26:21, max mem: 15.9 GB 
[10/27 08:46:56][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.7855,	0.6183 s / batch. (data: 3.15e-04). ETA=16:05:44, max mem: 15.9 GB 
[10/27 08:48:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 16.8383,	0.6347 s / batch. (data: 8.13e-04). ETA=16:30:12, max mem: 15.9 GB 
[10/27 08:49:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 18.9686,	0.6400 s / batch. (data: 3.27e-04). ETA=16:37:26, max mem: 15.9 GB 
[10/27 08:50:06][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.5301,	0.6179 s / batch. (data: 3.54e-04). ETA=16:01:57, max mem: 15.9 GB 
[10/27 08:51:09][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 7.4583,	0.6398 s / batch. (data: 7.72e-04). ETA=16:34:57, max mem: 15.9 GB 
[10/27 08:52:12][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.3177,	0.6353 s / batch. (data: 8.40e-04). ETA=16:26:59, max mem: 15.9 GB 
[10/27 08:53:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.0778,	0.6324 s / batch. (data: 7.98e-04). ETA=16:21:22, max mem: 15.9 GB 
[10/27 08:54:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 32.0942,	0.6186 s / batch. (data: 3.10e-04). ETA=15:58:51, max mem: 15.9 GB 
[10/27 08:55:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 25.2658,	0.6176 s / batch. (data: 1.60e-04). ETA=15:56:25, max mem: 15.9 GB 
[10/27 08:55:26][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.84e-03, avg batch time: 0.6339, average train loss: 10.2760
[10/27 08:56:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.866, 0.2517 s / batch. (data: 2.53e-05)max mem: 15.94594 GB 
[10/27 08:56:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.78e-05, avg batch time: 0.2330, average loss: 8.7504
[10/27 08:56:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.64	
[10/27 08:56:26][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 2.472684500917257
[10/27 08:57:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6369 s / batch. (data: 3.24e-04). ETA=16:25:05, max mem: 15.9 GB 
[10/27 08:58:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 8.2027,	0.6289 s / batch. (data: 2.90e-04). ETA=16:11:40, max mem: 15.9 GB 
[10/27 08:59:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4190,	0.6214 s / batch. (data: 3.16e-04). ETA=15:59:04, max mem: 15.9 GB 
[10/27 09:00:42][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 34.7001,	0.6309 s / batch. (data: 8.09e-04). ETA=16:12:40, max mem: 15.9 GB 
[10/27 09:01:45][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6171 s / batch. (data: 3.12e-04). ETA=15:50:21, max mem: 15.9 GB 
[10/27 09:02:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 14.7045,	0.6187 s / batch. (data: 3.06e-04). ETA=15:51:50, max mem: 15.9 GB 
[10/27 09:03:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.4380,	0.6601 s / batch. (data: 9.30e-04). ETA=16:54:28, max mem: 15.9 GB 
[10/27 09:04:54][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0057,	0.6370 s / batch. (data: 6.03e-03). ETA=16:17:46, max mem: 15.9 GB 
[10/27 09:05:58][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6565 s / batch. (data: 1.31e-02). ETA=16:46:42, max mem: 15.9 GB 
[10/27 09:07:01][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 37.5833,	0.6184 s / batch. (data: 3.13e-04). ETA=15:47:16, max mem: 15.9 GB 
[10/27 09:08:04][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0001,	0.6172 s / batch. (data: 1.59e-04). ETA=15:44:17, max mem: 15.9 GB 
[10/27 09:08:08][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.23e-03, avg batch time: 0.6341, average train loss: 11.8153
[10/27 09:08:58][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.758, 0.2431 s / batch. (data: 2.55e-05)max mem: 15.94594 GB 
[10/27 09:09:08][INFO] visual_prompt:  316: Inference (val):avg data time: 1.19e-04, avg batch time: 0.2327, average loss: 8.5320
[10/27 09:09:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.90	
[10/27 09:09:08][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[10/27 09:10:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 30.8414,	0.6313 s / batch. (data: 3.20e-04). ETA=16:04:48, max mem: 15.9 GB 
[10/27 09:11:17][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4250,	0.6321 s / batch. (data: 7.88e-04). ETA=16:04:58, max mem: 15.9 GB 
[10/27 09:12:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 22.0808,	0.6346 s / batch. (data: 3.19e-04). ETA=16:07:44, max mem: 15.9 GB 
[10/27 09:13:23][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 25.2903,	0.6362 s / batch. (data: 7.86e-04). ETA=16:09:03, max mem: 15.9 GB 
[10/27 09:14:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6268 s / batch. (data: 5.45e-03). ETA=15:53:41, max mem: 15.9 GB 
[10/27 09:15:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1615,	0.6186 s / batch. (data: 3.18e-04). ETA=15:40:18, max mem: 15.9 GB 
[10/27 09:16:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6444 s / batch. (data: 3.34e-04). ETA=16:18:22, max mem: 15.9 GB 
[10/27 09:17:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 7.8983,	0.6330 s / batch. (data: 8.02e-04). ETA=15:59:57, max mem: 15.9 GB 
[10/27 09:18:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 36.0343,	0.6341 s / batch. (data: 8.13e-04). ETA=16:00:37, max mem: 15.9 GB 
[10/27 09:19:43][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 15.5634,	0.6231 s / batch. (data: 3.73e-04). ETA=15:42:56, max mem: 15.9 GB 
[10/27 09:20:46][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 12.5051,	0.6185 s / batch. (data: 1.65e-04). ETA=15:34:54, max mem: 15.9 GB 
[10/27 09:20:50][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.16e-03, avg batch time: 0.6343, average train loss: 12.4975
[10/27 09:21:40][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.792, 0.2357 s / batch. (data: 5.48e-05)max mem: 15.94594 GB 
[10/27 09:21:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2321, average loss: 3.5648
[10/27 09:21:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.56	
[10/27 09:21:50][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[10/27 09:22:56][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6216 s / batch. (data: 3.53e-04). ETA=15:38:30, max mem: 15.9 GB 
[10/27 09:23:59][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 15.7945,	0.6303 s / batch. (data: 7.87e-04). ETA=15:50:40, max mem: 15.9 GB 
[10/27 09:25:02][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6608 s / batch. (data: 2.25e-02). ETA=16:35:34, max mem: 15.9 GB 
[10/27 09:26:05][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 7.5371,	0.6209 s / batch. (data: 2.93e-04). ETA=15:34:21, max mem: 15.9 GB 
[10/27 09:27:09][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6483 s / batch. (data: 8.23e-04). ETA=16:14:32, max mem: 15.9 GB 
[10/27 09:28:12][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 8.6351,	0.6314 s / batch. (data: 7.86e-04). ETA=15:48:05, max mem: 15.9 GB 
[10/27 09:29:15][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0306,	0.6300 s / batch. (data: 3.20e-04). ETA=15:44:53, max mem: 15.9 GB 
[10/27 09:30:18][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 13.2445,	0.6197 s / batch. (data: 3.10e-04). ETA=15:28:27, max mem: 15.9 GB 
[10/27 09:31:22][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.1605,	0.6185 s / batch. (data: 3.08e-04). ETA=15:25:32, max mem: 15.9 GB 
[10/27 09:32:24][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6280 s / batch. (data: 2.53e-04). ETA=15:38:45, max mem: 15.9 GB 
[10/27 09:33:28][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6183 s / batch. (data: 1.78e-04). ETA=15:23:10, max mem: 15.9 GB 
[10/27 09:33:32][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 3.98e-03, avg batch time: 0.6339, average train loss: 12.5257
[10/27 09:34:21][INFO] visual_prompt:  303: 	Test 100/123. loss: 25.005, 0.2316 s / batch. (data: 5.22e-05)max mem: 15.94594 GB 
[10/27 09:34:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2331, average loss: 22.7997
[10/27 09:34:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.16	
[10/27 09:34:32][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 2.438820645368942
[10/27 09:35:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.9726,	0.6291 s / batch. (data: 7.45e-04). ETA=15:38:17, max mem: 15.9 GB 
[10/27 09:36:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.1401,	0.6296 s / batch. (data: 7.93e-04). ETA=15:37:56, max mem: 15.9 GB 
[10/27 09:37:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 19.3823,	0.6182 s / batch. (data: 3.33e-04). ETA=15:19:58, max mem: 15.9 GB 
[10/27 09:38:47][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 4.9991,	0.6388 s / batch. (data: 1.47e-02). ETA=15:49:28, max mem: 15.9 GB 
[10/27 09:39:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 9.9389,	0.6170 s / batch. (data: 3.13e-04). ETA=15:16:07, max mem: 15.9 GB 
[10/27 09:40:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.7551,	0.6298 s / batch. (data: 1.26e-02). ETA=15:34:00, max mem: 15.9 GB 
[10/27 09:41:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6333 s / batch. (data: 8.33e-04). ETA=15:38:11, max mem: 15.9 GB 
[10/27 09:43:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1411,	0.6341 s / batch. (data: 9.22e-04). ETA=15:38:15, max mem: 15.9 GB 
[10/27 09:44:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0023,	0.6401 s / batch. (data: 7.40e-04). ETA=15:46:08, max mem: 15.9 GB 
[10/27 09:45:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6375 s / batch. (data: 7.65e-04). ETA=15:41:17, max mem: 15.9 GB 
[10/27 09:46:11][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.9758,	0.6178 s / batch. (data: 1.33e-04). ETA=15:11:03, max mem: 15.9 GB 
[10/27 09:46:14][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.88e-03, avg batch time: 0.6348, average train loss: 10.7062
[10/27 09:47:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.791, 0.2316 s / batch. (data: 3.08e-05)max mem: 15.94594 GB 
[10/27 09:47:15][INFO] visual_prompt:  316: Inference (val):avg data time: 4.25e-05, avg batch time: 0.2334, average loss: 0.7244
[10/27 09:47:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.82	
[10/27 09:47:15][INFO] visual_prompt:   36: Best epoch 20: best metric: -0.724
[10/27 09:47:15][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[10/27 09:48:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 40.9465,	0.6586 s / batch. (data: 7.85e-04). ETA=16:10:03, max mem: 15.9 GB 
[10/27 09:49:24][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6509 s / batch. (data: 8.39e-04). ETA=15:57:45, max mem: 15.9 GB 
[10/27 09:50:27][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6167 s / batch. (data: 3.17e-04). ETA=15:06:23, max mem: 15.9 GB 
[10/27 09:51:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 34.4800,	0.6486 s / batch. (data: 7.83e-04). ETA=15:52:11, max mem: 15.9 GB 
[10/27 09:52:33][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 30.8077,	0.6264 s / batch. (data: 3.45e-04). ETA=15:18:29, max mem: 15.9 GB 
[10/27 09:53:36][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6437 s / batch. (data: 7.97e-04). ETA=15:42:50, max mem: 15.9 GB 
[10/27 09:54:39][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 14.6120,	0.6195 s / batch. (data: 3.14e-04). ETA=15:06:20, max mem: 15.9 GB 
[10/27 09:55:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 20.0545,	0.6284 s / batch. (data: 1.05e-02). ETA=15:18:16, max mem: 15.9 GB 
[10/27 09:56:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.0947,	0.6520 s / batch. (data: 7.84e-04). ETA=15:51:44, max mem: 15.9 GB 
[10/27 09:57:49][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 5.4715,	0.6338 s / batch. (data: 3.21e-04). ETA=15:24:01, max mem: 15.9 GB 
[10/27 09:58:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 46.7418,	0.6177 s / batch. (data: 1.56e-04). ETA=14:59:31, max mem: 15.9 GB 
[10/27 09:58:56][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.56e-03, avg batch time: 0.6337, average train loss: 12.0342
[10/27 09:59:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 3.004, 0.2476 s / batch. (data: 3.10e-05)max mem: 15.94594 GB 
[10/27 09:59:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2329, average loss: 2.7200
[10/27 09:59:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.22	
[10/27 09:59:56][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[10/27 10:01:01][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 17.1877,	0.6544 s / batch. (data: 3.74e-02). ETA=15:51:49, max mem: 15.9 GB 
[10/27 10:02:04][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0002,	0.6468 s / batch. (data: 8.28e-04). ETA=15:39:44, max mem: 15.9 GB 
[10/27 10:03:08][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6185 s / batch. (data: 2.74e-04). ETA=14:57:31, max mem: 15.9 GB 
[10/27 10:04:11][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 12.4078,	0.6490 s / batch. (data: 7.74e-04). ETA=15:40:42, max mem: 15.9 GB 
[10/27 10:05:14][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6417 s / batch. (data: 7.57e-04). ETA=15:29:06, max mem: 15.9 GB 
[10/27 10:06:17][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6304 s / batch. (data: 8.14e-04). ETA=15:11:45, max mem: 15.9 GB 
[10/27 10:07:21][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 3.0310,	0.6280 s / batch. (data: 3.25e-04). ETA=15:07:12, max mem: 15.9 GB 
[10/27 10:08:24][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 32.3918,	0.6390 s / batch. (data: 1.17e-03). ETA=15:21:59, max mem: 15.9 GB 
[10/27 10:09:27][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.7118,	0.6246 s / batch. (data: 2.83e-04). ETA=15:00:10, max mem: 15.9 GB 
[10/27 10:10:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 24.6638,	0.6307 s / batch. (data: 1.34e-02). ETA=15:07:52, max mem: 15.9 GB 
[10/27 10:11:34][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 62.2981,	0.6173 s / batch. (data: 1.50e-04). ETA=14:47:38, max mem: 15.9 GB 
[10/27 10:11:38][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 4.29e-03, avg batch time: 0.6344, average train loss: 11.7748
[10/27 10:12:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 24.625, 0.2390 s / batch. (data: 2.98e-05)max mem: 15.94594 GB 
[10/27 10:12:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2315, average loss: 26.8337
[10/27 10:12:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.64	
[10/27 10:12:38][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 2.391931822053251
[10/27 10:13:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 18.7032,	0.6314 s / batch. (data: 2.80e-04). ETA=15:06:44, max mem: 15.9 GB 
[10/27 10:14:47][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 6.7978,	0.6190 s / batch. (data: 2.81e-04). ETA=14:47:53, max mem: 15.9 GB 
[10/27 10:15:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4105,	0.6354 s / batch. (data: 3.25e-04). ETA=15:10:24, max mem: 15.9 GB 
[10/27 10:16:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 18.1182,	0.6337 s / batch. (data: 8.06e-04). ETA=15:06:57, max mem: 15.9 GB 
[10/27 10:17:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6954,	0.6445 s / batch. (data: 1.37e-02). ETA=15:21:20, max mem: 15.9 GB 
[10/27 10:19:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 6.6042,	0.6199 s / batch. (data: 3.55e-04). ETA=14:45:03, max mem: 15.9 GB 
[10/27 10:20:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 3.9138,	0.6316 s / batch. (data: 7.94e-04). ETA=15:00:46, max mem: 15.9 GB 
[10/27 10:21:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 8.5453,	0.6190 s / batch. (data: 2.94e-04). ETA=14:41:41, max mem: 15.9 GB 
[10/27 10:22:10][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 5.5290,	0.6335 s / batch. (data: 3.54e-04). ETA=15:01:16, max mem: 15.9 GB 
[10/27 10:23:13][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0001,	0.6402 s / batch. (data: 3.26e-04). ETA=15:09:50, max mem: 15.9 GB 
[10/27 10:24:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 3.5558,	0.6170 s / batch. (data: 1.49e-04). ETA=14:35:47, max mem: 15.9 GB 
[10/27 10:24:20][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 4.87e-03, avg batch time: 0.6350, average train loss: 11.9816
[10/27 10:25:10][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.964, 0.2437 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/27 10:25:21][INFO] visual_prompt:  316: Inference (val):avg data time: 4.36e-05, avg batch time: 0.2319, average loss: 2.8277
[10/27 10:25:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.23	
[10/27 10:25:21][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[10/27 10:26:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 18.5779,	0.6170 s / batch. (data: 3.10e-04). ETA=14:34:42, max mem: 15.9 GB 
[10/27 10:27:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 26.6741,	0.6183 s / batch. (data: 3.24e-04). ETA=14:35:34, max mem: 15.9 GB 
[10/27 10:28:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0541,	0.6219 s / batch. (data: 3.23e-04). ETA=14:39:36, max mem: 15.9 GB 
[10/27 10:29:36][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.1525,	0.6186 s / batch. (data: 3.14e-04). ETA=14:33:52, max mem: 15.9 GB 
[10/27 10:30:39][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 22.9802,	0.6311 s / batch. (data: 8.17e-04). ETA=14:50:31, max mem: 15.9 GB 
[10/27 10:31:42][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.6411,	0.6174 s / batch. (data: 2.60e-04). ETA=14:30:07, max mem: 15.9 GB 
[10/27 10:32:45][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 25.4328,	0.6324 s / batch. (data: 1.24e-02). ETA=14:50:14, max mem: 15.9 GB 
[10/27 10:33:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.4976,	0.6297 s / batch. (data: 2.97e-04). ETA=14:45:20, max mem: 15.9 GB 
[10/27 10:34:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6312 s / batch. (data: 8.13e-04). ETA=14:46:30, max mem: 15.9 GB 
[10/27 10:35:55][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3364,	0.6365 s / batch. (data: 6.79e-04). ETA=14:52:45, max mem: 15.9 GB 
[10/27 10:36:58][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 11.9809,	0.6174 s / batch. (data: 1.89e-04). ETA=14:25:02, max mem: 15.9 GB 
[10/27 10:37:02][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 4.44e-03, avg batch time: 0.6343, average train loss: 9.3838
[10/27 10:37:52][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.590, 0.2322 s / batch. (data: 3.65e-05)max mem: 15.94594 GB 
[10/27 10:38:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-05, avg batch time: 0.2332, average loss: 6.1181
[10/27 10:38:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.75	
[10/27 10:38:03][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[10/27 10:39:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2878,	0.6504 s / batch. (data: 8.14e-04). ETA=15:10:01, max mem: 15.9 GB 
[10/27 10:40:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 5.9752,	0.6716 s / batch. (data: 5.92e-03). ETA=15:38:40, max mem: 15.9 GB 
[10/27 10:41:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 10.3076,	0.6609 s / batch. (data: 6.95e-04). ETA=15:22:34, max mem: 15.9 GB 
[10/27 10:42:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 33.8055,	0.6185 s / batch. (data: 2.97e-04). ETA=14:22:18, max mem: 15.9 GB 
[10/27 10:43:22][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 47.5119,	0.6183 s / batch. (data: 3.61e-04). ETA=14:20:59, max mem: 15.9 GB 
[10/27 10:44:25][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 25.6712,	0.6328 s / batch. (data: 7.44e-04). ETA=14:40:09, max mem: 15.9 GB 
[10/27 10:45:28][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 8.6942,	0.6527 s / batch. (data: 5.91e-03). ETA=15:06:45, max mem: 15.9 GB 
[10/27 10:46:32][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0006,	0.6268 s / batch. (data: 3.23e-04). ETA=14:29:43, max mem: 15.9 GB 
[10/27 10:47:35][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 14.0279,	0.6196 s / batch. (data: 3.08e-04). ETA=14:18:42, max mem: 15.9 GB 
[10/27 10:48:38][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 7.7251,	0.6243 s / batch. (data: 3.19e-04). ETA=14:24:10, max mem: 15.9 GB 
[10/27 10:49:42][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6184 s / batch. (data: 1.50e-04). ETA=14:14:59, max mem: 15.9 GB 
[10/27 10:49:45][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 4.34e-03, avg batch time: 0.6353, average train loss: 9.9751
[10/27 10:50:35][INFO] visual_prompt:  303: 	Test 100/123. loss: 20.182, 0.2293 s / batch. (data: 4.13e-03)max mem: 15.94594 GB 
[10/27 10:50:46][INFO] visual_prompt:  316: Inference (val):avg data time: 7.27e-05, avg batch time: 0.2317, average loss: 18.1849
[10/27 10:50:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.32	
[10/27 10:50:46][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[10/27 10:51:51][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 15.4122,	0.6357 s / batch. (data: 1.95e-02). ETA=14:37:45, max mem: 15.9 GB 
[10/27 10:52:54][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 44.3367,	0.6265 s / batch. (data: 8.16e-04). ETA=14:24:02, max mem: 15.9 GB 
[10/27 10:53:57][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 18.0720,	0.6445 s / batch. (data: 2.55e-02). ETA=14:47:45, max mem: 15.9 GB 
[10/27 10:55:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 3.4957,	0.6307 s / batch. (data: 7.82e-04). ETA=14:27:46, max mem: 15.9 GB 
[10/27 10:56:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 22.0977,	0.6389 s / batch. (data: 2.95e-04). ETA=14:38:00, max mem: 15.9 GB 
[10/27 10:57:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6465 s / batch. (data: 1.04e-02). ETA=14:47:16, max mem: 15.9 GB 
[10/27 10:58:10][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 7.3367,	0.6301 s / batch. (data: 8.00e-04). ETA=14:23:43, max mem: 15.9 GB 
[10/27 10:59:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6186 s / batch. (data: 3.44e-04). ETA=14:06:59, max mem: 15.9 GB 
[10/27 11:00:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0022,	0.6199 s / batch. (data: 3.21e-04). ETA=14:07:44, max mem: 15.9 GB 
[10/27 11:01:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6262 s / batch. (data: 7.09e-04). ETA=14:15:20, max mem: 15.9 GB 
[10/27 11:02:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6174 s / batch. (data: 1.69e-04). ETA=14:02:15, max mem: 15.9 GB 
[10/27 11:02:26][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 4.05e-03, avg batch time: 0.6335, average train loss: 10.8087
[10/27 11:03:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.483, 0.2260 s / batch. (data: 4.36e-05)max mem: 15.94594 GB 
[10/27 11:03:27][INFO] visual_prompt:  316: Inference (val):avg data time: 4.07e-05, avg batch time: 0.2319, average loss: 2.2421
[10/27 11:03:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.46	
[10/27 11:03:27][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 2.310060120195532
[10/27 11:04:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 22.2482,	0.6234 s / batch. (data: 3.15e-04). ETA=14:09:21, max mem: 15.9 GB 
[10/27 11:05:36][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0003,	0.6773 s / batch. (data: 3.72e-02). ETA=15:21:34, max mem: 15.9 GB 
[10/27 11:06:39][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 9.0920,	0.6189 s / batch. (data: 2.99e-04). ETA=14:01:08, max mem: 15.9 GB 
[10/27 11:07:43][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6175 s / batch. (data: 3.30e-04). ETA=13:58:15, max mem: 15.9 GB 
[10/27 11:08:46][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6480 s / batch. (data: 7.37e-04). ETA=14:38:31, max mem: 15.9 GB 
[10/27 11:09:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 48.2524,	0.6178 s / batch. (data: 2.60e-04). ETA=13:56:30, max mem: 15.9 GB 
[10/27 11:10:52][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 20.6314,	0.6308 s / batch. (data: 7.79e-04). ETA=14:13:07, max mem: 15.9 GB 
[10/27 11:11:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.5124,	0.6478 s / batch. (data: 7.94e-04). ETA=14:35:00, max mem: 15.9 GB 
[10/27 11:12:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 15.0546,	0.6307 s / batch. (data: 1.17e-03). ETA=14:10:47, max mem: 15.9 GB 
[10/27 11:14:02][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 3.6670,	0.6310 s / batch. (data: 7.87e-04). ETA=14:10:11, max mem: 15.9 GB 
[10/27 11:15:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6171 s / batch. (data: 1.42e-04). ETA=13:50:26, max mem: 15.9 GB 
[10/27 11:15:09][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 4.57e-03, avg batch time: 0.6346, average train loss: 9.6952
[10/27 11:15:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 20.661, 0.2252 s / batch. (data: 4.46e-05)max mem: 15.94594 GB 
[10/27 11:16:09][INFO] visual_prompt:  316: Inference (val):avg data time: 4.16e-05, avg batch time: 0.2336, average loss: 22.7357
[10/27 11:16:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.41	
[10/27 11:16:09][INFO] visual_prompt:   42: Stopping early.
