[10/26 02:14:37][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/26 02:14:38][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/26 02:14:38][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/26 02:14:38][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/26 02:14:38][INFO] visual_prompt:  108: Training with config:
[10/26 02:14:38][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/26 02:14:38][INFO] visual_prompt:   55: Loading training data...
[10/26 02:14:38][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/26 02:14:38][INFO] visual_prompt:   57: Loading validation data...
[10/26 02:14:38][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/26 02:14:38][INFO] visual_prompt:   38: Constructing models...
[10/26 02:14:40][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/26 02:14:40][INFO] visual_prompt:   54: tuned percent:0.522
[10/26 02:14:40][INFO] visual_prompt:   40: Device used for model: 0
[10/26 02:14:40][INFO] visual_prompt:   40: Setting up Evaluator...
[10/26 02:14:40][INFO] visual_prompt:   42: Setting up Trainer...
[10/26 02:14:40][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/26 02:14:40][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/26 02:15:46][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6237 s / batch. (data: 3.45e-04). ETA=19:08:40, max mem: 15.9 GB 
[10/26 02:16:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6408 s / batch. (data: 7.80e-04). ETA=19:39:05, max mem: 15.9 GB 
[10/26 02:17:53][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6467 s / batch. (data: 8.11e-04). ETA=19:48:51, max mem: 15.9 GB 
[10/26 02:18:56][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6303 s / batch. (data: 2.93e-04). ETA=19:17:37, max mem: 15.9 GB 
[10/26 02:19:59][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6562 s / batch. (data: 2.44e-02). ETA=20:04:08, max mem: 15.9 GB 
[10/26 02:21:03][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6320 s / batch. (data: 7.79e-04). ETA=19:18:45, max mem: 15.9 GB 
[10/26 02:22:06][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6468 s / batch. (data: 9.43e-04). ETA=19:44:44, max mem: 15.9 GB 
[10/26 02:23:10][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6440 s / batch. (data: 7.24e-04). ETA=19:38:33, max mem: 15.9 GB 
[10/26 02:24:13][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6508 s / batch. (data: 3.14e-04). ETA=19:49:49, max mem: 15.9 GB 
[10/26 02:25:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6189 s / batch. (data: 3.47e-04). ETA=18:50:33, max mem: 15.9 GB 
[10/26 02:26:20][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6181 s / batch. (data: 2.10e-04). ETA=18:47:58, max mem: 15.9 GB 
[10/26 02:26:23][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.82e-03, avg batch time: 0.6357, average train loss: 1.4028
[10/26 02:27:13][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2386 s / batch. (data: 3.91e-05)max mem: 15.92341 GB 
[10/26 02:27:24][INFO] visual_prompt:  316: Inference (val):avg data time: 1.31e-04, avg batch time: 0.2328, average loss: 1.3505
[10/26 02:27:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/26 02:27:24][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 1.0
[10/26 02:28:28][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 8.2329,	0.6213 s / batch. (data: 2.96e-04). ETA=18:52:45, max mem: 15.9 GB 
[10/26 02:29:32][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9971,	0.6326 s / batch. (data: 7.79e-04). ETA=19:12:23, max mem: 15.9 GB 
[10/26 02:30:35][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 3.1441,	0.6240 s / batch. (data: 3.22e-04). ETA=18:55:39, max mem: 15.9 GB 
[10/26 02:31:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0048,	0.6191 s / batch. (data: 3.97e-04). ETA=18:45:40, max mem: 15.9 GB 
[10/26 02:32:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 15.0241,	0.6381 s / batch. (data: 5.87e-03). ETA=19:19:13, max mem: 15.9 GB 
[10/26 02:33:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 3.3630,	0.6192 s / batch. (data: 4.11e-04). ETA=18:43:45, max mem: 15.9 GB 
[10/26 02:34:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0121,	0.6350 s / batch. (data: 1.20e-02). ETA=19:11:29, max mem: 15.9 GB 
[10/26 02:35:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 5.2975,	0.6440 s / batch. (data: 8.03e-04). ETA=19:26:42, max mem: 15.9 GB 
[10/26 02:36:54][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.4576,	0.6301 s / batch. (data: 3.09e-04). ETA=19:00:26, max mem: 15.9 GB 
[10/26 02:37:57][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0002,	0.6313 s / batch. (data: 3.91e-04). ETA=19:01:36, max mem: 15.9 GB 
[10/26 02:39:01][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0124,	0.6178 s / batch. (data: 1.33e-04). ETA=18:36:00, max mem: 15.9 GB 
[10/26 02:39:04][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.96e-03, avg batch time: 0.6334, average train loss: 6.9544
[10/26 02:39:54][INFO] visual_prompt:  303: 	Test 100/123. loss: 17.935, 0.2247 s / batch. (data: 3.41e-05)max mem: 15.92341 GB 
[10/26 02:40:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-05, avg batch time: 0.2323, average loss: 16.1472
[10/26 02:40:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.01	
[10/26 02:40:05][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 2.0
[10/26 02:41:11][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 21.2589,	0.6324 s / batch. (data: 7.91e-04). ETA=19:01:17, max mem: 15.9 GB 
[10/26 02:42:15][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6192 s / batch. (data: 3.15e-04). ETA=18:36:25, max mem: 15.9 GB 
[10/26 02:43:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6568 s / batch. (data: 1.68e-02). ETA=19:43:08, max mem: 15.9 GB 
[10/26 02:44:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.1936,	0.6320 s / batch. (data: 7.56e-04). ETA=18:57:28, max mem: 15.9 GB 
[10/26 02:45:24][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 28.6354,	0.6177 s / batch. (data: 3.49e-04). ETA=18:30:43, max mem: 15.9 GB 
[10/26 02:46:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2283,	0.6184 s / batch. (data: 2.75e-04). ETA=18:31:00, max mem: 15.9 GB 
[10/26 02:47:31][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.1187,	0.6356 s / batch. (data: 8.23e-04). ETA=19:00:46, max mem: 15.9 GB 
[10/26 02:48:34][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6442 s / batch. (data: 1.11e-03). ETA=19:15:06, max mem: 15.9 GB 
[10/26 02:49:38][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 51.4848,	0.6235 s / batch. (data: 3.14e-04). ETA=18:36:54, max mem: 15.9 GB 
[10/26 02:50:41][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 16.5636,	0.6429 s / batch. (data: 5.92e-03). ETA=19:10:36, max mem: 15.9 GB 
[10/26 02:51:44][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 7.7735,	0.6171 s / batch. (data: 1.50e-04). ETA=18:23:32, max mem: 15.9 GB 
[10/26 02:51:48][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.39e-03, avg batch time: 0.6357, average train loss: 9.6698
[10/26 02:52:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 22.757, 0.2250 s / batch. (data: 4.22e-05)max mem: 15.92341 GB 
[10/26 02:52:49][INFO] visual_prompt:  316: Inference (val):avg data time: 9.71e-05, avg batch time: 0.2316, average loss: 25.1383
[10/26 02:52:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.55	
[10/26 02:52:49][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 3.0
[10/26 02:53:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6345 s / batch. (data: 8.71e-04). ETA=18:53:30, max mem: 15.9 GB 
[10/26 02:54:57][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 78.0139,	0.6317 s / batch. (data: 8.01e-04). ETA=18:47:26, max mem: 15.9 GB 
[10/26 02:56:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2403,	0.6183 s / batch. (data: 4.51e-04). ETA=18:22:24, max mem: 15.9 GB 
[10/26 02:57:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.4286,	0.6417 s / batch. (data: 1.05e-02). ETA=19:03:04, max mem: 15.9 GB 
[10/26 02:58:07][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0386,	0.6176 s / batch. (data: 3.18e-04). ETA=18:19:07, max mem: 15.9 GB 
[10/26 02:59:10][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0427,	0.6312 s / batch. (data: 8.12e-04). ETA=18:42:19, max mem: 15.9 GB 
[10/26 03:00:13][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 55.8299,	0.6190 s / batch. (data: 3.24e-04). ETA=18:19:37, max mem: 15.9 GB 
[10/26 03:01:16][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6322 s / batch. (data: 8.03e-04). ETA=18:42:02, max mem: 15.9 GB 
[10/26 03:02:19][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 29.6817,	0.6746 s / batch. (data: 2.66e-02). ETA=19:56:03, max mem: 15.9 GB 
[10/26 03:03:22][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.6143,	0.6327 s / batch. (data: 7.90e-04). ETA=18:40:44, max mem: 15.9 GB 
[10/26 03:04:26][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 43.9399,	0.6132 s / batch. (data: 1.59e-04). ETA=18:05:06, max mem: 15.9 GB 
[10/26 03:04:30][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.70e-03, avg batch time: 0.6338, average train loss: 11.3971
[10/26 03:05:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 8.135, 0.2483 s / batch. (data: 4.34e-05)max mem: 15.92341 GB 
[10/26 03:05:30][INFO] visual_prompt:  316: Inference (val):avg data time: 4.53e-05, avg batch time: 0.2343, average loss: 9.2517
[10/26 03:05:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.82	
[10/26 03:05:30][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 4.0
[10/26 03:06:35][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 10.4839,	0.6241 s / batch. (data: 4.09e-04). ETA=18:23:18, max mem: 15.9 GB 
[10/26 03:07:38][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6181 s / batch. (data: 4.31e-04). ETA=18:11:43, max mem: 15.9 GB 
[10/26 03:08:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 7.2271,	0.6185 s / batch. (data: 3.11e-04). ETA=18:11:25, max mem: 15.9 GB 
[10/26 03:09:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 17.1649,	0.6284 s / batch. (data: 5.42e-03). ETA=18:27:52, max mem: 15.9 GB 
[10/26 03:10:48][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6177 s / batch. (data: 2.98e-04). ETA=18:07:56, max mem: 15.9 GB 
[10/26 03:11:51][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6232 s / batch. (data: 3.22e-04). ETA=18:16:38, max mem: 15.9 GB 
[10/26 03:12:54][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 32.5870,	0.6335 s / batch. (data: 8.37e-04). ETA=18:33:38, max mem: 15.9 GB 
[10/26 03:13:57][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 17.3638,	0.6180 s / batch. (data: 3.08e-04). ETA=18:05:19, max mem: 15.9 GB 
[10/26 03:15:01][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 11.3464,	0.6321 s / batch. (data: 7.33e-04). ETA=18:29:01, max mem: 15.9 GB 
[10/26 03:16:04][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6296 s / batch. (data: 1.22e-02). ETA=18:23:41, max mem: 15.9 GB 
[10/26 03:17:07][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 13.8585,	0.6166 s / batch. (data: 1.53e-04). ETA=17:59:46, max mem: 15.9 GB 
[10/26 03:17:11][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.26e-03, avg batch time: 0.6334, average train loss: 14.2390
[10/26 03:18:00][INFO] visual_prompt:  303: 	Test 100/123. loss: 13.652, 0.2253 s / batch. (data: 3.62e-05)max mem: 15.92341 GB 
[10/26 03:18:11][INFO] visual_prompt:  316: Inference (val):avg data time: 1.05e-04, avg batch time: 0.2318, average loss: 12.2119
[10/26 03:18:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.59	
[10/26 03:18:11][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 5.0
[10/26 03:19:16][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 5.0853,	0.6294 s / batch. (data: 1.30e-02). ETA=18:21:06, max mem: 15.9 GB 
[10/26 03:20:19][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6190 s / batch. (data: 2.96e-04). ETA=18:01:54, max mem: 15.9 GB 
[10/26 03:21:22][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6196 s / batch. (data: 8.19e-04). ETA=18:01:59, max mem: 15.9 GB 
[10/26 03:22:26][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6186 s / batch. (data: 3.35e-04). ETA=17:59:09, max mem: 15.9 GB 
[10/26 03:23:29][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.5571,	0.6188 s / batch. (data: 2.73e-04). ETA=17:58:23, max mem: 15.9 GB 
[10/26 03:24:32][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6180 s / batch. (data: 3.27e-04). ETA=17:56:00, max mem: 15.9 GB 
[10/26 03:25:35][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.9150,	0.6170 s / batch. (data: 3.24e-04). ETA=17:53:14, max mem: 15.9 GB 
[10/26 03:26:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 44.6903,	0.6116 s / batch. (data: 3.14e-04). ETA=17:42:50, max mem: 15.9 GB 
[10/26 03:27:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6444 s / batch. (data: 7.46e-04). ETA=18:38:48, max mem: 15.9 GB 
[10/26 03:28:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.2034,	0.6463 s / batch. (data: 2.68e-02). ETA=18:40:57, max mem: 15.9 GB 
[10/26 03:29:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6185 s / batch. (data: 1.51e-04). ETA=17:51:43, max mem: 15.9 GB 
[10/26 03:29:51][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 3.71e-03, avg batch time: 0.6330, average train loss: 18.4254
[10/26 03:30:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.434, 0.2354 s / batch. (data: 3.10e-05)max mem: 15.92341 GB 
[10/26 03:30:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.2318, average loss: 5.8284
[10/26 03:30:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.24	
[10/26 03:30:52][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 6.0
[10/26 03:31:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8344,	0.6180 s / batch. (data: 3.82e-04). ETA=17:49:50, max mem: 15.9 GB 
[10/26 03:33:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 79.8605,	0.6190 s / batch. (data: 3.59e-04). ETA=17:50:31, max mem: 15.9 GB 
[10/26 03:34:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6208 s / batch. (data: 3.19e-04). ETA=17:52:33, max mem: 15.9 GB 
[10/26 03:35:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1517,	0.6314 s / batch. (data: 8.03e-04). ETA=18:09:53, max mem: 15.9 GB 
[10/26 03:36:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 80.9803,	0.6473 s / batch. (data: 2.72e-04). ETA=18:36:12, max mem: 15.9 GB 
[10/26 03:37:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 48.7243,	0.6139 s / batch. (data: 3.03e-04). ETA=17:37:39, max mem: 15.9 GB 
[10/26 03:38:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 56.5040,	0.6555 s / batch. (data: 8.73e-04). ETA=18:48:11, max mem: 15.9 GB 
[10/26 03:39:19][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6309 s / batch. (data: 8.42e-04). ETA=18:04:49, max mem: 15.9 GB 
[10/26 03:40:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 31.3744,	0.6318 s / batch. (data: 2.96e-04). ETA=18:05:15, max mem: 15.9 GB 
[10/26 03:41:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 10.6432,	0.6244 s / batch. (data: 6.40e-03). ETA=17:51:34, max mem: 15.9 GB 
[10/26 03:42:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 28.2053,	0.6187 s / batch. (data: 1.54e-04). ETA=17:40:37, max mem: 15.9 GB 
[10/26 03:42:33][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.02e-03, avg batch time: 0.6337, average train loss: 22.6321
[10/26 03:43:23][INFO] visual_prompt:  303: 	Test 100/123. loss: 14.142, 0.2437 s / batch. (data: 3.12e-05)max mem: 15.92341 GB 
[10/26 03:43:33][INFO] visual_prompt:  316: Inference (val):avg data time: 9.81e-05, avg batch time: 0.2310, average loss: 12.7301
[10/26 03:43:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.85	
[10/26 03:43:33][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 7.0
[10/26 03:44:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6413 s / batch. (data: 7.99e-04). ETA=18:18:19, max mem: 15.9 GB 
[10/26 03:45:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 16.7423,	0.6453 s / batch. (data: 8.05e-04). ETA=18:24:01, max mem: 15.9 GB 
[10/26 03:46:45][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6436 s / batch. (data: 7.92e-04). ETA=18:20:05, max mem: 15.9 GB 
[10/26 03:47:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6133 s / batch. (data: 2.28e-04). ETA=17:27:17, max mem: 15.9 GB 
[10/26 03:48:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6295 s / batch. (data: 5.43e-03). ETA=17:53:55, max mem: 15.9 GB 
[10/26 03:49:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6267 s / batch. (data: 3.10e-04). ETA=17:48:03, max mem: 15.9 GB 
[10/26 03:50:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 19.7348,	0.6193 s / batch. (data: 3.15e-04). ETA=17:34:21, max mem: 15.9 GB 
[10/26 03:52:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 35.4319,	0.6486 s / batch. (data: 2.21e-02). ETA=18:23:16, max mem: 15.9 GB 
[10/26 03:53:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7153,	0.6174 s / batch. (data: 3.47e-04). ETA=17:29:09, max mem: 15.9 GB 
[10/26 03:54:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 43.4001,	0.6188 s / batch. (data: 4.67e-04). ETA=17:30:30, max mem: 15.9 GB 
[10/26 03:55:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 8.3717,	0.6162 s / batch. (data: 1.56e-04). ETA=17:25:08, max mem: 15.9 GB 
[10/26 03:55:13][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.46e-03, avg batch time: 0.6326, average train loss: 24.6478
[10/26 03:56:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 9.247, 0.2292 s / batch. (data: 3.91e-05)max mem: 15.92341 GB 
[10/26 03:56:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2315, average loss: 8.2102
[10/26 03:56:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.94	
[10/26 03:56:14][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 8.0
[10/26 03:57:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 116.1917,	0.6418 s / batch. (data: 2.52e-02). ETA=18:07:16, max mem: 15.9 GB 
[10/26 03:58:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6121 s / batch. (data: 3.41e-04). ETA=17:16:04, max mem: 15.9 GB 
[10/26 03:59:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 71.6447,	0.6276 s / batch. (data: 8.03e-04). ETA=17:41:09, max mem: 15.9 GB 
[10/26 04:00:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6151 s / batch. (data: 3.09e-04). ETA=17:19:03, max mem: 15.9 GB 
[10/26 04:01:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 112.2598,	0.6709 s / batch. (data: 1.10e-02). ETA=18:52:14, max mem: 15.9 GB 
[10/26 04:02:34][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 5.3968,	0.6428 s / batch. (data: 8.02e-04). ETA=18:03:38, max mem: 15.9 GB 
[10/26 04:03:37][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6181 s / batch. (data: 3.09e-04). ETA=17:20:58, max mem: 15.9 GB 
[10/26 04:04:41][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 11.4060,	0.6379 s / batch. (data: 3.24e-04). ETA=17:53:20, max mem: 15.9 GB 
[10/26 04:05:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 33.6840,	0.6453 s / batch. (data: 5.75e-04). ETA=18:04:36, max mem: 15.9 GB 
[10/26 04:06:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6308 s / batch. (data: 7.61e-04). ETA=17:39:18, max mem: 15.9 GB 
[10/26 04:07:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 32.2946,	0.6159 s / batch. (data: 1.37e-04). ETA=17:13:10, max mem: 15.9 GB 
[10/26 04:07:53][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.89e-03, avg batch time: 0.6325, average train loss: 27.6711
[10/26 04:08:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 17.493, 0.2380 s / batch. (data: 2.91e-05)max mem: 15.92341 GB 
[10/26 04:08:54][INFO] visual_prompt:  316: Inference (val):avg data time: 2.33e-04, avg batch time: 0.2317, average loss: 19.5376
[10/26 04:08:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.25	
[10/26 04:08:54][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 9.0
[10/26 04:09:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 46.6708,	0.6306 s / batch. (data: 7.82e-04). ETA=17:36:46, max mem: 15.9 GB 
[10/26 04:11:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 4.8445,	0.6179 s / batch. (data: 3.27e-04). ETA=17:14:23, max mem: 15.9 GB 
[10/26 04:12:04][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 76.1314,	0.6200 s / batch. (data: 3.40e-04). ETA=17:16:53, max mem: 15.9 GB 
[10/26 04:13:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 25.9983,	0.6311 s / batch. (data: 1.11e-03). ETA=17:34:26, max mem: 15.9 GB 
[10/26 04:14:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 19.8879,	0.6479 s / batch. (data: 1.12e-02). ETA=18:01:22, max mem: 15.9 GB 
[10/26 04:15:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 129.6018,	0.6320 s / batch. (data: 3.32e-04). ETA=17:33:46, max mem: 15.9 GB 
[10/26 04:16:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 8.0823,	0.6457 s / batch. (data: 9.86e-04). ETA=17:55:37, max mem: 15.9 GB 
[10/26 04:17:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 12.3471,	0.6440 s / batch. (data: 8.35e-04). ETA=17:51:41, max mem: 15.9 GB 
[10/26 04:18:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 79.5072,	0.6270 s / batch. (data: 3.24e-04). ETA=17:22:21, max mem: 15.9 GB 
[10/26 04:19:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6436 s / batch. (data: 7.98e-03). ETA=17:48:53, max mem: 15.9 GB 
[10/26 04:20:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.1020,	0.6163 s / batch. (data: 1.70e-04). ETA=17:02:32, max mem: 15.9 GB 
[10/26 04:20:33][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.83e-03, avg batch time: 0.6319, average train loss: 38.3915
[10/26 04:21:22][INFO] visual_prompt:  303: 	Test 100/123. loss: 18.348, 0.2272 s / batch. (data: 2.86e-05)max mem: 15.92341 GB 
[10/26 04:21:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2320, average loss: 16.5184
[10/26 04:21:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.70	
[10/26 04:21:33][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 10.0
[10/26 04:22:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 124.5439,	0.6204 s / batch. (data: 7.64e-04). ETA=17:08:15, max mem: 15.9 GB 
[10/26 04:23:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 31.6969,	0.6402 s / batch. (data: 8.07e-04). ETA=17:39:55, max mem: 15.9 GB 
[10/26 04:24:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 64.7448,	0.6314 s / batch. (data: 7.26e-04). ETA=17:24:18, max mem: 15.9 GB 
[10/26 04:25:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 54.9290,	0.6368 s / batch. (data: 7.79e-04). ETA=17:32:15, max mem: 15.9 GB 
[10/26 04:26:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.4568,	0.6328 s / batch. (data: 7.37e-04). ETA=17:24:33, max mem: 15.9 GB 
[10/26 04:27:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6165 s / batch. (data: 7.89e-04). ETA=16:56:37, max mem: 15.9 GB 
[10/26 04:28:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6211 s / batch. (data: 7.74e-04). ETA=17:03:06, max mem: 15.9 GB 
[10/26 04:30:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 11.3578,	0.6447 s / batch. (data: 1.34e-02). ETA=17:41:02, max mem: 15.9 GB 
[10/26 04:31:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 53.0086,	0.6177 s / batch. (data: 3.39e-04). ETA=16:55:31, max mem: 15.9 GB 
[10/26 04:32:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6098 s / batch. (data: 3.09e-04). ETA=16:41:33, max mem: 15.9 GB 
[10/26 04:33:08][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 32.1043,	0.6174 s / batch. (data: 1.49e-04). ETA=16:52:52, max mem: 15.9 GB 
[10/26 04:33:12][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.38e-03, avg batch time: 0.6319, average train loss: 34.6075
[10/26 04:34:02][INFO] visual_prompt:  303: 	Test 100/123. loss: 11.041, 0.2353 s / batch. (data: 4.03e-05)max mem: 15.92341 GB 
[10/26 04:34:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2325, average loss: 12.5504
[10/26 04:34:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.65	
[10/26 04:34:13][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 9.996954135095478
[10/26 04:35:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6178 s / batch. (data: 3.20e-04). ETA=16:52:27, max mem: 15.9 GB 
[10/26 04:36:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9730,	0.6429 s / batch. (data: 8.23e-04). ETA=17:32:34, max mem: 15.9 GB 
[10/26 04:37:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 93.0208,	0.6478 s / batch. (data: 2.81e-04). ETA=17:39:33, max mem: 15.9 GB 
[10/26 04:38:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2356,	0.6351 s / batch. (data: 7.80e-04). ETA=17:17:45, max mem: 15.9 GB 
[10/26 04:39:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 86.2861,	0.6230 s / batch. (data: 2.71e-04). ETA=16:56:48, max mem: 15.9 GB 
[10/26 04:40:34][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 15.2151,	0.6232 s / batch. (data: 7.50e-04). ETA=16:56:12, max mem: 15.9 GB 
[10/26 04:41:37][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 20.1023,	0.6336 s / batch. (data: 7.63e-04). ETA=17:12:05, max mem: 15.9 GB 
[10/26 04:42:40][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 26.0333,	0.6192 s / batch. (data: 3.01e-04). ETA=16:47:38, max mem: 15.9 GB 
[10/26 04:43:43][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6433 s / batch. (data: 8.00e-04). ETA=17:25:44, max mem: 15.9 GB 
[10/26 04:44:46][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 70.2770,	0.6390 s / batch. (data: 7.63e-04). ETA=17:17:41, max mem: 15.9 GB 
[10/26 04:45:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 97.4484,	0.6129 s / batch. (data: 1.56e-04). ETA=16:34:20, max mem: 15.9 GB 
[10/26 04:45:53][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 4.99e-03, avg batch time: 0.6333, average train loss: 33.2365
[10/26 04:46:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.145, 0.2446 s / batch. (data: 4.17e-05)max mem: 15.92341 GB 
[10/26 04:46:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2332, average loss: 4.0822
[10/26 04:46:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.12	
[10/26 04:46:54][INFO] visual_prompt:   36: Best epoch 12: best metric: -4.082
[10/26 04:46:54][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 9.987820251299121
[10/26 04:47:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 231.7540,	0.6313 s / batch. (data: 7.63e-04). ETA=17:02:55, max mem: 15.9 GB 
[10/26 04:49:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 61.7183,	0.6221 s / batch. (data: 7.89e-04). ETA=16:46:58, max mem: 15.9 GB 
[10/26 04:50:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5049,	0.6176 s / batch. (data: 3.37e-04). ETA=16:38:45, max mem: 15.9 GB 
[10/26 04:51:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 71.7070,	0.6187 s / batch. (data: 3.58e-04). ETA=16:39:29, max mem: 15.9 GB 
[10/26 04:52:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 4.4094,	0.6376 s / batch. (data: 7.62e-04). ETA=17:08:57, max mem: 15.9 GB 
[10/26 04:53:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 5.2783,	0.6330 s / batch. (data: 1.53e-02). ETA=17:00:26, max mem: 15.9 GB 
[10/26 04:54:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 35.1590,	0.6333 s / batch. (data: 3.17e-04). ETA=16:59:57, max mem: 15.9 GB 
[10/26 04:55:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 32.6473,	0.6186 s / batch. (data: 2.95e-04). ETA=16:35:13, max mem: 15.9 GB 
[10/26 04:56:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6573 s / batch. (data: 4.08e-02). ETA=17:36:25, max mem: 15.9 GB 
[10/26 04:57:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6217 s / batch. (data: 8.47e-04). ETA=16:38:04, max mem: 15.9 GB 
[10/26 04:58:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 23.6651,	0.6175 s / batch. (data: 1.71e-04). ETA=16:30:24, max mem: 15.9 GB 
[10/26 04:58:33][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.60e-03, avg batch time: 0.6323, average train loss: 37.4785
[10/26 04:59:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 22.402, 0.2377 s / batch. (data: 3.89e-05)max mem: 15.92341 GB 
[10/26 04:59:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.75e-05, avg batch time: 0.2324, average loss: 20.2268
[10/26 04:59:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.32	
[10/26 04:59:34][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 9.972609476841367
[10/26 05:00:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 29.9771,	0.6453 s / batch. (data: 7.71e-04). ETA=17:13:48, max mem: 15.9 GB 
[10/26 05:01:42][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 44.6806,	0.6253 s / batch. (data: 8.15e-04). ETA=16:40:37, max mem: 15.9 GB 
[10/26 05:02:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 45.9035,	0.6240 s / batch. (data: 3.15e-04). ETA=16:37:33, max mem: 15.9 GB 
[10/26 05:03:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6126 s / batch. (data: 8.32e-04). ETA=16:18:23, max mem: 15.9 GB 
[10/26 05:04:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 40.4977,	0.6181 s / batch. (data: 3.26e-04). ETA=16:26:05, max mem: 15.9 GB 
[10/26 05:05:55][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 30.7770,	0.6287 s / batch. (data: 3.45e-04). ETA=16:41:57, max mem: 15.9 GB 
[10/26 05:06:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6390 s / batch. (data: 7.96e-04). ETA=16:57:20, max mem: 15.9 GB 
[10/26 05:08:01][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 21.7468,	0.6547 s / batch. (data: 3.36e-02). ETA=17:21:10, max mem: 15.9 GB 
[10/26 05:09:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 14.7986,	0.6412 s / batch. (data: 7.88e-04). ETA=16:58:36, max mem: 15.9 GB 
[10/26 05:10:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 11.8635,	0.6331 s / batch. (data: 6.98e-04). ETA=16:44:43, max mem: 15.9 GB 
[10/26 05:11:10][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 23.6536,	0.6170 s / batch. (data: 1.61e-04). ETA=16:18:12, max mem: 15.9 GB 
[10/26 05:11:14][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.75e-03, avg batch time: 0.6327, average train loss: 31.8007
[10/26 05:12:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.501, 0.2411 s / batch. (data: 4.08e-05)max mem: 15.92341 GB 
[10/26 05:12:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2322, average loss: 1.5321
[10/26 05:12:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 51.64	
[10/26 05:12:14][INFO] visual_prompt:   36: Best epoch 14: best metric: -1.532
[10/26 05:12:14][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 9.951340343707852
[10/26 05:13:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 34.5650,	0.6174 s / batch. (data: 3.29e-04). ETA=16:17:44, max mem: 15.9 GB 
[10/26 05:14:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 24.7211,	0.6324 s / batch. (data: 7.60e-04). ETA=16:40:25, max mem: 15.9 GB 
[10/26 05:15:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 48.2212,	0.6380 s / batch. (data: 7.95e-04). ETA=16:48:12, max mem: 15.9 GB 
[10/26 05:16:29][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 305.2171,	0.6317 s / batch. (data: 8.08e-04). ETA=16:37:13, max mem: 15.9 GB 
[10/26 05:17:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0993,	0.6169 s / batch. (data: 3.22e-04). ETA=16:12:49, max mem: 15.9 GB 
[10/26 05:18:34][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 109.2182,	0.6341 s / batch. (data: 7.94e-04). ETA=16:38:49, max mem: 15.9 GB 
[10/26 05:19:37][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 33.5162,	0.6412 s / batch. (data: 2.63e-02). ETA=16:48:59, max mem: 15.9 GB 
[10/26 05:20:40][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 33.9572,	0.6219 s / batch. (data: 3.28e-04). ETA=16:17:32, max mem: 15.9 GB 
[10/26 05:21:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 74.6902,	0.6457 s / batch. (data: 3.36e-04). ETA=16:53:52, max mem: 15.9 GB 
[10/26 05:22:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 7.1354,	0.6224 s / batch. (data: 2.89e-04). ETA=16:16:21, max mem: 15.9 GB 
[10/26 05:23:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 100.2845,	0.6119 s / batch. (data: 1.53e-04). ETA=15:58:46, max mem: 15.9 GB 
[10/26 05:23:54][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.06e-03, avg batch time: 0.6324, average train loss: 43.2634
[10/26 05:24:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 72.649, 0.2326 s / batch. (data: 4.10e-05)max mem: 15.92341 GB 
[10/26 05:24:54][INFO] visual_prompt:  316: Inference (val):avg data time: 4.00e-05, avg batch time: 0.2318, average loss: 79.9774
[10/26 05:24:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.48	
[10/26 05:24:54][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 9.924038765061042
[10/26 05:25:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6164 s / batch. (data: 3.20e-04). ETA=16:04:43, max mem: 15.9 GB 
[10/26 05:27:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 11.8115,	0.6176 s / batch. (data: 3.00e-04). ETA=16:05:33, max mem: 15.9 GB 
[10/26 05:28:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6393 s / batch. (data: 7.70e-04). ETA=16:38:30, max mem: 15.9 GB 
[10/26 05:29:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 110.9579,	0.6292 s / batch. (data: 3.19e-04). ETA=16:21:34, max mem: 15.9 GB 
[10/26 05:30:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 30.2063,	0.6480 s / batch. (data: 8.16e-04). ETA=16:49:55, max mem: 15.9 GB 
[10/26 05:31:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 22.9468,	0.6188 s / batch. (data: 3.38e-04). ETA=16:03:25, max mem: 15.9 GB 
[10/26 05:32:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 8.7799,	0.6439 s / batch. (data: 7.68e-04). ETA=16:41:21, max mem: 15.9 GB 
[10/26 05:33:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 96.0372,	0.6434 s / batch. (data: 5.93e-03). ETA=16:39:31, max mem: 15.9 GB 
[10/26 05:34:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.3734,	0.6447 s / batch. (data: 8.53e-04). ETA=16:40:29, max mem: 15.9 GB 
[10/26 05:35:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 69.6492,	0.6187 s / batch. (data: 3.06e-04). ETA=15:59:01, max mem: 15.9 GB 
[10/26 05:36:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6065 s / batch. (data: 1.39e-04). ETA=15:39:13, max mem: 15.9 GB 
[10/26 05:36:34][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.12e-03, avg batch time: 0.6322, average train loss: 33.8372
[10/26 05:37:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 14.168, 0.2252 s / batch. (data: 3.96e-05)max mem: 15.92341 GB 
[10/26 05:37:34][INFO] visual_prompt:  316: Inference (val):avg data time: 1.29e-04, avg batch time: 0.2332, average loss: 12.8319
[10/26 05:37:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[10/26 05:37:34][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 9.890738003669028
[10/26 05:38:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4244,	0.6165 s / batch. (data: 4.15e-04). ETA=15:53:32, max mem: 15.9 GB 
[10/26 05:39:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6234 s / batch. (data: 5.44e-03). ETA=16:03:08, max mem: 15.9 GB 
[10/26 05:40:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6470 s / batch. (data: 1.05e-02). ETA=16:38:33, max mem: 15.9 GB 
[10/26 05:41:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 239.9983,	0.6435 s / batch. (data: 1.10e-02). ETA=16:32:04, max mem: 15.9 GB 
[10/26 05:42:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8629,	0.6183 s / batch. (data: 2.70e-04). ETA=15:52:16, max mem: 15.9 GB 
[10/26 05:43:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 7.1346,	0.6294 s / batch. (data: 1.20e-02). ETA=16:08:16, max mem: 15.9 GB 
[10/26 05:44:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0373,	0.6319 s / batch. (data: 7.81e-04). ETA=16:11:02, max mem: 15.9 GB 
[10/26 05:46:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 10.8997,	0.6178 s / batch. (data: 3.30e-04). ETA=15:48:20, max mem: 15.9 GB 
[10/26 05:47:05][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6314 s / batch. (data: 2.62e-04). ETA=16:08:10, max mem: 15.9 GB 
[10/26 05:48:08][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6086 s / batch. (data: 3.22e-04). ETA=15:32:15, max mem: 15.9 GB 
[10/26 05:49:11][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6175 s / batch. (data: 1.63e-04). ETA=15:44:53, max mem: 15.9 GB 
[10/26 05:49:14][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.45e-03, avg batch time: 0.6328, average train loss: 36.4691
[10/26 05:50:05][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.424, 0.2244 s / batch. (data: 4.08e-05)max mem: 15.92341 GB 
[10/26 05:50:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2331, average loss: 6.6810
[10/26 05:50:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.07	
[10/26 05:50:15][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 9.851478631379981
[10/26 05:51:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6281 s / batch. (data: 9.31e-04). ETA=16:00:00, max mem: 15.9 GB 
[10/26 05:52:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 148.7183,	0.6433 s / batch. (data: 8.57e-04). ETA=16:22:01, max mem: 15.9 GB 
[10/26 05:53:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 189.0644,	0.6183 s / batch. (data: 3.18e-04). ETA=15:42:55, max mem: 15.9 GB 
[10/26 05:54:29][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 33.9241,	0.6156 s / batch. (data: 3.57e-04). ETA=15:37:48, max mem: 15.9 GB 
[10/26 05:55:32][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6372 s / batch. (data: 3.04e-02). ETA=16:09:39, max mem: 15.9 GB 
[10/26 05:56:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 30.3311,	0.6267 s / batch. (data: 3.16e-04). ETA=15:52:36, max mem: 15.9 GB 
[10/26 05:57:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6309 s / batch. (data: 8.00e-04). ETA=15:57:50, max mem: 15.9 GB 
[10/26 05:58:41][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 28.4428,	0.6402 s / batch. (data: 8.07e-04). ETA=16:10:52, max mem: 15.9 GB 
[10/26 05:59:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 175.3996,	0.6525 s / batch. (data: 1.20e-03). ETA=16:28:34, max mem: 15.9 GB 
[10/26 06:00:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 31.2823,	0.6181 s / batch. (data: 3.09e-04). ETA=15:35:24, max mem: 15.9 GB 
[10/26 06:01:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6069 s / batch. (data: 1.45e-04). ETA=15:17:20, max mem: 15.9 GB 
[10/26 06:01:54][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.30e-03, avg batch time: 0.6318, average train loss: 35.5760
[10/26 06:02:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 13.952, 0.2454 s / batch. (data: 3.84e-05)max mem: 15.92341 GB 
[10/26 06:02:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2322, average loss: 13.4274
[10/26 06:02:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.62	
[10/26 06:02:54][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 9.806308479691594
[10/26 06:04:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0003,	0.6384 s / batch. (data: 7.72e-04). ETA=16:03:56, max mem: 15.9 GB 
[10/26 06:05:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 50.9047,	0.6150 s / batch. (data: 4.42e-04). ETA=15:27:30, max mem: 15.9 GB 
[10/26 06:06:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6229 s / batch. (data: 7.94e-04). ETA=15:38:27, max mem: 15.9 GB 
[10/26 06:07:09][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 29.9601,	0.6350 s / batch. (data: 8.00e-04). ETA=15:55:36, max mem: 15.9 GB 
[10/26 06:08:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 10.6438,	0.6302 s / batch. (data: 8.07e-04). ETA=15:47:23, max mem: 15.9 GB 
[10/26 06:09:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6077 s / batch. (data: 3.21e-04). ETA=15:12:26, max mem: 15.9 GB 
[10/26 06:10:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 10.5189,	0.6336 s / batch. (data: 9.43e-04). ETA=15:50:17, max mem: 15.9 GB 
[10/26 06:11:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6196 s / batch. (data: 3.20e-04). ETA=15:28:19, max mem: 15.9 GB 
[10/26 06:12:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0336,	0.6298 s / batch. (data: 3.10e-04). ETA=15:42:34, max mem: 15.9 GB 
[10/26 06:13:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6232 s / batch. (data: 8.76e-04). ETA=15:31:37, max mem: 15.9 GB 
[10/26 06:14:31][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 67.3537,	0.6175 s / batch. (data: 1.74e-04). ETA=15:22:01, max mem: 15.9 GB 
[10/26 06:14:34][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.07e-03, avg batch time: 0.6328, average train loss: 31.8030
[10/26 06:15:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 153.502, 0.2488 s / batch. (data: 4.10e-05)max mem: 15.92341 GB 
[10/26 06:15:35][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2318, average loss: 139.0392
[10/26 06:15:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.07	
[10/26 06:15:35][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 9.755282581475768
[10/26 06:16:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 6.4272,	0.6323 s / batch. (data: 1.19e-03). ETA=15:42:58, max mem: 15.9 GB 
[10/26 06:17:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 21.5890,	0.6533 s / batch. (data: 9.02e-04). ETA=16:13:13, max mem: 15.9 GB 
[10/26 06:18:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 54.7533,	0.6680 s / batch. (data: 8.40e-04). ETA=16:34:04, max mem: 15.9 GB 
[10/26 06:19:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 9.4948,	0.6406 s / batch. (data: 7.92e-04). ETA=15:52:16, max mem: 15.9 GB 
[10/26 06:20:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 72.3370,	0.6447 s / batch. (data: 8.59e-04). ETA=15:57:11, max mem: 15.9 GB 
[10/26 06:21:57][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 21.3013,	0.6195 s / batch. (data: 2.78e-04). ETA=15:18:46, max mem: 15.9 GB 
[10/26 06:23:00][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6247 s / batch. (data: 8.05e-04). ETA=15:25:22, max mem: 15.9 GB 
[10/26 06:24:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6086 s / batch. (data: 2.90e-04). ETA=15:00:34, max mem: 15.9 GB 
[10/26 06:25:06][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 172.1871,	0.6184 s / batch. (data: 3.27e-04). ETA=15:14:00, max mem: 15.9 GB 
[10/26 06:26:09][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6513 s / batch. (data: 7.76e-04). ETA=16:01:31, max mem: 15.9 GB 
[10/26 06:27:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 29.1769,	0.6172 s / batch. (data: 2.09e-04). ETA=15:10:15, max mem: 15.9 GB 
[10/26 06:27:16][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.82e-03, avg batch time: 0.6339, average train loss: 29.3827
[10/26 06:28:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.972, 0.2362 s / batch. (data: 3.89e-05)max mem: 15.92341 GB 
[10/26 06:28:17][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2338, average loss: 4.2496
[10/26 06:28:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 54.57	
[10/26 06:28:17][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 9.698463103929543
[10/26 06:29:23][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6438 s / batch. (data: 8.27e-04). ETA=15:48:19, max mem: 15.9 GB 
[10/26 06:30:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 41.0662,	0.6855 s / batch. (data: 1.10e-02). ETA=16:48:33, max mem: 15.9 GB 
[10/26 06:31:29][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6311 s / batch. (data: 8.54e-04). ETA=15:27:26, max mem: 15.9 GB 
[10/26 06:32:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 93.6149,	0.6241 s / batch. (data: 1.20e-02). ETA=15:16:12, max mem: 15.9 GB 
[10/26 06:33:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 198.2433,	0.6310 s / batch. (data: 7.96e-04). ETA=15:25:17, max mem: 15.9 GB 
[10/26 06:34:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 231.8794,	0.6331 s / batch. (data: 2.98e-04). ETA=15:27:19, max mem: 15.9 GB 
[10/26 06:35:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 16.3251,	0.6175 s / batch. (data: 2.95e-04). ETA=15:03:26, max mem: 15.9 GB 
[10/26 06:36:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 36.5582,	0.6274 s / batch. (data: 8.13e-04). ETA=15:16:51, max mem: 15.9 GB 
[10/26 06:37:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6360 s / batch. (data: 7.91e-04). ETA=15:28:21, max mem: 15.9 GB 
[10/26 06:38:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 16.1711,	0.6414 s / batch. (data: 7.88e-04). ETA=15:35:10, max mem: 15.9 GB 
[10/26 06:39:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 23.6636,	0.6173 s / batch. (data: 1.32e-04). ETA=14:58:59, max mem: 15.9 GB 
[10/26 06:39:57][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.58e-03, avg batch time: 0.6326, average train loss: 35.8901
[10/26 06:40:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 29.302, 0.2249 s / batch. (data: 2.91e-05)max mem: 15.92341 GB 
[10/26 06:40:57][INFO] visual_prompt:  316: Inference (val):avg data time: 9.82e-05, avg batch time: 0.2320, average loss: 25.3265
[10/26 06:40:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.96	
[10/26 06:40:57][INFO] visual_prompt:   42: Stopping early.
