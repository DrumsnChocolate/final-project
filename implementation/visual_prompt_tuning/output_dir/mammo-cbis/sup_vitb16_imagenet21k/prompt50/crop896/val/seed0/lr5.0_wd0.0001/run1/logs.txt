[10/26 15:59:48][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/26 15:59:48][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/26 15:59:48][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/26 15:59:48][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/26 15:59:48][INFO] visual_prompt:  108: Training with config:
[10/26 15:59:48][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/26 15:59:48][INFO] visual_prompt:   55: Loading training data...
[10/26 15:59:48][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/26 15:59:48][INFO] visual_prompt:   57: Loading validation data...
[10/26 15:59:48][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/26 15:59:48][INFO] visual_prompt:   38: Constructing models...
[10/26 15:59:51][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/26 15:59:51][INFO] visual_prompt:   54: tuned percent:0.522
[10/26 15:59:51][INFO] visual_prompt:   40: Device used for model: 0
[10/26 15:59:51][INFO] visual_prompt:   40: Setting up Evaluator...
[10/26 15:59:51][INFO] visual_prompt:   42: Setting up Trainer...
[10/26 15:59:51][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/26 15:59:51][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/26 16:00:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6273 s / batch. (data: 2.96e-04). ETA=19:15:18, max mem: 15.9 GB 
[10/26 16:02:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6333 s / batch. (data: 7.95e-04). ETA=19:25:15, max mem: 15.9 GB 
[10/26 16:03:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6189 s / batch. (data: 2.84e-04). ETA=18:57:40, max mem: 15.9 GB 
[10/26 16:04:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6483 s / batch. (data: 7.95e-04). ETA=19:50:43, max mem: 15.9 GB 
[10/26 16:05:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6320 s / batch. (data: 3.09e-04). ETA=19:19:42, max mem: 15.9 GB 
[10/26 16:06:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6181 s / batch. (data: 3.13e-04). ETA=18:53:15, max mem: 15.9 GB 
[10/26 16:07:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6398 s / batch. (data: 5.48e-03). ETA=19:31:50, max mem: 15.9 GB 
[10/26 16:08:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6377 s / batch. (data: 7.45e-04). ETA=19:26:58, max mem: 15.9 GB 
[10/26 16:09:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6640 s / batch. (data: 7.51e-04). ETA=20:14:01, max mem: 15.9 GB 
[10/26 16:10:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6193 s / batch. (data: 3.21e-04). ETA=18:51:19, max mem: 15.9 GB 
[10/26 16:11:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6178 s / batch. (data: 1.56e-04). ETA=18:47:32, max mem: 15.9 GB 
[10/26 16:11:34][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.51e-03, avg batch time: 0.6352, average train loss: 1.4028
[10/26 16:12:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2418 s / batch. (data: 4.05e-05)max mem: 15.94077 GB 
[10/26 16:12:34][INFO] visual_prompt:  316: Inference (val):avg data time: 4.33e-05, avg batch time: 0.2319, average loss: 1.3505
[10/26 16:12:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/26 16:12:34][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[10/26 16:13:39][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.2870,	0.6315 s / batch. (data: 8.28e-04). ETA=19:11:17, max mem: 15.9 GB 
[10/26 16:14:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 3.0209,	0.6302 s / batch. (data: 3.41e-04). ETA=19:07:53, max mem: 15.9 GB 
[10/26 16:15:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9145,	0.6342 s / batch. (data: 8.31e-04). ETA=19:14:05, max mem: 15.9 GB 
[10/26 16:16:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1681,	0.6328 s / batch. (data: 8.25e-04). ETA=19:10:32, max mem: 15.9 GB 
[10/26 16:17:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9863,	0.6680 s / batch. (data: 4.05e-02). ETA=20:13:26, max mem: 15.9 GB 
[10/26 16:18:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3496,	0.6403 s / batch. (data: 7.83e-04). ETA=19:21:59, max mem: 15.9 GB 
[10/26 16:19:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0007,	0.6294 s / batch. (data: 3.18e-04). ETA=19:01:11, max mem: 15.9 GB 
[10/26 16:21:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.4151,	0.6599 s / batch. (data: 5.94e-03). ETA=19:55:29, max mem: 15.9 GB 
[10/26 16:22:06][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9531,	0.6337 s / batch. (data: 8.05e-04). ETA=19:06:55, max mem: 15.9 GB 
[10/26 16:23:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1291,	0.6480 s / batch. (data: 3.14e-04). ETA=19:31:44, max mem: 15.9 GB 
[10/26 16:24:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0757,	0.6189 s / batch. (data: 1.40e-04). ETA=18:38:09, max mem: 15.9 GB 
[10/26 16:24:17][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.32e-03, avg batch time: 0.6349, average train loss: 2.4593
[10/26 16:25:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.681, 0.2277 s / batch. (data: 2.93e-05)max mem: 15.94077 GB 
[10/26 16:25:17][INFO] visual_prompt:  316: Inference (val):avg data time: 1.21e-04, avg batch time: 0.2320, average loss: 5.1185
[10/26 16:25:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.84	
[10/26 16:25:17][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[10/26 16:26:23][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0013,	0.6184 s / batch. (data: 3.47e-04). ETA=18:36:06, max mem: 15.9 GB 
[10/26 16:27:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0001,	0.6184 s / batch. (data: 3.19e-04). ETA=18:35:08, max mem: 15.9 GB 
[10/26 16:28:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0609,	0.6416 s / batch. (data: 4.89e-04). ETA=19:15:50, max mem: 15.9 GB 
[10/26 16:29:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.1378,	0.6453 s / batch. (data: 8.64e-04). ETA=19:21:19, max mem: 15.9 GB 
[10/26 16:30:36][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 7.2371,	0.6189 s / batch. (data: 4.73e-04). ETA=18:32:56, max mem: 15.9 GB 
[10/26 16:31:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6188 s / batch. (data: 1.07e-03). ETA=18:31:35, max mem: 15.9 GB 
[10/26 16:32:42][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.9126,	0.6374 s / batch. (data: 7.84e-04). ETA=19:03:57, max mem: 15.9 GB 
[10/26 16:33:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6403 s / batch. (data: 8.02e-04). ETA=19:08:06, max mem: 15.9 GB 
[10/26 16:34:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 3.5824,	0.6250 s / batch. (data: 5.44e-03). ETA=18:39:42, max mem: 15.9 GB 
[10/26 16:35:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 11.0780,	0.6354 s / batch. (data: 7.82e-04). ETA=18:57:17, max mem: 15.9 GB 
[10/26 16:36:56][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.8095,	0.6192 s / batch. (data: 1.57e-04). ETA=18:27:09, max mem: 15.9 GB 
[10/26 16:37:00][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.08e-03, avg batch time: 0.6349, average train loss: 4.6089
[10/26 16:37:50][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.659, 0.2406 s / batch. (data: 6.34e-05)max mem: 15.94077 GB 
[10/26 16:38:00][INFO] visual_prompt:  316: Inference (val):avg data time: 4.12e-05, avg batch time: 0.2318, average loss: 1.8456
[10/26 16:38:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.00	
[10/26 16:38:00][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[10/26 16:39:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0172,	0.6173 s / batch. (data: 2.92e-04). ETA=18:22:39, max mem: 15.9 GB 
[10/26 16:40:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 31.4533,	0.6741 s / batch. (data: 3.97e-02). ETA=20:02:59, max mem: 15.9 GB 
[10/26 16:41:12][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.1499,	0.6296 s / batch. (data: 8.00e-04). ETA=18:42:34, max mem: 15.9 GB 
[10/26 16:42:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.4371,	0.6307 s / batch. (data: 8.39e-04). ETA=18:43:33, max mem: 15.9 GB 
[10/26 16:43:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1902,	0.6183 s / batch. (data: 3.09e-04). ETA=18:20:28, max mem: 15.9 GB 
[10/26 16:44:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.4411,	0.6177 s / batch. (data: 3.17e-04). ETA=18:18:18, max mem: 15.9 GB 
[10/26 16:45:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 4.1768,	0.6187 s / batch. (data: 3.24e-04). ETA=18:19:06, max mem: 15.9 GB 
[10/26 16:46:28][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1827,	0.6177 s / batch. (data: 3.39e-04). ETA=18:16:16, max mem: 15.9 GB 
[10/26 16:47:31][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1070,	0.6332 s / batch. (data: 3.33e-04). ETA=18:42:43, max mem: 15.9 GB 
[10/26 16:48:35][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0009,	0.6251 s / batch. (data: 3.11e-04). ETA=18:27:16, max mem: 15.9 GB 
[10/26 16:49:38][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 14.2074,	0.6189 s / batch. (data: 1.51e-04). ETA=18:15:14, max mem: 15.9 GB 
[10/26 16:49:42][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.39e-03, avg batch time: 0.6342, average train loss: 5.8528
[10/26 16:50:31][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.259, 0.2348 s / batch. (data: 3.84e-05)max mem: 15.94077 GB 
[10/26 16:50:42][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2321, average loss: 1.4305
[10/26 16:50:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.11	
[10/26 16:50:42][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[10/26 16:51:47][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 14.7932,	0.6308 s / batch. (data: 8.34e-04). ETA=18:35:17, max mem: 15.9 GB 
[10/26 16:52:50][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 26.0046,	0.6445 s / batch. (data: 1.65e-02). ETA=18:58:26, max mem: 15.9 GB 
[10/26 16:53:54][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.1101,	0.6219 s / batch. (data: 3.35e-04). ETA=18:17:22, max mem: 15.9 GB 
[10/26 16:54:57][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 17.5856,	0.6232 s / batch. (data: 7.33e-04). ETA=18:18:43, max mem: 15.9 GB 
[10/26 16:56:00][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6422 s / batch. (data: 7.94e-04). ETA=18:51:01, max mem: 15.9 GB 
[10/26 16:57:04][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0980,	0.6321 s / batch. (data: 8.11e-04). ETA=18:32:15, max mem: 15.9 GB 
[10/26 16:58:07][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 8.7786,	0.6398 s / batch. (data: 8.17e-04). ETA=18:44:41, max mem: 15.9 GB 
[10/26 16:59:10][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.4527,	0.6188 s / batch. (data: 3.11e-04). ETA=18:06:47, max mem: 15.9 GB 
[10/26 17:00:13][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5575,	0.6468 s / batch. (data: 7.53e-04). ETA=18:54:53, max mem: 15.9 GB 
[10/26 17:01:17][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 7.8904,	0.6351 s / batch. (data: 8.07e-04). ETA=18:33:19, max mem: 15.9 GB 
[10/26 17:02:20][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 4.0861,	0.6200 s / batch. (data: 1.80e-04). ETA=18:05:42, max mem: 15.9 GB 
[10/26 17:02:24][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 3.74e-03, avg batch time: 0.6345, average train loss: 6.3521
[10/26 17:03:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 8.852, 0.2406 s / batch. (data: 5.10e-05)max mem: 15.94077 GB 
[10/26 17:03:24][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2320, average loss: 9.7592
[10/26 17:03:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.11	
[10/26 17:03:24][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[10/26 17:04:30][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 15.6455,	0.6518 s / batch. (data: 1.11e-02). ETA=19:00:23, max mem: 15.9 GB 
[10/26 17:05:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6314 s / batch. (data: 8.13e-04). ETA=18:23:31, max mem: 15.9 GB 
[10/26 17:06:36][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6306 s / batch. (data: 8.08e-04). ETA=18:21:07, max mem: 15.9 GB 
[10/26 17:07:39][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 6.0684,	0.6327 s / batch. (data: 2.81e-04). ETA=18:23:39, max mem: 15.9 GB 
[10/26 17:08:42][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.6663,	0.6190 s / batch. (data: 3.21e-04). ETA=17:58:48, max mem: 15.9 GB 
[10/26 17:09:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6377 s / batch. (data: 5.91e-03). ETA=18:30:15, max mem: 15.9 GB 
[10/26 17:10:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 14.1034,	0.6430 s / batch. (data: 8.20e-04). ETA=18:38:29, max mem: 15.9 GB 
[10/26 17:11:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 7.2658,	0.6322 s / batch. (data: 3.19e-04). ETA=18:18:34, max mem: 15.9 GB 
[10/26 17:12:56][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 44.6235,	0.6408 s / batch. (data: 8.32e-04). ETA=18:32:26, max mem: 15.9 GB 
[10/26 17:13:59][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0002,	0.6355 s / batch. (data: 7.98e-04). ETA=18:22:16, max mem: 15.9 GB 
[10/26 17:15:02][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6181 s / batch. (data: 1.37e-04). ETA=17:51:03, max mem: 15.9 GB 
[10/26 17:15:06][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.27e-03, avg batch time: 0.6342, average train loss: 10.5652
[10/26 17:15:56][INFO] visual_prompt:  303: 	Test 100/123. loss: 13.217, 0.2356 s / batch. (data: 2.84e-05)max mem: 15.94077 GB 
[10/26 17:16:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2321, average loss: 14.5185
[10/26 17:16:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.29	
[10/26 17:16:06][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[10/26 17:17:11][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 16.6056,	0.6442 s / batch. (data: 8.20e-04). ETA=18:35:05, max mem: 15.9 GB 
[10/26 17:18:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9252,	0.6275 s / batch. (data: 7.95e-04). ETA=18:05:09, max mem: 15.9 GB 
[10/26 17:19:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.7328,	0.6344 s / batch. (data: 3.18e-04). ETA=18:16:06, max mem: 15.9 GB 
[10/26 17:20:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 11.7479,	0.6466 s / batch. (data: 8.28e-04). ETA=18:36:04, max mem: 15.9 GB 
[10/26 17:21:24][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 18.2345,	0.6428 s / batch. (data: 1.05e-02). ETA=18:28:28, max mem: 15.9 GB 
[10/26 17:22:27][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.4132,	0.6192 s / batch. (data: 3.14e-04). ETA=17:46:38, max mem: 15.9 GB 
[10/26 17:23:30][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 24.4859,	0.6375 s / batch. (data: 6.02e-03). ETA=18:17:10, max mem: 15.9 GB 
[10/26 17:24:34][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6323 s / batch. (data: 7.80e-04). ETA=18:07:10, max mem: 15.9 GB 
[10/26 17:25:37][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 8.4377,	0.6354 s / batch. (data: 7.74e-04). ETA=18:11:25, max mem: 15.9 GB 
[10/26 17:26:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 6.1250,	0.6330 s / batch. (data: 8.37e-04). ETA=18:06:12, max mem: 15.9 GB 
[10/26 17:27:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6172 s / batch. (data: 1.47e-04). ETA=17:38:11, max mem: 15.9 GB 
[10/26 17:27:47][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.16e-03, avg batch time: 0.6339, average train loss: 8.2163
[10/26 17:28:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 3.716, 0.2350 s / batch. (data: 3.17e-05)max mem: 15.94077 GB 
[10/26 17:28:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.2333, average loss: 3.3313
[10/26 17:28:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.16	
[10/26 17:28:48][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[10/26 17:29:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 28.6781,	0.6306 s / batch. (data: 7.81e-04). ETA=17:59:54, max mem: 15.9 GB 
[10/26 17:30:57][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 9.1528,	0.6343 s / batch. (data: 2.95e-04). ETA=18:05:14, max mem: 15.9 GB 
[10/26 17:32:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 8.4199,	0.6584 s / batch. (data: 7.57e-04). ETA=18:45:26, max mem: 15.9 GB 
[10/26 17:33:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6196 s / batch. (data: 4.10e-04). ETA=17:38:00, max mem: 15.9 GB 
[10/26 17:34:07][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6389 s / batch. (data: 2.07e-02). ETA=18:09:59, max mem: 15.9 GB 
[10/26 17:35:10][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6335 s / batch. (data: 3.11e-04). ETA=17:59:42, max mem: 15.9 GB 
[10/26 17:36:13][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 3.8484,	0.6320 s / batch. (data: 1.20e-02). ETA=17:56:08, max mem: 15.9 GB 
[10/26 17:37:17][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6381 s / batch. (data: 5.56e-03). ETA=18:05:24, max mem: 15.9 GB 
[10/26 17:38:20][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6351 s / batch. (data: 8.12e-04). ETA=17:59:11, max mem: 15.9 GB 
[10/26 17:39:24][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4285,	0.6347 s / batch. (data: 7.64e-04). ETA=17:57:27, max mem: 15.9 GB 
[10/26 17:40:27][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0962,	0.6189 s / batch. (data: 1.60e-04). ETA=17:29:41, max mem: 15.9 GB 
[10/26 17:40:31][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.40e-03, avg batch time: 0.6351, average train loss: 14.3410
[10/26 17:41:20][INFO] visual_prompt:  303: 	Test 100/123. loss: 17.950, 0.2255 s / batch. (data: 2.84e-05)max mem: 15.94077 GB 
[10/26 17:41:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2323, average loss: 16.1433
[10/26 17:41:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.43	
[10/26 17:41:31][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[10/26 17:42:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 13.5174,	0.6337 s / batch. (data: 8.06e-04). ETA=17:53:33, max mem: 15.9 GB 
[10/26 17:43:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6523 s / batch. (data: 5.91e-03). ETA=18:24:03, max mem: 15.9 GB 
[10/26 17:44:43][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 33.7750,	0.6315 s / batch. (data: 7.71e-04). ETA=17:47:48, max mem: 15.9 GB 
[10/26 17:45:46][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6300 s / batch. (data: 3.22e-04). ETA=17:44:10, max mem: 15.9 GB 
[10/26 17:46:49][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 67.1572,	0.6360 s / batch. (data: 3.21e-04). ETA=17:53:16, max mem: 15.9 GB 
[10/26 17:47:52][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 7.7319,	0.6440 s / batch. (data: 8.26e-04). ETA=18:05:38, max mem: 15.9 GB 
[10/26 17:48:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 14.7628,	0.6179 s / batch. (data: 3.22e-04). ETA=17:20:36, max mem: 15.9 GB 
[10/26 17:49:59][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.5609,	0.6308 s / batch. (data: 8.02e-04). ETA=17:41:25, max mem: 15.9 GB 
[10/26 17:51:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6207 s / batch. (data: 3.15e-04). ETA=17:23:14, max mem: 15.9 GB 
[10/26 17:52:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6302,	0.6202 s / batch. (data: 8.23e-04). ETA=17:21:28, max mem: 15.9 GB 
[10/26 17:53:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.8020,	0.6186 s / batch. (data: 1.47e-04). ETA=17:17:38, max mem: 15.9 GB 
[10/26 17:53:13][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.29e-03, avg batch time: 0.6346, average train loss: 11.6522
[10/26 17:54:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.972, 0.2486 s / batch. (data: 3.60e-05)max mem: 15.94077 GB 
[10/26 17:54:13][INFO] visual_prompt:  316: Inference (val):avg data time: 4.07e-05, avg batch time: 0.2338, average loss: 6.2753
[10/26 17:54:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.82	
[10/26 17:54:13][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[10/26 17:55:18][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.5530,	0.6242 s / batch. (data: 2.74e-04). ETA=17:26:03, max mem: 15.9 GB 
[10/26 17:56:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 17.6002,	0.6255 s / batch. (data: 3.50e-04). ETA=17:27:04, max mem: 15.9 GB 
[10/26 17:57:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 26.1430,	0.6318 s / batch. (data: 5.53e-03). ETA=17:36:35, max mem: 15.9 GB 
[10/26 17:58:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0687,	0.6510 s / batch. (data: 7.80e-04). ETA=18:07:44, max mem: 15.9 GB 
[10/26 17:59:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 13.9488,	0.6192 s / batch. (data: 3.29e-04). ETA=17:13:28, max mem: 15.9 GB 
[10/26 18:00:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 33.4606,	0.6505 s / batch. (data: 5.94e-03). ETA=18:04:36, max mem: 15.9 GB 
[10/26 18:01:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 15.0572,	0.6242 s / batch. (data: 3.29e-04). ETA=17:19:42, max mem: 15.9 GB 
[10/26 18:02:41][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 5.3295,	0.6189 s / batch. (data: 3.02e-04). ETA=17:09:53, max mem: 15.9 GB 
[10/26 18:03:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 30.2022,	0.6304 s / batch. (data: 7.81e-04). ETA=17:28:01, max mem: 15.9 GB 
[10/26 18:04:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6200 s / batch. (data: 3.03e-04). ETA=17:09:37, max mem: 15.9 GB 
[10/26 18:05:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6181 s / batch. (data: 2.09e-04). ETA=17:05:34, max mem: 15.9 GB 
[10/26 18:05:54][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.12e-03, avg batch time: 0.6338, average train loss: 17.8250
[10/26 18:06:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.782, 0.2257 s / batch. (data: 4.60e-05)max mem: 15.94077 GB 
[10/26 18:06:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2329, average loss: 7.0025
[10/26 18:06:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.69	
[10/26 18:06:54][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[10/26 18:08:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6230 s / batch. (data: 9.76e-04). ETA=17:12:32, max mem: 15.9 GB 
[10/26 18:09:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.4083,	0.6345 s / batch. (data: 1.56e-02). ETA=17:30:34, max mem: 15.9 GB 
[10/26 18:10:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.4977,	0.6200 s / batch. (data: 4.57e-04). ETA=17:05:31, max mem: 15.9 GB 
[10/26 18:11:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 12.2567,	0.6371 s / batch. (data: 8.33e-04). ETA=17:32:39, max mem: 15.9 GB 
[10/26 18:12:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 8.5386,	0.6356 s / batch. (data: 3.34e-04). ETA=17:29:12, max mem: 15.9 GB 
[10/26 18:13:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6360 s / batch. (data: 8.00e-04). ETA=17:28:44, max mem: 15.9 GB 
[10/26 18:14:20][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0482,	0.6190 s / batch. (data: 2.85e-04). ETA=16:59:44, max mem: 15.9 GB 
[10/26 18:15:23][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 14.8672,	0.6189 s / batch. (data: 2.83e-04). ETA=16:58:30, max mem: 15.9 GB 
[10/26 18:16:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6083 s / batch. (data: 3.30e-04). ETA=16:39:57, max mem: 15.9 GB 
[10/26 18:17:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6300 s / batch. (data: 7.28e-04). ETA=17:14:44, max mem: 15.9 GB 
[10/26 18:18:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 7.1506,	0.6185 s / batch. (data: 1.61e-04). ETA=16:54:48, max mem: 15.9 GB 
[10/26 18:18:36][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.35e-03, avg batch time: 0.6341, average train loss: 23.0870
[10/26 18:19:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.179, 0.2252 s / batch. (data: 2.96e-05)max mem: 15.94077 GB 
[10/26 18:19:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2324, average loss: 4.6891
[10/26 18:19:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[10/26 18:19:37][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[10/26 18:20:43][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6211 s / batch. (data: 3.08e-04). ETA=16:57:51, max mem: 15.9 GB 
[10/26 18:21:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 6.6938,	0.6262 s / batch. (data: 2.98e-04). ETA=17:05:12, max mem: 15.9 GB 
[10/26 18:22:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 130.2747,	0.6184 s / batch. (data: 3.35e-04). ETA=16:51:30, max mem: 15.9 GB 
[10/26 18:23:52][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6281 s / batch. (data: 7.49e-04). ETA=17:06:15, max mem: 15.9 GB 
[10/26 18:24:55][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 41.1279,	0.6336 s / batch. (data: 2.83e-04). ETA=17:14:11, max mem: 15.9 GB 
[10/26 18:25:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6312 s / batch. (data: 8.20e-04). ETA=17:09:12, max mem: 15.9 GB 
[10/26 18:27:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 22.1866,	0.6283 s / batch. (data: 7.73e-04). ETA=17:03:29, max mem: 15.9 GB 
[10/26 18:28:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 18.4463,	0.6339 s / batch. (data: 7.85e-04). ETA=17:11:33, max mem: 15.9 GB 
[10/26 18:29:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6060,	0.6446 s / batch. (data: 7.85e-04). ETA=17:27:54, max mem: 15.9 GB 
[10/26 18:30:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 18.9028,	0.6261 s / batch. (data: 3.38e-04). ETA=16:56:41, max mem: 15.9 GB 
[10/26 18:31:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 77.2254,	0.6128 s / batch. (data: 1.51e-04). ETA=16:34:02, max mem: 15.9 GB 
[10/26 18:31:18][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 4.98e-03, avg batch time: 0.6342, average train loss: 23.9558
[10/26 18:32:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 15.668, 0.2300 s / batch. (data: 3.89e-05)max mem: 15.94077 GB 
[10/26 18:32:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2330, average loss: 14.0428
[10/26 18:32:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.11	
[10/26 18:32:19][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[10/26 18:33:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 35.1376,	0.6176 s / batch. (data: 2.94e-04). ETA=16:40:45, max mem: 15.9 GB 
[10/26 18:34:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 29.5510,	0.6182 s / batch. (data: 3.36e-04). ETA=16:40:46, max mem: 15.9 GB 
[10/26 18:35:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6255 s / batch. (data: 7.76e-04). ETA=16:51:33, max mem: 15.9 GB 
[10/26 18:36:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0210,	0.6323 s / batch. (data: 8.20e-04). ETA=17:01:31, max mem: 15.9 GB 
[10/26 18:37:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.0043,	0.6206 s / batch. (data: 2.73e-04). ETA=16:41:34, max mem: 15.9 GB 
[10/26 18:38:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 10.3099,	0.6462 s / batch. (data: 6.73e-04). ETA=17:21:47, max mem: 15.9 GB 
[10/26 18:39:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 30.5755,	0.6567 s / batch. (data: 7.84e-04). ETA=17:37:36, max mem: 15.9 GB 
[10/26 18:40:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 20.3106,	0.6338 s / batch. (data: 7.59e-04). ETA=16:59:41, max mem: 15.9 GB 
[10/26 18:41:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 139.1644,	0.6373 s / batch. (data: 3.66e-04). ETA=17:04:15, max mem: 15.9 GB 
[10/26 18:42:53][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 7.1577,	0.6381 s / batch. (data: 3.22e-04). ETA=17:04:28, max mem: 15.9 GB 
[10/26 18:43:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2700,	0.6178 s / batch. (data: 2.44e-04). ETA=16:30:49, max mem: 15.9 GB 
[10/26 18:44:00][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.60e-03, avg batch time: 0.6343, average train loss: 18.3484
[10/26 18:44:50][INFO] visual_prompt:  303: 	Test 100/123. loss: 14.174, 0.2318 s / batch. (data: 2.72e-05)max mem: 15.94077 GB 
[10/26 18:45:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.80e-05, avg batch time: 0.2318, average loss: 12.7826
[10/26 18:45:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.08	
[10/26 18:45:01][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[10/26 18:46:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 26.8029,	0.6285 s / batch. (data: 7.62e-04). ETA=16:46:50, max mem: 15.9 GB 
[10/26 18:47:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 24.0141,	0.6265 s / batch. (data: 3.30e-04). ETA=16:42:33, max mem: 15.9 GB 
[10/26 18:48:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 22.0194,	0.6342 s / batch. (data: 3.25e-04). ETA=16:53:56, max mem: 15.9 GB 
[10/26 18:49:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6356 s / batch. (data: 8.71e-04). ETA=16:55:01, max mem: 15.9 GB 
[10/26 18:50:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 57.3025,	0.6299 s / batch. (data: 1.05e-03). ETA=16:44:57, max mem: 15.9 GB 
[10/26 18:51:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 6.1633,	0.6326 s / batch. (data: 7.93e-04). ETA=16:48:06, max mem: 15.9 GB 
[10/26 18:52:26][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.9753,	0.6400 s / batch. (data: 7.52e-04). ETA=16:58:56, max mem: 15.9 GB 
[10/26 18:53:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 11.6852,	0.6314 s / batch. (data: 3.17e-04). ETA=16:44:04, max mem: 15.9 GB 
[10/26 18:54:32][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.0597,	0.6260 s / batch. (data: 3.23e-04). ETA=16:34:31, max mem: 15.9 GB 
[10/26 18:55:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0004,	0.6581 s / batch. (data: 1.16e-03). ETA=17:24:21, max mem: 15.9 GB 
[10/26 18:56:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 3.0417,	0.6185 s / batch. (data: 1.56e-04). ETA=16:20:32, max mem: 15.9 GB 
[10/26 18:56:43][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.26e-03, avg batch time: 0.6348, average train loss: 17.6799
[10/26 18:57:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 38.271, 0.2383 s / batch. (data: 4.24e-05)max mem: 15.94077 GB 
[10/26 18:57:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2314, average loss: 34.3409
[10/26 18:57:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.19	
[10/26 18:57:43][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[10/26 18:58:48][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 66.2855,	0.6299 s / batch. (data: 5.48e-03). ETA=16:37:29, max mem: 15.9 GB 
[10/26 18:59:51][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 74.7369,	0.6211 s / batch. (data: 7.78e-03). ETA=16:22:33, max mem: 15.9 GB 
[10/26 19:00:54][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 10.1340,	0.6169 s / batch. (data: 3.10e-04). ETA=16:14:49, max mem: 15.9 GB 
[10/26 19:01:58][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 211.7044,	0.6305 s / batch. (data: 8.43e-04). ETA=16:35:17, max mem: 15.9 GB 
[10/26 19:03:01][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6464 s / batch. (data: 1.04e-02). ETA=16:59:23, max mem: 15.9 GB 
[10/26 19:04:04][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 36.2278,	0.6175 s / batch. (data: 4.75e-04). ETA=16:12:46, max mem: 15.9 GB 
[10/26 19:05:07][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 41.8502,	0.6173 s / batch. (data: 3.05e-04). ETA=16:11:22, max mem: 15.9 GB 
[10/26 19:06:10][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 18.0554,	0.6279 s / batch. (data: 1.04e-02). ETA=16:27:05, max mem: 15.9 GB 
[10/26 19:07:14][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 29.2635,	0.6185 s / batch. (data: 3.14e-04). ETA=16:11:12, max mem: 15.9 GB 
[10/26 19:08:17][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 51.2766,	0.6207 s / batch. (data: 3.11e-04). ETA=16:13:33, max mem: 15.9 GB 
[10/26 19:09:20][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 39.1359,	0.6132 s / batch. (data: 1.53e-04). ETA=16:00:47, max mem: 15.9 GB 
[10/26 19:09:24][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.19e-03, avg batch time: 0.6333, average train loss: 23.2676
[10/26 19:10:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 27.532, 0.2247 s / batch. (data: 2.96e-05)max mem: 15.94077 GB 
[10/26 19:10:25][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2315, average loss: 30.2037
[10/26 19:10:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.46	
[10/26 19:10:25][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[10/26 19:11:30][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6219 s / batch. (data: 3.39e-04). ETA=16:13:20, max mem: 15.9 GB 
[10/26 19:12:33][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 19.5262,	0.6402 s / batch. (data: 8.19e-04). ETA=16:40:59, max mem: 15.9 GB 
[10/26 19:13:36][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6318 s / batch. (data: 8.13e-04). ETA=16:26:44, max mem: 15.9 GB 
[10/26 19:14:39][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.6939,	0.6334 s / batch. (data: 3.20e-04). ETA=16:28:12, max mem: 15.9 GB 
[10/26 19:15:43][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 21.9058,	0.6447 s / batch. (data: 7.62e-04). ETA=16:44:44, max mem: 15.9 GB 
[10/26 19:16:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 74.0051,	0.6327 s / batch. (data: 7.94e-04). ETA=16:25:03, max mem: 15.9 GB 
[10/26 19:17:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 9.4010,	0.6525 s / batch. (data: 8.21e-04). ETA=16:54:47, max mem: 15.9 GB 
[10/26 19:18:53][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 10.5592,	0.6189 s / batch. (data: 2.88e-04). ETA=16:01:29, max mem: 15.9 GB 
[10/26 19:19:56][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 11.7938,	0.6194 s / batch. (data: 3.20e-04). ETA=16:01:08, max mem: 15.9 GB 
[10/26 19:20:59][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 74.5481,	0.6186 s / batch. (data: 2.53e-04). ETA=15:58:59, max mem: 15.9 GB 
[10/26 19:22:02][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6093 s / batch. (data: 1.46e-04). ETA=15:43:25, max mem: 15.9 GB 
[10/26 19:22:06][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.06e-03, avg batch time: 0.6338, average train loss: 23.2576
[10/26 19:22:56][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.671, 0.2556 s / batch. (data: 4.84e-05)max mem: 15.94077 GB 
[10/26 19:23:06][INFO] visual_prompt:  316: Inference (val):avg data time: 4.23e-05, avg batch time: 0.2335, average loss: 0.7214
[10/26 19:23:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 44.90	
[10/26 19:23:06][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.721
[10/26 19:23:06][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[10/26 19:24:12][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6185 s / batch. (data: 3.31e-04). ETA=15:56:36, max mem: 15.9 GB 
[10/26 19:25:15][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 4.1083,	0.6330 s / batch. (data: 7.93e-04). ETA=16:18:01, max mem: 15.9 GB 
[10/26 19:26:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6231 s / batch. (data: 3.17e-04). ETA=16:01:38, max mem: 15.9 GB 
[10/26 19:27:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6400 s / batch. (data: 1.33e-02). ETA=16:26:42, max mem: 15.9 GB 
[10/26 19:28:25][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 21.1339,	0.6187 s / batch. (data: 3.33e-04). ETA=15:52:53, max mem: 15.9 GB 
[10/26 19:29:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1548,	0.6195 s / batch. (data: 3.15e-04). ETA=15:52:59, max mem: 15.9 GB 
[10/26 19:30:31][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 50.2557,	0.6146 s / batch. (data: 4.29e-04). ETA=15:44:30, max mem: 15.9 GB 
[10/26 19:31:34][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 4.3347,	0.6184 s / batch. (data: 4.38e-04). ETA=15:49:14, max mem: 15.9 GB 
[10/26 19:32:37][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6281 s / batch. (data: 2.95e-04). ETA=16:03:05, max mem: 15.9 GB 
[10/26 19:33:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6310 s / batch. (data: 7.73e-04). ETA=16:06:34, max mem: 15.9 GB 
[10/26 19:34:44][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6079 s / batch. (data: 1.61e-04). ETA=15:30:06, max mem: 15.9 GB 
[10/26 19:34:48][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.39e-03, avg batch time: 0.6340, average train loss: 16.3829
[10/26 19:35:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 42.210, 0.2251 s / batch. (data: 2.88e-05)max mem: 15.94077 GB 
[10/26 19:35:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2325, average loss: 46.2984
[10/26 19:35:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 37.06	
[10/26 19:35:48][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[10/26 19:36:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6147 s / batch. (data: 3.25e-04). ETA=15:39:25, max mem: 15.9 GB 
[10/26 19:37:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0585,	0.6400 s / batch. (data: 7.91e-04). ETA=16:17:05, max mem: 15.9 GB 
[10/26 19:38:59][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 233.5798,	0.6270 s / batch. (data: 3.13e-04). ETA=15:56:08, max mem: 15.9 GB 
[10/26 19:40:02][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 46.0016,	0.6341 s / batch. (data: 7.70e-04). ETA=16:05:54, max mem: 15.9 GB 
[10/26 19:41:05][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6489 s / batch. (data: 8.31e-04). ETA=16:27:21, max mem: 15.9 GB 
[10/26 19:42:08][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 60.1976,	0.6261 s / batch. (data: 1.13e-03). ETA=15:51:42, max mem: 15.9 GB 
[10/26 19:43:12][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 62.0404,	0.6457 s / batch. (data: 1.55e-02). ETA=16:20:20, max mem: 15.9 GB 
[10/26 19:44:15][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 5.0525,	0.6298 s / batch. (data: 8.38e-04). ETA=15:55:09, max mem: 15.9 GB 
[10/26 19:45:18][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 28.0907,	0.6304 s / batch. (data: 3.39e-04). ETA=15:55:06, max mem: 15.9 GB 
[10/26 19:46:21][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 4.2097,	0.6267 s / batch. (data: 3.15e-04). ETA=15:48:19, max mem: 15.9 GB 
[10/26 19:47:24][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6170 s / batch. (data: 1.59e-04). ETA=15:32:38, max mem: 15.9 GB 
[10/26 19:47:28][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.24e-03, avg batch time: 0.6328, average train loss: 25.1074
[10/26 19:48:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 11.721, 0.2277 s / batch. (data: 3.12e-05)max mem: 15.94077 GB 
[10/26 19:48:28][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-05, avg batch time: 0.2310, average loss: 10.5509
[10/26 19:48:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.04	
[10/26 19:48:28][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[10/26 19:49:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6459 s / batch. (data: 8.19e-04). ETA=16:15:13, max mem: 15.9 GB 
[10/26 19:50:37][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 14.8393,	0.6311 s / batch. (data: 8.20e-04). ETA=15:51:47, max mem: 15.9 GB 
[10/26 19:51:40][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6744 s / batch. (data: 1.10e-02). ETA=16:55:58, max mem: 15.9 GB 
[10/26 19:52:43][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 4.8302,	0.6174 s / batch. (data: 3.50e-04). ETA=15:29:02, max mem: 15.9 GB 
[10/26 19:53:46][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 37.4833,	0.6480 s / batch. (data: 8.02e-04). ETA=16:14:05, max mem: 15.9 GB 
[10/26 19:54:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 9.1267,	0.6311 s / batch. (data: 7.60e-04). ETA=15:47:39, max mem: 15.9 GB 
[10/26 19:55:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 15.7202,	0.6278 s / batch. (data: 3.31e-04). ETA=15:41:37, max mem: 15.9 GB 
[10/26 19:56:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 11.6771,	0.6343 s / batch. (data: 3.35e-04). ETA=15:50:14, max mem: 15.9 GB 
[10/26 19:57:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0005,	0.6188 s / batch. (data: 3.18e-04). ETA=15:26:06, max mem: 15.9 GB 
[10/26 19:59:02][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1940,	0.6305 s / batch. (data: 7.54e-04). ETA=15:42:29, max mem: 15.9 GB 
[10/26 20:00:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6181 s / batch. (data: 2.04e-04). ETA=15:22:53, max mem: 15.9 GB 
[10/26 20:00:09][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.17e-03, avg batch time: 0.6334, average train loss: 19.3453
[10/26 20:00:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 49.543, 0.2279 s / batch. (data: 2.93e-05)max mem: 15.94077 GB 
[10/26 20:01:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2334, average loss: 54.3294
[10/26 20:01:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.10	
[10/26 20:01:09][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[10/26 20:02:15][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 20.3878,	0.6303 s / batch. (data: 2.54e-04). ETA=15:40:03, max mem: 15.9 GB 
[10/26 20:03:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 28.3630,	0.6300 s / batch. (data: 8.37e-04). ETA=15:38:33, max mem: 15.9 GB 
[10/26 20:04:21][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 17.5568,	0.6356 s / batch. (data: 3.19e-04). ETA=15:45:47, max mem: 15.9 GB 
[10/26 20:05:25][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.7731,	0.6303 s / batch. (data: 3.39e-04). ETA=15:36:53, max mem: 15.9 GB 
[10/26 20:06:28][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 4.5064,	0.6274 s / batch. (data: 3.24e-04). ETA=15:31:29, max mem: 15.9 GB 
[10/26 20:07:31][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 38.0037,	0.6441 s / batch. (data: 1.09e-02). ETA=15:55:19, max mem: 15.9 GB 
[10/26 20:08:35][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6482 s / batch. (data: 8.23e-04). ETA=16:00:12, max mem: 15.9 GB 
[10/26 20:09:38][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 7.2439,	0.6360 s / batch. (data: 5.47e-03). ETA=15:41:07, max mem: 15.9 GB 
[10/26 20:10:41][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 61.0922,	0.6325 s / batch. (data: 3.14e-04). ETA=15:34:55, max mem: 15.9 GB 
[10/26 20:11:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6431 s / batch. (data: 1.34e-02). ETA=15:49:30, max mem: 15.9 GB 
[10/26 20:12:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0019,	0.6190 s / batch. (data: 1.45e-04). ETA=15:12:51, max mem: 15.9 GB 
[10/26 20:12:52][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 5.04e-03, avg batch time: 0.6352, average train loss: 15.6431
[10/26 20:13:42][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.658, 0.2250 s / batch. (data: 7.34e-05)max mem: 15.94077 GB 
[10/26 20:13:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2334, average loss: 5.9605
[10/26 20:13:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.67	
[10/26 20:13:52][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[10/26 20:14:58][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 55.5434,	0.6516 s / batch. (data: 3.44e-04). ETA=15:59:47, max mem: 15.9 GB 
[10/26 20:16:01][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 74.2379,	0.6358 s / batch. (data: 8.50e-04). ETA=15:35:30, max mem: 15.9 GB 
[10/26 20:17:04][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0075,	0.6338 s / batch. (data: 7.90e-04). ETA=15:31:30, max mem: 15.9 GB 
[10/26 20:18:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 39.5903,	0.6454 s / batch. (data: 7.95e-04). ETA=15:47:27, max mem: 15.9 GB 
[10/26 20:19:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 6.2326,	0.6224 s / batch. (data: 3.18e-04). ETA=15:12:40, max mem: 15.9 GB 
[10/26 20:20:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 38.0308,	0.6469 s / batch. (data: 9.47e-04). ETA=15:47:32, max mem: 15.9 GB 
[10/26 20:21:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 12.1240,	0.6327 s / batch. (data: 8.24e-04). ETA=15:25:39, max mem: 15.9 GB 
[10/26 20:22:19][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 32.6809,	0.6435 s / batch. (data: 7.97e-04). ETA=15:40:25, max mem: 15.9 GB 
[10/26 20:23:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6460 s / batch. (data: 1.09e-03). ETA=15:42:59, max mem: 15.9 GB 
[10/26 20:24:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 50.5344,	0.6416 s / batch. (data: 8.96e-04). ETA=15:35:28, max mem: 15.9 GB 
[10/26 20:25:28][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 46.3792,	0.6168 s / batch. (data: 1.46e-04). ETA=14:58:11, max mem: 15.9 GB 
[10/26 20:25:32][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.61e-03, avg batch time: 0.6329, average train loss: 25.7321
[10/26 20:26:22][INFO] visual_prompt:  303: 	Test 100/123. loss: 24.052, 0.2592 s / batch. (data: 3.03e-05)max mem: 15.94077 GB 
[10/26 20:26:33][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2328, average loss: 21.8059
[10/26 20:26:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.74	
[10/26 20:26:33][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[10/26 20:27:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.9387,	0.6531 s / batch. (data: 1.99e-02). ETA=15:49:59, max mem: 15.9 GB 
[10/26 20:28:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 30.0985,	0.6201 s / batch. (data: 3.56e-04). ETA=15:00:58, max mem: 15.9 GB 
[10/26 20:29:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 7.1960,	0.6299 s / batch. (data: 8.05e-04). ETA=15:14:07, max mem: 15.9 GB 
[10/26 20:30:47][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 14.7647,	0.6323 s / batch. (data: 3.09e-04). ETA=15:16:31, max mem: 15.9 GB 
[10/26 20:31:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6320 s / batch. (data: 3.38e-04). ETA=15:15:01, max mem: 15.9 GB 
[10/26 20:32:53][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6155 s / batch. (data: 3.14e-04). ETA=14:50:07, max mem: 15.9 GB 
[10/26 20:33:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 66.6030,	0.6401 s / batch. (data: 9.63e-03). ETA=15:24:43, max mem: 15.9 GB 
[10/26 20:35:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 18.7107,	0.6359 s / batch. (data: 7.91e-04). ETA=15:17:34, max mem: 15.9 GB 
[10/26 20:36:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.8314,	0.6426 s / batch. (data: 8.23e-04). ETA=15:26:04, max mem: 15.9 GB 
[10/26 20:37:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 74.5578,	0.6377 s / batch. (data: 1.16e-03). ETA=15:18:03, max mem: 15.9 GB 
[10/26 20:38:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 47.9371,	0.6177 s / batch. (data: 1.64e-04). ETA=14:48:12, max mem: 15.9 GB 
[10/26 20:38:13][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 3.96e-03, avg batch time: 0.6332, average train loss: 23.9766
[10/26 20:39:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 39.527, 0.2247 s / batch. (data: 3.05e-05)max mem: 15.94077 GB 
[10/26 20:39:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2325, average loss: 35.6528
[10/26 20:39:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.92	
[10/26 20:39:14][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[10/26 20:40:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 26.8196,	0.6170 s / batch. (data: 3.30e-04). ETA=14:46:04, max mem: 15.9 GB 
[10/26 20:41:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 13.8450,	0.6543 s / batch. (data: 8.26e-04). ETA=15:38:37, max mem: 15.9 GB 
[10/26 20:42:27][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6488 s / batch. (data: 1.75e-02). ETA=15:29:40, max mem: 15.9 GB 
[10/26 20:43:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 6.4291,	0.6187 s / batch. (data: 3.04e-04). ETA=14:45:27, max mem: 15.9 GB 
[10/26 20:44:33][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 5.0503,	0.6224 s / batch. (data: 2.81e-04). ETA=14:49:40, max mem: 15.9 GB 
[10/26 20:45:37][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6313 s / batch. (data: 8.36e-04). ETA=15:01:19, max mem: 15.9 GB 
[10/26 20:46:40][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 9.9727,	0.6196 s / batch. (data: 3.26e-04). ETA=14:43:33, max mem: 15.9 GB 
[10/26 20:47:43][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.1434,	0.6403 s / batch. (data: 8.16e-04). ETA=15:12:02, max mem: 15.9 GB 
[10/26 20:48:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5661,	0.6407 s / batch. (data: 3.19e-04). ETA=15:11:37, max mem: 15.9 GB 
[10/26 20:49:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6495 s / batch. (data: 8.14e-04). ETA=15:22:58, max mem: 15.9 GB 
[10/26 20:50:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 11.3108,	0.6164 s / batch. (data: 1.65e-04). ETA=14:34:55, max mem: 15.9 GB 
[10/26 20:50:57][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 5.06e-03, avg batch time: 0.6353, average train loss: 19.4618
[10/26 20:51:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 8.615, 0.2301 s / batch. (data: 2.98e-05)max mem: 15.94077 GB 
[10/26 20:51:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2315, average loss: 7.7649
[10/26 20:51:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.97	
[10/26 20:51:57][INFO] visual_prompt:   42: Stopping early.
