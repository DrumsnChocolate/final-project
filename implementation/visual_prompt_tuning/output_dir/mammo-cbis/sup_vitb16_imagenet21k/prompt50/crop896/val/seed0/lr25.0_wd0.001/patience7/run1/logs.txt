[10/24 19:43:50][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/24 19:43:50][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/24 19:43:50][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/24 19:43:50][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/24 19:43:50][INFO] visual_prompt:  108: Training with config:
[10/24 19:43:50][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/24 19:43:50][INFO] visual_prompt:   55: Loading training data...
[10/24 19:43:50][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/24 19:43:50][INFO] visual_prompt:   57: Loading validation data...
[10/24 19:43:50][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/24 19:43:50][INFO] visual_prompt:   38: Constructing models...
[10/24 19:43:52][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/24 19:43:52][INFO] visual_prompt:   54: tuned percent:0.522
[10/24 19:43:53][INFO] visual_prompt:   40: Device used for model: 0
[10/24 19:43:53][INFO] visual_prompt:   40: Setting up Evaluator...
[10/24 19:43:53][INFO] visual_prompt:   42: Setting up Trainer...
[10/24 19:43:53][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/24 19:43:53][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/24 19:44:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6453 s / batch. (data: 9.25e-04). ETA=19:48:20, max mem: 15.9 GB 
[10/24 19:46:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6303 s / batch. (data: 7.24e-04). ETA=19:19:39, max mem: 15.9 GB 
[10/24 19:47:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6187 s / batch. (data: 3.50e-04). ETA=18:57:18, max mem: 15.9 GB 
[10/24 19:48:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6328 s / batch. (data: 3.15e-04). ETA=19:22:17, max mem: 15.9 GB 
[10/24 19:49:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6602 s / batch. (data: 1.05e-02). ETA=20:11:31, max mem: 15.9 GB 
[10/24 19:50:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6305 s / batch. (data: 7.40e-04). ETA=19:15:49, max mem: 15.9 GB 
[10/24 19:51:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6197 s / batch. (data: 3.91e-04). ETA=18:55:00, max mem: 15.9 GB 
[10/24 19:52:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6374 s / batch. (data: 7.72e-04). ETA=19:26:28, max mem: 15.9 GB 
[10/24 19:53:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6200 s / batch. (data: 3.03e-04). ETA=18:53:33, max mem: 15.9 GB 
[10/24 19:54:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6360 s / batch. (data: 7.97e-04). ETA=19:21:47, max mem: 15.9 GB 
[10/24 19:55:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6176 s / batch. (data: 1.63e-04). ETA=18:47:04, max mem: 15.9 GB 
[10/24 19:55:35][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 5.03e-03, avg batch time: 0.6352, average train loss: 1.4028
[10/24 19:56:25][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2258 s / batch. (data: 3.27e-05)max mem: 15.91075 GB 
[10/24 19:56:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2320, average loss: 1.3505
[10/24 19:56:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/24 19:56:36][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 2.5
[10/24 19:57:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 24.5193,	0.6177 s / batch. (data: 2.46e-04). ETA=18:46:17, max mem: 15.9 GB 
[10/24 19:58:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 17.6197,	0.6335 s / batch. (data: 8.79e-04). ETA=19:14:01, max mem: 15.9 GB 
[10/24 19:59:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6457 s / batch. (data: 7.85e-04). ETA=19:35:06, max mem: 15.9 GB 
[10/24 20:00:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6258 s / batch. (data: 3.38e-04). ETA=18:57:49, max mem: 15.9 GB 
[10/24 20:01:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 8.9271,	0.6840 s / batch. (data: 3.99e-02). ETA=20:42:27, max mem: 15.9 GB 
[10/24 20:02:57][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 3.8181,	0.6422 s / batch. (data: 8.01e-04). ETA=19:25:35, max mem: 15.9 GB 
[10/24 20:04:00][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6347 s / batch. (data: 7.72e-04). ETA=19:10:47, max mem: 15.9 GB 
[10/24 20:05:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 12.8612,	0.6200 s / batch. (data: 3.13e-04). ETA=18:43:11, max mem: 15.9 GB 
[10/24 20:06:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 12.3197,	0.6320 s / batch. (data: 1.20e-02). ETA=19:03:54, max mem: 15.9 GB 
[10/24 20:07:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6396 s / batch. (data: 1.56e-02). ETA=19:16:34, max mem: 15.9 GB 
[10/24 20:08:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6184 s / batch. (data: 1.62e-04). ETA=18:37:14, max mem: 15.9 GB 
[10/24 20:08:17][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.07e-03, avg batch time: 0.6337, average train loss: 12.3614
[10/24 20:09:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.658, 0.2466 s / batch. (data: 3.98e-05)max mem: 15.91075 GB 
[10/24 20:09:18][INFO] visual_prompt:  316: Inference (val):avg data time: 1.32e-04, avg batch time: 0.2331, average loss: 6.9327
[10/24 20:09:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.26	
[10/24 20:09:18][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 5.0
[10/24 20:10:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3535,	0.6409 s / batch. (data: 8.43e-04). ETA=19:16:41, max mem: 15.9 GB 
[10/24 20:11:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 29.7258,	0.6520 s / batch. (data: 8.61e-04). ETA=19:35:38, max mem: 15.9 GB 
[10/24 20:12:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 6.8673,	0.6253 s / batch. (data: 3.15e-04). ETA=18:46:23, max mem: 15.9 GB 
[10/24 20:13:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 25.6901,	0.6321 s / batch. (data: 1.23e-02). ETA=18:57:42, max mem: 15.9 GB 
[10/24 20:14:36][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 73.9383,	0.6173 s / batch. (data: 3.06e-04). ETA=18:29:54, max mem: 15.9 GB 
[10/24 20:15:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 301.2530,	0.6187 s / batch. (data: 3.29e-04). ETA=18:31:28, max mem: 15.9 GB 
[10/24 20:16:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6245 s / batch. (data: 3.19e-04). ETA=18:40:49, max mem: 15.9 GB 
[10/24 20:17:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6184 s / batch. (data: 3.04e-04). ETA=18:28:50, max mem: 15.9 GB 
[10/24 20:18:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 12.1604,	0.6440 s / batch. (data: 3.10e-04). ETA=19:13:41, max mem: 15.9 GB 
[10/24 20:19:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 54.6757,	0.6187 s / batch. (data: 3.35e-04). ETA=18:27:23, max mem: 15.9 GB 
[10/24 20:20:55][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 63.4358,	0.6117 s / batch. (data: 1.68e-04). ETA=18:13:43, max mem: 15.9 GB 
[10/24 20:20:59][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.37e-03, avg batch time: 0.6340, average train loss: 26.6599
[10/24 20:21:49][INFO] visual_prompt:  303: 	Test 100/123. loss: 34.133, 0.2255 s / batch. (data: 4.27e-05)max mem: 15.91075 GB 
[10/24 20:22:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2317, average loss: 37.3333
[10/24 20:22:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.06	
[10/24 20:22:00][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 7.5
[10/24 20:23:05][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6326 s / batch. (data: 3.23e-04). ETA=18:50:05, max mem: 15.9 GB 
[10/24 20:24:08][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 164.6472,	0.6434 s / batch. (data: 8.25e-04). ETA=19:08:13, max mem: 15.9 GB 
[10/24 20:25:11][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.9370,	0.6179 s / batch. (data: 2.99e-04). ETA=18:21:43, max mem: 15.9 GB 
[10/24 20:26:14][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 5.1361,	0.6353 s / batch. (data: 8.03e-04). ETA=18:51:41, max mem: 15.9 GB 
[10/24 20:27:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 4.2917,	0.6191 s / batch. (data: 4.79e-04). ETA=18:21:44, max mem: 15.9 GB 
[10/24 20:28:21][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 23.2744,	0.6316 s / batch. (data: 3.15e-04). ETA=18:43:00, max mem: 15.9 GB 
[10/24 20:29:24][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 43.3586,	0.6454 s / batch. (data: 3.15e-04). ETA=19:06:28, max mem: 15.9 GB 
[10/24 20:30:27][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6174 s / batch. (data: 2.95e-04). ETA=18:15:36, max mem: 15.9 GB 
[10/24 20:31:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6328 s / batch. (data: 1.14e-03). ETA=18:41:59, max mem: 15.9 GB 
[10/24 20:32:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6120 s / batch. (data: 3.01e-04). ETA=18:04:04, max mem: 15.9 GB 
[10/24 20:33:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 14.4156,	0.6187 s / batch. (data: 1.39e-04). ETA=18:14:59, max mem: 15.9 GB 
[10/24 20:33:39][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.40e-03, avg batch time: 0.6326, average train loss: 36.8057
[10/24 20:34:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.116, 0.2397 s / batch. (data: 3.08e-05)max mem: 15.91075 GB 
[10/24 20:34:40][INFO] visual_prompt:  316: Inference (val):avg data time: 1.05e-04, avg batch time: 0.2322, average loss: 2.8251
[10/24 20:34:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.98	
[10/24 20:34:40][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 10.0
[10/24 20:35:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 50.6507,	0.6395 s / batch. (data: 8.34e-04). ETA=18:50:36, max mem: 15.9 GB 
[10/24 20:36:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6221 s / batch. (data: 3.04e-04). ETA=18:18:44, max mem: 15.9 GB 
[10/24 20:37:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 76.0419,	0.6319 s / batch. (data: 8.11e-04). ETA=18:34:57, max mem: 15.9 GB 
[10/24 20:38:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 69.1398,	0.6399 s / batch. (data: 7.48e-04). ETA=18:48:07, max mem: 15.9 GB 
[10/24 20:39:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6195 s / batch. (data: 3.19e-04). ETA=18:11:01, max mem: 15.9 GB 
[10/24 20:41:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 46.3404,	0.6403 s / batch. (data: 7.63e-04). ETA=18:46:35, max mem: 15.9 GB 
[10/24 20:42:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 98.4349,	0.6151 s / batch. (data: 2.98e-04). ETA=18:01:22, max mem: 15.9 GB 
[10/24 20:43:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 87.4513,	0.6442 s / batch. (data: 8.07e-04). ETA=18:51:18, max mem: 15.9 GB 
[10/24 20:44:10][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 27.1970,	0.6318 s / batch. (data: 1.35e-02). ETA=18:28:32, max mem: 15.9 GB 
[10/24 20:45:13][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6571 s / batch. (data: 2.98e-02). ETA=19:11:53, max mem: 15.9 GB 
[10/24 20:46:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 96.7316,	0.6140 s / batch. (data: 1.76e-04). ETA=17:55:13, max mem: 15.9 GB 
[10/24 20:46:20][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.67e-03, avg batch time: 0.6330, average train loss: 45.6176
[10/24 20:47:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 76.197, 0.2455 s / batch. (data: 2.96e-05)max mem: 15.91075 GB 
[10/24 20:47:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2327, average loss: 69.0951
[10/24 20:47:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.59	
[10/24 20:47:21][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 12.5
[10/24 20:48:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 186.7173,	0.6206 s / batch. (data: 3.39e-04). ETA=18:05:48, max mem: 15.9 GB 
[10/24 20:49:30][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 211.7769,	0.6188 s / batch. (data: 3.16e-04). ETA=18:01:31, max mem: 15.9 GB 
[10/24 20:50:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6098 s / batch. (data: 8.67e-04). ETA=17:44:45, max mem: 15.9 GB 
[10/24 20:51:35][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 83.2867,	0.6471 s / batch. (data: 7.62e-04). ETA=18:48:50, max mem: 15.9 GB 
[10/24 20:52:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 110.1973,	0.6239 s / batch. (data: 8.20e-04). ETA=18:07:26, max mem: 15.9 GB 
[10/24 20:53:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 22.2043,	0.6205 s / batch. (data: 4.62e-04). ETA=18:00:27, max mem: 15.9 GB 
[10/24 20:54:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 141.3908,	0.6136 s / batch. (data: 3.10e-04). ETA=17:47:25, max mem: 15.9 GB 
[10/24 20:55:48][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 182.8361,	0.6257 s / batch. (data: 1.26e-02). ETA=18:07:21, max mem: 15.9 GB 
[10/24 20:56:51][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6200 s / batch. (data: 2.64e-04). ETA=17:56:30, max mem: 15.9 GB 
[10/24 20:57:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 7.8574,	0.6381 s / batch. (data: 7.97e-04). ETA=18:26:45, max mem: 15.9 GB 
[10/24 20:58:59][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6193 s / batch. (data: 1.98e-04). ETA=17:53:07, max mem: 15.9 GB 
[10/24 20:59:03][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 6.15e-03, avg batch time: 0.6340, average train loss: 70.1587
[10/24 20:59:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 66.694, 0.2478 s / batch. (data: 2.74e-05)max mem: 15.91075 GB 
[10/24 21:00:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2321, average loss: 61.4782
[10/24 21:00:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.37	
[10/24 21:00:03][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 15.0
[10/24 21:01:09][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 4.4517,	0.6227 s / batch. (data: 2.81e-04). ETA=17:57:56, max mem: 15.9 GB 
[10/24 21:02:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 247.0433,	0.6346 s / batch. (data: 1.66e-02). ETA=18:17:30, max mem: 15.9 GB 
[10/24 21:03:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6447 s / batch. (data: 2.76e-02). ETA=18:33:49, max mem: 15.9 GB 
[10/24 21:04:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 203.2740,	0.6152 s / batch. (data: 3.11e-04). ETA=17:41:57, max mem: 15.9 GB 
[10/24 21:05:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 6.3257,	0.6176 s / batch. (data: 3.13e-04). ETA=17:45:04, max mem: 15.9 GB 
[10/24 21:06:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 236.7452,	0.6205 s / batch. (data: 3.03e-04). ETA=17:49:00, max mem: 15.9 GB 
[10/24 21:07:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 327.9857,	0.6457 s / batch. (data: 1.20e-02). ETA=18:31:13, max mem: 15.9 GB 
[10/24 21:08:31][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	2.1485 s / batch. (data: 1.54e+00). ETA=2 days, 13:34:09, max mem: 15.9 GB 
[10/24 21:09:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 85.0776,	0.6271 s / batch. (data: 2.78e-04). ETA=17:57:11, max mem: 15.9 GB 
[10/24 21:10:43][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4185,	0.6316 s / batch. (data: 1.40e-02). ETA=18:03:50, max mem: 15.9 GB 
[10/24 21:11:46][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6076 s / batch. (data: 1.45e-04). ETA=17:21:43, max mem: 15.9 GB 
[10/24 21:11:49][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.15e-02, avg batch time: 0.6381, average train loss: 74.8636
[10/24 21:12:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 67.111, 0.2309 s / batch. (data: 3.22e-05)max mem: 15.91075 GB 
[10/24 21:12:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2329, average loss: 60.5444
[10/24 21:12:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.39	
[10/24 21:12:52][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 17.5
[10/24 21:13:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 411.3835,	0.6180 s / batch. (data: 8.02e-04). ETA=17:38:28, max mem: 15.9 GB 
[10/24 21:15:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 57.7175,	0.6134 s / batch. (data: 2.74e-04). ETA=17:29:25, max mem: 15.9 GB 
[10/24 21:16:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6400 s / batch. (data: 8.31e-04). ETA=18:13:57, max mem: 15.9 GB 
[10/24 21:17:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 52.0988,	0.6193 s / batch. (data: 2.53e-04). ETA=17:37:31, max mem: 15.9 GB 
[10/24 21:18:09][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6274 s / batch. (data: 1.16e-03). ETA=17:50:18, max mem: 15.9 GB 
[10/24 21:19:12][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 265.1094,	0.6383 s / batch. (data: 3.33e-04). ETA=18:07:50, max mem: 15.9 GB 
[10/24 21:20:15][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 65.2296,	0.6267 s / batch. (data: 8.13e-04). ETA=17:47:06, max mem: 15.9 GB 
[10/24 21:21:18][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 155.6464,	0.6190 s / batch. (data: 3.14e-04). ETA=17:32:51, max mem: 15.9 GB 
[10/24 21:22:21][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6153 s / batch. (data: 1.25e-03). ETA=17:25:30, max mem: 15.9 GB 
[10/24 21:23:24][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6329 s / batch. (data: 3.21e-04). ETA=17:54:28, max mem: 15.9 GB 
[10/24 21:24:27][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 75.3786,	0.6181 s / batch. (data: 1.67e-04). ETA=17:28:16, max mem: 15.9 GB 
[10/24 21:24:30][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 5.00e-03, avg batch time: 0.6314, average train loss: 85.4984
[10/24 21:25:20][INFO] visual_prompt:  303: 	Test 100/123. loss: 183.931, 0.2249 s / batch. (data: 2.65e-05)max mem: 15.91075 GB 
[10/24 21:25:31][INFO] visual_prompt:  316: Inference (val):avg data time: 4.33e-05, avg batch time: 0.2323, average loss: 165.3182
[10/24 21:25:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.84	
[10/24 21:25:31][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 20.0
[10/24 21:26:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 34.7268,	0.6184 s / batch. (data: 3.13e-04). ETA=17:27:46, max mem: 15.9 GB 
[10/24 21:27:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6280 s / batch. (data: 7.99e-03). ETA=17:42:50, max mem: 15.9 GB 
[10/24 21:28:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 322.7923,	0.6138 s / batch. (data: 3.06e-04). ETA=17:17:46, max mem: 15.9 GB 
[10/24 21:29:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 317.5252,	0.6440 s / batch. (data: 7.59e-04). ETA=18:07:54, max mem: 15.9 GB 
[10/24 21:30:48][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 106.2589,	0.6480 s / batch. (data: 8.61e-04). ETA=18:13:30, max mem: 15.9 GB 
[10/24 21:31:51][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 118.7958,	0.6320 s / batch. (data: 3.80e-04). ETA=17:45:23, max mem: 15.9 GB 
[10/24 21:32:54][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6088 s / batch. (data: 3.06e-04). ETA=17:05:15, max mem: 15.9 GB 
[10/24 21:33:57][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 78.0836,	0.6141 s / batch. (data: 3.23e-04). ETA=17:13:17, max mem: 15.9 GB 
[10/24 21:35:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 139.4953,	0.6280 s / batch. (data: 7.28e-04). ETA=17:35:32, max mem: 15.9 GB 
[10/24 21:36:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6397 s / batch. (data: 7.56e-04). ETA=17:54:14, max mem: 15.9 GB 
[10/24 21:37:06][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 53.7882,	0.6187 s / batch. (data: 1.66e-04). ETA=17:17:53, max mem: 15.9 GB 
[10/24 21:37:09][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.48e-03, avg batch time: 0.6312, average train loss: 93.1130
[10/24 21:37:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 59.600, 0.2276 s / batch. (data: 3.39e-05)max mem: 15.91075 GB 
[10/24 21:38:10][INFO] visual_prompt:  316: Inference (val):avg data time: 1.12e-04, avg batch time: 0.2317, average loss: 53.7956
[10/24 21:38:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[10/24 21:38:10][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 22.5
[10/24 21:39:15][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 150.4392,	0.6123 s / batch. (data: 3.18e-04). ETA=17:06:04, max mem: 15.9 GB 
[10/24 21:40:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 98.0129,	0.6271 s / batch. (data: 7.94e-04). ETA=17:29:47, max mem: 15.9 GB 
[10/24 21:41:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 93.3190,	0.6228 s / batch. (data: 2.67e-04). ETA=17:21:32, max mem: 15.9 GB 
[10/24 21:42:23][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6199 s / batch. (data: 7.47e-04). ETA=17:15:46, max mem: 15.9 GB 
[10/24 21:43:26][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 19.0002,	0.6360 s / batch. (data: 8.54e-04). ETA=17:41:36, max mem: 15.9 GB 
[10/24 21:44:29][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6197 s / batch. (data: 7.73e-04). ETA=17:13:15, max mem: 15.9 GB 
[10/24 21:45:32][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 575.5989,	0.6188 s / batch. (data: 3.04e-04). ETA=17:10:42, max mem: 15.9 GB 
[10/24 21:46:35][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 46.1705,	0.6360 s / batch. (data: 3.41e-04). ETA=17:38:22, max mem: 15.9 GB 
[10/24 21:47:38][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 97.0456,	0.6400 s / batch. (data: 7.84e-04). ETA=17:43:57, max mem: 15.9 GB 
[10/24 21:48:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 131.3607,	0.6384 s / batch. (data: 3.14e-04). ETA=17:40:09, max mem: 15.9 GB 
[10/24 21:49:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6115 s / batch. (data: 1.36e-04). ETA=16:54:31, max mem: 15.9 GB 
[10/24 21:49:47][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.29e-03, avg batch time: 0.6301, average train loss: 114.5166
[10/24 21:50:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 20.624, 0.2406 s / batch. (data: 4.01e-05)max mem: 15.91075 GB 
[10/24 21:50:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2320, average loss: 18.2629
[10/24 21:50:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.43	
[10/24 21:50:48][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 25.0
[10/24 21:51:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6382 s / batch. (data: 7.82e-04). ETA=17:37:37, max mem: 15.9 GB 
[10/24 21:52:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 413.7233,	0.6138 s / batch. (data: 4.07e-04). ETA=16:56:13, max mem: 15.9 GB 
[10/24 21:53:59][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 207.5752,	0.6290 s / batch. (data: 8.18e-04). ETA=17:20:25, max mem: 15.9 GB 
[10/24 21:55:01][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 326.8474,	0.6193 s / batch. (data: 2.93e-04). ETA=17:03:14, max mem: 15.9 GB 
[10/24 21:56:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 371.3863,	0.6125 s / batch. (data: 3.68e-04). ETA=16:51:04, max mem: 15.9 GB 
[10/24 21:57:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6228 s / batch. (data: 3.29e-04). ETA=17:06:57, max mem: 15.9 GB 
[10/24 21:58:11][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 169.6854,	0.6336 s / batch. (data: 7.69e-04). ETA=17:23:41, max mem: 15.9 GB 
[10/24 21:59:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 187.1485,	0.6379 s / batch. (data: 5.84e-03). ETA=17:29:41, max mem: 15.9 GB 
[10/24 22:00:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6084 s / batch. (data: 7.67e-04). ETA=16:40:11, max mem: 15.9 GB 
[10/24 22:01:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6095 s / batch. (data: 2.79e-04). ETA=16:40:58, max mem: 15.9 GB 
[10/24 22:02:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 48.2975,	0.6140 s / batch. (data: 1.58e-04). ETA=16:47:22, max mem: 15.9 GB 
[10/24 22:02:26][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.42e-03, avg batch time: 0.6310, average train loss: 128.7926
[10/24 22:03:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 29.050, 0.2257 s / batch. (data: 3.74e-05)max mem: 15.91075 GB 
[10/24 22:03:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2314, average loss: 32.2410
[10/24 22:03:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.67	
[10/24 22:03:26][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 24.9923853377387
[10/24 22:04:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6289 s / batch. (data: 1.11e-03). ETA=17:10:43, max mem: 15.9 GB 
[10/24 22:05:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 101.0730,	0.6148 s / batch. (data: 3.29e-04). ETA=16:46:31, max mem: 15.9 GB 
[10/24 22:06:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 189.7538,	0.6307 s / batch. (data: 1.29e-02). ETA=17:11:30, max mem: 15.9 GB 
[10/24 22:07:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 117.6784,	0.6488 s / batch. (data: 3.87e-03). ETA=17:40:05, max mem: 15.9 GB 
[10/24 22:08:43][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6233 s / batch. (data: 8.16e-04). ETA=16:57:24, max mem: 15.9 GB 
[10/24 22:09:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 427.4761,	0.6389 s / batch. (data: 3.19e-04). ETA=17:21:48, max mem: 15.9 GB 
[10/24 22:10:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 84.8015,	0.6286 s / batch. (data: 2.61e-04). ETA=17:03:53, max mem: 15.9 GB 
[10/24 22:11:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 48.3012,	0.6192 s / batch. (data: 3.40e-04). ETA=16:47:39, max mem: 15.9 GB 
[10/24 22:12:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6133 s / batch. (data: 5.46e-03). ETA=16:37:00, max mem: 15.9 GB 
[10/24 22:13:57][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 133.9087,	0.6149 s / batch. (data: 3.38e-04). ETA=16:38:32, max mem: 15.9 GB 
[10/24 22:15:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 32.3823,	0.6179 s / batch. (data: 1.49e-04). ETA=16:42:21, max mem: 15.9 GB 
[10/24 22:15:04][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.09e-03, avg batch time: 0.6307, average train loss: 130.7792
[10/24 22:15:54][INFO] visual_prompt:  303: 	Test 100/123. loss: 55.282, 0.2477 s / batch. (data: 3.05e-05)max mem: 15.91075 GB 
[10/24 22:16:05][INFO] visual_prompt:  316: Inference (val):avg data time: 4.37e-05, avg batch time: 0.2337, average loss: 49.2748
[10/24 22:16:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.84	
[10/24 22:16:05][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 24.969550628247802
[10/24 22:17:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.2313,	0.6425 s / batch. (data: 7.97e-04). ETA=17:21:09, max mem: 15.9 GB 
[10/24 22:18:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 261.9313,	0.6136 s / batch. (data: 2.53e-04). ETA=16:33:22, max mem: 15.9 GB 
[10/24 22:19:16][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6215 s / batch. (data: 8.18e-04). ETA=16:44:58, max mem: 15.9 GB 
[10/24 22:20:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 346.8749,	0.6305 s / batch. (data: 7.75e-04). ETA=16:58:34, max mem: 15.9 GB 
[10/24 22:21:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6133 s / batch. (data: 3.23e-04). ETA=16:29:44, max mem: 15.9 GB 
[10/24 22:22:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 79.1147,	0.6120 s / batch. (data: 2.96e-04). ETA=16:26:33, max mem: 15.9 GB 
[10/24 22:23:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 37.7221,	0.6494 s / batch. (data: 1.34e-02). ETA=17:25:46, max mem: 15.9 GB 
[10/24 22:24:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 17.5144,	0.6136 s / batch. (data: 2.90e-04). ETA=16:27:08, max mem: 15.9 GB 
[10/24 22:25:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 325.9316,	0.6447 s / batch. (data: 1.13e-03). ETA=17:16:09, max mem: 15.9 GB 
[10/24 22:26:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 197.3320,	0.6324 s / batch. (data: 3.50e-04). ETA=16:55:20, max mem: 15.9 GB 
[10/24 22:27:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 76.2719,	0.6128 s / batch. (data: 1.74e-04). ETA=16:22:46, max mem: 15.9 GB 
[10/24 22:27:43][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.65e-03, avg batch time: 0.6309, average train loss: 118.1208
[10/24 22:28:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 34.913, 0.2253 s / batch. (data: 3.00e-05)max mem: 15.91075 GB 
[10/24 22:28:43][INFO] visual_prompt:  316: Inference (val):avg data time: 6.37e-05, avg batch time: 0.2323, average loss: 31.6482
[10/24 22:28:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[10/24 22:28:43][INFO] visual_prompt:   36: Best epoch 13: best metric: -31.648
[10/24 22:28:43][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 24.931523692103415
[10/24 22:29:49][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 219.7962,	0.6168 s / batch. (data: 3.28e-04). ETA=16:28:08, max mem: 15.9 GB 
[10/24 22:30:52][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 472.0587,	0.6140 s / batch. (data: 3.25e-04). ETA=16:22:35, max mem: 15.9 GB 
[10/24 22:31:55][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 61.9508,	0.6193 s / batch. (data: 3.39e-04). ETA=16:30:03, max mem: 15.9 GB 
[10/24 22:32:58][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6066 s / batch. (data: 2.85e-04). ETA=16:08:50, max mem: 15.9 GB 
[10/24 22:34:00][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 35.1263,	0.6247 s / batch. (data: 7.94e-04). ETA=16:36:37, max mem: 15.9 GB 
[10/24 22:35:03][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 28.5796,	0.6487 s / batch. (data: 8.44e-04). ETA=17:13:53, max mem: 15.9 GB 
[10/24 22:36:06][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 112.0890,	0.6200 s / batch. (data: 2.96e-04). ETA=16:27:04, max mem: 15.9 GB 
[10/24 22:37:09][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 666.7400,	0.6181 s / batch. (data: 7.39e-04). ETA=16:23:02, max mem: 15.9 GB 
[10/24 22:38:12][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 75.2722,	0.6259 s / batch. (data: 7.49e-04). ETA=16:34:18, max mem: 15.9 GB 
[10/24 22:39:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 519.6763,	0.6320 s / batch. (data: 2.96e-04). ETA=16:43:00, max mem: 15.9 GB 
[10/24 22:40:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 103.5692,	0.6125 s / batch. (data: 1.67e-04). ETA=16:11:00, max mem: 15.9 GB 
[10/24 22:40:21][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.57e-03, avg batch time: 0.6311, average train loss: 118.1210
[10/24 22:41:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 42.451, 0.2356 s / batch. (data: 3.10e-05)max mem: 15.91075 GB 
[10/24 22:41:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2333, average loss: 45.2138
[10/24 22:41:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.10	
[10/24 22:41:22][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 24.87835085926963
[10/24 22:42:27][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 748.6628,	0.6404 s / batch. (data: 7.91e-04). ETA=16:54:07, max mem: 15.9 GB 
[10/24 22:43:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 49.5659,	0.6302 s / batch. (data: 1.19e-03). ETA=16:36:57, max mem: 15.9 GB 
[10/24 22:44:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 268.7130,	0.6413 s / batch. (data: 1.29e-02). ETA=16:53:24, max mem: 15.9 GB 
[10/24 22:45:35][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 533.2347,	0.6324 s / batch. (data: 7.79e-04). ETA=16:38:15, max mem: 15.9 GB 
[10/24 22:46:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6122 s / batch. (data: 3.28e-04). ETA=16:05:25, max mem: 15.9 GB 
[10/24 22:47:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 14.2885,	0.6402 s / batch. (data: 8.13e-04). ETA=16:48:28, max mem: 15.9 GB 
[10/24 22:48:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 71.2274,	0.6358 s / batch. (data: 7.65e-04). ETA=16:40:32, max mem: 15.9 GB 
[10/24 22:49:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 113.6589,	0.6414 s / batch. (data: 7.61e-04). ETA=16:48:11, max mem: 15.9 GB 
[10/24 22:50:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 198.1887,	0.6217 s / batch. (data: 3.24e-04). ETA=16:16:11, max mem: 15.9 GB 
[10/24 22:51:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 230.6272,	0.6346 s / batch. (data: 7.45e-04). ETA=16:35:27, max mem: 15.9 GB 
[10/24 22:52:55][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 275.7973,	0.6121 s / batch. (data: 1.75e-04). ETA=15:59:08, max mem: 15.9 GB 
[10/24 22:52:59][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.11e-03, avg batch time: 0.6300, average train loss: 126.5842
[10/24 22:53:49][INFO] visual_prompt:  303: 	Test 100/123. loss: 81.379, 0.2357 s / batch. (data: 2.79e-05)max mem: 15.91075 GB 
[10/24 22:53:59][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.2333, average loss: 88.6188
[10/24 22:53:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.70	
[10/24 22:53:59][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 24.8100969126526
[10/24 22:55:04][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6277 s / batch. (data: 8.68e-04). ETA=16:22:24, max mem: 15.9 GB 
[10/24 22:56:07][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 75.5150,	0.6268 s / batch. (data: 8.77e-04). ETA=16:20:01, max mem: 15.9 GB 
[10/24 22:57:10][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 150.9041,	0.6195 s / batch. (data: 3.11e-04). ETA=16:07:37, max mem: 15.9 GB 
[10/24 22:58:13][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 129.7024,	0.6375 s / batch. (data: 8.04e-04). ETA=16:34:38, max mem: 15.9 GB 
[10/24 22:59:16][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 401.7729,	0.6248 s / batch. (data: 3.38e-04). ETA=16:13:45, max mem: 15.9 GB 
[10/24 23:00:19][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 97.2826,	0.6327 s / batch. (data: 7.95e-04). ETA=16:25:03, max mem: 15.9 GB 
[10/24 23:01:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 150.0333,	0.6264 s / batch. (data: 7.36e-04). ETA=16:14:08, max mem: 15.9 GB 
[10/24 23:02:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 143.8675,	0.6127 s / batch. (data: 2.97e-04). ETA=15:51:54, max mem: 15.9 GB 
[10/24 23:03:28][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 47.7978,	0.6301 s / batch. (data: 8.18e-04). ETA=16:17:45, max mem: 15.9 GB 
[10/24 23:04:31][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 83.0511,	0.6555 s / batch. (data: 9.11e-04). ETA=16:56:04, max mem: 15.9 GB 
[10/24 23:05:34][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 185.8646,	0.6174 s / batch. (data: 1.68e-04). ETA=15:56:06, max mem: 15.9 GB 
[10/24 23:05:37][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.40e-03, avg batch time: 0.6310, average train loss: 124.3782
[10/24 23:06:28][INFO] visual_prompt:  303: 	Test 100/123. loss: 116.885, 0.2255 s / batch. (data: 5.41e-05)max mem: 15.91075 GB 
[10/24 23:06:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2321, average loss: 124.4265
[10/24 23:06:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.98	
[10/24 23:06:38][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 24.72684500917257
[10/24 23:07:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6166 s / batch. (data: 3.01e-04). ETA=15:53:44, max mem: 15.9 GB 
[10/24 23:08:47][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 185.1731,	0.6279 s / batch. (data: 7.95e-04). ETA=16:10:05, max mem: 15.9 GB 
[10/24 23:09:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 546.8869,	0.6370 s / batch. (data: 8.22e-04). ETA=16:23:07, max mem: 15.9 GB 
[10/24 23:10:52][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6641 s / batch. (data: 2.80e-02). ETA=17:03:47, max mem: 15.9 GB 
[10/24 23:11:55][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6327 s / batch. (data: 7.94e-04). ETA=16:14:22, max mem: 15.9 GB 
[10/24 23:12:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 332.0647,	0.6257 s / batch. (data: 3.44e-04). ETA=16:02:38, max mem: 15.9 GB 
[10/24 23:14:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 171.4584,	0.6387 s / batch. (data: 7.90e-04). ETA=16:21:31, max mem: 15.9 GB 
[10/24 23:15:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6227 s / batch. (data: 7.85e-04). ETA=15:55:55, max mem: 15.9 GB 
[10/24 23:16:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6120 s / batch. (data: 2.72e-04). ETA=15:38:22, max mem: 15.9 GB 
[10/24 23:17:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6198 s / batch. (data: 3.21e-04). ETA=15:49:22, max mem: 15.9 GB 
[10/24 23:18:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6076 s / batch. (data: 1.50e-04). ETA=15:29:43, max mem: 15.9 GB 
[10/24 23:18:17][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.49e-03, avg batch time: 0.6314, average train loss: 123.7055
[10/24 23:19:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 27.243, 0.2438 s / batch. (data: 3.03e-05)max mem: 15.91075 GB 
[10/24 23:19:20][INFO] visual_prompt:  316: Inference (val):avg data time: 2.28e-04, avg batch time: 0.2335, average loss: 25.3818
[10/24 23:19:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.45	
[10/24 23:19:20][INFO] visual_prompt:   36: Best epoch 17: best metric: -25.382
[10/24 23:19:20][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 24.628696578449954
[10/24 23:20:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 501.4211,	0.6421 s / batch. (data: 7.51e-04). ETA=16:21:15, max mem: 15.9 GB 
[10/24 23:21:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 195.5617,	0.6284 s / batch. (data: 2.89e-04). ETA=15:59:23, max mem: 15.9 GB 
[10/24 23:22:32][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 643.8955,	0.6255 s / batch. (data: 3.28e-04). ETA=15:53:54, max mem: 15.9 GB 
[10/24 23:23:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 165.2491,	0.6295 s / batch. (data: 7.51e-04). ETA=15:58:52, max mem: 15.9 GB 
[10/24 23:24:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6253 s / batch. (data: 9.13e-04). ETA=15:51:31, max mem: 15.9 GB 
[10/24 23:25:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6278 s / batch. (data: 7.96e-04). ETA=15:54:12, max mem: 15.9 GB 
[10/24 23:26:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6255 s / batch. (data: 7.82e-04). ETA=15:49:38, max mem: 15.9 GB 
[10/24 23:27:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 155.6706,	0.6258 s / batch. (data: 8.08e-04). ETA=15:49:08, max mem: 15.9 GB 
[10/24 23:28:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 358.0078,	0.6259 s / batch. (data: 8.09e-04). ETA=15:48:09, max mem: 15.9 GB 
[10/24 23:29:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 98.3634,	0.6140 s / batch. (data: 3.08e-04). ETA=15:29:13, max mem: 15.9 GB 
[10/24 23:30:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 91.5761,	0.6178 s / batch. (data: 1.48e-04). ETA=15:33:55, max mem: 15.9 GB 
[10/24 23:30:58][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 5.27e-03, avg batch time: 0.6310, average train loss: 117.5346
[10/24 23:31:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 43.310, 0.2353 s / batch. (data: 2.77e-05)max mem: 15.91075 GB 
[10/24 23:31:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.76e-05, avg batch time: 0.2332, average loss: 48.6654
[10/24 23:31:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.86	
[10/24 23:31:58][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 24.515771199228986
[10/24 23:33:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6333 s / batch. (data: 8.16e-04). ETA=15:56:11, max mem: 15.9 GB 
[10/24 23:34:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6282 s / batch. (data: 1.60e-02). ETA=15:47:28, max mem: 15.9 GB 
[10/24 23:35:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6440 s / batch. (data: 7.74e-04). ETA=16:10:10, max mem: 15.9 GB 
[10/24 23:36:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 88.1939,	0.6254 s / batch. (data: 3.24e-04). ETA=15:41:07, max mem: 15.9 GB 
[10/24 23:37:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 51.7091,	0.6322 s / batch. (data: 7.90e-04). ETA=15:50:16, max mem: 15.9 GB 
[10/24 23:38:18][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 765.3746,	0.6192 s / batch. (data: 4.28e-04). ETA=15:29:48, max mem: 15.9 GB 
[10/24 23:39:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 4.8585,	0.6182 s / batch. (data: 3.05e-04). ETA=15:27:14, max mem: 15.9 GB 
[10/24 23:40:36][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6075 s / batch. (data: 3.25e-04). ETA=15:10:08, max mem: 15.9 GB 
[10/24 23:41:39][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 74.2979,	0.6179 s / batch. (data: 3.15e-04). ETA=15:24:43, max mem: 15.9 GB 
[10/24 23:42:42][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6318 s / batch. (data: 8.09e-04). ETA=15:44:29, max mem: 15.9 GB 
[10/24 23:43:45][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6178 s / batch. (data: 1.96e-04). ETA=15:22:28, max mem: 15.9 GB 
[10/24 23:43:49][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.64e-02, avg batch time: 0.6420, average train loss: 122.0435
[10/24 23:44:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 70.870, 0.2250 s / batch. (data: 3.58e-05)max mem: 15.91075 GB 
[10/24 23:44:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2310, average loss: 65.1144
[10/24 23:44:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.71	
[10/24 23:44:53][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 24.38820645368942
[10/24 23:45:58][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 32.3897,	0.6560 s / batch. (data: 7.92e-04). ETA=16:18:18, max mem: 15.9 GB 
[10/24 23:47:01][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6203 s / batch. (data: 3.01e-03). ETA=15:24:03, max mem: 15.9 GB 
[10/24 23:48:04][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 20.2761,	0.6276 s / batch. (data: 7.97e-03). ETA=15:33:56, max mem: 15.9 GB 
[10/24 23:49:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 158.0844,	0.6596 s / batch. (data: 4.06e-02). ETA=16:20:27, max mem: 15.9 GB 
[10/24 23:50:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 73.9700,	0.6452 s / batch. (data: 1.71e-02). ETA=15:57:53, max mem: 15.9 GB 
[10/24 23:51:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 569.4030,	0.6352 s / batch. (data: 1.57e-02). ETA=15:42:00, max mem: 15.9 GB 
[10/24 23:52:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6584 s / batch. (data: 3.84e-02). ETA=16:15:19, max mem: 15.9 GB 
[10/24 23:53:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 75.9686,	0.6323 s / batch. (data: 1.20e-03). ETA=15:35:38, max mem: 15.9 GB 
[10/24 23:54:22][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 324.3801,	0.6613 s / batch. (data: 7.99e-04). ETA=16:17:31, max mem: 15.9 GB 
[10/24 23:55:25][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 682.7183,	0.6439 s / batch. (data: 1.68e-02). ETA=15:50:37, max mem: 15.9 GB 
[10/24 23:56:28][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6427,	0.6132 s / batch. (data: 1.63e-04). ETA=15:04:17, max mem: 15.9 GB 
[10/24 23:56:32][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 5.42e-03, avg batch time: 0.6324, average train loss: 126.1492
[10/24 23:57:22][INFO] visual_prompt:  303: 	Test 100/123. loss: 60.593, 0.2392 s / batch. (data: 2.98e-05)max mem: 15.91075 GB 
[10/24 23:57:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.75e-05, avg batch time: 0.2321, average loss: 67.1120
[10/24 23:57:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.66	
[10/24 23:57:32][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 24.246157759823856
[10/24 23:58:38][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6465 s / batch. (data: 5.90e-03). ETA=15:52:18, max mem: 15.9 GB 
[10/24 23:59:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6345 s / batch. (data: 1.06e-02). ETA=15:33:34, max mem: 15.9 GB 
[10/25 00:00:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 489.8066,	0.6370 s / batch. (data: 9.07e-03). ETA=15:36:13, max mem: 15.9 GB 
[10/25 00:01:47][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 34.3874,	0.6612 s / batch. (data: 8.50e-04). ETA=16:10:35, max mem: 15.9 GB 
[10/25 00:02:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6139 s / batch. (data: 4.39e-04). ETA=15:00:07, max mem: 15.9 GB 
[10/25 00:03:53][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.4701,	0.6178 s / batch. (data: 3.34e-04). ETA=15:04:49, max mem: 15.9 GB 
[10/25 00:04:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 62.1117,	0.6271 s / batch. (data: 7.08e-04). ETA=15:17:27, max mem: 15.9 GB 
[10/25 00:05:59][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 476.4156,	0.6400 s / batch. (data: 7.91e-04). ETA=15:35:11, max mem: 15.9 GB 
[10/25 00:07:02][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 71.5161,	0.6480 s / batch. (data: 7.42e-04). ETA=15:45:48, max mem: 15.9 GB 
[10/25 00:08:05][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 83.7901,	0.6193 s / batch. (data: 3.20e-04). ETA=15:02:56, max mem: 15.9 GB 
[10/25 00:09:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6072 s / batch. (data: 1.70e-04). ETA=14:44:19, max mem: 15.9 GB 
[10/25 00:09:12][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.89e-03, avg batch time: 0.6327, average train loss: 112.3945
[10/25 00:10:05][INFO] visual_prompt:  303: 	Test 100/123. loss: 81.663, 0.2525 s / batch. (data: 7.08e-05)max mem: 15.91075 GB 
[10/25 00:10:21][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2313, average loss: 73.8199
[10/25 00:10:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.70	
[10/25 00:10:21][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 24.08979818208484
[10/25 00:11:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 23.1520,	0.6179 s / batch. (data: 7.67e-04). ETA=14:58:43, max mem: 15.9 GB 
[10/25 00:12:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 267.4109,	0.6389 s / batch. (data: 8.17e-04). ETA=15:28:17, max mem: 15.9 GB 
[10/25 00:13:32][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6166 s / batch. (data: 2.40e-03). ETA=14:54:47, max mem: 15.9 GB 
[10/25 00:14:35][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6192 s / batch. (data: 3.13e-04). ETA=14:57:35, max mem: 15.9 GB 
[10/25 00:15:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 86.5861,	0.6311 s / batch. (data: 3.19e-04). ETA=15:13:47, max mem: 15.9 GB 
[10/25 00:16:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6082 s / batch. (data: 4.26e-04). ETA=14:39:38, max mem: 15.9 GB 
[10/25 00:17:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6135 s / batch. (data: 3.09e-04). ETA=14:46:18, max mem: 15.9 GB 
[10/25 00:18:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 13.3801,	0.6198 s / batch. (data: 3.07e-04). ETA=14:54:14, max mem: 15.9 GB 
[10/25 00:19:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 124.8602,	0.6134 s / batch. (data: 2.75e-04). ETA=14:44:04, max mem: 15.9 GB 
[10/25 00:20:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 12.2789,	0.6480 s / batch. (data: 8.02e-04). ETA=15:32:46, max mem: 15.9 GB 
[10/25 00:21:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 134.0816,	0.6188 s / batch. (data: 1.80e-04). ETA=14:49:45, max mem: 15.9 GB 
[10/25 00:22:01][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 5.01e-03, avg batch time: 0.6326, average train loss: 97.9287
[10/25 00:22:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 152.176, 0.2515 s / batch. (data: 3.45e-04)max mem: 15.91075 GB 
[10/25 00:23:04][INFO] visual_prompt:  316: Inference (val):avg data time: 4.23e-05, avg batch time: 0.2319, average loss: 131.8432
[10/25 00:23:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.33	
[10/25 00:23:04][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 23.91931822053251
[10/25 00:24:11][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 215.5821,	0.6422 s / batch. (data: 1.82e-02). ETA=15:22:15, max mem: 15.9 GB 
[10/25 00:25:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 103.7693,	0.6426 s / batch. (data: 8.21e-04). ETA=15:21:49, max mem: 15.9 GB 
[10/25 00:26:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 139.8119,	0.6268 s / batch. (data: 7.99e-04). ETA=14:58:02, max mem: 15.9 GB 
[10/25 00:27:20][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 14.2595,	0.6331 s / batch. (data: 8.79e-04). ETA=15:06:05, max mem: 15.9 GB 
[10/25 00:28:23][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 15.0234,	0.6219 s / batch. (data: 3.29e-04). ETA=14:48:55, max mem: 15.9 GB 
[10/25 00:29:26][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6086 s / batch. (data: 3.27e-04). ETA=14:28:58, max mem: 15.9 GB 
[10/25 00:30:29][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 151.3967,	0.6262 s / batch. (data: 8.05e-04). ETA=14:53:01, max mem: 15.9 GB 
[10/25 00:31:32][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 45.9363,	0.6243 s / batch. (data: 3.02e-04). ETA=14:49:18, max mem: 15.9 GB 
[10/25 00:32:35][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 258.1361,	0.6256 s / batch. (data: 3.44e-04). ETA=14:50:07, max mem: 15.9 GB 
[10/25 00:33:38][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6347 s / batch. (data: 8.04e-04). ETA=15:02:03, max mem: 15.9 GB 
[10/25 00:34:41][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 58.9415,	0.6139 s / batch. (data: 1.51e-04). ETA=14:31:28, max mem: 15.9 GB 
[10/25 00:34:45][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 6.11e-03, avg batch time: 0.6335, average train loss: 127.1168
[10/25 00:35:36][INFO] visual_prompt:  303: 	Test 100/123. loss: 38.962, 0.2249 s / batch. (data: 4.36e-05)max mem: 15.91075 GB 
[10/25 00:35:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2316, average loss: 43.3219
[10/25 00:35:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.02	
[10/25 00:35:48][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 23.73492557873959
[10/25 00:36:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6288 s / batch. (data: 8.26e-04). ETA=14:51:26, max mem: 15.9 GB 
[10/25 00:37:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 152.1737,	0.6147 s / batch. (data: 2.94e-04). ETA=14:30:23, max mem: 15.9 GB 
[10/25 00:38:59][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6354 s / batch. (data: 8.83e-04). ETA=14:58:37, max mem: 15.9 GB 
[10/25 00:40:02][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 168.3738,	0.6134 s / batch. (data: 3.39e-04). ETA=14:26:32, max mem: 15.9 GB 
[10/25 00:41:05][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 384.8529,	0.6427 s / batch. (data: 5.89e-03). ETA=15:06:54, max mem: 15.9 GB 
[10/25 00:42:08][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 102.4772,	0.6125 s / batch. (data: 3.11e-04). ETA=14:23:13, max mem: 15.9 GB 
[10/25 00:43:12][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 119.9294,	0.6341 s / batch. (data: 3.16e-04). ETA=14:52:39, max mem: 15.9 GB 
[10/25 00:44:15][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 413.8970,	0.6138 s / batch. (data: 3.02e-04). ETA=14:23:03, max mem: 15.9 GB 
[10/25 00:45:18][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6181 s / batch. (data: 3.20e-04). ETA=14:27:59, max mem: 15.9 GB 
[10/25 00:46:21][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 72.7657,	0.6280 s / batch. (data: 7.98e-04). ETA=14:40:52, max mem: 15.9 GB 
[10/25 00:47:24][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 102.5525,	0.6134 s / batch. (data: 1.46e-04). ETA=14:19:19, max mem: 15.9 GB 
[10/25 00:47:28][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 5.97e-03, avg batch time: 0.6331, average train loss: 116.0251
[10/25 00:48:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 16.981, 0.2255 s / batch. (data: 4.77e-05)max mem: 15.91075 GB 
[10/25 00:48:30][INFO] visual_prompt:  316: Inference (val):avg data time: 2.60e-04, avg batch time: 0.2319, average loss: 17.9934
[10/25 00:48:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.54	
[10/25 00:48:30][INFO] visual_prompt:   36: Best epoch 24: best metric: -17.993
[10/25 00:48:30][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 23.536844910736587
[10/25 00:49:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 23.8716,	0.6610 s / batch. (data: 3.03e-04). ETA=15:24:54, max mem: 15.9 GB 
[10/25 00:50:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 31.8906,	0.6264 s / batch. (data: 3.41e-04). ETA=14:35:25, max mem: 15.9 GB 
[10/25 00:51:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 92.5490,	0.6255 s / batch. (data: 3.56e-04). ETA=14:33:07, max mem: 15.9 GB 
[10/25 00:52:45][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 166.5957,	0.6440 s / batch. (data: 2.15e-04). ETA=14:57:51, max mem: 15.9 GB 
[10/25 00:53:48][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 148.8714,	0.6332 s / batch. (data: 8.97e-04). ETA=14:41:46, max mem: 15.9 GB 
[10/25 00:54:51][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 332.8841,	0.6469 s / batch. (data: 8.53e-04). ETA=14:59:51, max mem: 15.9 GB 
[10/25 00:55:54][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 86.6632,	0.6320 s / batch. (data: 2.99e-04). ETA=14:38:00, max mem: 15.9 GB 
[10/25 00:56:57][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 142.9478,	0.6328 s / batch. (data: 3.08e-04). ETA=14:38:01, max mem: 15.9 GB 
[10/25 00:58:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 21.2022,	0.6183 s / batch. (data: 2.91e-04). ETA=14:16:57, max mem: 15.9 GB 
[10/25 00:59:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 13.0145,	0.6325 s / batch. (data: 7.89e-04). ETA=14:35:30, max mem: 15.9 GB 
[10/25 01:00:06][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 451.7282,	0.6179 s / batch. (data: 1.74e-04). ETA=14:14:17, max mem: 15.9 GB 
[10/25 01:00:10][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 5.19e-03, avg batch time: 0.6325, average train loss: 108.4790
[10/25 01:01:02][INFO] visual_prompt:  303: 	Test 100/123. loss: 154.785, 0.2317 s / batch. (data: 3.17e-05)max mem: 15.91075 GB 
[10/25 01:01:12][INFO] visual_prompt:  316: Inference (val):avg data time: 4.06e-05, avg batch time: 0.2331, average loss: 139.3006
[10/25 01:01:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.59	
[10/25 01:01:12][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 23.325317547305485
[10/25 01:02:18][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.7535,	0.6373 s / batch. (data: 2.86e-04). ETA=14:40:01, max mem: 15.9 GB 
[10/25 01:03:21][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 266.1630,	0.6220 s / batch. (data: 8.51e-04). ETA=14:17:49, max mem: 15.9 GB 
[10/25 01:04:24][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6295 s / batch. (data: 1.30e-02). ETA=14:27:07, max mem: 15.9 GB 
[10/25 01:05:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 182.1003,	0.6121 s / batch. (data: 3.11e-04). ETA=14:02:09, max mem: 15.9 GB 
[10/25 01:06:30][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 108.9824,	0.6234 s / batch. (data: 1.05e-02). ETA=14:16:40, max mem: 15.9 GB 
[10/25 01:07:33][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 54.4287,	0.6360 s / batch. (data: 3.37e-04). ETA=14:32:55, max mem: 15.9 GB 
[10/25 01:08:36][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6336 s / batch. (data: 8.44e-04). ETA=14:28:30, max mem: 15.9 GB 
[10/25 01:09:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 271.2348,	0.6180 s / batch. (data: 3.09e-04). ETA=14:06:11, max mem: 15.9 GB 
[10/25 01:10:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 103.4888,	0.6389 s / batch. (data: 1.03e-03). ETA=14:33:44, max mem: 15.9 GB 
[10/25 01:11:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 28.7736,	0.6362 s / batch. (data: 5.90e-03). ETA=14:28:59, max mem: 15.9 GB 
[10/25 01:12:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6165 s / batch. (data: 1.47e-04). ETA=14:01:01, max mem: 15.9 GB 
[10/25 01:12:52][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 4.98e-03, avg batch time: 0.6324, average train loss: 115.5925
[10/25 01:13:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 60.473, 0.2398 s / batch. (data: 2.69e-05)max mem: 15.91075 GB 
[10/25 01:13:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.80e-05, avg batch time: 0.2324, average loss: 54.5459
[10/25 01:13:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.52	
[10/25 01:13:54][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 23.100601201955325
[10/25 01:15:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 857.1221,	0.6169 s / batch. (data: 3.23e-04). ETA=14:00:27, max mem: 15.9 GB 
[10/25 01:16:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 187.2483,	0.6181 s / batch. (data: 7.93e-04). ETA=14:01:07, max mem: 15.9 GB 
[10/25 01:17:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 318.2576,	0.6350 s / batch. (data: 8.01e-04). ETA=14:23:01, max mem: 15.9 GB 
[10/25 01:18:09][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 321.5532,	0.6364 s / batch. (data: 3.19e-04). ETA=14:23:50, max mem: 15.9 GB 
[10/25 01:19:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6125 s / batch. (data: 5.47e-03). ETA=13:50:21, max mem: 15.9 GB 
[10/25 01:20:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 156.3926,	0.6239 s / batch. (data: 3.95e-04). ETA=14:04:51, max mem: 15.9 GB 
[10/25 01:21:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 226.0295,	0.6324 s / batch. (data: 8.21e-04). ETA=14:15:12, max mem: 15.9 GB 
[10/25 01:22:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 29.4855,	0.6226 s / batch. (data: 3.14e-04). ETA=14:00:54, max mem: 15.9 GB 
[10/25 01:23:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 83.2462,	0.6195 s / batch. (data: 8.86e-04). ETA=13:55:43, max mem: 15.9 GB 
[10/25 01:24:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 235.1633,	0.6237 s / batch. (data: 3.42e-04). ETA=14:00:22, max mem: 15.9 GB 
[10/25 01:25:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6174 s / batch. (data: 1.96e-04). ETA=13:50:54, max mem: 15.9 GB 
[10/25 01:25:33][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 5.31e-03, avg batch time: 0.6317, average train loss: 122.8583
[10/25 01:26:25][INFO] visual_prompt:  303: 	Test 100/123. loss: 207.807, 0.2333 s / batch. (data: 3.98e-05)max mem: 15.91075 GB 
[10/25 01:26:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2335, average loss: 230.6631
[10/25 01:26:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.41	
[10/25 01:26:36][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 22.86296965693802
[10/25 01:27:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6068 s / batch. (data: 3.50e-04). ETA=13:35:32, max mem: 15.9 GB 
[10/25 01:28:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6224 s / batch. (data: 8.58e-04). ETA=13:55:25, max mem: 15.9 GB 
[10/25 01:29:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6202 s / batch. (data: 3.28e-04). ETA=13:51:25, max mem: 15.9 GB 
[10/25 01:30:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 138.3862,	0.6480 s / batch. (data: 8.16e-04). ETA=14:27:36, max mem: 15.9 GB 
[10/25 01:31:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 11.5823,	0.6203 s / batch. (data: 3.17e-04). ETA=13:49:31, max mem: 15.9 GB 
[10/25 01:32:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 167.6088,	0.6592 s / batch. (data: 7.62e-04). ETA=14:40:23, max mem: 15.9 GB 
[10/25 01:33:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 97.7232,	0.6324 s / batch. (data: 3.55e-04). ETA=14:03:34, max mem: 15.9 GB 
[10/25 01:35:10][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 81.7778,	0.6315 s / batch. (data: 3.13e-04). ETA=14:01:21, max mem: 15.9 GB 
[10/25 01:36:13][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 33.5665,	0.6193 s / batch. (data: 3.48e-04). ETA=13:44:01, max mem: 15.9 GB 
[10/25 01:37:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6455 s / batch. (data: 3.50e-04). ETA=14:17:51, max mem: 15.9 GB 
[10/25 01:38:19][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 235.6552,	0.6136 s / batch. (data: 1.54e-04). ETA=13:34:22, max mem: 15.9 GB 
[10/25 01:38:23][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.21e-02, avg batch time: 0.6394, average train loss: 117.4811
[10/25 01:39:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 8.354, 0.2317 s / batch. (data: 2.72e-05)max mem: 15.91075 GB 
[10/25 01:39:25][INFO] visual_prompt:  316: Inference (val):avg data time: 4.06e-05, avg batch time: 0.2322, average loss: 7.1980
[10/25 01:39:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.15	
[10/25 01:39:25][INFO] visual_prompt:   36: Best epoch 28: best metric: -7.198
[10/25 01:39:25][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 22.612712429686844
[10/25 01:40:31][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 53.0760,	0.6400 s / batch. (data: 2.85e-04). ETA=14:08:19, max mem: 15.9 GB 
[10/25 01:41:34][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 51.4524,	0.6640 s / batch. (data: 3.70e-04). ETA=14:39:05, max mem: 15.9 GB 
[10/25 01:42:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 29.1055,	0.6182 s / batch. (data: 3.17e-04). ETA=13:37:21, max mem: 15.9 GB 
[10/25 01:43:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 90.0214,	0.6239 s / batch. (data: 3.50e-04). ETA=13:43:52, max mem: 15.9 GB 
[10/25 01:44:44][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 21.9607,	0.6417 s / batch. (data: 1.33e-02). ETA=14:06:21, max mem: 15.9 GB 
[10/25 01:45:47][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 108.1535,	0.6200 s / batch. (data: 3.74e-04). ETA=13:36:38, max mem: 15.9 GB 
[10/25 01:46:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 98.5215,	0.6360 s / batch. (data: 2.66e-04). ETA=13:56:41, max mem: 15.9 GB 
[10/25 01:47:54][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6323 s / batch. (data: 8.27e-04). ETA=13:50:46, max mem: 15.9 GB 
[10/25 01:48:57][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6269 s / batch. (data: 4.70e-04). ETA=13:42:34, max mem: 15.9 GB 
[10/25 01:50:01][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 108.1691,	0.6413 s / batch. (data: 5.43e-03). ETA=14:00:23, max mem: 15.9 GB 
[10/25 01:51:04][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 45.3825,	0.6146 s / batch. (data: 1.68e-04). ETA=13:24:29, max mem: 15.9 GB 
[10/25 01:51:08][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 5.51e-03, avg batch time: 0.6351, average train loss: 113.7869
[10/25 01:52:01][INFO] visual_prompt:  303: 	Test 100/123. loss: 128.132, 0.2267 s / batch. (data: 3.53e-05)max mem: 15.91075 GB 
[10/25 01:52:12][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2321, average loss: 115.0742
[10/25 01:52:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.60	
[10/25 01:52:12][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 22.35013442008402
[10/25 01:53:17][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 156.5910,	0.6207 s / batch. (data: 3.17e-04). ETA=13:31:17, max mem: 15.9 GB 
[10/25 01:54:20][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 231.7879,	0.6345 s / batch. (data: 8.16e-04). ETA=13:48:19, max mem: 15.9 GB 
[10/25 01:55:23][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 40.3250,	0.6334 s / batch. (data: 1.34e-02). ETA=13:45:51, max mem: 15.9 GB 
[10/25 01:56:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 79.3280,	0.6293 s / batch. (data: 6.95e-04). ETA=13:39:26, max mem: 15.9 GB 
[10/25 01:57:30][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 89.1430,	0.6287 s / batch. (data: 3.27e-04). ETA=13:37:38, max mem: 15.9 GB 
[10/25 01:58:33][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 118.0113,	0.6560 s / batch. (data: 8.04e-03). ETA=14:11:58, max mem: 15.9 GB 
[10/25 01:59:36][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 180.4695,	0.6307 s / batch. (data: 7.52e-04). ETA=13:38:02, max mem: 15.9 GB 
[10/25 02:00:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 124.9436,	0.6151 s / batch. (data: 8.16e-04). ETA=13:16:50, max mem: 15.9 GB 
[10/25 02:01:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 16.3471,	0.6276 s / batch. (data: 3.46e-04). ETA=13:32:00, max mem: 15.9 GB 
[10/25 02:02:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6090 s / batch. (data: 8.21e-04). ETA=13:06:56, max mem: 15.9 GB 
[10/25 02:03:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 329.2981,	0.6186 s / batch. (data: 1.89e-04). ETA=13:18:14, max mem: 15.9 GB 
[10/25 02:03:52][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 4.98e-03, avg batch time: 0.6326, average train loss: 109.7843
[10/25 02:04:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 13.077, 0.2263 s / batch. (data: 3.10e-05)max mem: 15.91075 GB 
[10/25 02:04:54][INFO] visual_prompt:  316: Inference (val):avg data time: 4.24e-05, avg batch time: 0.2317, average loss: 12.7927
[10/25 02:04:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 46.23	
[10/25 02:04:54][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 22.075555538987224
[10/25 02:06:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6278 s / batch. (data: 3.35e-04). ETA=13:29:00, max mem: 15.9 GB 
[10/25 02:07:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 343.1135,	0.6419 s / batch. (data: 8.21e-04). ETA=13:46:08, max mem: 15.9 GB 
[10/25 02:08:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6339 s / batch. (data: 1.06e-02). ETA=13:34:50, max mem: 15.9 GB 
[10/25 02:09:09][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 300.0972,	0.6324 s / batch. (data: 3.35e-04). ETA=13:31:47, max mem: 15.9 GB 
[10/25 02:10:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6260 s / batch. (data: 8.52e-04). ETA=13:22:33, max mem: 15.9 GB 
[10/25 02:11:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 94.7254,	0.6320 s / batch. (data: 3.29e-04). ETA=13:29:09, max mem: 15.9 GB 
[10/25 02:12:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1154.0796,	0.6332 s / batch. (data: 8.35e-04). ETA=13:29:37, max mem: 15.9 GB 
[10/25 02:13:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6094 s / batch. (data: 3.76e-04). ETA=12:58:15, max mem: 15.9 GB 
[10/25 02:14:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 150.9526,	0.6446 s / batch. (data: 8.19e-04). ETA=13:42:02, max mem: 15.9 GB 
[10/25 02:15:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 375.0662,	0.6251 s / batch. (data: 3.08e-04). ETA=13:16:11, max mem: 15.9 GB 
[10/25 02:16:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6091 s / batch. (data: 1.49e-04). ETA=12:54:45, max mem: 15.9 GB 
[10/25 02:16:34][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 5.17e-03, avg batch time: 0.6328, average train loss: 102.3317
[10/25 02:17:25][INFO] visual_prompt:  303: 	Test 100/123. loss: 49.083, 0.2256 s / batch. (data: 4.01e-05)max mem: 15.91075 GB 
[10/25 02:17:36][INFO] visual_prompt:  316: Inference (val):avg data time: 4.21e-05, avg batch time: 0.2330, average loss: 53.3371
[10/25 02:17:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.56	
[10/25 02:17:36][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 21.78931031846743
[10/25 02:18:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 126.6069,	0.6201 s / batch. (data: 2.90e-04). ETA=13:07:39, max mem: 15.9 GB 
[10/25 02:19:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 170.8268,	0.6333 s / batch. (data: 2.95e-04). ETA=13:23:23, max mem: 15.9 GB 
[10/25 02:20:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6121 s / batch. (data: 3.33e-04). ETA=12:55:25, max mem: 15.9 GB 
[10/25 02:21:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 80.4923,	0.6369 s / batch. (data: 1.68e-03). ETA=13:25:52, max mem: 15.9 GB 
[10/25 02:22:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 24.7565,	0.6431 s / batch. (data: 7.77e-04). ETA=13:32:36, max mem: 15.9 GB 
[10/25 02:23:57][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 15.9651,	0.6341 s / batch. (data: 2.99e-04). ETA=13:20:10, max mem: 15.9 GB 
[10/25 02:25:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 345.8220,	0.6219 s / batch. (data: 3.44e-04). ETA=13:03:44, max mem: 15.9 GB 
[10/25 02:26:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 86.3265,	0.6555 s / batch. (data: 4.51e-04). ETA=13:45:02, max mem: 15.9 GB 
[10/25 02:27:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0003,	0.6319 s / batch. (data: 7.89e-04). ETA=13:14:11, max mem: 15.9 GB 
[10/25 02:28:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6240 s / batch. (data: 2.96e-04). ETA=13:03:15, max mem: 15.9 GB 
[10/25 02:29:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 404.3026,	0.6192 s / batch. (data: 1.71e-04). ETA=12:56:15, max mem: 15.9 GB 
[10/25 02:29:16][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 5.31e-03, avg batch time: 0.6331, average train loss: 110.8642
[10/25 02:30:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 113.100, 0.2292 s / batch. (data: 5.00e-04)max mem: 15.91075 GB 
[10/25 02:30:19][INFO] visual_prompt:  316: Inference (val):avg data time: 4.23e-05, avg batch time: 0.2320, average loss: 124.6308
[10/25 02:30:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.53	
[10/25 02:30:19][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 21.49174750423314
[10/25 02:31:23][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6227 s / batch. (data: 3.32e-04). ETA=12:59:30, max mem: 15.9 GB 
[10/25 02:32:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6181 s / batch. (data: 8.08e-04). ETA=12:52:46, max mem: 15.9 GB 
[10/25 02:33:29][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6290 s / batch. (data: 2.66e-04). ETA=13:05:14, max mem: 15.9 GB 
[10/25 02:34:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 193.3268,	0.6317 s / batch. (data: 8.01e-04). ETA=13:07:37, max mem: 15.9 GB 
[10/25 02:35:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6247 s / batch. (data: 3.03e-04). ETA=12:57:47, max mem: 15.9 GB 
[10/25 02:36:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 80.8401,	0.6416 s / batch. (data: 7.95e-04). ETA=13:17:48, max mem: 15.9 GB 
[10/25 02:37:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6458 s / batch. (data: 2.91e-04). ETA=13:21:54, max mem: 15.9 GB 
[10/25 02:38:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 115.5135,	0.6256 s / batch. (data: 2.99e-04). ETA=12:55:52, max mem: 15.9 GB 
[10/25 02:39:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6222 s / batch. (data: 7.93e-04). ETA=12:50:35, max mem: 15.9 GB 
[10/25 02:40:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6513 s / batch. (data: 3.46e-02). ETA=13:25:33, max mem: 15.9 GB 
[10/25 02:41:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.7556,	0.6191 s / batch. (data: 1.53e-04). ETA=12:44:40, max mem: 15.9 GB 
[10/25 02:41:56][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 4.07e-03, avg batch time: 0.6305, average train loss: 100.0059
[10/25 02:42:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 21.729, 0.2257 s / batch. (data: 3.10e-05)max mem: 15.91075 GB 
[10/25 02:42:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2323, average loss: 24.7393
[10/25 02:42:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.04	
[10/25 02:42:57][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 21.183229630737465
[10/25 02:44:01][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 106.7115,	0.6380 s / batch. (data: 7.77e-04). ETA=13:06:56, max mem: 15.9 GB 
[10/25 02:45:04][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 230.0456,	0.6346 s / batch. (data: 3.41e-04). ETA=13:01:40, max mem: 15.9 GB 
[10/25 02:46:07][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 179.2769,	0.6414 s / batch. (data: 7.89e-04). ETA=13:08:58, max mem: 15.9 GB 
[10/25 02:47:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 72.2988,	0.6440 s / batch. (data: 1.21e-02). ETA=13:11:06, max mem: 15.9 GB 
[10/25 02:48:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6091 s / batch. (data: 3.25e-04). ETA=12:27:09, max mem: 15.9 GB 
[10/25 02:49:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 66.7859,	0.6599 s / batch. (data: 1.13e-03). ETA=13:28:26, max mem: 15.9 GB 
[10/25 02:50:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 222.8192,	0.6137 s / batch. (data: 3.35e-04). ETA=12:30:49, max mem: 15.9 GB 
[10/25 02:51:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 338.2643,	0.6197 s / batch. (data: 3.29e-04). ETA=12:37:06, max mem: 15.9 GB 
[10/25 02:52:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 7.3981,	0.6202 s / batch. (data: 3.28e-04). ETA=12:36:39, max mem: 15.9 GB 
[10/25 02:53:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 64.3225,	0.6166 s / batch. (data: 2.73e-04). ETA=12:31:17, max mem: 15.9 GB 
[10/25 02:54:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 109.7883,	0.6140 s / batch. (data: 1.59e-04). ETA=12:27:04, max mem: 15.9 GB 
[10/25 02:54:34][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 4.23e-03, avg batch time: 0.6306, average train loss: 105.4052
[10/25 02:55:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 73.578, 0.2286 s / batch. (data: 4.34e-05)max mem: 15.91075 GB 
[10/25 02:55:34][INFO] visual_prompt:  316: Inference (val):avg data time: 2.51e-04, avg batch time: 0.2327, average loss: 81.6002
[10/25 02:55:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.97	
[10/25 02:55:34][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 20.864132579485727
[10/25 02:56:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6200 s / batch. (data: 5.03e-04). ETA=12:33:17, max mem: 15.9 GB 
[10/25 02:57:42][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 134.1078,	0.6516 s / batch. (data: 8.47e-04). ETA=13:10:31, max mem: 15.9 GB 
[10/25 02:58:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6137 s / batch. (data: 3.02e-04). ETA=12:23:35, max mem: 15.9 GB 
[10/25 02:59:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 70.0733,	0.6228 s / batch. (data: 2.99e-04). ETA=12:33:36, max mem: 15.9 GB 
[10/25 03:00:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 65.4526,	0.6427 s / batch. (data: 5.43e-03). ETA=12:56:30, max mem: 15.9 GB 
[10/25 03:01:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 67.1779,	0.6544 s / batch. (data: 5.94e-03). ETA=13:09:33, max mem: 15.9 GB 
[10/25 03:02:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0053,	0.6410 s / batch. (data: 7.72e-04). ETA=12:52:21, max mem: 15.9 GB 
[10/25 03:04:01][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 357.8712,	0.6144 s / batch. (data: 3.00e-04). ETA=12:19:19, max mem: 15.9 GB 
[10/25 03:05:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6085 s / batch. (data: 3.13e-04). ETA=12:11:12, max mem: 15.9 GB 
[10/25 03:06:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 14.8167,	0.6357 s / batch. (data: 2.87e-04). ETA=12:42:46, max mem: 15.9 GB 
[10/25 03:07:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 159.2403,	0.6185 s / batch. (data: 1.60e-04). ETA=12:21:04, max mem: 15.9 GB 
[10/25 03:07:13][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 4.74e-03, avg batch time: 0.6318, average train loss: 100.3226
[10/25 03:08:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 123.932, 0.2317 s / batch. (data: 2.79e-05)max mem: 15.91075 GB 
[10/25 03:08:14][INFO] visual_prompt:  316: Inference (val):avg data time: 1.70e-04, avg batch time: 0.2321, average loss: 111.6956
[10/25 03:08:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.19	
[10/25 03:08:14][INFO] visual_prompt:   42: Stopping early.
