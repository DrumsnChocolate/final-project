[10/29 23:42:33][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/29 23:42:33][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/29 23:42:33][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/29 23:42:33][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/29 23:42:33][INFO] visual_prompt:  108: Training with config:
[10/29 23:42:33][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/29 23:42:33][INFO] visual_prompt:   55: Loading training data...
[10/29 23:42:33][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/29 23:42:33][INFO] visual_prompt:   57: Loading validation data...
[10/29 23:42:33][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/29 23:42:33][INFO] visual_prompt:   38: Constructing models...
[10/29 23:42:36][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/29 23:42:36][INFO] visual_prompt:   54: tuned percent:0.522
[10/29 23:42:36][INFO] visual_prompt:   40: Device used for model: 0
[10/29 23:42:36][INFO] visual_prompt:   40: Setting up Evaluator...
[10/29 23:42:36][INFO] visual_prompt:   42: Setting up Trainer...
[10/29 23:42:36][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/29 23:42:36][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/29 23:43:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6440 s / batch. (data: 1.20e-02). ETA=19:45:59, max mem: 15.9 GB 
[10/29 23:44:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6183 s / batch. (data: 2.85e-04). ETA=18:57:35, max mem: 15.9 GB 
[10/29 23:45:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6480 s / batch. (data: 9.53e-04). ETA=19:51:12, max mem: 15.9 GB 
[10/29 23:46:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6463 s / batch. (data: 7.46e-04). ETA=19:46:57, max mem: 15.9 GB 
[10/29 23:47:55][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6320 s / batch. (data: 2.88e-04). ETA=19:19:45, max mem: 15.9 GB 
[10/29 23:48:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6306 s / batch. (data: 3.03e-04). ETA=19:16:09, max mem: 15.9 GB 
[10/29 23:50:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6204 s / batch. (data: 3.03e-04). ETA=18:56:18, max mem: 15.9 GB 
[10/29 23:51:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6578 s / batch. (data: 1.61e-02). ETA=20:03:41, max mem: 15.9 GB 
[10/29 23:52:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6600 s / batch. (data: 8.14e-04). ETA=20:06:37, max mem: 15.9 GB 
[10/29 23:53:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6424 s / batch. (data: 8.62e-04). ETA=19:33:25, max mem: 15.9 GB 
[10/29 23:54:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6185 s / batch. (data: 1.51e-04). ETA=18:48:45, max mem: 15.9 GB 
[10/29 23:54:19][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.69e-03, avg batch time: 0.6353, average train loss: 1.4028
[10/29 23:55:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2281 s / batch. (data: 3.91e-05)max mem: 15.94594 GB 
[10/29 23:55:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2325, average loss: 1.3505
[10/29 23:55:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/29 23:55:19][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.025
[10/29 23:56:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7292,	0.6417 s / batch. (data: 3.74e-04). ETA=19:29:55, max mem: 15.9 GB 
[10/29 23:57:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7610,	0.6448 s / batch. (data: 1.00e-03). ETA=19:34:28, max mem: 15.9 GB 
[10/29 23:58:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7158,	0.6371 s / batch. (data: 5.41e-03). ETA=19:19:30, max mem: 15.9 GB 
[10/29 23:59:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3557,	0.6327 s / batch. (data: 8.24e-04). ETA=19:10:19, max mem: 15.9 GB 
[10/30 00:00:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5810,	0.6600 s / batch. (data: 8.26e-04). ETA=19:58:53, max mem: 15.9 GB 
[10/30 00:01:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6091,	0.6424 s / batch. (data: 1.10e-02). ETA=19:25:53, max mem: 15.9 GB 
[10/30 00:02:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0866,	0.6440 s / batch. (data: 7.85e-04). ETA=19:27:45, max mem: 15.9 GB 
[10/30 00:03:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7527,	0.6190 s / batch. (data: 3.27e-04). ETA=18:41:19, max mem: 15.9 GB 
[10/30 00:04:51][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9438,	0.6196 s / batch. (data: 3.36e-04). ETA=18:41:25, max mem: 15.9 GB 
[10/30 00:05:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5298,	0.6333 s / batch. (data: 7.73e-04). ETA=19:05:08, max mem: 15.9 GB 
[10/30 00:06:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4876,	0.6190 s / batch. (data: 1.38e-04). ETA=18:38:11, max mem: 15.9 GB 
[10/30 00:07:01][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.91e-03, avg batch time: 0.6344, average train loss: 0.8691
[10/30 00:07:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.612, 0.2478 s / batch. (data: 4.84e-05)max mem: 15.94594 GB 
[10/30 00:08:02][INFO] visual_prompt:  316: Inference (val):avg data time: 1.30e-04, avg batch time: 0.2326, average loss: 1.4749
[10/30 00:08:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[10/30 00:08:02][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.05
[10/30 00:09:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3443,	0.6302 s / batch. (data: 8.04e-04). ETA=18:57:24, max mem: 15.9 GB 
[10/30 00:10:11][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6004,	0.6464 s / batch. (data: 8.11e-04). ETA=19:25:27, max mem: 15.9 GB 
[10/30 00:11:14][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2009,	0.6531 s / batch. (data: 7.25e-04). ETA=19:36:33, max mem: 15.9 GB 
[10/30 00:12:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6267,	0.6335 s / batch. (data: 7.84e-04). ETA=19:00:14, max mem: 15.9 GB 
[10/30 00:13:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3244,	0.6291 s / batch. (data: 8.98e-04). ETA=18:51:17, max mem: 15.9 GB 
[10/30 00:14:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7322,	0.6189 s / batch. (data: 2.91e-04). ETA=18:31:45, max mem: 15.9 GB 
[10/30 00:15:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.5857,	0.6192 s / batch. (data: 3.07e-04). ETA=18:31:20, max mem: 15.9 GB 
[10/30 00:16:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8584,	0.6192 s / batch. (data: 3.02e-04). ETA=18:30:22, max mem: 15.9 GB 
[10/30 00:17:34][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.3534,	0.6309 s / batch. (data: 2.90e-04). ETA=18:50:13, max mem: 15.9 GB 
[10/30 00:18:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6734,	0.6347 s / batch. (data: 8.15e-04). ETA=18:56:00, max mem: 15.9 GB 
[10/30 00:19:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6391,	0.6192 s / batch. (data: 1.41e-04). ETA=18:27:11, max mem: 15.9 GB 
[10/30 00:19:44][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.05e-03, avg batch time: 0.6350, average train loss: 0.9029
[10/30 00:20:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.951, 0.2397 s / batch. (data: 2.96e-05)max mem: 15.94594 GB 
[10/30 00:20:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2338, average loss: 0.9963
[10/30 00:20:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.31	
[10/30 00:20:44][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.075
[10/30 00:21:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5269,	0.6469 s / batch. (data: 8.13e-04). ETA=19:15:37, max mem: 15.9 GB 
[10/30 00:22:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.0856,	0.6376 s / batch. (data: 1.35e-02). ETA=18:57:55, max mem: 15.9 GB 
[10/30 00:23:56][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.1138,	0.6327 s / batch. (data: 8.02e-04). ETA=18:48:10, max mem: 15.9 GB 
[10/30 00:25:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9071,	0.6183 s / batch. (data: 7.81e-04). ETA=18:21:22, max mem: 15.9 GB 
[10/30 00:26:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.7991,	0.6331 s / batch. (data: 8.13e-04). ETA=18:46:42, max mem: 15.9 GB 
[10/30 00:27:06][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1303,	0.6470 s / batch. (data: 7.99e-04). ETA=19:10:26, max mem: 15.9 GB 
[10/30 00:28:09][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.8217,	0.6182 s / batch. (data: 3.03e-04). ETA=18:18:04, max mem: 15.9 GB 
[10/30 00:29:12][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5423,	0.6342 s / batch. (data: 3.46e-04). ETA=18:45:34, max mem: 15.9 GB 
[10/30 00:30:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8199,	0.6338 s / batch. (data: 7.97e-04). ETA=18:43:44, max mem: 15.9 GB 
[10/30 00:31:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.1389,	0.6521 s / batch. (data: 1.69e-02). ETA=19:15:01, max mem: 15.9 GB 
[10/30 00:32:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.8154,	0.6174 s / batch. (data: 1.56e-04). ETA=18:12:34, max mem: 15.9 GB 
[10/30 00:32:26][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.47e-03, avg batch time: 0.6344, average train loss: 0.9413
[10/30 00:33:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.703, 0.2243 s / batch. (data: 3.15e-05)max mem: 15.94594 GB 
[10/30 00:33:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2315, average loss: 0.6864
[10/30 00:33:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 55.77	
[10/30 00:33:27][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.1
[10/30 00:34:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.6084,	0.6171 s / batch. (data: 3.17e-04). ETA=18:10:55, max mem: 15.9 GB 
[10/30 00:35:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8231,	0.6400 s / batch. (data: 7.61e-04). ETA=18:50:23, max mem: 15.9 GB 
[10/30 00:36:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9178,	0.6238 s / batch. (data: 3.31e-04). ETA=18:20:41, max mem: 15.9 GB 
[10/30 00:37:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0749,	0.6298 s / batch. (data: 3.35e-04). ETA=18:30:22, max mem: 15.9 GB 
[10/30 00:38:45][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2648,	0.6339 s / batch. (data: 8.13e-04). ETA=18:36:28, max mem: 15.9 GB 
[10/30 00:39:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.9025,	0.6460 s / batch. (data: 8.23e-04). ETA=18:56:45, max mem: 15.9 GB 
[10/30 00:40:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8172,	0.6250 s / batch. (data: 3.26e-04). ETA=18:18:39, max mem: 15.9 GB 
[10/30 00:41:54][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.3836,	0.6176 s / batch. (data: 2.77e-04). ETA=18:04:44, max mem: 15.9 GB 
[10/30 00:42:58][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8703,	0.6401 s / batch. (data: 1.21e-02). ETA=18:43:07, max mem: 15.9 GB 
[10/30 00:44:01][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.3845,	0.6192 s / batch. (data: 3.21e-04). ETA=18:05:21, max mem: 15.9 GB 
[10/30 00:45:04][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8479,	0.6171 s / batch. (data: 1.87e-04). ETA=18:00:41, max mem: 15.9 GB 
[10/30 00:45:08][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.14e-03, avg batch time: 0.6341, average train loss: 1.0455
[10/30 00:45:58][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.606, 0.2252 s / batch. (data: 4.15e-05)max mem: 15.94594 GB 
[10/30 00:46:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.2331, average loss: 1.7110
[10/30 00:46:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.21	
[10/30 00:46:09][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.125
[10/30 00:47:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4673,	0.6322 s / batch. (data: 8.36e-04). ETA=18:26:01, max mem: 15.9 GB 
[10/30 00:48:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0212,	0.6429 s / batch. (data: 8.05e-04). ETA=18:43:45, max mem: 15.9 GB 
[10/30 00:49:21][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0194,	0.6188 s / batch. (data: 3.07e-04). ETA=18:00:30, max mem: 15.9 GB 
[10/30 00:50:24][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2145,	0.6187 s / batch. (data: 3.24e-04). ETA=17:59:22, max mem: 15.9 GB 
[10/30 00:51:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8448,	0.6460 s / batch. (data: 7.61e-04). ETA=18:45:53, max mem: 15.9 GB 
[10/30 00:52:31][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1944,	0.6404 s / batch. (data: 7.99e-04). ETA=18:35:02, max mem: 15.9 GB 
[10/30 00:53:34][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.9358,	0.6724 s / batch. (data: 1.11e-02). ETA=19:29:37, max mem: 15.9 GB 
[10/30 00:54:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.8033,	0.6438 s / batch. (data: 8.11e-04). ETA=18:38:52, max mem: 15.9 GB 
[10/30 00:55:41][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.7638,	0.6320 s / batch. (data: 3.02e-04). ETA=18:17:15, max mem: 15.9 GB 
[10/30 00:56:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7609,	0.6185 s / batch. (data: 3.16e-04). ETA=17:52:49, max mem: 15.9 GB 
[10/30 00:57:47][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0261,	0.6175 s / batch. (data: 1.52e-04). ETA=17:50:03, max mem: 15.9 GB 
[10/30 00:57:51][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.16e-03, avg batch time: 0.6345, average train loss: 1.0021
[10/30 00:58:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.933, 0.2359 s / batch. (data: 2.74e-05)max mem: 15.94594 GB 
[10/30 00:58:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.2313, average loss: 1.0091
[10/30 00:58:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.40	
[10/30 00:58:52][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.15
[10/30 00:59:57][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.1306,	0.6187 s / batch. (data: 3.13e-04). ETA=17:51:00, max mem: 15.9 GB 
[10/30 01:01:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.6051,	0.6331 s / batch. (data: 7.57e-04). ETA=18:14:56, max mem: 15.9 GB 
[10/30 01:02:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1130,	0.6299 s / batch. (data: 7.64e-04). ETA=18:08:16, max mem: 15.9 GB 
[10/30 01:03:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9694,	0.6375 s / batch. (data: 3.43e-04). ETA=18:20:18, max mem: 15.9 GB 
[10/30 01:04:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.1011,	0.6291 s / batch. (data: 2.71e-04). ETA=18:04:50, max mem: 15.9 GB 
[10/30 01:05:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.1447,	0.6372 s / batch. (data: 3.36e-04). ETA=18:17:39, max mem: 15.9 GB 
[10/30 01:06:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.7702,	0.6600 s / batch. (data: 1.20e-02). ETA=18:55:54, max mem: 15.9 GB 
[10/30 01:07:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2288,	0.6304 s / batch. (data: 9.74e-04). ETA=18:03:51, max mem: 15.9 GB 
[10/30 01:08:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8393,	0.6336 s / batch. (data: 7.59e-04). ETA=18:08:23, max mem: 15.9 GB 
[10/30 01:09:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7480,	0.6190 s / batch. (data: 3.03e-04). ETA=17:42:09, max mem: 15.9 GB 
[10/30 01:10:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4787,	0.6181 s / batch. (data: 1.47e-04). ETA=17:39:41, max mem: 15.9 GB 
[10/30 01:10:33][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.05e-03, avg batch time: 0.6343, average train loss: 1.0353
[10/30 01:11:23][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.829, 0.2346 s / batch. (data: 2.96e-05)max mem: 15.94594 GB 
[10/30 01:11:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2320, average loss: 0.7742
[10/30 01:11:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[10/30 01:11:34][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.175
[10/30 01:12:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.1895,	0.6296 s / batch. (data: 3.00e-04). ETA=17:58:16, max mem: 15.9 GB 
[10/30 01:13:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7469,	0.6456 s / batch. (data: 8.32e-04). ETA=18:24:35, max mem: 15.9 GB 
[10/30 01:14:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0415,	0.6461 s / batch. (data: 7.75e-04). ETA=18:24:25, max mem: 15.9 GB 
[10/30 01:15:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3209,	0.6194 s / batch. (data: 2.57e-04). ETA=17:37:42, max mem: 15.9 GB 
[10/30 01:16:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0741,	0.6323 s / batch. (data: 3.29e-04). ETA=17:58:45, max mem: 15.9 GB 
[10/30 01:17:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0955,	0.6245 s / batch. (data: 3.47e-04). ETA=17:44:16, max mem: 15.9 GB 
[10/30 01:18:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9273,	0.6286 s / batch. (data: 7.82e-04). ETA=17:50:14, max mem: 15.9 GB 
[10/30 01:20:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.5733,	0.6376 s / batch. (data: 7.93e-04). ETA=18:04:29, max mem: 15.9 GB 
[10/30 01:21:06][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0253,	0.6402 s / batch. (data: 3.10e-04). ETA=18:07:53, max mem: 15.9 GB 
[10/30 01:22:09][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.2040,	0.6360 s / batch. (data: 8.19e-04). ETA=17:59:37, max mem: 15.9 GB 
[10/30 01:23:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0819,	0.6188 s / batch. (data: 1.49e-04). ETA=17:29:26, max mem: 15.9 GB 
[10/30 01:23:16][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.21e-03, avg batch time: 0.6347, average train loss: 1.1373
[10/30 01:24:06][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.761, 0.2436 s / batch. (data: 2.96e-05)max mem: 15.94594 GB 
[10/30 01:24:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.98e-05, avg batch time: 0.2348, average loss: 0.7150
[10/30 01:24:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.63	
[10/30 01:24:17][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.2
[10/30 01:25:23][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.0230,	0.6184 s / batch. (data: 2.99e-04). ETA=17:27:44, max mem: 15.9 GB 
[10/30 01:26:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7277,	0.6246 s / batch. (data: 4.46e-04). ETA=17:37:07, max mem: 15.9 GB 
[10/30 01:27:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0579,	0.6325 s / batch. (data: 8.49e-04). ETA=17:49:31, max mem: 15.9 GB 
[10/30 01:28:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0123,	0.6318 s / batch. (data: 7.98e-04). ETA=17:47:14, max mem: 15.9 GB 
[10/30 01:29:36][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.9255,	0.6668 s / batch. (data: 1.11e-02). ETA=18:45:18, max mem: 15.9 GB 
[10/30 01:30:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7624,	0.6583 s / batch. (data: 8.38e-04). ETA=18:29:50, max mem: 15.9 GB 
[10/30 01:31:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1181,	0.6200 s / batch. (data: 3.35e-04). ETA=17:24:11, max mem: 15.9 GB 
[10/30 01:32:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2875,	0.6212 s / batch. (data: 2.85e-04). ETA=17:25:13, max mem: 15.9 GB 
[10/30 01:33:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3925,	0.6322 s / batch. (data: 8.08e-04). ETA=17:42:38, max mem: 15.9 GB 
[10/30 01:34:53][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.0218,	0.6321 s / batch. (data: 7.54e-04). ETA=17:41:23, max mem: 15.9 GB 
[10/30 01:35:56][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0420,	0.6183 s / batch. (data: 1.56e-04). ETA=17:17:08, max mem: 15.9 GB 
[10/30 01:36:00][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.85e-03, avg batch time: 0.6354, average train loss: 1.0006
[10/30 01:36:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.827, 0.2248 s / batch. (data: 4.84e-05)max mem: 15.94594 GB 
[10/30 01:37:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.98e-05, avg batch time: 0.2327, average loss: 0.8450
[10/30 01:37:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.95	
[10/30 01:37:01][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.225
[10/30 01:38:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7964,	0.6174 s / batch. (data: 3.19e-04). ETA=17:14:40, max mem: 15.9 GB 
[10/30 01:39:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 3.8895,	0.6188 s / batch. (data: 3.22e-04). ETA=17:15:56, max mem: 15.9 GB 
[10/30 01:40:12][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.6449,	0.6372 s / batch. (data: 9.20e-03). ETA=17:45:37, max mem: 15.9 GB 
[10/30 01:41:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.6271,	0.6247 s / batch. (data: 3.43e-04). ETA=17:23:46, max mem: 15.9 GB 
[10/30 01:42:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9588,	0.6323 s / batch. (data: 3.17e-04). ETA=17:35:25, max mem: 15.9 GB 
[10/30 01:43:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.2820,	0.6317 s / batch. (data: 8.20e-04). ETA=17:33:18, max mem: 15.9 GB 
[10/30 01:44:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5062,	0.6194 s / batch. (data: 3.13e-04). ETA=17:11:44, max mem: 15.9 GB 
[10/30 01:45:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8259,	0.6312 s / batch. (data: 7.98e-04). ETA=17:30:26, max mem: 15.9 GB 
[10/30 01:46:32][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.3868,	0.6271 s / batch. (data: 3.25e-04). ETA=17:22:31, max mem: 15.9 GB 
[10/30 01:47:35][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0593,	0.6402 s / batch. (data: 8.26e-04). ETA=17:43:18, max mem: 15.9 GB 
[10/30 01:48:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.5972,	0.6172 s / batch. (data: 1.61e-04). ETA=17:03:59, max mem: 15.9 GB 
[10/30 01:48:42][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.12e-03, avg batch time: 0.6343, average train loss: 1.2090
[10/30 01:49:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.729, 0.2599 s / batch. (data: 3.89e-05)max mem: 15.94594 GB 
[10/30 01:49:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2328, average loss: 0.7572
[10/30 01:49:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.61	
[10/30 01:49:43][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.25
[10/30 01:50:48][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 4.4278,	0.6185 s / batch. (data: 3.37e-04). ETA=17:05:04, max mem: 15.9 GB 
[10/30 01:51:52][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7302,	0.6292 s / batch. (data: 3.15e-04). ETA=17:21:42, max mem: 15.9 GB 
[10/30 01:52:55][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7509,	0.6379 s / batch. (data: 8.08e-04). ETA=17:35:05, max mem: 15.9 GB 
[10/30 01:53:59][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7802,	0.6334 s / batch. (data: 8.07e-04). ETA=17:26:35, max mem: 15.9 GB 
[10/30 01:55:02][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2296,	0.6189 s / batch. (data: 2.80e-04). ETA=17:01:31, max mem: 15.9 GB 
[10/30 01:56:05][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0206,	0.6486 s / batch. (data: 7.99e-04). ETA=17:49:34, max mem: 15.9 GB 
[10/30 01:57:08][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.2148,	0.6253 s / batch. (data: 6.34e-03). ETA=17:10:09, max mem: 15.9 GB 
[10/30 01:58:12][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.8310,	0.6440 s / batch. (data: 9.59e-04). ETA=17:39:43, max mem: 15.9 GB 
[10/30 01:59:15][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.2426,	0.6338 s / batch. (data: 8.15e-04). ETA=17:22:02, max mem: 15.9 GB 
[10/30 02:00:18][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6859,	0.6197 s / batch. (data: 3.34e-04). ETA=16:57:42, max mem: 15.9 GB 
[10/30 02:01:21][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7974,	0.6194 s / batch. (data: 1.94e-04). ETA=16:56:10, max mem: 15.9 GB 
[10/30 02:01:25][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.22e-03, avg batch time: 0.6348, average train loss: 1.0856
[10/30 02:02:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.675, 0.2247 s / batch. (data: 4.79e-05)max mem: 15.94594 GB 
[10/30 02:02:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2317, average loss: 0.6717
[10/30 02:02:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 59.61	
[10/30 02:02:26][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/30 02:03:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4592,	0.6447 s / batch. (data: 1.13e-03). ETA=17:36:40, max mem: 15.9 GB 
[10/30 02:04:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6455,	0.6336 s / batch. (data: 8.25e-04). ETA=17:17:24, max mem: 15.9 GB 
[10/30 02:05:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.0134,	0.6192 s / batch. (data: 2.99e-04). ETA=16:52:42, max mem: 15.9 GB 
[10/30 02:06:42][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2455,	0.6307 s / batch. (data: 3.45e-04). ETA=17:10:31, max mem: 15.9 GB 
[10/30 02:07:45][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.0988,	0.6416 s / batch. (data: 7.67e-04). ETA=17:27:10, max mem: 15.9 GB 
[10/30 02:08:48][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9119,	0.6328 s / batch. (data: 8.13e-04). ETA=17:11:51, max mem: 15.9 GB 
[10/30 02:09:51][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6741,	0.6457 s / batch. (data: 7.55e-04). ETA=17:31:43, max mem: 15.9 GB 
[10/30 02:10:54][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6527,	0.6188 s / batch. (data: 3.04e-04). ETA=16:46:52, max mem: 15.9 GB 
[10/30 02:11:58][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9362,	0.6443 s / batch. (data: 8.18e-04). ETA=17:27:17, max mem: 15.9 GB 
[10/30 02:13:01][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8417,	0.6318 s / batch. (data: 8.22e-04). ETA=17:05:57, max mem: 15.9 GB 
[10/30 02:14:04][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.3923,	0.6175 s / batch. (data: 1.55e-04). ETA=16:41:42, max mem: 15.9 GB 
[10/30 02:14:08][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.03e-03, avg batch time: 0.6348, average train loss: 1.0595
[10/30 02:14:57][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.004, 0.2257 s / batch. (data: 3.65e-05)max mem: 15.94594 GB 
[10/30 02:15:08][INFO] visual_prompt:  316: Inference (val):avg data time: 4.16e-05, avg batch time: 0.2328, average loss: 1.1090
[10/30 02:15:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.85	
[10/30 02:15:08][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/30 02:16:14][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.4379,	0.6189 s / batch. (data: 3.38e-04). ETA=16:42:50, max mem: 15.9 GB 
[10/30 02:17:17][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.3422,	0.6313 s / batch. (data: 7.54e-04). ETA=17:01:56, max mem: 15.9 GB 
[10/30 02:18:21][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1531,	0.6300 s / batch. (data: 8.13e-04). ETA=16:58:47, max mem: 15.9 GB 
[10/30 02:19:24][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.7649,	0.6287 s / batch. (data: 3.21e-04). ETA=16:55:34, max mem: 15.9 GB 
[10/30 02:20:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6568,	0.6301 s / batch. (data: 7.52e-04). ETA=16:56:53, max mem: 15.9 GB 
[10/30 02:21:31][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.1279,	0.6210 s / batch. (data: 3.24e-04). ETA=16:41:06, max mem: 15.9 GB 
[10/30 02:22:34][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3514,	0.6370 s / batch. (data: 5.40e-03). ETA=17:05:53, max mem: 15.9 GB 
[10/30 02:23:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.0673,	0.6236 s / batch. (data: 3.78e-04). ETA=16:43:10, max mem: 15.9 GB 
[10/30 02:24:41][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.6892,	0.6450 s / batch. (data: 8.09e-04). ETA=17:16:32, max mem: 15.9 GB 
[10/30 02:25:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0181,	0.6318 s / batch. (data: 8.04e-04). ETA=16:54:18, max mem: 15.9 GB 
[10/30 02:26:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.8314,	0.6188 s / batch. (data: 1.98e-04). ETA=16:32:25, max mem: 15.9 GB 
[10/30 02:26:51][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.39e-03, avg batch time: 0.6355, average train loss: 1.0470
[10/30 02:27:41][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.859, 0.2251 s / batch. (data: 2.67e-05)max mem: 15.94594 GB 
[10/30 02:27:52][INFO] visual_prompt:  316: Inference (val):avg data time: 1.02e-04, avg batch time: 0.2326, average loss: 0.9667
[10/30 02:27:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.26	
[10/30 02:27:52][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/30 02:28:58][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2061,	0.6362 s / batch. (data: 7.91e-04). ETA=16:59:12, max mem: 15.9 GB 
[10/30 02:30:01][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.3894,	0.6185 s / batch. (data: 3.37e-04). ETA=16:29:48, max mem: 15.9 GB 
[10/30 02:31:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9230,	0.6183 s / batch. (data: 3.25e-04). ETA=16:28:25, max mem: 15.9 GB 
[10/30 02:32:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.1379,	0.6336 s / batch. (data: 3.72e-04). ETA=16:51:49, max mem: 15.9 GB 
[10/30 02:33:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9897,	0.6177 s / batch. (data: 3.16e-04). ETA=16:25:27, max mem: 15.9 GB 
[10/30 02:34:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9874,	0.6248 s / batch. (data: 3.14e-04). ETA=16:35:46, max mem: 15.9 GB 
[10/30 02:35:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9307,	0.6360 s / batch. (data: 3.20e-04). ETA=16:52:30, max mem: 15.9 GB 
[10/30 02:36:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2633,	0.6336 s / batch. (data: 3.18e-04). ETA=16:47:37, max mem: 15.9 GB 
[10/30 02:37:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.6709,	0.6194 s / batch. (data: 3.16e-04). ETA=16:24:01, max mem: 15.9 GB 
[10/30 02:38:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1365,	0.6332 s / batch. (data: 7.90e-04). ETA=16:44:56, max mem: 15.9 GB 
[10/30 02:39:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8349,	0.6175 s / batch. (data: 1.61e-04). ETA=16:18:56, max mem: 15.9 GB 
[10/30 02:39:34][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 5.11e-03, avg batch time: 0.6346, average train loss: 0.9914
[10/30 02:40:24][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.683, 0.2356 s / batch. (data: 2.88e-05)max mem: 15.94594 GB 
[10/30 02:40:35][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2323, average loss: 0.6840
[10/30 02:40:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.52	
[10/30 02:40:35][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/30 02:41:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.2907,	0.6176 s / batch. (data: 3.36e-04). ETA=16:18:01, max mem: 15.9 GB 
[10/30 02:42:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2505,	0.6182 s / batch. (data: 2.76e-04). ETA=16:18:01, max mem: 15.9 GB 
[10/30 02:43:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.2450,	0.6193 s / batch. (data: 3.12e-04). ETA=16:18:39, max mem: 15.9 GB 
[10/30 02:44:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 4.0939,	0.6324 s / batch. (data: 3.26e-04). ETA=16:38:22, max mem: 15.9 GB 
[10/30 02:45:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7944,	0.6369 s / batch. (data: 3.11e-04). ETA=16:44:22, max mem: 15.9 GB 
[10/30 02:46:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9090,	0.6194 s / batch. (data: 7.67e-04). ETA=16:15:44, max mem: 15.9 GB 
[10/30 02:47:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1549,	0.6415 s / batch. (data: 7.34e-04). ETA=16:49:26, max mem: 15.9 GB 
[10/30 02:49:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6298,	0.6210 s / batch. (data: 3.29e-04). ETA=16:16:13, max mem: 15.9 GB 
[10/30 02:50:06][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9212,	0.6385 s / batch. (data: 1.47e-02). ETA=16:42:35, max mem: 15.9 GB 
[10/30 02:51:09][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8899,	0.6308 s / batch. (data: 2.72e-04). ETA=16:29:23, max mem: 15.9 GB 
[10/30 02:52:12][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.9882,	0.6177 s / batch. (data: 1.42e-04). ETA=16:07:51, max mem: 15.9 GB 
[10/30 02:52:16][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 3.66e-03, avg batch time: 0.6341, average train loss: 1.1086
[10/30 02:53:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.396, 0.2252 s / batch. (data: 3.05e-05)max mem: 15.94594 GB 
[10/30 02:53:17][INFO] visual_prompt:  316: Inference (val):avg data time: 9.68e-05, avg batch time: 0.2322, average loss: 1.5470
[10/30 02:53:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.54	
[10/30 02:53:17][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[10/30 02:54:22][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4090,	0.6380 s / batch. (data: 8.31e-04). ETA=16:38:33, max mem: 15.9 GB 
[10/30 02:55:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2700,	0.6197 s / batch. (data: 3.15e-04). ETA=16:08:57, max mem: 15.9 GB 
[10/30 02:56:29][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7057,	0.6200 s / batch. (data: 3.56e-04). ETA=16:08:15, max mem: 15.9 GB 
[10/30 02:57:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7800,	0.6306 s / batch. (data: 8.15e-04). ETA=16:23:50, max mem: 15.9 GB 
[10/30 02:58:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9253,	0.6351 s / batch. (data: 3.45e-04). ETA=16:29:47, max mem: 15.9 GB 
[10/30 02:59:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9264,	0.6193 s / batch. (data: 3.22e-04). ETA=16:04:05, max mem: 15.9 GB 
[10/30 03:00:42][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.3162,	0.6197 s / batch. (data: 3.29e-04). ETA=16:03:45, max mem: 15.9 GB 
[10/30 03:01:45][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.2376,	0.6478 s / batch. (data: 1.53e-02). ETA=16:46:18, max mem: 15.9 GB 
[10/30 03:02:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.5789,	0.6344 s / batch. (data: 8.25e-04). ETA=16:24:29, max mem: 15.9 GB 
[10/30 03:03:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7900,	0.6200 s / batch. (data: 3.21e-04). ETA=16:01:02, max mem: 15.9 GB 
[10/30 03:04:55][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0719,	0.6177 s / batch. (data: 2.95e-04). ETA=15:56:31, max mem: 15.9 GB 
[10/30 03:04:59][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.94e-03, avg batch time: 0.6348, average train loss: 1.0027
[10/30 03:05:49][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.741, 0.2277 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/30 03:06:00][INFO] visual_prompt:  316: Inference (val):avg data time: 1.31e-04, avg batch time: 0.2325, average loss: 0.7648
[10/30 03:06:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.62	
[10/30 03:06:00][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[10/30 03:07:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8502,	0.6482 s / batch. (data: 1.00e-02). ETA=16:42:35, max mem: 15.9 GB 
[10/30 03:08:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7281,	0.6186 s / batch. (data: 3.00e-04). ETA=15:55:44, max mem: 15.9 GB 
[10/30 03:09:12][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.2534,	0.6181 s / batch. (data: 3.14e-04). ETA=15:53:57, max mem: 15.9 GB 
[10/30 03:10:15][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 6.0134,	0.6319 s / batch. (data: 8.03e-04). ETA=16:14:13, max mem: 15.9 GB 
[10/30 03:11:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0433,	0.6310 s / batch. (data: 4.81e-04). ETA=16:11:42, max mem: 15.9 GB 
[10/30 03:12:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7600,	0.6353 s / batch. (data: 7.69e-04). ETA=16:17:16, max mem: 15.9 GB 
[10/30 03:13:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1790,	0.6329 s / batch. (data: 8.02e-04). ETA=16:12:32, max mem: 15.9 GB 
[10/30 03:14:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2343,	0.6488 s / batch. (data: 1.41e-02). ETA=16:35:54, max mem: 15.9 GB 
[10/30 03:15:32][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.8057,	0.6600 s / batch. (data: 2.80e-02). ETA=16:51:58, max mem: 15.9 GB 
[10/30 03:16:35][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1437,	0.6304 s / batch. (data: 3.60e-04). ETA=16:05:39, max mem: 15.9 GB 
[10/30 03:17:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0503,	0.6181 s / batch. (data: 1.32e-04). ETA=15:45:40, max mem: 15.9 GB 
[10/30 03:17:43][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.41e-03, avg batch time: 0.6351, average train loss: 1.0966
[10/30 03:18:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.919, 0.2252 s / batch. (data: 3.05e-05)max mem: 15.94594 GB 
[10/30 03:18:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.2326, average loss: 1.0258
[10/30 03:18:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.22	
[10/30 03:18:43][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[10/30 03:19:48][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2513,	0.6181 s / batch. (data: 3.31e-04). ETA=15:44:34, max mem: 15.9 GB 
[10/30 03:20:51][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.3973,	0.6406 s / batch. (data: 8.22e-04). ETA=16:17:56, max mem: 15.9 GB 
[10/30 03:21:55][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 5.2892,	0.6174 s / batch. (data: 2.77e-04). ETA=15:41:35, max mem: 15.9 GB 
[10/30 03:22:58][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8150,	0.6240 s / batch. (data: 4.28e-04). ETA=15:50:36, max mem: 15.9 GB 
[10/30 03:24:01][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0108,	0.6352 s / batch. (data: 3.18e-04). ETA=16:06:30, max mem: 15.9 GB 
[10/30 03:25:05][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2571,	0.6368 s / batch. (data: 1.24e-03). ETA=16:07:50, max mem: 15.9 GB 
[10/30 03:26:08][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3797,	0.6332 s / batch. (data: 5.44e-03). ETA=16:01:25, max mem: 15.9 GB 
[10/30 03:27:11][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5912,	0.6185 s / batch. (data: 3.34e-04). ETA=15:38:00, max mem: 15.9 GB 
[10/30 03:28:14][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.4390,	0.6313 s / batch. (data: 4.54e-04). ETA=15:56:27, max mem: 15.9 GB 
[10/30 03:29:17][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7138,	0.6183 s / batch. (data: 3.32e-04). ETA=15:35:36, max mem: 15.9 GB 
[10/30 03:30:21][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0913,	0.6189 s / batch. (data: 1.99e-04). ETA=15:35:28, max mem: 15.9 GB 
[10/30 03:30:24][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.42e-03, avg batch time: 0.6341, average train loss: 1.1093
[10/30 03:31:15][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.674, 0.2317 s / batch. (data: 2.91e-05)max mem: 15.94594 GB 
[10/30 03:31:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2326, average loss: 0.7012
[10/30 03:31:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.70	
[10/30 03:31:25][INFO] visual_prompt:   42: Stopping early.
