[10/23 21:33:46][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/23 21:33:50][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/23 21:33:50][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/23 21:33:50][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/23 21:33:50][INFO] visual_prompt:  108: Training with config:
[10/23 21:33:50][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr50.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/23 21:33:50][INFO] visual_prompt:   55: Loading training data...
[10/23 21:33:50][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/23 21:33:50][INFO] visual_prompt:   57: Loading validation data...
[10/23 21:33:50][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/23 21:33:50][INFO] visual_prompt:   38: Constructing models...
[10/23 21:34:08][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/23 21:34:08][INFO] visual_prompt:   54: tuned percent:0.522
[10/23 21:34:08][INFO] visual_prompt:   40: Device used for model: 0
[10/23 21:34:08][INFO] visual_prompt:   40: Setting up Evaluator...
[10/23 21:34:08][INFO] visual_prompt:   42: Setting up Trainer...
[10/23 21:34:08][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/23 21:34:08][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/23 21:35:17][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6543 s / batch. (data: 8.27e-04). ETA=20:05:05, max mem: 15.9 GB 
[10/23 21:36:21][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6328 s / batch. (data: 4.27e-04). ETA=19:24:20, max mem: 15.9 GB 
[10/23 21:37:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6339 s / batch. (data: 7.39e-04). ETA=19:25:16, max mem: 15.9 GB 
[10/23 21:38:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6218 s / batch. (data: 8.06e-04). ETA=19:02:00, max mem: 15.9 GB 
[10/23 21:39:32][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6281 s / batch. (data: 3.03e-04). ETA=19:12:30, max mem: 15.9 GB 
[10/23 21:40:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6194 s / batch. (data: 3.01e-04). ETA=18:55:30, max mem: 15.9 GB 
[10/23 21:41:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6297 s / batch. (data: 7.91e-04). ETA=19:13:26, max mem: 15.9 GB 
[10/23 21:42:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6317 s / batch. (data: 8.40e-04). ETA=19:15:59, max mem: 15.9 GB 
[10/23 21:43:45][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6316 s / batch. (data: 7.39e-04). ETA=19:14:49, max mem: 15.9 GB 
[10/23 21:44:48][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6201 s / batch. (data: 3.04e-04). ETA=18:52:39, max mem: 15.9 GB 
[10/23 21:45:51][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6189 s / batch. (data: 3.35e-04). ETA=18:49:33, max mem: 15.9 GB 
[10/23 21:45:55][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 6.87e-03, avg batch time: 0.6390, average train loss: 1.4028
[10/23 21:46:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2260 s / batch. (data: 4.15e-05)max mem: 15.88805 GB 
[10/23 21:46:57][INFO] visual_prompt:  316: Inference (val):avg data time: 9.77e-05, avg batch time: 0.2333, average loss: 1.3505
[10/23 21:46:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/23 21:46:57][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 5.0
[10/23 21:48:01][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 27.4343,	0.6360 s / batch. (data: 8.01e-04). ETA=19:19:34, max mem: 15.9 GB 
[10/23 21:49:04][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 53.8110,	0.6141 s / batch. (data: 3.31e-04). ETA=18:38:32, max mem: 15.9 GB 
[10/23 21:50:07][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 21.1374,	0.6430 s / batch. (data: 7.75e-04). ETA=19:30:07, max mem: 15.9 GB 
[10/23 21:51:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6338 s / batch. (data: 8.96e-04). ETA=19:12:25, max mem: 15.9 GB 
[10/23 21:52:14][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 21.3293,	0.6303 s / batch. (data: 3.17e-04). ETA=19:05:04, max mem: 15.9 GB 
[10/23 21:53:17][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 14.1258,	0.6400 s / batch. (data: 3.25e-04). ETA=19:21:28, max mem: 15.9 GB 
[10/23 21:54:20][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6095 s / batch. (data: 7.43e-04). ETA=18:25:09, max mem: 15.9 GB 
[10/23 21:55:23][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 30.2459,	0.6480 s / batch. (data: 8.03e-04). ETA=19:33:54, max mem: 15.9 GB 
[10/23 21:56:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 5.2480,	0.6561 s / batch. (data: 8.09e-03). ETA=19:47:28, max mem: 15.9 GB 
[10/23 21:57:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6092 s / batch. (data: 3.71e-04). ETA=18:21:31, max mem: 15.9 GB 
[10/23 21:58:33][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6190 s / batch. (data: 1.47e-04). ETA=18:38:14, max mem: 15.9 GB 
[10/23 21:58:37][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.56e-03, avg batch time: 0.6331, average train loss: 23.4313
[10/23 21:59:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.812, 0.2421 s / batch. (data: 3.10e-05)max mem: 15.88805 GB 
[10/23 21:59:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2312, average loss: 4.3982
[10/23 21:59:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.32	
[10/23 21:59:38][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 10.0
[10/23 22:00:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6219 s / batch. (data: 8.78e-04). ETA=18:42:24, max mem: 15.9 GB 
[10/23 22:01:47][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 54.1226,	0.6189 s / batch. (data: 3.19e-04). ETA=18:35:56, max mem: 15.9 GB 
[10/23 22:02:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6598 s / batch. (data: 3.27e-02). ETA=19:48:37, max mem: 15.9 GB 
[10/23 22:03:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 42.3653,	0.6200 s / batch. (data: 2.83e-04). ETA=18:35:53, max mem: 15.9 GB 
[10/23 22:04:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 135.7412,	0.6187 s / batch. (data: 3.87e-04). ETA=18:32:33, max mem: 15.9 GB 
[10/23 22:05:59][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 23.2834,	0.6339 s / batch. (data: 1.24e-03). ETA=18:58:47, max mem: 15.9 GB 
[10/23 22:07:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6386 s / batch. (data: 8.49e-04). ETA=19:06:04, max mem: 15.9 GB 
[10/23 22:08:09][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6482 s / batch. (data: 5.91e-03). ETA=19:22:19, max mem: 15.9 GB 
[10/23 22:09:12][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6344 s / batch. (data: 3.19e-04). ETA=18:56:26, max mem: 15.9 GB 
[10/23 22:10:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 57.6222,	0.6454 s / batch. (data: 5.99e-03). ETA=19:15:11, max mem: 15.9 GB 
[10/23 22:11:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 78.9610,	0.6129 s / batch. (data: 2.70e-04). ETA=18:15:52, max mem: 15.9 GB 
[10/23 22:11:22][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 8.06e-03, avg batch time: 0.6364, average train loss: 44.2857
[10/23 22:12:12][INFO] visual_prompt:  303: 	Test 100/123. loss: 40.254, 0.2326 s / batch. (data: 3.74e-05)max mem: 15.88805 GB 
[10/23 22:12:23][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2311, average loss: 44.3250
[10/23 22:12:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.30	
[10/23 22:12:23][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 15.0
[10/23 22:13:29][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6115 s / batch. (data: 3.01e-04). ETA=18:12:23, max mem: 15.9 GB 
[10/23 22:14:32][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 219.8725,	0.6479 s / batch. (data: 1.07e-02). ETA=19:16:21, max mem: 15.9 GB 
[10/23 22:15:35][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 15.0034,	0.6329 s / batch. (data: 7.65e-04). ETA=18:48:24, max mem: 15.9 GB 
[10/23 22:16:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 97.0201,	0.6320 s / batch. (data: 3.63e-04). ETA=18:45:50, max mem: 15.9 GB 
[10/23 22:17:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6421 s / batch. (data: 1.41e-02). ETA=19:02:43, max mem: 15.9 GB 
[10/23 22:18:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.5750,	0.6356 s / batch. (data: 7.50e-04). ETA=18:50:07, max mem: 15.9 GB 
[10/23 22:19:47][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6097 s / batch. (data: 7.84e-04). ETA=18:03:06, max mem: 15.9 GB 
[10/23 22:20:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 12.9150,	0.6185 s / batch. (data: 3.84e-04). ETA=18:17:39, max mem: 15.9 GB 
[10/23 22:21:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6373 s / batch. (data: 7.32e-04). ETA=18:49:56, max mem: 15.9 GB 
[10/23 22:22:55][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 12.1979,	0.6445 s / batch. (data: 1.06e-02). ETA=19:01:35, max mem: 15.9 GB 
[10/23 22:23:59][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 45.2297,	0.6123 s / batch. (data: 2.04e-04). ETA=18:03:30, max mem: 15.9 GB 
[10/23 22:24:02][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.77e-03, avg batch time: 0.6318, average train loss: 65.8904
[10/23 22:24:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 135.665, 0.2356 s / batch. (data: 3.08e-05)max mem: 15.88805 GB 
[10/23 22:25:04][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2325, average loss: 123.0385
[10/23 22:25:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[10/23 22:25:04][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 20.0
[10/23 22:26:09][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 97.2543,	0.6267 s / batch. (data: 8.53e-04). ETA=18:27:59, max mem: 15.9 GB 
[10/23 22:27:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 53.9001,	0.6469 s / batch. (data: 1.49e-02). ETA=19:02:40, max mem: 15.9 GB 
[10/23 22:28:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 25.6364,	0.6451 s / batch. (data: 7.63e-04). ETA=18:58:20, max mem: 15.9 GB 
[10/23 22:29:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 44.2170,	0.6173 s / batch. (data: 3.18e-04). ETA=18:08:17, max mem: 15.9 GB 
[10/23 22:30:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6210 s / batch. (data: 7.73e-04). ETA=18:13:45, max mem: 15.9 GB 
[10/23 22:31:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 47.7470,	0.6338 s / batch. (data: 8.20e-04). ETA=18:35:14, max mem: 15.9 GB 
[10/23 22:32:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 140.3451,	0.6348 s / batch. (data: 1.20e-03). ETA=18:35:53, max mem: 15.9 GB 
[10/23 22:33:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 10.2788,	0.6389 s / batch. (data: 7.53e-04). ETA=18:42:01, max mem: 15.9 GB 
[10/23 22:34:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 340.6313,	0.6297 s / batch. (data: 3.65e-04). ETA=18:24:54, max mem: 15.9 GB 
[10/23 22:35:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6161 s / batch. (data: 3.24e-04). ETA=18:00:02, max mem: 15.9 GB 
[10/23 22:36:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 142.8685,	0.6143 s / batch. (data: 2.43e-04). ETA=17:55:49, max mem: 15.9 GB 
[10/23 22:36:42][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.80e-03, avg batch time: 0.6316, average train loss: 91.4435
[10/23 22:37:33][INFO] visual_prompt:  303: 	Test 100/123. loss: 245.158, 0.2419 s / batch. (data: 3.60e-05)max mem: 15.88805 GB 
[10/23 22:37:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2326, average loss: 220.4447
[10/23 22:37:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.34	
[10/23 22:37:44][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 25.0
[10/23 22:38:49][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 417.2016,	0.6237 s / batch. (data: 3.04e-04). ETA=18:11:10, max mem: 15.9 GB 
[10/23 22:39:52][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 421.2350,	0.6475 s / batch. (data: 7.50e-04). ETA=18:51:46, max mem: 15.9 GB 
[10/23 22:40:55][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6231 s / batch. (data: 3.21e-04). ETA=18:08:03, max mem: 15.9 GB 
[10/23 22:41:58][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 224.2868,	0.6280 s / batch. (data: 3.30e-04). ETA=18:15:29, max mem: 15.9 GB 
[10/23 22:43:01][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 139.6360,	0.6240 s / batch. (data: 3.02e-04). ETA=18:07:32, max mem: 15.9 GB 
[10/23 22:44:04][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 72.8576,	0.6451 s / batch. (data: 7.81e-04). ETA=18:43:13, max mem: 15.9 GB 
[10/23 22:45:07][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 64.9925,	0.6240 s / batch. (data: 3.17e-04). ETA=18:05:25, max mem: 15.9 GB 
[10/23 22:46:10][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 210.1074,	0.6131 s / batch. (data: 3.20e-04). ETA=17:45:25, max mem: 15.9 GB 
[10/23 22:47:13][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 128.3392,	0.6476 s / batch. (data: 5.87e-03). ETA=18:44:25, max mem: 15.9 GB 
[10/23 22:48:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6301 s / batch. (data: 7.96e-04). ETA=18:12:56, max mem: 15.9 GB 
[10/23 22:49:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6077 s / batch. (data: 1.80e-04). ETA=17:33:01, max mem: 15.9 GB 
[10/23 22:49:22][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.22e-03, avg batch time: 0.6312, average train loss: 112.4610
[10/23 22:50:13][INFO] visual_prompt:  303: 	Test 100/123. loss: 287.542, 0.2253 s / batch. (data: 4.32e-05)max mem: 15.88805 GB 
[10/23 22:50:24][INFO] visual_prompt:  316: Inference (val):avg data time: 3.82e-05, avg batch time: 0.2320, average loss: 259.2788
[10/23 22:50:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.31	
[10/23 22:50:24][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 30.0
[10/23 22:51:28][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 98.5208,	0.6193 s / batch. (data: 3.38e-04). ETA=17:52:01, max mem: 15.9 GB 
[10/23 22:52:31][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6139 s / batch. (data: 4.09e-04). ETA=17:41:40, max mem: 15.9 GB 
[10/23 22:53:34][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 270.3148,	0.6197 s / batch. (data: 8.15e-04). ETA=17:50:40, max mem: 15.9 GB 
[10/23 22:54:37][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 100.6968,	0.6176 s / batch. (data: 4.96e-04). ETA=17:46:01, max mem: 15.9 GB 
[10/23 22:55:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 27.3817,	0.6234 s / batch. (data: 3.44e-03). ETA=17:55:00, max mem: 15.9 GB 
[10/23 22:56:43][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 106.8540,	0.6249 s / batch. (data: 3.29e-04). ETA=17:56:34, max mem: 15.9 GB 
[10/23 22:57:46][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 451.0879,	0.6400 s / batch. (data: 4.21e-04). ETA=18:21:24, max mem: 15.9 GB 
[10/23 22:58:49][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6184 s / batch. (data: 2.86e-04). ETA=17:43:12, max mem: 15.9 GB 
[10/23 22:59:52][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 183.2745,	0.6135 s / batch. (data: 7.51e-04). ETA=17:33:51, max mem: 15.9 GB 
[10/23 23:00:55][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 117.1072,	0.6323 s / batch. (data: 3.15e-04). ETA=18:05:05, max mem: 15.9 GB 
[10/23 23:01:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0001,	0.6186 s / batch. (data: 2.19e-04). ETA=17:40:28, max mem: 15.9 GB 
[10/23 23:02:01][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.77e-03, avg batch time: 0.6306, average train loss: 139.2894
[10/23 23:02:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 254.217, 0.2362 s / batch. (data: 3.08e-05)max mem: 15.88805 GB 
[10/23 23:03:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.98e-05, avg batch time: 0.2331, average loss: 250.7735
[10/23 23:03:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.60	
[10/23 23:03:03][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 35.0
[10/23 23:04:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6074 s / batch. (data: 3.39e-04). ETA=17:20:16, max mem: 15.9 GB 
[10/23 23:05:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 125.4227,	0.6280 s / batch. (data: 2.91e-04). ETA=17:54:30, max mem: 15.9 GB 
[10/23 23:06:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6081 s / batch. (data: 2.77e-04). ETA=17:19:20, max mem: 15.9 GB 
[10/23 23:07:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 322.0450,	0.6192 s / batch. (data: 4.03e-04). ETA=17:37:18, max mem: 15.9 GB 
[10/23 23:08:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6094 s / batch. (data: 2.99e-04). ETA=17:19:38, max mem: 15.9 GB 
[10/23 23:09:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6370 s / batch. (data: 2.10e-02). ETA=18:05:34, max mem: 15.9 GB 
[10/23 23:10:25][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 303.9340,	0.6136 s / batch. (data: 8.09e-04). ETA=17:24:47, max mem: 15.9 GB 
[10/23 23:11:28][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6285 s / batch. (data: 2.83e-04). ETA=17:48:59, max mem: 15.9 GB 
[10/23 23:12:30][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6087 s / batch. (data: 3.63e-04). ETA=17:14:25, max mem: 15.9 GB 
[10/23 23:13:33][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6083 s / batch. (data: 3.30e-04). ETA=17:12:35, max mem: 15.9 GB 
[10/23 23:14:36][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 225.6636,	0.6176 s / batch. (data: 1.52e-04). ETA=17:27:24, max mem: 15.9 GB 
[10/23 23:14:40][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.27e-03, avg batch time: 0.6303, average train loss: 148.1846
[10/23 23:15:30][INFO] visual_prompt:  303: 	Test 100/123. loss: 471.579, 0.2262 s / batch. (data: 3.08e-05)max mem: 15.88805 GB 
[10/23 23:15:41][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2334, average loss: 422.7750
[10/23 23:15:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.19	
[10/23 23:15:41][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 40.0
[10/23 23:16:46][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6265 s / batch. (data: 3.30e-04). ETA=17:41:21, max mem: 15.9 GB 
[10/23 23:17:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6741 s / batch. (data: 8.35e-04). ETA=19:00:57, max mem: 15.9 GB 
[10/23 23:18:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 401.5913,	0.6254 s / batch. (data: 7.73e-04). ETA=17:37:28, max mem: 15.9 GB 
[10/23 23:19:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6094 s / batch. (data: 3.57e-04). ETA=17:09:25, max mem: 15.9 GB 
[10/23 23:20:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6462 s / batch. (data: 1.42e-02). ETA=18:10:27, max mem: 15.9 GB 
[10/23 23:22:00][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 91.3479,	0.6228 s / batch. (data: 2.74e-04). ETA=17:30:02, max mem: 15.9 GB 
[10/23 23:23:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 240.4525,	0.6141 s / batch. (data: 2.57e-04). ETA=17:14:16, max mem: 15.9 GB 
[10/23 23:24:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 482.6885,	0.6167 s / batch. (data: 4.95e-04). ETA=17:17:32, max mem: 15.9 GB 
[10/23 23:25:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 240.2178,	0.6400 s / batch. (data: 3.63e-04). ETA=17:55:48, max mem: 15.9 GB 
[10/23 23:26:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 173.3219,	0.6334 s / batch. (data: 3.15e-04). ETA=17:43:38, max mem: 15.9 GB 
[10/23 23:27:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 51.7314,	0.6145 s / batch. (data: 1.87e-04). ETA=17:10:54, max mem: 15.9 GB 
[10/23 23:27:17][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.60e-03, avg batch time: 0.6290, average train loss: 181.2720
[10/23 23:28:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 17.589, 0.2262 s / batch. (data: 3.03e-05)max mem: 15.88805 GB 
[10/23 23:28:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.75e-05, avg batch time: 0.2329, average loss: 24.9190
[10/23 23:28:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 50.13	
[10/23 23:28:18][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 45.0
[10/23 23:29:23][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 27.7607,	0.6225 s / batch. (data: 3.12e-04). ETA=17:23:10, max mem: 15.9 GB 
[10/23 23:30:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 318.3625,	0.6294 s / batch. (data: 1.60e-02). ETA=17:33:39, max mem: 15.9 GB 
[10/23 23:31:29][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 163.0788,	0.6458 s / batch. (data: 1.19e-02). ETA=18:00:00, max mem: 15.9 GB 
[10/23 23:32:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 15.1817,	0.6320 s / batch. (data: 7.98e-04). ETA=17:35:50, max mem: 15.9 GB 
[10/23 23:33:34][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 102.1859,	0.6196 s / batch. (data: 3.15e-04). ETA=17:14:12, max mem: 15.9 GB 
[10/23 23:34:37][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6240 s / batch. (data: 8.62e-04). ETA=17:20:28, max mem: 15.9 GB 
[10/23 23:35:40][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 158.6999,	0.6349 s / batch. (data: 8.38e-04). ETA=17:37:38, max mem: 15.9 GB 
[10/23 23:36:43][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 44.7102,	0.6520 s / batch. (data: 7.94e-04). ETA=18:05:01, max mem: 15.9 GB 
[10/23 23:37:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 214.9229,	0.6328 s / batch. (data: 8.74e-04). ETA=17:31:54, max mem: 15.9 GB 
[10/23 23:38:48][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 593.2907,	0.6353 s / batch. (data: 8.11e-04). ETA=17:35:03, max mem: 15.9 GB 
[10/23 23:39:51][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6080 s / batch. (data: 1.69e-04). ETA=16:48:42, max mem: 15.9 GB 
[10/23 23:39:55][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.69e-03, avg batch time: 0.6298, average train loss: 175.3739
[10/23 23:40:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 131.597, 0.2406 s / batch. (data: 4.94e-05)max mem: 15.88805 GB 
[10/23 23:40:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2332, average loss: 121.9892
[10/23 23:40:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.64	
[10/23 23:40:56][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 50.0
[10/23 23:42:01][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6334 s / batch. (data: 7.69e-04). ETA=17:29:43, max mem: 15.9 GB 
[10/23 23:43:04][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 285.0993,	0.6354 s / batch. (data: 6.02e-03). ETA=17:32:05, max mem: 15.9 GB 
[10/23 23:44:07][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 341.5803,	0.6121 s / batch. (data: 3.14e-04). ETA=16:52:25, max mem: 15.9 GB 
[10/23 23:45:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 968.9158,	0.6186 s / batch. (data: 2.82e-04). ETA=17:02:08, max mem: 15.9 GB 
[10/23 23:46:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 240.5148,	0.6134 s / batch. (data: 3.09e-04). ETA=16:52:35, max mem: 15.9 GB 
[10/23 23:47:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6186 s / batch. (data: 8.35e-04). ETA=17:00:05, max mem: 15.9 GB 
[10/23 23:48:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 768.4421,	0.6218 s / batch. (data: 3.07e-04). ETA=17:04:18, max mem: 15.9 GB 
[10/23 23:49:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6200 s / batch. (data: 7.63e-04). ETA=17:00:22, max mem: 15.9 GB 
[10/23 23:50:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6168 s / batch. (data: 3.24e-04). ETA=16:53:56, max mem: 15.9 GB 
[10/23 23:51:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	1.7141 s / batch. (data: 1.10e+00). ETA=1 day, 22:55:09, max mem: 15.9 GB 
[10/23 23:52:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 8.4036,	0.6190 s / batch. (data: 1.99e-04). ETA=16:55:34, max mem: 15.9 GB 
[10/23 23:52:35][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 6.78e-03, avg batch time: 0.6322, average train loss: 221.0753
[10/23 23:53:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 115.737, 0.2317 s / batch. (data: 2.86e-05)max mem: 15.88805 GB 
[10/23 23:53:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.2333, average loss: 127.0357
[10/23 23:53:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.18	
[10/23 23:53:37][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 49.9847706754774
[10/23 23:54:43][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6203 s / batch. (data: 3.21e-04). ETA=16:56:34, max mem: 15.9 GB 
[10/23 23:55:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 394.2355,	0.6269 s / batch. (data: 8.22e-04). ETA=17:06:21, max mem: 15.9 GB 
[10/23 23:56:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 387.9666,	0.6182 s / batch. (data: 3.17e-04). ETA=16:51:08, max mem: 15.9 GB 
[10/23 23:57:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 696.7471,	0.6301 s / batch. (data: 1.05e-02). ETA=17:09:28, max mem: 15.9 GB 
[10/23 23:58:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6420 s / batch. (data: 1.39e-02). ETA=17:27:52, max mem: 15.9 GB 
[10/23 23:59:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6173 s / batch. (data: 8.33e-04). ETA=16:46:28, max mem: 15.9 GB 
[10/24 00:00:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 180.2896,	0.6201 s / batch. (data: 3.04e-04). ETA=16:50:03, max mem: 15.9 GB 
[10/24 00:02:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 139.4487,	0.6390 s / batch. (data: 5.48e-03). ETA=17:19:50, max mem: 15.9 GB 
[10/24 00:03:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6123 s / batch. (data: 7.56e-04). ETA=16:35:19, max mem: 15.9 GB 
[10/24 00:04:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 9.5004,	0.6308 s / batch. (data: 8.23e-04). ETA=17:04:21, max mem: 15.9 GB 
[10/24 00:05:20][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 15.8632,	0.6166 s / batch. (data: 1.45e-04). ETA=16:40:16, max mem: 15.9 GB 
[10/24 00:05:24][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.48e-02, avg batch time: 0.6397, average train loss: 221.7713
[10/24 00:06:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 84.217, 0.2481 s / batch. (data: 2.29e-05)max mem: 15.88805 GB 
[10/24 00:06:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2317, average loss: 97.5583
[10/24 00:06:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.65	
[10/24 00:06:27][INFO] visual_prompt:   36: Best epoch 12: best metric: -97.558
[10/24 00:06:27][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 49.939101256495604
[10/24 00:07:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 485.4920,	0.6165 s / batch. (data: 3.24e-04). ETA=16:39:01, max mem: 15.9 GB 
[10/24 00:08:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 656.6922,	0.6179 s / batch. (data: 4.76e-04). ETA=16:40:10, max mem: 15.9 GB 
[10/24 00:09:38][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6215 s / batch. (data: 7.91e-04). ETA=16:44:59, max mem: 15.9 GB 
[10/24 00:10:41][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 612.1642,	0.6281 s / batch. (data: 8.10e-04). ETA=16:54:43, max mem: 15.9 GB 
[10/24 00:11:43][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 278.6561,	0.6404 s / batch. (data: 8.25e-04). ETA=17:13:23, max mem: 15.9 GB 
[10/24 00:12:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 219.8076,	0.6253 s / batch. (data: 3.09e-04). ETA=16:48:07, max mem: 15.9 GB 
[10/24 00:13:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6320 s / batch. (data: 3.47e-04). ETA=16:57:48, max mem: 15.9 GB 
[10/24 00:14:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 140.4039,	0.6336 s / batch. (data: 2.97e-04). ETA=16:59:23, max mem: 15.9 GB 
[10/24 00:15:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6087 s / batch. (data: 3.12e-04). ETA=16:18:20, max mem: 15.9 GB 
[10/24 00:16:57][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 15.1508,	0.6451 s / batch. (data: 7.49e-04). ETA=17:15:37, max mem: 15.9 GB 
[10/24 00:18:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 301.2523,	0.6123 s / batch. (data: 1.79e-04). ETA=16:22:00, max mem: 15.9 GB 
[10/24 00:18:04][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 5.17e-03, avg batch time: 0.6304, average train loss: 217.0686
[10/24 00:18:55][INFO] visual_prompt:  303: 	Test 100/123. loss: 216.868, 0.2617 s / batch. (data: 3.50e-05)max mem: 15.88805 GB 
[10/24 00:19:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2314, average loss: 200.6579
[10/24 00:19:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.42	
[10/24 00:19:05][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 49.86304738420683
[10/24 00:20:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6286 s / batch. (data: 8.09e-04). ETA=16:47:00, max mem: 15.9 GB 
[10/24 00:21:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 642.1770,	0.6139 s / batch. (data: 3.85e-04). ETA=16:22:26, max mem: 15.9 GB 
[10/24 00:22:16][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 88.4017,	0.6385 s / batch. (data: 1.05e-02). ETA=17:00:48, max mem: 15.9 GB 
[10/24 00:23:19][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 457.3574,	0.6291 s / batch. (data: 8.28e-04). ETA=16:44:41, max mem: 15.9 GB 
[10/24 00:24:21][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 176.0507,	0.6534 s / batch. (data: 4.22e-02). ETA=17:22:23, max mem: 15.9 GB 
[10/24 00:25:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 395.3578,	0.6296 s / batch. (data: 8.01e-04). ETA=16:43:19, max mem: 15.9 GB 
[10/24 00:26:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 892.3925,	0.6377 s / batch. (data: 5.42e-03). ETA=16:55:10, max mem: 15.9 GB 
[10/24 00:27:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0708,	0.6244 s / batch. (data: 1.20e-02). ETA=16:32:59, max mem: 15.9 GB 
[10/24 00:28:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 8.5061,	0.6154 s / batch. (data: 3.20e-04). ETA=16:17:37, max mem: 15.9 GB 
[10/24 00:29:36][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6298 s / batch. (data: 3.15e-04). ETA=16:39:33, max mem: 15.9 GB 
[10/24 00:30:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 219.2570,	0.6123 s / batch. (data: 1.24e-04). ETA=16:10:45, max mem: 15.9 GB 
[10/24 00:30:42][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.78e-03, avg batch time: 0.6305, average train loss: 195.2581
[10/24 00:31:34][INFO] visual_prompt:  303: 	Test 100/123. loss: 90.185, 0.2357 s / batch. (data: 3.19e-05)max mem: 15.88805 GB 
[10/24 00:31:44][INFO] visual_prompt:  316: Inference (val):avg data time: 1.12e-04, avg batch time: 0.2316, average loss: 98.7433
[10/24 00:31:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.76	
[10/24 00:31:44][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 49.75670171853926
[10/24 00:32:49][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 280.0917,	0.6261 s / batch. (data: 8.17e-04). ETA=16:31:26, max mem: 15.9 GB 
[10/24 00:33:51][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 401.9496,	0.6183 s / batch. (data: 8.70e-04). ETA=16:18:03, max mem: 15.9 GB 
[10/24 00:34:54][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 326.9548,	0.6360 s / batch. (data: 9.22e-04). ETA=16:45:03, max mem: 15.9 GB 
[10/24 00:36:02][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 289.3702,	0.6194 s / batch. (data: 7.84e-04). ETA=16:17:50, max mem: 15.9 GB 
[10/24 00:37:06][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.3078,	0.6240 s / batch. (data: 7.45e-04). ETA=16:24:04, max mem: 15.9 GB 
[10/24 00:38:09][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 24.3263,	0.6309 s / batch. (data: 8.19e-04). ETA=16:33:47, max mem: 15.9 GB 
[10/24 00:39:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 830.0529,	0.6320 s / batch. (data: 3.05e-04). ETA=16:34:30, max mem: 15.9 GB 
[10/24 00:40:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 44.8379,	0.6276 s / batch. (data: 6.84e-04). ETA=16:26:32, max mem: 15.9 GB 
[10/24 00:41:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 867.4948,	0.6171 s / batch. (data: 3.19e-04). ETA=16:09:02, max mem: 15.9 GB 
[10/24 00:42:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 423.0663,	0.6174 s / batch. (data: 2.63e-04). ETA=16:08:24, max mem: 15.9 GB 
[10/24 00:43:31][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 282.6359,	0.6132 s / batch. (data: 1.55e-04). ETA=16:00:49, max mem: 15.9 GB 
[10/24 00:43:35][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.77e-02, avg batch time: 0.6422, average train loss: 225.6892
[10/24 00:44:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 375.358, 0.2277 s / batch. (data: 3.00e-05)max mem: 15.88805 GB 
[10/24 00:44:37][INFO] visual_prompt:  316: Inference (val):avg data time: 4.29e-05, avg batch time: 0.2314, average loss: 334.0556
[10/24 00:44:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.73	
[10/24 00:44:37][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 49.6201938253052
[10/24 00:45:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 336.7470,	0.6181 s / batch. (data: 3.16e-04). ETA=16:07:25, max mem: 15.9 GB 
[10/24 00:46:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 419.9223,	0.6263 s / batch. (data: 7.55e-04). ETA=16:19:12, max mem: 15.9 GB 
[10/24 00:47:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 979.1212,	0.6330 s / batch. (data: 3.23e-04). ETA=16:28:39, max mem: 15.9 GB 
[10/24 00:48:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 250.3063,	0.6192 s / batch. (data: 3.66e-04). ETA=16:06:05, max mem: 15.9 GB 
[10/24 00:49:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 99.3463,	0.6527 s / batch. (data: 8.85e-04). ETA=16:57:18, max mem: 15.9 GB 
[10/24 00:50:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.0155,	0.6193 s / batch. (data: 3.09e-04). ETA=16:04:11, max mem: 15.9 GB 
[10/24 00:51:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 364.4892,	0.6221 s / batch. (data: 3.36e-04). ETA=16:07:25, max mem: 15.9 GB 
[10/24 00:53:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 60.2867,	0.6387 s / batch. (data: 9.05e-04). ETA=16:32:08, max mem: 15.9 GB 
[10/24 00:54:05][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 209.5277,	0.6378 s / batch. (data: 8.73e-04). ETA=16:29:46, max mem: 15.9 GB 
[10/24 00:55:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 870.8479,	0.6465 s / batch. (data: 3.45e-04). ETA=16:42:08, max mem: 15.9 GB 
[10/24 00:56:10][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 195.4234,	0.6182 s / batch. (data: 1.54e-04). ETA=15:57:13, max mem: 15.9 GB 
[10/24 00:56:14][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.12e-03, avg batch time: 0.6299, average train loss: 230.8488
[10/24 00:57:06][INFO] visual_prompt:  303: 	Test 100/123. loss: 120.159, 0.2640 s / batch. (data: 2.57e-05)max mem: 15.88805 GB 
[10/24 00:57:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.97e-05, avg batch time: 0.2334, average loss: 131.3931
[10/24 00:57:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.20	
[10/24 00:57:16][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 49.45369001834514
[10/24 00:58:21][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6188 s / batch. (data: 3.59e-04). ETA=15:57:03, max mem: 15.9 GB 
[10/24 00:59:24][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 743.2273,	0.6266 s / batch. (data: 4.02e-04). ETA=16:08:04, max mem: 15.9 GB 
[10/24 01:00:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6268 s / batch. (data: 5.58e-03). ETA=16:07:20, max mem: 15.9 GB 
[10/24 01:01:29][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 229.7598,	0.6448 s / batch. (data: 2.48e-02). ETA=16:34:06, max mem: 15.9 GB 
[10/24 01:02:32][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6079 s / batch. (data: 3.19e-04). ETA=15:36:12, max mem: 15.9 GB 
[10/24 01:03:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 81.6837,	0.6187 s / batch. (data: 2.70e-04). ETA=15:51:50, max mem: 15.9 GB 
[10/24 01:04:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 136.9234,	0.6194 s / batch. (data: 2.54e-04). ETA=15:51:54, max mem: 15.9 GB 
[10/24 01:05:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 286.7973,	0.6385 s / batch. (data: 7.58e-04). ETA=16:20:12, max mem: 15.9 GB 
[10/24 01:06:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6349 s / batch. (data: 7.68e-04). ETA=16:13:30, max mem: 15.9 GB 
[10/24 01:07:51][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 266.9612,	0.6337 s / batch. (data: 8.39e-04). ETA=16:10:36, max mem: 15.9 GB 
[10/24 01:08:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6071 s / batch. (data: 1.27e-04). ETA=15:28:53, max mem: 15.9 GB 
[10/24 01:08:58][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 9.54e-03, avg batch time: 0.6349, average train loss: 226.6672
[10/24 01:09:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 680.274, 0.2428 s / batch. (data: 4.74e-05)max mem: 15.88805 GB 
[10/24 01:09:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.98e-05, avg batch time: 0.2345, average loss: 588.7328
[10/24 01:09:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.88	
[10/24 01:09:58][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 49.25739315689991
[10/24 01:11:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 369.6573,	0.6616 s / batch. (data: 1.18e-03). ETA=16:51:05, max mem: 15.9 GB 
[10/24 01:12:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 457.4185,	0.6191 s / batch. (data: 3.03e-04). ETA=15:45:07, max mem: 15.9 GB 
[10/24 01:13:09][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6118 s / batch. (data: 3.65e-04). ETA=15:33:01, max mem: 15.9 GB 
[10/24 01:14:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 93.2881,	0.6447 s / batch. (data: 8.89e-04). ETA=16:22:03, max mem: 15.9 GB 
[10/24 01:15:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 257.7671,	0.6303 s / batch. (data: 7.88e-04). ETA=15:59:08, max mem: 15.9 GB 
[10/24 01:16:17][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 114.0009,	0.6262 s / batch. (data: 3.90e-04). ETA=15:51:44, max mem: 15.9 GB 
[10/24 01:17:20][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6430 s / batch. (data: 7.83e-04). ETA=16:16:14, max mem: 15.9 GB 
[10/24 01:18:23][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 15.4966,	0.6334 s / batch. (data: 3.36e-04). ETA=16:00:40, max mem: 15.9 GB 
[10/24 01:19:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 304.3315,	0.6286 s / batch. (data: 7.63e-04). ETA=15:52:20, max mem: 15.9 GB 
[10/24 01:20:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 28.4514,	0.6443 s / batch. (data: 8.46e-04). ETA=16:15:01, max mem: 15.9 GB 
[10/24 01:21:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6079 s / batch. (data: 1.49e-04). ETA=15:18:53, max mem: 15.9 GB 
[10/24 01:21:35][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.49e-03, avg batch time: 0.6301, average train loss: 216.7278
[10/24 01:22:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 565.687, 0.2498 s / batch. (data: 3.70e-05)max mem: 15.88805 GB 
[10/24 01:22:36][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2327, average loss: 619.5292
[10/24 01:22:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[10/24 01:22:36][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 49.03154239845797
[10/24 01:23:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6485 s / batch. (data: 2.85e-02). ETA=16:19:07, max mem: 15.9 GB 
[10/24 01:24:44][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 207.1321,	0.6136 s / batch. (data: 3.11e-04). ETA=15:25:27, max mem: 15.9 GB 
[10/24 01:25:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 42.5812,	0.6275 s / batch. (data: 3.35e-04). ETA=15:45:17, max mem: 15.9 GB 
[10/24 01:26:50][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 542.2055,	0.6123 s / batch. (data: 3.18e-04). ETA=15:21:25, max mem: 15.9 GB 
[10/24 01:27:53][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 385.2707,	0.6438 s / batch. (data: 8.27e-04). ETA=16:07:49, max mem: 15.9 GB 
[10/24 01:28:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 459.8913,	0.6298 s / batch. (data: 7.77e-04). ETA=15:45:40, max mem: 15.9 GB 
[10/24 01:29:58][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 33.5591,	0.6200 s / batch. (data: 3.29e-04). ETA=15:29:58, max mem: 15.9 GB 
[10/24 01:31:01][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6172 s / batch. (data: 7.55e-04). ETA=15:24:41, max mem: 15.9 GB 
[10/24 01:32:04][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6083 s / batch. (data: 3.97e-04). ETA=15:10:19, max mem: 15.9 GB 
[10/24 01:33:07][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 6.6420,	0.6244 s / batch. (data: 2.95e-04). ETA=15:33:26, max mem: 15.9 GB 
[10/24 01:34:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6194 s / batch. (data: 1.83e-04). ETA=15:24:52, max mem: 15.9 GB 
[10/24 01:34:13][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.61e-03, avg batch time: 0.6299, average train loss: 205.1725
[10/24 01:35:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 401.421, 0.2248 s / batch. (data: 4.29e-05)max mem: 15.88805 GB 
[10/24 01:35:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2323, average loss: 361.9676
[10/24 01:35:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.16	
[10/24 01:35:14][INFO] visual_prompt:   42: Stopping early.
