[10/29 13:45:20][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/29 13:45:20][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/29 13:45:20][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/29 13:45:20][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/29 13:45:20][INFO] visual_prompt:  108: Training with config:
[10/29 13:45:20][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/29 13:45:20][INFO] visual_prompt:   55: Loading training data...
[10/29 13:45:20][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/29 13:45:20][INFO] visual_prompt:   57: Loading validation data...
[10/29 13:45:20][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/29 13:45:20][INFO] visual_prompt:   38: Constructing models...
[10/29 13:45:23][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/29 13:45:23][INFO] visual_prompt:   54: tuned percent:0.522
[10/29 13:45:23][INFO] visual_prompt:   40: Device used for model: 0
[10/29 13:45:23][INFO] visual_prompt:   40: Setting up Evaluator...
[10/29 13:45:23][INFO] visual_prompt:   42: Setting up Trainer...
[10/29 13:45:23][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/29 13:45:23][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/29 13:46:28][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6396 s / batch. (data: 5.95e-03). ETA=19:37:56, max mem: 15.9 GB 
[10/29 13:47:32][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6410 s / batch. (data: 7.26e-04). ETA=19:39:21, max mem: 15.9 GB 
[10/29 13:48:35][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6306 s / batch. (data: 8.18e-04). ETA=19:19:12, max mem: 15.9 GB 
[10/29 13:49:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6180 s / batch. (data: 3.37e-04). ETA=18:55:03, max mem: 15.9 GB 
[10/29 13:50:42][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6360 s / batch. (data: 2.83e-04). ETA=19:27:04, max mem: 15.9 GB 
[10/29 13:51:45][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6175 s / batch. (data: 2.76e-04). ETA=18:52:05, max mem: 15.9 GB 
[10/29 13:52:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6182 s / batch. (data: 3.21e-04). ETA=18:52:19, max mem: 15.9 GB 
[10/29 13:53:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6399 s / batch. (data: 8.07e-04). ETA=19:31:01, max mem: 15.9 GB 
[10/29 13:54:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6400 s / batch. (data: 8.63e-04). ETA=19:30:05, max mem: 15.9 GB 
[10/29 13:55:58][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6189 s / batch. (data: 3.65e-04). ETA=18:50:35, max mem: 15.9 GB 
[10/29 13:57:01][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6185 s / batch. (data: 1.64e-04). ETA=18:48:49, max mem: 15.9 GB 
[10/29 13:57:05][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.35e-03, avg batch time: 0.6348, average train loss: 1.4028
[10/29 13:57:55][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2437 s / batch. (data: 3.63e-03)max mem: 15.94594 GB 
[10/29 13:58:06][INFO] visual_prompt:  316: Inference (val):avg data time: 2.86e-04, avg batch time: 0.2309, average loss: 1.3505
[10/29 13:58:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/29 13:58:06][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.025
[10/29 13:59:11][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.7087,	0.6496 s / batch. (data: 2.24e-02). ETA=19:44:21, max mem: 15.9 GB 
[10/29 14:00:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7849,	0.6179 s / batch. (data: 2.95e-04). ETA=18:45:36, max mem: 15.9 GB 
[10/29 14:01:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9198,	0.6356 s / batch. (data: 8.03e-04). ETA=19:16:40, max mem: 15.9 GB 
[10/29 14:02:20][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3144,	0.6338 s / batch. (data: 8.00e-04). ETA=19:12:28, max mem: 15.9 GB 
[10/29 14:03:24][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5913,	0.6240 s / batch. (data: 3.29e-04). ETA=18:53:30, max mem: 15.9 GB 
[10/29 14:04:27][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6461,	0.6372 s / batch. (data: 2.88e-04). ETA=19:16:22, max mem: 15.9 GB 
[10/29 14:05:30][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0472,	0.6589 s / batch. (data: 2.92e-02). ETA=19:54:46, max mem: 15.9 GB 
[10/29 14:06:34][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7124,	0.6563 s / batch. (data: 7.92e-04). ETA=19:48:59, max mem: 15.9 GB 
[10/29 14:07:37][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9179,	0.6435 s / batch. (data: 8.09e-04). ETA=19:24:41, max mem: 15.9 GB 
[10/29 14:08:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.5996,	0.6320 s / batch. (data: 3.06e-04). ETA=19:02:45, max mem: 15.9 GB 
[10/29 14:09:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.4731,	0.6175 s / batch. (data: 1.37e-04). ETA=18:35:29, max mem: 15.9 GB 
[10/29 14:09:47][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.91e-03, avg batch time: 0.6339, average train loss: 0.8610
[10/29 14:10:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.535, 0.2393 s / batch. (data: 3.65e-05)max mem: 15.94594 GB 
[10/29 14:10:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2324, average loss: 1.4059
[10/29 14:10:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[10/29 14:10:47][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.05
[10/29 14:11:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3327,	0.6300 s / batch. (data: 8.59e-04). ETA=18:56:59, max mem: 15.9 GB 
[10/29 14:12:57][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5051,	0.6428 s / batch. (data: 7.61e-04). ETA=19:19:04, max mem: 15.9 GB 
[10/29 14:14:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2238,	0.6631 s / batch. (data: 1.14e-02). ETA=19:54:29, max mem: 15.9 GB 
[10/29 14:15:04][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6736,	0.6507 s / batch. (data: 3.26e-04). ETA=19:31:04, max mem: 15.9 GB 
[10/29 14:16:07][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3079,	0.6188 s / batch. (data: 3.27e-04). ETA=18:32:36, max mem: 15.9 GB 
[10/29 14:17:10][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7421,	0.6306 s / batch. (data: 3.14e-04). ETA=18:52:49, max mem: 15.9 GB 
[10/29 14:18:14][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.5472,	0.6470 s / batch. (data: 7.57e-04). ETA=19:21:16, max mem: 15.9 GB 
[10/29 14:19:17][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2901,	0.6360 s / batch. (data: 7.51e-04). ETA=19:00:24, max mem: 15.9 GB 
[10/29 14:20:20][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.7713,	0.6366 s / batch. (data: 5.43e-03). ETA=19:00:32, max mem: 15.9 GB 
[10/29 14:21:23][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7219,	0.6440 s / batch. (data: 2.99e-04). ETA=19:12:39, max mem: 15.9 GB 
[10/29 14:22:26][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6789,	0.6186 s / batch. (data: 1.64e-04). ETA=18:26:04, max mem: 15.9 GB 
[10/29 14:22:30][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.39e-03, avg batch time: 0.6356, average train loss: 0.8751
[10/29 14:23:20][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.817, 0.2440 s / batch. (data: 4.24e-05)max mem: 15.94594 GB 
[10/29 14:23:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2314, average loss: 0.8650
[10/29 14:23:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.32	
[10/29 14:23:31][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.075
[10/29 14:24:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.9903,	0.6278 s / batch. (data: 7.82e-04). ETA=18:41:29, max mem: 15.9 GB 
[10/29 14:25:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.3786,	0.6320 s / batch. (data: 3.31e-04). ETA=18:47:51, max mem: 15.9 GB 
[10/29 14:26:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0160,	0.6306 s / batch. (data: 8.27e-04). ETA=18:44:18, max mem: 15.9 GB 
[10/29 14:27:46][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9948,	0.6585 s / batch. (data: 5.94e-03). ETA=19:33:04, max mem: 15.9 GB 
[10/29 14:28:49][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.3093,	0.6342 s / batch. (data: 7.84e-04). ETA=18:48:38, max mem: 15.9 GB 
[10/29 14:29:52][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2714,	0.6277 s / batch. (data: 1.06e-02). ETA=18:36:01, max mem: 15.9 GB 
[10/29 14:30:55][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.6417,	0.6173 s / batch. (data: 3.30e-04). ETA=18:16:29, max mem: 15.9 GB 
[10/29 14:31:58][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0653,	0.6184 s / batch. (data: 3.38e-04). ETA=18:17:30, max mem: 15.9 GB 
[10/29 14:33:02][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6972,	0.6344 s / batch. (data: 1.43e-02). ETA=18:44:46, max mem: 15.9 GB 
[10/29 14:34:05][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.1315,	0.6304 s / batch. (data: 5.40e-03). ETA=18:36:43, max mem: 15.9 GB 
[10/29 14:35:08][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.3932,	0.6169 s / batch. (data: 1.78e-04). ETA=18:11:48, max mem: 15.9 GB 
[10/29 14:35:12][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.46e-03, avg batch time: 0.6342, average train loss: 0.8724
[10/29 14:36:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.814, 0.2385 s / batch. (data: 4.46e-05)max mem: 15.94594 GB 
[10/29 14:36:12][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-05, avg batch time: 0.2340, average loss: 0.7634
[10/29 14:36:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.42	
[10/29 14:36:12][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.1
[10/29 14:37:17][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.3510,	0.6178 s / batch. (data: 3.66e-04). ETA=18:12:16, max mem: 15.9 GB 
[10/29 14:38:20][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.4294,	0.6544 s / batch. (data: 4.04e-04). ETA=19:15:53, max mem: 15.9 GB 
[10/29 14:39:23][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8143,	0.6312 s / batch. (data: 8.28e-04). ETA=18:33:45, max mem: 15.9 GB 
[10/29 14:40:27][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0911,	0.6191 s / batch. (data: 8.50e-04). ETA=18:11:27, max mem: 15.9 GB 
[10/29 14:41:30][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0852,	0.6189 s / batch. (data: 3.38e-04). ETA=18:10:06, max mem: 15.9 GB 
[10/29 14:42:33][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.4550,	0.6290 s / batch. (data: 3.37e-04). ETA=18:26:48, max mem: 15.9 GB 
[10/29 14:43:37][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6895,	0.6175 s / batch. (data: 3.29e-04). ETA=18:05:34, max mem: 15.9 GB 
[10/29 14:44:40][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.6468,	0.6183 s / batch. (data: 3.01e-04). ETA=18:05:50, max mem: 15.9 GB 
[10/29 14:45:43][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7395,	0.6403 s / batch. (data: 3.46e-04). ETA=18:43:31, max mem: 15.9 GB 
[10/29 14:46:46][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.3968,	0.6342 s / batch. (data: 8.74e-04). ETA=18:31:39, max mem: 15.9 GB 
[10/29 14:47:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7085,	0.6176 s / batch. (data: 1.91e-04). ETA=18:01:34, max mem: 15.9 GB 
[10/29 14:47:53][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 3.90e-03, avg batch time: 0.6338, average train loss: 0.8603
[10/29 14:48:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.123, 0.2520 s / batch. (data: 3.27e-05)max mem: 15.94594 GB 
[10/29 14:48:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.2319, average loss: 1.2182
[10/29 14:48:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.12	
[10/29 14:48:54][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.125
[10/29 14:49:59][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.9647,	0.6566 s / batch. (data: 2.47e-02). ETA=19:08:40, max mem: 15.9 GB 
[10/29 14:51:02][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0210,	0.6172 s / batch. (data: 3.23e-04). ETA=17:58:42, max mem: 15.9 GB 
[10/29 14:52:05][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0207,	0.6168 s / batch. (data: 3.04e-04). ETA=17:57:06, max mem: 15.9 GB 
[10/29 14:53:08][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3132,	0.6280 s / batch. (data: 4.06e-03). ETA=18:15:32, max mem: 15.9 GB 
[10/29 14:54:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8568,	0.6582 s / batch. (data: 7.00e-04). ETA=19:07:09, max mem: 15.9 GB 
[10/29 14:55:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.3941,	0.6391 s / batch. (data: 5.44e-03). ETA=18:32:48, max mem: 15.9 GB 
[10/29 14:56:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2292,	0.6460 s / batch. (data: 8.02e-04). ETA=18:43:46, max mem: 15.9 GB 
[10/29 14:57:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8697,	0.6178 s / batch. (data: 3.05e-04). ETA=17:53:42, max mem: 15.9 GB 
[10/29 14:58:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7719,	0.6349 s / batch. (data: 7.55e-04). ETA=18:22:15, max mem: 15.9 GB 
[10/29 14:59:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.4985,	0.6325 s / batch. (data: 1.59e-02). ETA=18:17:04, max mem: 15.9 GB 
[10/29 15:00:31][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2234,	0.6181 s / batch. (data: 1.38e-04). ETA=17:51:04, max mem: 15.9 GB 
[10/29 15:00:35][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.04e-03, avg batch time: 0.6338, average train loss: 0.9017
[10/29 15:01:25][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.855, 0.2406 s / batch. (data: 5.27e-05)max mem: 15.94594 GB 
[10/29 15:01:35][INFO] visual_prompt:  316: Inference (val):avg data time: 1.31e-04, avg batch time: 0.2317, average loss: 0.7979
[10/29 15:01:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.71	
[10/29 15:01:35][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.15
[10/29 15:02:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8995,	0.6317 s / batch. (data: 8.33e-04). ETA=18:13:33, max mem: 15.9 GB 
[10/29 15:03:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.6555,	0.6243 s / batch. (data: 3.09e-04). ETA=17:59:37, max mem: 15.9 GB 
[10/29 15:04:46][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1183,	0.6295 s / batch. (data: 3.14e-04). ETA=18:07:38, max mem: 15.9 GB 
[10/29 15:05:49][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9308,	0.6191 s / batch. (data: 4.27e-04). ETA=17:48:31, max mem: 15.9 GB 
[10/29 15:06:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9309,	0.6321 s / batch. (data: 3.20e-04). ETA=18:09:55, max mem: 15.9 GB 
[10/29 15:07:56][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.6555,	0.6274 s / batch. (data: 3.05e-04). ETA=18:00:53, max mem: 15.9 GB 
[10/29 15:08:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.4775,	0.6172 s / batch. (data: 3.10e-04). ETA=17:42:14, max mem: 15.9 GB 
[10/29 15:10:02][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2367,	0.6316 s / batch. (data: 7.73e-04). ETA=18:05:53, max mem: 15.9 GB 
[10/29 15:11:05][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8000,	0.6192 s / batch. (data: 3.79e-04). ETA=17:43:37, max mem: 15.9 GB 
[10/29 15:12:08][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6978,	0.6442 s / batch. (data: 7.92e-04). ETA=18:25:31, max mem: 15.9 GB 
[10/29 15:13:11][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.5075,	0.6157 s / batch. (data: 1.54e-04). ETA=17:35:31, max mem: 15.9 GB 
[10/29 15:13:15][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 3.82e-03, avg batch time: 0.6327, average train loss: 0.9301
[10/29 15:14:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.806, 0.2357 s / batch. (data: 4.98e-05)max mem: 15.94594 GB 
[10/29 15:14:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2319, average loss: 0.7588
[10/29 15:14:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.45	
[10/29 15:14:15][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.175
[10/29 15:15:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.4223,	0.6181 s / batch. (data: 3.35e-04). ETA=17:38:32, max mem: 15.9 GB 
[10/29 15:16:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9842,	0.6161 s / batch. (data: 3.23e-04). ETA=17:34:08, max mem: 15.9 GB 
[10/29 15:17:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0778,	0.6415 s / batch. (data: 1.29e-02). ETA=18:16:34, max mem: 15.9 GB 
[10/29 15:18:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.2885,	0.6171 s / batch. (data: 2.31e-04). ETA=17:33:44, max mem: 15.9 GB 
[10/29 15:19:33][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1990,	0.6223 s / batch. (data: 3.24e-04). ETA=17:41:40, max mem: 15.9 GB 
[10/29 15:20:36][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.3607,	0.6165 s / batch. (data: 3.18e-04). ETA=17:30:39, max mem: 15.9 GB 
[10/29 15:21:39][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8509,	0.6319 s / batch. (data: 7.90e-04). ETA=17:55:53, max mem: 15.9 GB 
[10/29 15:22:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 2.1139,	0.6556 s / batch. (data: 1.10e-02). ETA=18:35:07, max mem: 15.9 GB 
[10/29 15:23:45][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0483,	0.6222 s / batch. (data: 3.25e-04). ETA=17:37:22, max mem: 15.9 GB 
[10/29 15:24:49][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.9620,	0.6314 s / batch. (data: 8.06e-04). ETA=17:51:50, max mem: 15.9 GB 
[10/29 15:25:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2072,	0.6175 s / batch. (data: 1.53e-04). ETA=17:27:18, max mem: 15.9 GB 
[10/29 15:25:56][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.10e-03, avg batch time: 0.6335, average train loss: 1.0034
[10/29 15:26:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.789, 0.2245 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/29 15:26:56][INFO] visual_prompt:  316: Inference (val):avg data time: 4.38e-05, avg batch time: 0.2321, average loss: 0.7463
[10/29 15:26:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.77	
[10/29 15:26:56][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.2
[10/29 15:28:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 6.4866,	0.6318 s / batch. (data: 7.60e-04). ETA=17:50:23, max mem: 15.9 GB 
[10/29 15:29:05][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4271,	0.6404 s / batch. (data: 7.87e-04). ETA=18:03:56, max mem: 15.9 GB 
[10/29 15:30:08][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8990,	0.6184 s / batch. (data: 3.23e-04). ETA=17:25:42, max mem: 15.9 GB 
[10/29 15:31:11][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.4124,	0.6249 s / batch. (data: 3.08e-04). ETA=17:35:39, max mem: 15.9 GB 
[10/29 15:32:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.5584,	0.6411 s / batch. (data: 1.10e-02). ETA=18:01:57, max mem: 15.9 GB 
[10/29 15:33:18][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7079,	0.6337 s / batch. (data: 7.21e-04). ETA=17:48:22, max mem: 15.9 GB 
[10/29 15:34:21][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5564,	0.6340 s / batch. (data: 7.51e-04). ETA=17:47:43, max mem: 15.9 GB 
[10/29 15:35:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8980,	0.6319 s / batch. (data: 7.68e-04). ETA=17:43:12, max mem: 15.9 GB 
[10/29 15:36:28][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3534,	0.6399 s / batch. (data: 1.09e-03). ETA=17:55:38, max mem: 15.9 GB 
[10/29 15:37:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7299,	0.6455 s / batch. (data: 8.24e-04). ETA=18:03:58, max mem: 15.9 GB 
[10/29 15:38:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.9130,	0.6178 s / batch. (data: 1.46e-04). ETA=17:16:20, max mem: 15.9 GB 
[10/29 15:38:39][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.55e-03, avg batch time: 0.6352, average train loss: 1.0422
[10/29 15:39:28][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.778, 0.2256 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/29 15:39:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2329, average loss: 0.8222
[10/29 15:39:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.53	
[10/29 15:39:39][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.225
[10/29 15:40:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.3904,	0.6173 s / batch. (data: 3.01e-04). ETA=17:14:25, max mem: 15.9 GB 
[10/29 15:41:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 4.4684,	0.6225 s / batch. (data: 2.96e-04). ETA=17:22:03, max mem: 15.9 GB 
[10/29 15:42:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.5119,	0.6455 s / batch. (data: 7.77e-04). ETA=17:59:31, max mem: 15.9 GB 
[10/29 15:43:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.5915,	0.6179 s / batch. (data: 3.21e-04). ETA=17:12:19, max mem: 15.9 GB 
[10/29 15:44:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7857,	0.6560 s / batch. (data: 8.08e-04). ETA=18:14:56, max mem: 15.9 GB 
[10/29 15:46:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.6159,	0.6360 s / batch. (data: 3.02e-04). ETA=17:40:28, max mem: 15.9 GB 
[10/29 15:47:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5126,	0.6212 s / batch. (data: 3.16e-04). ETA=17:14:46, max mem: 15.9 GB 
[10/29 15:48:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7090,	0.6520 s / batch. (data: 7.67e-04). ETA=18:04:58, max mem: 15.9 GB 
[10/29 15:49:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7832,	0.6450 s / batch. (data: 2.55e-02). ETA=17:52:18, max mem: 15.9 GB 
[10/29 15:50:14][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.2110,	0.6342 s / batch. (data: 7.97e-04). ETA=17:33:19, max mem: 15.9 GB 
[10/29 15:51:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.5347,	0.6186 s / batch. (data: 1.48e-04). ETA=17:06:18, max mem: 15.9 GB 
[10/29 15:51:21][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.86e-03, avg batch time: 0.6348, average train loss: 1.1190
[10/29 15:52:11][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.692, 0.2405 s / batch. (data: 5.41e-05)max mem: 15.94594 GB 
[10/29 15:52:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-05, avg batch time: 0.2314, average loss: 0.6883
[10/29 15:52:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.03	
[10/29 15:52:22][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.25
[10/29 15:53:27][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.6007,	0.6374 s / batch. (data: 3.06e-04). ETA=17:36:22, max mem: 15.9 GB 
[10/29 15:54:30][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7453,	0.6431 s / batch. (data: 8.43e-04). ETA=17:44:47, max mem: 15.9 GB 
[10/29 15:55:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7753,	0.6187 s / batch. (data: 3.07e-04). ETA=17:03:17, max mem: 15.9 GB 
[10/29 15:56:37][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.5588,	0.6344 s / batch. (data: 8.58e-04). ETA=17:28:16, max mem: 15.9 GB 
[10/29 15:57:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7517,	0.6336 s / batch. (data: 3.27e-04). ETA=17:25:53, max mem: 15.9 GB 
[10/29 15:58:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0555,	0.6213 s / batch. (data: 2.80e-04). ETA=17:04:28, max mem: 15.9 GB 
[10/29 15:59:47][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3498,	0.6195 s / batch. (data: 2.81e-04). ETA=17:00:34, max mem: 15.9 GB 
[10/29 16:00:50][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5428,	0.6589 s / batch. (data: 8.18e-04). ETA=18:04:15, max mem: 15.9 GB 
[10/29 16:01:53][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1383,	0.6182 s / batch. (data: 3.15e-04). ETA=16:56:18, max mem: 15.9 GB 
[10/29 16:02:56][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0168,	0.6201 s / batch. (data: 3.29e-04). ETA=16:58:29, max mem: 15.9 GB 
[10/29 16:04:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0619,	0.6189 s / batch. (data: 1.57e-04). ETA=16:55:25, max mem: 15.9 GB 
[10/29 16:04:03][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.11e-03, avg batch time: 0.6342, average train loss: 1.1551
[10/29 16:04:54][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.260, 0.2542 s / batch. (data: 3.86e-05)max mem: 15.94594 GB 
[10/29 16:05:04][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2331, average loss: 1.1487
[10/29 16:05:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.01	
[10/29 16:05:04][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/29 16:06:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0983,	0.6315 s / batch. (data: 7.71e-04). ETA=17:14:57, max mem: 15.9 GB 
[10/29 16:07:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8042,	0.6324 s / batch. (data: 8.25e-04). ETA=17:15:19, max mem: 15.9 GB 
[10/29 16:08:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.5700,	0.6241 s / batch. (data: 5.54e-03). ETA=17:00:45, max mem: 15.9 GB 
[10/29 16:09:20][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0833,	0.6714 s / batch. (data: 3.90e-02). ETA=18:16:56, max mem: 15.9 GB 
[10/29 16:10:23][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 5.6291,	0.6306 s / batch. (data: 3.05e-04). ETA=17:09:16, max mem: 15.9 GB 
[10/29 16:11:26][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.9858,	0.6229 s / batch. (data: 2.66e-04). ETA=16:55:41, max mem: 15.9 GB 
[10/29 16:12:30][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7247,	0.6309 s / batch. (data: 7.52e-04). ETA=17:07:42, max mem: 15.9 GB 
[10/29 16:13:33][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7450,	0.6340 s / batch. (data: 7.30e-04). ETA=17:11:43, max mem: 15.9 GB 
[10/29 16:14:36][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.0042,	0.6314 s / batch. (data: 8.21e-04). ETA=17:06:27, max mem: 15.9 GB 
[10/29 16:15:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8350,	0.6193 s / batch. (data: 3.19e-04). ETA=16:45:41, max mem: 15.9 GB 
[10/29 16:16:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.6055,	0.6173 s / batch. (data: 1.58e-04). ETA=16:41:19, max mem: 15.9 GB 
[10/29 16:16:47][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.21e-03, avg batch time: 0.6352, average train loss: 1.2138
[10/29 16:17:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.693, 0.2272 s / batch. (data: 3.86e-05)max mem: 15.94594 GB 
[10/29 16:17:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-05, avg batch time: 0.2320, average loss: 0.6964
[10/29 16:17:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.67	
[10/29 16:17:47][INFO] visual_prompt:   36: Best epoch 12: best metric: -0.696
[10/29 16:17:47][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/29 16:18:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.4373,	0.6304 s / batch. (data: 8.26e-04). ETA=17:01:31, max mem: 15.9 GB 
[10/29 16:19:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2439,	0.6261 s / batch. (data: 4.78e-04). ETA=16:53:31, max mem: 15.9 GB 
[10/29 16:20:59][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0907,	0.6317 s / batch. (data: 8.12e-04). ETA=17:01:31, max mem: 15.9 GB 
[10/29 16:22:02][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.5865,	0.6187 s / batch. (data: 3.14e-04). ETA=16:39:25, max mem: 15.9 GB 
[10/29 16:23:06][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6865,	0.6199 s / batch. (data: 3.38e-04). ETA=16:40:22, max mem: 15.9 GB 
[10/29 16:24:09][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.3904,	0.6263 s / batch. (data: 2.96e-04). ETA=16:49:40, max mem: 15.9 GB 
[10/29 16:25:12][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3353,	0.6354 s / batch. (data: 3.09e-04). ETA=17:03:13, max mem: 15.9 GB 
[10/29 16:26:16][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2537,	0.6550 s / batch. (data: 8.00e-04). ETA=17:33:48, max mem: 15.9 GB 
[10/29 16:27:19][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 3.4873,	0.6432 s / batch. (data: 1.20e-02). ETA=17:13:39, max mem: 15.9 GB 
[10/29 16:28:22][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0054,	0.6350 s / batch. (data: 8.37e-04). ETA=16:59:30, max mem: 15.9 GB 
[10/29 16:29:26][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.3018,	0.6192 s / batch. (data: 1.85e-04). ETA=16:33:06, max mem: 15.9 GB 
[10/29 16:29:29][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.66e-03, avg batch time: 0.6346, average train loss: 1.4126
[10/29 16:30:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.699, 0.2436 s / batch. (data: 1.11e-02)max mem: 15.94594 GB 
[10/29 16:30:30][INFO] visual_prompt:  316: Inference (val):avg data time: 1.88e-04, avg batch time: 0.2328, average loss: 0.7179
[10/29 16:30:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.16	
[10/29 16:30:30][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/29 16:31:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0715,	0.6276 s / batch. (data: 3.02e-04). ETA=16:45:21, max mem: 15.9 GB 
[10/29 16:32:39][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7057,	0.6467 s / batch. (data: 9.50e-04). ETA=17:14:58, max mem: 15.9 GB 
[10/29 16:33:42][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.7602,	0.6447 s / batch. (data: 7.56e-04). ETA=17:10:41, max mem: 15.9 GB 
[10/29 16:34:46][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0625,	0.6328 s / batch. (data: 7.79e-04). ETA=16:50:33, max mem: 15.9 GB 
[10/29 16:35:49][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.2201,	0.6339 s / batch. (data: 8.10e-04). ETA=16:51:20, max mem: 15.9 GB 
[10/29 16:36:52][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8912,	0.6181 s / batch. (data: 3.15e-04). ETA=16:25:05, max mem: 15.9 GB 
[10/29 16:37:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.0349,	0.6331 s / batch. (data: 8.03e-04). ETA=16:47:53, max mem: 15.9 GB 
[10/29 16:38:59][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2250,	0.6336 s / batch. (data: 3.35e-04). ETA=16:47:42, max mem: 15.9 GB 
[10/29 16:40:03][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7405,	0.6307 s / batch. (data: 7.19e-04). ETA=16:42:00, max mem: 15.9 GB 
[10/29 16:41:06][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1197,	0.6400 s / batch. (data: 7.98e-03). ETA=16:55:41, max mem: 15.9 GB 
[10/29 16:42:09][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7398,	0.6178 s / batch. (data: 1.47e-04). ETA=16:19:26, max mem: 15.9 GB 
[10/29 16:42:13][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.32e-03, avg batch time: 0.6352, average train loss: 1.1657
[10/29 16:43:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.451, 0.2294 s / batch. (data: 4.86e-05)max mem: 15.94594 GB 
[10/29 16:43:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2322, average loss: 1.3085
[10/29 16:43:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.93	
[10/29 16:43:13][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/29 16:44:18][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.5826,	0.6376 s / batch. (data: 7.48e-04). ETA=16:49:41, max mem: 15.9 GB 
[10/29 16:45:22][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7338,	0.6193 s / batch. (data: 4.34e-04). ETA=16:19:42, max mem: 15.9 GB 
[10/29 16:46:25][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 4.3839,	0.6321 s / batch. (data: 3.31e-04). ETA=16:38:50, max mem: 15.9 GB 
[10/29 16:47:28][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 13.2085,	0.6189 s / batch. (data: 3.09e-04). ETA=16:17:01, max mem: 15.9 GB 
[10/29 16:48:31][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6386,	0.6480 s / batch. (data: 7.73e-04). ETA=17:01:51, max mem: 15.9 GB 
[10/29 16:49:35][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1494,	0.6274 s / batch. (data: 2.92e-04). ETA=16:28:18, max mem: 15.9 GB 
[10/29 16:50:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.1855,	0.6332 s / batch. (data: 7.91e-04). ETA=16:36:20, max mem: 15.9 GB 
[10/29 16:51:41][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.0594,	0.6448 s / batch. (data: 7.75e-04). ETA=16:53:30, max mem: 15.9 GB 
[10/29 16:52:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.3275,	0.6495 s / batch. (data: 1.68e-02). ETA=16:59:53, max mem: 15.9 GB 
[10/29 16:53:48][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8060,	0.6182 s / batch. (data: 2.98e-04). ETA=16:09:46, max mem: 15.9 GB 
[10/29 16:54:51][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.7634,	0.6191 s / batch. (data: 1.65e-04). ETA=16:10:01, max mem: 15.9 GB 
[10/29 16:54:55][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.17e-03, avg batch time: 0.6341, average train loss: 1.6137
[10/29 16:55:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.186, 0.2266 s / batch. (data: 4.01e-05)max mem: 15.94594 GB 
[10/29 16:55:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.2333, average loss: 1.2922
[10/29 16:55:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.10	
[10/29 16:55:55][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[10/29 16:57:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5137,	0.6456 s / batch. (data: 8.74e-04). ETA=16:50:31, max mem: 15.9 GB 
[10/29 16:58:04][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8852,	0.6183 s / batch. (data: 3.15e-04). ETA=16:06:46, max mem: 15.9 GB 
[10/29 16:59:07][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3373,	0.6312 s / batch. (data: 3.40e-04). ETA=16:25:49, max mem: 15.9 GB 
[10/29 17:00:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.0345,	0.6191 s / batch. (data: 3.27e-04). ETA=16:05:50, max mem: 15.9 GB 
[10/29 17:01:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9764,	0.6472 s / batch. (data: 8.16e-04). ETA=16:48:35, max mem: 15.9 GB 
[10/29 17:02:17][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8761,	0.6177 s / batch. (data: 3.52e-04). ETA=16:01:42, max mem: 15.9 GB 
[10/29 17:03:20][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0147,	0.6195 s / batch. (data: 2.98e-04). ETA=16:03:22, max mem: 15.9 GB 
[10/29 17:04:24][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6921,	0.6281 s / batch. (data: 4.49e-04). ETA=16:15:42, max mem: 15.9 GB 
[10/29 17:05:27][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8490,	0.6316 s / batch. (data: 8.44e-04). ETA=16:20:04, max mem: 15.9 GB 
[10/29 17:06:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.0891,	0.6353 s / batch. (data: 7.43e-04). ETA=16:24:46, max mem: 15.9 GB 
[10/29 17:07:34][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0683,	0.6176 s / batch. (data: 1.39e-04). ETA=15:56:25, max mem: 15.9 GB 
[10/29 17:07:37][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.84e-03, avg batch time: 0.6348, average train loss: 1.0738
[10/29 17:08:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.712, 0.2317 s / batch. (data: 3.22e-05)max mem: 15.94594 GB 
[10/29 17:08:38][INFO] visual_prompt:  316: Inference (val):avg data time: 1.20e-04, avg batch time: 0.2328, average loss: 0.6929
[10/29 17:08:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.26	
[10/29 17:08:38][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.693
[10/29 17:08:38][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[10/29 17:09:43][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0615,	0.6257 s / batch. (data: 7.81e-04). ETA=16:07:43, max mem: 15.9 GB 
[10/29 17:10:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8937,	0.6406 s / batch. (data: 2.88e-04). ETA=16:29:47, max mem: 15.9 GB 
[10/29 17:11:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5953,	0.6305 s / batch. (data: 1.26e-02). ETA=16:13:10, max mem: 15.9 GB 
[10/29 17:12:53][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3177,	0.6381 s / batch. (data: 3.65e-04). ETA=16:23:50, max mem: 15.9 GB 
[10/29 17:13:56][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0651,	0.6350 s / batch. (data: 8.55e-04). ETA=16:17:58, max mem: 15.9 GB 
[10/29 17:14:59][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7710,	0.6467 s / batch. (data: 8.16e-04). ETA=16:34:52, max mem: 15.9 GB 
[10/29 17:16:03][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.7118,	0.6181 s / batch. (data: 7.74e-04). ETA=15:49:53, max mem: 15.9 GB 
[10/29 17:17:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.4824,	0.6222 s / batch. (data: 2.97e-04). ETA=15:55:03, max mem: 15.9 GB 
[10/29 17:18:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.2761,	0.6332 s / batch. (data: 8.08e-04). ETA=16:10:59, max mem: 15.9 GB 
[10/29 17:19:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0909,	0.6194 s / batch. (data: 5.96e-04). ETA=15:48:43, max mem: 15.9 GB 
[10/29 17:20:16][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.1112,	0.6194 s / batch. (data: 1.55e-04). ETA=15:47:43, max mem: 15.9 GB 
[10/29 17:20:19][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.24e-03, avg batch time: 0.6345, average train loss: 1.1513
[10/29 17:21:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.963, 0.2467 s / batch. (data: 2.86e-05)max mem: 15.94594 GB 
[10/29 17:21:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.2320, average loss: 1.0409
[10/29 17:21:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.31	
[10/29 17:21:20][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[10/29 17:22:25][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2809,	0.6328 s / batch. (data: 9.95e-04). ETA=16:07:04, max mem: 15.9 GB 
[10/29 17:23:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1471,	0.6444 s / batch. (data: 7.97e-04). ETA=16:23:41, max mem: 15.9 GB 
[10/29 17:24:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 7.9690,	0.6184 s / batch. (data: 3.12e-04). ETA=15:43:03, max mem: 15.9 GB 
[10/29 17:25:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.2334,	0.6336 s / batch. (data: 8.24e-04). ETA=16:05:06, max mem: 15.9 GB 
[10/29 17:26:38][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0064,	0.6349 s / batch. (data: 3.19e-04). ETA=16:06:04, max mem: 15.9 GB 
[10/29 17:27:41][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.3081,	0.6332 s / batch. (data: 1.18e-03). ETA=16:02:27, max mem: 15.9 GB 
[10/29 17:28:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.8447,	0.6191 s / batch. (data: 3.21e-04). ETA=15:39:58, max mem: 15.9 GB 
[10/29 17:29:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7591,	0.6342 s / batch. (data: 3.20e-04). ETA=16:01:48, max mem: 15.9 GB 
[10/29 17:30:51][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.8462,	0.6402 s / batch. (data: 5.93e-03). ETA=16:09:52, max mem: 15.9 GB 
[10/29 17:31:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8738,	0.6192 s / batch. (data: 3.02e-04). ETA=15:37:01, max mem: 15.9 GB 
[10/29 17:32:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0212,	0.6180 s / batch. (data: 2.06e-04). ETA=15:34:12, max mem: 15.9 GB 
[10/29 17:33:01][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.45e-03, avg batch time: 0.6340, average train loss: 1.2621
[10/29 17:33:51][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.874, 0.2406 s / batch. (data: 4.41e-05)max mem: 15.94594 GB 
[10/29 17:34:02][INFO] visual_prompt:  316: Inference (val):avg data time: 4.27e-05, avg batch time: 0.2318, average loss: 0.9393
[10/29 17:34:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.32	
[10/29 17:34:02][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[10/29 17:35:07][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3289,	0.6327 s / batch. (data: 8.65e-04). ETA=15:55:16, max mem: 15.9 GB 
[10/29 17:36:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.5993,	0.6190 s / batch. (data: 3.23e-04). ETA=15:33:35, max mem: 15.9 GB 
[10/29 17:37:14][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4048,	0.6393 s / batch. (data: 7.88e-04). ETA=16:03:07, max mem: 15.9 GB 
[10/29 17:38:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7116,	0.6419 s / batch. (data: 1.17e-02). ETA=16:05:58, max mem: 15.9 GB 
[10/29 17:39:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1223,	0.6560 s / batch. (data: 1.60e-02). ETA=16:26:04, max mem: 15.9 GB 
[10/29 17:40:23][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1821,	0.6189 s / batch. (data: 3.18e-04). ETA=15:29:14, max mem: 15.9 GB 
[10/29 17:41:27][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7402,	0.6181 s / batch. (data: 3.26e-04). ETA=15:27:08, max mem: 15.9 GB 
[10/29 17:42:30][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0087,	0.6341 s / batch. (data: 8.22e-04). ETA=15:49:58, max mem: 15.9 GB 
[10/29 17:43:33][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.8097,	0.6320 s / batch. (data: 3.32e-04). ETA=15:45:49, max mem: 15.9 GB 
[10/29 17:44:37][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0111,	0.6398 s / batch. (data: 7.45e-04). ETA=15:56:25, max mem: 15.9 GB 
[10/29 17:45:40][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 4.8669,	0.6322 s / batch. (data: 1.80e-04). ETA=15:43:55, max mem: 15.9 GB 
[10/29 17:45:44][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.19e-03, avg batch time: 0.6348, average train loss: 1.2148
[10/29 17:46:35][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.054, 0.2315 s / batch. (data: 4.41e-05)max mem: 15.94594 GB 
[10/29 17:46:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2325, average loss: 4.5580
[10/29 17:46:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.01	
[10/29 17:46:44][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[10/29 17:47:50][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0958,	0.6269 s / batch. (data: 2.54e-04). ETA=15:34:55, max mem: 15.9 GB 
[10/29 17:48:53][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4067,	0.6337 s / batch. (data: 1.60e-02). ETA=15:44:03, max mem: 15.9 GB 
[10/29 17:49:56][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.9096,	0.6280 s / batch. (data: 7.32e-04). ETA=15:34:31, max mem: 15.9 GB 
[10/29 17:51:00][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1788,	0.6179 s / batch. (data: 2.67e-04). ETA=15:18:31, max mem: 15.9 GB 
[10/29 17:52:03][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.8792,	0.6205 s / batch. (data: 3.28e-04). ETA=15:21:15, max mem: 15.9 GB 
[10/29 17:53:06][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8999,	0.6185 s / batch. (data: 3.75e-04). ETA=15:17:14, max mem: 15.9 GB 
[10/29 17:54:09][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0747,	0.6537 s / batch. (data: 3.39e-02). ETA=16:08:24, max mem: 15.9 GB 
[10/29 17:55:13][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.1265,	0.6301 s / batch. (data: 2.95e-04). ETA=15:32:22, max mem: 15.9 GB 
[10/29 17:56:16][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5754,	0.6311 s / batch. (data: 7.75e-04). ETA=15:32:52, max mem: 15.9 GB 
[10/29 17:57:19][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6469 s / batch. (data: 5.88e-03). ETA=15:55:08, max mem: 15.9 GB 
[10/29 17:58:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.1936,	0.6184 s / batch. (data: 1.45e-04). ETA=15:12:02, max mem: 15.9 GB 
[10/29 17:58:27][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.75e-03, avg batch time: 0.6350, average train loss: 1.1390
[10/29 17:59:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.698, 0.2441 s / batch. (data: 4.36e-05)max mem: 15.94594 GB 
[10/29 17:59:27][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2316, average loss: 0.6885
[10/29 17:59:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.21	
[10/29 17:59:27][INFO] visual_prompt:   36: Best epoch 20: best metric: -0.689
[10/29 17:59:27][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[10/29 18:00:33][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.1459,	0.6566 s / batch. (data: 1.10e-02). ETA=16:07:06, max mem: 15.9 GB 
[10/29 18:01:37][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.0916,	0.6560 s / batch. (data: 3.11e-04). ETA=16:05:09, max mem: 15.9 GB 
[10/29 18:02:40][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8908,	0.6304 s / batch. (data: 2.64e-04). ETA=15:26:31, max mem: 15.9 GB 
[10/29 18:03:43][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1146,	0.6466 s / batch. (data: 7.61e-04). ETA=15:49:09, max mem: 15.9 GB 
[10/29 18:04:46][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0851,	0.6210 s / batch. (data: 3.22e-04). ETA=15:10:37, max mem: 15.9 GB 
[10/29 18:05:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1958,	0.6179 s / batch. (data: 3.22e-04). ETA=15:05:05, max mem: 15.9 GB 
[10/29 18:06:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.8426,	0.6195 s / batch. (data: 2.87e-04). ETA=15:06:17, max mem: 15.9 GB 
[10/29 18:07:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7581,	0.6180 s / batch. (data: 2.93e-04). ETA=15:03:06, max mem: 15.9 GB 
[10/29 18:08:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0005,	0.6400 s / batch. (data: 7.97e-04). ETA=15:34:14, max mem: 15.9 GB 
[10/29 18:10:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7111,	0.6197 s / batch. (data: 3.26e-04). ETA=15:03:33, max mem: 15.9 GB 
[10/29 18:11:06][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4527,	0.6186 s / batch. (data: 1.53e-04). ETA=15:00:57, max mem: 15.9 GB 
[10/29 18:11:09][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.83e-03, avg batch time: 0.6347, average train loss: 1.2074
[10/29 18:12:00][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.762, 0.2486 s / batch. (data: 4.48e-05)max mem: 15.94594 GB 
[10/29 18:12:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2335, average loss: 0.7263
[10/29 18:12:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.34	
[10/29 18:12:10][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[10/29 18:13:16][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0790,	0.6321 s / batch. (data: 8.18e-04). ETA=15:19:23, max mem: 15.9 GB 
[10/29 18:14:19][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0448,	0.6200 s / batch. (data: 4.59e-04). ETA=15:00:49, max mem: 15.9 GB 
[10/29 18:15:22][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5267,	0.6194 s / batch. (data: 3.29e-04). ETA=14:58:55, max mem: 15.9 GB 
[10/29 18:16:25][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1254,	0.6204 s / batch. (data: 3.11e-04). ETA=14:59:15, max mem: 15.9 GB 
[10/29 18:17:28][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.9999,	0.6326 s / batch. (data: 3.02e-04). ETA=15:15:53, max mem: 15.9 GB 
[10/29 18:18:32][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0489,	0.6430 s / batch. (data: 8.30e-04). ETA=15:29:53, max mem: 15.9 GB 
[10/29 18:19:35][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.5106,	0.6384 s / batch. (data: 8.14e-04). ETA=15:22:15, max mem: 15.9 GB 
[10/29 18:20:39][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 4.4337,	0.6498 s / batch. (data: 7.91e-04). ETA=15:37:38, max mem: 15.9 GB 
[10/29 18:21:42][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5603,	0.6324 s / batch. (data: 4.63e-04). ETA=15:11:22, max mem: 15.9 GB 
[10/29 18:22:46][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.5799,	0.6207 s / batch. (data: 2.55e-04). ETA=14:53:30, max mem: 15.9 GB 
[10/29 18:23:49][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 3.7574,	0.6187 s / batch. (data: 1.59e-04). ETA=14:49:40, max mem: 15.9 GB 
[10/29 18:23:53][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 4.11e-03, avg batch time: 0.6351, average train loss: 1.1727
[10/29 18:24:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.449, 0.2251 s / batch. (data: 4.05e-05)max mem: 15.94594 GB 
[10/29 18:24:54][INFO] visual_prompt:  316: Inference (val):avg data time: 1.15e-04, avg batch time: 0.2312, average loss: 1.3149
[10/29 18:24:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.11	
[10/29 18:24:54][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[10/29 18:26:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6219,	0.6278 s / batch. (data: 7.84e-04). ETA=15:01:36, max mem: 15.9 GB 
[10/29 18:27:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1511,	0.6180 s / batch. (data: 3.15e-04). ETA=14:46:26, max mem: 15.9 GB 
[10/29 18:28:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1870,	0.6444 s / batch. (data: 7.81e-04). ETA=15:23:14, max mem: 15.9 GB 
[10/29 18:29:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7355,	0.6370 s / batch. (data: 7.91e-04). ETA=15:11:41, max mem: 15.9 GB 
[10/29 18:30:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6999,	0.6440 s / batch. (data: 1.61e-02). ETA=15:20:34, max mem: 15.9 GB 
[10/29 18:31:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.1449,	0.6334 s / batch. (data: 8.23e-04). ETA=15:04:19, max mem: 15.9 GB 
[10/29 18:32:20][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3020,	0.6208 s / batch. (data: 3.02e-04). ETA=14:45:19, max mem: 15.9 GB 
[10/29 18:33:23][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9708,	0.6216 s / batch. (data: 3.20e-04). ETA=14:45:30, max mem: 15.9 GB 
[10/29 18:34:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7891,	0.6496 s / batch. (data: 5.91e-03). ETA=15:24:14, max mem: 15.9 GB 
[10/29 18:35:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0393,	0.6401 s / batch. (data: 7.28e-04). ETA=15:09:41, max mem: 15.9 GB 
[10/29 18:36:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0207,	0.6166 s / batch. (data: 1.59e-04). ETA=14:35:11, max mem: 15.9 GB 
[10/29 18:36:36][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 4.90e-03, avg batch time: 0.6351, average train loss: 1.0752
[10/29 18:37:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.784, 0.2458 s / batch. (data: 3.27e-05)max mem: 15.94594 GB 
[10/29 18:37:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.2322, average loss: 0.7413
[10/29 18:37:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.62	
[10/29 18:37:36][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[10/29 18:38:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 3.2735,	0.6309 s / batch. (data: 8.66e-04). ETA=14:54:24, max mem: 15.9 GB 
[10/29 18:39:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2979,	0.6327 s / batch. (data: 7.82e-04). ETA=14:55:57, max mem: 15.9 GB 
[10/29 18:40:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6687,	0.6187 s / batch. (data: 3.21e-04). ETA=14:35:05, max mem: 15.9 GB 
[10/29 18:41:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7726,	0.6192 s / batch. (data: 2.64e-04). ETA=14:34:43, max mem: 15.9 GB 
[10/29 18:42:55][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 2.1507,	0.6287 s / batch. (data: 3.18e-04). ETA=14:47:10, max mem: 15.9 GB 
[10/29 18:43:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.2879,	0.6253 s / batch. (data: 3.26e-04). ETA=14:41:18, max mem: 15.9 GB 
[10/29 18:45:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.0860,	0.6190 s / batch. (data: 2.84e-04). ETA=14:31:19, max mem: 15.9 GB 
[10/29 18:46:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8494,	0.6310 s / batch. (data: 1.25e-02). ETA=14:47:16, max mem: 15.9 GB 
[10/29 18:47:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8039,	0.6194 s / batch. (data: 2.93e-04). ETA=14:29:54, max mem: 15.9 GB 
[10/29 18:48:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6994,	0.6444 s / batch. (data: 8.16e-04). ETA=15:03:54, max mem: 15.9 GB 
[10/29 18:49:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0052,	0.6177 s / batch. (data: 1.54e-04). ETA=14:25:24, max mem: 15.9 GB 
[10/29 18:49:18][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 4.58e-03, avg batch time: 0.6345, average train loss: 1.1698
[10/29 18:50:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.439, 0.2397 s / batch. (data: 5.44e-05)max mem: 15.94594 GB 
[10/29 18:50:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.2341, average loss: 1.3035
[10/29 18:50:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.77	
[10/29 18:50:18][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[10/29 18:51:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.8922,	0.6349 s / batch. (data: 8.02e-04). ETA=14:48:19, max mem: 15.9 GB 
[10/29 18:52:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7770,	0.6489 s / batch. (data: 2.11e-02). ETA=15:06:56, max mem: 15.9 GB 
[10/29 18:53:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0031,	0.6554 s / batch. (data: 1.10e-02). ETA=15:14:51, max mem: 15.9 GB 
[10/29 18:54:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.5025,	0.6283 s / batch. (data: 3.04e-04). ETA=14:36:00, max mem: 15.9 GB 
[10/29 18:55:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7414,	0.6194 s / batch. (data: 2.92e-04). ETA=14:22:34, max mem: 15.9 GB 
[10/29 18:56:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.5814,	0.6190 s / batch. (data: 3.12e-04). ETA=14:20:57, max mem: 15.9 GB 
[10/29 18:57:44][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1119,	0.6440 s / batch. (data: 3.19e-04). ETA=14:54:38, max mem: 15.9 GB 
[10/29 18:58:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2989,	0.6294 s / batch. (data: 1.02e-03). ETA=14:33:25, max mem: 15.9 GB 
[10/29 18:59:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7138,	0.6191 s / batch. (data: 6.11e-04). ETA=14:18:02, max mem: 15.9 GB 
[10/29 19:00:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6983,	0.6422 s / batch. (data: 8.72e-04). ETA=14:49:01, max mem: 15.9 GB 
[10/29 19:01:57][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0264,	0.6169 s / batch. (data: 1.55e-04). ETA=14:12:59, max mem: 15.9 GB 
[10/29 19:02:01][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 4.30e-03, avg batch time: 0.6351, average train loss: 1.1619
[10/29 19:02:50][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.919, 0.2381 s / batch. (data: 3.05e-05)max mem: 15.94594 GB 
[10/29 19:03:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.2321, average loss: 0.8500
[10/29 19:03:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.79	
[10/29 19:03:01][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[10/29 19:04:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8060,	0.6256 s / batch. (data: 3.13e-04). ETA=14:23:49, max mem: 15.9 GB 
[10/29 19:05:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2570,	0.6459 s / batch. (data: 7.86e-04). ETA=14:50:45, max mem: 15.9 GB 
[10/29 19:06:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2002,	0.6327 s / batch. (data: 8.08e-04). ETA=14:31:35, max mem: 15.9 GB 
[10/29 19:07:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7533,	0.6310 s / batch. (data: 3.04e-04). ETA=14:28:10, max mem: 15.9 GB 
[10/29 19:08:19][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.5351,	0.6191 s / batch. (data: 3.23e-04). ETA=14:10:44, max mem: 15.9 GB 
[10/29 19:09:22][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7883,	0.6456 s / batch. (data: 2.95e-04). ETA=14:46:01, max mem: 15.9 GB 
[10/29 19:10:26][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2775,	0.6214 s / batch. (data: 3.18e-04). ETA=14:11:49, max mem: 15.9 GB 
[10/29 19:11:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.6015,	0.6289 s / batch. (data: 2.65e-04). ETA=14:21:03, max mem: 15.9 GB 
[10/29 19:12:32][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.5353,	0.6342 s / batch. (data: 7.92e-04). ETA=14:27:13, max mem: 15.9 GB 
[10/29 19:13:35][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.4702,	0.6441 s / batch. (data: 8.82e-03). ETA=14:39:46, max mem: 15.9 GB 
[10/29 19:14:39][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0986,	0.6187 s / batch. (data: 1.32e-04). ETA=14:04:04, max mem: 15.9 GB 
[10/29 19:14:42][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 4.29e-03, avg batch time: 0.6338, average train loss: 1.1099
[10/29 19:15:32][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.201, 0.2250 s / batch. (data: 2.84e-05)max mem: 15.94594 GB 
[10/29 19:15:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.2324, average loss: 1.0895
[10/29 19:15:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.64	
[10/29 19:15:43][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[10/29 19:16:48][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.2014,	0.6395 s / batch. (data: 8.67e-04). ETA=14:31:16, max mem: 15.9 GB 
[10/29 19:17:51][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2811,	0.6189 s / batch. (data: 3.05e-04). ETA=14:02:07, max mem: 15.9 GB 
[10/29 19:18:54][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.8196,	0.6310 s / batch. (data: 7.87e-04). ETA=14:17:36, max mem: 15.9 GB 
[10/29 19:19:58][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 6.3940,	0.6191 s / batch. (data: 3.28e-04). ETA=14:00:21, max mem: 15.9 GB 
[10/29 19:21:01][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5254,	0.6383 s / batch. (data: 3.35e-04). ETA=14:25:25, max mem: 15.9 GB 
[10/29 19:22:04][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.5616,	0.6270 s / batch. (data: 3.29e-04). ETA=14:08:59, max mem: 15.9 GB 
[10/29 19:23:08][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.3425,	0.6313 s / batch. (data: 7.93e-04). ETA=14:13:43, max mem: 15.9 GB 
[10/29 19:24:11][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7859,	0.6376 s / batch. (data: 5.89e-03). ETA=14:21:14, max mem: 15.9 GB 
[10/29 19:25:14][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.3033,	0.6317 s / batch. (data: 7.98e-04). ETA=14:12:11, max mem: 15.9 GB 
[10/29 19:26:17][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7047,	0.6318 s / batch. (data: 3.14e-04). ETA=14:11:19, max mem: 15.9 GB 
[10/29 19:27:21][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.3984,	0.6182 s / batch. (data: 1.57e-04). ETA=13:51:55, max mem: 15.9 GB 
[10/29 19:27:24][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 4.56e-03, avg batch time: 0.6344, average train loss: 1.1024
[10/29 19:28:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.026, 0.2326 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/29 19:28:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.2326, average loss: 2.2258
[10/29 19:28:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.09	
[10/29 19:28:25][INFO] visual_prompt:   42: Stopping early.
