[10/25 03:08:14][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/25 03:08:14][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/25 03:08:14][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/25 03:08:14][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/25 03:08:14][INFO] visual_prompt:  108: Training with config:
[10/25 03:08:14][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/25 03:08:14][INFO] visual_prompt:   55: Loading training data...
[10/25 03:08:14][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/25 03:08:14][INFO] visual_prompt:   57: Loading validation data...
[10/25 03:08:14][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/25 03:08:14][INFO] visual_prompt:   38: Constructing models...
[10/25 03:08:22][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/25 03:08:22][INFO] visual_prompt:   54: tuned percent:0.522
[10/25 03:08:22][INFO] visual_prompt:   40: Device used for model: 0
[10/25 03:08:22][INFO] visual_prompt:   40: Setting up Evaluator...
[10/25 03:08:22][INFO] visual_prompt:   42: Setting up Trainer...
[10/25 03:08:22][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/25 03:08:22][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/25 03:09:28][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6179 s / batch. (data: 2.76e-04). ETA=18:57:54, max mem: 15.9 GB 
[10/25 03:10:31][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6319 s / batch. (data: 9.16e-04). ETA=19:22:44, max mem: 15.9 GB 
[10/25 03:11:34][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6218 s / batch. (data: 3.29e-04). ETA=19:03:07, max mem: 15.9 GB 
[10/25 03:12:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6427 s / batch. (data: 3.09e-04). ETA=19:40:22, max mem: 15.9 GB 
[10/25 03:13:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6193 s / batch. (data: 3.22e-04). ETA=18:56:26, max mem: 15.9 GB 
[10/25 03:14:45][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6240 s / batch. (data: 3.24e-04). ETA=19:03:56, max mem: 15.9 GB 
[10/25 03:15:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6310 s / batch. (data: 8.77e-03). ETA=19:15:46, max mem: 15.9 GB 
[10/25 03:16:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6235 s / batch. (data: 3.68e-04). ETA=19:01:05, max mem: 15.9 GB 
[10/25 03:17:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6531 s / batch. (data: 1.10e-02). ETA=19:54:05, max mem: 15.9 GB 
[10/25 03:18:58][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6310 s / batch. (data: 3.28e-04). ETA=19:12:39, max mem: 15.9 GB 
[10/25 03:20:01][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6172 s / batch. (data: 1.49e-04). ETA=18:46:21, max mem: 15.9 GB 
[10/25 03:20:05][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.72e-03, avg batch time: 0.6354, average train loss: 1.4028
[10/25 03:20:55][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2254 s / batch. (data: 3.79e-05)max mem: 15.91075 GB 
[10/25 03:21:06][INFO] visual_prompt:  316: Inference (val):avg data time: 1.32e-04, avg batch time: 0.2334, average loss: 1.3505
[10/25 03:21:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/25 03:21:06][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 2.5
[10/25 03:22:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 60.5930,	0.6288 s / batch. (data: 2.93e-04). ETA=19:06:28, max mem: 15.9 GB 
[10/25 03:23:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 16.6184,	0.6321 s / batch. (data: 1.30e-03). ETA=19:11:29, max mem: 15.9 GB 
[10/25 03:24:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0002,	0.6344 s / batch. (data: 5.87e-03). ETA=19:14:33, max mem: 15.9 GB 
[10/25 03:25:20][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0116,	0.6311 s / batch. (data: 8.11e-04). ETA=19:07:27, max mem: 15.9 GB 
[10/25 03:26:23][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 59.6030,	0.6221 s / batch. (data: 3.04e-04). ETA=18:50:02, max mem: 15.9 GB 
[10/25 03:27:27][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.3879,	0.6233 s / batch. (data: 3.42e-04). ETA=18:51:14, max mem: 15.9 GB 
[10/25 03:28:30][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0009,	0.6353 s / batch. (data: 2.95e-04). ETA=19:11:55, max mem: 15.9 GB 
[10/25 03:29:33][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 8.0687,	0.6734 s / batch. (data: 5.88e-03). ETA=20:19:54, max mem: 15.9 GB 
[10/25 03:30:36][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.7011,	0.6327 s / batch. (data: 3.26e-04). ETA=19:05:11, max mem: 15.9 GB 
[10/25 03:31:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6226 s / batch. (data: 3.24e-04). ETA=18:45:49, max mem: 15.9 GB 
[10/25 03:32:43][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6180 s / batch. (data: 1.34e-04). ETA=18:36:23, max mem: 15.9 GB 
[10/25 03:32:47][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 4.16e-03, avg batch time: 0.6335, average train loss: 14.4283
[10/25 03:33:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 47.039, 0.2319 s / batch. (data: 2.65e-05)max mem: 15.91075 GB 
[10/25 03:33:47][INFO] visual_prompt:  316: Inference (val):avg data time: 4.13e-05, avg batch time: 0.2332, average loss: 42.3837
[10/25 03:33:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.32	
[10/25 03:33:47][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 5.0
[10/25 03:34:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6236 s / batch. (data: 6.25e-04). ETA=18:45:33, max mem: 15.9 GB 
[10/25 03:35:57][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6307 s / batch. (data: 3.20e-04). ETA=18:57:18, max mem: 15.9 GB 
[10/25 03:37:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6559 s / batch. (data: 9.73e-03). ETA=19:41:31, max mem: 15.9 GB 
[10/25 03:38:03][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 13.8526,	0.6300 s / batch. (data: 1.30e-02). ETA=18:53:49, max mem: 15.9 GB 
[10/25 03:39:06][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 72.8209,	0.6319 s / batch. (data: 8.33e-04). ETA=18:56:16, max mem: 15.9 GB 
[10/25 03:40:09][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6243 s / batch. (data: 3.18e-04). ETA=18:41:35, max mem: 15.9 GB 
[10/25 03:41:12][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6411 s / batch. (data: 8.27e-04). ETA=19:10:38, max mem: 15.9 GB 
[10/25 03:42:15][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 21.0994,	0.6283 s / batch. (data: 8.16e-04). ETA=18:46:38, max mem: 15.9 GB 
[10/25 03:43:19][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 44.0743,	0.6288 s / batch. (data: 1.05e-02). ETA=18:46:32, max mem: 15.9 GB 
[10/25 03:44:22][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 20.9386,	0.6194 s / batch. (data: 2.97e-04). ETA=18:28:36, max mem: 15.9 GB 
[10/25 03:45:25][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 25.6863,	0.6171 s / batch. (data: 1.54e-04). ETA=18:23:27, max mem: 15.9 GB 
[10/25 03:45:29][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 5.29e-03, avg batch time: 0.6342, average train loss: 23.2931
[10/25 03:46:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 27.532, 0.2260 s / batch. (data: 4.15e-05)max mem: 15.91075 GB 
[10/25 03:46:29][INFO] visual_prompt:  316: Inference (val):avg data time: 9.37e-05, avg batch time: 0.2331, average loss: 30.3531
[10/25 03:46:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.14	
[10/25 03:46:29][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 7.5
[10/25 03:47:35][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6304 s / batch. (data: 2.83e-04). ETA=18:46:04, max mem: 15.9 GB 
[10/25 03:48:38][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 112.0422,	0.6329 s / batch. (data: 8.46e-04). ETA=18:49:27, max mem: 15.9 GB 
[10/25 03:49:41][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 4.4839,	0.6325 s / batch. (data: 8.37e-04). ETA=18:47:51, max mem: 15.9 GB 
[10/25 03:50:44][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 39.3375,	0.6201 s / batch. (data: 2.03e-03). ETA=18:24:40, max mem: 15.9 GB 
[10/25 03:51:47][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 44.8946,	0.6436 s / batch. (data: 7.94e-04). ETA=19:05:25, max mem: 15.9 GB 
[10/25 03:52:50][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6377 s / batch. (data: 7.86e-04). ETA=18:53:48, max mem: 15.9 GB 
[10/25 03:53:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 184.8901,	0.6195 s / batch. (data: 3.26e-04). ETA=18:20:31, max mem: 15.9 GB 
[10/25 03:54:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6186 s / batch. (data: 3.18e-04). ETA=18:17:53, max mem: 15.9 GB 
[10/25 03:55:59][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6080 s / batch. (data: 3.17e-04). ETA=17:58:01, max mem: 15.9 GB 
[10/25 03:57:02][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0001,	0.6396 s / batch. (data: 1.56e-02). ETA=18:52:57, max mem: 15.9 GB 
[10/25 03:58:05][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 140.5187,	0.6131 s / batch. (data: 1.70e-04). ETA=18:04:57, max mem: 15.9 GB 
[10/25 03:58:09][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.48e-03, avg batch time: 0.6326, average train loss: 32.5587
[10/25 03:58:59][INFO] visual_prompt:  303: 	Test 100/123. loss: 23.819, 0.2397 s / batch. (data: 3.84e-05)max mem: 15.91075 GB 
[10/25 03:59:10][INFO] visual_prompt:  316: Inference (val):avg data time: 4.09e-05, avg batch time: 0.2319, average loss: 26.2890
[10/25 03:59:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.53	
[10/25 03:59:10][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 10.0
[10/25 04:00:15][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 20.2781,	0.6425 s / batch. (data: 7.98e-04). ETA=18:55:53, max mem: 15.9 GB 
[10/25 04:01:18][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6301 s / batch. (data: 8.06e-04). ETA=18:32:51, max mem: 15.9 GB 
[10/25 04:02:20][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 84.8374,	0.6250 s / batch. (data: 2.97e-04). ETA=18:22:54, max mem: 15.9 GB 
[10/25 04:03:23][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 61.6705,	0.6278 s / batch. (data: 5.42e-03). ETA=18:26:43, max mem: 15.9 GB 
[10/25 04:04:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6291 s / batch. (data: 7.91e-04). ETA=18:28:04, max mem: 15.9 GB 
[10/25 04:05:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6226 s / batch. (data: 3.40e-04). ETA=18:15:35, max mem: 15.9 GB 
[10/25 04:06:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 14.7386,	0.6330 s / batch. (data: 8.29e-04). ETA=18:32:44, max mem: 15.9 GB 
[10/25 04:07:36][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 22.6587,	0.6190 s / batch. (data: 3.04e-04). ETA=18:07:12, max mem: 15.9 GB 
[10/25 04:08:39][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 60.0040,	0.6412 s / batch. (data: 7.74e-04). ETA=18:45:08, max mem: 15.9 GB 
[10/25 04:09:41][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 28.5309,	0.6372 s / batch. (data: 5.94e-03). ETA=18:37:00, max mem: 15.9 GB 
[10/25 04:10:44][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 100.9567,	0.6118 s / batch. (data: 1.88e-04). ETA=17:51:21, max mem: 15.9 GB 
[10/25 04:10:48][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.04e-03, avg batch time: 0.6312, average train loss: 45.9440
[10/25 04:11:37][INFO] visual_prompt:  303: 	Test 100/123. loss: 198.512, 0.2254 s / batch. (data: 3.43e-05)max mem: 15.91075 GB 
[10/25 04:11:48][INFO] visual_prompt:  316: Inference (val):avg data time: 4.04e-05, avg batch time: 0.2328, average loss: 217.5785
[10/25 04:11:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.71	
[10/25 04:11:48][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 12.5
[10/25 04:12:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 23.7469,	0.6369 s / batch. (data: 8.73e-04). ETA=18:34:14, max mem: 15.9 GB 
[10/25 04:13:56][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6150 s / batch. (data: 3.32e-04). ETA=17:54:56, max mem: 15.9 GB 
[10/25 04:14:59][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6327 s / batch. (data: 4.42e-04). ETA=18:24:53, max mem: 15.9 GB 
[10/25 04:16:02][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 79.0362,	0.6282 s / batch. (data: 3.12e-04). ETA=18:15:58, max mem: 15.9 GB 
[10/25 04:17:04][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 74.5540,	0.6152 s / batch. (data: 3.14e-04). ETA=17:52:13, max mem: 15.9 GB 
[10/25 04:18:07][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 118.0798,	0.6189 s / batch. (data: 3.09e-04). ETA=17:57:39, max mem: 15.9 GB 
[10/25 04:19:11][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 22.4985,	0.6507 s / batch. (data: 3.13e-04). ETA=18:51:55, max mem: 15.9 GB 
[10/25 04:20:14][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 117.8486,	0.6276 s / batch. (data: 2.56e-04). ETA=18:10:39, max mem: 15.9 GB 
[10/25 04:21:17][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 19.0900,	0.6347 s / batch. (data: 7.87e-04). ETA=18:21:53, max mem: 15.9 GB 
[10/25 04:22:20][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6486 s / batch. (data: 7.90e-04). ETA=18:45:03, max mem: 15.9 GB 
[10/25 04:23:22][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6063 s / batch. (data: 1.52e-04). ETA=17:30:36, max mem: 15.9 GB 
[10/25 04:23:26][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.10e-03, avg batch time: 0.6311, average train loss: 61.4173
[10/25 04:24:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 167.080, 0.2248 s / batch. (data: 3.36e-05)max mem: 15.91075 GB 
[10/25 04:24:26][INFO] visual_prompt:  316: Inference (val):avg data time: 4.08e-05, avg batch time: 0.2330, average loss: 183.2552
[10/25 04:24:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.98	
[10/25 04:24:26][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 15.0
[10/25 04:25:31][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 223.9428,	0.6228 s / batch. (data: 3.22e-04). ETA=17:58:11, max mem: 15.9 GB 
[10/25 04:26:34][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 88.6273,	0.6388 s / batch. (data: 8.07e-04). ETA=18:24:47, max mem: 15.9 GB 
[10/25 04:27:37][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1021,	0.6437 s / batch. (data: 9.53e-04). ETA=18:32:07, max mem: 15.9 GB 
[10/25 04:28:40][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 111.0155,	0.6177 s / batch. (data: 3.22e-04). ETA=17:46:12, max mem: 15.9 GB 
[10/25 04:29:43][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 333.5473,	0.6404 s / batch. (data: 1.05e-02). ETA=18:24:13, max mem: 15.9 GB 
[10/25 04:30:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 193.3076,	0.6127 s / batch. (data: 3.02e-04). ETA=17:35:30, max mem: 15.9 GB 
[10/25 04:31:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 52.7754,	0.6173 s / batch. (data: 3.19e-04). ETA=17:42:26, max mem: 15.9 GB 
[10/25 04:32:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6151 s / batch. (data: 3.41e-04). ETA=17:37:38, max mem: 15.9 GB 
[10/25 04:33:54][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 25.3437,	0.6441 s / batch. (data: 8.03e-04). ETA=18:26:21, max mem: 15.9 GB 
[10/25 04:34:57][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 41.8918,	0.6404 s / batch. (data: 2.91e-04). ETA=18:18:57, max mem: 15.9 GB 
[10/25 04:36:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 302.6747,	0.6176 s / batch. (data: 1.39e-04). ETA=17:38:53, max mem: 15.9 GB 
[10/25 04:36:04][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.39e-03, avg batch time: 0.6303, average train loss: 74.9160
[10/25 04:36:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 148.734, 0.2247 s / batch. (data: 3.96e-05)max mem: 15.91075 GB 
[10/25 04:37:04][INFO] visual_prompt:  316: Inference (val):avg data time: 4.47e-05, avg batch time: 0.2315, average loss: 134.4320
[10/25 04:37:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.93	
[10/25 04:37:04][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 17.5
[10/25 04:38:09][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 175.4333,	0.6362 s / batch. (data: 9.00e-04). ETA=18:09:31, max mem: 15.9 GB 
[10/25 04:39:12][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 21.3959,	0.6244 s / batch. (data: 3.26e-04). ETA=17:48:17, max mem: 15.9 GB 
[10/25 04:40:15][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 65.3047,	0.6597 s / batch. (data: 7.71e-04). ETA=18:47:38, max mem: 15.9 GB 
[10/25 04:41:18][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6079 s / batch. (data: 2.58e-04). ETA=17:18:01, max mem: 15.9 GB 
[10/25 04:42:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 6.0213,	0.6186 s / batch. (data: 3.34e-04). ETA=17:35:19, max mem: 15.9 GB 
[10/25 04:43:23][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6566 s / batch. (data: 7.08e-04). ETA=18:38:59, max mem: 15.9 GB 
[10/25 04:44:26][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 30.4676,	0.6224 s / batch. (data: 5.45e-03). ETA=17:39:40, max mem: 15.9 GB 
[10/25 04:45:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 20.3265,	0.6316 s / batch. (data: 8.32e-04). ETA=17:54:24, max mem: 15.9 GB 
[10/25 04:46:31][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6082 s / batch. (data: 3.24e-04). ETA=17:13:28, max mem: 15.9 GB 
[10/25 04:47:34][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 175.4325,	0.6185 s / batch. (data: 3.30e-04). ETA=17:30:00, max mem: 15.9 GB 
[10/25 04:48:37][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6169 s / batch. (data: 1.62e-04). ETA=17:26:13, max mem: 15.9 GB 
[10/25 04:48:41][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 3.84e-03, avg batch time: 0.6302, average train loss: 103.7949
[10/25 04:49:30][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.720, 0.2379 s / batch. (data: 3.46e-05)max mem: 15.91075 GB 
[10/25 04:49:41][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.2329, average loss: 0.7051
[10/25 04:49:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.66	
[10/25 04:49:41][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 20.0
[10/25 04:50:46][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 309.2645,	0.6325 s / batch. (data: 7.45e-04). ETA=17:51:33, max mem: 15.9 GB 
[10/25 04:51:49][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 10.3709,	0.6535 s / batch. (data: 1.11e-02). ETA=18:26:08, max mem: 15.9 GB 
[10/25 04:52:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 120.0977,	0.6269 s / batch. (data: 9.73e-04). ETA=17:40:02, max mem: 15.9 GB 
[10/25 04:53:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6424 s / batch. (data: 8.10e-04). ETA=18:05:08, max mem: 15.9 GB 
[10/25 04:54:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 420.0358,	0.6205 s / batch. (data: 3.14e-04). ETA=17:27:06, max mem: 15.9 GB 
[10/25 04:56:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 69.4152,	0.6275 s / batch. (data: 8.43e-04). ETA=17:37:49, max mem: 15.9 GB 
[10/25 04:57:03][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6203 s / batch. (data: 8.23e-04). ETA=17:24:41, max mem: 15.9 GB 
[10/25 04:58:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 15.0666,	0.6343 s / batch. (data: 7.83e-04). ETA=17:47:13, max mem: 15.9 GB 
[10/25 04:59:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 49.4939,	0.6728 s / batch. (data: 8.14e-04). ETA=18:50:48, max mem: 15.9 GB 
[10/25 05:00:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6205 s / batch. (data: 3.32e-04). ETA=17:21:58, max mem: 15.9 GB 
[10/25 05:01:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 80.0398,	0.6125 s / batch. (data: 1.43e-04). ETA=17:07:27, max mem: 15.9 GB 
[10/25 05:01:19][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.56e-03, avg batch time: 0.6306, average train loss: 91.8988
[10/25 05:02:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 77.922, 0.2329 s / batch. (data: 3.98e-05)max mem: 15.91075 GB 
[10/25 05:02:19][INFO] visual_prompt:  316: Inference (val):avg data time: 4.01e-05, avg batch time: 0.2330, average loss: 141.4103
[10/25 05:02:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.53	
[10/25 05:02:19][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 22.5
[10/25 05:03:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 99.2399,	0.6296 s / batch. (data: 8.34e-04). ETA=17:35:05, max mem: 15.9 GB 
[10/25 05:04:26][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 690.8031,	0.6263 s / batch. (data: 8.13e-04). ETA=17:28:25, max mem: 15.9 GB 
[10/25 05:05:29][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 86.6419,	0.6171 s / batch. (data: 8.08e-04). ETA=17:12:02, max mem: 15.9 GB 
[10/25 05:06:31][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6068 s / batch. (data: 2.92e-04). ETA=16:53:52, max mem: 15.9 GB 
[10/25 05:07:34][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 9.0267,	0.6280 s / batch. (data: 3.08e-04). ETA=17:28:09, max mem: 15.9 GB 
[10/25 05:08:37][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 16.1839,	0.6331 s / batch. (data: 7.83e-04). ETA=17:35:40, max mem: 15.9 GB 
[10/25 05:09:40][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 239.7010,	0.6188 s / batch. (data: 3.26e-04). ETA=17:10:46, max mem: 15.9 GB 
[10/25 05:10:43][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 33.6794,	0.6198 s / batch. (data: 3.20e-04). ETA=17:11:28, max mem: 15.9 GB 
[10/25 05:11:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 92.5709,	0.6366 s / batch. (data: 1.66e-02). ETA=17:38:18, max mem: 15.9 GB 
[10/25 05:12:48][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6402 s / batch. (data: 8.38e-04). ETA=17:43:18, max mem: 15.9 GB 
[10/25 05:13:51][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 258.5326,	0.6176 s / batch. (data: 1.53e-04). ETA=17:04:41, max mem: 15.9 GB 
[10/25 05:13:55][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.03e-03, avg batch time: 0.6291, average train loss: 120.9362
[10/25 05:14:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 15.414, 0.2276 s / batch. (data: 3.00e-05)max mem: 15.91075 GB 
[10/25 05:14:55][INFO] visual_prompt:  316: Inference (val):avg data time: 5.54e-05, avg batch time: 0.2319, average loss: 16.6054
[10/25 05:14:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.30	
[10/25 05:14:55][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 25.0
[10/25 05:16:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 344.0775,	0.6200 s / batch. (data: 7.90e-04). ETA=17:07:30, max mem: 15.9 GB 
[10/25 05:17:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 121.8311,	0.6403 s / batch. (data: 8.42e-04). ETA=17:40:02, max mem: 15.9 GB 
[10/25 05:18:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 59.4446,	0.6126 s / batch. (data: 3.59e-04). ETA=16:53:09, max mem: 15.9 GB 
[10/25 05:19:09][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 210.7343,	0.6317 s / batch. (data: 8.30e-04). ETA=17:23:45, max mem: 15.9 GB 
[10/25 05:20:12][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 87.5238,	0.6369 s / batch. (data: 8.99e-04). ETA=17:31:14, max mem: 15.9 GB 
[10/25 05:21:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6189 s / batch. (data: 7.79e-04). ETA=17:00:30, max mem: 15.9 GB 
[10/25 05:22:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 504.9359,	0.6323 s / batch. (data: 7.30e-04). ETA=17:21:39, max mem: 15.9 GB 
[10/25 05:23:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 237.0805,	0.6340 s / batch. (data: 4.51e-03). ETA=17:23:23, max mem: 15.9 GB 
[10/25 05:24:23][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6399 s / batch. (data: 8.37e-04). ETA=17:32:03, max mem: 15.9 GB 
[10/25 05:25:26][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6176 s / batch. (data: 3.18e-04). ETA=16:54:13, max mem: 15.9 GB 
[10/25 05:26:29][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 91.3099,	0.6134 s / batch. (data: 1.97e-04). ETA=16:46:24, max mem: 15.9 GB 
[10/25 05:26:33][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.78e-03, avg batch time: 0.6307, average train loss: 125.8866
[10/25 05:27:23][INFO] visual_prompt:  303: 	Test 100/123. loss: 74.225, 0.2290 s / batch. (data: 2.79e-05)max mem: 15.91075 GB 
[10/25 05:27:33][INFO] visual_prompt:  316: Inference (val):avg data time: 4.03e-05, avg batch time: 0.2315, average loss: 67.2638
[10/25 05:27:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[10/25 05:27:33][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 24.9923853377387
[10/25 05:28:39][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 286.1913,	0.6110 s / batch. (data: 2.94e-04). ETA=16:41:24, max mem: 15.9 GB 
[10/25 05:29:42][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 45.6293,	0.6345 s / batch. (data: 7.95e-04). ETA=17:18:50, max mem: 15.9 GB 
[10/25 05:30:45][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 165.1596,	0.6318 s / batch. (data: 3.05e-04). ETA=17:13:20, max mem: 15.9 GB 
[10/25 05:31:47][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 376.8125,	0.6444 s / batch. (data: 2.91e-04). ETA=17:32:56, max mem: 15.9 GB 
[10/25 05:32:50][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6280 s / batch. (data: 8.24e-04). ETA=17:05:03, max mem: 15.9 GB 
[10/25 05:33:53][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6107 s / batch. (data: 4.21e-04). ETA=16:35:45, max mem: 15.9 GB 
[10/25 05:34:56][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 176.7245,	0.6243 s / batch. (data: 9.01e-04). ETA=16:56:59, max mem: 15.9 GB 
[10/25 05:35:59][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 147.5689,	0.6132 s / batch. (data: 3.35e-04). ETA=16:37:48, max mem: 15.9 GB 
[10/25 05:37:01][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6314 s / batch. (data: 8.30e-04). ETA=17:06:27, max mem: 15.9 GB 
[10/25 05:38:04][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 82.8496,	0.6368 s / batch. (data: 7.93e-04). ETA=17:14:04, max mem: 15.9 GB 
[10/25 05:39:07][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 509.4506,	0.6125 s / batch. (data: 1.62e-04). ETA=16:33:41, max mem: 15.9 GB 
[10/25 05:39:11][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.12e-03, avg batch time: 0.6303, average train loss: 129.0668
[10/25 05:40:01][INFO] visual_prompt:  303: 	Test 100/123. loss: 8.788, 0.2245 s / batch. (data: 3.12e-05)max mem: 15.91075 GB 
[10/25 05:40:11][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2308, average loss: 9.8244
[10/25 05:40:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.87	
[10/25 05:40:11][INFO] visual_prompt:   36: Best epoch 12: best metric: -9.824
[10/25 05:40:11][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 24.969550628247802
[10/25 05:41:16][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6119 s / batch. (data: 3.62e-04). ETA=16:31:30, max mem: 15.9 GB 
[10/25 05:42:19][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 45.0675,	0.6362 s / batch. (data: 7.91e-04). ETA=17:09:51, max mem: 15.9 GB 
[10/25 05:43:22][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6222 s / batch. (data: 7.95e-04). ETA=16:46:07, max mem: 15.9 GB 
[10/25 05:44:25][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 149.4167,	0.6318 s / batch. (data: 8.51e-04). ETA=17:00:37, max mem: 15.9 GB 
[10/25 05:45:27][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6131 s / batch. (data: 2.88e-04). ETA=16:29:27, max mem: 15.9 GB 
[10/25 05:46:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 119.6193,	0.6160 s / batch. (data: 3.74e-04). ETA=16:33:01, max mem: 15.9 GB 
[10/25 05:47:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6200 s / batch. (data: 2.96e-04). ETA=16:38:28, max mem: 15.9 GB 
[10/25 05:48:36][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 4.7134,	0.6291 s / batch. (data: 2.78e-04). ETA=16:52:08, max mem: 15.9 GB 
[10/25 05:49:39][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6295 s / batch. (data: 7.58e-04). ETA=16:51:42, max mem: 15.9 GB 
[10/25 05:50:42][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6307 s / batch. (data: 8.06e-04). ETA=16:52:35, max mem: 15.9 GB 
[10/25 05:51:45][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 132.4709,	0.6126 s / batch. (data: 2.07e-04). ETA=16:22:33, max mem: 15.9 GB 
[10/25 05:51:49][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.69e-03, avg batch time: 0.6304, average train loss: 133.6009
[10/25 05:52:38][INFO] visual_prompt:  303: 	Test 100/123. loss: 4.657, 0.2252 s / batch. (data: 3.05e-05)max mem: 15.91075 GB 
[10/25 05:52:49][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2315, average loss: 5.6895
[10/25 05:52:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.32	
[10/25 05:52:49][INFO] visual_prompt:   36: Best epoch 13: best metric: -5.690
[10/25 05:52:49][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 24.931523692103415
[10/25 05:53:54][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 26.5557,	0.6172 s / batch. (data: 3.53e-04). ETA=16:28:51, max mem: 15.9 GB 
[10/25 05:54:57][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 75.8408,	0.6132 s / batch. (data: 3.24e-04). ETA=16:21:16, max mem: 15.9 GB 
[10/25 05:56:00][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 93.5661,	0.6263 s / batch. (data: 3.29e-04). ETA=16:41:16, max mem: 15.9 GB 
[10/25 05:57:03][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6233 s / batch. (data: 9.05e-04). ETA=16:35:26, max mem: 15.9 GB 
[10/25 05:58:06][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 51.6373,	0.6304 s / batch. (data: 8.20e-04). ETA=16:45:40, max mem: 15.9 GB 
[10/25 05:59:09][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 23.8472,	0.6305 s / batch. (data: 3.26e-04). ETA=16:44:46, max mem: 15.9 GB 
[10/25 06:00:12][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 210.4142,	0.6230 s / batch. (data: 3.19e-04). ETA=16:31:46, max mem: 15.9 GB 
[10/25 06:01:14][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 124.1098,	0.6149 s / batch. (data: 2.74e-04). ETA=16:17:50, max mem: 15.9 GB 
[10/25 06:02:17][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 188.7702,	0.6203 s / batch. (data: 3.18e-04). ETA=16:25:28, max mem: 15.9 GB 
[10/25 06:03:20][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 208.9030,	0.6288 s / batch. (data: 5.43e-03). ETA=16:37:59, max mem: 15.9 GB 
[10/25 06:04:23][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 17.5410,	0.6189 s / batch. (data: 1.47e-04). ETA=16:21:13, max mem: 15.9 GB 
[10/25 06:04:27][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.54e-03, avg batch time: 0.6310, average train loss: 114.6824
[10/25 06:05:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 83.529, 0.2254 s / batch. (data: 3.91e-05)max mem: 15.91075 GB 
[10/25 06:05:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2325, average loss: 75.0515
[10/25 06:05:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.04	
[10/25 06:05:27][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 24.87835085926963
[10/25 06:06:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 48.1864,	0.6507 s / batch. (data: 8.67e-04). ETA=17:10:31, max mem: 15.9 GB 
[10/25 06:07:34][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 67.7711,	0.6244 s / batch. (data: 3.46e-04). ETA=16:27:45, max mem: 15.9 GB 
[10/25 06:08:37][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 79.1674,	0.6264 s / batch. (data: 3.18e-04). ETA=16:29:48, max mem: 15.9 GB 
[10/25 06:09:40][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6329 s / batch. (data: 8.21e-04). ETA=16:39:03, max mem: 15.9 GB 
[10/25 06:10:42][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6296 s / batch. (data: 7.91e-04). ETA=16:32:51, max mem: 15.9 GB 
[10/25 06:11:45][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 94.6962,	0.6264 s / batch. (data: 3.23e-04). ETA=16:26:49, max mem: 15.9 GB 
[10/25 06:12:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 102.3650,	0.6269 s / batch. (data: 7.43e-04). ETA=16:26:26, max mem: 15.9 GB 
[10/25 06:13:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 26.2719,	0.6187 s / batch. (data: 3.39e-04). ETA=16:12:30, max mem: 15.9 GB 
[10/25 06:14:54][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 144.4017,	0.6431 s / batch. (data: 5.47e-03). ETA=16:49:54, max mem: 15.9 GB 
[10/25 06:15:57][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 55.4786,	0.6482 s / batch. (data: 5.89e-03). ETA=16:56:44, max mem: 15.9 GB 
[10/25 06:17:00][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 99.6858,	0.6115 s / batch. (data: 1.89e-04). ETA=15:58:09, max mem: 15.9 GB 
[10/25 06:17:03][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 4.32e-03, avg batch time: 0.6297, average train loss: 130.5085
[10/25 06:17:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 51.817, 0.2642 s / batch. (data: 4.10e-05)max mem: 15.91075 GB 
[10/25 06:18:04][INFO] visual_prompt:  316: Inference (val):avg data time: 4.16e-05, avg batch time: 0.2319, average loss: 46.5546
[10/25 06:18:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.07	
[10/25 06:18:04][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 24.8100969126526
[10/25 06:19:08][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6328 s / batch. (data: 8.33e-04). ETA=16:30:28, max mem: 15.9 GB 
[10/25 06:20:11][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 200.5121,	0.6259 s / batch. (data: 3.03e-04). ETA=16:18:38, max mem: 15.9 GB 
[10/25 06:21:14][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 255.1569,	0.6174 s / batch. (data: 3.41e-04). ETA=16:04:16, max mem: 15.9 GB 
[10/25 06:22:17][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 159.6145,	0.6372 s / batch. (data: 8.31e-04). ETA=16:34:06, max mem: 15.9 GB 
[10/25 06:23:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 110.8159,	0.6254 s / batch. (data: 5.45e-03). ETA=16:14:38, max mem: 15.9 GB 
[10/25 06:24:23][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6231 s / batch. (data: 7.93e-04). ETA=16:10:03, max mem: 15.9 GB 
[10/25 06:25:26][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 80.0893,	0.6355 s / batch. (data: 3.24e-04). ETA=16:28:20, max mem: 15.9 GB 
[10/25 06:26:29][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 133.6008,	0.6320 s / batch. (data: 7.95e-03). ETA=16:21:51, max mem: 15.9 GB 
[10/25 06:27:31][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 57.2924,	0.6315 s / batch. (data: 8.35e-04). ETA=16:19:57, max mem: 15.9 GB 
[10/25 06:28:34][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6073 s / batch. (data: 3.16e-04). ETA=15:41:24, max mem: 15.9 GB 
[10/25 06:29:37][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 435.4764,	0.6185 s / batch. (data: 1.64e-04). ETA=15:57:42, max mem: 15.9 GB 
[10/25 06:29:41][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 4.18e-03, avg batch time: 0.6303, average train loss: 137.7743
[10/25 06:30:30][INFO] visual_prompt:  303: 	Test 100/123. loss: 89.621, 0.2382 s / batch. (data: 2.88e-05)max mem: 15.91075 GB 
[10/25 06:30:41][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2330, average loss: 96.0274
[10/25 06:30:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.38	
[10/25 06:30:41][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 24.72684500917257
[10/25 06:31:47][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6349 s / batch. (data: 8.04e-04). ETA=16:21:58, max mem: 15.9 GB 
[10/25 06:32:50][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 32.1779,	0.6280 s / batch. (data: 9.97e-04). ETA=16:10:14, max mem: 15.9 GB 
[10/25 06:33:52][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 362.5815,	0.6308 s / batch. (data: 1.20e-02). ETA=16:13:35, max mem: 15.9 GB 
[10/25 06:34:55][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6198 s / batch. (data: 7.16e-04). ETA=15:55:29, max mem: 15.9 GB 
[10/25 06:35:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 91.7561,	0.6300 s / batch. (data: 7.66e-04). ETA=16:10:10, max mem: 15.9 GB 
[10/25 06:37:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 66.1710,	0.6186 s / batch. (data: 5.51e-03). ETA=15:51:38, max mem: 15.9 GB 
[10/25 06:38:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 123.6458,	0.6263 s / batch. (data: 8.30e-04). ETA=16:02:26, max mem: 15.9 GB 
[10/25 06:39:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 105.6989,	0.6355 s / batch. (data: 1.64e-02). ETA=16:15:35, max mem: 15.9 GB 
[10/25 06:40:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6197 s / batch. (data: 8.06e-04). ETA=15:50:19, max mem: 15.9 GB 
[10/25 06:41:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6089 s / batch. (data: 3.48e-04). ETA=15:32:37, max mem: 15.9 GB 
[10/25 06:42:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6081 s / batch. (data: 1.40e-04). ETA=15:30:23, max mem: 15.9 GB 
[10/25 06:42:19][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.81e-03, avg batch time: 0.6308, average train loss: 108.9413
[10/25 06:43:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 15.520, 0.2278 s / batch. (data: 3.15e-05)max mem: 15.91075 GB 
[10/25 06:43:19][INFO] visual_prompt:  316: Inference (val):avg data time: 4.45e-05, avg batch time: 0.2319, average loss: 14.5941
[10/25 06:43:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.49	
[10/25 06:43:19][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 24.628696578449954
[10/25 06:44:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 365.1511,	0.6157 s / batch. (data: 3.30e-04). ETA=15:40:59, max mem: 15.9 GB 
[10/25 06:45:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 237.2891,	0.6430 s / batch. (data: 8.26e-04). ETA=16:21:36, max mem: 15.9 GB 
[10/25 06:46:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 882.7492,	0.6509 s / batch. (data: 1.10e-02). ETA=16:32:35, max mem: 15.9 GB 
[10/25 06:47:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 247.4934,	0.6139 s / batch. (data: 3.23e-04). ETA=15:35:07, max mem: 15.9 GB 
[10/25 06:48:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6259 s / batch. (data: 4.05e-04). ETA=15:52:27, max mem: 15.9 GB 
[10/25 06:49:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6207 s / batch. (data: 3.15e-04). ETA=15:43:27, max mem: 15.9 GB 
[10/25 06:50:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6178 s / batch. (data: 3.14e-04). ETA=15:37:56, max mem: 15.9 GB 
[10/25 06:51:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 57.3580,	0.6304 s / batch. (data: 7.33e-04). ETA=15:56:09, max mem: 15.9 GB 
[10/25 06:52:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 24.4496,	0.6530 s / batch. (data: 2.75e-02). ETA=16:29:13, max mem: 15.9 GB 
[10/25 06:53:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 93.4380,	0.6136 s / batch. (data: 3.48e-04). ETA=15:28:34, max mem: 15.9 GB 
[10/25 06:54:52][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6067 s / batch. (data: 1.45e-04). ETA=15:17:05, max mem: 15.9 GB 
[10/25 06:54:56][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.27e-03, avg batch time: 0.6300, average train loss: 107.1602
[10/25 06:55:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 99.174, 0.2248 s / batch. (data: 3.17e-05)max mem: 15.91075 GB 
[10/25 06:55:57][INFO] visual_prompt:  316: Inference (val):avg data time: 4.10e-05, avg batch time: 0.2319, average loss: 88.6203
[10/25 06:55:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.88	
[10/25 06:55:57][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 24.515771199228986
[10/25 06:57:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 123.7441,	0.6291 s / batch. (data: 8.16e-04). ETA=15:49:51, max mem: 15.9 GB 
[10/25 06:58:04][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 113.8206,	0.6113 s / batch. (data: 3.75e-04). ETA=15:22:01, max mem: 15.9 GB 
[10/25 06:59:07][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 76.2709,	0.6596 s / batch. (data: 4.20e-02). ETA=16:33:46, max mem: 15.9 GB 
[10/25 07:00:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 73.4840,	0.6159 s / batch. (data: 2.93e-04). ETA=15:26:54, max mem: 15.9 GB 
[10/25 07:01:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6242 s / batch. (data: 8.12e-04). ETA=15:38:17, max mem: 15.9 GB 
[10/25 07:02:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6203 s / batch. (data: 7.83e-04). ETA=15:31:27, max mem: 15.9 GB 
[10/25 07:03:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 29.4370,	0.6327 s / batch. (data: 9.58e-04). ETA=15:48:54, max mem: 15.9 GB 
[10/25 07:04:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 126.0950,	0.6298 s / batch. (data: 7.74e-04). ETA=15:43:38, max mem: 15.9 GB 
[10/25 07:05:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6140 s / batch. (data: 3.10e-04). ETA=15:18:52, max mem: 15.9 GB 
[10/25 07:06:27][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6445 s / batch. (data: 5.91e-03). ETA=16:03:24, max mem: 15.9 GB 
[10/25 07:07:30][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6064 s / batch. (data: 1.86e-04). ETA=15:05:30, max mem: 15.9 GB 
[10/25 07:07:33][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.62e-03, avg batch time: 0.6301, average train loss: 125.9688
[10/25 07:08:23][INFO] visual_prompt:  303: 	Test 100/123. loss: 70.280, 0.2301 s / batch. (data: 4.08e-05)max mem: 15.91075 GB 
[10/25 07:08:34][INFO] visual_prompt:  316: Inference (val):avg data time: 4.31e-05, avg batch time: 0.2322, average loss: 64.5641
[10/25 07:08:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.40	
[10/25 07:08:34][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 24.38820645368942
[10/25 07:09:39][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 65.5329,	0.6124 s / batch. (data: 3.60e-04). ETA=15:13:23, max mem: 15.9 GB 
[10/25 07:10:42][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 113.4851,	0.6298 s / batch. (data: 8.18e-04). ETA=15:38:15, max mem: 15.9 GB 
[10/25 07:11:45][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 5.8671,	0.6436 s / batch. (data: 9.03e-04). ETA=15:57:45, max mem: 15.9 GB 
[10/25 07:12:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 227.3198,	0.6464 s / batch. (data: 5.92e-03). ETA=16:00:49, max mem: 15.9 GB 
[10/25 07:13:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 29.0313,	0.6428 s / batch. (data: 8.16e-04). ETA=15:54:27, max mem: 15.9 GB 
[10/25 07:14:54][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 495.0229,	0.6292 s / batch. (data: 1.20e-02). ETA=15:33:10, max mem: 15.9 GB 
[10/25 07:15:57][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6081 s / batch. (data: 3.36e-04). ETA=15:00:54, max mem: 15.9 GB 
[10/25 07:17:00][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6233 s / batch. (data: 8.28e-04). ETA=15:22:19, max mem: 15.9 GB 
[10/25 07:18:02][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 277.5616,	0.6285 s / batch. (data: 7.69e-04). ETA=15:28:58, max mem: 15.9 GB 
[10/25 07:19:05][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 67.5194,	0.6170 s / batch. (data: 3.06e-04). ETA=15:10:54, max mem: 15.9 GB 
[10/25 07:20:08][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 199.0411,	0.6184 s / batch. (data: 1.37e-04). ETA=15:12:03, max mem: 15.9 GB 
[10/25 07:20:12][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.49e-03, avg batch time: 0.6313, average train loss: 105.9228
[10/25 07:21:02][INFO] visual_prompt:  303: 	Test 100/123. loss: 27.017, 0.2255 s / batch. (data: 4.67e-05)max mem: 15.91075 GB 
[10/25 07:21:12][INFO] visual_prompt:  316: Inference (val):avg data time: 4.08e-05, avg batch time: 0.2321, average loss: 24.2843
[10/25 07:21:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.32	
[10/25 07:21:12][INFO] visual_prompt:   42: Stopping early.
