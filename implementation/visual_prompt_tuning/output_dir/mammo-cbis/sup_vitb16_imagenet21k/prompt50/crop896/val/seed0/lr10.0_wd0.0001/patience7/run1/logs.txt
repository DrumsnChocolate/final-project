[10/25 21:47:46][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/25 21:47:46][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/25 21:47:46][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/25 21:47:46][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/25 21:47:46][INFO] visual_prompt:  108: Training with config:
[10/25 21:47:46][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/25 21:47:46][INFO] visual_prompt:   55: Loading training data...
[10/25 21:47:46][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/25 21:47:46][INFO] visual_prompt:   57: Loading validation data...
[10/25 21:47:46][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/25 21:47:46][INFO] visual_prompt:   38: Constructing models...
[10/25 21:47:49][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/25 21:47:49][INFO] visual_prompt:   54: tuned percent:0.522
[10/25 21:47:50][INFO] visual_prompt:   40: Device used for model: 0
[10/25 21:47:50][INFO] visual_prompt:   40: Setting up Evaluator...
[10/25 21:47:50][INFO] visual_prompt:   42: Setting up Trainer...
[10/25 21:47:50][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/25 21:47:50][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/25 21:48:56][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.8353,	0.6177 s / batch. (data: 7.62e-04). ETA=18:57:41, max mem: 15.9 GB 
[10/25 21:49:59][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2683,	0.6258 s / batch. (data: 5.42e-03). ETA=19:11:33, max mem: 15.9 GB 
[10/25 21:51:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0252,	0.6180 s / batch. (data: 3.18e-04). ETA=18:56:01, max mem: 15.9 GB 
[10/25 21:52:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.9968,	0.6202 s / batch. (data: 3.46e-04). ETA=18:59:11, max mem: 15.9 GB 
[10/25 21:53:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.3889,	0.6474 s / batch. (data: 5.48e-03). ETA=19:47:59, max mem: 15.9 GB 
[10/25 21:54:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3294,	0.6189 s / batch. (data: 2.96e-04). ETA=18:54:43, max mem: 15.9 GB 
[10/25 21:55:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.5781,	0.6191 s / batch. (data: 7.99e-04). ETA=18:54:00, max mem: 15.9 GB 
[10/25 21:56:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0815,	0.6353 s / batch. (data: 3.07e-04). ETA=19:22:32, max mem: 15.9 GB 
[10/25 21:57:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1448,	0.6237 s / batch. (data: 2.97e-04). ETA=19:00:15, max mem: 15.9 GB 
[10/25 21:58:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.9846,	0.6310 s / batch. (data: 3.22e-04). ETA=19:12:38, max mem: 15.9 GB 
[10/25 21:59:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.4255,	0.6183 s / batch. (data: 2.29e-04). ETA=18:48:21, max mem: 15.9 GB 
[10/25 21:59:36][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 5.92e-03, avg batch time: 0.6383, average train loss: 1.4028
[10/25 22:00:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.529, 0.2439 s / batch. (data: 2.57e-05)max mem: 15.91637 GB 
[10/25 22:00:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2334, average loss: 1.3505
[10/25 22:00:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[10/25 22:00:39][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 1.0
[10/25 22:01:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 23.4051,	0.6324 s / batch. (data: 5.45e-03). ETA=19:13:05, max mem: 15.9 GB 
[10/25 22:02:47][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 10.2662,	0.6191 s / batch. (data: 3.02e-04). ETA=18:47:43, max mem: 15.9 GB 
[10/25 22:03:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0126,	0.6240 s / batch. (data: 3.30e-04). ETA=18:55:39, max mem: 15.9 GB 
[10/25 22:04:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6180 s / batch. (data: 2.89e-04). ETA=18:43:38, max mem: 15.9 GB 
[10/25 22:05:58][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 11.3309,	0.6352 s / batch. (data: 8.02e-03). ETA=19:13:52, max mem: 15.9 GB 
[10/25 22:07:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 4.1070,	0.6269 s / batch. (data: 3.52e-04). ETA=18:57:47, max mem: 15.9 GB 
[10/25 22:08:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6185 s / batch. (data: 3.21e-04). ETA=18:41:24, max mem: 15.9 GB 
[10/25 22:09:08][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 3.1605,	0.6478 s / batch. (data: 1.57e-02). ETA=19:33:28, max mem: 15.9 GB 
[10/25 22:10:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 4.6072,	0.6424 s / batch. (data: 8.05e-04). ETA=19:22:37, max mem: 15.9 GB 
[10/25 22:11:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6185 s / batch. (data: 3.13e-04). ETA=18:38:25, max mem: 15.9 GB 
[10/25 22:12:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6168 s / batch. (data: 1.64e-04). ETA=18:34:15, max mem: 15.9 GB 
[10/25 22:12:22][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 5.16e-03, avg batch time: 0.6359, average train loss: 6.6899
[10/25 22:13:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 12.414, 0.2277 s / batch. (data: 3.19e-05)max mem: 15.91637 GB 
[10/25 22:13:25][INFO] visual_prompt:  316: Inference (val):avg data time: 4.18e-05, avg batch time: 0.2329, average loss: 11.1894
[10/25 22:13:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.37	
[10/25 22:13:25][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 2.0
[10/25 22:14:32][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0001,	0.6325 s / batch. (data: 7.77e-04). ETA=19:01:27, max mem: 15.9 GB 
[10/25 22:15:35][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6339 s / batch. (data: 3.29e-04). ETA=19:03:01, max mem: 15.9 GB 
[10/25 22:16:39][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6596 s / batch. (data: 3.80e-02). ETA=19:48:11, max mem: 15.9 GB 
[10/25 22:17:42][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.4691,	0.6206 s / batch. (data: 4.77e-04). ETA=18:36:56, max mem: 15.9 GB 
[10/25 22:18:46][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 11.6193,	0.6322 s / batch. (data: 1.30e-02). ETA=18:56:42, max mem: 15.9 GB 
[10/25 22:19:49][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6505 s / batch. (data: 3.26e-02). ETA=19:28:34, max mem: 15.9 GB 
[10/25 22:20:53][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3884,	0.6342 s / batch. (data: 8.60e-04). ETA=18:58:14, max mem: 15.9 GB 
[10/25 22:21:56][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0009,	0.6405 s / batch. (data: 1.25e-02). ETA=19:08:31, max mem: 15.9 GB 
[10/25 22:23:00][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 9.5186,	0.6489 s / batch. (data: 8.72e-04). ETA=19:22:32, max mem: 15.9 GB 
[10/25 22:24:03][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 8.5267,	0.6189 s / batch. (data: 3.21e-04). ETA=18:27:37, max mem: 15.9 GB 
[10/25 22:25:07][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 4.7125,	0.6193 s / batch. (data: 1.75e-04). ETA=18:27:20, max mem: 15.9 GB 
[10/25 22:25:11][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 6.12e-03, avg batch time: 0.6377, average train loss: 7.9460
[10/25 22:26:03][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.927, 0.2247 s / batch. (data: 4.32e-05)max mem: 15.91637 GB 
[10/25 22:26:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.12e-05, avg batch time: 0.2327, average loss: 6.5348
[10/25 22:26:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.76	
[10/25 22:26:14][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 3.0
[10/25 22:27:19][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0252,	0.6393 s / batch. (data: 3.19e-04). ETA=19:02:02, max mem: 15.9 GB 
[10/25 22:28:23][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 55.2922,	0.6185 s / batch. (data: 3.12e-04). ETA=18:23:52, max mem: 15.9 GB 
[10/25 22:29:26][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.0916,	0.6415 s / batch. (data: 1.10e-02). ETA=19:03:45, max mem: 15.9 GB 
[10/25 22:30:30][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.6251,	0.6213 s / batch. (data: 3.03e-04). ETA=18:26:42, max mem: 15.9 GB 
[10/25 22:31:33][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 18.6333,	0.6432 s / batch. (data: 2.50e-02). ETA=19:04:43, max mem: 15.9 GB 
[10/25 22:32:36][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 8.7875,	0.6198 s / batch. (data: 3.21e-04). ETA=18:22:06, max mem: 15.9 GB 
[10/25 22:33:40][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 38.2799,	0.6514 s / batch. (data: 8.71e-04). ETA=19:17:10, max mem: 15.9 GB 
[10/25 22:34:43][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0151,	0.6454 s / batch. (data: 7.95e-04). ETA=19:05:24, max mem: 15.9 GB 
[10/25 22:35:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 30.3358,	0.6299 s / batch. (data: 2.89e-04). ETA=18:36:45, max mem: 15.9 GB 
[10/25 22:36:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6447 s / batch. (data: 3.57e-04). ETA=19:01:59, max mem: 15.9 GB 
[10/25 22:37:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 16.4115,	0.6184 s / batch. (data: 1.66e-04). ETA=18:14:19, max mem: 15.9 GB 
[10/25 22:37:57][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 5.25e-03, avg batch time: 0.6360, average train loss: 12.8852
[10/25 22:38:49][INFO] visual_prompt:  303: 	Test 100/123. loss: 7.301, 0.2364 s / batch. (data: 3.34e-05)max mem: 15.91637 GB 
[10/25 22:39:00][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-05, avg batch time: 0.2327, average loss: 6.5741
[10/25 22:39:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.95	
[10/25 22:39:00][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 4.0
[10/25 22:40:06][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 17.7233,	0.6397 s / batch. (data: 8.25e-04). ETA=18:50:54, max mem: 15.9 GB 
[10/25 22:41:10][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6290 s / batch. (data: 3.28e-04). ETA=18:31:02, max mem: 15.9 GB 
[10/25 22:42:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 31.3137,	0.6173 s / batch. (data: 3.32e-04). ETA=18:09:14, max mem: 15.9 GB 
[10/25 22:43:19][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 13.1205,	0.6475 s / batch. (data: 5.93e-03). ETA=19:01:27, max mem: 15.9 GB 
[10/25 22:44:23][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6576,	0.6452 s / batch. (data: 8.16e-04). ETA=18:56:17, max mem: 15.9 GB 
[10/25 22:45:26][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6294 s / batch. (data: 8.32e-04). ETA=18:27:25, max mem: 15.9 GB 
[10/25 22:46:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 16.0873,	0.6330 s / batch. (data: 2.57e-04). ETA=18:32:42, max mem: 15.9 GB 
[10/25 22:47:40][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 6.3810,	0.6245 s / batch. (data: 3.16e-04). ETA=18:16:46, max mem: 15.9 GB 
[10/25 22:48:44][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 17.9051,	0.6399 s / batch. (data: 8.20e-04). ETA=18:42:49, max mem: 15.9 GB 
[10/25 22:49:47][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 23.5516,	0.6240 s / batch. (data: 7.66e-04). ETA=18:13:48, max mem: 15.9 GB 
[10/25 22:50:50][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 23.4452,	0.6182 s / batch. (data: 1.74e-04). ETA=18:02:41, max mem: 15.9 GB 
[10/25 22:50:54][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 1.51e-02, avg batch time: 0.6449, average train loss: 20.8661
[10/25 22:51:44][INFO] visual_prompt:  303: 	Test 100/123. loss: 32.045, 0.2357 s / batch. (data: 3.10e-05)max mem: 15.91637 GB 
[10/25 22:51:55][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2316, average loss: 28.7970
[10/25 22:51:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.38	
[10/25 22:51:55][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 5.0
[10/25 22:53:00][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 48.4565,	0.6342 s / batch. (data: 8.47e-04). ETA=18:29:28, max mem: 15.9 GB 
[10/25 22:54:03][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6176 s / batch. (data: 3.30e-04). ETA=17:59:23, max mem: 15.9 GB 
[10/25 22:55:06][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6387 s / batch. (data: 7.98e-04). ETA=18:35:16, max mem: 15.9 GB 
[10/25 22:56:10][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 27.7933,	0.6197 s / batch. (data: 2.70e-04). ETA=18:01:02, max mem: 15.9 GB 
[10/25 22:57:13][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 9.5212,	0.6315 s / batch. (data: 3.24e-04). ETA=18:20:38, max mem: 15.9 GB 
[10/25 22:58:16][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6491 s / batch. (data: 8.15e-04). ETA=18:50:09, max mem: 15.9 GB 
[10/25 22:59:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 77.8168,	0.6541 s / batch. (data: 1.61e-02). ETA=18:57:51, max mem: 15.9 GB 
[10/25 23:00:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 67.5725,	0.6249 s / batch. (data: 3.16e-04). ETA=18:05:59, max mem: 15.9 GB 
[10/25 23:01:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 98.2886,	0.6473 s / batch. (data: 1.60e-02). ETA=18:43:53, max mem: 15.9 GB 
[10/25 23:02:29][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6369 s / batch. (data: 8.18e-04). ETA=18:24:39, max mem: 15.9 GB 
[10/25 23:03:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6067 s / batch. (data: 1.39e-04). ETA=17:31:19, max mem: 15.9 GB 
[10/25 23:03:36][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.16e-03, avg batch time: 0.6339, average train loss: 23.8353
[10/25 23:04:26][INFO] visual_prompt:  303: 	Test 100/123. loss: 5.175, 0.2258 s / batch. (data: 2.86e-05)max mem: 15.91637 GB 
[10/25 23:04:36][INFO] visual_prompt:  316: Inference (val):avg data time: 1.13e-04, avg batch time: 0.2325, average loss: 4.6970
[10/25 23:04:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[10/25 23:04:36][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 6.0
[10/25 23:05:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 20.0877,	0.6170 s / batch. (data: 3.39e-04). ETA=17:48:01, max mem: 15.9 GB 
[10/25 23:06:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6169 s / batch. (data: 2.75e-04). ETA=17:46:50, max mem: 15.9 GB 
[10/25 23:07:48][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 18.2126,	0.6360 s / batch. (data: 3.39e-04). ETA=18:18:50, max mem: 15.9 GB 
[10/25 23:08:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 40.3543,	0.6156 s / batch. (data: 3.53e-04). ETA=17:42:35, max mem: 15.9 GB 
[10/25 23:09:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 62.3014,	0.6401 s / batch. (data: 3.14e-04). ETA=18:23:45, max mem: 15.9 GB 
[10/25 23:10:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 92.1608,	0.6211 s / batch. (data: 3.36e-04). ETA=17:49:57, max mem: 15.9 GB 
[10/25 23:12:01][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 77.1923,	0.6406 s / batch. (data: 9.00e-04). ETA=18:22:31, max mem: 15.9 GB 
[10/25 23:13:04][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 32.9716,	0.6183 s / batch. (data: 3.82e-04). ETA=17:43:03, max mem: 15.9 GB 
[10/25 23:14:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 14.3400,	0.6334 s / batch. (data: 2.62e-04). ETA=18:07:58, max mem: 15.9 GB 
[10/25 23:15:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 12.0723,	0.6174 s / batch. (data: 2.65e-04). ETA=17:39:30, max mem: 15.9 GB 
[10/25 23:16:13][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 16.7959,	0.6177 s / batch. (data: 1.50e-04). ETA=17:38:56, max mem: 15.9 GB 
[10/25 23:16:17][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 4.16e-03, avg batch time: 0.6329, average train loss: 30.3053
[10/25 23:17:07][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.747, 0.2309 s / batch. (data: 3.00e-05)max mem: 15.91637 GB 
[10/25 23:17:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-05, avg batch time: 0.2322, average loss: 0.8892
[10/25 23:17:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.69	
[10/25 23:17:17][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 7.0
[10/25 23:18:22][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 55.1054,	0.6227 s / batch. (data: 2.93e-04). ETA=17:46:22, max mem: 15.9 GB 
[10/25 23:19:25][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 24.4395,	0.6214 s / batch. (data: 3.09e-04). ETA=17:43:14, max mem: 15.9 GB 
[10/25 23:20:28][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 51.9736,	0.6474 s / batch. (data: 8.34e-04). ETA=18:26:37, max mem: 15.9 GB 
[10/25 23:21:32][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6081 s / batch. (data: 2.39e-04). ETA=17:18:21, max mem: 15.9 GB 
[10/25 23:22:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6341 s / batch. (data: 7.98e-04). ETA=18:01:45, max mem: 15.9 GB 
[10/25 23:23:38][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6440 s / batch. (data: 7.44e-04). ETA=18:17:35, max mem: 15.9 GB 
[10/25 23:24:41][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 48.4959,	0.6125 s / batch. (data: 3.42e-04). ETA=17:22:55, max mem: 15.9 GB 
[10/25 23:25:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 6.7818,	0.6560 s / batch. (data: 8.26e-04). ETA=18:35:46, max mem: 15.9 GB 
[10/25 23:26:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6075 s / batch. (data: 4.49e-04). ETA=17:12:19, max mem: 15.9 GB 
[10/25 23:27:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 269.4610,	0.6319 s / batch. (data: 1.22e-03). ETA=17:52:42, max mem: 15.9 GB 
[10/25 23:28:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 39.7767,	0.6188 s / batch. (data: 1.68e-04). ETA=17:29:31, max mem: 15.9 GB 
[10/25 23:28:57][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 4.51e-03, avg batch time: 0.6327, average train loss: 34.4624
[10/25 23:29:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.842, 0.2346 s / batch. (data: 2.74e-05)max mem: 15.91637 GB 
[10/25 23:29:57][INFO] visual_prompt:  316: Inference (val):avg data time: 4.16e-05, avg batch time: 0.2324, average loss: 0.7895
[10/25 23:29:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.89	
[10/25 23:29:57][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 8.0
[10/25 23:31:02][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 282.3400,	0.6170 s / batch. (data: 3.27e-04). ETA=17:25:22, max mem: 15.9 GB 
[10/25 23:32:05][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6158 s / batch. (data: 2.72e-04). ETA=17:22:17, max mem: 15.9 GB 
[10/25 23:33:08][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 42.3178,	0.6156 s / batch. (data: 3.40e-04). ETA=17:20:56, max mem: 15.9 GB 
[10/25 23:34:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6390 s / batch. (data: 2.21e-02). ETA=17:59:28, max mem: 15.9 GB 
[10/25 23:35:15][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 33.8147,	0.6679 s / batch. (data: 8.37e-04). ETA=18:47:10, max mem: 15.9 GB 
[10/25 23:36:18][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 26.9132,	0.6294 s / batch. (data: 7.81e-04). ETA=17:41:01, max mem: 15.9 GB 
[10/25 23:37:21][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6194 s / batch. (data: 3.24e-04). ETA=17:23:07, max mem: 15.9 GB 
[10/25 23:38:24][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 31.3857,	0.6416 s / batch. (data: 3.78e-04). ETA=17:59:32, max mem: 15.9 GB 
[10/25 23:39:28][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6400 s / batch. (data: 3.23e-04). ETA=17:55:46, max mem: 15.9 GB 
[10/25 23:40:31][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.7270,	0.6224 s / batch. (data: 3.18e-04). ETA=17:25:12, max mem: 15.9 GB 
[10/25 23:41:34][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 43.5190,	0.6141 s / batch. (data: 1.50e-04). ETA=17:10:09, max mem: 15.9 GB 
[10/25 23:41:37][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 4.55e-03, avg batch time: 0.6330, average train loss: 34.2270
[10/25 23:42:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 55.662, 0.2358 s / batch. (data: 2.88e-05)max mem: 15.91637 GB 
[10/25 23:42:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.2325, average loss: 61.0178
[10/25 23:42:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.92	
[10/25 23:42:38][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 9.0
[10/25 23:43:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 62.9277,	0.6284 s / batch. (data: 1.50e-02). ETA=17:33:05, max mem: 15.9 GB 
[10/25 23:44:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 261.8511,	0.6385 s / batch. (data: 5.97e-03). ETA=17:48:53, max mem: 15.9 GB 
[10/25 23:45:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 22.9044,	0.6182 s / batch. (data: 2.68e-04). ETA=17:13:51, max mem: 15.9 GB 
[10/25 23:46:53][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6250 s / batch. (data: 1.21e-03). ETA=17:24:10, max mem: 15.9 GB 
[10/25 23:47:56][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 13.3923,	0.6320 s / batch. (data: 2.99e-04). ETA=17:34:55, max mem: 15.9 GB 
[10/25 23:48:59][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 207.5486,	0.6393 s / batch. (data: 3.38e-04). ETA=17:46:01, max mem: 15.9 GB 
[10/25 23:50:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 69.2942,	0.6334 s / batch. (data: 3.36e-04). ETA=17:35:08, max mem: 15.9 GB 
[10/25 23:51:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 11.8580,	0.6326 s / batch. (data: 8.19e-04). ETA=17:32:46, max mem: 15.9 GB 
[10/25 23:52:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 47.4646,	0.6213 s / batch. (data: 3.22e-04). ETA=17:12:51, max mem: 15.9 GB 
[10/25 23:53:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6421 s / batch. (data: 8.37e-04). ETA=17:46:24, max mem: 15.9 GB 
[10/25 23:54:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6188 s / batch. (data: 1.67e-04). ETA=17:06:35, max mem: 15.9 GB 
[10/25 23:54:19][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 4.15e-03, avg batch time: 0.6335, average train loss: 41.1596
[10/25 23:55:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.375, 0.2357 s / batch. (data: 3.43e-05)max mem: 15.91637 GB 
[10/25 23:55:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2326, average loss: 1.4694
[10/25 23:55:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.33	
[10/25 23:55:19][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 10.0
[10/25 23:56:25][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 225.8642,	0.6600 s / batch. (data: 8.24e-04). ETA=18:13:48, max mem: 15.9 GB 
[10/25 23:57:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 12.5687,	0.6372 s / batch. (data: 6.04e-03). ETA=17:35:03, max mem: 15.9 GB 
[10/25 23:58:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 92.7959,	0.6141 s / batch. (data: 3.68e-04). ETA=16:55:39, max mem: 15.9 GB 
[10/25 23:59:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 56.8049,	0.6334 s / batch. (data: 7.89e-04). ETA=17:26:32, max mem: 15.9 GB 
[10/26 00:00:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 48.4839,	0.6391 s / batch. (data: 7.93e-04). ETA=17:34:53, max mem: 15.9 GB 
[10/26 00:01:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6150 s / batch. (data: 7.71e-04). ETA=16:54:07, max mem: 15.9 GB 
[10/26 00:02:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 142.5671,	0.6367 s / batch. (data: 7.91e-04). ETA=17:28:46, max mem: 15.9 GB 
[10/26 00:03:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 97.5416,	0.6316 s / batch. (data: 1.20e-02). ETA=17:19:19, max mem: 15.9 GB 
[10/26 00:04:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6360 s / batch. (data: 8.66e-04). ETA=17:25:31, max mem: 15.9 GB 
[10/26 00:05:52][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6328 s / batch. (data: 9.78e-04). ETA=17:19:13, max mem: 15.9 GB 
[10/26 00:06:55][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.1073,	0.6177 s / batch. (data: 1.47e-04). ETA=16:53:26, max mem: 15.9 GB 
[10/26 00:06:59][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.40e-03, avg batch time: 0.6322, average train loss: 38.1451
[10/26 00:07:49][INFO] visual_prompt:  303: 	Test 100/123. loss: 17.983, 0.2251 s / batch. (data: 2.69e-05)max mem: 15.91637 GB 
[10/26 00:07:59][INFO] visual_prompt:  316: Inference (val):avg data time: 2.05e-04, avg batch time: 0.2328, average loss: 16.1093
[10/26 00:07:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.12	
[10/26 00:07:59][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 9.996954135095478
[10/26 00:09:05][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6132 s / batch. (data: 3.17e-04). ETA=16:44:56, max mem: 15.9 GB 
[10/26 00:10:08][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 6.7429,	0.6176 s / batch. (data: 3.42e-04). ETA=16:51:04, max mem: 15.9 GB 
[10/26 00:11:11][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 121.7036,	0.6190 s / batch. (data: 3.36e-04). ETA=16:52:28, max mem: 15.9 GB 
[10/26 00:12:14][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6340 s / batch. (data: 8.27e-04). ETA=17:15:54, max mem: 15.9 GB 
[10/26 00:13:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6297 s / batch. (data: 1.37e-02). ETA=17:07:48, max mem: 15.9 GB 
[10/26 00:14:20][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6390 s / batch. (data: 7.61e-04). ETA=17:21:51, max mem: 15.9 GB 
[10/26 00:15:23][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 39.0259,	0.6324 s / batch. (data: 3.64e-04). ETA=17:10:08, max mem: 15.9 GB 
[10/26 00:16:27][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 59.7423,	0.6382 s / batch. (data: 7.58e-04). ETA=17:18:27, max mem: 15.9 GB 
[10/26 00:17:30][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 129.4753,	0.6368 s / batch. (data: 7.54e-04). ETA=17:15:07, max mem: 15.9 GB 
[10/26 00:18:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 27.3597,	0.6316 s / batch. (data: 7.78e-04). ETA=17:05:35, max mem: 15.9 GB 
[10/26 00:19:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 117.3780,	0.6137 s / batch. (data: 1.66e-04). ETA=16:35:36, max mem: 15.9 GB 
[10/26 00:19:39][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 5.14e-03, avg batch time: 0.6326, average train loss: 58.5446
[10/26 00:20:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 51.875, 0.2305 s / batch. (data: 2.79e-05)max mem: 15.91637 GB 
[10/26 00:20:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2325, average loss: 46.7708
[10/26 00:20:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.38	
[10/26 00:20:39][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 9.987820251299121
[10/26 00:21:45][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6322 s / batch. (data: 8.00e-04). ETA=17:04:30, max mem: 15.9 GB 
[10/26 00:22:48][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 97.3913,	0.6131 s / batch. (data: 3.35e-04). ETA=16:32:32, max mem: 15.9 GB 
[10/26 00:23:51][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0002,	0.6312 s / batch. (data: 3.22e-04). ETA=17:00:45, max mem: 15.9 GB 
[10/26 00:24:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0006,	0.6305 s / batch. (data: 8.29e-04). ETA=16:58:34, max mem: 15.9 GB 
[10/26 00:25:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6183 s / batch. (data: 3.10e-04). ETA=16:37:49, max mem: 15.9 GB 
[10/26 00:27:00][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 22.8785,	0.6182 s / batch. (data: 3.10e-04). ETA=16:36:36, max mem: 15.9 GB 
[10/26 00:28:03][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6266 s / batch. (data: 3.19e-04). ETA=16:49:11, max mem: 15.9 GB 
[10/26 00:29:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 13.7373,	0.6351 s / batch. (data: 8.34e-04). ETA=17:01:47, max mem: 15.9 GB 
[10/26 00:30:09][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 45.8830,	0.6188 s / batch. (data: 3.11e-04). ETA=16:34:30, max mem: 15.9 GB 
[10/26 00:31:12][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 29.0761,	0.6179 s / batch. (data: 3.33e-04). ETA=16:32:03, max mem: 15.9 GB 
[10/26 00:32:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 160.4080,	0.6131 s / batch. (data: 2.51e-04). ETA=16:23:12, max mem: 15.9 GB 
[10/26 00:32:19][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.39e-03, avg batch time: 0.6324, average train loss: 44.0732
[10/26 00:33:09][INFO] visual_prompt:  303: 	Test 100/123. loss: 33.977, 0.2318 s / batch. (data: 2.84e-05)max mem: 15.91637 GB 
[10/26 00:33:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.2324, average loss: 37.4344
[10/26 00:33:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.67	
[10/26 00:33:19][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 9.972609476841367
[10/26 00:34:25][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6276 s / batch. (data: 8.31e-04). ETA=16:45:26, max mem: 15.9 GB 
[10/26 00:35:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 27.7745,	0.6343 s / batch. (data: 7.92e-04). ETA=16:55:06, max mem: 15.9 GB 
[10/26 00:36:31][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 31.9543,	0.6400 s / batch. (data: 3.54e-04). ETA=17:03:08, max mem: 15.9 GB 
[10/26 00:37:34][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6363 s / batch. (data: 1.10e-02). ETA=16:56:06, max mem: 15.9 GB 
[10/26 00:38:37][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 13.9143,	0.6202 s / batch. (data: 3.22e-04). ETA=16:29:23, max mem: 15.9 GB 
[10/26 00:39:40][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 74.2771,	0.6398 s / batch. (data: 7.97e-04). ETA=16:59:38, max mem: 15.9 GB 
[10/26 00:40:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6106 s / batch. (data: 3.16e-04). ETA=16:12:07, max mem: 15.9 GB 
[10/26 00:41:46][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 82.3541,	0.6134 s / batch. (data: 3.40e-04). ETA=16:15:29, max mem: 15.9 GB 
[10/26 00:42:49][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 33.1998,	0.6350 s / batch. (data: 7.54e-04). ETA=16:48:44, max mem: 15.9 GB 
[10/26 00:43:53][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0000,	0.6383 s / batch. (data: 8.09e-04). ETA=16:53:00, max mem: 15.9 GB 
[10/26 00:44:56][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 16.3858,	0.6194 s / batch. (data: 1.63e-04). ETA=16:21:54, max mem: 15.9 GB 
[10/26 00:44:59][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.57e-03, avg batch time: 0.6330, average train loss: 44.7011
[10/26 00:45:50][INFO] visual_prompt:  303: 	Test 100/123. loss: 6.402, 0.2252 s / batch. (data: 4.51e-05)max mem: 15.91637 GB 
[10/26 00:46:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.2329, average loss: 5.8523
[10/26 00:46:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.74	
[10/26 00:46:00][INFO] visual_prompt:   36: Best epoch 14: best metric: -5.852
[10/26 00:46:00][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 9.951340343707852
[10/26 00:47:05][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 173.2571,	0.6224 s / batch. (data: 2.94e-04). ETA=16:25:38, max mem: 15.9 GB 
[10/26 00:48:08][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 32.4031,	0.6321 s / batch. (data: 8.70e-04). ETA=16:39:54, max mem: 15.9 GB 
[10/26 00:49:11][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 110.6741,	0.6238 s / batch. (data: 3.06e-04). ETA=16:25:47, max mem: 15.9 GB 
[10/26 00:50:14][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0000,	0.6206 s / batch. (data: 3.45e-04). ETA=16:19:42, max mem: 15.9 GB 
[10/26 00:51:17][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 19.8609,	0.6474 s / batch. (data: 7.35e-04). ETA=17:00:53, max mem: 15.9 GB 
[10/26 00:52:20][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 79.4410,	0.6135 s / batch. (data: 2.98e-04). ETA=16:06:21, max mem: 15.9 GB 
[10/26 00:53:23][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 28.4753,	0.6174 s / batch. (data: 2.95e-04). ETA=16:11:32, max mem: 15.9 GB 
[10/26 00:54:26][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 41.4774,	0.6400 s / batch. (data: 9.06e-04). ETA=16:45:58, max mem: 15.9 GB 
[10/26 00:55:29][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 66.3081,	0.6417 s / batch. (data: 2.50e-02). ETA=16:47:42, max mem: 15.9 GB 
[10/26 00:56:32][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 30.3896,	0.6184 s / batch. (data: 2.58e-04). ETA=16:09:59, max mem: 15.9 GB 
[10/26 00:57:35][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 256.6254,	0.6131 s / batch. (data: 1.54e-04). ETA=16:00:40, max mem: 15.9 GB 
[10/26 00:57:39][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 3.82e-03, avg batch time: 0.6319, average train loss: 51.0963
[10/26 00:58:29][INFO] visual_prompt:  303: 	Test 100/123. loss: 37.744, 0.2286 s / batch. (data: 3.89e-05)max mem: 15.91637 GB 
[10/26 00:58:39][INFO] visual_prompt:  316: Inference (val):avg data time: 4.02e-05, avg batch time: 0.2324, average loss: 41.6221
[10/26 00:58:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.18	
[10/26 00:58:39][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 9.924038765061042
[10/26 00:59:44][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6385 s / batch. (data: 2.73e-04). ETA=16:39:23, max mem: 15.9 GB 
[10/26 01:00:47][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 20.2677,	0.6434 s / batch. (data: 8.43e-04). ETA=16:45:52, max mem: 15.9 GB 
[10/26 01:01:50][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 60.8769,	0.6190 s / batch. (data: 3.26e-04). ETA=16:06:41, max mem: 15.9 GB 
[10/26 01:02:54][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 49.7493,	0.6245 s / batch. (data: 7.65e-04). ETA=16:14:19, max mem: 15.9 GB 
[10/26 01:03:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 53.7476,	0.6360 s / batch. (data: 3.11e-04). ETA=16:31:13, max mem: 15.9 GB 
[10/26 01:04:59][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 86.7203,	0.6240 s / batch. (data: 2.73e-04). ETA=16:11:29, max mem: 15.9 GB 
[10/26 01:06:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 39.2551,	0.6274 s / batch. (data: 7.79e-04). ETA=16:15:39, max mem: 15.9 GB 
[10/26 01:07:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 21.8632,	0.6298 s / batch. (data: 3.18e-04). ETA=16:18:20, max mem: 15.9 GB 
[10/26 01:08:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 33.0453,	0.6337 s / batch. (data: 8.35e-04). ETA=16:23:27, max mem: 15.9 GB 
[10/26 01:09:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 52.4604,	0.6179 s / batch. (data: 3.44e-04). ETA=15:57:55, max mem: 15.9 GB 
[10/26 01:10:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6107 s / batch. (data: 1.45e-04). ETA=15:45:41, max mem: 15.9 GB 
[10/26 01:10:18][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.81e-03, avg batch time: 0.6316, average train loss: 43.1309
[10/26 01:11:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 25.296, 0.2248 s / batch. (data: 2.98e-05)max mem: 15.91637 GB 
[10/26 01:11:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2327, average loss: 17.9063
[10/26 01:11:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.10	
[10/26 01:11:19][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 9.890738003669028
[10/26 01:12:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6097 s / batch. (data: 3.29e-04). ETA=15:42:58, max mem: 15.9 GB 
[10/26 01:13:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.3293,	0.6189 s / batch. (data: 3.02e-04). ETA=15:56:15, max mem: 15.9 GB 
[10/26 01:14:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 28.9519,	0.6330 s / batch. (data: 1.29e-02). ETA=16:17:02, max mem: 15.9 GB 
[10/26 01:15:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 869.5384,	0.6388 s / batch. (data: 7.59e-04). ETA=16:24:51, max mem: 15.9 GB 
[10/26 01:16:36][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6161 s / batch. (data: 3.53e-04). ETA=15:48:50, max mem: 15.9 GB 
[10/26 01:17:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 26.1838,	0.6176 s / batch. (data: 2.77e-04). ETA=15:50:08, max mem: 15.9 GB 
[10/26 01:18:42][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 30.9343,	0.6180 s / batch. (data: 3.63e-04). ETA=15:49:41, max mem: 15.9 GB 
[10/26 01:19:45][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 19.5921,	0.6321 s / batch. (data: 2.93e-04). ETA=16:10:22, max mem: 15.9 GB 
[10/26 01:20:48][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 255.6687,	0.6436 s / batch. (data: 7.90e-04). ETA=16:26:53, max mem: 15.9 GB 
[10/26 01:21:51][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 6.6706,	0.6301 s / batch. (data: 7.94e-04). ETA=16:05:05, max mem: 15.9 GB 
[10/26 01:22:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0000,	0.6064 s / batch. (data: 1.54e-04). ETA=15:27:47, max mem: 15.9 GB 
[10/26 01:22:58][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 4.56e-03, avg batch time: 0.6324, average train loss: 46.4667
[10/26 01:23:48][INFO] visual_prompt:  303: 	Test 100/123. loss: 63.084, 0.2326 s / batch. (data: 4.36e-05)max mem: 15.91637 GB 
[10/26 01:23:59][INFO] visual_prompt:  316: Inference (val):avg data time: 4.11e-05, avg batch time: 0.2322, average loss: 68.1407
[10/26 01:23:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.52	
[10/26 01:23:59][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 9.851478631379981
[10/26 01:25:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 222.9611,	0.6311 s / batch. (data: 8.29e-04). ETA=16:04:32, max mem: 15.9 GB 
[10/26 01:26:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 229.3746,	0.6338 s / batch. (data: 7.93e-04). ETA=16:07:30, max mem: 15.9 GB 
[10/26 01:27:10][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 296.4660,	0.6476 s / batch. (data: 3.22e-04). ETA=16:27:30, max mem: 15.9 GB 
[10/26 01:28:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 142.4961,	0.6284 s / batch. (data: 1.27e-03). ETA=15:57:15, max mem: 15.9 GB 
[10/26 01:29:16][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6090 s / batch. (data: 3.74e-04). ETA=15:26:39, max mem: 15.9 GB 
[10/26 01:30:19][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0000,	0.6306 s / batch. (data: 7.97e-04). ETA=15:58:31, max mem: 15.9 GB 
[10/26 01:31:22][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.0000,	0.6400 s / batch. (data: 7.85e-04). ETA=16:11:42, max mem: 15.9 GB 
[10/26 01:32:25][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 33.1187,	0.6311 s / batch. (data: 3.20e-04). ETA=15:57:05, max mem: 15.9 GB 
[10/26 01:33:27][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 268.1121,	0.6336 s / batch. (data: 1.20e-02). ETA=15:59:53, max mem: 15.9 GB 
[10/26 01:34:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 45.8741,	0.6272 s / batch. (data: 8.10e-04). ETA=15:49:07, max mem: 15.9 GB 
[10/26 01:35:33][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 22.4004,	0.6187 s / batch. (data: 1.66e-04). ETA=15:35:13, max mem: 15.9 GB 
[10/26 01:35:37][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 4.40e-03, avg batch time: 0.6316, average train loss: 54.0637
[10/26 01:36:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 53.617, 0.2317 s / batch. (data: 2.88e-05)max mem: 15.91637 GB 
[10/26 01:36:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.2310, average loss: 48.4080
[10/26 01:36:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.55	
[10/26 01:36:38][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 9.806308479691594
[10/26 01:37:43][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 74.6403,	0.6240 s / batch. (data: 3.09e-04). ETA=15:42:12, max mem: 15.9 GB 
[10/26 01:38:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 73.1862,	0.6253 s / batch. (data: 1.30e-02). ETA=15:43:08, max mem: 15.9 GB 
[10/26 01:39:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0000,	0.6468 s / batch. (data: 8.36e-04). ETA=16:14:24, max mem: 15.9 GB 
[10/26 01:40:52][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 17.1900,	0.6189 s / batch. (data: 3.03e-04). ETA=15:31:20, max mem: 15.9 GB 
[10/26 01:41:55][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0000,	0.6343 s / batch. (data: 7.92e-04). ETA=15:53:31, max mem: 15.9 GB 
[10/26 01:42:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 44.9756,	0.6259 s / batch. (data: 3.20e-04). ETA=15:39:45, max mem: 15.9 GB 
[10/26 01:44:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 4.7063,	0.6202 s / batch. (data: 3.17e-04). ETA=15:30:13, max mem: 15.9 GB 
[10/26 01:45:05][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6083 s / batch. (data: 3.26e-04). ETA=15:11:22, max mem: 15.9 GB 
[10/26 01:46:08][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 17.7381,	0.6174 s / batch. (data: 3.12e-04). ETA=15:23:55, max mem: 15.9 GB 
[10/26 01:47:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 8.0667,	0.6243 s / batch. (data: 2.84e-04). ETA=15:33:18, max mem: 15.9 GB 
[10/26 01:48:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 225.4837,	0.6169 s / batch. (data: 1.69e-04). ETA=15:21:07, max mem: 15.9 GB 
[10/26 01:48:18][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 4.53e-03, avg batch time: 0.6326, average train loss: 41.8261
[10/26 01:49:08][INFO] visual_prompt:  303: 	Test 100/123. loss: 294.792, 0.2257 s / batch. (data: 6.15e-05)max mem: 15.91637 GB 
[10/26 01:49:18][INFO] visual_prompt:  316: Inference (val):avg data time: 4.15e-05, avg batch time: 0.2332, average loss: 265.2812
[10/26 01:49:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.16	
[10/26 01:49:18][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 9.755282581475768
[10/26 01:50:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 50.8663,	0.6126 s / batch. (data: 2.81e-04). ETA=15:13:43, max mem: 15.9 GB 
[10/26 01:51:27][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.0000,	0.6436 s / batch. (data: 8.31e-04). ETA=15:58:51, max mem: 15.9 GB 
[10/26 01:52:30][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 52.8105,	0.6330 s / batch. (data: 7.73e-04). ETA=15:41:57, max mem: 15.9 GB 
[10/26 01:53:33][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 11.0893,	0.6364 s / batch. (data: 3.07e-04). ETA=15:45:53, max mem: 15.9 GB 
[10/26 01:54:36][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 78.1878,	0.6418 s / batch. (data: 7.64e-04). ETA=15:52:58, max mem: 15.9 GB 
[10/26 01:55:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 33.7978,	0.6332 s / batch. (data: 3.13e-04). ETA=15:39:04, max mem: 15.9 GB 
[10/26 01:56:42][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 33.2084,	0.6293 s / batch. (data: 7.52e-04). ETA=15:32:19, max mem: 15.9 GB 
[10/26 01:57:44][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0000,	0.6080 s / batch. (data: 3.32e-04). ETA=14:59:38, max mem: 15.9 GB 
[10/26 01:58:47][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 224.7066,	0.6319 s / batch. (data: 3.07e-04). ETA=15:34:02, max mem: 15.9 GB 
[10/26 01:59:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 26.7826,	0.6456 s / batch. (data: 1.36e-02). ETA=15:53:10, max mem: 15.9 GB 
[10/26 02:00:53][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 90.5437,	0.6184 s / batch. (data: 4.79e-04). ETA=15:11:56, max mem: 15.9 GB 
[10/26 02:00:57][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 4.76e-03, avg batch time: 0.6320, average train loss: 46.6303
[10/26 02:01:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 41.960, 0.2251 s / batch. (data: 2.96e-05)max mem: 15.91637 GB 
[10/26 02:01:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.99e-05, avg batch time: 0.2321, average loss: 46.6717
[10/26 02:01:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.12	
[10/26 02:01:58][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 9.698463103929543
[10/26 02:03:03][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0000,	0.6400 s / batch. (data: 3.18e-04). ETA=15:42:42, max mem: 15.9 GB 
[10/26 02:04:06][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 86.4574,	0.6480 s / batch. (data: 3.10e-04). ETA=15:53:23, max mem: 15.9 GB 
[10/26 02:05:10][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 40.7823,	0.6488 s / batch. (data: 5.90e-03). ETA=15:53:28, max mem: 15.9 GB 
[10/26 02:06:12][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 109.1672,	0.6378 s / batch. (data: 6.00e-03). ETA=15:36:17, max mem: 15.9 GB 
[10/26 02:07:16][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 203.6524,	0.6185 s / batch. (data: 3.34e-04). ETA=15:06:58, max mem: 15.9 GB 
[10/26 02:08:18][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 348.6924,	0.6306 s / batch. (data: 7.97e-04). ETA=15:23:33, max mem: 15.9 GB 
[10/26 02:09:21][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 84.7570,	0.6142 s / batch. (data: 3.11e-04). ETA=14:58:34, max mem: 15.9 GB 
[10/26 02:10:24][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 48.5479,	0.6207 s / batch. (data: 2.69e-04). ETA=15:07:01, max mem: 15.9 GB 
[10/26 02:11:27][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.0000,	0.6205 s / batch. (data: 1.29e-02). ETA=15:05:43, max mem: 15.9 GB 
[10/26 02:12:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 28.6605,	0.6315 s / batch. (data: 8.16e-04). ETA=15:20:40, max mem: 15.9 GB 
[10/26 02:13:33][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 14.1982,	0.6185 s / batch. (data: 1.54e-04). ETA=15:00:45, max mem: 15.9 GB 
[10/26 02:13:37][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 4.51e-03, avg batch time: 0.6324, average train loss: 52.1312
[10/26 02:14:27][INFO] visual_prompt:  303: 	Test 100/123. loss: 33.550, 0.2254 s / batch. (data: 3.60e-05)max mem: 15.91637 GB 
[10/26 02:14:37][INFO] visual_prompt:  316: Inference (val):avg data time: 1.59e-04, avg batch time: 0.2339, average loss: 30.4788
[10/26 02:14:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.36	
[10/26 02:14:37][INFO] visual_prompt:   42: Stopping early.
