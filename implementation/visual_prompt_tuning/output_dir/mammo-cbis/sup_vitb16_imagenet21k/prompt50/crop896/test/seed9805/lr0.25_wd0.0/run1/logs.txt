[10/31 20:02:30][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/31 20:02:30][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/31 20:02:30][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '2', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '896', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/31 20:02:30][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/31 20:02:30][INFO] visual_prompt:  108: Training with config:
[10/31 20:02:30][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop896/test/seed9805/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 896, 'NO_TEST': False, 'BATCH_SIZE': 2, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/31 20:02:30][INFO] visual_prompt:   55: Loading training data...
[10/31 20:02:30][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/31 20:02:30][INFO] visual_prompt:   57: Loading validation data...
[10/31 20:02:30][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/31 20:02:30][INFO] visual_prompt:   61: Loading test data...
[10/31 20:02:30][INFO] visual_prompt:   28: Constructing mammo-cbis dataset test...
[10/31 20:02:30][INFO] visual_prompt:   38: Constructing models...
[10/31 20:02:35][INFO] visual_prompt:   52: Total Parameters: 88518914	 Gradient Parameters: 462338
[10/31 20:02:35][INFO] visual_prompt:   54: tuned percent:0.522
[10/31 20:02:35][INFO] visual_prompt:   40: Device used for model: 0
[10/31 20:02:35][INFO] visual_prompt:   40: Setting up Evaluator...
[10/31 20:02:35][INFO] visual_prompt:   42: Setting up Trainer...
[10/31 20:02:35][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/31 20:02:35][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/31 20:03:42][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.3219,	0.6313 s / batch. (data: 9.97e-04). ETA=19:22:33, max mem: 15.9 GB 
[10/31 20:04:46][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.5424,	0.6594 s / batch. (data: 3.94e-02). ETA=20:13:16, max mem: 15.9 GB 
[10/31 20:05:50][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.1459,	0.6193 s / batch. (data: 3.87e-04). ETA=18:58:28, max mem: 15.9 GB 
[10/31 20:06:53][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7442,	0.6400 s / batch. (data: 7.96e-03). ETA=19:35:27, max mem: 15.9 GB 
[10/31 20:07:57][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.3799,	0.6184 s / batch. (data: 4.15e-04). ETA=18:54:44, max mem: 15.9 GB 
[10/31 20:09:01][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.7927,	0.6175 s / batch. (data: 4.00e-04). ETA=18:52:03, max mem: 15.9 GB 
[10/31 20:10:05][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.7472,	0.6520 s / batch. (data: 1.02e-03). ETA=19:54:14, max mem: 15.9 GB 
[10/31 20:11:09][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.0533,	0.6340 s / batch. (data: 3.78e-04). ETA=19:20:10, max mem: 15.9 GB 
[10/31 20:12:12][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.3219,	0.6188 s / batch. (data: 3.58e-04). ETA=18:51:19, max mem: 15.9 GB 
[10/31 20:13:16][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.0743,	0.6353 s / batch. (data: 9.42e-04). ETA=19:20:23, max mem: 15.9 GB 
[10/31 20:14:20][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7837,	0.6191 s / batch. (data: 2.30e-04). ETA=18:49:56, max mem: 15.9 GB 
[10/31 20:14:24][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 6.95e-03, avg batch time: 0.6408, average train loss: 1.0102
[10/31 20:15:19][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.597, 0.2254 s / batch. (data: 4.03e-05)max mem: 15.94594 GB 
[10/31 20:15:31][INFO] visual_prompt:  316: Inference (val):avg data time: 5.31e-05, avg batch time: 0.2321, average loss: 1.0778
[10/31 20:15:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.79	
[10/31 20:16:28][INFO] visual_prompt:  303: 	Test 100/323. loss: 1.641, 0.2360 s / batch. (data: 5.56e-05)max mem: 15.94594 GB 
[10/31 20:17:23][INFO] visual_prompt:  303: 	Test 200/323. loss: 1.159, 0.2318 s / batch. (data: 3.41e-05)max mem: 15.94594 GB 
[10/31 20:18:17][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.940, 0.2242 s / batch. (data: 4.84e-05)max mem: 15.94594 GB 
[10/31 20:18:29][INFO] visual_prompt:  316: Inference (test):avg data time: 7.26e-05, avg batch time: 0.2317, average loss: 1.1233
[10/31 20:18:29][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.16	rocauc: 47.74	
[10/31 20:18:29][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.025
[10/31 20:19:36][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5959,	0.6334 s / batch. (data: 3.61e-04). ETA=19:14:45, max mem: 15.9 GB 
[10/31 20:20:40][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.5489,	0.6359 s / batch. (data: 7.98e-03). ETA=19:18:21, max mem: 15.9 GB 
[10/31 20:21:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.7453,	0.6527 s / batch. (data: 9.86e-04). ETA=19:47:50, max mem: 15.9 GB 
[10/31 20:22:47][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9791,	0.6600 s / batch. (data: 1.18e-03). ETA=19:59:59, max mem: 15.9 GB 
[10/31 20:23:51][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.3033,	0.6400 s / batch. (data: 4.80e-04). ETA=19:22:31, max mem: 15.9 GB 
[10/31 20:24:55][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.2421,	0.6522 s / batch. (data: 2.09e-02). ETA=19:43:37, max mem: 15.9 GB 
[10/31 20:25:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6595,	0.6356 s / batch. (data: 4.40e-04). ETA=19:12:29, max mem: 15.9 GB 
[10/31 20:27:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7057,	0.6342 s / batch. (data: 1.02e-03). ETA=19:08:50, max mem: 15.9 GB 
[10/31 20:28:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.3019,	0.6355 s / batch. (data: 9.81e-04). ETA=19:10:12, max mem: 15.9 GB 
[10/31 20:29:11][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.0653,	0.6199 s / batch. (data: 3.85e-04). ETA=18:40:58, max mem: 15.9 GB 
[10/31 20:30:15][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2839,	0.6179 s / batch. (data: 2.46e-04). ETA=18:36:16, max mem: 15.9 GB 
[10/31 20:30:19][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 7.08e-03, avg batch time: 0.6417, average train loss: 0.8584
[10/31 20:31:14][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.721, 0.2344 s / batch. (data: 5.82e-05)max mem: 15.94594 GB 
[10/31 20:31:26][INFO] visual_prompt:  316: Inference (val):avg data time: 5.28e-05, avg batch time: 0.2318, average loss: 0.7552
[10/31 20:31:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.17	
[10/31 20:32:22][INFO] visual_prompt:  303: 	Test 100/323. loss: 1.000, 0.2367 s / batch. (data: 6.15e-05)max mem: 15.94594 GB 
[10/31 20:33:15][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.726, 0.2249 s / batch. (data: 3.65e-05)max mem: 15.94594 GB 
[10/31 20:34:08][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.746, 0.2250 s / batch. (data: 3.62e-05)max mem: 15.94594 GB 
[10/31 20:34:19][INFO] visual_prompt:  316: Inference (test):avg data time: 5.16e-05, avg batch time: 0.2319, average loss: 0.7708
[10/31 20:34:19][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 50.39	
[10/31 20:34:19][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.05
[10/31 20:35:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5941,	0.6330 s / batch. (data: 3.39e-04). ETA=19:02:25, max mem: 15.9 GB 
[10/31 20:36:30][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.9329,	0.6454 s / batch. (data: 1.02e-03). ETA=19:23:47, max mem: 15.9 GB 
[10/31 20:37:34][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.3365,	0.6564 s / batch. (data: 1.01e-03). ETA=19:42:24, max mem: 15.9 GB 
[10/31 20:38:37][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.0411,	0.6320 s / batch. (data: 3.85e-04). ETA=18:57:27, max mem: 15.9 GB 
[10/31 20:39:41][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.9259,	0.6186 s / batch. (data: 4.48e-04). ETA=18:32:16, max mem: 15.9 GB 
[10/31 20:40:45][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.7210,	0.6401 s / batch. (data: 1.07e-02). ETA=19:09:49, max mem: 15.9 GB 
[10/31 20:41:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.1545,	0.6350 s / batch. (data: 9.54e-04). ETA=18:59:38, max mem: 15.9 GB 
[10/31 20:42:53][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8876,	0.6441 s / batch. (data: 9.71e-04). ETA=19:14:56, max mem: 15.9 GB 
[10/31 20:43:57][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.9130,	0.6454 s / batch. (data: 1.12e-02). ETA=19:16:17, max mem: 15.9 GB 
[10/31 20:45:00][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7338,	0.6401 s / batch. (data: 4.33e-04). ETA=19:05:34, max mem: 15.9 GB 
[10/31 20:46:04][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.3002,	0.6194 s / batch. (data: 2.43e-04). ETA=18:27:36, max mem: 15.9 GB 
[10/31 20:46:08][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 6.69e-03, avg batch time: 0.6409, average train loss: 0.8671
[10/31 20:47:04][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.741, 0.2394 s / batch. (data: 4.60e-05)max mem: 15.94594 GB 
[10/31 20:47:15][INFO] visual_prompt:  316: Inference (val):avg data time: 2.39e-04, avg batch time: 0.2332, average loss: 0.6969
[10/31 20:47:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.99	
[10/31 20:48:11][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.466, 0.2249 s / batch. (data: 5.32e-05)max mem: 15.94594 GB 
[10/31 20:49:04][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.648, 0.2325 s / batch. (data: 5.72e-05)max mem: 15.94594 GB 
[10/31 20:49:57][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.761, 0.2240 s / batch. (data: 6.46e-05)max mem: 15.94594 GB 
[10/31 20:50:09][INFO] visual_prompt:  316: Inference (test):avg data time: 9.84e-05, avg batch time: 0.2312, average loss: 0.6734
[10/31 20:50:09][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 55.48	
[10/31 20:50:09][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.075
[10/31 20:51:15][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6641,	0.6440 s / batch. (data: 1.00e-03). ETA=19:10:29, max mem: 15.9 GB 
[10/31 20:52:19][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8077,	0.6480 s / batch. (data: 1.04e-03). ETA=19:16:29, max mem: 15.9 GB 
[10/31 20:53:23][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0036,	0.6234 s / batch. (data: 3.77e-04). ETA=18:31:28, max mem: 15.9 GB 
[10/31 20:54:26][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.8655,	0.6331 s / batch. (data: 3.56e-04). ETA=18:47:42, max mem: 15.9 GB 
[10/31 20:55:30][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5793,	0.6280 s / batch. (data: 4.07e-04). ETA=18:37:35, max mem: 15.9 GB 
[10/31 20:56:34][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.4685,	0.6411 s / batch. (data: 9.84e-04). ETA=18:59:53, max mem: 15.9 GB 
[10/31 20:57:38][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.6992,	0.6324 s / batch. (data: 3.96e-04). ETA=18:43:27, max mem: 15.9 GB 
[10/31 20:58:42][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6089,	0.6602 s / batch. (data: 3.67e-02). ETA=19:31:37, max mem: 15.9 GB 
[10/31 20:59:46][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8086,	0.6358 s / batch. (data: 3.71e-04). ETA=18:47:18, max mem: 15.9 GB 
[10/31 21:00:50][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6809,	0.6400 s / batch. (data: 3.63e-04). ETA=18:53:39, max mem: 15.9 GB 
[10/31 21:01:54][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6601,	0.6240 s / batch. (data: 2.50e-04). ETA=18:24:15, max mem: 15.9 GB 
[10/31 21:01:58][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 6.64e-03, avg batch time: 0.6408, average train loss: 0.9565
[10/31 21:02:53][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.780, 0.2275 s / batch. (data: 6.94e-05)max mem: 15.94594 GB 
[10/31 21:03:05][INFO] visual_prompt:  316: Inference (val):avg data time: 5.19e-05, avg batch time: 0.2330, average loss: 0.7212
[10/31 21:03:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.47	
[10/31 21:04:00][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.370, 0.2247 s / batch. (data: 4.39e-05)max mem: 15.94594 GB 
[10/31 21:04:54][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.682, 0.2294 s / batch. (data: 6.37e-05)max mem: 15.94594 GB 
[10/31 21:05:47][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.804, 0.2458 s / batch. (data: 4.91e-05)max mem: 15.94594 GB 
[10/31 21:05:58][INFO] visual_prompt:  316: Inference (test):avg data time: 7.78e-05, avg batch time: 0.2324, average loss: 0.6860
[10/31 21:05:58][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 56.64	
[10/31 21:05:58][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.1
[10/31 21:07:05][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0699,	0.6320 s / batch. (data: 3.71e-04). ETA=18:37:20, max mem: 15.9 GB 
[10/31 21:08:09][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1884,	0.6248 s / batch. (data: 5.55e-03). ETA=18:23:38, max mem: 15.9 GB 
[10/31 21:09:13][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4814,	0.6414 s / batch. (data: 6.15e-03). ETA=18:51:44, max mem: 15.9 GB 
[10/31 21:10:16][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 2.1590,	0.6344 s / batch. (data: 9.99e-04). ETA=18:38:22, max mem: 15.9 GB 
[10/31 21:11:20][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.5144,	0.6201 s / batch. (data: 3.62e-04). ETA=18:12:13, max mem: 15.9 GB 
[10/31 21:12:24][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.0648,	0.6296 s / batch. (data: 3.98e-04). ETA=18:27:48, max mem: 15.9 GB 
[10/31 21:13:28][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2119,	0.6421 s / batch. (data: 4.24e-04). ETA=18:48:47, max mem: 15.9 GB 
[10/31 21:14:32][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.1772,	0.6190 s / batch. (data: 4.15e-04). ETA=18:07:05, max mem: 15.9 GB 
[10/31 21:15:36][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1393,	0.6201 s / batch. (data: 3.90e-04). ETA=18:08:05, max mem: 15.9 GB 
[10/31 21:16:40][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6178,	0.6187 s / batch. (data: 4.51e-04). ETA=18:04:29, max mem: 15.9 GB 
[10/31 21:17:44][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2258,	0.6189 s / batch. (data: 2.37e-04). ETA=18:03:53, max mem: 15.9 GB 
[10/31 21:17:47][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 6.92e-03, avg batch time: 0.6413, average train loss: 0.9628
[10/31 21:18:43][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.522, 0.2252 s / batch. (data: 4.94e-05)max mem: 15.94594 GB 
[10/31 21:18:54][INFO] visual_prompt:  316: Inference (val):avg data time: 1.45e-04, avg batch time: 0.2335, average loss: 1.3498
[10/31 21:18:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.58	
[10/31 21:19:50][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.049, 0.2246 s / batch. (data: 4.79e-05)max mem: 15.94594 GB 
[10/31 21:20:44][INFO] visual_prompt:  303: 	Test 200/323. loss: 1.368, 0.2344 s / batch. (data: 3.19e-05)max mem: 15.94594 GB 
[10/31 21:21:37][INFO] visual_prompt:  303: 	Test 300/323. loss: 1.613, 0.2270 s / batch. (data: 3.74e-05)max mem: 15.94594 GB 
[10/31 21:21:48][INFO] visual_prompt:  316: Inference (test):avg data time: 2.56e-04, avg batch time: 0.2319, average loss: 1.2267
[10/31 21:21:48][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 56.81	
[10/31 21:21:48][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.125
[10/31 21:22:55][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.5868,	0.6172 s / batch. (data: 3.86e-04). ETA=17:59:50, max mem: 15.9 GB 
[10/31 21:23:58][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.6297,	0.6322 s / batch. (data: 1.01e-03). ETA=18:24:56, max mem: 15.9 GB 
[10/31 21:25:02][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.5601,	0.6480 s / batch. (data: 1.20e-02). ETA=18:51:32, max mem: 15.9 GB 
[10/31 21:26:06][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8129,	0.6617 s / batch. (data: 1.63e-02). ETA=19:14:21, max mem: 15.9 GB 
[10/31 21:27:10][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7956,	0.6345 s / batch. (data: 1.01e-03). ETA=18:25:53, max mem: 15.9 GB 
[10/31 21:28:14][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0710,	0.6234 s / batch. (data: 3.96e-04). ETA=18:05:22, max mem: 15.9 GB 
[10/31 21:29:17][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.2355,	0.6276 s / batch. (data: 4.15e-04). ETA=18:11:38, max mem: 15.9 GB 
[10/31 21:30:21][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0672,	0.6411 s / batch. (data: 1.01e-03). ETA=18:34:11, max mem: 15.9 GB 
[10/31 21:31:25][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.1181,	0.6199 s / batch. (data: 3.89e-04). ETA=17:56:19, max mem: 15.9 GB 
[10/31 21:32:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 3.3113,	0.6190 s / batch. (data: 3.61e-04). ETA=17:53:42, max mem: 15.9 GB 
[10/31 21:33:33][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8153,	0.6193 s / batch. (data: 2.35e-04). ETA=17:53:07, max mem: 15.9 GB 
[10/31 21:33:37][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 7.03e-03, avg batch time: 0.6405, average train loss: 1.0526
[10/31 21:34:31][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.728, 0.2397 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/31 21:34:42][INFO] visual_prompt:  316: Inference (val):avg data time: 1.07e-04, avg batch time: 0.2322, average loss: 0.7100
[10/31 21:34:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 57.59	
[10/31 21:35:38][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.831, 0.2249 s / batch. (data: 3.19e-05)max mem: 15.94594 GB 
[10/31 21:36:30][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.641, 0.2243 s / batch. (data: 3.08e-05)max mem: 15.94594 GB 
[10/31 21:37:22][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.765, 0.2417 s / batch. (data: 5.41e-05)max mem: 15.94594 GB 
[10/31 21:37:33][INFO] visual_prompt:  316: Inference (test):avg data time: 2.59e-04, avg batch time: 0.2322, average loss: 0.7260
[10/31 21:37:33][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.62	rocauc: 56.15	
[10/31 21:37:33][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.15
[10/31 21:38:40][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8720,	0.6306 s / batch. (data: 1.20e-02). ETA=18:11:33, max mem: 15.9 GB 
[10/31 21:39:43][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8587,	0.6342 s / batch. (data: 1.06e-02). ETA=18:16:51, max mem: 15.9 GB 
[10/31 21:40:47][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.2428,	0.6274 s / batch. (data: 3.59e-04). ETA=18:03:54, max mem: 15.9 GB 
[10/31 21:41:51][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9660,	0.6459 s / batch. (data: 8.92e-04). ETA=18:34:48, max mem: 15.9 GB 
[10/31 21:42:54][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.7591,	0.6387 s / batch. (data: 8.78e-04). ETA=18:21:22, max mem: 15.9 GB 
[10/31 21:43:58][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.5920,	0.6469 s / batch. (data: 8.48e-04). ETA=18:34:29, max mem: 15.9 GB 
[10/31 21:45:02][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.5891,	0.6402 s / batch. (data: 3.79e-04). ETA=18:21:53, max mem: 15.9 GB 
[10/31 21:46:06][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2211,	0.6403 s / batch. (data: 8.69e-04). ETA=18:20:55, max mem: 15.9 GB 
[10/31 21:47:10][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8339,	0.6381 s / batch. (data: 3.46e-04). ETA=18:16:03, max mem: 15.9 GB 
[10/31 21:48:14][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.2515,	0.6514 s / batch. (data: 1.55e-02). ETA=18:37:51, max mem: 15.9 GB 
[10/31 21:49:17][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7517,	0.6179 s / batch. (data: 2.32e-04). ETA=17:39:22, max mem: 15.9 GB 
[10/31 21:49:21][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 6.37e-03, avg batch time: 0.6400, average train loss: 1.0685
[10/31 21:50:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.751, 0.2356 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/31 21:50:27][INFO] visual_prompt:  316: Inference (val):avg data time: 1.88e-04, avg batch time: 0.2315, average loss: 0.7394
[10/31 21:50:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.77	
[10/31 21:51:23][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.936, 0.2247 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/31 21:52:15][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.626, 0.2240 s / batch. (data: 3.08e-05)max mem: 15.94594 GB 
[10/31 21:53:07][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.787, 0.2324 s / batch. (data: 6.06e-05)max mem: 15.94594 GB 
[10/31 21:53:18][INFO] visual_prompt:  316: Inference (test):avg data time: 8.92e-05, avg batch time: 0.2317, average loss: 0.7684
[10/31 21:53:18][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 57.46	
[10/31 21:53:18][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.175
[10/31 21:54:24][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0753,	0.6349 s / batch. (data: 3.83e-04). ETA=18:07:26, max mem: 15.9 GB 
[10/31 21:55:28][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 2.3903,	0.6504 s / batch. (data: 1.06e-02). ETA=18:32:45, max mem: 15.9 GB 
[10/31 21:56:32][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 3.0551,	0.6329 s / batch. (data: 3.50e-04). ETA=18:01:47, max mem: 15.9 GB 
[10/31 21:57:36][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.1818,	0.6390 s / batch. (data: 3.74e-04). ETA=18:11:13, max mem: 15.9 GB 
[10/31 21:58:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0677,	0.6733 s / batch. (data: 8.54e-04). ETA=19:08:38, max mem: 15.9 GB 
[10/31 21:59:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.2003,	0.6441 s / batch. (data: 1.06e-02). ETA=18:17:48, max mem: 15.9 GB 
[10/31 22:00:47][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3057,	0.6399 s / batch. (data: 8.65e-04). ETA=18:09:30, max mem: 15.9 GB 
[10/31 22:01:51][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.2753,	0.6180 s / batch. (data: 4.17e-04). ETA=17:31:10, max mem: 15.9 GB 
[10/31 22:02:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8212,	0.6480 s / batch. (data: 8.45e-04). ETA=18:21:12, max mem: 15.9 GB 
[10/31 22:03:58][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.5669,	0.6203 s / batch. (data: 1.03e-03). ETA=17:33:01, max mem: 15.9 GB 
[10/31 22:05:02][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 4.6611,	0.6188 s / batch. (data: 1.76e-04). ETA=17:29:32, max mem: 15.9 GB 
[10/31 22:05:06][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 6.14e-03, avg batch time: 0.6398, average train loss: 0.9996
[10/31 22:06:00][INFO] visual_prompt:  303: 	Test 100/123. loss: 2.052, 0.2249 s / batch. (data: 6.03e-05)max mem: 15.94594 GB 
[10/31 22:06:12][INFO] visual_prompt:  316: Inference (val):avg data time: 9.89e-05, avg batch time: 0.2327, average loss: 1.7833
[10/31 22:06:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.65	
[10/31 22:07:07][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.019, 0.2351 s / batch. (data: 5.27e-05)max mem: 15.94594 GB 
[10/31 22:07:59][INFO] visual_prompt:  303: 	Test 200/323. loss: 1.788, 0.2243 s / batch. (data: 3.22e-05)max mem: 15.94594 GB 
[10/31 22:08:52][INFO] visual_prompt:  303: 	Test 300/323. loss: 2.154, 0.2242 s / batch. (data: 6.56e-05)max mem: 15.94594 GB 
[10/31 22:09:03][INFO] visual_prompt:  316: Inference (test):avg data time: 1.86e-04, avg batch time: 0.2325, average loss: 1.6203
[10/31 22:09:03][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 55.39	
[10/31 22:09:03][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.2
[10/31 22:10:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4475,	0.6510 s / batch. (data: 8.77e-04). ETA=18:22:53, max mem: 15.9 GB 
[10/31 22:11:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.6459,	0.6241 s / batch. (data: 3.12e-04). ETA=17:36:17, max mem: 15.9 GB 
[10/31 22:12:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 2.3286,	0.6189 s / batch. (data: 3.57e-04). ETA=17:26:24, max mem: 15.9 GB 
[10/31 22:13:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.6775,	0.6383 s / batch. (data: 8.75e-04). ETA=17:58:13, max mem: 15.9 GB 
[10/31 22:14:25][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.6683,	0.6183 s / batch. (data: 3.55e-04). ETA=17:23:27, max mem: 15.9 GB 
[10/31 22:15:29][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.5357,	0.6483 s / batch. (data: 8.89e-04). ETA=18:12:55, max mem: 15.9 GB 
[10/31 22:16:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.2556,	0.6440 s / batch. (data: 3.37e-04). ETA=18:04:36, max mem: 15.9 GB 
[10/31 22:17:36][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6668,	0.6360 s / batch. (data: 8.39e-04). ETA=17:50:05, max mem: 15.9 GB 
[10/31 22:18:40][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8496,	0.6552 s / batch. (data: 8.69e-04). ETA=18:21:21, max mem: 15.9 GB 
[10/31 22:19:44][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.4286,	0.6315 s / batch. (data: 3.49e-04). ETA=17:40:20, max mem: 15.9 GB 
[10/31 22:20:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8912,	0.6176 s / batch. (data: 3.77e-04). ETA=17:16:04, max mem: 15.9 GB 
[10/31 22:20:52][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 7.09e-03, avg batch time: 0.6409, average train loss: 1.1566
[10/31 22:21:46][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.594, 0.2436 s / batch. (data: 3.74e-05)max mem: 15.94594 GB 
[10/31 22:21:58][INFO] visual_prompt:  316: Inference (val):avg data time: 5.38e-05, avg batch time: 0.2317, average loss: 1.3490
[10/31 22:21:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.07	
[10/31 22:22:53][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.040, 0.2291 s / batch. (data: 4.96e-05)max mem: 15.94594 GB 
[10/31 22:23:45][INFO] visual_prompt:  303: 	Test 200/323. loss: 1.206, 0.2362 s / batch. (data: 5.44e-05)max mem: 15.94594 GB 
[10/31 22:24:37][INFO] visual_prompt:  303: 	Test 300/323. loss: 1.719, 0.2237 s / batch. (data: 4.89e-05)max mem: 15.94594 GB 
[10/31 22:24:49][INFO] visual_prompt:  316: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2320, average loss: 1.2301
[10/31 22:24:49][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 57.19	
[10/31 22:24:49][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.225
[10/31 22:25:56][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.9486,	0.6600 s / batch. (data: 8.88e-04). ETA=18:26:00, max mem: 15.9 GB 
[10/31 22:27:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8885,	0.6240 s / batch. (data: 3.75e-04). ETA=17:24:40, max mem: 15.9 GB 
[10/31 22:28:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.2749,	0.6196 s / batch. (data: 4.37e-04). ETA=17:16:13, max mem: 15.9 GB 
[10/31 22:29:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 3.4491,	0.6286 s / batch. (data: 3.83e-04). ETA=17:30:10, max mem: 15.9 GB 
[10/31 22:30:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.1215,	0.6536 s / batch. (data: 8.95e-04). ETA=18:10:51, max mem: 15.9 GB 
[10/31 22:31:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.0117,	0.6556 s / batch. (data: 1.62e-02). ETA=18:13:13, max mem: 15.9 GB 
[10/31 22:32:18][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.9438,	0.6467 s / batch. (data: 8.62e-04). ETA=17:57:14, max mem: 15.9 GB 
[10/31 22:33:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.0205,	0.6790 s / batch. (data: 6.05e-03). ETA=18:49:52, max mem: 15.9 GB 
[10/31 22:34:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.2109,	0.6281 s / batch. (data: 3.79e-04). ETA=17:24:07, max mem: 15.9 GB 
[10/31 22:35:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.1838,	0.6364 s / batch. (data: 3.72e-04). ETA=17:36:58, max mem: 15.9 GB 
[10/31 22:36:33][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.7785,	0.6353 s / batch. (data: 1.98e-04). ETA=17:34:05, max mem: 15.9 GB 
[10/31 22:36:37][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 6.72e-03, avg batch time: 0.6406, average train loss: 1.0923
[10/31 22:37:32][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.662, 0.2334 s / batch. (data: 3.27e-05)max mem: 15.94594 GB 
[10/31 22:37:43][INFO] visual_prompt:  316: Inference (val):avg data time: 1.99e-04, avg batch time: 0.2326, average loss: 0.6739
[10/31 22:37:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 58.78	
[10/31 22:38:38][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.590, 0.2380 s / batch. (data: 6.94e-05)max mem: 15.94594 GB 
[10/31 22:39:31][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.608, 0.2240 s / batch. (data: 3.10e-05)max mem: 15.94594 GB 
[10/31 22:40:23][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.761, 0.2448 s / batch. (data: 6.18e-05)max mem: 15.94594 GB 
[10/31 22:40:34][INFO] visual_prompt:  316: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2319, average loss: 0.6790
[10/31 22:40:34][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 56.74	rocauc: 53.75	
[10/31 22:40:34][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.25
[10/31 22:41:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.8376,	0.6360 s / batch. (data: 9.09e-04). ETA=17:34:08, max mem: 15.9 GB 
[10/31 22:42:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.7135,	0.6448 s / batch. (data: 8.40e-04). ETA=17:47:32, max mem: 15.9 GB 
[10/31 22:43:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 4.1042,	0.6216 s / batch. (data: 3.57e-04). ETA=17:08:08, max mem: 15.9 GB 
[10/31 22:44:52][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.4450,	0.6319 s / batch. (data: 1.06e-02). ETA=17:24:09, max mem: 15.9 GB 
[10/31 22:45:56][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.0384,	0.6366 s / batch. (data: 8.43e-04). ETA=17:30:51, max mem: 15.9 GB 
[10/31 22:47:00][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3761,	0.6643 s / batch. (data: 1.11e-02). ETA=18:15:28, max mem: 15.9 GB 
[10/31 22:48:04][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3681,	0.6493 s / batch. (data: 6.19e-03). ETA=17:49:35, max mem: 15.9 GB 
[10/31 22:49:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.3365,	0.6336 s / batch. (data: 3.62e-04). ETA=17:22:44, max mem: 15.9 GB 
[10/31 22:50:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7424,	0.6320 s / batch. (data: 5.52e-03). ETA=17:19:00, max mem: 15.9 GB 
[10/31 22:51:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0229,	0.6459 s / batch. (data: 1.19e-03). ETA=17:40:51, max mem: 15.9 GB 
[10/31 22:52:18][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2420,	0.6192 s / batch. (data: 4.39e-04). ETA=16:55:56, max mem: 15.9 GB 
[10/31 22:52:22][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 6.52e-03, avg batch time: 0.6401, average train loss: 1.2228
[10/31 22:53:16][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.542, 0.2397 s / batch. (data: 3.19e-05)max mem: 15.94594 GB 
[10/31 22:53:28][INFO] visual_prompt:  316: Inference (val):avg data time: 5.09e-05, avg batch time: 0.2326, average loss: 0.7219
[10/31 22:53:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.04	
[10/31 22:54:23][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.880, 0.2286 s / batch. (data: 6.22e-05)max mem: 15.94594 GB 
[10/31 22:55:16][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.460, 0.2250 s / batch. (data: 5.25e-05)max mem: 15.94594 GB 
[10/31 22:56:08][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.947, 0.2410 s / batch. (data: 5.44e-05)max mem: 15.94594 GB 
[10/31 22:56:19][INFO] visual_prompt:  316: Inference (test):avg data time: 7.76e-05, avg batch time: 0.2319, average loss: 0.7602
[10/31 22:56:19][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 47.13	rocauc: 53.42	
[10/31 22:56:19][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/31 22:57:26][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.9950,	0.6283 s / batch. (data: 1.17e-02). ETA=17:09:45, max mem: 15.9 GB 
[10/31 22:58:29][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1877,	0.6240 s / batch. (data: 3.62e-04). ETA=17:01:37, max mem: 15.9 GB 
[10/31 22:59:33][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.0621,	0.6270 s / batch. (data: 8.53e-04). ETA=17:05:25, max mem: 15.9 GB 
[10/31 23:00:36][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.7568,	0.6541 s / batch. (data: 3.26e-02). ETA=17:48:39, max mem: 15.9 GB 
[10/31 23:01:40][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6427,	0.6320 s / batch. (data: 3.46e-04). ETA=17:11:33, max mem: 15.9 GB 
[10/31 23:02:44][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.3971,	0.6187 s / batch. (data: 3.66e-04). ETA=16:48:53, max mem: 15.9 GB 
[10/31 23:03:48][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.1679,	0.6325 s / batch. (data: 3.37e-04). ETA=17:10:14, max mem: 15.9 GB 
[10/31 23:04:52][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 1.5536,	0.6440 s / batch. (data: 8.34e-04). ETA=17:27:53, max mem: 15.9 GB 
[10/31 23:05:55][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.1135,	0.6280 s / batch. (data: 3.76e-04). ETA=17:00:50, max mem: 15.9 GB 
[10/31 23:06:59][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6225,	0.6485 s / batch. (data: 1.57e-02). ETA=17:33:07, max mem: 15.9 GB 
[10/31 23:08:03][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.0082,	0.6183 s / batch. (data: 1.76e-04). ETA=16:42:58, max mem: 15.9 GB 
[10/31 23:08:06][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 6.62e-03, avg batch time: 0.6397, average train loss: 0.9979
[10/31 23:09:01][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.776, 0.2477 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/31 23:09:13][INFO] visual_prompt:  316: Inference (val):avg data time: 4.99e-05, avg batch time: 0.2321, average loss: 0.7502
[10/31 23:09:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.31	
[10/31 23:10:08][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.281, 0.2432 s / batch. (data: 3.34e-05)max mem: 15.94594 GB 
[10/31 23:11:00][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.532, 0.2249 s / batch. (data: 5.72e-05)max mem: 15.94594 GB 
[10/31 23:11:53][INFO] visual_prompt:  303: 	Test 300/323. loss: 1.046, 0.2242 s / batch. (data: 5.13e-05)max mem: 15.94594 GB 
[10/31 23:12:04][INFO] visual_prompt:  316: Inference (test):avg data time: 7.28e-05, avg batch time: 0.2311, average loss: 0.7080
[10/31 23:12:04][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 57.39	
[10/31 23:12:04][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/31 23:13:11][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 5.6397,	0.6400 s / batch. (data: 3.38e-04). ETA=17:17:06, max mem: 15.9 GB 
[10/31 23:14:14][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.8871,	0.6182 s / batch. (data: 3.45e-04). ETA=16:40:42, max mem: 15.9 GB 
[10/31 23:15:18][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6607,	0.6443 s / batch. (data: 3.51e-04). ETA=17:21:58, max mem: 15.9 GB 
[10/31 23:16:22][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.4868,	0.6708 s / batch. (data: 8.63e-04). ETA=18:03:40, max mem: 15.9 GB 
[10/31 23:17:26][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.5293,	0.6360 s / batch. (data: 3.61e-04). ETA=17:06:22, max mem: 15.9 GB 
[10/31 23:18:30][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.0306,	0.6450 s / batch. (data: 8.50e-04). ETA=17:19:45, max mem: 15.9 GB 
[10/31 23:19:33][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3101,	0.6399 s / batch. (data: 8.81e-04). ETA=17:10:28, max mem: 15.9 GB 
[10/31 23:20:37][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.9098,	0.6403 s / batch. (data: 9.01e-04). ETA=17:10:03, max mem: 15.9 GB 
[10/31 23:21:41][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6259,	0.6299 s / batch. (data: 1.26e-02). ETA=16:52:16, max mem: 15.9 GB 
[10/31 23:22:45][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.8764,	0.6350 s / batch. (data: 5.52e-03). ETA=16:59:29, max mem: 15.9 GB 
[10/31 23:23:48][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.2633,	0.6189 s / batch. (data: 1.98e-04). ETA=16:32:40, max mem: 15.9 GB 
[10/31 23:23:52][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 6.44e-03, avg batch time: 0.6400, average train loss: 1.0779
[10/31 23:24:47][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.652, 0.2357 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/31 23:24:58][INFO] visual_prompt:  316: Inference (val):avg data time: 2.17e-04, avg batch time: 0.2317, average loss: 0.6783
[10/31 23:24:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 60.00	
[10/31 23:25:53][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.714, 0.2277 s / batch. (data: 3.89e-05)max mem: 15.94594 GB 
[10/31 23:26:46][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.519, 0.2252 s / batch. (data: 5.87e-05)max mem: 15.94594 GB 
[10/31 23:27:38][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.803, 0.2344 s / batch. (data: 5.10e-05)max mem: 15.94594 GB 
[10/31 23:27:49][INFO] visual_prompt:  316: Inference (test):avg data time: 8.00e-05, avg batch time: 0.2326, average loss: 0.6907
[10/31 23:27:49][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 55.50	rocauc: 57.40	
[10/31 23:27:49][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.678
[10/31 23:27:49][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/31 23:28:56][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0674,	0.6400 s / batch. (data: 3.53e-04). ETA=17:05:17, max mem: 15.9 GB 
[10/31 23:30:00][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4000,	0.6485 s / batch. (data: 9.07e-04). ETA=17:17:53, max mem: 15.9 GB 
[10/31 23:31:03][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6045,	0.6277 s / batch. (data: 3.67e-04). ETA=16:43:31, max mem: 15.9 GB 
[10/31 23:32:07][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.8708,	0.6499 s / batch. (data: 8.86e-04). ETA=17:17:58, max mem: 15.9 GB 
[10/31 23:33:11][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.1990,	0.6181 s / batch. (data: 3.65e-04). ETA=16:26:06, max mem: 15.9 GB 
[10/31 23:34:15][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.1814,	0.6389 s / batch. (data: 5.52e-03). ETA=16:58:12, max mem: 15.9 GB 
[10/31 23:35:19][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.0157,	0.6335 s / batch. (data: 1.38e-02). ETA=16:48:34, max mem: 15.9 GB 
[10/31 23:36:22][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.0729,	0.6554 s / batch. (data: 3.81e-02). ETA=17:22:17, max mem: 15.9 GB 
[10/31 23:37:26][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.7524,	0.6559 s / batch. (data: 6.10e-03). ETA=17:22:01, max mem: 15.9 GB 
[10/31 23:38:30][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.0170,	0.6551 s / batch. (data: 6.04e-03). ETA=17:19:40, max mem: 15.9 GB 
[10/31 23:39:34][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.6793,	0.6194 s / batch. (data: 2.07e-04). ETA=16:21:59, max mem: 15.9 GB 
[10/31 23:39:38][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 6.73e-03, avg batch time: 0.6403, average train loss: 1.0660
[10/31 23:40:32][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.628, 0.2325 s / batch. (data: 5.70e-05)max mem: 15.94594 GB 
[10/31 23:40:44][INFO] visual_prompt:  316: Inference (val):avg data time: 1.07e-04, avg batch time: 0.2335, average loss: 0.7248
[10/31 23:40:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 58.57	
[10/31 23:41:39][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.841, 0.2264 s / batch. (data: 5.70e-05)max mem: 15.94594 GB 
[10/31 23:42:32][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.457, 0.2396 s / batch. (data: 3.17e-05)max mem: 15.94594 GB 
[10/31 23:43:24][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.863, 0.2244 s / batch. (data: 5.39e-05)max mem: 15.94594 GB 
[10/31 23:43:35][INFO] visual_prompt:  316: Inference (test):avg data time: 2.23e-04, avg batch time: 0.2329, average loss: 0.7475
[10/31 23:43:35][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 48.22	rocauc: 58.02	
[10/31 23:43:35][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/31 23:44:41][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.4637,	0.6410 s / batch. (data: 8.72e-04). ETA=16:55:09, max mem: 15.9 GB 
[10/31 23:45:45][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.9214,	0.6692 s / batch. (data: 6.04e-03). ETA=17:38:36, max mem: 15.9 GB 
[10/31 23:46:49][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.4180,	0.6332 s / batch. (data: 8.89e-04). ETA=16:40:40, max mem: 15.9 GB 
[10/31 23:47:53][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.6450,	0.6480 s / batch. (data: 8.96e-04). ETA=17:02:54, max mem: 15.9 GB 
[10/31 23:48:56][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2552,	0.6440 s / batch. (data: 3.49e-04). ETA=16:55:33, max mem: 15.9 GB 
[10/31 23:50:00][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.2834,	0.6288 s / batch. (data: 3.40e-04). ETA=16:30:36, max mem: 15.9 GB 
[10/31 23:51:03][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.4519,	0.6485 s / batch. (data: 1.57e-02). ETA=17:00:32, max mem: 15.9 GB 
[10/31 23:52:07][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7617,	0.6445 s / batch. (data: 9.12e-04). ETA=16:53:10, max mem: 15.9 GB 
[10/31 23:53:11][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 1.5614,	0.6303 s / batch. (data: 8.81e-04). ETA=16:29:43, max mem: 15.9 GB 
[10/31 23:54:15][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 2.9085,	0.6564 s / batch. (data: 1.11e-02). ETA=17:09:36, max mem: 15.9 GB 
[10/31 23:55:19][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8081,	0.6177 s / batch. (data: 2.24e-04). ETA=16:07:53, max mem: 15.9 GB 
[10/31 23:55:22][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 6.08e-03, avg batch time: 0.6396, average train loss: 1.0532
[10/31 23:56:17][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.903, 0.2250 s / batch. (data: 3.12e-05)max mem: 15.94594 GB 
[10/31 23:56:29][INFO] visual_prompt:  316: Inference (val):avg data time: 4.81e-05, avg batch time: 0.2323, average loss: 0.8516
[10/31 23:56:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.99	
[10/31 23:57:24][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.211, 0.2244 s / batch. (data: 3.22e-05)max mem: 15.94594 GB 
[10/31 23:58:17][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.686, 0.2276 s / batch. (data: 3.08e-05)max mem: 15.94594 GB 
[10/31 23:59:09][INFO] visual_prompt:  303: 	Test 300/323. loss: 1.111, 0.2430 s / batch. (data: 6.72e-05)max mem: 15.94594 GB 
[10/31 23:59:20][INFO] visual_prompt:  316: Inference (test):avg data time: 1.53e-04, avg batch time: 0.2316, average loss: 0.7793
[10/31 23:59:20][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.39	
[10/31 23:59:20][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/01 00:00:27][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.0050,	0.6215 s / batch. (data: 3.59e-04). ETA=16:12:45, max mem: 15.9 GB 
[11/01 00:01:31][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 0.4101,	0.6261 s / batch. (data: 3.43e-04). ETA=16:18:51, max mem: 15.9 GB 
[11/01 00:02:34][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 1.3606,	0.6428 s / batch. (data: 8.81e-04). ETA=16:43:57, max mem: 15.9 GB 
[11/01 00:03:38][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.9608,	0.6442 s / batch. (data: 8.65e-04). ETA=16:45:00, max mem: 15.9 GB 
[11/01 00:04:42][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.0023,	0.6428 s / batch. (data: 1.23e-02). ETA=16:41:44, max mem: 15.9 GB 
[11/01 00:05:46][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 2.5657,	0.6547 s / batch. (data: 1.19e-03). ETA=16:59:15, max mem: 15.9 GB 
[11/01 00:06:49][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 2.9459,	0.6320 s / batch. (data: 3.42e-04). ETA=16:22:52, max mem: 15.9 GB 
[11/01 00:07:53][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.5161,	0.6600 s / batch. (data: 3.63e-04). ETA=17:05:18, max mem: 15.9 GB 
[11/01 00:08:57][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6515,	0.6249 s / batch. (data: 3.66e-04). ETA=16:09:43, max mem: 15.9 GB 
[11/01 00:10:00][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6496,	0.6237 s / batch. (data: 3.26e-04). ETA=16:06:52, max mem: 15.9 GB 
[11/01 00:11:04][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 1.0214,	0.6193 s / batch. (data: 2.51e-04). ETA=15:59:00, max mem: 15.9 GB 
[11/01 00:11:08][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 7.02e-03, avg batch time: 0.6401, average train loss: 1.0984
[11/01 00:12:02][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.604, 0.2326 s / batch. (data: 6.08e-05)max mem: 15.94594 GB 
[11/01 00:12:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.87e-05, avg batch time: 0.2332, average loss: 0.7446
[11/01 00:12:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.98	
[11/01 00:13:08][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.930, 0.2366 s / batch. (data: 6.03e-05)max mem: 15.94594 GB 
[11/01 00:14:01][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.571, 0.2241 s / batch. (data: 3.10e-05)max mem: 15.94594 GB 
[11/01 00:14:53][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.742, 0.2242 s / batch. (data: 4.67e-05)max mem: 15.94594 GB 
[11/01 00:15:04][INFO] visual_prompt:  316: Inference (test):avg data time: 1.05e-04, avg batch time: 0.2320, average loss: 0.7895
[11/01 00:15:04][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 42.17	rocauc: 55.89	
[11/01 00:15:04][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/01 00:16:10][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.2174,	0.6400 s / batch. (data: 5.53e-03). ETA=16:29:54, max mem: 15.9 GB 
[11/01 00:17:13][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.7627,	0.6185 s / batch. (data: 3.58e-04). ETA=15:55:33, max mem: 15.9 GB 
[11/01 00:18:17][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.0353,	0.6360 s / batch. (data: 3.69e-04). ETA=16:21:37, max mem: 15.9 GB 
[11/01 00:19:21][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.2475,	0.6542 s / batch. (data: 1.41e-02). ETA=16:48:33, max mem: 15.9 GB 
[11/01 00:20:24][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.6839,	0.6441 s / batch. (data: 1.28e-02). ETA=16:32:01, max mem: 15.9 GB 
[11/01 00:21:28][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.6526,	0.6349 s / batch. (data: 1.49e-02). ETA=16:16:46, max mem: 15.9 GB 
[11/01 00:22:31][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.2450,	0.6296 s / batch. (data: 8.27e-04). ETA=16:07:28, max mem: 15.9 GB 
[11/01 00:23:35][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.2180,	0.6320 s / batch. (data: 3.49e-04). ETA=16:10:09, max mem: 15.9 GB 
[11/01 00:24:39][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.8981,	0.6195 s / batch. (data: 3.21e-04). ETA=15:49:58, max mem: 15.9 GB 
[11/01 00:25:43][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.2737,	0.6327 s / batch. (data: 8.86e-04). ETA=16:09:07, max mem: 15.9 GB 
[11/01 00:26:46][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.2346,	0.6183 s / batch. (data: 2.16e-04). ETA=15:46:06, max mem: 15.9 GB 
[11/01 00:26:50][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 6.15e-03, avg batch time: 0.6385, average train loss: 0.9984
[11/01 00:27:45][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.618, 0.2386 s / batch. (data: 4.05e-05)max mem: 15.94594 GB 
[11/01 00:27:56][INFO] visual_prompt:  316: Inference (val):avg data time: 1.37e-04, avg batch time: 0.2318, average loss: 0.6990
[11/01 00:27:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 59.73	
[11/01 00:28:51][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.825, 0.2316 s / batch. (data: 3.10e-05)max mem: 15.94594 GB 
[11/01 00:29:43][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.446, 0.2563 s / batch. (data: 3.08e-05)max mem: 15.94594 GB 
[11/01 00:30:35][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.680, 0.2245 s / batch. (data: 5.65e-05)max mem: 15.94594 GB 
[11/01 00:30:46][INFO] visual_prompt:  316: Inference (test):avg data time: 1.80e-04, avg batch time: 0.2322, average loss: 0.7159
[11/01 00:30:46][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 51.78	rocauc: 59.60	
[11/01 00:30:46][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/01 00:31:53][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 1.0400,	0.6179 s / batch. (data: 3.69e-04). ETA=15:44:18, max mem: 15.9 GB 
[11/01 00:32:58][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.0680,	0.6609 s / batch. (data: 1.11e-02). ETA=16:48:55, max mem: 15.9 GB 
[11/01 00:34:02][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6831,	0.6424 s / batch. (data: 2.27e-02). ETA=16:19:35, max mem: 15.9 GB 
[11/01 00:35:05][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 1.4984,	0.6336 s / batch. (data: 1.60e-02). ETA=16:05:07, max mem: 15.9 GB 
[11/01 00:36:09][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 1.8985,	0.6384 s / batch. (data: 8.73e-04). ETA=16:11:26, max mem: 15.9 GB 
[11/01 00:37:13][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3490,	0.6560 s / batch. (data: 8.83e-04). ETA=16:37:08, max mem: 15.9 GB 
[11/01 00:38:16][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.9255,	0.6432 s / batch. (data: 8.66e-04). ETA=16:16:36, max mem: 15.9 GB 
[11/01 00:39:20][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.7442,	0.6299 s / batch. (data: 8.58e-04). ETA=15:55:16, max mem: 15.9 GB 
[11/01 00:40:24][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 2.3954,	0.6336 s / batch. (data: 8.39e-04). ETA=15:59:55, max mem: 15.9 GB 
[11/01 00:41:28][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 1.8764,	0.6280 s / batch. (data: 3.39e-04). ETA=15:50:20, max mem: 15.9 GB 
[11/01 00:42:32][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.1208,	0.6193 s / batch. (data: 2.17e-04). ETA=15:36:04, max mem: 15.9 GB 
[11/01 00:42:35][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 7.42e-03, avg batch time: 0.6412, average train loss: 1.0508
[11/01 00:43:30][INFO] visual_prompt:  303: 	Test 100/123. loss: 1.054, 0.2249 s / batch. (data: 5.79e-05)max mem: 15.94594 GB 
[11/01 00:43:41][INFO] visual_prompt:  316: Inference (val):avg data time: 4.81e-05, avg batch time: 0.2321, average loss: 0.9659
[11/01 00:43:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.08	
[11/01 00:44:36][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.112, 0.2394 s / batch. (data: 2.98e-05)max mem: 15.94594 GB 
[11/01 00:45:29][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.491, 0.2244 s / batch. (data: 7.84e-05)max mem: 15.94594 GB 
[11/01 00:46:21][INFO] visual_prompt:  303: 	Test 300/323. loss: 1.503, 0.2297 s / batch. (data: 4.63e-05)max mem: 15.94594 GB 
[11/01 00:46:31][INFO] visual_prompt:  316: Inference (test):avg data time: 4.93e-05, avg batch time: 0.2323, average loss: 0.8988
[11/01 00:46:31][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.91	rocauc: 56.56	
[11/01 00:46:31][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/01 00:47:37][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 2.4825,	0.6326 s / batch. (data: 3.61e-04). ETA=15:55:13, max mem: 15.9 GB 
[11/01 00:48:41][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.2786,	0.6280 s / batch. (data: 3.64e-04). ETA=15:47:09, max mem: 15.9 GB 
[11/01 00:49:44][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.6520,	0.6448 s / batch. (data: 1.11e-02). ETA=16:11:23, max mem: 15.9 GB 
[11/01 00:50:48][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.3643,	0.6583 s / batch. (data: 6.08e-03). ETA=16:30:39, max mem: 15.9 GB 
[11/01 00:51:52][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.4577,	0.6200 s / batch. (data: 3.85e-04). ETA=15:31:57, max mem: 15.9 GB 
[11/01 00:52:55][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 1.3693,	0.6327 s / batch. (data: 5.57e-03). ETA=15:50:05, max mem: 15.9 GB 
[11/01 00:53:59][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 1.7280,	0.6400 s / batch. (data: 8.08e-04). ETA=15:59:54, max mem: 15.9 GB 
[11/01 00:55:03][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.8469,	0.6480 s / batch. (data: 8.48e-04). ETA=16:10:51, max mem: 15.9 GB 
[11/01 00:56:07][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.6623,	0.6435 s / batch. (data: 8.77e-04). ETA=16:02:59, max mem: 15.9 GB 
[11/01 00:57:10][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.7865,	0.6280 s / batch. (data: 3.49e-04). ETA=15:38:45, max mem: 15.9 GB 
[11/01 00:58:14][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 2.6994,	0.6314 s / batch. (data: 2.32e-04). ETA=15:42:50, max mem: 15.9 GB 
[11/01 00:58:18][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 5.45e-03, avg batch time: 0.6388, average train loss: 1.0415
[11/01 00:59:13][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.553, 0.2278 s / batch. (data: 5.29e-05)max mem: 15.94594 GB 
[11/01 00:59:24][INFO] visual_prompt:  316: Inference (val):avg data time: 5.06e-05, avg batch time: 0.2326, average loss: 0.7205
[11/01 00:59:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 58.73	
[11/01 01:00:19][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.653, 0.2241 s / batch. (data: 5.60e-05)max mem: 15.94594 GB 
[11/01 01:01:11][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.246, 0.2517 s / batch. (data: 3.15e-05)max mem: 15.94594 GB 
[11/01 01:02:03][INFO] visual_prompt:  303: 	Test 300/323. loss: 0.689, 0.2296 s / batch. (data: 4.70e-05)max mem: 15.94594 GB 
[11/01 01:02:14][INFO] visual_prompt:  316: Inference (test):avg data time: 9.59e-05, avg batch time: 0.2321, average loss: 0.7266
[11/01 01:02:14][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.14	rocauc: 59.69	
[11/01 01:02:14][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/01 01:03:20][INFO] visual_prompt:  204: 	Training 100/1106. train loss: 0.6220,	0.6427 s / batch. (data: 4.43e-04). ETA=15:58:35, max mem: 15.9 GB 
[11/01 01:04:24][INFO] visual_prompt:  204: 	Training 200/1106. train loss: 1.1063,	0.6462 s / batch. (data: 6.03e-03). ETA=16:02:43, max mem: 15.9 GB 
[11/01 01:05:28][INFO] visual_prompt:  204: 	Training 300/1106. train loss: 0.8220,	0.6682 s / batch. (data: 3.79e-02). ETA=16:34:22, max mem: 15.9 GB 
[11/01 01:06:31][INFO] visual_prompt:  204: 	Training 400/1106. train loss: 0.5753,	0.6480 s / batch. (data: 8.46e-04). ETA=16:03:13, max mem: 15.9 GB 
[11/01 01:07:35][INFO] visual_prompt:  204: 	Training 500/1106. train loss: 0.2128,	0.6266 s / batch. (data: 3.72e-04). ETA=15:30:22, max mem: 15.9 GB 
[11/01 01:08:39][INFO] visual_prompt:  204: 	Training 600/1106. train loss: 0.8239,	0.6391 s / batch. (data: 8.87e-04). ETA=15:47:49, max mem: 15.9 GB 
[11/01 01:09:43][INFO] visual_prompt:  204: 	Training 700/1106. train loss: 0.3344,	0.6433 s / batch. (data: 5.55e-03). ETA=15:53:00, max mem: 15.9 GB 
[11/01 01:10:47][INFO] visual_prompt:  204: 	Training 800/1106. train loss: 0.6722,	0.6468 s / batch. (data: 8.96e-04). ETA=15:57:06, max mem: 15.9 GB 
[11/01 01:11:50][INFO] visual_prompt:  204: 	Training 900/1106. train loss: 0.2495,	0.6430 s / batch. (data: 8.59e-04). ETA=15:50:26, max mem: 15.9 GB 
[11/01 01:12:54][INFO] visual_prompt:  204: 	Training 1000/1106. train loss: 0.6905,	0.6179 s / batch. (data: 3.58e-04). ETA=15:12:19, max mem: 15.9 GB 
[11/01 01:13:58][INFO] visual_prompt:  204: 	Training 1100/1106. train loss: 0.8409,	0.6191 s / batch. (data: 2.32e-04). ETA=15:12:58, max mem: 15.9 GB 
[11/01 01:14:02][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 6.60e-03, avg batch time: 0.6401, average train loss: 1.0522
[11/01 01:14:56][INFO] visual_prompt:  303: 	Test 100/123. loss: 0.931, 0.2316 s / batch. (data: 3.19e-05)max mem: 15.94594 GB 
[11/01 01:15:07][INFO] visual_prompt:  316: Inference (val):avg data time: 5.03e-05, avg batch time: 0.2326, average loss: 0.9056
[11/01 01:15:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.99	
[11/01 01:16:02][INFO] visual_prompt:  303: 	Test 100/323. loss: 0.166, 0.2268 s / batch. (data: 4.96e-05)max mem: 15.94594 GB 
[11/01 01:16:55][INFO] visual_prompt:  303: 	Test 200/323. loss: 0.560, 0.2357 s / batch. (data: 3.74e-05)max mem: 15.94594 GB 
[11/01 01:17:46][INFO] visual_prompt:  303: 	Test 300/323. loss: 1.126, 0.2247 s / batch. (data: 5.29e-05)max mem: 15.94594 GB 
[11/01 01:17:58][INFO] visual_prompt:  316: Inference (test):avg data time: 2.05e-04, avg batch time: 0.2324, average loss: 0.8379
[11/01 01:17:58][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 57.35	
[11/01 01:17:58][INFO] visual_prompt:   42: Stopping early.
