[11/28 16:03:05][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/28 16:03:05][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 16:03:05][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[11/28 16:03:05][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 16:03:05][INFO] visual_prompt:  108: Training with config:
[11/28 16:03:05][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/test/seed8393/lr0.25_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8393, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/28 16:03:05][INFO] visual_prompt:   55: Loading training data...
[11/28 16:03:05][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/28 16:03:05][INFO] visual_prompt:   57: Loading validation data...
[11/28 16:03:05][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/28 16:03:05][INFO] visual_prompt:   61: Loading test data...
[11/28 16:03:05][INFO] visual_prompt:   28: Constructing mammo-cbis dataset test...
[11/28 16:03:05][INFO] visual_prompt:   38: Constructing models...
[11/28 16:03:08][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[11/28 16:03:08][INFO] visual_prompt:   54: tuned percent:0.525
[11/28 16:03:08][INFO] visual_prompt:   40: Device used for model: 0
[11/28 16:03:08][INFO] visual_prompt:   40: Setting up Evaluator...
[11/28 16:03:08][INFO] visual_prompt:   42: Setting up Trainer...
[11/28 16:03:08][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/28 16:03:08][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/28 16:04:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.9026,	0.8409 s / batch. (data: 1.64e-02). ETA=12:53:37, max mem: 20.9 GB 
[11/28 16:06:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.0438,	1.4710 s / batch. (data: 6.60e-01). ETA=22:30:54, max mem: 20.9 GB 
[11/28 16:08:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5743,	0.8160 s / batch. (data: 3.44e-04). ETA=12:28:00, max mem: 20.9 GB 
[11/28 16:10:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.8444,	0.8360 s / batch. (data: 3.29e-04). ETA=12:44:57, max mem: 20.9 GB 
[11/28 16:11:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3674,	0.8303 s / batch. (data: 3.82e-04). ETA=12:38:21, max mem: 20.9 GB 
[11/28 16:12:44][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 2.16e-01, avg batch time: 1.0415, average train loss: 1.5642
[11/28 16:13:44][INFO] visual_prompt:  316: Inference (val):avg data time: 5.43e-05, avg batch time: 0.3087, average loss: 1.5627
[11/28 16:13:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.52	
[11/28 16:15:23][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.942, 0.3132 s / batch. (data: 4.91e-05)max mem: 20.92025 GB 
[11/28 16:16:17][INFO] visual_prompt:  316: Inference (test):avg data time: 4.95e-05, avg batch time: 0.3099, average loss: 1.4065
[11/28 16:16:17][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 53.97	
[11/28 16:16:17][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.025
[11/28 16:18:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3988,	2.5095 s / batch. (data: 1.68e+00). ETA=1 day, 14:05:38, max mem: 20.9 GB 
[11/28 16:19:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6891,	0.8270 s / batch. (data: 3.43e-04). ETA=12:31:51, max mem: 20.9 GB 
[11/28 16:21:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6664,	1.0320 s / batch. (data: 2.15e-01). ETA=15:36:27, max mem: 20.9 GB 
[11/28 16:23:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6510,	0.8132 s / batch. (data: 3.45e-04). ETA=12:16:32, max mem: 20.9 GB 
[11/28 16:24:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7170,	0.8301 s / batch. (data: 3.63e-04). ETA=12:30:30, max mem: 20.9 GB 
[11/28 16:25:53][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 2.15e-01, avg batch time: 1.0408, average train loss: 0.8184
[11/28 16:26:52][INFO] visual_prompt:  316: Inference (val):avg data time: 4.57e-05, avg batch time: 0.3072, average loss: 0.6905
[11/28 16:26:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 50.95	
[11/28 16:28:31][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.727, 0.3079 s / batch. (data: 4.94e-05)max mem: 20.92025 GB 
[11/28 16:29:25][INFO] visual_prompt:  316: Inference (test):avg data time: 1.78e-04, avg batch time: 0.3082, average loss: 0.6853
[11/28 16:29:25][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.91	rocauc: 52.72	
[11/28 16:29:25][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.05
[11/28 16:31:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6567,	1.0064 s / batch. (data: 1.98e-01). ETA=15:07:20, max mem: 20.9 GB 
[11/28 16:32:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5431,	0.8371 s / batch. (data: 9.06e-03). ETA=12:33:20, max mem: 20.9 GB 
[11/28 16:34:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.2176,	0.8326 s / batch. (data: 3.40e-04). ETA=12:27:54, max mem: 20.9 GB 
[11/28 16:36:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2469,	0.8120 s / batch. (data: 3.21e-04). ETA=12:08:01, max mem: 20.9 GB 
[11/28 16:38:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7580,	0.8230 s / batch. (data: 3.51e-04). ETA=12:16:31, max mem: 20.9 GB 
[11/28 16:39:03][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 2.19e-01, avg batch time: 1.0439, average train loss: 0.8115
[11/28 16:40:02][INFO] visual_prompt:  316: Inference (val):avg data time: 4.49e-05, avg batch time: 0.3088, average loss: 0.7281
[11/28 16:40:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.65	
[11/28 16:41:40][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.744, 0.3036 s / batch. (data: 4.82e-05)max mem: 20.92025 GB 
[11/28 16:42:35][INFO] visual_prompt:  316: Inference (test):avg data time: 4.86e-05, avg batch time: 0.3084, average loss: 0.7395
[11/28 16:42:35][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 55.06	
[11/28 16:42:35][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.075
[11/28 16:44:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7590,	1.7726 s / batch. (data: 9.36e-01). ETA=1 day, 2:21:45, max mem: 20.9 GB 
[11/28 16:46:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6798,	0.8320 s / batch. (data: 8.02e-03). ETA=12:21:04, max mem: 20.9 GB 
[11/28 16:47:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1722,	0.8279 s / batch. (data: 5.98e-03). ETA=12:16:02, max mem: 20.9 GB 
[11/28 16:49:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9550,	0.8240 s / batch. (data: 3.02e-04). ETA=12:11:10, max mem: 20.9 GB 
[11/28 16:51:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6652,	0.8321 s / batch. (data: 4.46e-04). ETA=12:16:57, max mem: 20.9 GB 
[11/28 16:52:11][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 2.16e-01, avg batch time: 1.0410, average train loss: 0.8216
[11/28 16:53:11][INFO] visual_prompt:  316: Inference (val):avg data time: 4.60e-05, avg batch time: 0.3076, average loss: 0.7885
[11/28 16:53:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.10	
[11/28 16:54:49][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.753, 0.3089 s / batch. (data: 7.92e-05)max mem: 20.92025 GB 
[11/28 16:55:44][INFO] visual_prompt:  316: Inference (test):avg data time: 1.92e-04, avg batch time: 0.3078, average loss: 0.8181
[11/28 16:55:44][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 58.58	
[11/28 16:55:44][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.1
[11/28 16:57:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6850,	0.8267 s / batch. (data: 3.14e-04). ETA=12:10:06, max mem: 20.9 GB 
[11/28 16:59:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7549,	0.8280 s / batch. (data: 3.29e-04). ETA=12:09:50, max mem: 20.9 GB 
[11/28 17:00:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3173,	0.8320 s / batch. (data: 3.15e-04). ETA=12:11:59, max mem: 20.9 GB 
[11/28 17:02:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5281,	0.8257 s / batch. (data: 5.45e-03). ETA=12:05:06, max mem: 20.9 GB 
[11/28 17:04:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5014,	2.0156 s / batch. (data: 1.20e+00). ETA=1 day, 5:26:36, max mem: 20.9 GB 
[11/28 17:05:19][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 2.13e-01, avg batch time: 1.0393, average train loss: 0.8297
[11/28 17:06:18][INFO] visual_prompt:  316: Inference (val):avg data time: 4.74e-05, avg batch time: 0.3085, average loss: 0.6852
[11/28 17:06:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 55.75	
[11/28 17:07:56][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.695, 0.3270 s / batch. (data: 4.84e-05)max mem: 20.92025 GB 
[11/28 17:08:51][INFO] visual_prompt:  316: Inference (test):avg data time: 4.69e-05, avg batch time: 0.3100, average loss: 0.6768
[11/28 17:08:51][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 58.76	rocauc: 60.16	
[11/28 17:08:51][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.125
[11/28 17:10:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7243,	0.8371 s / batch. (data: 9.53e-03). ETA=12:11:35, max mem: 20.9 GB 
[11/28 17:12:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8198,	1.7200 s / batch. (data: 8.98e-01). ETA=1 day, 1:00:14, max mem: 20.9 GB 
[11/28 17:14:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9502,	0.8586 s / batch. (data: 1.56e-02). ETA=12:27:29, max mem: 20.9 GB 
[11/28 17:15:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.6833,	0.8385 s / batch. (data: 1.43e-02). ETA=12:08:35, max mem: 20.9 GB 
[11/28 17:17:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1074,	0.8454 s / batch. (data: 2.59e-02). ETA=12:13:09, max mem: 20.9 GB 
[11/28 17:18:27][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 2.15e-01, avg batch time: 1.0412, average train loss: 0.8250
[11/28 17:19:27][INFO] visual_prompt:  316: Inference (val):avg data time: 4.64e-05, avg batch time: 0.3097, average loss: 0.7429
[11/28 17:19:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.94	
[11/28 17:21:05][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.753, 0.3034 s / batch. (data: 7.70e-05)max mem: 20.92025 GB 
[11/28 17:22:00][INFO] visual_prompt:  316: Inference (test):avg data time: 4.71e-05, avg batch time: 0.3089, average loss: 0.6970
[11/28 17:22:00][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.33	
[11/28 17:22:00][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.15
[11/28 17:23:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7105,	0.8259 s / batch. (data: 7.95e-03). ETA=11:54:10, max mem: 20.9 GB 
[11/28 17:25:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3889,	0.8494 s / batch. (data: 9.35e-03). ETA=12:13:03, max mem: 20.9 GB 
[11/28 17:27:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.4684,	0.8155 s / batch. (data: 3.38e-04). ETA=11:42:26, max mem: 20.9 GB 
[11/28 17:28:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6319,	0.8227 s / batch. (data: 3.65e-04). ETA=11:47:13, max mem: 20.9 GB 
[11/28 17:30:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0311,	0.8424 s / batch. (data: 1.63e-02). ETA=12:02:50, max mem: 20.9 GB 
[11/28 17:31:37][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 2.18e-01, avg batch time: 1.0433, average train loss: 0.8222
[11/28 17:32:36][INFO] visual_prompt:  316: Inference (val):avg data time: 4.53e-05, avg batch time: 0.3071, average loss: 0.7335
[11/28 17:32:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.79	
[11/28 17:34:14][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.664, 0.3187 s / batch. (data: 7.70e-05)max mem: 20.92025 GB 
[11/28 17:35:09][INFO] visual_prompt:  316: Inference (test):avg data time: 4.86e-05, avg batch time: 0.3090, average loss: 0.7496
[11/28 17:35:09][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 63.95	
[11/28 17:35:09][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.175
[11/28 17:36:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6015,	0.8566 s / batch. (data: 2.06e-02). ETA=12:12:47, max mem: 20.9 GB 
[11/28 17:38:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8938,	0.8093 s / batch. (data: 3.45e-04). ETA=11:30:59, max mem: 20.9 GB 
[11/28 17:40:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.6213,	0.8201 s / batch. (data: 3.39e-04). ETA=11:38:51, max mem: 20.9 GB 
[11/28 17:42:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.6724,	0.8278 s / batch. (data: 1.07e-02). ETA=11:44:02, max mem: 20.9 GB 
[11/28 17:43:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6135,	0.8171 s / batch. (data: 3.27e-04). ETA=11:33:33, max mem: 20.9 GB 
[11/28 17:44:45][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 2.16e-01, avg batch time: 1.0417, average train loss: 0.9772
[11/28 17:45:45][INFO] visual_prompt:  316: Inference (val):avg data time: 1.67e-04, avg batch time: 0.3086, average loss: 1.5409
[11/28 17:45:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.59	
[11/28 17:47:24][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.625, 0.3272 s / batch. (data: 4.94e-05)max mem: 20.92025 GB 
[11/28 17:48:18][INFO] visual_prompt:  316: Inference (test):avg data time: 4.71e-05, avg batch time: 0.3090, average loss: 1.3817
[11/28 17:48:18][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.09	
[11/28 17:48:18][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.2
[11/28 17:50:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3397,	1.9840 s / batch. (data: 1.17e+00). ETA=1 day, 3:59:00, max mem: 20.9 GB 
[11/28 17:51:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3440,	0.8160 s / batch. (data: 4.01e-04). ETA=11:29:12, max mem: 20.9 GB 
[11/28 17:53:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6592,	0.8117 s / batch. (data: 4.35e-04). ETA=11:24:11, max mem: 20.9 GB 
[11/28 17:55:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3258,	0.8218 s / batch. (data: 3.35e-04). ETA=11:31:23, max mem: 20.9 GB 
[11/28 17:57:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5593,	0.8320 s / batch. (data: 3.45e-04). ETA=11:38:32, max mem: 20.9 GB 
[11/28 17:57:54][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 2.16e-01, avg batch time: 1.0419, average train loss: 0.9118
[11/28 17:58:54][INFO] visual_prompt:  316: Inference (val):avg data time: 4.50e-05, avg batch time: 0.3081, average loss: 0.7920
[11/28 17:58:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.56	
[11/28 18:00:32][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.564, 0.3037 s / batch. (data: 5.10e-05)max mem: 20.92025 GB 
[11/28 18:01:26][INFO] visual_prompt:  316: Inference (test):avg data time: 9.17e-05, avg batch time: 0.3088, average loss: 0.8301
[11/28 18:01:26][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.62	rocauc: 66.00	
[11/28 18:01:26][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.225
[11/28 18:03:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7507,	0.8285 s / batch. (data: 3.11e-04). ETA=11:33:27, max mem: 20.9 GB 
[11/28 18:04:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8402,	0.8092 s / batch. (data: 4.03e-04). ETA=11:15:58, max mem: 20.9 GB 
[11/28 18:06:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0067,	0.8520 s / batch. (data: 3.52e-04). ETA=11:50:18, max mem: 20.9 GB 
[11/28 18:08:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5479,	0.8320 s / batch. (data: 3.47e-04). ETA=11:32:16, max mem: 20.9 GB 
[11/28 18:10:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4778,	0.8400 s / batch. (data: 7.95e-03). ETA=11:37:31, max mem: 20.9 GB 
[11/28 18:11:03][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 2.16e-01, avg batch time: 1.0420, average train loss: 1.0329
[11/28 18:12:02][INFO] visual_prompt:  316: Inference (val):avg data time: 1.57e-04, avg batch time: 0.3090, average loss: 0.7012
[11/28 18:12:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 62.85	
[11/28 18:13:40][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.562, 0.3042 s / batch. (data: 1.37e-04)max mem: 20.92025 GB 
[11/28 18:14:35][INFO] visual_prompt:  316: Inference (test):avg data time: 4.92e-05, avg batch time: 0.3093, average loss: 0.7178
[11/28 18:14:35][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 49.46	rocauc: 65.13	
[11/28 18:14:35][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.25
[11/28 18:16:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6710,	0.8093 s / batch. (data: 2.75e-04). ETA=11:09:59, max mem: 20.9 GB 
[11/28 18:18:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7322,	0.9360 s / batch. (data: 1.12e-01). ETA=12:53:17, max mem: 20.9 GB 
[11/28 18:19:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7343,	0.8400 s / batch. (data: 7.96e-03). ETA=11:32:33, max mem: 20.9 GB 
[11/28 18:21:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5683,	1.5935 s / batch. (data: 7.80e-01). ETA=21:51:09, max mem: 20.9 GB 
[11/28 18:23:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5666,	0.8685 s / batch. (data: 1.05e-02). ETA=11:53:11, max mem: 20.9 GB 
[11/28 18:24:12][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 2.17e-01, avg batch time: 1.0431, average train loss: 0.9752
[11/28 18:25:12][INFO] visual_prompt:  316: Inference (val):avg data time: 4.52e-05, avg batch time: 0.3079, average loss: 0.7296
[11/28 18:25:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 63.71	
[11/28 18:26:50][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.531, 0.3216 s / batch. (data: 5.51e-05)max mem: 20.92025 GB 
[11/28 18:27:44][INFO] visual_prompt:  316: Inference (test):avg data time: 4.87e-05, avg batch time: 0.3101, average loss: 0.7617
[11/28 18:27:44][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 50.39	rocauc: 65.35	
[11/28 18:27:44][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/28 18:29:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5554,	0.8360 s / batch. (data: 3.03e-04). ETA=11:24:21, max mem: 20.9 GB 
[11/28 18:31:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9201,	0.8107 s / batch. (data: 3.44e-04). ETA=11:02:17, max mem: 20.9 GB 
[11/28 18:32:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6151,	0.8245 s / batch. (data: 3.48e-04). ETA=11:12:09, max mem: 20.9 GB 
[11/28 18:34:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0759,	0.8404 s / batch. (data: 5.45e-03). ETA=11:23:47, max mem: 20.9 GB 
[11/28 18:36:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4168,	0.8441 s / batch. (data: 3.65e-04). ETA=11:25:19, max mem: 20.9 GB 
[11/28 18:37:21][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 2.15e-01, avg batch time: 1.0421, average train loss: 0.9030
[11/28 18:38:21][INFO] visual_prompt:  316: Inference (val):avg data time: 4.47e-05, avg batch time: 0.3078, average loss: 1.1994
[11/28 18:38:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.49	
[11/28 18:39:59][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.890, 0.3198 s / batch. (data: 6.65e-05)max mem: 20.92025 GB 
[11/28 18:40:54][INFO] visual_prompt:  316: Inference (test):avg data time: 4.75e-05, avg batch time: 0.3092, average loss: 1.3192
[11/28 18:40:54][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 64.69	
[11/28 18:40:54][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/28 18:42:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4233,	0.9859 s / batch. (data: 1.76e-01). ETA=13:17:59, max mem: 20.9 GB 
[11/28 18:44:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8965,	0.8278 s / batch. (data: 4.57e-04). ETA=11:08:39, max mem: 20.9 GB 
[11/28 18:46:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6423,	0.8403 s / batch. (data: 3.22e-04). ETA=11:17:20, max mem: 20.9 GB 
[11/28 18:47:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5094,	0.8227 s / batch. (data: 1.19e-02). ETA=11:01:48, max mem: 20.9 GB 
[11/28 18:49:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7306,	0.8379 s / batch. (data: 2.07e-02). ETA=11:12:38, max mem: 20.9 GB 
[11/28 18:50:29][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 2.13e-01, avg batch time: 1.0398, average train loss: 0.9497
[11/28 18:51:28][INFO] visual_prompt:  316: Inference (val):avg data time: 4.56e-05, avg batch time: 0.3068, average loss: 1.4000
[11/28 18:51:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.91	
[11/28 18:53:06][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.528, 0.3145 s / batch. (data: 4.94e-05)max mem: 20.92025 GB 
[11/28 18:54:01][INFO] visual_prompt:  316: Inference (test):avg data time: 4.74e-05, avg batch time: 0.3099, average loss: 1.2543
[11/28 18:54:01][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.35	
[11/28 18:54:01][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/28 18:55:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5373,	0.8400 s / batch. (data: 3.82e-04). ETA=11:12:08, max mem: 20.9 GB 
[11/28 18:57:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0711,	0.8330 s / batch. (data: 5.95e-03). ETA=11:05:09, max mem: 20.9 GB 
[11/28 18:59:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.2308,	0.8115 s / batch. (data: 4.84e-04). ETA=10:46:39, max mem: 20.9 GB 
[11/28 19:01:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.9554,	2.4561 s / batch. (data: 1.64e+00). ETA=1 day, 8:33:01, max mem: 20.9 GB 
[11/28 19:02:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6857,	0.8200 s / batch. (data: 4.14e-04). ETA=10:50:40, max mem: 20.9 GB 
[11/28 19:03:38][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 2.15e-01, avg batch time: 1.0422, average train loss: 1.0366
[11/28 19:04:37][INFO] visual_prompt:  316: Inference (val):avg data time: 2.06e-04, avg batch time: 0.3080, average loss: 0.9133
[11/28 19:04:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 67.93	
[11/28 19:06:17][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.985, 0.3086 s / batch. (data: 5.08e-05)max mem: 20.92025 GB 
[11/28 19:07:13][INFO] visual_prompt:  316: Inference (test):avg data time: 4.76e-05, avg batch time: 0.3089, average loss: 0.8274
[11/28 19:07:13][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.53	rocauc: 66.54	
[11/28 19:07:13][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/28 19:09:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4346,	0.8561 s / batch. (data: 2.05e-02). ETA=11:17:08, max mem: 20.9 GB 
[11/28 19:10:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6712,	0.8512 s / batch. (data: 1.05e-02). ETA=11:11:51, max mem: 20.9 GB 
[11/28 19:12:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8174,	2.1193 s / batch. (data: 1.29e+00). ETA=1 day, 3:49:12, max mem: 20.9 GB 
[11/28 19:14:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6161,	0.8318 s / batch. (data: 3.98e-04). ETA=10:53:46, max mem: 20.9 GB 
[11/28 19:16:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4646,	0.8424 s / batch. (data: 8.04e-04). ETA=11:00:40, max mem: 20.9 GB 
[11/28 19:16:55][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 2.18e-01, avg batch time: 1.0512, average train loss: 0.8262
[11/28 19:17:56][INFO] visual_prompt:  316: Inference (val):avg data time: 4.51e-05, avg batch time: 0.3085, average loss: 1.3914
[11/28 19:17:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.03	
[11/28 19:19:35][INFO] visual_prompt:  303: 	Test 100/162. loss: 1.441, 0.3032 s / batch. (data: 5.44e-05)max mem: 20.92025 GB 
[11/28 19:20:30][INFO] visual_prompt:  316: Inference (test):avg data time: 4.93e-05, avg batch time: 0.3098, average loss: 1.2594
[11/28 19:20:30][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 64.35	
[11/28 19:20:30][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/28 19:22:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5817,	2.3359 s / batch. (data: 1.49e+00). ETA=1 day, 6:26:06, max mem: 20.9 GB 
[11/28 19:24:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2833,	0.8539 s / batch. (data: 1.13e-02). ETA=11:06:07, max mem: 20.9 GB 
[11/28 19:25:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.2210,	0.8396 s / batch. (data: 7.94e-03). ETA=10:53:34, max mem: 20.9 GB 
[11/28 19:27:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.1851,	0.8200 s / batch. (data: 3.76e-04). ETA=10:36:55, max mem: 20.9 GB 
[11/28 19:29:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6041,	0.8281 s / batch. (data: 1.20e-02). ETA=10:41:52, max mem: 20.9 GB 
[11/28 19:30:06][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 2.13e-01, avg batch time: 1.0415, average train loss: 0.8916
[11/28 19:31:05][INFO] visual_prompt:  316: Inference (val):avg data time: 4.67e-05, avg batch time: 0.3108, average loss: 0.6711
[11/28 19:31:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 70.27	
[11/28 19:32:43][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.588, 0.3094 s / batch. (data: 5.53e-05)max mem: 20.92025 GB 
[11/28 19:33:38][INFO] visual_prompt:  316: Inference (test):avg data time: 1.44e-04, avg batch time: 0.3099, average loss: 0.6451
[11/28 19:33:38][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 66.79	
[11/28 19:33:38][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.671
[11/28 19:33:38][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/28 19:35:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2301,	1.3160 s / batch. (data: 4.72e-01). ETA=16:56:40, max mem: 20.9 GB 
[11/28 19:37:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0083,	0.8247 s / batch. (data: 3.33e-04). ETA=10:35:44, max mem: 20.9 GB 
[11/28 19:38:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7198,	0.8293 s / batch. (data: 3.28e-04). ETA=10:37:53, max mem: 20.9 GB 
[11/28 19:40:37][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.8718,	0.8533 s / batch. (data: 5.57e-03). ETA=10:54:53, max mem: 20.9 GB 
[11/28 19:42:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.1105,	0.8361 s / batch. (data: 3.22e-04). ETA=10:40:19, max mem: 20.9 GB 
[11/28 19:43:15][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 2.14e-01, avg batch time: 1.0427, average train loss: 0.9001
[11/28 19:44:15][INFO] visual_prompt:  316: Inference (val):avg data time: 4.79e-05, avg batch time: 0.3091, average loss: 1.0079
[11/28 19:44:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 72.98	
[11/28 19:45:53][INFO] visual_prompt:  303: 	Test 100/162. loss: 0.759, 0.3217 s / batch. (data: 6.60e-05)max mem: 20.92025 GB 
[11/28 19:46:47][INFO] visual_prompt:  316: Inference (test):avg data time: 1.91e-04, avg batch time: 0.3089, average loss: 1.1735
[11/28 19:46:47][INFO] visual_prompt:  113: Classification results with test_mammo-cbis: top1: 43.41	rocauc: 65.45	
[11/28 19:46:47][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.24628696578449955
