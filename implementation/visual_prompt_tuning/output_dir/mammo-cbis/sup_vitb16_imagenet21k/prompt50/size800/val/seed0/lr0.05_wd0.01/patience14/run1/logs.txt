[12/02 04:41:13][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[12/02 04:41:13][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 04:41:13][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[12/02 04:41:13][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 04:41:13][INFO] visual_prompt:  108: Training with config:
[12/02 04:41:13][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr0.05_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/02 04:41:13][INFO] visual_prompt:   55: Loading training data...
[12/02 04:41:13][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[12/02 04:41:13][INFO] visual_prompt:   57: Loading validation data...
[12/02 04:41:13][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[12/02 04:41:13][INFO] visual_prompt:   38: Constructing models...
[12/02 04:41:15][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[12/02 04:41:15][INFO] visual_prompt:   54: tuned percent:0.525
[12/02 04:41:16][INFO] visual_prompt:   40: Device used for model: 0
[12/02 04:41:16][INFO] visual_prompt:   40: Setting up Evaluator...
[12/02 04:41:16][INFO] visual_prompt:   42: Setting up Trainer...
[12/02 04:41:16][INFO] visual_prompt:   45: 	Setting up the optimizer...
[12/02 04:41:16][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[12/02 04:43:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8640 s / batch. (data: 3.53e-04). ETA=13:14:51, max mem: 20.9 GB 
[12/02 04:44:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8202 s / batch. (data: 3.12e-04). ETA=12:33:11, max mem: 20.9 GB 
[12/02 04:46:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	1.6307 s / batch. (data: 8.05e-01). ETA=1 day, 0:54:49, max mem: 20.9 GB 
[12/02 04:48:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8175 s / batch. (data: 3.85e-04). ETA=12:28:00, max mem: 20.9 GB 
[12/02 04:49:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8172 s / batch. (data: 7.84e-04). ETA=12:26:24, max mem: 20.9 GB 
[12/02 04:50:51][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 2.17e-01, avg batch time: 1.0403, average train loss: 1.5403
[12/02 04:51:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3082, average loss: 1.5201
[12/02 04:51:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[12/02 04:51:50][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/02 04:53:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7362,	0.8106 s / batch. (data: 3.50e-04). ETA=12:18:14, max mem: 20.9 GB 
[12/02 04:55:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4418,	0.8596 s / batch. (data: 1.97e-02). ETA=13:01:29, max mem: 20.9 GB 
[12/02 04:57:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6967,	1.1501 s / batch. (data: 3.40e-01). ETA=17:23:39, max mem: 20.9 GB 
[12/02 04:58:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7413,	0.8232 s / batch. (data: 3.32e-04). ETA=12:25:39, max mem: 20.9 GB 
[12/02 05:00:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6909,	0.8168 s / batch. (data: 3.03e-04). ETA=12:18:29, max mem: 20.9 GB 
[12/02 05:01:24][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 2.13e-01, avg batch time: 1.0366, average train loss: 0.7611
[12/02 05:02:23][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.3070, average loss: 0.7329
[12/02 05:02:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.20	
[12/02 05:02:23][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/02 05:04:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7497,	0.8200 s / batch. (data: 3.06e-04). ETA=12:19:16, max mem: 20.9 GB 
[12/02 05:05:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7420,	0.8440 s / batch. (data: 1.20e-02). ETA=12:39:33, max mem: 20.9 GB 
[12/02 05:07:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5553,	0.8092 s / batch. (data: 3.17e-04). ETA=12:06:51, max mem: 20.9 GB 
[12/02 05:09:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6189,	0.8238 s / batch. (data: 3.12e-04). ETA=12:18:36, max mem: 20.9 GB 
[12/02 05:11:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7347,	1.3591 s / batch. (data: 5.09e-01). ETA=20:16:15, max mem: 20.9 GB 
[12/02 05:11:56][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 2.11e-01, avg batch time: 1.0353, average train loss: 0.7369
[12/02 05:12:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.3076, average loss: 0.7264
[12/02 05:12:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[12/02 05:12:55][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.015
[12/02 05:14:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7391,	0.8410 s / batch. (data: 1.05e-02). ETA=12:30:29, max mem: 20.9 GB 
[12/02 05:16:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6014,	1.1495 s / batch. (data: 3.30e-01). ETA=17:03:50, max mem: 20.9 GB 
[12/02 05:18:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6650,	1.1170 s / batch. (data: 2.85e-01). ETA=16:33:01, max mem: 20.9 GB 
[12/02 05:19:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7954,	0.8412 s / batch. (data: 2.66e-04). ETA=12:26:25, max mem: 20.9 GB 
[12/02 05:21:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4476,	3.9116 s / batch. (data: 3.10e+00). ETA=2 days, 9:44:26, max mem: 20.9 GB 
[12/02 05:22:30][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 2.13e-01, avg batch time: 1.0385, average train loss: 0.7284
[12/02 05:23:29][INFO] visual_prompt:  316: Inference (val):avg data time: 6.13e-04, avg batch time: 0.3082, average loss: 0.6993
[12/02 05:23:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.44	
[12/02 05:23:29][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/02 05:25:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5385,	0.8240 s / batch. (data: 1.56e-02). ETA=12:07:40, max mem: 20.9 GB 
[12/02 05:26:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5671,	1.3964 s / batch. (data: 5.75e-01). ETA=20:30:51, max mem: 20.9 GB 
[12/02 05:28:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7473,	0.8278 s / batch. (data: 7.92e-03). ETA=12:08:19, max mem: 20.9 GB 
[12/02 05:30:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5758,	0.8497 s / batch. (data: 9.71e-03). ETA=12:26:10, max mem: 20.9 GB 
[12/02 05:32:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6920,	0.8204 s / batch. (data: 1.19e-02). ETA=11:59:00, max mem: 20.9 GB 
[12/02 05:33:04][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 2.14e-01, avg batch time: 1.0384, average train loss: 0.7159
[12/02 05:34:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.3062, average loss: 0.6982
[12/02 05:34:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.16	
[12/02 05:34:03][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.025
[12/02 05:35:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9852,	0.8466 s / batch. (data: 5.45e-03). ETA=12:19:53, max mem: 20.9 GB 
[12/02 05:37:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5738,	0.8511 s / batch. (data: 1.11e-02). ETA=12:22:24, max mem: 20.9 GB 
[12/02 05:39:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6145,	0.8380 s / batch. (data: 5.47e-03). ETA=12:09:34, max mem: 20.9 GB 
[12/02 05:41:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6492,	0.8610 s / batch. (data: 1.71e-02). ETA=12:28:06, max mem: 20.9 GB 
[12/02 05:42:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6936,	0.8328 s / batch. (data: 5.44e-03). ETA=12:02:13, max mem: 20.9 GB 
[12/02 05:43:37][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 2.14e-01, avg batch time: 1.0389, average train loss: 0.7148
[12/02 05:44:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-04, avg batch time: 0.3090, average loss: 0.7517
[12/02 05:44:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.21	
[12/02 05:44:37][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.03
[12/02 05:46:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5537,	0.8096 s / batch. (data: 3.25e-04). ETA=11:40:01, max mem: 20.9 GB 
[12/02 05:48:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6174,	0.8084 s / batch. (data: 3.19e-04). ETA=11:37:42, max mem: 20.9 GB 
[12/02 05:49:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6421,	1.9917 s / batch. (data: 1.18e+00). ETA=1 day, 4:35:37, max mem: 20.9 GB 
[12/02 05:51:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6692,	2.1502 s / batch. (data: 1.33e+00). ETA=1 day, 6:48:33, max mem: 20.9 GB 
[12/02 05:53:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6996,	0.8320 s / batch. (data: 3.25e-04). ETA=11:53:53, max mem: 20.9 GB 
[12/02 05:54:09][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 2.11e-01, avg batch time: 1.0348, average train loss: 0.7063
[12/02 05:55:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-05, avg batch time: 0.3064, average loss: 0.7846
[12/02 05:55:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.72	
[12/02 05:55:09][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/02 05:56:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7271,	0.8321 s / batch. (data: 7.95e-03). ETA=11:51:49, max mem: 20.9 GB 
[12/02 05:58:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0237,	0.8195 s / batch. (data: 3.28e-04). ETA=11:39:44, max mem: 20.9 GB 
[12/02 06:00:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6814,	0.8440 s / batch. (data: 2.94e-04). ETA=11:59:13, max mem: 20.9 GB 
[12/02 06:02:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6991,	1.1923 s / batch. (data: 3.70e-01). ETA=16:54:01, max mem: 20.9 GB 
[12/02 06:03:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9823,	1.6273 s / batch. (data: 8.13e-01). ETA=23:01:17, max mem: 20.9 GB 
[12/02 06:04:43][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 2.16e-01, avg batch time: 1.0390, average train loss: 0.7204
[12/02 06:05:42][INFO] visual_prompt:  316: Inference (val):avg data time: 1.88e-04, avg batch time: 0.3062, average loss: 0.7744
[12/02 06:05:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.18	
[12/02 06:05:42][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/02 06:07:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6898,	0.8240 s / batch. (data: 2.91e-04). ETA=11:37:20, max mem: 20.9 GB 
[12/02 06:09:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5737,	0.8350 s / batch. (data: 1.20e-02). ETA=11:45:15, max mem: 20.9 GB 
[12/02 06:10:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6114,	1.5400 s / batch. (data: 7.14e-01). ETA=21:38:05, max mem: 20.9 GB 
[12/02 06:12:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6397,	0.8360 s / batch. (data: 2.97e-04). ETA=11:43:16, max mem: 20.9 GB 
[12/02 06:14:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5622,	1.1507 s / batch. (data: 3.37e-01). ETA=16:06:09, max mem: 20.9 GB 
[12/02 06:15:16][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 2.13e-01, avg batch time: 1.0364, average train loss: 0.7289
[12/02 06:16:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.63e-05, avg batch time: 0.3076, average loss: 0.7123
[12/02 06:16:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.67	
[12/02 06:16:15][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/02 06:18:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7076,	0.8480 s / batch. (data: 8.31e-04). ETA=11:49:49, max mem: 20.9 GB 
[12/02 06:19:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6601,	0.8312 s / batch. (data: 7.93e-03). ETA=11:34:20, max mem: 20.9 GB 
[12/02 06:21:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6690,	2.8653 s / batch. (data: 2.03e+00). ETA=1 day, 15:48:52, max mem: 20.9 GB 
[12/02 06:23:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8959,	0.9310 s / batch. (data: 1.15e-01). ETA=12:54:38, max mem: 20.9 GB 
[12/02 06:24:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9823,	0.8480 s / batch. (data: 3.32e-04). ETA=11:44:10, max mem: 20.9 GB 
[12/02 06:25:49][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 2.14e-01, avg batch time: 1.0385, average train loss: 0.7426
[12/02 06:26:49][INFO] visual_prompt:  316: Inference (val):avg data time: 4.25e-04, avg batch time: 0.3073, average loss: 0.7593
[12/02 06:26:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.14	
[12/02 06:26:49][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.05
[12/02 06:28:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7617,	0.8228 s / batch. (data: 1.19e-02). ETA=11:21:07, max mem: 20.9 GB 
[12/02 06:30:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0110,	0.8081 s / batch. (data: 3.13e-04). ETA=11:07:37, max mem: 20.9 GB 
[12/02 06:32:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4844,	2.3299 s / batch. (data: 1.52e+00). ETA=1 day, 8:01:00, max mem: 20.9 GB 
[12/02 06:33:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7756,	0.8200 s / batch. (data: 3.19e-04). ETA=11:14:42, max mem: 20.9 GB 
[12/02 06:35:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7049,	0.8178 s / batch. (data: 2.14e-03). ETA=11:11:32, max mem: 20.9 GB 
[12/02 06:36:23][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 2.13e-01, avg batch time: 1.0370, average train loss: 0.7302
[12/02 06:37:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.53e-05, avg batch time: 0.3058, average loss: 0.7035
[12/02 06:37:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.18	
[12/02 06:37:22][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/02 06:39:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8556,	0.9394 s / batch. (data: 1.20e-01). ETA=12:49:00, max mem: 20.9 GB 
[12/02 06:40:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5623,	0.8342 s / batch. (data: 7.94e-03). ETA=11:21:28, max mem: 20.9 GB 
[12/02 06:42:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7245,	0.8360 s / batch. (data: 3.40e-04). ETA=11:21:34, max mem: 20.9 GB 
[12/02 06:44:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7212,	0.8199 s / batch. (data: 3.02e-04). ETA=11:07:04, max mem: 20.9 GB 
[12/02 06:46:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1302,	0.8228 s / batch. (data: 5.43e-03). ETA=11:08:02, max mem: 20.9 GB 
[12/02 06:46:56][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 2.14e-01, avg batch time: 1.0377, average train loss: 0.7411
[12/02 06:47:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.74e-05, avg batch time: 0.3071, average loss: 0.7780
[12/02 06:47:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.04	
[12/02 06:47:55][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/02 06:49:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5924,	0.8420 s / batch. (data: 2.10e-02). ETA=11:21:29, max mem: 20.9 GB 
[12/02 06:51:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7854,	0.8324 s / batch. (data: 3.30e-04). ETA=11:12:22, max mem: 20.9 GB 
[12/02 06:53:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6264,	1.9531 s / batch. (data: 1.14e+00). ETA=1 day, 2:14:22, max mem: 20.9 GB 
[12/02 06:54:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9327,	0.8215 s / batch. (data: 3.25e-04). ETA=11:00:48, max mem: 20.9 GB 
[12/02 06:56:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7167,	0.8469 s / batch. (data: 2.83e-04). ETA=11:19:50, max mem: 20.9 GB 
[12/02 06:57:28][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 2.11e-01, avg batch time: 1.0357, average train loss: 0.7423
[12/02 06:58:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.73e-05, avg batch time: 0.3055, average loss: 0.6906
[12/02 06:58:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.40	
[12/02 06:58:27][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.691
[12/02 06:58:27][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/02 07:00:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7079,	0.8280 s / batch. (data: 4.56e-04). ETA=11:02:33, max mem: 20.9 GB 
[12/02 07:01:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7104,	1.3391 s / batch. (data: 5.17e-01). ETA=17:49:16, max mem: 20.9 GB 
[12/02 07:03:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6932,	0.9322 s / batch. (data: 9.38e-02). ETA=12:22:50, max mem: 20.9 GB 
[12/02 07:05:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6018,	0.8285 s / batch. (data: 1.05e-02). ETA=10:58:49, max mem: 20.9 GB 
[12/02 07:07:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8810,	0.8274 s / batch. (data: 3.02e-04). ETA=10:56:32, max mem: 20.9 GB 
[12/02 07:08:01][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 2.12e-01, avg batch time: 1.0368, average train loss: 0.7261
[12/02 07:09:00][INFO] visual_prompt:  316: Inference (val):avg data time: 1.54e-04, avg batch time: 0.3082, average loss: 0.7525
[12/02 07:09:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.57	
[12/02 07:09:00][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/02 07:10:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7093,	0.8271 s / batch. (data: 3.54e-04). ETA=10:54:10, max mem: 20.9 GB 
[12/02 07:12:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7900,	0.8296 s / batch. (data: 1.04e-03). ETA=10:54:50, max mem: 20.9 GB 
[12/02 07:14:14][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7789,	0.8240 s / batch. (data: 1.20e-02). ETA=10:48:59, max mem: 20.9 GB 
[12/02 07:15:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6269,	0.8841 s / batch. (data: 4.60e-02). ETA=11:34:52, max mem: 20.9 GB 
[12/02 07:17:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8421,	0.8226 s / batch. (data: 3.25e-04). ETA=10:45:07, max mem: 20.9 GB 
[12/02 07:18:33][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 2.13e-01, avg batch time: 1.0363, average train loss: 0.7268
[12/02 07:19:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.66e-05, avg batch time: 0.3060, average loss: 0.6970
[12/02 07:19:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[12/02 07:19:33][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/02 07:21:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5824,	0.8247 s / batch. (data: 1.59e-02). ETA=10:44:43, max mem: 20.9 GB 
[12/02 07:23:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8093,	0.8286 s / batch. (data: 1.05e-02). ETA=10:46:22, max mem: 20.9 GB 
[12/02 07:24:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8776,	0.8504 s / batch. (data: 2.64e-02). ETA=11:01:57, max mem: 20.9 GB 
[12/02 07:26:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7453,	0.8320 s / batch. (data: 8.24e-04). ETA=10:46:14, max mem: 20.9 GB 
[12/02 07:28:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7290,	1.7999 s / batch. (data: 9.77e-01). ETA=23:15:05, max mem: 20.9 GB 
[12/02 07:29:06][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 2.13e-01, avg batch time: 1.0369, average train loss: 0.7222
[12/02 07:30:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.95e-05, avg batch time: 0.3054, average loss: 0.7414
[12/02 07:30:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.75	
[12/02 07:30:06][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/02 07:31:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5557,	0.8191 s / batch. (data: 5.11e-03). ETA=10:32:45, max mem: 20.9 GB 
[12/02 07:33:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6924,	0.8148 s / batch. (data: 7.94e-03). ETA=10:28:06, max mem: 20.9 GB 
[12/02 07:35:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9320,	0.8424 s / batch. (data: 7.94e-03). ETA=10:47:56, max mem: 20.9 GB 
[12/02 07:37:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7058,	1.2382 s / batch. (data: 4.31e-01). ETA=15:50:21, max mem: 20.9 GB 
[12/02 07:38:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6474,	1.3795 s / batch. (data: 5.59e-01). ETA=17:36:32, max mem: 20.9 GB 
[12/02 07:39:40][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 2.14e-01, avg batch time: 1.0376, average train loss: 0.7232
[12/02 07:40:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.67e-05, avg batch time: 0.3065, average loss: 0.7062
[12/02 07:40:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.74	
[12/02 07:40:39][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/02 07:42:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7177,	0.8398 s / batch. (data: 1.17e-02). ETA=10:41:01, max mem: 20.9 GB 
[12/02 07:44:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7552,	0.8240 s / batch. (data: 3.20e-04). ETA=10:27:36, max mem: 20.9 GB 
[12/02 07:45:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6352,	0.8074 s / batch. (data: 3.05e-04). ETA=10:13:37, max mem: 20.9 GB 
[12/02 07:47:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6973,	0.8493 s / batch. (data: 2.13e-02). ETA=10:44:03, max mem: 20.9 GB 
[12/02 07:49:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6885,	0.8115 s / batch. (data: 3.04e-04). ETA=10:14:00, max mem: 20.9 GB 
[12/02 07:50:13][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 2.14e-01, avg batch time: 1.0383, average train loss: 0.7277
[12/02 07:51:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3076, average loss: 0.7176
[12/02 07:51:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.01	
[12/02 07:51:13][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/02 07:53:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1004,	1.2196 s / batch. (data: 4.00e-01). ETA=15:19:42, max mem: 20.9 GB 
[12/02 07:54:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7952,	0.8601 s / batch. (data: 1.20e-02). ETA=10:47:07, max mem: 20.9 GB 
[12/02 07:56:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0886,	0.8192 s / batch. (data: 1.20e-02). ETA=10:15:03, max mem: 20.9 GB 
[12/02 07:58:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5627,	0.8117 s / batch. (data: 2.93e-04). ETA=10:08:03, max mem: 20.9 GB 
[12/02 07:59:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8933,	0.8640 s / batch. (data: 3.35e-04). ETA=10:45:46, max mem: 20.9 GB 
[12/02 08:00:43][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 2.08e-01, avg batch time: 1.0317, average train loss: 0.7233
[12/02 08:01:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.78e-05, avg batch time: 0.3069, average loss: 0.6883
[12/02 08:01:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.65	
[12/02 08:01:43][INFO] visual_prompt:   36: Best epoch 19: best metric: -0.688
[12/02 08:01:43][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/02 08:03:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6585,	0.8412 s / batch. (data: 1.71e-02). ETA=10:26:34, max mem: 20.9 GB 
[12/02 08:05:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6598,	0.8240 s / batch. (data: 7.93e-03). ETA=10:12:24, max mem: 20.9 GB 
[12/02 08:06:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9129,	0.8302 s / batch. (data: 3.14e-04). ETA=10:15:36, max mem: 20.9 GB 
[12/02 08:08:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5675,	0.8316 s / batch. (data: 5.47e-03). ETA=10:15:15, max mem: 20.9 GB 
[12/02 08:10:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8200,	0.8406 s / batch. (data: 3.18e-04). ETA=10:20:34, max mem: 20.9 GB 
[12/02 08:11:18][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 2.15e-01, avg batch time: 1.0393, average train loss: 0.7394
[12/02 08:12:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.62e-05, avg batch time: 0.3069, average loss: 0.8410
[12/02 08:12:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.62	
[12/02 08:12:17][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/02 08:14:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5638,	0.8160 s / batch. (data: 7.94e-03). ETA=10:00:17, max mem: 20.9 GB 
[12/02 08:15:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6998,	0.8275 s / batch. (data: 2.47e-04). ETA=10:07:20, max mem: 20.9 GB 
[12/02 08:17:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8890,	1.1921 s / batch. (data: 3.72e-01). ETA=14:33:01, max mem: 20.9 GB 
[12/02 08:19:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6447,	0.8188 s / batch. (data: 6.71e-03). ETA=9:58:14, max mem: 20.9 GB 
[12/02 08:20:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7090,	0.8181 s / batch. (data: 3.17e-04). ETA=9:56:24, max mem: 20.9 GB 
[12/02 08:21:51][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 2.14e-01, avg batch time: 1.0378, average train loss: 0.7324
[12/02 08:22:50][INFO] visual_prompt:  316: Inference (val):avg data time: 1.84e-04, avg batch time: 0.3047, average loss: 0.8239
[12/02 08:22:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.72	
[12/02 08:22:50][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/02 08:24:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7025,	0.8320 s / batch. (data: 3.26e-04). ETA=10:04:23, max mem: 20.9 GB 
[12/02 08:26:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5765,	0.8360 s / batch. (data: 3.06e-04). ETA=10:05:53, max mem: 20.9 GB 
[12/02 08:28:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4743,	0.8139 s / batch. (data: 3.17e-04). ETA=9:48:31, max mem: 20.9 GB 
[12/02 08:29:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6852,	0.8280 s / batch. (data: 3.67e-04). ETA=9:57:20, max mem: 20.9 GB 
[12/02 08:31:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7153,	0.8084 s / batch. (data: 3.32e-04). ETA=9:41:52, max mem: 20.9 GB 
[12/02 08:32:24][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 2.13e-01, avg batch time: 1.0372, average train loss: 0.7361
[12/02 08:33:24][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3077, average loss: 0.7459
[12/02 08:33:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[12/02 08:33:24][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/02 08:35:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7706,	0.8320 s / batch. (data: 3.08e-04). ETA=9:56:44, max mem: 20.9 GB 
[12/02 08:36:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5909,	0.9584 s / batch. (data: 1.43e-01). ETA=11:25:47, max mem: 20.9 GB 
[12/02 08:38:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9823,	0.8441 s / batch. (data: 8.81e-04). ETA=10:02:34, max mem: 20.9 GB 
[12/02 08:40:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5615,	0.8389 s / batch. (data: 7.91e-04). ETA=9:57:28, max mem: 20.9 GB 
[12/02 08:42:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8922,	0.8421 s / batch. (data: 2.09e-02). ETA=9:58:22, max mem: 20.9 GB 
[12/02 08:42:57][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 2.12e-01, avg batch time: 1.0362, average train loss: 0.7355
[12/02 08:43:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.3070, average loss: 0.6890
[12/02 08:43:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.04	
[12/02 08:43:56][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/02 08:45:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8287,	0.8277 s / batch. (data: 5.45e-03). ETA=9:46:01, max mem: 20.9 GB 
[12/02 08:47:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8403,	0.8204 s / batch. (data: 7.98e-04). ETA=9:39:27, max mem: 20.9 GB 
[12/02 08:49:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7115,	1.1363 s / batch. (data: 3.30e-01). ETA=13:20:45, max mem: 20.9 GB 
[12/02 08:50:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6434,	0.8319 s / batch. (data: 1.19e-02). ETA=9:44:52, max mem: 20.9 GB 
[12/02 08:52:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6983,	0.8360 s / batch. (data: 3.36e-04). ETA=9:46:20, max mem: 20.9 GB 
[12/02 08:53:29][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 2.14e-01, avg batch time: 1.0369, average train loss: 0.7322
[12/02 08:54:29][INFO] visual_prompt:  316: Inference (val):avg data time: 3.68e-04, avg batch time: 0.3063, average loss: 0.7030
[12/02 08:54:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.87	
[12/02 08:54:29][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/02 08:56:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6338,	0.8120 s / batch. (data: 2.79e-04). ETA=9:27:26, max mem: 20.9 GB 
[12/02 08:58:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7358,	0.8268 s / batch. (data: 1.05e-02). ETA=9:36:23, max mem: 20.9 GB 
[12/02 08:59:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6945,	0.8239 s / batch. (data: 7.92e-03). ETA=9:33:01, max mem: 20.9 GB 
[12/02 09:01:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6581,	1.4279 s / batch. (data: 6.07e-01). ETA=16:30:42, max mem: 20.9 GB 
[12/02 09:03:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8074,	1.7041 s / batch. (data: 8.77e-01). ETA=19:39:26, max mem: 20.9 GB 
[12/02 09:04:02][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 2.13e-01, avg batch time: 1.0373, average train loss: 0.7230
[12/02 09:05:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.67e-05, avg batch time: 0.3075, average loss: 0.7684
[12/02 09:05:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.02	
[12/02 09:05:02][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/02 09:06:49][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6225,	0.8127 s / batch. (data: 3.04e-04). ETA=9:20:23, max mem: 20.9 GB 
[12/02 09:08:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7678,	1.9662 s / batch. (data: 1.14e+00). ETA=22:32:35, max mem: 20.9 GB 
[12/02 09:10:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4548,	0.8265 s / batch. (data: 3.01e-04). ETA=9:27:12, max mem: 20.9 GB 
[12/02 09:12:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6088,	0.8345 s / batch. (data: 5.47e-03). ETA=9:31:15, max mem: 20.9 GB 
[12/02 09:13:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6843,	0.8291 s / batch. (data: 4.40e-04). ETA=9:26:10, max mem: 20.9 GB 
[12/02 09:14:35][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 2.12e-01, avg batch time: 1.0365, average train loss: 0.7344
[12/02 09:15:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.66e-05, avg batch time: 0.3063, average loss: 0.7692
[12/02 09:15:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.33	
[12/02 09:15:34][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/02 09:17:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5822,	0.8238 s / batch. (data: 3.08e-04). ETA=9:20:27, max mem: 20.9 GB 
[12/02 09:19:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6404,	1.6164 s / batch. (data: 7.85e-01). ETA=18:17:03, max mem: 20.9 GB 
[12/02 09:20:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6310,	0.8385 s / batch. (data: 1.05e-02). ETA=9:27:43, max mem: 20.9 GB 
[12/02 09:22:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6971,	0.8523 s / batch. (data: 3.58e-04). ETA=9:35:37, max mem: 20.9 GB 
[12/02 09:24:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7902,	0.8382 s / batch. (data: 5.83e-03). ETA=9:24:40, max mem: 20.9 GB 
[12/02 09:25:08][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 2.12e-01, avg batch time: 1.0372, average train loss: 0.7307
[12/02 09:26:08][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3071, average loss: 0.7244
[12/02 09:26:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.99	
[12/02 09:26:08][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/02 09:27:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4665,	1.0203 s / batch. (data: 1.77e-01). ETA=11:24:47, max mem: 20.9 GB 
[12/02 09:29:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6210,	0.8200 s / batch. (data: 4.11e-04). ETA=9:08:57, max mem: 20.9 GB 
[12/02 09:31:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6214,	1.6288 s / batch. (data: 8.17e-01). ETA=18:07:45, max mem: 20.9 GB 
[12/02 09:33:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7940,	0.8280 s / batch. (data: 3.04e-04). ETA=9:11:34, max mem: 20.9 GB 
[12/02 09:34:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4935,	0.8399 s / batch. (data: 1.19e-02). ETA=9:18:07, max mem: 20.9 GB 
[12/02 09:35:40][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 2.10e-01, avg batch time: 1.0346, average train loss: 0.7182
[12/02 09:36:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-04, avg batch time: 0.3075, average loss: 0.7068
[12/02 09:36:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.50	
[12/02 09:36:39][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/02 09:38:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4862,	0.8269 s / batch. (data: 3.07e-04). ETA=9:07:22, max mem: 20.9 GB 
[12/02 09:40:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7084,	1.9880 s / batch. (data: 1.15e+00). ETA=21:52:36, max mem: 20.9 GB 
[12/02 09:41:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6940,	0.8112 s / batch. (data: 2.94e-04). ETA=8:54:16, max mem: 20.9 GB 
[12/02 09:43:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5642,	0.9198 s / batch. (data: 1.02e-01). ETA=10:04:14, max mem: 20.9 GB 
[12/02 09:45:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7135,	0.8225 s / batch. (data: 3.04e-04). ETA=8:58:56, max mem: 20.9 GB 
[12/02 09:46:13][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 2.12e-01, avg batch time: 1.0370, average train loss: 0.7329
[12/02 09:47:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.76e-05, avg batch time: 0.3096, average loss: 0.6886
[12/02 09:47:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.75	
[12/02 09:47:12][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/02 09:48:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7129,	0.8323 s / batch. (data: 1.05e-02). ETA=9:03:14, max mem: 20.9 GB 
[12/02 09:50:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8537,	0.8333 s / batch. (data: 1.04e-02). ETA=9:02:32, max mem: 20.9 GB 
[12/02 09:52:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4646,	1.4957 s / batch. (data: 6.79e-01). ETA=16:11:16, max mem: 20.9 GB 
[12/02 09:54:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6949,	1.4349 s / batch. (data: 6.21e-01). ETA=15:29:26, max mem: 20.9 GB 
[12/02 09:55:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6183,	1.5198 s / batch. (data: 6.63e-01). ETA=16:21:51, max mem: 20.9 GB 
[12/02 09:56:46][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 2.12e-01, avg batch time: 1.0369, average train loss: 0.7364
[12/02 09:57:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.72e-04, avg batch time: 0.3053, average loss: 0.6984
[12/02 09:57:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[12/02 09:57:45][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/02 09:59:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6346,	0.8440 s / batch. (data: 1.20e-02). ETA=9:03:07, max mem: 20.9 GB 
[12/02 10:01:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6968,	0.8267 s / batch. (data: 4.81e-03). ETA=8:50:34, max mem: 20.9 GB 
[12/02 10:03:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6921,	0.8279 s / batch. (data: 5.12e-04). ETA=8:49:59, max mem: 20.9 GB 
[12/02 10:04:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5798,	1.2329 s / batch. (data: 4.13e-01). ETA=13:07:11, max mem: 20.9 GB 
[12/02 10:06:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8273,	0.8360 s / batch. (data: 3.22e-04). ETA=8:52:22, max mem: 20.9 GB 
[12/02 10:07:19][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 2.12e-01, avg batch time: 1.0370, average train loss: 0.7255
[12/02 10:08:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.55e-05, avg batch time: 0.3054, average loss: 0.7755
[12/02 10:08:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.90	
[12/02 10:08:18][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/02 10:10:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9652,	0.8362 s / batch. (data: 2.09e-02). ETA=8:50:23, max mem: 20.9 GB 
[12/02 10:11:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6413,	0.8293 s / batch. (data: 5.48e-03). ETA=8:44:39, max mem: 20.9 GB 
[12/02 10:13:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7001,	0.8067 s / batch. (data: 2.88e-04). ETA=8:29:00, max mem: 20.9 GB 
[12/02 10:15:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8825,	0.8200 s / batch. (data: 3.18e-04). ETA=8:36:00, max mem: 20.9 GB 
[12/02 10:17:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7550,	0.8400 s / batch. (data: 2.94e-04). ETA=8:47:12, max mem: 20.9 GB 
[12/02 10:17:52][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 2.14e-01, avg batch time: 1.0377, average train loss: 0.7269
[12/02 10:18:52][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-05, avg batch time: 0.3072, average loss: 0.7076
[12/02 10:18:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.44	
[12/02 10:18:52][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/02 10:20:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0446,	1.1200 s / batch. (data: 2.82e-01). ETA=11:40:03, max mem: 20.9 GB 
[12/02 10:22:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5647,	1.6602 s / batch. (data: 8.54e-01). ETA=17:14:58, max mem: 20.9 GB 
[12/02 10:24:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6214,	0.8235 s / batch. (data: 3.11e-04). ETA=8:32:01, max mem: 20.9 GB 
[12/02 10:25:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7398,	0.8613 s / batch. (data: 9.26e-03). ETA=8:54:02, max mem: 20.9 GB 
[12/02 10:27:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6914,	0.9601 s / batch. (data: 1.30e-01). ETA=9:53:42, max mem: 20.9 GB 
[12/02 10:28:24][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 2.11e-01, avg batch time: 1.0345, average train loss: 0.7358
[12/02 10:29:23][INFO] visual_prompt:  316: Inference (val):avg data time: 4.10e-05, avg batch time: 0.3061, average loss: 0.6893
[12/02 10:29:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.59	
[12/02 10:29:23][INFO] visual_prompt:   42: Stopping early.
