[12/07 06:44:08][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[12/07 06:44:08][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/07 06:44:08][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/07 06:44:08][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/07 06:44:08][INFO] visual_prompt:  108: Training with config:
[12/07 06:44:08][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr0.05_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/07 06:44:08][INFO] visual_prompt:   70: Loading training data...
[12/07 06:44:08][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[12/07 06:44:08][INFO] visual_prompt:   72: Loading validation data...
[12/07 06:44:08][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[12/07 06:44:08][INFO] visual_prompt:   36: Constructing models...
[12/07 06:44:11][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[12/07 06:44:11][INFO] visual_prompt:   54: tuned percent:0.525
[12/07 06:44:11][INFO] visual_prompt:   40: Device used for model: 0
[12/07 06:44:11][INFO] visual_prompt:   38: Setting up Evaluator...
[12/07 06:44:11][INFO] visual_prompt:   40: Setting up Trainer...
[12/07 06:44:11][INFO] visual_prompt:   45: 	Setting up the optimizer...
[12/07 06:44:11][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[12/07 06:46:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8439 s / batch. (data: 6.62e-04). ETA=12:56:20, max mem: 20.9 GB 
[12/07 06:48:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8226 s / batch. (data: 4.52e-04). ETA=12:35:27, max mem: 20.9 GB 
[12/07 06:49:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	2.1919 s / batch. (data: 1.34e+00). ETA=1 day, 9:29:12, max mem: 20.9 GB 
[12/07 06:51:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8160 s / batch. (data: 4.24e-04). ETA=12:26:37, max mem: 20.9 GB 
[12/07 06:53:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8336 s / batch. (data: 3.57e-04). ETA=12:41:19, max mem: 20.9 GB 
[12/07 06:54:43][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 3.09e-01, avg batch time: 1.1416, average train loss: 1.5403
[12/07 06:55:49][INFO] visual_prompt:  316: Inference (val):avg data time: 5.01e-05, avg batch time: 0.3087, average loss: 1.5201
[12/07 06:55:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[12/07 06:55:49][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/07 06:57:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7362,	1.0416 s / batch. (data: 2.25e-01). ETA=15:48:42, max mem: 20.9 GB 
[12/07 06:59:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4418,	0.8267 s / batch. (data: 7.94e-03). ETA=12:31:31, max mem: 20.9 GB 
[12/07 07:01:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6967,	1.3770 s / batch. (data: 5.64e-01). ETA=20:49:32, max mem: 20.9 GB 
[12/07 07:03:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7413,	0.8291 s / batch. (data: 1.06e-02). ETA=12:31:01, max mem: 20.9 GB 
[12/07 07:05:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6909,	0.8281 s / batch. (data: 3.81e-04). ETA=12:28:41, max mem: 20.9 GB 
[12/07 07:06:19][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.07e-01, avg batch time: 1.1384, average train loss: 0.7611
[12/07 07:07:26][INFO] visual_prompt:  316: Inference (val):avg data time: 2.32e-04, avg batch time: 0.3091, average loss: 0.7329
[12/07 07:07:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.20	
[12/07 07:07:26][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/07 07:09:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7497,	0.8518 s / batch. (data: 1.06e-02). ETA=12:47:54, max mem: 20.9 GB 
[12/07 07:11:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7420,	0.8377 s / batch. (data: 3.70e-04). ETA=12:33:51, max mem: 20.9 GB 
[12/07 07:13:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5553,	0.8474 s / batch. (data: 7.06e-03). ETA=12:41:12, max mem: 20.9 GB 
[12/07 07:15:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6189,	0.8392 s / batch. (data: 7.94e-03). ETA=12:32:23, max mem: 20.9 GB 
[12/07 07:16:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7347,	1.7320 s / batch. (data: 9.04e-01). ETA=1 day, 1:49:55, max mem: 20.9 GB 
[12/07 07:17:55][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 3.05e-01, avg batch time: 1.1370, average train loss: 0.7369
[12/07 07:19:00][INFO] visual_prompt:  316: Inference (val):avg data time: 2.20e-04, avg batch time: 0.3087, average loss: 0.7264
[12/07 07:19:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[12/07 07:19:00][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.015
[12/07 07:20:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7391,	0.8598 s / batch. (data: 2.38e-02). ETA=12:47:15, max mem: 20.9 GB 
[12/07 07:22:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6014,	0.8183 s / batch. (data: 3.53e-04). ETA=12:08:53, max mem: 20.9 GB 
[12/07 07:24:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6650,	1.5961 s / batch. (data: 7.80e-01). ETA=23:38:55, max mem: 20.9 GB 
[12/07 07:26:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7954,	1.9303 s / batch. (data: 1.12e+00). ETA=1 day, 4:32:51, max mem: 20.9 GB 
[12/07 07:28:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4476,	4.1272 s / batch. (data: 3.30e+00). ETA=2 days, 12:55:22, max mem: 20.9 GB 
[12/07 07:29:30][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 3.06e-01, avg batch time: 1.1383, average train loss: 0.7284
[12/07 07:30:37][INFO] visual_prompt:  316: Inference (val):avg data time: 5.93e-05, avg batch time: 0.3115, average loss: 0.6993
[12/07 07:30:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.44	
[12/07 07:30:37][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/07 07:32:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5385,	0.8337 s / batch. (data: 6.17e-03). ETA=12:16:16, max mem: 20.9 GB 
[12/07 07:34:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5671,	1.6360 s / batch. (data: 8.09e-01). ETA=1 day, 0:02:04, max mem: 20.9 GB 
[12/07 07:36:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7473,	0.8324 s / batch. (data: 3.24e-04). ETA=12:12:18, max mem: 20.9 GB 
[12/07 07:38:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5758,	0.8256 s / batch. (data: 7.58e-04). ETA=12:05:01, max mem: 20.9 GB 
[12/07 07:40:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6920,	0.8871 s / batch. (data: 1.51e-02). ETA=12:57:29, max mem: 20.9 GB 
[12/07 07:41:07][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 3.06e-01, avg batch time: 1.1392, average train loss: 0.7159
[12/07 07:42:13][INFO] visual_prompt:  316: Inference (val):avg data time: 2.18e-04, avg batch time: 0.3114, average loss: 0.6982
[12/07 07:42:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.16	
[12/07 07:42:13][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.025
[12/07 07:44:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9852,	0.8588 s / batch. (data: 3.31e-03). ETA=12:30:28, max mem: 20.9 GB 
[12/07 07:46:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5738,	0.8268 s / batch. (data: 9.75e-03). ETA=12:01:09, max mem: 20.9 GB 
[12/07 07:47:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6145,	0.8265 s / batch. (data: 3.59e-04). ETA=11:59:33, max mem: 20.9 GB 
[12/07 07:49:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6492,	0.8227 s / batch. (data: 4.10e-04). ETA=11:54:52, max mem: 20.9 GB 
[12/07 07:51:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6936,	1.3661 s / batch. (data: 5.31e-01). ETA=19:44:44, max mem: 20.9 GB 
[12/07 07:52:44][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 3.08e-01, avg batch time: 1.1402, average train loss: 0.7148
[12/07 07:53:50][INFO] visual_prompt:  316: Inference (val):avg data time: 5.48e-05, avg batch time: 0.3104, average loss: 0.7517
[12/07 07:53:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.21	
[12/07 07:53:50][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.03
[12/07 07:55:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5537,	1.1180 s / batch. (data: 2.62e-01). ETA=16:06:46, max mem: 20.9 GB 
[12/07 07:57:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6174,	0.8471 s / batch. (data: 1.09e-02). ETA=12:11:03, max mem: 20.9 GB 
[12/07 07:59:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6421,	2.6737 s / batch. (data: 1.85e+00). ETA=1 day, 14:23:00, max mem: 20.9 GB 
[12/07 08:01:28][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6692,	2.6318 s / batch. (data: 1.80e+00). ETA=1 day, 13:42:32, max mem: 20.9 GB 
[12/07 08:03:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6996,	0.8280 s / batch. (data: 3.56e-04). ETA=11:50:27, max mem: 20.9 GB 
[12/07 08:04:17][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 3.03e-01, avg batch time: 1.1335, average train loss: 0.7063
[12/07 08:05:23][INFO] visual_prompt:  316: Inference (val):avg data time: 7.37e-04, avg batch time: 0.3115, average loss: 0.7846
[12/07 08:05:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.72	
[12/07 08:05:23][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/07 08:07:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7271,	1.2883 s / batch. (data: 4.34e-01). ETA=18:22:09, max mem: 20.9 GB 
[12/07 08:09:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0237,	0.8361 s / batch. (data: 6.60e-04). ETA=11:53:54, max mem: 20.9 GB 
[12/07 08:11:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6814,	0.8338 s / batch. (data: 5.46e-03). ETA=11:50:32, max mem: 20.9 GB 
[12/07 08:13:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6991,	0.8278 s / batch. (data: 5.52e-03). ETA=11:44:01, max mem: 20.9 GB 
[12/07 08:14:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9823,	1.8478 s / batch. (data: 1.02e+00). ETA=1 day, 2:08:24, max mem: 20.9 GB 
[12/07 08:15:53][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 3.06e-01, avg batch time: 1.1380, average train loss: 0.7204
[12/07 08:16:59][INFO] visual_prompt:  316: Inference (val):avg data time: 5.42e-05, avg batch time: 0.3106, average loss: 0.7744
[12/07 08:16:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.18	
[12/07 08:16:59][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/07 08:18:57][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6898,	0.8264 s / batch. (data: 5.47e-03). ETA=11:39:23, max mem: 20.9 GB 
[12/07 08:20:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5737,	0.8515 s / batch. (data: 1.52e-03). ETA=11:59:09, max mem: 20.9 GB 
[12/07 08:22:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6114,	2.1234 s / batch. (data: 1.30e+00). ETA=1 day, 5:49:52, max mem: 20.9 GB 
[12/07 08:24:36][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6397,	0.8358 s / batch. (data: 7.13e-04). ETA=11:43:09, max mem: 20.9 GB 
[12/07 08:26:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5622,	1.2160 s / batch. (data: 3.95e-01). ETA=17:00:57, max mem: 20.9 GB 
[12/07 08:27:28][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 3.04e-01, avg batch time: 1.1372, average train loss: 0.7289
[12/07 08:28:34][INFO] visual_prompt:  316: Inference (val):avg data time: 5.97e-05, avg batch time: 0.3104, average loss: 0.7123
[12/07 08:28:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.67	
[12/07 08:28:34][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/07 08:30:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7076,	0.8297 s / batch. (data: 1.19e-03). ETA=11:34:28, max mem: 20.9 GB 
[12/07 08:32:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6601,	0.8659 s / batch. (data: 5.51e-03). ETA=12:03:20, max mem: 20.9 GB 
[12/07 08:34:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6690,	1.9168 s / batch. (data: 1.10e+00). ETA=1 day, 2:38:05, max mem: 20.9 GB 
[12/07 08:36:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8959,	1.0760 s / batch. (data: 2.32e-01). ETA=14:55:17, max mem: 20.9 GB 
[12/07 08:38:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9823,	1.3697 s / batch. (data: 5.34e-01). ETA=18:57:20, max mem: 20.9 GB 
[12/07 08:39:03][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.07e-01, avg batch time: 1.1384, average train loss: 0.7426
[12/07 08:40:10][INFO] visual_prompt:  316: Inference (val):avg data time: 6.73e-05, avg batch time: 0.3104, average loss: 0.7593
[12/07 08:40:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.14	
[12/07 08:40:10][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.05
[12/07 08:42:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7617,	0.8400 s / batch. (data: 3.50e-04). ETA=11:35:22, max mem: 20.9 GB 
[12/07 08:44:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0110,	0.8226 s / batch. (data: 5.45e-03). ETA=11:19:38, max mem: 20.9 GB 
[12/07 08:45:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4844,	2.7573 s / batch. (data: 1.88e+00). ETA=1 day, 13:53:24, max mem: 20.9 GB 
[12/07 08:47:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7756,	0.8302 s / batch. (data: 5.74e-03). ETA=11:23:08, max mem: 20.9 GB 
[12/07 08:49:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7049,	0.8360 s / batch. (data: 3.38e-04). ETA=11:26:29, max mem: 20.9 GB 
[12/07 08:50:38][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 3.03e-01, avg batch time: 1.1349, average train loss: 0.7302
[12/07 08:51:44][INFO] visual_prompt:  316: Inference (val):avg data time: 5.72e-05, avg batch time: 0.3118, average loss: 0.7035
[12/07 08:51:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.18	
[12/07 08:51:44][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/07 08:53:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8556,	1.4880 s / batch. (data: 6.41e-01). ETA=20:18:06, max mem: 20.9 GB 
[12/07 08:55:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5623,	0.8492 s / batch. (data: 1.06e-02). ETA=11:33:46, max mem: 20.9 GB 
[12/07 08:57:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7245,	0.8359 s / batch. (data: 1.56e-02). ETA=11:21:30, max mem: 20.9 GB 
[12/07 08:59:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7212,	0.8266 s / batch. (data: 1.06e-02). ETA=11:12:33, max mem: 20.9 GB 
[12/07 09:01:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1302,	0.8210 s / batch. (data: 3.24e-04). ETA=11:06:38, max mem: 20.9 GB 
[12/07 09:02:14][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 3.07e-01, avg batch time: 1.1390, average train loss: 0.7411
[12/07 09:03:20][INFO] visual_prompt:  316: Inference (val):avg data time: 5.60e-05, avg batch time: 0.3111, average loss: 0.7780
[12/07 09:03:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.04	
[12/07 09:03:20][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/07 09:05:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5924,	0.8328 s / batch. (data: 7.74e-03). ETA=11:14:06, max mem: 20.9 GB 
[12/07 09:07:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7854,	0.9313 s / batch. (data: 8.57e-02). ETA=12:32:12, max mem: 20.9 GB 
[12/07 09:09:03][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6264,	1.6800 s / batch. (data: 8.66e-01). ETA=22:34:11, max mem: 20.9 GB 
[12/07 09:10:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9327,	0.8244 s / batch. (data: 3.44e-04). ETA=11:03:10, max mem: 20.9 GB 
[12/07 09:12:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7167,	0.8325 s / batch. (data: 3.47e-04). ETA=11:08:17, max mem: 20.9 GB 
[12/07 09:13:49][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 3.04e-01, avg batch time: 1.1363, average train loss: 0.7423
[12/07 09:14:55][INFO] visual_prompt:  316: Inference (val):avg data time: 6.06e-05, avg batch time: 0.3091, average loss: 0.6906
[12/07 09:14:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.40	
[12/07 09:14:55][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.691
[12/07 09:14:55][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/07 09:16:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7079,	0.8399 s / batch. (data: 6.24e-04). ETA=11:12:03, max mem: 20.9 GB 
[12/07 09:18:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7104,	1.7260 s / batch. (data: 8.88e-01). ETA=22:58:14, max mem: 20.9 GB 
[12/07 09:20:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6932,	0.9601 s / batch. (data: 1.31e-01). ETA=12:45:03, max mem: 20.9 GB 
[12/07 09:22:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6018,	0.8300 s / batch. (data: 1.08e-02). ETA=11:00:01, max mem: 20.9 GB 
[12/07 09:24:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8810,	0.8263 s / batch. (data: 1.02e-02). ETA=10:55:43, max mem: 20.9 GB 
[12/07 09:25:25][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 3.06e-01, avg batch time: 1.1383, average train loss: 0.7261
[12/07 09:26:30][INFO] visual_prompt:  316: Inference (val):avg data time: 5.91e-05, avg batch time: 0.3097, average loss: 0.7525
[12/07 09:26:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.57	
[12/07 09:26:30][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/07 09:28:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7093,	0.8440 s / batch. (data: 3.91e-04). ETA=11:07:34, max mem: 20.9 GB 
[12/07 09:30:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7900,	0.8382 s / batch. (data: 4.84e-04). ETA=11:01:34, max mem: 20.9 GB 
[12/07 09:32:14][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7789,	0.8306 s / batch. (data: 7.95e-03). ETA=10:54:12, max mem: 20.9 GB 
[12/07 09:34:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6269,	0.8436 s / batch. (data: 1.09e-03). ETA=11:03:03, max mem: 20.9 GB 
[12/07 09:35:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8421,	0.8273 s / batch. (data: 3.28e-04). ETA=10:48:50, max mem: 20.9 GB 
[12/07 09:36:57][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 3.00e-01, avg batch time: 1.1326, average train loss: 0.7268
[12/07 09:38:03][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-04, avg batch time: 0.3097, average loss: 0.6970
[12/07 09:38:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[12/07 09:38:03][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/07 09:40:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5824,	0.8292 s / batch. (data: 4.48e-04). ETA=10:48:12, max mem: 20.9 GB 
[12/07 09:41:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8093,	0.8638 s / batch. (data: 1.56e-02). ETA=11:13:48, max mem: 20.9 GB 
[12/07 09:43:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8776,	0.8363 s / batch. (data: 9.27e-04). ETA=10:50:58, max mem: 20.9 GB 
[12/07 09:45:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7453,	0.8234 s / batch. (data: 3.63e-04). ETA=10:39:36, max mem: 20.9 GB 
[12/07 09:47:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7290,	1.8075 s / batch. (data: 9.66e-01). ETA=23:20:56, max mem: 20.9 GB 
[12/07 09:48:32][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.04e-01, avg batch time: 1.1364, average train loss: 0.7222
[12/07 09:49:37][INFO] visual_prompt:  316: Inference (val):avg data time: 2.90e-04, avg batch time: 0.3097, average loss: 0.7414
[12/07 09:49:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.75	
[12/07 09:49:37][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/07 09:51:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5557,	0.8382 s / batch. (data: 1.56e-02). ETA=10:47:33, max mem: 20.9 GB 
[12/07 09:53:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6924,	0.8400 s / batch. (data: 3.33e-04). ETA=10:47:31, max mem: 20.9 GB 
[12/07 09:55:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9320,	0.8160 s / batch. (data: 3.29e-04). ETA=10:27:41, max mem: 20.9 GB 
[12/07 09:57:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7058,	0.8260 s / batch. (data: 3.34e-04). ETA=10:34:00, max mem: 20.9 GB 
[12/07 09:59:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6474,	2.2655 s / batch. (data: 1.44e+00). ETA=1 day, 4:55:03, max mem: 20.9 GB 
[12/07 10:00:06][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 3.06e-01, avg batch time: 1.1371, average train loss: 0.7232
[12/07 10:01:13][INFO] visual_prompt:  316: Inference (val):avg data time: 5.55e-05, avg batch time: 0.3097, average loss: 0.7062
[12/07 10:01:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.74	
[12/07 10:01:13][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/07 10:03:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7177,	0.8442 s / batch. (data: 3.45e-04). ETA=10:44:24, max mem: 20.9 GB 
[12/07 10:05:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7552,	0.8243 s / batch. (data: 1.06e-02). ETA=10:27:50, max mem: 20.9 GB 
[12/07 10:06:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6352,	0.8359 s / batch. (data: 5.88e-04). ETA=10:35:14, max mem: 20.9 GB 
[12/07 10:08:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6973,	0.8245 s / batch. (data: 5.49e-03). ETA=10:25:13, max mem: 20.9 GB 
[12/07 10:10:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6885,	0.8451 s / batch. (data: 9.19e-03). ETA=10:39:25, max mem: 20.9 GB 
[12/07 10:11:41][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 3.04e-01, avg batch time: 1.1360, average train loss: 0.7277
[12/07 10:12:47][INFO] visual_prompt:  316: Inference (val):avg data time: 5.53e-05, avg batch time: 0.3095, average loss: 0.7176
[12/07 10:12:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.01	
[12/07 10:12:47][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/07 10:14:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1004,	1.2760 s / batch. (data: 4.53e-01). ETA=16:02:15, max mem: 20.9 GB 
[12/07 10:16:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7952,	0.8555 s / batch. (data: 1.18e-02). ETA=10:43:43, max mem: 20.9 GB 
[12/07 10:18:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0886,	0.8205 s / batch. (data: 3.39e-04). ETA=10:15:59, max mem: 20.9 GB 
[12/07 10:20:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5627,	0.8740 s / batch. (data: 9.34e-04). ETA=10:54:44, max mem: 20.9 GB 
[12/07 10:22:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8933,	0.8400 s / batch. (data: 5.27e-04). ETA=10:27:52, max mem: 20.9 GB 
[12/07 10:23:15][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 3.03e-01, avg batch time: 1.1350, average train loss: 0.7233
[12/07 10:24:21][INFO] visual_prompt:  316: Inference (val):avg data time: 6.44e-05, avg batch time: 0.3087, average loss: 0.6883
[12/07 10:24:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.65	
[12/07 10:24:21][INFO] visual_prompt:   36: Best epoch 19: best metric: -0.688
[12/07 10:24:21][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/07 10:26:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6585,	0.8440 s / batch. (data: 8.02e-03). ETA=10:28:42, max mem: 20.9 GB 
[12/07 10:28:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6598,	0.8360 s / batch. (data: 7.95e-03). ETA=10:21:19, max mem: 20.9 GB 
[12/07 10:30:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9129,	0.8169 s / batch. (data: 3.14e-04). ETA=10:05:48, max mem: 20.9 GB 
[12/07 10:31:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5675,	0.8385 s / batch. (data: 9.92e-04). ETA=10:20:24, max mem: 20.9 GB 
[12/07 10:33:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8200,	0.8280 s / batch. (data: 3.44e-04). ETA=10:11:15, max mem: 20.9 GB 
[12/07 10:34:51][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 3.07e-01, avg batch time: 1.1397, average train loss: 0.7394
[12/07 10:35:57][INFO] visual_prompt:  316: Inference (val):avg data time: 5.06e-05, avg batch time: 0.3115, average loss: 0.8410
[12/07 10:35:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.62	
[12/07 10:35:57][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/07 10:38:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5638,	0.8478 s / batch. (data: 5.45e-03). ETA=10:23:41, max mem: 20.9 GB 
[12/07 10:40:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6998,	0.8339 s / batch. (data: 3.65e-04). ETA=10:12:05, max mem: 20.9 GB 
[12/07 10:42:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8890,	2.4211 s / batch. (data: 1.59e+00). ETA=1 day, 5:33:01, max mem: 20.9 GB 
[12/07 10:45:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6447,	1.1132 s / batch. (data: 3.02e-01). ETA=13:33:21, max mem: 20.9 GB 
[12/07 10:47:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7090,	0.8116 s / batch. (data: 3.44e-04). ETA=9:51:38, max mem: 20.9 GB 
[12/07 10:48:50][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 5.74e-01, avg batch time: 1.3978, average train loss: 0.7324
[12/07 10:50:21][INFO] visual_prompt:  316: Inference (val):avg data time: 9.64e-05, avg batch time: 0.3077, average loss: 0.8239
[12/07 10:50:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.72	
[12/07 10:50:21][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/07 10:52:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7025,	0.8765 s / batch. (data: 1.20e-02). ETA=10:36:42, max mem: 20.9 GB 
[12/07 10:54:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5765,	0.8484 s / batch. (data: 3.38e-04). ETA=10:14:54, max mem: 20.9 GB 
[12/07 10:56:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4743,	0.8678 s / batch. (data: 1.43e-03). ETA=10:27:32, max mem: 20.9 GB 
[12/07 10:58:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6852,	0.8345 s / batch. (data: 9.78e-03). ETA=10:02:01, max mem: 20.9 GB 
[12/07 11:00:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7153,	0.8517 s / batch. (data: 7.39e-03). ETA=10:13:02, max mem: 20.9 GB 
[12/07 11:01:04][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 3.30e-01, avg batch time: 1.1615, average train loss: 0.7361
[12/07 11:02:10][INFO] visual_prompt:  316: Inference (val):avg data time: 6.11e-05, avg batch time: 0.3110, average loss: 0.7459
[12/07 11:02:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[12/07 11:02:10][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/07 11:04:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7706,	0.8150 s / batch. (data: 4.94e-04). ETA=9:44:31, max mem: 20.9 GB 
[12/07 11:06:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5909,	1.2666 s / batch. (data: 4.27e-01). ETA=15:06:18, max mem: 20.9 GB 
[12/07 11:08:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9823,	0.8160 s / batch. (data: 3.57e-04). ETA=9:42:32, max mem: 20.9 GB 
[12/07 11:09:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5615,	0.8540 s / batch. (data: 1.57e-02). ETA=10:08:13, max mem: 20.9 GB 
[12/07 11:11:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8922,	0.8520 s / batch. (data: 5.46e-03). ETA=10:05:24, max mem: 20.9 GB 
[12/07 11:12:44][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 3.14e-01, avg batch time: 1.1465, average train loss: 0.7355
[12/07 11:13:50][INFO] visual_prompt:  316: Inference (val):avg data time: 6.10e-05, avg batch time: 0.3119, average loss: 0.6890
[12/07 11:13:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.04	
[12/07 11:13:50][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/07 11:15:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8287,	0.8688 s / batch. (data: 4.34e-02). ETA=10:15:09, max mem: 20.9 GB 
[12/07 11:17:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8403,	0.8326 s / batch. (data: 5.46e-04). ETA=9:48:08, max mem: 20.9 GB 
[12/07 11:19:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7115,	1.5100 s / batch. (data: 6.93e-01). ETA=17:44:03, max mem: 20.9 GB 
[12/07 11:21:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6434,	0.8360 s / batch. (data: 3.84e-04). ETA=9:47:42, max mem: 20.9 GB 
[12/07 11:23:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6983,	0.8300 s / batch. (data: 1.42e-02). ETA=9:42:05, max mem: 20.9 GB 
[12/07 11:24:25][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 3.16e-01, avg batch time: 1.1478, average train loss: 0.7322
[12/07 11:25:31][INFO] visual_prompt:  316: Inference (val):avg data time: 5.74e-05, avg batch time: 0.3114, average loss: 0.7030
[12/07 11:25:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.87	
[12/07 11:25:31][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/07 11:27:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6338,	0.8302 s / batch. (data: 5.35e-04). ETA=9:40:08, max mem: 20.9 GB 
[12/07 11:29:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7358,	0.8280 s / batch. (data: 3.20e-04). ETA=9:37:13, max mem: 20.9 GB 
[12/07 11:31:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6945,	0.8469 s / batch. (data: 5.13e-04). ETA=9:48:59, max mem: 20.9 GB 
[12/07 11:33:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6581,	1.6091 s / batch. (data: 7.85e-01). ETA=18:36:21, max mem: 20.9 GB 
[12/07 11:35:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8074,	2.1939 s / batch. (data: 1.37e+00). ETA=1 day, 1:18:28, max mem: 20.9 GB 
[12/07 11:36:04][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 3.13e-01, avg batch time: 1.1449, average train loss: 0.7230
[12/07 11:37:11][INFO] visual_prompt:  316: Inference (val):avg data time: 6.72e-05, avg batch time: 0.3094, average loss: 0.7684
[12/07 11:37:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.02	
[12/07 11:37:11][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/07 11:39:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6225,	0.8480 s / batch. (data: 7.95e-03). ETA=9:44:45, max mem: 20.9 GB 
[12/07 11:41:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7678,	2.2725 s / batch. (data: 1.45e+00). ETA=1 day, 2:03:17, max mem: 20.9 GB 
[12/07 11:43:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4548,	0.8351 s / batch. (data: 5.71e-03). ETA=9:33:06, max mem: 20.9 GB 
[12/07 11:44:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6088,	0.8163 s / batch. (data: 3.76e-04). ETA=9:18:51, max mem: 20.9 GB 
[12/07 11:46:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6843,	0.8360 s / batch. (data: 3.36e-04). ETA=9:30:55, max mem: 20.9 GB 
[12/07 11:47:45][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 3.14e-01, avg batch time: 1.1450, average train loss: 0.7344
[12/07 11:48:52][INFO] visual_prompt:  316: Inference (val):avg data time: 6.39e-05, avg batch time: 0.3100, average loss: 0.7692
[12/07 11:48:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.33	
[12/07 11:48:52][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/07 11:50:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5822,	0.8538 s / batch. (data: 3.27e-04). ETA=9:40:55, max mem: 20.9 GB 
[12/07 11:52:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6404,	1.9287 s / batch. (data: 1.10e+00). ETA=21:49:02, max mem: 20.9 GB 
[12/07 11:54:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6310,	1.0279 s / batch. (data: 2.08e-01). ETA=11:35:56, max mem: 20.9 GB 
[12/07 11:56:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6971,	0.8531 s / batch. (data: 5.47e-03). ETA=9:36:09, max mem: 20.9 GB 
[12/07 11:58:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7902,	0.8865 s / batch. (data: 4.65e-02). ETA=9:57:15, max mem: 20.9 GB 
[12/07 11:59:33][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 3.26e-01, avg batch time: 1.1579, average train loss: 0.7307
[12/07 12:00:41][INFO] visual_prompt:  316: Inference (val):avg data time: 6.21e-05, avg batch time: 0.3091, average loss: 0.7244
[12/07 12:00:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.99	
[12/07 12:00:41][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/07 12:02:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4665,	0.8159 s / batch. (data: 5.65e-04). ETA=9:07:34, max mem: 20.9 GB 
[12/07 12:04:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6210,	0.8600 s / batch. (data: 1.22e-02). ETA=9:35:45, max mem: 20.9 GB 
[12/07 12:06:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6214,	2.2053 s / batch. (data: 1.39e+00). ETA=1 day, 0:32:44, max mem: 20.9 GB 
[12/07 12:08:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7940,	0.8181 s / batch. (data: 5.86e-04). ETA=9:04:59, max mem: 20.9 GB 
[12/07 12:10:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4935,	0.8321 s / batch. (data: 3.43e-04). ETA=9:12:56, max mem: 20.9 GB 
[12/07 12:11:16][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 3.17e-01, avg batch time: 1.1486, average train loss: 0.7182
[12/07 12:12:24][INFO] visual_prompt:  316: Inference (val):avg data time: 6.73e-05, avg batch time: 0.3080, average loss: 0.7068
[12/07 12:12:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.50	
[12/07 12:12:24][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/07 12:14:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4862,	0.8483 s / batch. (data: 1.56e-02). ETA=9:21:31, max mem: 20.9 GB 
[12/07 12:16:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7084,	2.0123 s / batch. (data: 1.19e+00). ETA=22:08:38, max mem: 20.9 GB 
[12/07 12:18:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6940,	0.8650 s / batch. (data: 8.66e-04). ETA=9:29:40, max mem: 20.9 GB 
[12/07 12:20:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5642,	2.1042 s / batch. (data: 1.24e+00). ETA=23:02:20, max mem: 20.9 GB 
[12/07 12:22:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7135,	0.8163 s / batch. (data: 3.37e-04). ETA=8:54:53, max mem: 20.9 GB 
[12/07 12:23:13][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 3.42e-01, avg batch time: 1.1728, average train loss: 0.7329
[12/07 12:24:19][INFO] visual_prompt:  316: Inference (val):avg data time: 5.64e-05, avg batch time: 0.3095, average loss: 0.6886
[12/07 12:24:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.75	
[12/07 12:24:19][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/07 12:26:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7129,	0.8540 s / batch. (data: 1.10e-02). ETA=9:17:23, max mem: 20.9 GB 
[12/07 12:28:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8537,	0.8595 s / batch. (data: 1.49e-03). ETA=9:19:35, max mem: 20.9 GB 
[12/07 12:30:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4646,	2.8010 s / batch. (data: 1.95e+00). ETA=1 day, 6:18:55, max mem: 20.9 GB 
[12/07 12:32:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6949,	1.8433 s / batch. (data: 9.97e-01). ETA=19:53:56, max mem: 20.9 GB 
[12/07 12:33:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6183,	1.9935 s / batch. (data: 1.16e+00). ETA=21:27:52, max mem: 20.9 GB 
[12/07 12:34:54][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 3.16e-01, avg batch time: 1.1478, average train loss: 0.7364
[12/07 12:35:59][INFO] visual_prompt:  316: Inference (val):avg data time: 1.99e-04, avg batch time: 0.3094, average loss: 0.6984
[12/07 12:35:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[12/07 12:35:59][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/07 12:38:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6346,	0.8181 s / batch. (data: 3.44e-04). ETA=8:46:26, max mem: 20.9 GB 
[12/07 12:40:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6968,	0.8645 s / batch. (data: 5.44e-03). ETA=9:14:52, max mem: 20.9 GB 
[12/07 12:41:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6921,	0.8553 s / batch. (data: 1.15e-02). ETA=9:07:30, max mem: 20.9 GB 
[12/07 12:43:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5798,	0.8338 s / batch. (data: 3.66e-04). ETA=8:52:23, max mem: 20.9 GB 
[12/07 12:45:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8273,	0.8268 s / batch. (data: 7.00e-04). ETA=8:46:31, max mem: 20.9 GB 
[12/07 12:46:38][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 3.22e-01, avg batch time: 1.1543, average train loss: 0.7255
[12/07 12:47:45][INFO] visual_prompt:  316: Inference (val):avg data time: 6.79e-05, avg batch time: 0.3108, average loss: 0.7755
[12/07 12:47:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.90	
[12/07 12:47:45][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/07 12:49:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9652,	0.8560 s / batch. (data: 6.70e-04). ETA=9:02:57, max mem: 20.9 GB 
[12/07 12:51:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6413,	0.8287 s / batch. (data: 7.62e-04). ETA=8:44:16, max mem: 20.9 GB 
[12/07 12:53:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7001,	1.9840 s / batch. (data: 1.16e+00). ETA=20:51:49, max mem: 20.9 GB 
[12/07 12:55:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8825,	0.8440 s / batch. (data: 5.56e-03). ETA=8:51:06, max mem: 20.9 GB 
[12/07 12:57:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7550,	0.8360 s / batch. (data: 3.62e-04). ETA=8:44:41, max mem: 20.9 GB 
[12/07 12:58:23][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 3.21e-01, avg batch time: 1.1534, average train loss: 0.7269
[12/07 12:59:31][INFO] visual_prompt:  316: Inference (val):avg data time: 5.27e-05, avg batch time: 0.3106, average loss: 0.7076
[12/07 12:59:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.44	
[12/07 12:59:31][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/07 13:01:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0446,	0.8272 s / batch. (data: 4.67e-04). ETA=8:37:02, max mem: 20.9 GB 
[12/07 13:03:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5647,	2.5748 s / batch. (data: 1.74e+00). ETA=1 day, 2:45:07, max mem: 20.9 GB 
[12/07 13:05:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6214,	0.8422 s / batch. (data: 1.16e-02). ETA=8:43:37, max mem: 20.9 GB 
[12/07 13:07:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7398,	0.8205 s / batch. (data: 5.45e-03). ETA=8:28:45, max mem: 20.9 GB 
[12/07 13:09:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6914,	0.8395 s / batch. (data: 3.00e-04). ETA=8:39:10, max mem: 20.9 GB 
[12/07 13:10:11][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 3.25e-01, avg batch time: 1.1571, average train loss: 0.7358
[12/07 13:11:18][INFO] visual_prompt:  316: Inference (val):avg data time: 6.11e-05, avg batch time: 0.3122, average loss: 0.6893
[12/07 13:11:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.59	
[12/07 13:11:18][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/07 13:13:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7530,	1.2480 s / batch. (data: 4.14e-01). ETA=12:48:34, max mem: 20.9 GB 
[12/07 13:15:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8312,	0.8470 s / batch. (data: 6.28e-03). ETA=8:40:13, max mem: 20.9 GB 
[12/07 13:17:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7050,	0.8261 s / batch. (data: 1.06e-02). ETA=8:26:00, max mem: 20.9 GB 
[12/07 13:19:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6348,	0.8322 s / batch. (data: 3.42e-04). ETA=8:28:20, max mem: 20.9 GB 
[12/07 13:20:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9476,	1.8545 s / batch. (data: 1.03e+00). ETA=18:49:42, max mem: 20.9 GB 
[12/07 13:21:55][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 3.19e-01, avg batch time: 1.1504, average train loss: 0.7302
[12/07 13:23:03][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-04, avg batch time: 0.3107, average loss: 0.6922
[12/07 13:23:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.17	
[12/07 13:23:03][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/07 13:25:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8240,	0.8509 s / batch. (data: 1.12e-02). ETA=8:36:11, max mem: 20.9 GB 
[12/07 13:27:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6961,	0.9716 s / batch. (data: 1.42e-01). ETA=9:47:47, max mem: 20.9 GB 
[12/07 13:28:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7426,	0.8292 s / batch. (data: 1.30e-03). ETA=8:20:15, max mem: 20.9 GB 
[12/07 13:30:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6165,	0.8440 s / batch. (data: 4.85e-03). ETA=8:27:46, max mem: 20.9 GB 
[12/07 13:32:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0052,	1.5880 s / batch. (data: 7.37e-01). ETA=15:52:43, max mem: 20.9 GB 
[12/07 13:33:41][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 3.21e-01, avg batch time: 1.1534, average train loss: 0.7445
[12/07 13:34:49][INFO] visual_prompt:  316: Inference (val):avg data time: 6.63e-05, avg batch time: 0.3093, average loss: 0.6891
[12/07 13:34:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[12/07 13:34:49][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/07 13:36:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8626,	0.8650 s / batch. (data: 1.57e-02). ETA=8:36:45, max mem: 20.9 GB 
[12/07 13:38:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7270,	0.8283 s / batch. (data: 5.48e-03). ETA=8:13:26, max mem: 20.9 GB 
[12/07 13:40:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5907,	0.8426 s / batch. (data: 1.46e-02). ETA=8:20:34, max mem: 20.9 GB 
[12/07 13:42:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9251,	0.8360 s / batch. (data: 7.99e-03). ETA=8:15:15, max mem: 20.9 GB 
[12/07 13:44:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7093,	1.1145 s / batch. (data: 2.96e-01). ETA=10:58:23, max mem: 20.9 GB 
[12/07 13:45:23][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 3.13e-01, avg batch time: 1.1463, average train loss: 0.7451
[12/07 13:46:30][INFO] visual_prompt:  316: Inference (val):avg data time: 3.02e-04, avg batch time: 0.3089, average loss: 0.6908
[12/07 13:46:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[12/07 13:46:31][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/07 13:48:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9079,	0.8364 s / batch. (data: 3.66e-04). ETA=8:11:58, max mem: 20.9 GB 
[12/07 13:50:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8645,	0.8358 s / batch. (data: 6.69e-04). ETA=8:10:14, max mem: 20.9 GB 
[12/07 13:52:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6900,	2.1119 s / batch. (data: 1.29e+00). ETA=20:35:12, max mem: 20.9 GB 
[12/07 13:54:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9448,	2.1813 s / batch. (data: 1.36e+00). ETA=21:12:09, max mem: 20.9 GB 
[12/07 13:56:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7032,	1.6640 s / batch. (data: 8.40e-01). ETA=16:07:40, max mem: 20.9 GB 
[12/07 13:57:22][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 3.46e-01, avg batch time: 1.1777, average train loss: 0.7344
[12/07 13:58:29][INFO] visual_prompt:  316: Inference (val):avg data time: 5.32e-05, avg batch time: 0.3102, average loss: 0.6987
[12/07 13:58:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.45	
[12/07 13:58:29][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/07 14:00:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6048,	1.2284 s / batch. (data: 4.06e-01). ETA=11:51:14, max mem: 20.9 GB 
[12/07 14:02:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6992,	1.2898 s / batch. (data: 4.62e-01). ETA=12:24:36, max mem: 20.9 GB 
[12/07 14:04:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7610,	0.8272 s / batch. (data: 3.62e-04). ETA=7:56:11, max mem: 20.9 GB 
[12/07 14:06:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7086,	0.8324 s / batch. (data: 3.45e-04). ETA=7:57:48, max mem: 20.9 GB 
[12/07 14:08:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7313,	0.8295 s / batch. (data: 5.55e-03). ETA=7:54:43, max mem: 20.9 GB 
[12/07 14:09:07][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 3.21e-01, avg batch time: 1.1539, average train loss: 0.7337
[12/07 14:10:13][INFO] visual_prompt:  316: Inference (val):avg data time: 5.43e-05, avg batch time: 0.3107, average loss: 0.7165
[12/07 14:10:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[12/07 14:10:13][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/07 14:12:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9430,	0.8284 s / batch. (data: 3.75e-04). ETA=7:51:58, max mem: 20.9 GB 
[12/07 14:14:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.5680,	0.8442 s / batch. (data: 8.09e-03). ETA=7:59:35, max mem: 20.9 GB 
[12/07 14:16:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8499,	0.8269 s / batch. (data: 5.48e-03). ETA=7:48:22, max mem: 20.9 GB 
[12/07 14:18:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6155,	0.8708 s / batch. (data: 3.36e-02). ETA=8:11:47, max mem: 20.9 GB 
[12/07 14:20:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5705,	2.2342 s / batch. (data: 1.42e+00). ETA=20:58:04, max mem: 20.9 GB 
[12/07 14:21:03][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 3.44e-01, avg batch time: 1.1752, average train loss: 0.7324
[12/07 14:22:12][INFO] visual_prompt:  316: Inference (val):avg data time: 6.08e-05, avg batch time: 0.3079, average loss: 0.6939
[12/07 14:22:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.35	
[12/07 14:22:12][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/07 14:24:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7548,	0.8320 s / batch. (data: 3.21e-04). ETA=7:46:22, max mem: 20.9 GB 
[12/07 14:26:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6518,	0.8148 s / batch. (data: 3.36e-04). ETA=7:35:22, max mem: 20.9 GB 
[12/07 14:28:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5872,	0.8439 s / batch. (data: 7.91e-03). ETA=7:50:14, max mem: 20.9 GB 
[12/07 14:30:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6028,	0.8358 s / batch. (data: 5.51e-03). ETA=7:44:20, max mem: 20.9 GB 
[12/07 14:32:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4116,	0.8242 s / batch. (data: 3.30e-04). ETA=7:36:29, max mem: 20.9 GB 
[12/07 14:33:16][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 3.71e-01, avg batch time: 1.2013, average train loss: 0.7181
[12/07 14:34:27][INFO] visual_prompt:  316: Inference (val):avg data time: 5.57e-05, avg batch time: 0.3077, average loss: 0.6903
[12/07 14:34:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.10	
[12/07 14:34:27][INFO] visual_prompt:   42: Stopping early.
