[11/27 14:28:24][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/27 14:28:24][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 14:28:24][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/27 14:28:24][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 14:28:24][INFO] visual_prompt:  108: Training with config:
[11/27 14:28:24][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr1.0_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 14:28:24][INFO] visual_prompt:   55: Loading training data...
[11/27 14:28:24][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/27 14:28:24][INFO] visual_prompt:   57: Loading validation data...
[11/27 14:28:24][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/27 14:28:24][INFO] visual_prompt:   38: Constructing models...
[11/27 14:28:27][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[11/27 14:28:27][INFO] visual_prompt:   54: tuned percent:0.525
[11/27 14:28:27][INFO] visual_prompt:   40: Device used for model: 0
[11/27 14:28:27][INFO] visual_prompt:   40: Setting up Evaluator...
[11/27 14:28:27][INFO] visual_prompt:   42: Setting up Trainer...
[11/27 14:28:27][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/27 14:28:27][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/27 14:30:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8176 s / batch. (data: 3.14e-04). ETA=12:32:12, max mem: 20.9 GB 
[11/27 14:31:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8181 s / batch. (data: 2.81e-04). ETA=12:31:18, max mem: 20.9 GB 
[11/27 14:33:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	1.3344 s / batch. (data: 5.13e-01). ETA=20:23:11, max mem: 20.9 GB 
[11/27 14:35:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8298 s / batch. (data: 1.19e-02). ETA=12:39:13, max mem: 20.9 GB 
[11/27 14:36:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8075 s / batch. (data: 3.14e-04). ETA=12:17:33, max mem: 20.9 GB 
[11/27 14:37:47][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 1.88e-01, avg batch time: 1.0115, average train loss: 1.5403
[11/27 14:38:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.58e-05, avg batch time: 0.3067, average loss: 1.5201
[11/27 14:38:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[11/27 14:38:44][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.1
[11/27 14:40:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7319,	0.8760 s / batch. (data: 6.84e-02). ETA=13:17:52, max mem: 20.9 GB 
[11/27 14:42:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0588,	0.8200 s / batch. (data: 3.23e-04). ETA=12:25:28, max mem: 20.9 GB 
[11/27 14:43:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7024,	1.0296 s / batch. (data: 2.06e-01). ETA=15:34:16, max mem: 20.9 GB 
[11/27 14:45:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2103,	0.8302 s / batch. (data: 1.01e-02). ETA=12:31:57, max mem: 20.9 GB 
[11/27 14:47:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6010,	0.8473 s / batch. (data: 2.34e-02). ETA=12:46:02, max mem: 20.9 GB 
[11/27 14:48:02][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 1.86e-01, avg batch time: 1.0083, average train loss: 0.9073
[11/27 14:48:59][INFO] visual_prompt:  316: Inference (val):avg data time: 3.67e-05, avg batch time: 0.3078, average loss: 1.4984
[11/27 14:48:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.17	
[11/27 14:48:59][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.2
[11/27 14:50:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1307,	0.8329 s / batch. (data: 5.45e-03). ETA=12:30:56, max mem: 20.9 GB 
[11/27 14:52:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7188,	2.1062 s / batch. (data: 1.28e+00). ETA=1 day, 7:35:19, max mem: 20.9 GB 
[11/27 14:54:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0751,	0.8430 s / batch. (data: 1.05e-02). ETA=12:37:13, max mem: 20.9 GB 
[11/27 14:55:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2364,	0.8491 s / batch. (data: 1.10e-02). ETA=12:41:15, max mem: 20.9 GB 
[11/27 14:57:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7146,	1.2243 s / batch. (data: 4.04e-01). ETA=18:15:36, max mem: 20.9 GB 
[11/27 14:58:16][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 1.83e-01, avg batch time: 1.0061, average train loss: 1.0137
[11/27 14:59:13][INFO] visual_prompt:  316: Inference (val):avg data time: 4.54e-04, avg batch time: 0.3057, average loss: 0.7381
[11/27 14:59:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.10	
[11/27 14:59:13][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.3
[11/27 15:00:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7098,	0.8546 s / batch. (data: 1.05e-02). ETA=12:42:35, max mem: 20.9 GB 
[11/27 15:02:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6045,	0.8560 s / batch. (data: 7.95e-03). ETA=12:42:25, max mem: 20.9 GB 
[11/27 15:04:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6077,	0.8129 s / batch. (data: 3.04e-04). ETA=12:02:39, max mem: 20.9 GB 
[11/27 15:05:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5648,	1.3320 s / batch. (data: 5.17e-01). ETA=19:41:56, max mem: 20.9 GB 
[11/27 15:07:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8408,	3.5951 s / batch. (data: 2.79e+00). ETA=2 days, 5:04:08, max mem: 20.9 GB 
[11/27 15:08:32][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 1.87e-01, avg batch time: 1.0098, average train loss: 1.0741
[11/27 15:09:29][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.3071, average loss: 0.6947
[11/27 15:09:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.97	
[11/27 15:09:29][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.4
[11/27 15:11:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.1885,	0.8403 s / batch. (data: 2.81e-02). ETA=12:22:04, max mem: 20.9 GB 
[11/27 15:12:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6860,	1.3560 s / batch. (data: 5.12e-01). ETA=19:55:16, max mem: 20.9 GB 
[11/27 15:14:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9858,	0.8271 s / batch. (data: 5.42e-03). ETA=12:07:42, max mem: 20.9 GB 
[11/27 15:16:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.0841,	0.8240 s / batch. (data: 3.06e-04). ETA=12:03:34, max mem: 20.9 GB 
[11/27 15:17:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5765,	0.8464 s / batch. (data: 1.20e-02). ETA=12:21:49, max mem: 20.9 GB 
[11/27 15:18:47][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 1.85e-01, avg batch time: 1.0082, average train loss: 1.3406
[11/27 15:19:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.3074, average loss: 1.1708
[11/27 15:19:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.42	
[11/27 15:19:44][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.5
[11/27 15:21:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4281,	0.8440 s / batch. (data: 7.62e-04). ETA=12:17:35, max mem: 20.9 GB 
[11/27 15:23:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3868,	0.8544 s / batch. (data: 3.02e-04). ETA=12:25:15, max mem: 20.9 GB 
[11/27 15:24:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5484,	0.8258 s / batch. (data: 3.18e-04). ETA=11:58:57, max mem: 20.9 GB 
[11/27 15:26:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1725,	0.8285 s / batch. (data: 5.79e-03). ETA=11:59:52, max mem: 20.9 GB 
[11/27 15:28:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1503,	0.8310 s / batch. (data: 3.34e-04). ETA=12:00:41, max mem: 20.9 GB 
[11/27 15:29:04][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 1.87e-01, avg batch time: 1.0112, average train loss: 1.4767
[11/27 15:30:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.3061, average loss: 0.7122
[11/27 15:30:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.23	
[11/27 15:30:02][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.6
[11/27 15:31:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8221 s / batch. (data: 1.52e-02). ETA=11:50:52, max mem: 20.9 GB 
[11/27 15:33:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5725,	0.8259 s / batch. (data: 5.44e-03). ETA=11:52:48, max mem: 20.9 GB 
[11/27 15:35:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1049,	0.8108 s / batch. (data: 3.24e-04). ETA=11:38:26, max mem: 20.9 GB 
[11/27 15:36:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8149,	1.6599 s / batch. (data: 8.22e-01). ETA=23:47:02, max mem: 20.9 GB 
[11/27 15:38:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.5716,	0.8360 s / batch. (data: 5.46e-03). ETA=11:57:17, max mem: 20.9 GB 
[11/27 15:39:19][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.83e-01, avg batch time: 1.0062, average train loss: 1.7214
[11/27 15:40:16][INFO] visual_prompt:  316: Inference (val):avg data time: 2.49e-04, avg batch time: 0.3068, average loss: 2.4383
[11/27 15:40:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.17	
[11/27 15:40:16][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.7
[11/27 15:41:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4058,	0.8112 s / batch. (data: 3.01e-04). ETA=11:33:55, max mem: 20.9 GB 
[11/27 15:43:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2943,	0.8395 s / batch. (data: 1.05e-02). ETA=11:56:45, max mem: 20.9 GB 
[11/27 15:45:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1910,	0.8260 s / batch. (data: 1.80e-02). ETA=11:43:51, max mem: 20.9 GB 
[11/27 15:47:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.4699,	0.9811 s / batch. (data: 1.55e-01). ETA=13:54:23, max mem: 20.9 GB 
[11/27 15:48:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.6714,	1.4921 s / batch. (data: 6.66e-01). ETA=21:06:29, max mem: 20.9 GB 
[11/27 15:49:35][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 1.87e-01, avg batch time: 1.0105, average train loss: 1.7855
[11/27 15:50:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3072, average loss: 1.4725
[11/27 15:50:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.95	
[11/27 15:50:32][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.8
[11/27 15:52:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.1074,	0.8200 s / batch. (data: 2.97e-04). ETA=11:33:54, max mem: 20.9 GB 
[11/27 15:53:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8484,	0.8400 s / batch. (data: 7.94e-03). ETA=11:49:28, max mem: 20.9 GB 
[11/27 15:55:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5530,	1.8901 s / batch. (data: 1.08e+00). ETA=1 day, 2:33:12, max mem: 20.9 GB 
[11/27 15:57:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3158,	0.8208 s / batch. (data: 4.52e-04). ETA=11:30:32, max mem: 20.9 GB 
[11/27 15:58:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.6353,	1.0505 s / batch. (data: 2.12e-01). ETA=14:41:59, max mem: 20.9 GB 
[11/27 15:59:50][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 1.86e-01, avg batch time: 1.0089, average train loss: 2.0420
[11/27 16:00:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.3067, average loss: 2.6569
[11/27 16:00:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.63	
[11/27 16:00:48][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.9
[11/27 16:02:36][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.6758,	0.8261 s / batch. (data: 3.22e-04). ETA=11:31:27, max mem: 20.9 GB 
[11/27 16:04:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.1651,	0.8209 s / batch. (data: 5.42e-03). ETA=11:25:47, max mem: 20.9 GB 
[11/27 16:05:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9748,	1.4275 s / batch. (data: 6.00e-01). ETA=19:50:08, max mem: 20.9 GB 
[11/27 16:07:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8070,	0.8344 s / batch. (data: 5.44e-03). ETA=11:34:14, max mem: 20.9 GB 
[11/27 16:09:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5712,	0.8428 s / batch. (data: 2.15e-02). ETA=11:39:52, max mem: 20.9 GB 
[11/27 16:10:06][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 1.85e-01, avg batch time: 1.0083, average train loss: 2.7223
[11/27 16:11:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.3077, average loss: 0.9930
[11/27 16:11:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.69	
[11/27 16:11:03][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 1.0
[11/27 16:12:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3468,	0.8320 s / batch. (data: 3.03e-04). ETA=11:28:45, max mem: 20.9 GB 
[11/27 16:14:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 7.5440,	0.8466 s / batch. (data: 5.41e-03). ETA=11:39:27, max mem: 20.9 GB 
[11/27 16:16:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0002,	2.2330 s / batch. (data: 1.42e+00). ETA=1 day, 6:41:06, max mem: 20.9 GB 
[11/27 16:17:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.0701,	0.8445 s / batch. (data: 2.85e-02). ETA=11:34:54, max mem: 20.9 GB 
[11/27 16:19:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.2936,	0.8280 s / batch. (data: 3.37e-04). ETA=11:19:55, max mem: 20.9 GB 
[11/27 16:20:20][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 1.83e-01, avg batch time: 1.0062, average train loss: 2.7813
[11/27 16:21:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.3067, average loss: 0.7190
[11/27 16:21:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.25	
[11/27 16:21:21][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/27 16:23:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2974,	0.9960 s / batch. (data: 1.73e-01). ETA=13:35:20, max mem: 20.9 GB 
[11/27 16:24:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2570,	0.8395 s / batch. (data: 3.19e-04). ETA=11:25:51, max mem: 20.9 GB 
[11/27 16:26:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0898,	0.8080 s / batch. (data: 2.73e-04). ETA=10:58:44, max mem: 20.9 GB 
[11/27 16:28:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.4149,	0.8231 s / batch. (data: 3.19e-04). ETA=11:09:40, max mem: 20.9 GB 
[11/27 16:29:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8156,	0.8229 s / batch. (data: 2.94e-04). ETA=11:08:07, max mem: 20.9 GB 
[11/27 16:30:42][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.91e-01, avg batch time: 1.0136, average train loss: 2.2124
[11/27 16:31:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.55e-05, avg batch time: 0.3058, average loss: 1.9518
[11/27 16:31:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 42.65	
[11/27 16:31:39][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/27 16:33:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.6673,	0.8106 s / batch. (data: 3.16e-04). ETA=10:56:05, max mem: 20.9 GB 
[11/27 16:35:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0907,	0.8442 s / batch. (data: 2.84e-04). ETA=11:21:51, max mem: 20.9 GB 
[11/27 16:36:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 11.3819,	1.7097 s / batch. (data: 8.74e-01). ETA=22:58:09, max mem: 20.9 GB 
[11/27 16:38:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8201,	0.8120 s / batch. (data: 3.02e-04). ETA=10:53:10, max mem: 20.9 GB 
[11/27 16:40:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.5766,	0.8108 s / batch. (data: 2.54e-04). ETA=10:50:50, max mem: 20.9 GB 
[11/27 16:40:55][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 1.83e-01, avg batch time: 1.0061, average train loss: 3.3906
[11/27 16:41:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3080, average loss: 1.8345
[11/27 16:41:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 54.85	
[11/27 16:41:53][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/27 16:43:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4706,	0.8223 s / batch. (data: 3.46e-04). ETA=10:57:59, max mem: 20.9 GB 
[11/27 16:45:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0002,	1.2325 s / batch. (data: 4.12e-01). ETA=16:24:10, max mem: 20.9 GB 
[11/27 16:46:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9847,	0.8330 s / batch. (data: 1.56e-02). ETA=11:03:48, max mem: 20.9 GB 
[11/27 16:48:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6098,	0.8107 s / batch. (data: 2.94e-04). ETA=10:44:40, max mem: 20.9 GB 
[11/27 16:50:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8445,	0.8357 s / batch. (data: 2.93e-04). ETA=11:03:08, max mem: 20.9 GB 
[11/27 16:51:09][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 1.83e-01, avg batch time: 1.0064, average train loss: 2.9013
[11/27 16:52:07][INFO] visual_prompt:  316: Inference (val):avg data time: 1.52e-04, avg batch time: 0.3067, average loss: 2.6851
[11/27 16:52:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/27 16:52:07][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/27 16:53:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7502,	0.8481 s / batch. (data: 3.32e-04). ETA=11:10:50, max mem: 20.9 GB 
[11/27 16:55:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.2084,	0.8480 s / batch. (data: 2.81e-04). ETA=11:09:18, max mem: 20.9 GB 
[11/27 16:57:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.2141,	0.8375 s / batch. (data: 8.19e-04). ETA=10:59:38, max mem: 20.9 GB 
[11/27 16:58:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.9723,	1.0073 s / batch. (data: 1.93e-01). ETA=13:11:43, max mem: 20.9 GB 
[11/27 17:00:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5792,	0.8411 s / batch. (data: 1.56e-02). ETA=10:59:38, max mem: 20.9 GB 
[11/27 17:01:24][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.85e-01, avg batch time: 1.0079, average train loss: 2.8800
[11/27 17:02:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.84e-05, avg batch time: 0.3054, average loss: 1.1222
[11/27 17:02:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.96	
[11/27 17:02:22][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/27 17:04:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9188,	0.8457 s / batch. (data: 2.86e-04). ETA=11:01:06, max mem: 20.9 GB 
[11/27 17:05:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6138,	0.8113 s / batch. (data: 2.85e-04). ETA=10:32:54, max mem: 20.9 GB 
[11/27 17:07:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6054,	0.8074 s / batch. (data: 2.40e-04). ETA=10:28:28, max mem: 20.9 GB 
[11/27 17:09:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 11.0380,	0.8182 s / batch. (data: 8.14e-04). ETA=10:35:30, max mem: 20.9 GB 
[11/27 17:10:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0261,	1.0600 s / batch. (data: 2.43e-01). ETA=13:41:35, max mem: 20.9 GB 
[11/27 17:11:49][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 2.02e-01, avg batch time: 1.0250, average train loss: 3.0492
[11/27 17:12:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.77e-05, avg batch time: 0.3057, average loss: 1.8886
[11/27 17:12:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.51	
[11/27 17:12:46][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/27 17:14:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.0164,	0.8204 s / batch. (data: 7.95e-03). ETA=10:33:47, max mem: 20.9 GB 
[11/27 17:16:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7377,	0.8080 s / batch. (data: 3.19e-04). ETA=10:22:51, max mem: 20.9 GB 
[11/27 17:17:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.3622,	0.8181 s / batch. (data: 7.97e-03). ETA=10:29:16, max mem: 20.9 GB 
[11/27 17:19:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.6778,	1.1919 s / batch. (data: 3.73e-01). ETA=15:14:51, max mem: 20.9 GB 
[11/27 17:21:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.8617,	1.6274 s / batch. (data: 7.87e-01). ETA=20:46:23, max mem: 20.9 GB 
[11/27 17:22:04][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 1.86e-01, avg batch time: 1.0092, average train loss: 3.0789
[11/27 17:23:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3070, average loss: 2.8243
[11/27 17:23:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.42	
[11/27 17:23:02][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/27 17:24:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.2617,	0.8191 s / batch. (data: 2.87e-03). ETA=10:25:13, max mem: 20.9 GB 
[11/27 17:26:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3063,	0.8240 s / batch. (data: 3.18e-04). ETA=10:27:35, max mem: 20.9 GB 
[11/27 17:28:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5358,	0.8315 s / batch. (data: 1.14e-02). ETA=10:31:54, max mem: 20.9 GB 
[11/27 17:29:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.9620,	0.8223 s / batch. (data: 3.07e-04). ETA=10:23:33, max mem: 20.9 GB 
[11/27 17:31:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2236,	0.8221 s / batch. (data: 2.93e-04). ETA=10:22:03, max mem: 20.9 GB 
[11/27 17:32:20][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 1.85e-01, avg batch time: 1.0095, average train loss: 3.1646
[11/27 17:33:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3079, average loss: 2.9035
[11/27 17:33:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.02	
[11/27 17:33:18][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/27 17:35:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2002,	0.8299 s / batch. (data: 1.19e-02). ETA=10:25:49, max mem: 20.9 GB 
[11/27 17:36:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4388,	0.8333 s / batch. (data: 5.40e-03). ETA=10:26:59, max mem: 20.9 GB 
[11/27 17:38:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 12.4888,	0.8292 s / batch. (data: 3.05e-04). ETA=10:22:33, max mem: 20.9 GB 
[11/27 17:40:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.7336,	0.8386 s / batch. (data: 8.18e-04). ETA=10:28:11, max mem: 20.9 GB 
[11/27 17:41:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7673,	0.8160 s / batch. (data: 2.99e-04). ETA=10:09:55, max mem: 20.9 GB 
[11/27 17:42:34][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.82e-01, avg batch time: 1.0053, average train loss: 2.8470
[11/27 17:43:31][INFO] visual_prompt:  316: Inference (val):avg data time: 4.00e-05, avg batch time: 0.3068, average loss: 7.4800
[11/27 17:43:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.49	
[11/27 17:43:31][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/27 17:45:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.2764,	0.8400 s / batch. (data: 3.13e-04). ETA=10:25:42, max mem: 20.9 GB 
[11/27 17:46:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8867,	0.8360 s / batch. (data: 7.95e-03). ETA=10:21:19, max mem: 20.9 GB 
[11/27 17:48:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9475,	0.8415 s / batch. (data: 3.06e-04). ETA=10:23:59, max mem: 20.9 GB 
[11/27 17:50:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5581,	0.8240 s / batch. (data: 3.21e-04). ETA=10:09:40, max mem: 20.9 GB 
[11/27 17:51:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.0633,	0.8209 s / batch. (data: 1.01e-02). ETA=10:06:00, max mem: 20.9 GB 
[11/27 17:52:49][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 1.85e-01, avg batch time: 1.0089, average train loss: 2.7796
[11/27 17:53:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-04, avg batch time: 0.3049, average loss: 0.8203
[11/27 17:53:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.48	
[11/27 17:53:48][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/27 17:55:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.5754,	0.8266 s / batch. (data: 6.55e-03). ETA=10:08:05, max mem: 20.9 GB 
[11/27 17:57:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.4108,	0.8207 s / batch. (data: 2.93e-04). ETA=10:02:23, max mem: 20.9 GB 
[11/27 17:58:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.5463,	0.8640 s / batch. (data: 4.31e-02). ETA=10:32:44, max mem: 20.9 GB 
[11/27 18:00:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.4283,	0.8217 s / batch. (data: 3.23e-04). ETA=10:00:24, max mem: 20.9 GB 
[11/27 18:02:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.6179,	0.8400 s / batch. (data: 3.22e-04). ETA=10:12:21, max mem: 20.9 GB 
[11/27 18:03:06][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 1.86e-01, avg batch time: 1.0092, average train loss: 2.9148
[11/27 18:04:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.62e-05, avg batch time: 0.3052, average loss: 15.3549
[11/27 18:04:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.30	
[11/27 18:04:03][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/27 18:05:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.5224,	0.8080 s / batch. (data: 3.20e-04). ETA=9:46:57, max mem: 20.9 GB 
[11/27 18:07:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 13.7409,	0.8116 s / batch. (data: 5.38e-03). ETA=9:48:14, max mem: 20.9 GB 
[11/27 18:09:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0334,	0.8803 s / batch. (data: 7.36e-02). ETA=10:36:32, max mem: 20.9 GB 
[11/27 18:10:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1310,	0.8165 s / batch. (data: 5.42e-03). ETA=9:49:04, max mem: 20.9 GB 
[11/27 18:12:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 22.3371,	0.8385 s / batch. (data: 1.05e-02). ETA=10:03:30, max mem: 20.9 GB 
[11/27 18:13:21][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 1.85e-01, avg batch time: 1.0080, average train loss: 3.2062
[11/27 18:14:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.93e-05, avg batch time: 0.3073, average loss: 4.0187
[11/27 18:14:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.98	
[11/27 18:14:18][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/27 18:16:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.3435,	0.8560 s / batch. (data: 5.46e-03). ETA=10:13:56, max mem: 20.9 GB 
[11/27 18:17:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8062,	0.8112 s / batch. (data: 3.15e-04). ETA=9:40:29, max mem: 20.9 GB 
[11/27 18:19:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5328,	0.8321 s / batch. (data: 8.89e-04). ETA=9:54:02, max mem: 20.9 GB 
[11/27 18:21:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.7154,	0.8278 s / batch. (data: 3.06e-04). ETA=9:49:36, max mem: 20.9 GB 
[11/27 18:22:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2378,	0.8162 s / batch. (data: 3.00e-04). ETA=9:39:58, max mem: 20.9 GB 
[11/27 18:23:36][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 1.84e-01, avg batch time: 1.0082, average train loss: 2.7538
[11/27 18:24:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.3058, average loss: 0.8995
[11/27 18:24:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.44	
[11/27 18:24:34][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/27 18:26:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7059,	0.8519 s / batch. (data: 1.99e-02). ETA=10:03:11, max mem: 20.9 GB 
[11/27 18:27:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.1721,	0.8412 s / batch. (data: 7.99e-04). ETA=9:54:09, max mem: 20.9 GB 
[11/27 18:29:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.1876,	1.0825 s / batch. (data: 2.69e-01). ETA=12:42:50, max mem: 20.9 GB 
[11/27 18:31:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9383,	0.8174 s / batch. (data: 3.02e-04). ETA=9:34:39, max mem: 20.9 GB 
[11/27 18:32:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6994,	0.8320 s / batch. (data: 3.04e-04). ETA=9:43:31, max mem: 20.9 GB 
[11/27 18:33:52][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 1.86e-01, avg batch time: 1.0089, average train loss: 2.7766
[11/27 18:34:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.3073, average loss: 0.6933
[11/27 18:34:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 51.58	
[11/27 18:34:49][INFO] visual_prompt:   36: Best epoch 24: best metric: -0.693
[11/27 18:34:49][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/27 18:36:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9825,	0.8147 s / batch. (data: 2.84e-04). ETA=9:29:18, max mem: 20.9 GB 
[11/27 18:38:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.4278,	1.1063 s / batch. (data: 2.61e-01). ETA=12:51:15, max mem: 20.9 GB 
[11/27 18:39:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6883,	0.8228 s / batch. (data: 3.18e-04). ETA=9:32:14, max mem: 20.9 GB 
[11/27 18:41:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 10.6437,	1.1451 s / batch. (data: 3.28e-01). ETA=13:14:29, max mem: 20.9 GB 
[11/27 18:43:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9651,	1.3360 s / batch. (data: 5.02e-01). ETA=15:24:41, max mem: 20.9 GB 
[11/27 18:44:07][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 1.85e-01, avg batch time: 1.0089, average train loss: 2.5519
[11/27 18:45:05][INFO] visual_prompt:  316: Inference (val):avg data time: 2.93e-04, avg batch time: 0.3064, average loss: 13.9499
[11/27 18:45:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.81	
[11/27 18:45:05][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/27 18:46:49][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1473,	0.8528 s / batch. (data: 3.68e-02). ETA=9:48:05, max mem: 20.9 GB 
[11/27 18:48:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6540,	1.6582 s / batch. (data: 8.52e-01). ETA=19:00:40, max mem: 20.9 GB 
[11/27 18:50:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3755,	0.8440 s / batch. (data: 7.92e-04). ETA=9:39:11, max mem: 20.9 GB 
[11/27 18:51:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.4730,	0.8440 s / batch. (data: 7.94e-03). ETA=9:37:47, max mem: 20.9 GB 
[11/27 18:53:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6244,	0.8508 s / batch. (data: 1.89e-02). ETA=9:41:02, max mem: 20.9 GB 
[11/27 18:54:22][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 1.83e-01, avg batch time: 1.0067, average train loss: 2.1947
[11/27 18:55:19][INFO] visual_prompt:  316: Inference (val):avg data time: 2.18e-04, avg batch time: 0.3073, average loss: 3.6868
[11/27 18:55:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.12	
[11/27 18:55:19][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/27 18:57:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7660,	0.8439 s / batch. (data: 7.89e-03). ETA=9:34:11, max mem: 20.9 GB 
[11/27 18:58:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.8494,	1.3022 s / batch. (data: 4.96e-01). ETA=14:43:50, max mem: 20.9 GB 
[11/27 19:00:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.5061,	0.8320 s / batch. (data: 3.05e-04). ETA=9:23:17, max mem: 20.9 GB 
[11/27 19:02:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2970,	0.8400 s / batch. (data: 3.07e-04). ETA=9:27:18, max mem: 20.9 GB 
[11/27 19:03:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5721,	0.8311 s / batch. (data: 2.87e-04). ETA=9:19:53, max mem: 20.9 GB 
[11/27 19:04:36][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 1.84e-01, avg batch time: 1.0071, average train loss: 2.6540
[11/27 19:05:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.48e-05, avg batch time: 0.3077, average loss: 3.5891
[11/27 19:05:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.28	
[11/27 19:05:33][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/27 19:07:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0002,	0.8120 s / batch. (data: 2.62e-04). ETA=9:05:00, max mem: 20.9 GB 
[11/27 19:08:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6356,	0.8157 s / batch. (data: 3.44e-04). ETA=9:06:06, max mem: 20.9 GB 
[11/27 19:10:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6102,	1.6558 s / batch. (data: 8.26e-01). ETA=18:25:47, max mem: 20.9 GB 
[11/27 19:12:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.8450,	0.8440 s / batch. (data: 2.75e-04). ETA=9:22:14, max mem: 20.9 GB 
[11/27 19:13:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6316,	0.8141 s / batch. (data: 2.92e-04). ETA=9:00:56, max mem: 20.9 GB 
[11/27 19:14:50][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.84e-01, avg batch time: 1.0062, average train loss: 2.5020
[11/27 19:15:48][INFO] visual_prompt:  316: Inference (val):avg data time: 2.17e-04, avg batch time: 0.3058, average loss: 2.3042
[11/27 19:15:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/27 19:15:48][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/27 19:17:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3383,	0.8207 s / batch. (data: 2.84e-04). ETA=9:03:14, max mem: 20.9 GB 
[11/27 19:19:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6855,	1.9301 s / batch. (data: 1.11e+00). ETA=21:14:23, max mem: 20.9 GB 
[11/27 19:20:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6887,	0.8110 s / batch. (data: 3.20e-04). ETA=8:54:06, max mem: 20.9 GB 
[11/27 19:22:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.9906,	0.8894 s / batch. (data: 7.71e-02). ETA=9:44:15, max mem: 20.9 GB 
[11/27 19:24:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.3491,	0.8506 s / batch. (data: 1.56e-02). ETA=9:17:23, max mem: 20.9 GB 
[11/27 19:25:06][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 1.86e-01, avg batch time: 1.0094, average train loss: 2.7083
[11/27 19:26:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.3053, average loss: 2.2601
[11/27 19:26:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.89	
[11/27 19:26:03][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/27 19:27:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3582,	0.8179 s / batch. (data: 3.92e-04). ETA=8:53:52, max mem: 20.9 GB 
[11/27 19:29:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6117,	0.8380 s / batch. (data: 5.43e-03). ETA=9:05:36, max mem: 20.9 GB 
[11/27 19:31:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0323,	1.9758 s / batch. (data: 1.16e+00). ETA=21:23:03, max mem: 20.9 GB 
[11/27 19:32:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7059,	1.1121 s / batch. (data: 3.00e-01). ETA=12:00:18, max mem: 20.9 GB 
[11/27 19:34:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.8829,	1.4960 s / batch. (data: 6.78e-01). ETA=16:06:30, max mem: 20.9 GB 
[11/27 19:35:21][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 1.85e-01, avg batch time: 1.0080, average train loss: 2.6531
[11/27 19:36:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.3070, average loss: 2.0257
[11/27 19:36:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.52	
[11/27 19:36:18][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/27 19:38:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9641,	0.8320 s / batch. (data: 7.93e-03). ETA=8:55:22, max mem: 20.9 GB 
[11/27 19:39:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.9513,	0.8240 s / batch. (data: 2.81e-04). ETA=8:48:52, max mem: 20.9 GB 
[11/27 19:41:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 10.7418,	0.8280 s / batch. (data: 3.08e-04). ETA=8:50:03, max mem: 20.9 GB 
[11/27 19:43:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.2864,	1.4859 s / batch. (data: 6.65e-01). ETA=15:48:45, max mem: 20.9 GB 
[11/27 19:44:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9899,	0.8102 s / batch. (data: 2.99e-04). ETA=8:35:56, max mem: 20.9 GB 
[11/27 19:45:35][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 1.82e-01, avg batch time: 1.0058, average train loss: 2.2740
[11/27 19:46:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.68e-05, avg batch time: 0.3058, average loss: 0.7490
[11/27 19:46:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.76	
[11/27 19:46:32][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/27 19:48:18][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6049,	0.8351 s / batch. (data: 8.09e-04). ETA=8:49:42, max mem: 20.9 GB 
[11/27 19:49:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5663,	0.8316 s / batch. (data: 1.05e-02). ETA=8:46:05, max mem: 20.9 GB 
[11/27 19:51:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 7.0590,	0.8200 s / batch. (data: 3.24e-04). ETA=8:37:22, max mem: 20.9 GB 
[11/27 19:53:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7622,	0.8440 s / batch. (data: 2.77e-04). ETA=8:51:07, max mem: 20.9 GB 
[11/27 19:54:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6783,	0.8160 s / batch. (data: 4.24e-04). ETA=8:32:07, max mem: 20.9 GB 
[11/27 19:55:49][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 1.84e-01, avg batch time: 1.0071, average train loss: 2.2939
[11/27 19:56:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.39e-05, avg batch time: 0.3077, average loss: 2.3057
[11/27 19:56:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.82	
[11/27 19:56:45][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/27 19:58:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0002,	0.8076 s / batch. (data: 3.03e-04). ETA=8:24:47, max mem: 20.9 GB 
[11/27 20:00:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.4458,	1.2535 s / batch. (data: 4.26e-01). ETA=13:01:26, max mem: 20.9 GB 
[11/27 20:01:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7954,	0.8360 s / batch. (data: 2.87e-04). ETA=8:39:46, max mem: 20.9 GB 
[11/27 20:03:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3548,	0.8197 s / batch. (data: 2.91e-04). ETA=8:28:14, max mem: 20.9 GB 
[11/27 20:04:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6328,	0.8240 s / batch. (data: 1.19e-02). ETA=8:29:32, max mem: 20.9 GB 
[11/27 20:05:36][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 1.37e-01, avg batch time: 0.9604, average train loss: 2.1522
[11/27 20:06:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3065, average loss: 0.6910
[11/27 20:06:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.83	
[11/27 20:06:31][INFO] visual_prompt:   36: Best epoch 33: best metric: -0.691
[11/27 20:06:31][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/27 20:08:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7138,	0.8120 s / batch. (data: 3.20e-04). ETA=8:20:03, max mem: 20.9 GB 
[11/27 20:09:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.4925,	0.8200 s / batch. (data: 3.14e-04). ETA=8:23:37, max mem: 20.9 GB 
[11/27 20:11:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.9661,	0.8377 s / batch. (data: 9.66e-03). ETA=8:33:07, max mem: 20.9 GB 
[11/27 20:12:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.7802,	0.8256 s / batch. (data: 2.96e-04). ETA=8:24:19, max mem: 20.9 GB 
[11/27 20:14:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8462,	1.3736 s / batch. (data: 5.53e-01). ETA=13:56:46, max mem: 20.9 GB 
[11/27 20:15:22][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 1.39e-01, avg batch time: 0.9615, average train loss: 2.6615
[11/27 20:16:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3059, average loss: 1.1740
[11/27 20:16:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.93	
[11/27 20:16:17][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/27 20:17:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.9830,	0.8152 s / batch. (data: 7.95e-03). ETA=8:14:32, max mem: 20.9 GB 
[11/27 20:19:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6856,	0.8370 s / batch. (data: 1.05e-02). ETA=8:26:20, max mem: 20.9 GB 
[11/27 20:21:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.6449,	0.8215 s / batch. (data: 5.38e-03). ETA=8:15:38, max mem: 20.9 GB 
[11/27 20:22:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6149,	0.8339 s / batch. (data: 5.44e-03). ETA=8:21:41, max mem: 20.9 GB 
[11/27 20:24:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6931,	1.1813 s / batch. (data: 3.60e-01). ETA=11:48:44, max mem: 20.9 GB 
[11/27 20:25:13][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 1.46e-01, avg batch time: 0.9688, average train loss: 1.8298
[11/27 20:26:08][INFO] visual_prompt:  316: Inference (val):avg data time: 1.89e-04, avg batch time: 0.3059, average loss: 1.8427
[11/27 20:26:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.98	
[11/27 20:26:08][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/27 20:27:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1378,	0.8173 s / batch. (data: 3.29e-04). ETA=8:08:17, max mem: 20.9 GB 
[11/27 20:29:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.7021,	0.8169 s / batch. (data: 2.81e-04). ETA=8:06:38, max mem: 20.9 GB 
[11/27 20:31:03][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.7361,	0.8274 s / batch. (data: 5.42e-03). ETA=8:11:34, max mem: 20.9 GB 
[11/27 20:32:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.4654,	0.8067 s / batch. (data: 2.98e-04). ETA=7:57:52, max mem: 20.9 GB 
[11/27 20:34:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5981,	0.9195 s / batch. (data: 7.53e-02). ETA=9:03:11, max mem: 20.9 GB 
[11/27 20:35:03][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 1.44e-01, avg batch time: 0.9674, average train loss: 2.2093
[11/27 20:35:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3057, average loss: 5.9647
[11/27 20:35:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.15	
[11/27 20:35:58][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/27 20:37:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.6822,	0.8211 s / batch. (data: 3.22e-04). ETA=8:02:57, max mem: 20.9 GB 
[11/27 20:39:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6890,	0.8077 s / batch. (data: 2.97e-04). ETA=7:53:46, max mem: 20.9 GB 
[11/27 20:40:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9766,	1.4240 s / batch. (data: 6.12e-01). ETA=13:52:50, max mem: 20.9 GB 
[11/27 20:42:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1788,	1.9186 s / batch. (data: 1.11e+00). ETA=18:38:55, max mem: 20.9 GB 
[11/27 20:44:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.2658,	1.0356 s / batch. (data: 2.29e-01). ETA=10:02:12, max mem: 20.9 GB 
[11/27 20:44:54][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 1.46e-01, avg batch time: 0.9693, average train loss: 2.0978
[11/27 20:45:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.52e-05, avg batch time: 0.3101, average loss: 1.5988
[11/27 20:45:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.77	
[11/27 20:45:49][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/27 20:47:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8851,	0.8070 s / batch. (data: 3.02e-04). ETA=7:47:13, max mem: 20.9 GB 
[11/27 20:49:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.0352,	1.4988 s / batch. (data: 6.82e-01). ETA=14:25:18, max mem: 20.9 GB 
[11/27 20:50:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5409,	0.8072 s / batch. (data: 2.93e-04). ETA=7:44:38, max mem: 20.9 GB 
[11/27 20:52:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6111,	0.8420 s / batch. (data: 1.19e-02). ETA=8:03:16, max mem: 20.9 GB 
[11/27 20:53:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 22.3139,	0.8520 s / batch. (data: 1.14e-03). ETA=8:07:36, max mem: 20.9 GB 
[11/27 20:54:44][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 1.44e-01, avg batch time: 0.9671, average train loss: 2.1677
[11/27 20:55:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.3070, average loss: 4.7694
[11/27 20:55:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.79	
[11/27 20:55:39][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/27 20:57:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0604,	0.8655 s / batch. (data: 5.47e-03). ETA=8:13:08, max mem: 20.9 GB 
[11/27 20:58:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6759,	0.8258 s / batch. (data: 8.33e-04). ETA=7:49:08, max mem: 20.9 GB 
[11/27 21:00:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.5685,	0.8178 s / batch. (data: 2.60e-04). ETA=7:43:14, max mem: 20.9 GB 
[11/27 21:02:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.7708,	1.0027 s / batch. (data: 1.81e-01). ETA=9:26:17, max mem: 20.9 GB 
[11/27 21:03:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4081,	1.7811 s / batch. (data: 9.68e-01). ETA=16:42:55, max mem: 20.9 GB 
[11/27 21:04:37][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 1.48e-01, avg batch time: 0.9714, average train loss: 1.9088
[11/27 21:05:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.52e-05, avg batch time: 0.3057, average loss: 0.8640
[11/27 21:05:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/27 21:05:32][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/27 21:07:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.1731,	0.8220 s / batch. (data: 2.97e-04). ETA=7:40:45, max mem: 20.9 GB 
[11/27 21:08:48][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3754,	0.8294 s / batch. (data: 7.94e-03). ETA=7:43:30, max mem: 20.9 GB 
[11/27 21:10:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.2486,	0.8500 s / batch. (data: 7.95e-04). ETA=7:53:39, max mem: 20.9 GB 
[11/27 21:12:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7807,	0.8450 s / batch. (data: 8.59e-04). ETA=7:49:27, max mem: 20.9 GB 
[11/27 21:13:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.5303,	0.8181 s / batch. (data: 1.19e-02). ETA=7:33:09, max mem: 20.9 GB 
[11/27 21:14:30][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 1.49e-01, avg batch time: 0.9726, average train loss: 2.1051
[11/27 21:15:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3068, average loss: 0.8930
[11/27 21:15:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.54	
[11/27 21:15:25][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.75
[11/27 21:17:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6960,	0.8236 s / batch. (data: 5.55e-03). ETA=7:34:03, max mem: 20.9 GB 
[11/27 21:18:48][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1739,	0.8240 s / batch. (data: 3.05e-04). ETA=7:32:54, max mem: 20.9 GB 
[11/27 21:20:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.3497,	0.8526 s / batch. (data: 3.46e-02). ETA=7:47:14, max mem: 20.9 GB 
[11/27 21:21:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9638,	0.8219 s / batch. (data: 3.00e-04). ETA=7:29:03, max mem: 20.9 GB 
[11/27 21:23:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.8615,	0.8353 s / batch. (data: 5.88e-03). ETA=7:34:57, max mem: 20.9 GB 
[11/27 21:24:21][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 1.45e-01, avg batch time: 0.9688, average train loss: 1.9298
[11/27 21:25:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3058, average loss: 1.0720
[11/27 21:25:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 55.11	
[11/27 21:25:16][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/27 21:26:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.6607,	0.8204 s / batch. (data: 2.84e-04). ETA=7:24:46, max mem: 20.9 GB 
[11/27 21:28:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.9794,	0.8399 s / batch. (data: 5.43e-03). ETA=7:33:55, max mem: 20.9 GB 
[11/27 21:30:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8868,	0.8064 s / batch. (data: 2.97e-04). ETA=7:14:29, max mem: 20.9 GB 
[11/27 21:31:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9817,	0.8240 s / batch. (data: 3.18e-04). ETA=7:22:34, max mem: 20.9 GB 
[11/27 21:33:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.0830,	0.8320 s / batch. (data: 3.05e-04). ETA=7:25:29, max mem: 20.9 GB 
[11/27 21:34:11][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 1.46e-01, avg batch time: 0.9679, average train loss: 2.3765
[11/27 21:35:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.49e-05, avg batch time: 0.3075, average loss: 2.6654
[11/27 21:35:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.41	
[11/27 21:35:06][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/27 21:36:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6919,	0.8069 s / batch. (data: 2.92e-04). ETA=7:09:58, max mem: 20.9 GB 
[11/27 21:38:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.3715,	0.8360 s / batch. (data: 5.46e-03). ETA=7:24:06, max mem: 20.9 GB 
[11/27 21:39:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.3153,	0.8367 s / batch. (data: 7.96e-03). ETA=7:23:05, max mem: 20.9 GB 
[11/27 21:41:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5495,	0.8091 s / batch. (data: 2.71e-04). ETA=7:07:08, max mem: 20.9 GB 
[11/27 21:43:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.3719,	0.8332 s / batch. (data: 2.57e-02). ETA=7:18:28, max mem: 20.9 GB 
[11/27 21:44:03][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 1.48e-01, avg batch time: 0.9715, average train loss: 2.1711
[11/27 21:44:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.49e-05, avg batch time: 0.3067, average loss: 1.0611
[11/27 21:44:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.77	
[11/27 21:44:58][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/27 21:46:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6536,	1.2552 s / batch. (data: 4.48e-01). ETA=10:57:18, max mem: 20.9 GB 
[11/27 21:48:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2334,	0.8361 s / batch. (data: 2.65e-04). ETA=7:16:26, max mem: 20.9 GB 
[11/27 21:49:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8066,	0.8400 s / batch. (data: 1.20e-02). ETA=7:17:06, max mem: 20.9 GB 
[11/27 21:51:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1292,	0.8307 s / batch. (data: 5.12e-03). ETA=7:10:51, max mem: 20.9 GB 
[11/27 21:53:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.5931,	0.8069 s / batch. (data: 2.96e-04). ETA=6:57:10, max mem: 20.9 GB 
[11/27 21:53:53][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 1.42e-01, avg batch time: 0.9659, average train loss: 2.0941
[11/27 21:54:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.38e-05, avg batch time: 0.3061, average loss: 3.0344
[11/27 21:54:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.45	
[11/27 21:54:48][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/27 21:56:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.6431,	0.8280 s / batch. (data: 7.95e-03). ETA=7:05:58, max mem: 20.9 GB 
[11/27 21:58:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6821,	0.9391 s / batch. (data: 1.13e-01). ETA=8:01:35, max mem: 20.9 GB 
[11/27 21:59:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.4774,	0.8389 s / batch. (data: 3.10e-04). ETA=7:08:46, max mem: 20.9 GB 
[11/27 22:01:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.2171,	0.8075 s / batch. (data: 2.96e-04). ETA=6:51:23, max mem: 20.9 GB 
[11/27 22:02:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6980,	0.8216 s / batch. (data: 3.40e-04). ETA=6:57:11, max mem: 20.9 GB 
[11/27 22:03:41][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 1.41e-01, avg batch time: 0.9643, average train loss: 1.9767
[11/27 22:04:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3063, average loss: 1.0924
[11/27 22:04:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.41	
[11/27 22:04:36][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/27 22:06:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.2458,	0.8330 s / batch. (data: 1.59e-02). ETA=7:00:52, max mem: 20.9 GB 
[11/27 22:07:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2857,	0.9010 s / batch. (data: 7.87e-04). ETA=7:33:42, max mem: 20.9 GB 
[11/27 22:09:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5727,	0.8360 s / batch. (data: 2.78e-04). ETA=6:59:37, max mem: 20.9 GB 
[11/27 22:11:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7820,	0.8202 s / batch. (data: 1.05e-02). ETA=6:50:17, max mem: 20.9 GB 
[11/27 22:12:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.5864,	0.8145 s / batch. (data: 2.52e-04). ETA=6:46:06, max mem: 20.9 GB 
[11/27 22:13:28][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 1.39e-01, avg batch time: 0.9619, average train loss: 1.7843
[11/27 22:14:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.53e-05, avg batch time: 0.3063, average loss: 1.3203
[11/27 22:14:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.42	
[11/27 22:14:22][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/27 22:16:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.5818,	0.8114 s / batch. (data: 5.42e-03). ETA=6:42:27, max mem: 20.9 GB 
[11/27 22:17:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7208,	0.8200 s / batch. (data: 3.03e-04). ETA=6:45:22, max mem: 20.9 GB 
[11/27 22:19:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.1863,	0.8400 s / batch. (data: 8.10e-04). ETA=6:53:51, max mem: 20.9 GB 
[11/27 22:20:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4958,	0.8200 s / batch. (data: 2.88e-04). ETA=6:42:38, max mem: 20.9 GB 
[11/27 22:22:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8249,	0.8481 s / batch. (data: 7.94e-03). ETA=6:55:00, max mem: 20.9 GB 
[11/27 22:23:16][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 1.40e-01, avg batch time: 0.9644, average train loss: 2.1250
[11/27 22:24:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3074, average loss: 0.7435
[11/27 22:24:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.28	
[11/27 22:24:10][INFO] visual_prompt:   42: Stopping early.
