[11/30 05:37:12][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/30 05:37:12][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 05:37:12][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 05:37:12][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 05:37:12][INFO] visual_prompt:  108: Training with config:
[11/30 05:37:12][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr1.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 05:37:12][INFO] visual_prompt:   70: Loading training data...
[11/30 05:37:12][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/30 05:37:12][INFO] visual_prompt:   72: Loading validation data...
[11/30 05:37:12][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/30 05:37:12][INFO] visual_prompt:   36: Constructing models...
[11/30 05:37:14][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[11/30 05:37:14][INFO] visual_prompt:   54: tuned percent:0.525
[11/30 05:37:15][INFO] visual_prompt:   40: Device used for model: 0
[11/30 05:37:15][INFO] visual_prompt:   38: Setting up Evaluator...
[11/30 05:37:15][INFO] visual_prompt:   40: Setting up Trainer...
[11/30 05:37:15][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/30 05:37:15][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/30 05:38:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8173 s / batch. (data: 3.02e-04). ETA=12:31:53, max mem: 20.9 GB 
[11/30 05:40:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8480 s / batch. (data: 7.95e-03). ETA=12:58:44, max mem: 20.9 GB 
[11/30 05:42:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	0.9082 s / batch. (data: 8.30e-02). ETA=13:52:30, max mem: 20.9 GB 
[11/30 05:43:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8421 s / batch. (data: 3.30e-04). ETA=12:50:32, max mem: 20.9 GB 
[11/30 05:45:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8400 s / batch. (data: 7.94e-03). ETA=12:47:10, max mem: 20.9 GB 
[11/30 05:46:07][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 1.28e-01, avg batch time: 0.9618, average train loss: 1.5403
[11/30 05:47:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.48e-05, avg batch time: 0.3096, average loss: 1.5201
[11/30 05:47:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[11/30 05:47:01][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.1
[11/30 05:48:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7319,	0.8201 s / batch. (data: 2.99e-04). ETA=12:26:56, max mem: 20.9 GB 
[11/30 05:50:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0588,	0.8402 s / batch. (data: 3.35e-04). ETA=12:43:47, max mem: 20.9 GB 
[11/30 05:51:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7024,	0.9047 s / batch. (data: 6.55e-02). ETA=13:40:59, max mem: 20.9 GB 
[11/30 05:53:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2103,	0.8318 s / batch. (data: 2.90e-04). ETA=12:33:28, max mem: 20.9 GB 
[11/30 05:55:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6010,	0.8520 s / batch. (data: 2.93e-04). ETA=12:50:18, max mem: 20.9 GB 
[11/30 05:55:51][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 1.25e-01, avg batch time: 0.9593, average train loss: 0.9073
[11/30 05:56:46][INFO] visual_prompt:  316: Inference (val):avg data time: 4.11e-05, avg batch time: 0.3103, average loss: 1.4984
[11/30 05:56:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.17	
[11/30 05:56:46][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.2
[11/30 05:58:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1307,	0.8236 s / batch. (data: 5.40e-03). ETA=12:22:31, max mem: 20.9 GB 
[11/30 06:00:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7188,	1.4400 s / batch. (data: 6.05e-01). ETA=21:35:51, max mem: 20.9 GB 
[11/30 06:01:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0751,	0.8338 s / batch. (data: 2.77e-04). ETA=12:28:54, max mem: 20.9 GB 
[11/30 06:03:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2364,	0.8480 s / batch. (data: 3.90e-03). ETA=12:40:16, max mem: 20.9 GB 
[11/30 06:04:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7146,	1.1821 s / batch. (data: 3.43e-01). ETA=17:37:53, max mem: 20.9 GB 
[11/30 06:05:38][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 1.28e-01, avg batch time: 0.9618, average train loss: 1.0137
[11/30 06:06:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.59e-05, avg batch time: 0.3119, average loss: 0.7381
[11/30 06:06:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.10	
[11/30 06:06:33][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.3
[11/30 06:08:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7098,	0.8539 s / batch. (data: 3.52e-04). ETA=12:42:01, max mem: 20.9 GB 
[11/30 06:09:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6045,	0.8211 s / batch. (data: 3.26e-04). ETA=12:11:20, max mem: 20.9 GB 
[11/30 06:11:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6077,	1.3784 s / batch. (data: 5.49e-01). ETA=20:25:25, max mem: 20.9 GB 
[11/30 06:13:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5648,	1.2271 s / batch. (data: 4.09e-01). ETA=18:08:51, max mem: 20.9 GB 
[11/30 06:14:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8408,	3.1369 s / batch. (data: 2.32e+00). ETA=1 day, 22:18:17, max mem: 20.9 GB 
[11/30 06:15:29][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 1.35e-01, avg batch time: 0.9698, average train loss: 1.0741
[11/30 06:16:24][INFO] visual_prompt:  316: Inference (val):avg data time: 3.26e-05, avg batch time: 0.3122, average loss: 0.6947
[11/30 06:16:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.97	
[11/30 06:16:24][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.4
[11/30 06:18:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.1885,	0.8414 s / batch. (data: 1.05e-02). ETA=12:23:06, max mem: 20.9 GB 
[11/30 06:19:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6860,	1.0336 s / batch. (data: 1.87e-01). ETA=15:11:05, max mem: 20.9 GB 
[11/30 06:21:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9858,	0.8362 s / batch. (data: 1.05e-02). ETA=12:15:41, max mem: 20.9 GB 
[11/30 06:22:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.0841,	0.8408 s / batch. (data: 2.96e-04). ETA=12:18:20, max mem: 20.9 GB 
[11/30 06:24:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5765,	0.8398 s / batch. (data: 4.50e-04). ETA=12:16:04, max mem: 20.9 GB 
[11/30 06:25:20][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 1.33e-01, avg batch time: 0.9679, average train loss: 1.3406
[11/30 06:26:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.49e-05, avg batch time: 0.3108, average loss: 1.1708
[11/30 06:26:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.42	
[11/30 06:26:15][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.5
[11/30 06:27:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4281,	0.8435 s / batch. (data: 1.05e-02). ETA=12:17:09, max mem: 20.9 GB 
[11/30 06:29:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3868,	0.8331 s / batch. (data: 5.41e-03). ETA=12:06:41, max mem: 20.9 GB 
[11/30 06:31:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5484,	0.8507 s / batch. (data: 3.19e-04). ETA=12:20:38, max mem: 20.9 GB 
[11/30 06:32:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1725,	0.8600 s / batch. (data: 3.68e-04). ETA=12:27:16, max mem: 20.9 GB 
[11/30 06:34:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1503,	0.8320 s / batch. (data: 3.27e-04). ETA=12:01:32, max mem: 20.9 GB 
[11/30 06:35:11][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 1.37e-01, avg batch time: 0.9704, average train loss: 1.4767
[11/30 06:36:06][INFO] visual_prompt:  316: Inference (val):avg data time: 2.15e-04, avg batch time: 0.3096, average loss: 0.7122
[11/30 06:36:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.23	
[11/30 06:36:06][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.6
[11/30 06:37:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8525 s / batch. (data: 2.04e-02). ETA=12:17:07, max mem: 20.9 GB 
[11/30 06:39:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5725,	0.8559 s / batch. (data: 3.01e-02). ETA=12:18:41, max mem: 20.9 GB 
[11/30 06:41:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1049,	1.8115 s / batch. (data: 9.59e-01). ETA=1 day, 2:00:24, max mem: 20.9 GB 
[11/30 06:42:36][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8149,	1.7275 s / batch. (data: 8.88e-01). ETA=1 day, 0:45:08, max mem: 20.9 GB 
[11/30 06:44:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.5716,	0.8280 s / batch. (data: 5.43e-03). ETA=11:50:26, max mem: 20.9 GB 
[11/30 06:45:00][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.30e-01, avg batch time: 0.9650, average train loss: 1.7214
[11/30 06:45:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.67e-05, avg batch time: 0.3109, average loss: 2.4383
[11/30 06:45:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.17	
[11/30 06:45:55][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.7
[11/30 06:47:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4058,	0.8394 s / batch. (data: 1.10e-02). ETA=11:58:05, max mem: 20.9 GB 
[11/30 06:49:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2943,	0.8453 s / batch. (data: 7.96e-03). ETA=12:01:41, max mem: 20.9 GB 
[11/30 06:50:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1910,	0.8194 s / batch. (data: 3.16e-04). ETA=11:38:13, max mem: 20.9 GB 
[11/30 06:52:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.4699,	0.8267 s / batch. (data: 7.95e-03). ETA=11:43:07, max mem: 20.9 GB 
[11/30 06:54:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.6714,	1.2555 s / batch. (data: 4.28e-01). ETA=17:45:42, max mem: 20.9 GB 
[11/30 06:54:51][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 1.35e-01, avg batch time: 0.9696, average train loss: 1.7855
[11/30 06:55:46][INFO] visual_prompt:  316: Inference (val):avg data time: 1.51e-04, avg batch time: 0.3095, average loss: 1.4725
[11/30 06:55:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.95	
[11/30 06:55:46][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.8
[11/30 06:57:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.1074,	0.8231 s / batch. (data: 5.42e-03). ETA=11:36:35, max mem: 20.9 GB 
[11/30 06:59:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8484,	0.8802 s / batch. (data: 2.82e-02). ETA=12:23:26, max mem: 20.9 GB 
[11/30 07:00:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5530,	1.6147 s / batch. (data: 7.86e-01). ETA=22:41:02, max mem: 20.9 GB 
[11/30 07:02:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3158,	0.8349 s / batch. (data: 3.36e-04). ETA=11:42:24, max mem: 20.9 GB 
[11/30 07:03:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.6353,	0.8421 s / batch. (data: 1.40e-02). ETA=11:47:00, max mem: 20.9 GB 
[11/30 07:04:42][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 1.34e-01, avg batch time: 0.9681, average train loss: 2.0420
[11/30 07:05:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3107, average loss: 2.6569
[11/30 07:05:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.63	
[11/30 07:05:36][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.9
[11/30 07:07:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.6758,	0.8240 s / batch. (data: 3.32e-04). ETA=11:29:43, max mem: 20.9 GB 
[11/30 07:08:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.1651,	0.8327 s / batch. (data: 3.22e-04). ETA=11:35:35, max mem: 20.9 GB 
[11/30 07:10:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9748,	1.6458 s / batch. (data: 8.16e-01). ETA=22:52:08, max mem: 20.9 GB 
[11/30 07:12:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8070,	0.8360 s / batch. (data: 7.96e-03). ETA=11:35:35, max mem: 20.9 GB 
[11/30 07:13:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5712,	0.8320 s / batch. (data: 3.48e-04). ETA=11:30:53, max mem: 20.9 GB 
[11/30 07:14:32][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 1.33e-01, avg batch time: 0.9674, average train loss: 2.7223
[11/30 07:15:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3100, average loss: 0.9930
[11/30 07:15:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.69	
[11/30 07:15:27][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 1.0
[11/30 07:17:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3468,	0.8440 s / batch. (data: 2.91e-04). ETA=11:38:43, max mem: 20.9 GB 
[11/30 07:18:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 7.5440,	0.8248 s / batch. (data: 3.17e-04). ETA=11:21:27, max mem: 20.9 GB 
[11/30 07:20:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0002,	1.9760 s / batch. (data: 1.13e+00). ETA=1 day, 3:09:11, max mem: 20.9 GB 
[11/30 07:21:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.0701,	0.8593 s / batch. (data: 4.14e-04). ETA=11:47:04, max mem: 20.9 GB 
[11/30 07:23:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.2936,	0.8392 s / batch. (data: 3.14e-04). ETA=11:29:06, max mem: 20.9 GB 
[11/30 07:24:21][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 1.32e-01, avg batch time: 0.9659, average train loss: 2.7813
[11/30 07:25:15][INFO] visual_prompt:  316: Inference (val):avg data time: 6.93e-05, avg batch time: 0.3095, average loss: 0.7190
[11/30 07:25:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.25	
[11/30 07:25:15][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/30 07:26:57][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2974,	0.8271 s / batch. (data: 3.09e-04). ETA=11:17:06, max mem: 20.9 GB 
[11/30 07:28:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2570,	0.8551 s / batch. (data: 5.42e-03). ETA=11:38:33, max mem: 20.9 GB 
[11/30 07:30:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0898,	0.8600 s / batch. (data: 3.33e-04). ETA=11:41:07, max mem: 20.9 GB 
[11/30 07:31:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.4149,	0.8520 s / batch. (data: 1.20e-02). ETA=11:33:11, max mem: 20.9 GB 
[11/30 07:33:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8156,	0.8404 s / batch. (data: 7.67e-04). ETA=11:22:21, max mem: 20.9 GB 
[11/30 07:34:08][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.29e-01, avg batch time: 0.9633, average train loss: 2.2124
[11/30 07:35:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3111, average loss: 1.9518
[11/30 07:35:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 42.65	
[11/30 07:35:03][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/30 07:36:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.6673,	0.8440 s / batch. (data: 2.96e-04). ETA=11:23:07, max mem: 20.9 GB 
[11/30 07:38:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0907,	0.8560 s / batch. (data: 5.44e-03). ETA=11:31:24, max mem: 20.9 GB 
[11/30 07:39:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 11.3819,	1.3950 s / batch. (data: 5.76e-01). ETA=18:44:28, max mem: 20.9 GB 
[11/30 07:41:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8201,	0.8476 s / batch. (data: 2.27e-02). ETA=11:21:46, max mem: 20.9 GB 
[11/30 07:43:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.5766,	0.8196 s / batch. (data: 2.96e-04). ETA=10:57:56, max mem: 20.9 GB 
[11/30 07:43:54][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 1.25e-01, avg batch time: 0.9598, average train loss: 3.3906
[11/30 07:44:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.43e-05, avg batch time: 0.3100, average loss: 1.8345
[11/30 07:44:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 54.85	
[11/30 07:44:48][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/30 07:46:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4706,	0.8680 s / batch. (data: 5.90e-03). ETA=11:34:32, max mem: 20.9 GB 
[11/30 07:48:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0002,	0.8520 s / batch. (data: 3.20e-04). ETA=11:20:21, max mem: 20.9 GB 
[11/30 07:49:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9847,	0.8214 s / batch. (data: 3.39e-04). ETA=10:54:32, max mem: 20.9 GB 
[11/30 07:51:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6098,	0.8284 s / batch. (data: 3.34e-04). ETA=10:58:43, max mem: 20.9 GB 
[11/30 07:52:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8445,	0.8667 s / batch. (data: 1.55e-02). ETA=11:27:44, max mem: 20.9 GB 
[11/30 07:53:40][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 1.27e-01, avg batch time: 0.9614, average train loss: 2.9013
[11/30 07:54:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.3106, average loss: 2.6851
[11/30 07:54:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/30 07:54:34][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/30 07:56:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7502,	0.8473 s / batch. (data: 2.99e-04). ETA=11:10:10, max mem: 20.9 GB 
[11/30 07:57:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.2084,	0.8317 s / batch. (data: 3.21e-04). ETA=10:56:28, max mem: 20.9 GB 
[11/30 07:59:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.2141,	0.8330 s / batch. (data: 3.09e-04). ETA=10:56:03, max mem: 20.9 GB 
[11/30 08:01:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.9723,	1.2274 s / batch. (data: 3.92e-01). ETA=16:04:39, max mem: 20.9 GB 
[11/30 08:02:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5792,	1.1160 s / batch. (data: 2.60e-01). ETA=14:35:15, max mem: 20.9 GB 
[11/30 08:03:32][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.39e-01, avg batch time: 0.9724, average train loss: 2.8800
[11/30 08:04:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.49e-05, avg batch time: 0.3085, average loss: 1.1222
[11/30 08:04:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.96	
[11/30 08:04:26][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/30 08:06:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9188,	0.8185 s / batch. (data: 3.04e-04). ETA=10:39:52, max mem: 20.9 GB 
[11/30 08:07:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6138,	0.8425 s / batch. (data: 1.05e-02). ETA=10:57:13, max mem: 20.9 GB 
[11/30 08:09:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6054,	0.8671 s / batch. (data: 2.30e-02). ETA=11:14:59, max mem: 20.9 GB 
[11/30 08:10:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 11.0380,	0.8221 s / batch. (data: 3.26e-04). ETA=10:38:33, max mem: 20.9 GB 
[11/30 08:12:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0261,	1.0960 s / batch. (data: 2.55e-01). ETA=14:09:29, max mem: 20.9 GB 
[11/30 08:13:17][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 1.25e-01, avg batch time: 0.9596, average train loss: 3.0492
[11/30 08:14:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.43e-05, avg batch time: 0.3102, average loss: 1.8886
[11/30 08:14:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.51	
[11/30 08:14:12][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/30 08:15:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.0164,	0.8400 s / batch. (data: 3.01e-04). ETA=10:48:56, max mem: 20.9 GB 
[11/30 08:17:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7377,	0.8357 s / batch. (data: 5.43e-03). ETA=10:44:14, max mem: 20.9 GB 
[11/30 08:19:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.3622,	0.8278 s / batch. (data: 3.11e-04). ETA=10:36:45, max mem: 20.9 GB 
[11/30 08:20:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.6778,	1.0080 s / batch. (data: 1.66e-01). ETA=12:53:39, max mem: 20.9 GB 
[11/30 08:22:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.8617,	1.3228 s / batch. (data: 4.83e-01). ETA=16:53:06, max mem: 20.9 GB 
[11/30 08:23:07][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 1.34e-01, avg batch time: 0.9677, average train loss: 3.0789
[11/30 08:24:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.46e-05, avg batch time: 0.3098, average loss: 2.8243
[11/30 08:24:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.42	
[11/30 08:24:02][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/30 08:25:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.2617,	0.8259 s / batch. (data: 2.81e-04). ETA=10:30:25, max mem: 20.9 GB 
[11/30 08:27:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3063,	0.8284 s / batch. (data: 2.68e-04). ETA=10:30:59, max mem: 20.9 GB 
[11/30 08:28:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5358,	0.8495 s / batch. (data: 9.43e-03). ETA=10:45:35, max mem: 20.9 GB 
[11/30 08:30:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.9620,	0.8472 s / batch. (data: 5.43e-03). ETA=10:42:24, max mem: 20.9 GB 
[11/30 08:32:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2236,	1.4080 s / batch. (data: 5.85e-01). ETA=17:45:23, max mem: 20.9 GB 
[11/30 08:32:58][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 1.34e-01, avg batch time: 0.9687, average train loss: 3.1646
[11/30 08:33:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.3113, average loss: 2.9035
[11/30 08:33:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.02	
[11/30 08:33:53][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/30 08:35:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2002,	0.8396 s / batch. (data: 3.09e-04). ETA=10:33:06, max mem: 20.9 GB 
[11/30 08:37:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4388,	0.8280 s / batch. (data: 3.15e-04). ETA=10:23:01, max mem: 20.9 GB 
[11/30 08:38:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 12.4888,	0.8440 s / batch. (data: 1.20e-02). ETA=10:33:38, max mem: 20.9 GB 
[11/30 08:40:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.7336,	0.8384 s / batch. (data: 2.69e-04). ETA=10:28:00, max mem: 20.9 GB 
[11/30 08:41:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7673,	0.8440 s / batch. (data: 3.13e-04). ETA=10:30:49, max mem: 20.9 GB 
[11/30 08:42:45][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.29e-01, avg batch time: 0.9635, average train loss: 2.8470
[11/30 08:43:40][INFO] visual_prompt:  316: Inference (val):avg data time: 2.28e-04, avg batch time: 0.3121, average loss: 7.4800
[11/30 08:43:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.49	
[11/30 08:43:40][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/30 08:45:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.2764,	0.8360 s / batch. (data: 3.14e-04). ETA=10:22:42, max mem: 20.9 GB 
[11/30 08:46:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8867,	0.9250 s / batch. (data: 1.01e-01). ETA=11:27:26, max mem: 20.9 GB 
[11/30 08:48:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9475,	0.8674 s / batch. (data: 8.13e-04). ETA=10:43:13, max mem: 20.9 GB 
[11/30 08:50:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5581,	0.8600 s / batch. (data: 3.55e-04). ETA=10:36:17, max mem: 20.9 GB 
[11/30 08:51:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.0633,	0.8444 s / batch. (data: 3.01e-04). ETA=10:23:21, max mem: 20.9 GB 
[11/30 08:52:36][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 1.35e-01, avg batch time: 0.9689, average train loss: 2.7796
[11/30 08:53:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.53e-05, avg batch time: 0.3093, average loss: 0.8203
[11/30 08:53:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.48	
[11/30 08:53:31][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/30 08:55:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.5754,	0.8230 s / batch. (data: 3.45e-04). ETA=10:05:27, max mem: 20.9 GB 
[11/30 08:56:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.4108,	0.8379 s / batch. (data: 5.88e-04). ETA=10:14:59, max mem: 20.9 GB 
[11/30 08:58:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.5463,	1.1006 s / batch. (data: 2.62e-01). ETA=13:26:02, max mem: 20.9 GB 
[11/30 09:00:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.4283,	0.8320 s / batch. (data: 3.06e-04). ETA=10:07:54, max mem: 20.9 GB 
[11/30 09:01:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.6179,	0.8512 s / batch. (data: 1.17e-02). ETA=10:20:29, max mem: 20.9 GB 
[11/30 09:02:34][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 1.48e-01, avg batch time: 0.9814, average train loss: 2.9148
[11/30 09:03:29][INFO] visual_prompt:  316: Inference (val):avg data time: 2.09e-04, avg batch time: 0.3094, average loss: 15.3549
[11/30 09:03:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.30	
[11/30 09:03:29][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/30 09:05:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.5224,	0.8390 s / batch. (data: 2.78e-04). ETA=10:09:27, max mem: 20.9 GB 
[11/30 09:06:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 13.7409,	0.8482 s / batch. (data: 3.02e-04). ETA=10:14:47, max mem: 20.9 GB 
[11/30 09:08:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0334,	0.8350 s / batch. (data: 1.05e-02). ETA=10:03:50, max mem: 20.9 GB 
[11/30 09:09:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1310,	0.8280 s / batch. (data: 3.14e-04). ETA=9:57:20, max mem: 20.9 GB 
[11/30 09:11:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 22.3371,	0.8440 s / batch. (data: 1.06e-03). ETA=10:07:29, max mem: 20.9 GB 
[11/30 09:12:26][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 1.36e-01, avg batch time: 0.9703, average train loss: 3.2062
[11/30 09:13:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.39e-05, avg batch time: 0.3099, average loss: 4.0187
[11/30 09:13:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.98	
[11/30 09:13:20][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/30 09:15:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.3435,	0.8653 s / batch. (data: 2.58e-02). ETA=10:20:38, max mem: 20.9 GB 
[11/30 09:16:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8062,	0.8457 s / batch. (data: 5.45e-03). ETA=10:05:07, max mem: 20.9 GB 
[11/30 09:18:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5328,	0.8638 s / batch. (data: 5.58e-03). ETA=10:16:41, max mem: 20.9 GB 
[11/30 09:19:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.7154,	0.8360 s / batch. (data: 2.97e-04). ETA=9:55:25, max mem: 20.9 GB 
[11/30 09:21:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2378,	0.8674 s / batch. (data: 1.14e-02). ETA=10:16:20, max mem: 20.9 GB 
[11/30 09:22:16][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 1.34e-01, avg batch time: 0.9681, average train loss: 2.7538
[11/30 09:23:11][INFO] visual_prompt:  316: Inference (val):avg data time: 3.52e-05, avg batch time: 0.3097, average loss: 0.8995
[11/30 09:23:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.44	
[11/30 09:23:11][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/30 09:24:49][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7059,	0.8452 s / batch. (data: 1.06e-02). ETA=9:58:25, max mem: 20.9 GB 
[11/30 09:26:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.1721,	0.8560 s / batch. (data: 1.20e-02). ETA=10:04:38, max mem: 20.9 GB 
[11/30 09:28:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.1876,	0.8589 s / batch. (data: 7.03e-03). ETA=10:05:14, max mem: 20.9 GB 
[11/30 09:29:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9383,	0.8514 s / batch. (data: 1.13e-02). ETA=9:58:31, max mem: 20.9 GB 
[11/30 09:31:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6994,	0.8468 s / batch. (data: 3.36e-04). ETA=9:53:53, max mem: 20.9 GB 
[11/30 09:32:06][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 1.32e-01, avg batch time: 0.9677, average train loss: 2.7766
[11/30 09:33:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3101, average loss: 0.6933
[11/30 09:33:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 51.58	
[11/30 09:33:01][INFO] visual_prompt:   36: Best epoch 24: best metric: -0.693
[11/30 09:33:01][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/30 09:34:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9825,	0.8240 s / batch. (data: 3.15e-04). ETA=9:35:48, max mem: 20.9 GB 
[11/30 09:36:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.4278,	0.8567 s / batch. (data: 1.05e-02). ETA=9:57:15, max mem: 20.9 GB 
[11/30 09:37:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6883,	0.8520 s / batch. (data: 3.06e-04). ETA=9:52:30, max mem: 20.9 GB 
[11/30 09:39:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 10.6437,	0.8398 s / batch. (data: 3.37e-04). ETA=9:42:39, max mem: 20.9 GB 
[11/30 09:41:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9651,	1.0520 s / batch. (data: 1.90e-01). ETA=12:08:05, max mem: 20.9 GB 
[11/30 09:41:58][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 1.37e-01, avg batch time: 0.9715, average train loss: 2.5519
[11/30 09:42:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.11e-05, avg batch time: 0.3100, average loss: 13.9499
[11/30 09:42:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.81	
[11/30 09:42:53][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/30 09:44:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1473,	0.8400 s / batch. (data: 3.09e-04). ETA=9:39:14, max mem: 20.9 GB 
[11/30 09:46:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6540,	1.5680 s / batch. (data: 7.45e-01). ETA=17:58:38, max mem: 20.9 GB 
[11/30 09:47:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3755,	0.8500 s / batch. (data: 3.20e-04). ETA=9:43:16, max mem: 20.9 GB 
[11/30 09:49:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.4730,	0.8254 s / batch. (data: 2.90e-04). ETA=9:25:02, max mem: 20.9 GB 
[11/30 09:50:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6244,	0.8551 s / batch. (data: 4.18e-04). ETA=9:43:57, max mem: 20.9 GB 
[11/30 09:51:47][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 1.31e-01, avg batch time: 0.9658, average train loss: 2.1947
[11/30 09:52:42][INFO] visual_prompt:  316: Inference (val):avg data time: 1.52e-04, avg batch time: 0.3107, average loss: 3.6868
[11/30 09:52:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.12	
[11/30 09:52:42][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/30 09:54:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7660,	0.8524 s / batch. (data: 8.43e-03). ETA=9:39:58, max mem: 20.9 GB 
[11/30 09:55:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.8494,	1.0840 s / batch. (data: 2.43e-01). ETA=12:15:42, max mem: 20.9 GB 
[11/30 09:57:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.5061,	0.8440 s / batch. (data: 3.13e-04). ETA=9:31:25, max mem: 20.9 GB 
[11/30 09:59:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2970,	0.8185 s / batch. (data: 3.05e-04). ETA=9:12:46, max mem: 20.9 GB 
[11/30 10:00:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5721,	0.8471 s / batch. (data: 3.05e-04). ETA=9:30:42, max mem: 20.9 GB 
[11/30 10:01:37][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 1.33e-01, avg batch time: 0.9668, average train loss: 2.6540
[11/30 10:02:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.3126, average loss: 3.5891
[11/30 10:02:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.28	
[11/30 10:02:32][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/30 10:04:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0002,	1.5583 s / batch. (data: 7.22e-01). ETA=17:25:51, max mem: 20.9 GB 
[11/30 10:05:48][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6356,	0.8321 s / batch. (data: 3.32e-04). ETA=9:17:05, max mem: 20.9 GB 
[11/30 10:07:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6102,	1.3879 s / batch. (data: 5.62e-01). ETA=15:26:52, max mem: 20.9 GB 
[11/30 10:09:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.8450,	0.8788 s / batch. (data: 2.69e-02). ETA=9:45:25, max mem: 20.9 GB 
[11/30 10:10:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6316,	0.8675 s / batch. (data: 2.34e-02). ETA=9:36:25, max mem: 20.9 GB 
[11/30 10:11:26][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.33e-01, avg batch time: 0.9668, average train loss: 2.5020
[11/30 10:12:21][INFO] visual_prompt:  316: Inference (val):avg data time: 1.53e-04, avg batch time: 0.3100, average loss: 2.3042
[11/30 10:12:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/30 10:12:21][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/30 10:14:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3383,	0.8560 s / batch. (data: 2.88e-04). ETA=9:26:36, max mem: 20.9 GB 
[11/30 10:15:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6855,	1.5040 s / batch. (data: 6.74e-01). ETA=16:33:02, max mem: 20.9 GB 
[11/30 10:17:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6887,	0.8560 s / batch. (data: 7.82e-04). ETA=9:23:45, max mem: 20.9 GB 
[11/30 10:18:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.9906,	1.1760 s / batch. (data: 3.21e-01). ETA=12:52:32, max mem: 20.9 GB 
[11/30 10:20:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.3491,	0.8280 s / batch. (data: 5.42e-03). ETA=9:02:33, max mem: 20.9 GB 
[11/30 10:21:16][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 1.32e-01, avg batch time: 0.9673, average train loss: 2.7083
[11/30 10:22:11][INFO] visual_prompt:  316: Inference (val):avg data time: 3.52e-05, avg batch time: 0.3096, average loss: 2.2601
[11/30 10:22:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.89	
[11/30 10:22:11][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/30 10:23:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3582,	0.8422 s / batch. (data: 1.19e-02). ETA=9:09:43, max mem: 20.9 GB 
[11/30 10:25:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6117,	0.8187 s / batch. (data: 3.29e-04). ETA=8:53:01, max mem: 20.9 GB 
[11/30 10:27:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0323,	1.4880 s / batch. (data: 6.60e-01). ETA=16:06:16, max mem: 20.9 GB 
[11/30 10:28:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7059,	0.9840 s / batch. (data: 1.52e-01). ETA=10:37:21, max mem: 20.9 GB 
[11/30 10:30:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.8829,	1.2883 s / batch. (data: 4.71e-01). ETA=13:52:19, max mem: 20.9 GB 
[11/30 10:31:07][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 1.35e-01, avg batch time: 0.9690, average train loss: 2.6531
[11/30 10:32:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-05, avg batch time: 0.3116, average loss: 2.0257
[11/30 10:32:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.52	
[11/30 10:32:02][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/30 10:33:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9641,	0.8583 s / batch. (data: 7.94e-03). ETA=9:12:18, max mem: 20.9 GB 
[11/30 10:35:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.9513,	0.8409 s / batch. (data: 8.65e-03). ETA=8:59:41, max mem: 20.9 GB 
[11/30 10:36:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 10.7418,	0.8526 s / batch. (data: 7.96e-03). ETA=9:05:47, max mem: 20.9 GB 
[11/30 10:38:28][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.2864,	0.8720 s / batch. (data: 3.03e-02). ETA=9:16:45, max mem: 20.9 GB 
[11/30 10:40:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9899,	0.8668 s / batch. (data: 2.71e-02). ETA=9:11:59, max mem: 20.9 GB 
[11/30 10:40:52][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 1.23e-01, avg batch time: 0.9581, average train loss: 2.2740
[11/30 10:41:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.36e-05, avg batch time: 0.3095, average loss: 0.7490
[11/30 10:41:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.76	
[11/30 10:41:46][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/30 10:43:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6049,	0.8464 s / batch. (data: 8.66e-04). ETA=8:56:50, max mem: 20.9 GB 
[11/30 10:45:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5663,	0.8760 s / batch. (data: 1.05e-02). ETA=9:14:09, max mem: 20.9 GB 
[11/30 10:46:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 7.0590,	1.6837 s / batch. (data: 8.51e-01). ETA=17:42:19, max mem: 20.9 GB 
[11/30 10:48:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7622,	0.8323 s / batch. (data: 3.01e-04). ETA=8:43:45, max mem: 20.9 GB 
[11/30 10:49:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6783,	0.8440 s / batch. (data: 7.94e-03). ETA=8:49:42, max mem: 20.9 GB 
[11/30 10:50:39][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 1.28e-01, avg batch time: 0.9626, average train loss: 2.2939
[11/30 10:51:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3120, average loss: 2.3057
[11/30 10:51:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.82	
[11/30 10:51:33][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/30 10:53:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0002,	1.1720 s / batch. (data: 3.24e-01). ETA=12:12:34, max mem: 20.9 GB 
[11/30 10:54:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.4458,	0.8360 s / batch. (data: 3.23e-04). ETA=8:41:10, max mem: 20.9 GB 
[11/30 10:56:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7954,	0.8212 s / batch. (data: 2.95e-04). ETA=8:30:35, max mem: 20.9 GB 
[11/30 10:58:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3548,	0.8640 s / batch. (data: 2.80e-04). ETA=8:55:44, max mem: 20.9 GB 
[11/30 10:59:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6328,	0.8434 s / batch. (data: 5.43e-03). ETA=8:41:31, max mem: 20.9 GB 
[11/30 11:00:24][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 1.25e-01, avg batch time: 0.9591, average train loss: 2.1522
[11/30 11:01:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3090, average loss: 0.6910
[11/30 11:01:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.83	
[11/30 11:01:18][INFO] visual_prompt:   36: Best epoch 33: best metric: -0.691
[11/30 11:01:18][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/30 11:02:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7138,	0.8363 s / batch. (data: 7.95e-03). ETA=8:35:02, max mem: 20.9 GB 
[11/30 11:04:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.4925,	0.8193 s / batch. (data: 3.55e-04). ETA=8:23:10, max mem: 20.9 GB 
[11/30 11:06:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.9661,	1.3043 s / batch. (data: 4.83e-01). ETA=13:18:54, max mem: 20.9 GB 
[11/30 11:08:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.7802,	0.8469 s / batch. (data: 2.30e-03). ETA=8:37:18, max mem: 20.9 GB 
[11/30 11:10:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8462,	2.4895 s / batch. (data: 1.65e+00). ETA=1 day, 1:16:32, max mem: 20.9 GB 
[11/30 11:11:40][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 2.88e-01, avg batch time: 1.1245, average train loss: 2.6615
[11/30 11:12:54][INFO] visual_prompt:  316: Inference (val):avg data time: 2.96e-04, avg batch time: 0.3118, average loss: 1.1740
[11/30 11:12:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.93	
[11/30 11:12:54][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/30 11:15:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.9830,	1.2366 s / batch. (data: 4.00e-01). ETA=12:30:09, max mem: 20.9 GB 
[11/30 11:17:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6856,	1.0155 s / batch. (data: 1.90e-01). ETA=10:14:21, max mem: 20.9 GB 
[11/30 11:19:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.6449,	0.8323 s / batch. (data: 8.61e-04). ETA=8:22:08, max mem: 20.9 GB 
[11/30 11:21:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6149,	1.1601 s / batch. (data: 3.18e-01). ETA=11:37:55, max mem: 20.9 GB 
[11/30 11:23:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6931,	0.9701 s / batch. (data: 1.45e-01). ETA=9:42:03, max mem: 20.9 GB 
[11/30 11:24:22][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 4.07e-01, avg batch time: 1.2440, average train loss: 1.8298
[11/30 11:25:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-04, avg batch time: 0.3124, average loss: 1.8427
[11/30 11:25:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.98	
[11/30 11:25:34][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/30 11:27:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1378,	1.1524 s / batch. (data: 3.00e-01). ETA=11:28:26, max mem: 20.9 GB 
[11/30 11:29:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.7021,	0.8548 s / batch. (data: 1.09e-02). ETA=8:29:13, max mem: 20.9 GB 
[11/30 11:31:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.7361,	0.8200 s / batch. (data: 5.56e-03). ETA=8:07:09, max mem: 20.9 GB 
[11/30 11:33:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.4654,	0.8554 s / batch. (data: 1.44e-03). ETA=8:26:46, max mem: 20.9 GB 
[11/30 11:35:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5981,	1.1895 s / batch. (data: 3.41e-01). ETA=11:42:41, max mem: 20.9 GB 
[11/30 11:36:36][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 3.60e-01, avg batch time: 1.1964, average train loss: 2.2093
[11/30 11:37:42][INFO] visual_prompt:  316: Inference (val):avg data time: 1.74e-04, avg batch time: 0.3116, average loss: 5.9647
[11/30 11:37:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.15	
[11/30 11:37:42][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/30 11:39:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.6822,	0.8322 s / batch. (data: 1.00e-03). ETA=8:09:28, max mem: 20.9 GB 
[11/30 11:41:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6890,	0.8467 s / batch. (data: 6.09e-03). ETA=8:16:37, max mem: 20.9 GB 
[11/30 11:43:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9766,	1.9240 s / batch. (data: 1.10e+00). ETA=18:45:17, max mem: 20.9 GB 
[11/30 11:45:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1788,	2.6643 s / batch. (data: 1.85e+00). ETA=1 day, 1:53:49, max mem: 20.9 GB 
[11/30 11:47:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.2658,	1.0203 s / batch. (data: 1.87e-01). ETA=9:53:21, max mem: 20.9 GB 
[11/30 11:48:16][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 3.11e-01, avg batch time: 1.1450, average train loss: 2.0978
[11/30 11:49:28][INFO] visual_prompt:  316: Inference (val):avg data time: 2.94e-04, avg batch time: 0.3086, average loss: 1.5988
[11/30 11:49:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.77	
[11/30 11:49:28][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/30 11:51:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8851,	0.8224 s / batch. (data: 7.97e-03). ETA=7:56:08, max mem: 20.9 GB 
[11/30 11:53:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.0352,	2.0360 s / batch. (data: 1.19e+00). ETA=19:35:25, max mem: 20.9 GB 
[11/30 11:55:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5409,	0.8177 s / batch. (data: 3.30e-04). ETA=7:50:43, max mem: 20.9 GB 
[11/30 11:57:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6111,	1.8197 s / batch. (data: 9.98e-01). ETA=17:24:27, max mem: 20.9 GB 
[11/30 11:59:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 22.3139,	2.2395 s / batch. (data: 1.41e+00). ETA=21:21:41, max mem: 20.9 GB 
[11/30 12:00:36][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 3.70e-01, avg batch time: 1.2065, average train loss: 2.1677
[11/30 12:01:46][INFO] visual_prompt:  316: Inference (val):avg data time: 8.57e-05, avg batch time: 0.3118, average loss: 4.7694
[11/30 12:01:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.79	
[11/30 12:01:46][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/30 12:03:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0604,	0.8209 s / batch. (data: 5.99e-03). ETA=7:47:43, max mem: 20.9 GB 
[11/30 12:05:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6759,	0.8320 s / batch. (data: 8.93e-04). ETA=7:52:39, max mem: 20.9 GB 
[11/30 12:07:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.5685,	0.8589 s / batch. (data: 1.14e-02). ETA=8:06:29, max mem: 20.9 GB 
[11/30 12:09:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.7708,	0.8301 s / batch. (data: 2.82e-04). ETA=7:48:50, max mem: 20.9 GB 
[11/30 12:11:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4081,	2.4674 s / batch. (data: 1.64e+00). ETA=23:09:22, max mem: 20.9 GB 
[11/30 12:12:32][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 3.33e-01, avg batch time: 1.1677, average train loss: 1.9088
[11/30 12:13:39][INFO] visual_prompt:  316: Inference (val):avg data time: 1.90e-04, avg batch time: 0.3104, average loss: 0.8640
[11/30 12:13:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/30 12:13:39][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/30 12:15:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.1731,	0.8488 s / batch. (data: 2.45e-02). ETA=7:55:49, max mem: 20.9 GB 
[11/30 12:17:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3754,	0.9111 s / batch. (data: 2.23e-02). ETA=8:29:11, max mem: 20.9 GB 
[11/30 12:19:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.2486,	0.8582 s / batch. (data: 3.43e-04). ETA=7:58:11, max mem: 20.9 GB 
[11/30 12:21:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7807,	0.8333 s / batch. (data: 2.57e-03). ETA=7:42:54, max mem: 20.9 GB 
[11/30 12:23:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.5303,	0.8260 s / batch. (data: 3.10e-04). ETA=7:37:31, max mem: 20.9 GB 
[11/30 12:24:17][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 3.20e-01, avg batch time: 1.1535, average train loss: 2.1051
[11/30 12:25:23][INFO] visual_prompt:  316: Inference (val):avg data time: 6.50e-05, avg batch time: 0.3091, average loss: 0.8930
[11/30 12:25:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.54	
[11/30 12:25:23][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.75
[11/30 12:27:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6960,	0.8425 s / batch. (data: 1.05e-02). ETA=7:44:29, max mem: 20.9 GB 
[11/30 12:29:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1739,	0.8401 s / batch. (data: 7.86e-04). ETA=7:41:48, max mem: 20.9 GB 
[11/30 12:31:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.3497,	0.8556 s / batch. (data: 1.10e-02). ETA=7:48:52, max mem: 20.9 GB 
[11/30 12:33:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9638,	0.8402 s / batch. (data: 2.91e-04). ETA=7:39:02, max mem: 20.9 GB 
[11/30 12:35:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.8615,	0.8485 s / batch. (data: 7.75e-04). ETA=7:42:10, max mem: 20.9 GB 
[11/30 12:36:03][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 3.22e-01, avg batch time: 1.1565, average train loss: 1.9298
[11/30 12:37:09][INFO] visual_prompt:  316: Inference (val):avg data time: 5.44e-05, avg batch time: 0.3083, average loss: 1.0720
[11/30 12:37:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 55.11	
[11/30 12:37:09][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/30 12:39:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.6607,	0.8232 s / batch. (data: 7.20e-03). ETA=7:26:17, max mem: 20.9 GB 
[11/30 12:40:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.9794,	0.8908 s / batch. (data: 6.20e-02). ETA=8:01:26, max mem: 20.9 GB 
[11/30 12:42:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8868,	0.8293 s / batch. (data: 4.21e-04). ETA=7:26:49, max mem: 20.9 GB 
[11/30 12:44:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9817,	0.8479 s / batch. (data: 3.39e-04). ETA=7:35:26, max mem: 20.9 GB 
[11/30 12:46:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.0830,	0.8284 s / batch. (data: 3.40e-04). ETA=7:23:34, max mem: 20.9 GB 
[11/30 12:47:42][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 3.11e-01, avg batch time: 1.1445, average train loss: 2.3765
[11/30 12:48:49][INFO] visual_prompt:  316: Inference (val):avg data time: 6.40e-05, avg batch time: 0.3111, average loss: 2.6654
[11/30 12:48:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.41	
[11/30 12:48:49][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/30 12:50:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6919,	0.8449 s / batch. (data: 5.64e-03). ETA=7:30:14, max mem: 20.9 GB 
[11/30 12:52:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.3715,	0.8310 s / batch. (data: 3.70e-04). ETA=7:21:27, max mem: 20.9 GB 
[11/30 12:54:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.3153,	0.8385 s / batch. (data: 7.03e-03). ETA=7:24:03, max mem: 20.9 GB 
[11/30 12:56:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5495,	0.8400 s / batch. (data: 3.23e-04). ETA=7:23:25, max mem: 20.9 GB 
[11/30 12:58:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.3719,	0.8875 s / batch. (data: 3.82e-03). ETA=7:47:03, max mem: 20.9 GB 
[11/30 12:59:36][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 3.34e-01, avg batch time: 1.1696, average train loss: 2.1711
[11/30 13:00:46][INFO] visual_prompt:  316: Inference (val):avg data time: 8.96e-05, avg batch time: 0.3108, average loss: 1.0611
[11/30 13:00:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.77	
[11/30 13:00:46][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/30 13:02:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6536,	1.2363 s / batch. (data: 4.05e-01). ETA=10:47:25, max mem: 20.9 GB 
[11/30 13:04:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2334,	0.8401 s / batch. (data: 1.30e-03). ETA=7:18:32, max mem: 20.9 GB 
[11/30 13:06:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8066,	0.8611 s / batch. (data: 5.45e-03). ETA=7:28:04, max mem: 20.9 GB 
[11/30 13:08:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1292,	0.8636 s / batch. (data: 2.60e-02). ETA=7:27:55, max mem: 20.9 GB 
[11/30 13:10:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.5931,	0.9390 s / batch. (data: 1.15e-01). ETA=8:05:28, max mem: 20.9 GB 
[11/30 13:11:41][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 3.47e-01, avg batch time: 1.1836, average train loss: 2.0941
[11/30 13:12:47][INFO] visual_prompt:  316: Inference (val):avg data time: 6.65e-05, avg batch time: 0.3081, average loss: 3.0344
[11/30 13:12:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.45	
[11/30 13:12:47][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/30 13:14:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.6431,	0.8623 s / batch. (data: 8.47e-04). ETA=7:23:37, max mem: 20.9 GB 
[11/30 13:16:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6821,	0.8483 s / batch. (data: 1.20e-02). ETA=7:15:01, max mem: 20.9 GB 
[11/30 13:18:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.4774,	0.8551 s / batch. (data: 5.46e-03). ETA=7:17:03, max mem: 20.9 GB 
[11/30 13:20:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.2171,	0.8295 s / batch. (data: 7.83e-03). ETA=7:02:35, max mem: 20.9 GB 
[11/30 13:22:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6980,	0.8160 s / batch. (data: 3.47e-04). ETA=6:54:20, max mem: 20.9 GB 
[11/30 13:23:21][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 3.13e-01, avg batch time: 1.1469, average train loss: 1.9767
[11/30 13:24:29][INFO] visual_prompt:  316: Inference (val):avg data time: 7.75e-05, avg batch time: 0.3104, average loss: 1.0924
[11/30 13:24:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.41	
[11/30 13:24:29][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/30 13:26:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.2458,	1.6893 s / batch. (data: 8.30e-01). ETA=14:13:30, max mem: 20.9 GB 
[11/30 13:28:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2857,	0.8418 s / batch. (data: 1.94e-03). ETA=7:03:55, max mem: 20.9 GB 
[11/30 13:30:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5727,	0.8294 s / batch. (data: 1.16e-02). ETA=6:56:17, max mem: 20.9 GB 
[11/30 13:32:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7820,	0.8441 s / batch. (data: 6.45e-03). ETA=7:02:14, max mem: 20.9 GB 
[11/30 13:34:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.5864,	0.8185 s / batch. (data: 1.36e-03). ETA=6:48:05, max mem: 20.9 GB 
[11/30 13:35:08][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 3.21e-01, avg batch time: 1.1549, average train loss: 1.7843
[11/30 13:36:16][INFO] visual_prompt:  316: Inference (val):avg data time: 7.21e-05, avg batch time: 0.3093, average loss: 1.3203
[11/30 13:36:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.42	
[11/30 13:36:16][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/30 13:38:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.5818,	0.8549 s / batch. (data: 3.41e-02). ETA=7:04:04, max mem: 20.9 GB 
[11/30 13:40:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7208,	1.6160 s / batch. (data: 7.46e-01). ETA=13:18:54, max mem: 20.9 GB 
[11/30 13:42:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.1863,	0.8415 s / batch. (data: 8.52e-04). ETA=6:54:37, max mem: 20.9 GB 
[11/30 13:44:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4958,	0.8683 s / batch. (data: 6.61e-03). ETA=7:06:23, max mem: 20.9 GB 
[11/30 13:46:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8249,	0.8336 s / batch. (data: 5.60e-03). ETA=6:47:55, max mem: 20.9 GB 
[11/30 13:47:15][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 3.56e-01, avg batch time: 1.1918, average train loss: 2.1250
[11/30 13:48:28][INFO] visual_prompt:  316: Inference (val):avg data time: 2.40e-04, avg batch time: 0.3119, average loss: 0.7435
[11/30 13:48:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.28	
[11/30 13:48:28][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/30 13:50:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9621,	0.8442 s / batch. (data: 7.69e-04). ETA=6:50:57, max mem: 20.9 GB 
[11/30 13:52:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7486,	0.8718 s / batch. (data: 1.18e-02). ETA=7:02:56, max mem: 20.9 GB 
[11/30 13:54:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.1024,	2.7479 s / batch. (data: 1.93e+00). ETA=22:08:32, max mem: 20.9 GB 
[11/30 13:56:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3197,	1.0652 s / batch. (data: 2.39e-01). ETA=8:33:14, max mem: 20.9 GB 
[11/30 13:58:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.1887,	0.8274 s / batch. (data: 1.17e-03). ETA=6:37:17, max mem: 20.9 GB 
[11/30 13:59:41][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 3.79e-01, avg batch time: 1.2176, average train loss: 1.6458
[11/30 14:00:51][INFO] visual_prompt:  316: Inference (val):avg data time: 8.50e-05, avg batch time: 0.3115, average loss: 3.0819
[11/30 14:00:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.79	
[11/30 14:00:51][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/30 14:03:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1156,	0.8559 s / batch. (data: 3.14e-03). ETA=6:48:46, max mem: 20.9 GB 
[11/30 14:04:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.1905,	0.8601 s / batch. (data: 6.28e-03). ETA=6:49:19, max mem: 20.9 GB 
[11/30 14:07:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.1327,	1.0960 s / batch. (data: 2.73e-01). ETA=8:39:47, max mem: 20.9 GB 
[11/30 14:09:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0822,	0.8260 s / batch. (data: 1.14e-03). ETA=6:30:21, max mem: 20.9 GB 
[11/30 14:11:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9880,	0.8781 s / batch. (data: 2.38e-02). ETA=6:53:31, max mem: 20.9 GB 
[11/30 14:12:08][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 3.86e-01, avg batch time: 1.2247, average train loss: 1.7943
[11/30 14:13:22][INFO] visual_prompt:  316: Inference (val):avg data time: 4.56e-04, avg batch time: 0.3168, average loss: 1.5640
[11/30 14:13:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.78	
[11/30 14:13:22][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/30 14:15:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3883,	0.8360 s / batch. (data: 3.23e-04). ETA=6:31:34, max mem: 20.9 GB 
[11/30 14:17:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.9734,	0.8917 s / batch. (data: 2.37e-02). ETA=6:56:11, max mem: 20.9 GB 
[11/30 14:19:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7607,	0.8585 s / batch. (data: 2.55e-03). ETA=6:39:13, max mem: 20.9 GB 
[11/30 14:21:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0439,	0.8805 s / batch. (data: 1.50e-03). ETA=6:47:59, max mem: 20.9 GB 
[11/30 14:23:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.9308,	0.8459 s / batch. (data: 1.48e-03). ETA=6:30:33, max mem: 20.9 GB 
[11/30 14:24:37][INFO] visual_prompt:  217: Epoch 50 / 100: avg data time: 3.80e-01, avg batch time: 1.2209, average train loss: 1.6563
[11/30 14:25:46][INFO] visual_prompt:  316: Inference (val):avg data time: 6.36e-05, avg batch time: 0.3119, average loss: 2.6452
[11/30 14:25:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.17	
[11/30 14:25:46][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/30 14:27:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0896,	1.8958 s / batch. (data: 1.05e+00). ETA=14:30:29, max mem: 20.9 GB 
[11/30 14:29:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.8811,	0.8469 s / batch. (data: 6.11e-03). ETA=6:27:28, max mem: 20.9 GB 
[11/30 14:31:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1684,	0.8306 s / batch. (data: 1.09e-03). ETA=6:18:37, max mem: 20.9 GB 
[11/30 14:33:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5511,	2.3760 s / batch. (data: 1.54e+00). ETA=17:59:05, max mem: 20.9 GB 
[11/30 14:35:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8281,	0.8543 s / batch. (data: 9.04e-04). ETA=6:26:35, max mem: 20.9 GB 
[11/30 14:36:51][INFO] visual_prompt:  217: Epoch 51 / 100: avg data time: 3.64e-01, avg batch time: 1.2030, average train loss: 1.4512
[11/30 14:38:01][INFO] visual_prompt:  316: Inference (val):avg data time: 8.32e-05, avg batch time: 0.3098, average loss: 1.2400
[11/30 14:38:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.66	
[11/30 14:38:01][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/30 14:40:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.5407,	0.8637 s / batch. (data: 1.12e-02). ETA=6:28:37, max mem: 20.9 GB 
[11/30 14:42:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2539,	0.8539 s / batch. (data: 3.59e-04). ETA=6:22:48, max mem: 20.9 GB 
[11/30 14:44:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.7346,	0.8639 s / batch. (data: 1.18e-02). ETA=6:25:49, max mem: 20.9 GB 
[11/30 14:46:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0008,	0.8504 s / batch. (data: 2.28e-02). ETA=6:18:23, max mem: 20.9 GB 
[11/30 14:48:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.5077,	0.8566 s / batch. (data: 3.47e-04). ETA=6:19:42, max mem: 20.9 GB 
[11/30 14:49:00][INFO] visual_prompt:  217: Epoch 52 / 100: avg data time: 3.53e-01, avg batch time: 1.1906, average train loss: 1.8658
[11/30 14:50:06][INFO] visual_prompt:  316: Inference (val):avg data time: 6.83e-05, avg batch time: 0.3115, average loss: 5.0050
[11/30 14:50:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.26	
[11/30 14:50:06][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/30 14:52:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7898,	0.8328 s / batch. (data: 1.01e-02). ETA=6:07:01, max mem: 20.9 GB 
[11/30 14:53:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.5885,	0.8384 s / batch. (data: 5.49e-03). ETA=6:08:06, max mem: 20.9 GB 
[11/30 14:55:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.4154,	0.8519 s / batch. (data: 1.22e-03). ETA=6:12:36, max mem: 20.9 GB 
[11/30 14:57:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0066,	1.2679 s / batch. (data: 4.33e-01). ETA=9:12:28, max mem: 20.9 GB 
[11/30 14:59:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.0576,	0.8730 s / batch. (data: 1.29e-02). ETA=6:18:55, max mem: 20.9 GB 
[11/30 15:00:40][INFO] visual_prompt:  217: Epoch 53 / 100: avg data time: 3.13e-01, avg batch time: 1.1464, average train loss: 1.5731
[11/30 15:01:48][INFO] visual_prompt:  316: Inference (val):avg data time: 2.54e-04, avg batch time: 0.3101, average loss: 5.4345
[11/30 15:01:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.49	
[11/30 15:01:48][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/30 15:03:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1204,	0.8405 s / batch. (data: 1.28e-03). ETA=6:02:40, max mem: 20.9 GB 
[11/30 15:05:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6302,	0.8726 s / batch. (data: 4.12e-02). ETA=6:15:04, max mem: 20.9 GB 
[11/30 15:07:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.3439,	1.2163 s / batch. (data: 3.86e-01). ETA=8:40:47, max mem: 20.9 GB 
[11/30 15:09:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.6110,	0.8314 s / batch. (data: 7.87e-04). ETA=5:54:37, max mem: 20.9 GB 
[11/30 15:11:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5944,	0.8380 s / batch. (data: 3.17e-04). ETA=5:56:00, max mem: 20.9 GB 
[11/30 15:12:26][INFO] visual_prompt:  217: Epoch 54 / 100: avg data time: 3.20e-01, avg batch time: 1.1547, average train loss: 1.5220
[11/30 15:13:34][INFO] visual_prompt:  316: Inference (val):avg data time: 5.95e-04, avg batch time: 0.3109, average loss: 3.7185
[11/30 15:13:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.83	
[11/30 15:13:34][INFO] visual_prompt:   42: Stopping early.
