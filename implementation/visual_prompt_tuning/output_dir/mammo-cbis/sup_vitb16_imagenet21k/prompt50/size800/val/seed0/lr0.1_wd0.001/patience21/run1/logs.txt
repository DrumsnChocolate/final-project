[12/05 14:34:17][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[12/05 14:34:17][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/05 14:34:17][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/05 14:34:17][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/05 14:34:17][INFO] visual_prompt:  108: Training with config:
[12/05 14:34:17][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr0.1_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/05 14:34:17][INFO] visual_prompt:   70: Loading training data...
[12/05 14:34:17][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[12/05 14:34:17][INFO] visual_prompt:   72: Loading validation data...
[12/05 14:34:17][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[12/05 14:34:17][INFO] visual_prompt:   36: Constructing models...
[12/05 14:34:21][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[12/05 14:34:21][INFO] visual_prompt:   54: tuned percent:0.525
[12/05 14:34:21][INFO] visual_prompt:   40: Device used for model: 0
[12/05 14:34:21][INFO] visual_prompt:   38: Setting up Evaluator...
[12/05 14:34:21][INFO] visual_prompt:   40: Setting up Trainer...
[12/05 14:34:21][INFO] visual_prompt:   45: 	Setting up the optimizer...
[12/05 14:34:21][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[12/05 14:36:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8633 s / batch. (data: 2.12e-02). ETA=13:14:16, max mem: 20.9 GB 
[12/05 14:38:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8614 s / batch. (data: 1.05e-02). ETA=13:11:02, max mem: 20.9 GB 
[12/05 14:40:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	3.5567 s / batch. (data: 2.73e+00). ETA=2 days, 6:20:21, max mem: 20.9 GB 
[12/05 14:42:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8517 s / batch. (data: 1.53e-03). ETA=12:59:20, max mem: 20.9 GB 
[12/05 14:44:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8421 s / batch. (data: 3.11e-04). ETA=12:49:08, max mem: 20.9 GB 
[12/05 14:45:54][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 4.16e-01, avg batch time: 1.2526, average train loss: 1.5403
[12/05 14:47:07][INFO] visual_prompt:  316: Inference (val):avg data time: 1.01e-04, avg batch time: 0.3114, average loss: 1.5201
[12/05 14:47:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[12/05 14:47:07][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/05 14:49:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6279,	0.8324 s / batch. (data: 8.70e-04). ETA=12:38:08, max mem: 20.9 GB 
[12/05 14:51:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2577,	0.8322 s / batch. (data: 3.40e-04). ETA=12:36:34, max mem: 20.9 GB 
[12/05 14:53:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7430,	1.6577 s / batch. (data: 8.16e-01). ETA=1 day, 1:04:18, max mem: 20.9 GB 
[12/05 14:55:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9585,	0.8461 s / batch. (data: 6.14e-03). ETA=12:46:23, max mem: 20.9 GB 
[12/05 14:57:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6860,	0.8623 s / batch. (data: 1.20e-02). ETA=12:59:34, max mem: 20.9 GB 
[12/05 14:58:18][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.76e-01, avg batch time: 1.2123, average train loss: 0.7769
[12/05 14:59:31][INFO] visual_prompt:  316: Inference (val):avg data time: 1.19e-04, avg batch time: 0.3131, average loss: 0.7374
[12/05 14:59:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.00	
[12/05 14:59:31][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/05 15:01:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7862,	0.8280 s / batch. (data: 3.35e-04). ETA=12:26:29, max mem: 20.9 GB 
[12/05 15:03:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7773,	0.8477 s / batch. (data: 1.05e-02). ETA=12:42:53, max mem: 20.9 GB 
[12/05 15:05:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7054,	0.8318 s / batch. (data: 1.36e-02). ETA=12:27:06, max mem: 20.9 GB 
[12/05 15:07:37][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5651,	0.8394 s / batch. (data: 1.25e-02). ETA=12:32:36, max mem: 20.9 GB 
[12/05 15:09:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7718,	2.2280 s / batch. (data: 1.40e+00). ETA=1 day, 9:13:50, max mem: 20.9 GB 
[12/05 15:10:44][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 3.79e-01, avg batch time: 1.2147, average train loss: 0.7468
[12/05 15:11:57][INFO] visual_prompt:  316: Inference (val):avg data time: 1.14e-04, avg batch time: 0.3116, average loss: 0.7184
[12/05 15:11:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.24	
[12/05 15:11:57][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.03
[12/05 15:14:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6853,	0.8656 s / batch. (data: 8.96e-04). ETA=12:52:22, max mem: 20.9 GB 
[12/05 15:16:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8473,	0.8498 s / batch. (data: 1.24e-03). ETA=12:36:53, max mem: 20.9 GB 
[12/05 15:18:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5468,	2.1062 s / batch. (data: 1.28e+00). ETA=1 day, 7:12:27, max mem: 20.9 GB 
[12/05 15:20:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6213,	1.6400 s / batch. (data: 8.09e-01). ETA=1 day, 0:15:17, max mem: 20.9 GB 
[12/05 15:22:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7584,	4.5403 s / batch. (data: 3.72e+00). ETA=2 days, 19:01:17, max mem: 20.9 GB 
[12/05 15:23:28][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.11e-01, avg batch time: 1.2479, average train loss: 0.7848
[12/05 15:24:44][INFO] visual_prompt:  316: Inference (val):avg data time: 1.07e-04, avg batch time: 0.3125, average loss: 0.6919
[12/05 15:24:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[12/05 15:24:44][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/05 15:26:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4628,	0.8451 s / batch. (data: 2.05e-02). ETA=12:26:19, max mem: 20.9 GB 
[12/05 15:28:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8532,	2.1877 s / batch. (data: 1.34e+00). ETA=1 day, 8:08:24, max mem: 20.9 GB 
[12/05 15:31:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9400,	0.8633 s / batch. (data: 6.71e-03). ETA=12:39:32, max mem: 20.9 GB 
[12/05 15:33:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7033,	0.8148 s / batch. (data: 3.38e-04). ETA=11:55:28, max mem: 20.9 GB 
[12/05 15:35:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6027,	0.8395 s / batch. (data: 1.33e-03). ETA=12:15:47, max mem: 20.9 GB 
[12/05 15:36:09][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 4.04e-01, avg batch time: 1.2391, average train loss: 0.8043
[12/05 15:37:22][INFO] visual_prompt:  316: Inference (val):avg data time: 9.62e-05, avg batch time: 0.3130, average loss: 0.7580
[12/05 15:37:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.73	
[12/05 15:37:22][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.05
[12/05 15:39:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5946,	0.8473 s / batch. (data: 3.64e-03). ETA=12:20:25, max mem: 20.9 GB 
[12/05 15:41:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6098,	0.8627 s / batch. (data: 1.07e-02). ETA=12:32:29, max mem: 20.9 GB 
[12/05 15:43:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5594,	0.8405 s / batch. (data: 2.99e-04). ETA=12:11:43, max mem: 20.9 GB 
[12/05 15:45:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5339,	0.8341 s / batch. (data: 3.90e-04). ETA=12:04:48, max mem: 20.9 GB 
[12/05 15:47:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7692,	0.8426 s / batch. (data: 3.59e-04). ETA=12:10:43, max mem: 20.9 GB 
[12/05 15:48:06][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 3.28e-01, avg batch time: 1.1643, average train loss: 0.7513
[12/05 15:49:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.55e-05, avg batch time: 0.3058, average loss: 0.6778
[12/05 15:49:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.26	
[12/05 15:49:55][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.06
[12/05 15:53:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5749,	0.8079 s / batch. (data: 4.36e-04). ETA=11:38:35, max mem: 20.9 GB 
[12/05 15:56:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5493,	3.5252 s / batch. (data: 2.70e+00). ETA=2 days, 2:42:21, max mem: 20.9 GB 
[12/05 15:59:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7380,	0.9479 s / batch. (data: 1.29e-01). ETA=13:36:29, max mem: 20.9 GB 
[12/05 16:02:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5772,	4.2653 s / batch. (data: 3.45e+00). ETA=2 days, 13:06:55, max mem: 20.9 GB 
[12/05 16:04:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9787,	0.8239 s / batch. (data: 9.63e-04). ETA=11:46:58, max mem: 20.9 GB 
[12/05 16:06:35][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 9.82e-01, avg batch time: 1.8086, average train loss: 0.7599
[12/05 16:07:50][INFO] visual_prompt:  316: Inference (val):avg data time: 1.03e-04, avg batch time: 0.3108, average loss: 0.8091
[12/05 16:07:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.96	
[12/05 16:07:50][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/05 16:10:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6921,	0.8538 s / batch. (data: 5.48e-03). ETA=12:10:25, max mem: 20.9 GB 
[12/05 16:12:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2244,	0.8545 s / batch. (data: 5.48e-03). ETA=12:09:35, max mem: 20.9 GB 
[12/05 16:14:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7496,	0.8432 s / batch. (data: 9.86e-04). ETA=11:58:33, max mem: 20.9 GB 
[12/05 16:16:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7586,	1.4376 s / batch. (data: 5.92e-01). ETA=20:22:36, max mem: 20.9 GB 
[12/05 16:18:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8660,	2.6957 s / batch. (data: 1.86e+00). ETA=1 day, 14:08:08, max mem: 20.9 GB 
[12/05 16:19:13][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 3.97e-01, avg batch time: 1.2354, average train loss: 0.7670
[12/05 16:20:25][INFO] visual_prompt:  316: Inference (val):avg data time: 9.22e-05, avg batch time: 0.3116, average loss: 0.6925
[12/05 16:20:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.24	
[12/05 16:20:25][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/05 16:22:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4150,	0.8449 s / batch. (data: 2.90e-02). ETA=11:54:58, max mem: 20.9 GB 
[12/05 16:24:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6221,	0.8320 s / batch. (data: 3.13e-04). ETA=11:42:42, max mem: 20.9 GB 
[12/05 16:26:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7428,	2.0440 s / batch. (data: 1.21e+00). ETA=1 day, 4:42:57, max mem: 20.9 GB 
[12/05 16:28:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5888,	0.8572 s / batch. (data: 3.36e-02). ETA=12:01:05, max mem: 20.9 GB 
[12/05 16:30:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7645,	0.8320 s / batch. (data: 3.52e-04). ETA=11:38:32, max mem: 20.9 GB 
[12/05 16:31:07][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 3.27e-01, avg batch time: 1.1609, average train loss: 0.7426
[12/05 16:32:16][INFO] visual_prompt:  316: Inference (val):avg data time: 1.49e-04, avg batch time: 0.3123, average loss: 0.7558
[12/05 16:32:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.53	
[12/05 16:32:16][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/05 16:34:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6994,	0.8551 s / batch. (data: 5.47e-03). ETA=11:55:43, max mem: 20.9 GB 
[12/05 16:36:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6694,	0.8558 s / batch. (data: 6.85e-04). ETA=11:54:56, max mem: 20.9 GB 
[12/05 16:38:14][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6549,	3.1265 s / batch. (data: 2.30e+00). ETA=1 day, 19:26:37, max mem: 20.9 GB 
[12/05 16:40:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7412,	1.1252 s / batch. (data: 3.04e-01). ETA=15:36:11, max mem: 20.9 GB 
[12/05 16:42:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0304,	1.5602 s / batch. (data: 7.46e-01). ETA=21:35:35, max mem: 20.9 GB 
[12/05 16:43:06][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.40e-01, avg batch time: 1.1743, average train loss: 0.7587
[12/05 16:44:15][INFO] visual_prompt:  316: Inference (val):avg data time: 7.65e-05, avg batch time: 0.3116, average loss: 0.9164
[12/05 16:44:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.02	
[12/05 16:44:15][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.1
[12/05 16:46:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6765,	0.8644 s / batch. (data: 3.20e-04). ETA=11:55:32, max mem: 20.9 GB 
[12/05 16:48:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0358,	0.8299 s / batch. (data: 4.30e-04). ETA=11:25:36, max mem: 20.9 GB 
[12/05 16:50:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6732,	2.9922 s / batch. (data: 2.15e+00). ETA=1 day, 17:07:03, max mem: 20.9 GB 
[12/05 16:52:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7097,	0.8414 s / batch. (data: 7.73e-04). ETA=11:32:18, max mem: 20.9 GB 
[12/05 16:54:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6885,	0.8560 s / batch. (data: 1.19e-02). ETA=11:42:54, max mem: 20.9 GB 
[12/05 16:55:13][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 3.53e-01, avg batch time: 1.1899, average train loss: 0.7534
[12/05 16:56:20][INFO] visual_prompt:  316: Inference (val):avg data time: 6.88e-05, avg batch time: 0.3098, average loss: 0.6948
[12/05 16:56:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.59	
[12/05 16:56:20][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/05 16:58:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9692,	1.5802 s / batch. (data: 7.42e-01). ETA=21:33:34, max mem: 20.9 GB 
[12/05 17:00:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5911,	0.8282 s / batch. (data: 3.86e-04). ETA=11:16:34, max mem: 20.9 GB 
[12/05 17:02:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6782,	0.8333 s / batch. (data: 7.95e-03). ETA=11:19:22, max mem: 20.9 GB 
[12/05 17:04:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7094,	0.8271 s / batch. (data: 3.57e-04). ETA=11:12:54, max mem: 20.9 GB 
[12/05 17:06:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.0742,	0.8238 s / batch. (data: 7.78e-03). ETA=11:08:54, max mem: 20.9 GB 
[12/05 17:07:12][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 3.43e-01, avg batch time: 1.1785, average train loss: 0.7615
[12/05 17:08:19][INFO] visual_prompt:  316: Inference (val):avg data time: 5.26e-05, avg batch time: 0.3109, average loss: 0.8491
[12/05 17:08:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.20	
[12/05 17:08:19][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/05 17:10:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7742,	0.8447 s / batch. (data: 3.29e-04). ETA=11:23:41, max mem: 20.9 GB 
[12/05 17:12:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6752,	0.8152 s / batch. (data: 3.67e-04). ETA=10:58:26, max mem: 20.9 GB 
[12/05 17:14:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6694,	2.3520 s / batch. (data: 1.51e+00). ETA=1 day, 7:35:51, max mem: 20.9 GB 
[12/05 17:16:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9745,	0.8238 s / batch. (data: 3.38e-04). ETA=11:02:38, max mem: 20.9 GB 
[12/05 17:18:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7368,	0.8255 s / batch. (data: 3.35e-04). ETA=11:02:38, max mem: 20.9 GB 
[12/05 17:19:15][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 3.51e-01, avg batch time: 1.1844, average train loss: 0.7640
[12/05 17:20:39][INFO] visual_prompt:  316: Inference (val):avg data time: 6.97e-05, avg batch time: 0.3095, average loss: 0.7014
[12/05 17:20:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.98	
[12/05 17:20:39][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/05 17:22:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6431,	0.8473 s / batch. (data: 1.06e-02). ETA=11:17:57, max mem: 20.9 GB 
[12/05 17:24:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7708,	2.4636 s / batch. (data: 1.62e+00). ETA=1 day, 8:47:12, max mem: 20.9 GB 
[12/05 17:27:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7119,	2.2797 s / batch. (data: 1.46e+00). ETA=1 day, 6:16:34, max mem: 20.9 GB 
[12/05 17:29:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6560,	0.8409 s / batch. (data: 1.47e-02). ETA=11:08:38, max mem: 20.9 GB 
[12/05 17:31:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9734,	0.8399 s / batch. (data: 5.31e-04). ETA=11:06:30, max mem: 20.9 GB 
[12/05 17:32:39][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 4.72e-01, avg batch time: 1.3015, average train loss: 0.7485
[12/05 17:33:51][INFO] visual_prompt:  316: Inference (val):avg data time: 6.80e-05, avg batch time: 0.3095, average loss: 0.6943
[12/05 17:33:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.04	
[12/05 17:33:52][INFO] visual_prompt:   36: Best epoch 14: best metric: -0.694
[12/05 17:33:52][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/05 17:36:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7109,	4.8572 s / batch. (data: 4.01e+00). ETA=2 days, 16:01:52, max mem: 20.9 GB 
[12/05 17:38:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6378,	1.1279 s / batch. (data: 2.89e-01). ETA=14:50:13, max mem: 20.9 GB 
[12/05 17:40:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7343,	0.8592 s / batch. (data: 1.61e-02). ETA=11:16:43, max mem: 20.9 GB 
[12/05 17:42:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5733,	0.8472 s / batch. (data: 3.46e-04). ETA=11:05:50, max mem: 20.9 GB 
[12/05 17:45:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9717,	0.8291 s / batch. (data: 3.41e-04). ETA=10:50:14, max mem: 20.9 GB 
[12/05 17:46:11][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 5.07e-01, avg batch time: 1.3356, average train loss: 0.7359
[12/05 17:47:34][INFO] visual_prompt:  316: Inference (val):avg data time: 7.91e-05, avg batch time: 0.3094, average loss: 0.7089
[12/05 17:47:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[12/05 17:47:34][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/05 17:49:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5607,	0.8119 s / batch. (data: 3.59e-04). ETA=10:34:42, max mem: 20.9 GB 
[12/05 17:51:48][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8435,	0.8678 s / batch. (data: 1.55e-02). ETA=11:16:57, max mem: 20.9 GB 
[12/05 17:53:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.2283,	0.8446 s / batch. (data: 1.18e-03). ETA=10:57:28, max mem: 20.9 GB 
[12/05 17:55:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6431,	0.8385 s / batch. (data: 1.06e-02). ETA=10:51:17, max mem: 20.9 GB 
[12/05 17:57:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8496,	1.9982 s / batch. (data: 1.17e+00). ETA=1 day, 1:48:44, max mem: 20.9 GB 
[12/05 17:58:38][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.71e-01, avg batch time: 1.2016, average train loss: 0.7228
[12/05 17:59:45][INFO] visual_prompt:  316: Inference (val):avg data time: 5.40e-05, avg batch time: 0.3092, average loss: 0.7196
[12/05 17:59:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[12/05 17:59:45][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/05 18:01:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5634,	0.8333 s / batch. (data: 5.53e-03). ETA=10:43:44, max mem: 20.9 GB 
[12/05 18:03:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6783,	0.8618 s / batch. (data: 3.38e-02). ETA=11:04:21, max mem: 20.9 GB 
[12/05 18:05:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0435,	0.8213 s / batch. (data: 3.58e-04). ETA=10:31:45, max mem: 20.9 GB 
[12/05 18:07:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6753,	0.8320 s / batch. (data: 1.15e-02). ETA=10:38:33, max mem: 20.9 GB 
[12/05 18:09:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6440,	2.4400 s / batch. (data: 1.60e+00). ETA=1 day, 7:08:44, max mem: 20.9 GB 
[12/05 18:10:11][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 2.99e-01, avg batch time: 1.1322, average train loss: 0.7228
[12/05 18:11:16][INFO] visual_prompt:  316: Inference (val):avg data time: 4.83e-05, avg batch time: 0.3113, average loss: 0.7145
[12/05 18:11:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.94	
[12/05 18:11:16][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/05 18:13:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7472,	0.8448 s / batch. (data: 1.68e-02). ETA=10:44:49, max mem: 20.9 GB 
[12/05 18:15:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7476,	0.8342 s / batch. (data: 1.06e-02). ETA=10:35:23, max mem: 20.9 GB 
[12/05 18:17:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6563,	0.8246 s / batch. (data: 3.16e-04). ETA=10:26:38, max mem: 20.9 GB 
[12/05 18:18:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6872,	0.8359 s / batch. (data: 5.32e-04). ETA=10:33:52, max mem: 20.9 GB 
[12/05 18:20:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7037,	0.8560 s / batch. (data: 1.19e-02). ETA=10:47:40, max mem: 20.9 GB 
[12/05 18:21:42][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 2.98e-01, avg batch time: 1.1308, average train loss: 0.7249
[12/05 18:22:48][INFO] visual_prompt:  316: Inference (val):avg data time: 5.79e-05, avg batch time: 0.3093, average loss: 0.7495
[12/05 18:22:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[12/05 18:22:48][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/05 18:24:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0922,	0.8360 s / batch. (data: 3.56e-04). ETA=10:30:25, max mem: 20.9 GB 
[12/05 18:26:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7904,	0.8186 s / batch. (data: 4.41e-04). ETA=10:15:56, max mem: 20.9 GB 
[12/05 18:28:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0872,	1.4345 s / batch. (data: 6.05e-01). ETA=17:56:59, max mem: 20.9 GB 
[12/05 18:30:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5629,	0.8304 s / batch. (data: 5.81e-04). ETA=10:22:00, max mem: 20.9 GB 
[12/05 18:32:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7644,	0.8279 s / batch. (data: 6.29e-04). ETA=10:18:49, max mem: 20.9 GB 
[12/05 18:33:13][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 2.97e-01, avg batch time: 1.1299, average train loss: 0.7397
[12/05 18:34:19][INFO] visual_prompt:  316: Inference (val):avg data time: 6.09e-05, avg batch time: 0.3125, average loss: 0.9610
[12/05 18:34:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[12/05 18:34:19][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/05 18:36:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1063,	0.8470 s / batch. (data: 1.27e-02). ETA=10:30:56, max mem: 20.9 GB 
[12/05 18:38:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5885,	0.8412 s / batch. (data: 3.43e-04). ETA=10:25:10, max mem: 20.9 GB 
[12/05 18:40:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7721,	0.8205 s / batch. (data: 2.83e-04). ETA=10:08:26, max mem: 20.9 GB 
[12/05 18:41:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5869,	0.8397 s / batch. (data: 3.09e-04). ETA=10:21:16, max mem: 20.9 GB 
[12/05 18:43:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7745,	0.8211 s / batch. (data: 5.50e-04). ETA=10:06:10, max mem: 20.9 GB 
[12/05 18:44:52][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 3.11e-01, avg batch time: 1.1434, average train loss: 0.7536
[12/05 18:45:59][INFO] visual_prompt:  316: Inference (val):avg data time: 2.73e-04, avg batch time: 0.3099, average loss: 0.7681
[12/05 18:45:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.59	
[12/05 18:45:59][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/05 18:48:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5750,	0.8621 s / batch. (data: 1.39e-02). ETA=10:34:14, max mem: 20.9 GB 
[12/05 18:50:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6979,	0.8380 s / batch. (data: 5.49e-03). ETA=10:15:05, max mem: 20.9 GB 
[12/05 18:52:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8871,	1.2989 s / batch. (data: 4.68e-01). ETA=15:51:13, max mem: 20.9 GB 
[12/05 18:53:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6125,	0.8348 s / batch. (data: 3.45e-04). ETA=10:09:59, max mem: 20.9 GB 
[12/05 18:55:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7041,	0.8301 s / batch. (data: 3.17e-04). ETA=10:05:10, max mem: 20.9 GB 
[12/05 18:57:00][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 3.64e-01, avg batch time: 1.1947, average train loss: 0.7327
[12/05 18:58:08][INFO] visual_prompt:  316: Inference (val):avg data time: 5.82e-05, avg batch time: 0.3106, average loss: 0.8394
[12/05 18:58:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.32	
[12/05 18:58:08][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/05 19:00:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7008,	0.8357 s / batch. (data: 2.07e-02). ETA=10:07:07, max mem: 20.9 GB 
[12/05 19:02:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6293,	0.8400 s / batch. (data: 3.56e-04). ETA=10:08:48, max mem: 20.9 GB 
[12/05 19:04:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5109,	0.8440 s / batch. (data: 3.67e-04). ETA=10:10:18, max mem: 20.9 GB 
[12/05 19:05:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6693,	0.8520 s / batch. (data: 1.19e-02). ETA=10:14:39, max mem: 20.9 GB 
[12/05 19:07:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7878,	0.8280 s / batch. (data: 7.95e-03). ETA=9:55:58, max mem: 20.9 GB 
[12/05 19:08:58][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 3.43e-01, avg batch time: 1.1750, average train loss: 0.7470
[12/05 19:10:10][INFO] visual_prompt:  316: Inference (val):avg data time: 6.53e-05, avg batch time: 0.3098, average loss: 0.8130
[12/05 19:10:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.08	
[12/05 19:10:10][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/05 19:12:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6956,	0.8183 s / batch. (data: 3.59e-04). ETA=9:46:55, max mem: 20.9 GB 
[12/05 19:14:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6218,	0.8401 s / batch. (data: 3.17e-04). ETA=10:01:10, max mem: 20.9 GB 
[12/05 19:16:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7497,	0.8415 s / batch. (data: 2.90e-03). ETA=10:00:43, max mem: 20.9 GB 
[12/05 19:19:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5635,	0.8320 s / batch. (data: 3.40e-04). ETA=9:52:34, max mem: 20.9 GB 
[12/05 19:21:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9569,	0.8199 s / batch. (data: 9.39e-04). ETA=9:42:35, max mem: 20.9 GB 
[12/05 19:22:04][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 4.63e-01, avg batch time: 1.2921, average train loss: 0.7392
[12/05 19:23:14][INFO] visual_prompt:  316: Inference (val):avg data time: 5.84e-05, avg batch time: 0.3108, average loss: 0.7030
[12/05 19:23:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.18	
[12/05 19:23:14][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/05 19:25:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8127,	0.8410 s / batch. (data: 8.37e-03). ETA=9:55:26, max mem: 20.9 GB 
[12/05 19:27:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6567,	0.8292 s / batch. (data: 6.49e-04). ETA=9:45:41, max mem: 20.9 GB 
[12/05 19:28:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7255,	1.3936 s / batch. (data: 5.63e-01). ETA=16:22:03, max mem: 20.9 GB 
[12/05 19:30:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6234,	0.8293 s / batch. (data: 4.78e-04). ETA=9:43:00, max mem: 20.9 GB 
[12/05 19:32:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8428,	0.8463 s / batch. (data: 8.27e-04). ETA=9:53:31, max mem: 20.9 GB 
[12/05 19:33:48][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 3.13e-01, avg batch time: 1.1463, average train loss: 0.7447
[12/05 19:34:55][INFO] visual_prompt:  316: Inference (val):avg data time: 2.72e-04, avg batch time: 0.3095, average loss: 0.6957
[12/05 19:34:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.08	
[12/05 19:34:55][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/05 19:36:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6123,	0.8437 s / batch. (data: 1.17e-02). ETA=9:49:36, max mem: 20.9 GB 
[12/05 19:38:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7145,	1.1758 s / batch. (data: 3.47e-01). ETA=13:39:39, max mem: 20.9 GB 
[12/05 19:40:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6933,	0.8390 s / batch. (data: 2.31e-02). ETA=9:43:31, max mem: 20.9 GB 
[12/05 19:42:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6574,	2.6100 s / batch. (data: 1.80e+00). ETA=1 day, 6:10:49, max mem: 20.9 GB 
[12/05 19:44:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8415,	1.9296 s / batch. (data: 1.12e+00). ETA=22:15:32, max mem: 20.9 GB 
[12/05 19:45:34][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 3.23e-01, avg batch time: 1.1545, average train loss: 0.7556
[12/05 19:46:41][INFO] visual_prompt:  316: Inference (val):avg data time: 5.32e-05, avg batch time: 0.3098, average loss: 0.6886
[12/05 19:46:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.84	
[12/05 19:46:41][INFO] visual_prompt:   36: Best epoch 25: best metric: -0.689
[12/05 19:46:41][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/05 19:48:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6289,	0.8287 s / batch. (data: 3.31e-04). ETA=9:31:29, max mem: 20.9 GB 
[12/05 19:50:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6732,	2.3692 s / batch. (data: 1.53e+00). ETA=1 day, 3:09:49, max mem: 20.9 GB 
[12/05 19:52:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6006,	0.8263 s / batch. (data: 5.27e-04). ETA=9:27:04, max mem: 20.9 GB 
[12/05 19:54:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6134,	0.8252 s / batch. (data: 6.10e-04). ETA=9:24:56, max mem: 20.9 GB 
[12/05 19:56:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6837,	0.8478 s / batch. (data: 2.07e-02). ETA=9:38:58, max mem: 20.9 GB 
[12/05 19:57:13][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 3.10e-01, avg batch time: 1.1426, average train loss: 0.7446
[12/05 19:58:20][INFO] visual_prompt:  316: Inference (val):avg data time: 2.20e-04, avg batch time: 0.3113, average loss: 0.7707
[12/05 19:58:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.01	
[12/05 19:58:20][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/05 20:00:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5759,	0.8357 s / batch. (data: 3.45e-04). ETA=9:28:35, max mem: 20.9 GB 
[12/05 20:02:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7599,	1.9560 s / batch. (data: 1.12e+00). ETA=22:07:31, max mem: 20.9 GB 
[12/05 20:04:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6171,	0.9959 s / batch. (data: 1.58e-01). ETA=11:14:15, max mem: 20.9 GB 
[12/05 20:06:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8538,	0.8160 s / batch. (data: 3.58e-04). ETA=9:11:05, max mem: 20.9 GB 
[12/05 20:07:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9023,	0.8231 s / batch. (data: 3.67e-04). ETA=9:14:29, max mem: 20.9 GB 
[12/05 20:08:53][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 3.11e-01, avg batch time: 1.1438, average train loss: 0.7394
[12/05 20:10:00][INFO] visual_prompt:  316: Inference (val):avg data time: 6.92e-05, avg batch time: 0.3092, average loss: 0.7072
[12/05 20:10:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.06	
[12/05 20:10:00][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/05 20:11:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2810,	0.8200 s / batch. (data: 5.26e-04). ETA=9:10:18, max mem: 20.9 GB 
[12/05 20:13:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6226,	0.8503 s / batch. (data: 3.25e-04). ETA=9:29:15, max mem: 20.9 GB 
[12/05 20:15:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6038,	2.0881 s / batch. (data: 1.24e+00). ETA=23:14:27, max mem: 20.9 GB 
[12/05 20:17:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7277,	0.8300 s / batch. (data: 4.19e-04). ETA=9:12:55, max mem: 20.9 GB 
[12/05 20:19:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4626,	0.8483 s / batch. (data: 8.78e-04). ETA=9:23:41, max mem: 20.9 GB 
[12/05 20:20:31][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 3.09e-01, avg batch time: 1.1418, average train loss: 0.7363
[12/05 20:21:38][INFO] visual_prompt:  316: Inference (val):avg data time: 5.98e-05, avg batch time: 0.3094, average loss: 0.7467
[12/05 20:21:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.67	
[12/05 20:21:38][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/05 20:23:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5933,	0.8467 s / batch. (data: 2.85e-02). ETA=9:20:26, max mem: 20.9 GB 
[12/05 20:25:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7172,	2.2821 s / batch. (data: 1.46e+00). ETA=1 day, 1:06:47, max mem: 20.9 GB 
[12/05 20:27:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7275,	0.8701 s / batch. (data: 1.68e-02). ETA=9:33:02, max mem: 20.9 GB 
[12/05 20:29:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5660,	1.6117 s / batch. (data: 7.70e-01). ETA=17:38:46, max mem: 20.9 GB 
[12/05 20:31:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7062,	0.8356 s / batch. (data: 1.54e-03). ETA=9:07:33, max mem: 20.9 GB 
[12/05 20:32:09][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 3.07e-01, avg batch time: 1.1399, average train loss: 0.7461
[12/05 20:33:16][INFO] visual_prompt:  316: Inference (val):avg data time: 2.25e-04, avg batch time: 0.3086, average loss: 0.6946
[12/05 20:33:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.42	
[12/05 20:33:16][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/05 20:35:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7167,	0.8311 s / batch. (data: 3.75e-04). ETA=9:02:29, max mem: 20.9 GB 
[12/05 20:37:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8070,	0.8384 s / batch. (data: 1.46e-02). ETA=9:05:51, max mem: 20.9 GB 
[12/05 20:38:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4083,	1.7399 s / batch. (data: 9.22e-01). ETA=18:49:50, max mem: 20.9 GB 
[12/05 20:40:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6901,	1.5973 s / batch. (data: 7.83e-01). ETA=17:14:34, max mem: 20.9 GB 
[12/05 20:42:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6150,	1.9532 s / batch. (data: 1.12e+00). ETA=21:01:50, max mem: 20.9 GB 
[12/05 20:43:47][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 3.10e-01, avg batch time: 1.1421, average train loss: 0.7426
[12/05 20:44:54][INFO] visual_prompt:  316: Inference (val):avg data time: 5.97e-05, avg batch time: 0.3092, average loss: 0.6990
[12/05 20:44:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.13	
[12/05 20:44:54][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/05 20:46:55][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6396,	0.8656 s / batch. (data: 2.07e-02). ETA=9:17:02, max mem: 20.9 GB 
[12/05 20:48:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7085,	0.8428 s / batch. (data: 1.44e-02). ETA=9:00:54, max mem: 20.9 GB 
[12/05 20:50:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6918,	0.8366 s / batch. (data: 4.30e-04). ETA=8:55:35, max mem: 20.9 GB 
[12/05 20:52:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5714,	1.5620 s / batch. (data: 7.36e-01). ETA=16:37:21, max mem: 20.9 GB 
[12/05 20:54:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8400,	0.8331 s / batch. (data: 1.56e-02). ETA=8:50:32, max mem: 20.9 GB 
[12/05 20:55:26][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 3.09e-01, avg batch time: 1.1413, average train loss: 0.7275
[12/05 20:56:32][INFO] visual_prompt:  316: Inference (val):avg data time: 6.07e-05, avg batch time: 0.3102, average loss: 0.7573
[12/05 20:56:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.90	
[12/05 20:56:32][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/05 20:58:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9191,	0.8484 s / batch. (data: 8.08e-03). ETA=8:58:07, max mem: 20.9 GB 
[12/05 21:00:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6166,	0.8205 s / batch. (data: 5.66e-03). ETA=8:39:04, max mem: 20.9 GB 
[12/05 21:02:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6997,	0.8444 s / batch. (data: 2.07e-02). ETA=8:52:48, max mem: 20.9 GB 
[12/05 21:04:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9619,	0.8515 s / batch. (data: 1.36e-03). ETA=8:55:50, max mem: 20.9 GB 
[12/05 21:06:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7259,	0.8439 s / batch. (data: 5.47e-04). ETA=8:49:40, max mem: 20.9 GB 
[12/05 21:07:22][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 3.43e-01, avg batch time: 1.1741, average train loss: 0.7294
[12/05 21:08:30][INFO] visual_prompt:  316: Inference (val):avg data time: 6.80e-05, avg batch time: 0.3124, average loss: 0.7094
[12/05 21:08:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.94	
[12/05 21:08:30][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/05 21:10:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0189,	0.8481 s / batch. (data: 8.01e-03). ETA=8:50:06, max mem: 20.9 GB 
[12/05 21:12:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5624,	2.6400 s / batch. (data: 1.79e+00). ETA=1 day, 3:25:46, max mem: 20.9 GB 
[12/05 21:14:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6215,	0.8280 s / batch. (data: 3.45e-04). ETA=8:34:46, max mem: 20.9 GB 
[12/05 21:16:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7281,	0.8444 s / batch. (data: 2.50e-02). ETA=8:43:34, max mem: 20.9 GB 
[12/05 21:18:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6636,	0.8704 s / batch. (data: 3.79e-02). ETA=8:58:14, max mem: 20.9 GB 
[12/05 21:19:09][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 3.24e-01, avg batch time: 1.1560, average train loss: 0.7357
[12/05 21:20:17][INFO] visual_prompt:  316: Inference (val):avg data time: 7.02e-05, avg batch time: 0.3101, average loss: 0.6899
[12/05 21:20:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.10	
[12/05 21:20:17][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[12/05 21:22:18][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7234,	0.9487 s / batch. (data: 8.29e-02). ETA=9:44:17, max mem: 20.9 GB 
[12/05 21:24:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7554,	0.8360 s / batch. (data: 5.48e-03). ETA=8:33:27, max mem: 20.9 GB 
[12/05 21:26:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6948,	1.0914 s / batch. (data: 2.51e-01). ETA=11:08:29, max mem: 20.9 GB 
[12/05 21:27:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6472,	0.8288 s / batch. (data: 6.08e-04). ETA=8:26:16, max mem: 20.9 GB 
[12/05 21:29:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8990,	1.9838 s / batch. (data: 1.13e+00). ETA=20:08:31, max mem: 20.9 GB 
[12/05 21:30:47][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 3.06e-01, avg batch time: 1.1394, average train loss: 0.7285
[12/05 21:31:53][INFO] visual_prompt:  316: Inference (val):avg data time: 5.70e-05, avg batch time: 0.3098, average loss: 0.6929
[12/05 21:31:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 61.63	
[12/05 21:31:53][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[12/05 21:33:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6518,	0.8170 s / batch. (data: 3.26e-04). ETA=8:15:35, max mem: 20.9 GB 
[12/05 21:35:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5978,	0.8290 s / batch. (data: 3.76e-04). ETA=8:21:30, max mem: 20.9 GB 
[12/05 21:37:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7145,	0.8675 s / batch. (data: 3.98e-02). ETA=8:43:20, max mem: 20.9 GB 
[12/05 21:39:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6154,	0.8440 s / batch. (data: 3.67e-04). ETA=8:27:46, max mem: 20.9 GB 
[12/05 21:41:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8840,	1.2560 s / batch. (data: 4.24e-01). ETA=12:33:33, max mem: 20.9 GB 
[12/05 21:42:24][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 3.07e-01, avg batch time: 1.1399, average train loss: 0.7593
[12/05 21:43:29][INFO] visual_prompt:  316: Inference (val):avg data time: 4.88e-05, avg batch time: 0.3098, average loss: 0.6881
[12/05 21:43:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.04	
[12/05 21:43:29][INFO] visual_prompt:   36: Best epoch 35: best metric: -0.688
[12/05 21:43:29][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[12/05 21:45:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8359,	0.9586 s / batch. (data: 1.31e-01). ETA=9:32:40, max mem: 20.9 GB 
[12/05 21:47:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8371,	0.8379 s / batch. (data: 1.09e-02). ETA=8:19:11, max mem: 20.9 GB 
[12/05 21:49:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5996,	0.8725 s / batch. (data: 7.98e-03). ETA=8:38:21, max mem: 20.9 GB 
[12/05 21:51:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9676,	2.1282 s / batch. (data: 1.31e+00). ETA=21:00:48, max mem: 20.9 GB 
[12/05 21:53:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8029,	0.9880 s / batch. (data: 1.64e-01). ETA=9:43:39, max mem: 20.9 GB 
[12/05 21:53:58][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 3.03e-01, avg batch time: 1.1369, average train loss: 0.7692
[12/05 21:55:04][INFO] visual_prompt:  316: Inference (val):avg data time: 5.99e-05, avg batch time: 0.3122, average loss: 0.6884
[12/05 21:55:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.01	
[12/05 21:55:04][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[12/05 21:57:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8847,	0.8346 s / batch. (data: 7.13e-03). ETA=8:10:54, max mem: 20.9 GB 
[12/05 21:58:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8832,	0.8166 s / batch. (data: 5.47e-04). ETA=7:58:56, max mem: 20.9 GB 
[12/05 22:00:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6878,	2.0270 s / batch. (data: 1.21e+00). ETA=19:45:33, max mem: 20.9 GB 
[12/05 22:02:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9354,	2.0731 s / batch. (data: 1.25e+00). ETA=20:09:00, max mem: 20.9 GB 
[12/05 22:04:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7281,	1.5280 s / batch. (data: 6.88e-01). ETA=14:48:35, max mem: 20.9 GB 
[12/05 22:05:35][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 3.09e-01, avg batch time: 1.1419, average train loss: 0.7389
[12/05 22:06:41][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-04, avg batch time: 0.3117, average loss: 0.6901
[12/05 22:06:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[12/05 22:06:41][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[12/05 22:08:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5886,	1.2414 s / batch. (data: 4.14e-01). ETA=11:58:44, max mem: 20.9 GB 
[12/05 22:10:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6969,	2.0736 s / batch. (data: 1.22e+00). ETA=19:57:08, max mem: 20.9 GB 
[12/05 22:12:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6772,	0.8305 s / batch. (data: 3.37e-04). ETA=7:58:04, max mem: 20.9 GB 
[12/05 22:14:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6716,	0.8568 s / batch. (data: 2.89e-02). ETA=8:11:48, max mem: 20.9 GB 
[12/05 22:16:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8136,	0.8509 s / batch. (data: 1.29e-02). ETA=8:06:59, max mem: 20.9 GB 
[12/05 22:17:14][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 3.10e-01, avg batch time: 1.1440, average train loss: 0.7327
[12/05 22:18:20][INFO] visual_prompt:  316: Inference (val):avg data time: 1.98e-04, avg batch time: 0.3097, average loss: 0.7041
[12/05 22:18:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.40	
[12/05 22:18:20][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[12/05 22:20:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9555,	0.8226 s / batch. (data: 5.76e-04). ETA=7:48:41, max mem: 20.9 GB 
[12/05 22:22:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4361,	0.8335 s / batch. (data: 3.33e-04). ETA=7:53:30, max mem: 20.9 GB 
[12/05 22:24:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6856,	0.8167 s / batch. (data: 3.71e-04). ETA=7:42:34, max mem: 20.9 GB 
[12/05 22:26:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6102,	0.8307 s / batch. (data: 1.06e-02). ETA=7:49:09, max mem: 20.9 GB 
[12/05 22:27:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5632,	2.2772 s / batch. (data: 1.46e+00). ETA=21:22:16, max mem: 20.9 GB 
[12/05 22:28:52][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 3.10e-01, avg batch time: 1.1431, average train loss: 0.7370
[12/05 22:29:57][INFO] visual_prompt:  316: Inference (val):avg data time: 5.54e-05, avg batch time: 0.3098, average loss: 0.7066
[12/05 22:29:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.70	
[12/05 22:29:57][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[12/05 22:31:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7542,	0.8379 s / batch. (data: 3.22e-04). ETA=7:49:40, max mem: 20.9 GB 
[12/05 22:33:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6078,	0.8320 s / batch. (data: 3.24e-04). ETA=7:44:59, max mem: 20.9 GB 
[12/05 22:35:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6014,	0.8299 s / batch. (data: 5.86e-03). ETA=7:42:26, max mem: 20.9 GB 
[12/05 22:37:37][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6166,	0.8353 s / batch. (data: 3.37e-04). ETA=7:44:03, max mem: 20.9 GB 
[12/05 22:39:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2852,	0.8396 s / batch. (data: 1.29e-03). ETA=7:45:02, max mem: 20.9 GB 
[12/05 22:40:29][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 3.08e-01, avg batch time: 1.1417, average train loss: 0.7328
[12/05 22:41:35][INFO] visual_prompt:  316: Inference (val):avg data time: 2.82e-04, avg batch time: 0.3122, average loss: 0.6878
[12/05 22:41:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.89	
[12/05 22:41:35][INFO] visual_prompt:   36: Best epoch 40: best metric: -0.688
[12/05 22:41:35][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[12/05 22:43:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7385,	0.8256 s / batch. (data: 1.20e-02). ETA=7:35:09, max mem: 20.9 GB 
[12/05 22:45:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6140,	0.8664 s / batch. (data: 1.18e-02). ETA=7:56:14, max mem: 20.9 GB 
[12/05 22:47:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7005,	0.8402 s / batch. (data: 7.95e-03). ETA=7:40:26, max mem: 20.9 GB 
[12/05 22:49:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8565,	0.8449 s / batch. (data: 6.60e-03). ETA=7:41:37, max mem: 20.9 GB 
[12/05 22:51:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2732,	0.8444 s / batch. (data: 3.39e-04). ETA=7:39:53, max mem: 20.9 GB 
[12/05 22:52:05][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 3.06e-01, avg batch time: 1.1402, average train loss: 0.7478
[12/05 22:53:11][INFO] visual_prompt:  316: Inference (val):avg data time: 6.05e-05, avg batch time: 0.3097, average loss: 0.7116
[12/05 22:53:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.84	
[12/05 22:53:11][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[12/05 22:55:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7005,	0.8876 s / batch. (data: 1.08e-03). ETA=8:01:11, max mem: 20.9 GB 
[12/05 22:57:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7370,	0.8220 s / batch. (data: 6.70e-04). ETA=7:24:13, max mem: 20.9 GB 
[12/05 22:58:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6795,	0.8372 s / batch. (data: 1.56e-02). ETA=7:31:03, max mem: 20.9 GB 
[12/05 23:00:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6917,	0.8242 s / batch. (data: 3.32e-04). ETA=7:22:42, max mem: 20.9 GB 
[12/05 23:02:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.5781,	0.8406 s / batch. (data: 2.47e-02). ETA=7:30:05, max mem: 20.9 GB 
[12/05 23:03:42][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 3.07e-01, avg batch time: 1.1401, average train loss: 0.7293
[12/05 23:04:47][INFO] visual_prompt:  316: Inference (val):avg data time: 6.38e-05, avg batch time: 0.3098, average loss: 0.7266
[12/05 23:04:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.95	
[12/05 23:04:47][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[12/05 23:06:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5882,	0.8567 s / batch. (data: 1.28e-02). ETA=7:36:31, max mem: 20.9 GB 
[12/05 23:08:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7907,	0.8466 s / batch. (data: 5.92e-03). ETA=7:29:45, max mem: 20.9 GB 
[12/05 23:10:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9188,	0.8215 s / batch. (data: 5.62e-03). ETA=7:15:00, max mem: 20.9 GB 
[12/05 23:12:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6374,	0.8456 s / batch. (data: 1.06e-02). ETA=7:26:23, max mem: 20.9 GB 
[12/05 23:14:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5805,	0.8439 s / batch. (data: 7.85e-03). ETA=7:24:06, max mem: 20.9 GB 
[12/05 23:15:18][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 3.07e-01, avg batch time: 1.1400, average train loss: 0.7341
[12/05 23:16:23][INFO] visual_prompt:  316: Inference (val):avg data time: 5.56e-05, avg batch time: 0.3114, average loss: 0.6918
[12/05 23:16:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.26	
[12/05 23:16:23][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[12/05 23:18:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6247,	0.9417 s / batch. (data: 8.25e-02). ETA=8:13:09, max mem: 20.9 GB 
[12/05 23:20:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6427,	0.8304 s / batch. (data: 3.44e-04). ETA=7:13:28, max mem: 20.9 GB 
[12/05 23:22:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6587,	0.8425 s / batch. (data: 2.28e-02). ETA=7:18:24, max mem: 20.9 GB 
[12/05 23:24:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7130,	0.8361 s / batch. (data: 2.50e-04). ETA=7:13:41, max mem: 20.9 GB 
[12/05 23:25:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8189,	0.8601 s / batch. (data: 3.55e-04). ETA=7:24:41, max mem: 20.9 GB 
[12/05 23:26:55][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 3.09e-01, avg batch time: 1.1420, average train loss: 0.7433
[12/05 23:28:01][INFO] visual_prompt:  316: Inference (val):avg data time: 5.57e-05, avg batch time: 0.3090, average loss: 0.7069
[12/05 23:28:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[12/05 23:28:01][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[12/05 23:30:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7058,	0.8384 s / batch. (data: 3.81e-04). ETA=7:11:21, max mem: 20.9 GB 
[12/05 23:31:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6636,	1.5079 s / batch. (data: 6.73e-01). ETA=12:53:14, max mem: 20.9 GB 
[12/05 23:33:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7507,	0.8372 s / batch. (data: 3.37e-04). ETA=7:07:54, max mem: 20.9 GB 
[12/05 23:35:36][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7370,	0.8213 s / batch. (data: 4.10e-04). ETA=6:58:24, max mem: 20.9 GB 
[12/05 23:37:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5791,	0.8240 s / batch. (data: 3.87e-04). ETA=6:58:25, max mem: 20.9 GB 
[12/05 23:38:33][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 3.10e-01, avg batch time: 1.1426, average train loss: 0.7129
[12/05 23:39:39][INFO] visual_prompt:  316: Inference (val):avg data time: 5.39e-05, avg batch time: 0.3088, average loss: 0.7066
[12/05 23:39:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[12/05 23:39:39][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[12/05 23:41:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7631,	1.1134 s / batch. (data: 2.66e-01). ETA=9:22:34, max mem: 20.9 GB 
[12/05 23:43:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7522,	0.8202 s / batch. (data: 3.76e-04). ETA=6:53:01, max mem: 20.9 GB 
[12/05 23:45:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5610,	0.8488 s / batch. (data: 3.23e-04). ETA=7:06:00, max mem: 20.9 GB 
[12/05 23:47:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7299,	0.8360 s / batch. (data: 1.11e-03). ETA=6:58:11, max mem: 20.9 GB 
[12/05 23:49:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0928,	0.8645 s / batch. (data: 7.98e-03). ETA=7:11:02, max mem: 20.9 GB 
[12/05 23:50:07][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 3.03e-01, avg batch time: 1.1357, average train loss: 0.7486
[12/05 23:51:13][INFO] visual_prompt:  316: Inference (val):avg data time: 5.53e-05, avg batch time: 0.3089, average loss: 0.7006
[12/05 23:51:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[12/05 23:51:13][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[12/05 23:53:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6885,	0.8324 s / batch. (data: 4.45e-03). ETA=6:52:52, max mem: 20.9 GB 
[12/05 23:55:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6934,	0.8512 s / batch. (data: 2.13e-02). ETA=7:00:49, max mem: 20.9 GB 
[12/05 23:56:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8040,	0.8533 s / batch. (data: 8.34e-04). ETA=7:00:24, max mem: 20.9 GB 
[12/05 23:58:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6061,	0.8204 s / batch. (data: 3.52e-04). ETA=6:42:51, max mem: 20.9 GB 
[12/06 00:00:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6369,	0.8450 s / batch. (data: 5.52e-03). ETA=6:53:31, max mem: 20.9 GB 
[12/06 00:01:40][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 3.02e-01, avg batch time: 1.1345, average train loss: 0.7348
[12/06 00:02:47][INFO] visual_prompt:  316: Inference (val):avg data time: 5.37e-05, avg batch time: 0.3111, average loss: 0.7785
[12/06 00:02:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.70	
[12/06 00:02:47][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[12/06 00:04:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7700,	0.8300 s / batch. (data: 2.11e-04). ETA=6:44:02, max mem: 20.9 GB 
[12/06 00:06:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7895,	0.8615 s / batch. (data: 1.13e-02). ETA=6:57:57, max mem: 20.9 GB 
[12/06 00:08:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7046,	1.5880 s / batch. (data: 7.55e-01). ETA=12:47:45, max mem: 20.9 GB 
[12/06 00:10:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7237,	1.2641 s / batch. (data: 4.18e-01). ETA=10:09:02, max mem: 20.9 GB 
[12/06 00:12:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6944,	0.8266 s / batch. (data: 3.59e-04). ETA=6:36:54, max mem: 20.9 GB 
[12/06 00:13:12][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 2.98e-01, avg batch time: 1.1302, average train loss: 0.7270
[12/06 00:14:19][INFO] visual_prompt:  316: Inference (val):avg data time: 6.08e-05, avg batch time: 0.3113, average loss: 0.6921
[12/06 00:14:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.02	
[12/06 00:14:19][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[12/06 00:16:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6981,	0.8381 s / batch. (data: 1.06e-02). ETA=6:40:17, max mem: 20.9 GB 
[12/06 00:18:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5986,	0.8415 s / batch. (data: 1.13e-02). ETA=6:40:29, max mem: 20.9 GB 
[12/06 00:20:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8896,	0.8279 s / batch. (data: 1.17e-03). ETA=6:32:38, max mem: 20.9 GB 
[12/06 00:21:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7094,	0.8510 s / batch. (data: 1.61e-02). ETA=6:42:11, max mem: 20.9 GB 
[12/06 00:23:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5954,	0.8166 s / batch. (data: 3.37e-04). ETA=6:24:32, max mem: 20.9 GB 
[12/06 00:24:48][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 3.05e-01, avg batch time: 1.1371, average train loss: 0.7211
[12/06 00:25:53][INFO] visual_prompt:  316: Inference (val):avg data time: 4.94e-05, avg batch time: 0.3105, average loss: 0.7125
[12/06 00:25:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.78	
[12/06 00:25:53][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[12/06 00:27:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8036,	0.8400 s / batch. (data: 1.03e-03). ETA=6:33:26, max mem: 20.9 GB 
[12/06 00:29:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6952,	0.8243 s / batch. (data: 3.49e-04). ETA=6:24:42, max mem: 20.9 GB 
[12/06 00:31:39][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8076,	0.8292 s / batch. (data: 3.48e-04). ETA=6:25:37, max mem: 20.9 GB 
[12/06 00:33:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6585,	0.8400 s / batch. (data: 3.33e-04). ETA=6:29:14, max mem: 20.9 GB 
[12/06 00:35:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6939,	0.8405 s / batch. (data: 8.46e-04). ETA=6:28:04, max mem: 20.9 GB 
[12/06 00:36:22][INFO] visual_prompt:  217: Epoch 50 / 100: avg data time: 3.05e-01, avg batch time: 1.1363, average train loss: 0.7186
[12/06 00:37:30][INFO] visual_prompt:  316: Inference (val):avg data time: 5.71e-05, avg batch time: 0.3090, average loss: 0.6883
[12/06 00:37:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.41	
[12/06 00:37:30][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[12/06 00:39:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6971,	1.5358 s / batch. (data: 6.97e-01). ETA=11:45:10, max mem: 20.9 GB 
[12/06 00:41:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5786,	0.8376 s / batch. (data: 1.06e-02). ETA=6:23:10, max mem: 20.9 GB 
[12/06 00:43:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7544,	2.1970 s / batch. (data: 1.35e+00). ETA=16:41:29, max mem: 20.9 GB 
[12/06 00:45:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8711,	1.8599 s / batch. (data: 1.01e+00). ETA=14:04:43, max mem: 20.9 GB 
[12/06 00:47:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6790,	0.8313 s / batch. (data: 7.11e-04). ETA=6:16:08, max mem: 20.9 GB 
[12/06 00:48:03][INFO] visual_prompt:  217: Epoch 51 / 100: avg data time: 3.13e-01, avg batch time: 1.1446, average train loss: 0.7075
[12/06 00:49:09][INFO] visual_prompt:  316: Inference (val):avg data time: 5.44e-05, avg batch time: 0.3109, average loss: 0.6923
[12/06 00:49:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.65	
[12/06 00:49:09][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[12/06 00:51:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6983,	0.8269 s / batch. (data: 8.57e-04). ETA=6:12:05, max mem: 20.9 GB 
[12/06 00:53:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7498,	0.8510 s / batch. (data: 3.42e-04). ETA=6:21:30, max mem: 20.9 GB 
[12/06 00:54:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0877,	0.8156 s / batch. (data: 3.08e-04). ETA=6:04:16, max mem: 20.9 GB 
[12/06 00:56:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2293,	0.8575 s / batch. (data: 5.59e-03). ETA=6:21:33, max mem: 20.9 GB 
[12/06 00:58:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3295,	0.8303 s / batch. (data: 5.33e-04). ETA=6:08:04, max mem: 20.9 GB 
[12/06 00:59:37][INFO] visual_prompt:  217: Epoch 52 / 100: avg data time: 3.03e-01, avg batch time: 1.1356, average train loss: 0.7140
[12/06 01:00:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.07e-04, avg batch time: 0.3120, average loss: 0.6886
[12/06 01:00:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.45	
[12/06 01:00:44][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[12/06 01:02:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6933,	0.8307 s / batch. (data: 5.51e-03). ETA=6:06:07, max mem: 20.9 GB 
[12/06 01:04:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6126,	0.8369 s / batch. (data: 8.50e-04). ETA=6:07:27, max mem: 20.9 GB 
[12/06 01:06:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7796,	0.8681 s / batch. (data: 5.45e-04). ETA=6:19:41, max mem: 20.9 GB 
[12/06 01:08:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6196,	1.3280 s / batch. (data: 4.92e-01). ETA=9:38:39, max mem: 20.9 GB 
[12/06 01:10:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7754,	0.8241 s / batch. (data: 9.11e-03). ETA=5:57:43, max mem: 20.9 GB 
[12/06 01:11:15][INFO] visual_prompt:  217: Epoch 53 / 100: avg data time: 3.08e-01, avg batch time: 1.1408, average train loss: 0.7110
[12/06 01:12:21][INFO] visual_prompt:  316: Inference (val):avg data time: 5.51e-05, avg batch time: 0.3102, average loss: 0.7336
[12/06 01:12:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.94	
[12/06 01:12:21][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[12/06 01:14:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6907,	0.8424 s / batch. (data: 1.87e-02). ETA=6:03:30, max mem: 20.9 GB 
[12/06 01:16:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8765,	0.8636 s / batch. (data: 1.20e-03). ETA=6:11:13, max mem: 20.9 GB 
[12/06 01:18:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5391,	1.4497 s / batch. (data: 6.20e-01). ETA=10:20:44, max mem: 20.9 GB 
[12/06 01:20:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5725,	0.8812 s / batch. (data: 5.45e-03). ETA=6:15:51, max mem: 20.9 GB 
[12/06 01:21:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7692,	0.8617 s / batch. (data: 2.25e-03). ETA=6:06:05, max mem: 20.9 GB 
[12/06 01:22:53][INFO] visual_prompt:  217: Epoch 54 / 100: avg data time: 3.10e-01, avg batch time: 1.1419, average train loss: 0.7174
[12/06 01:24:00][INFO] visual_prompt:  316: Inference (val):avg data time: 5.89e-05, avg batch time: 0.3097, average loss: 0.7027
[12/06 01:24:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.49	
[12/06 01:24:00][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[12/06 01:25:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5440,	0.8160 s / batch. (data: 4.01e-04). ETA=5:44:35, max mem: 20.9 GB 
[12/06 01:27:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8228,	0.8436 s / batch. (data: 6.07e-03). ETA=5:54:51, max mem: 20.9 GB 
[12/06 01:29:44][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7059,	0.8160 s / batch. (data: 3.50e-04). ETA=5:41:53, max mem: 20.9 GB 
[12/06 01:31:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7232,	0.8446 s / batch. (data: 1.06e-02). ETA=5:52:26, max mem: 20.9 GB 
[12/06 01:33:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5736,	0.8204 s / batch. (data: 3.77e-04). ETA=5:40:59, max mem: 20.9 GB 
[12/06 01:34:30][INFO] visual_prompt:  217: Epoch 55 / 100: avg data time: 3.08e-01, avg batch time: 1.1396, average train loss: 0.7140
[12/06 01:35:37][INFO] visual_prompt:  316: Inference (val):avg data time: 7.12e-05, avg batch time: 0.3108, average loss: 0.7568
[12/06 01:35:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.50	
[12/06 01:35:37][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 0.05
[12/06 01:37:36][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5743,	0.8167 s / batch. (data: 3.59e-04). ETA=5:37:21, max mem: 20.9 GB 
[12/06 01:39:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6604,	0.8456 s / batch. (data: 1.83e-02). ETA=5:47:53, max mem: 20.9 GB 
[12/06 01:41:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8273,	0.8432 s / batch. (data: 2.19e-03). ETA=5:45:29, max mem: 20.9 GB 
[12/06 01:43:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6922,	0.8408 s / batch. (data: 8.35e-04). ETA=5:43:07, max mem: 20.9 GB 
[12/06 01:45:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7116,	2.9771 s / batch. (data: 2.16e+00). ETA=20:09:56, max mem: 20.9 GB 
[12/06 01:46:06][INFO] visual_prompt:  217: Epoch 56 / 100: avg data time: 3.04e-01, avg batch time: 1.1371, average train loss: 0.7259
[12/06 01:47:12][INFO] visual_prompt:  316: Inference (val):avg data time: 1.62e-04, avg batch time: 0.3104, average loss: 0.7514
[12/06 01:47:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.77	
[12/06 01:47:12][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[12/06 01:49:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7456,	0.8601 s / batch. (data: 3.86e-02). ETA=5:47:21, max mem: 20.9 GB 
[12/06 01:51:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7603,	0.8256 s / batch. (data: 6.09e-03). ETA=5:32:03, max mem: 20.9 GB 
[12/06 01:52:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6697,	2.6559 s / batch. (data: 1.83e+00). ETA=17:43:46, max mem: 20.9 GB 
[12/06 01:54:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7668,	0.8218 s / batch. (data: 3.70e-04). ETA=5:27:47, max mem: 20.9 GB 
[12/06 01:56:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7879,	0.8405 s / batch. (data: 3.05e-04). ETA=5:33:51, max mem: 20.9 GB 
[12/06 01:57:40][INFO] visual_prompt:  217: Epoch 57 / 100: avg data time: 3.02e-01, avg batch time: 1.1348, average train loss: 0.7076
[12/06 01:58:46][INFO] visual_prompt:  316: Inference (val):avg data time: 6.46e-04, avg batch time: 0.3111, average loss: 0.7448
[12/06 01:58:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.10	
[12/06 01:58:46][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[12/06 02:00:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5669,	0.9356 s / batch. (data: 1.09e-01). ETA=6:09:14, max mem: 20.9 GB 
[12/06 02:02:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7520,	0.8357 s / batch. (data: 1.08e-02). ETA=5:28:25, max mem: 20.9 GB 
[12/06 02:04:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6367,	0.8240 s / batch. (data: 3.63e-04). ETA=5:22:26, max mem: 20.9 GB 
[12/06 02:06:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6933,	0.8320 s / batch. (data: 3.63e-04). ETA=5:24:11, max mem: 20.9 GB 
[12/06 02:08:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4982,	0.8167 s / batch. (data: 3.60e-04). ETA=5:16:51, max mem: 20.9 GB 
[12/06 02:09:16][INFO] visual_prompt:  217: Epoch 58 / 100: avg data time: 3.06e-01, avg batch time: 1.1381, average train loss: 0.7076
[12/06 02:10:22][INFO] visual_prompt:  316: Inference (val):avg data time: 5.20e-05, avg batch time: 0.3117, average loss: 0.6955
[12/06 02:10:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.05	
[12/06 02:10:22][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[12/06 02:12:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6555,	0.8535 s / batch. (data: 1.33e-02). ETA=5:28:58, max mem: 20.9 GB 
[12/06 02:14:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5385,	0.8226 s / batch. (data: 6.93e-04). ETA=5:15:41, max mem: 20.9 GB 
[12/06 02:16:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5627,	0.8480 s / batch. (data: 3.84e-04). ETA=5:24:00, max mem: 20.9 GB 
[12/06 02:17:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7599,	1.1639 s / batch. (data: 3.30e-01). ETA=7:22:47, max mem: 20.9 GB 
[12/06 02:19:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7786,	0.8288 s / batch. (data: 8.48e-04). ETA=5:13:55, max mem: 20.9 GB 
[12/06 02:20:51][INFO] visual_prompt:  217: Epoch 59 / 100: avg data time: 3.03e-01, avg batch time: 1.1371, average train loss: 0.7090
[12/06 02:21:58][INFO] visual_prompt:  316: Inference (val):avg data time: 6.32e-05, avg batch time: 0.3100, average loss: 0.6876
[12/06 02:21:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.90	
[12/06 02:21:58][INFO] visual_prompt:   36: Best epoch 59: best metric: -0.688
[12/06 02:21:58][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[12/06 02:23:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8796,	0.8280 s / batch. (data: 3.96e-04). ETA=5:11:29, max mem: 20.9 GB 
[12/06 02:25:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7007,	0.8481 s / batch. (data: 9.06e-03). ETA=5:17:38, max mem: 20.9 GB 
[12/06 02:27:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4380,	2.8798 s / batch. (data: 2.06e+00). ETA=17:53:50, max mem: 20.9 GB 
[12/06 02:29:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8006,	1.3440 s / batch. (data: 5.24e-01). ETA=8:18:55, max mem: 20.9 GB 
[12/06 02:31:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6435,	0.8309 s / batch. (data: 1.56e-02). ETA=5:07:03, max mem: 20.9 GB 
[12/06 02:32:26][INFO] visual_prompt:  217: Epoch 60 / 100: avg data time: 3.04e-01, avg batch time: 1.1364, average train loss: 0.7152
[12/06 02:33:32][INFO] visual_prompt:  316: Inference (val):avg data time: 5.82e-05, avg batch time: 0.3099, average loss: 0.6788
[12/06 02:33:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.44	
[12/06 02:33:32][INFO] visual_prompt:   36: Best epoch 60: best metric: -0.679
[12/06 02:33:32][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[12/06 02:35:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6703,	0.8160 s / batch. (data: 3.61e-04). ETA=4:59:28, max mem: 20.9 GB 
[12/06 02:37:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7674,	2.2083 s / batch. (data: 1.39e+00). ETA=13:26:45, max mem: 20.9 GB 
[12/06 02:39:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8071,	1.7129 s / batch. (data: 8.71e-01). ETA=10:22:55, max mem: 20.9 GB 
[12/06 02:41:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6790,	0.9432 s / batch. (data: 1.09e-01). ETA=5:41:25, max mem: 20.9 GB 
[12/06 02:43:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6982,	3.4528 s / batch. (data: 2.62e+00). ETA=20:44:09, max mem: 20.9 GB 
[12/06 02:44:00][INFO] visual_prompt:  217: Epoch 61 / 100: avg data time: 3.02e-01, avg batch time: 1.1340, average train loss: 0.7039
[12/06 02:45:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-04, avg batch time: 0.3099, average loss: 0.6965
[12/06 02:45:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.82	
[12/06 02:45:05][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[12/06 02:47:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7193,	0.8484 s / batch. (data: 1.89e-03). ETA=5:03:31, max mem: 20.9 GB 
[12/06 02:48:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7465,	0.8398 s / batch. (data: 6.79e-04). ETA=4:59:04, max mem: 20.9 GB 
[12/06 02:50:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6063,	0.8320 s / batch. (data: 7.93e-03). ETA=4:54:53, max mem: 20.9 GB 
[12/06 02:52:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6456,	0.8306 s / batch. (data: 5.74e-03). ETA=4:53:01, max mem: 20.9 GB 
[12/06 02:54:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6953,	0.8405 s / batch. (data: 3.47e-04). ETA=4:55:06, max mem: 20.9 GB 
[12/06 02:55:33][INFO] visual_prompt:  217: Epoch 62 / 100: avg data time: 3.03e-01, avg batch time: 1.1354, average train loss: 0.7073
[12/06 02:56:39][INFO] visual_prompt:  316: Inference (val):avg data time: 2.79e-04, avg batch time: 0.3110, average loss: 0.6878
[12/06 02:56:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.84	
[12/06 02:56:39][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[12/06 02:58:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6921,	0.8479 s / batch. (data: 1.19e-02). ETA=4:55:33, max mem: 20.9 GB 
[12/06 03:00:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7003,	0.8499 s / batch. (data: 5.49e-03). ETA=4:54:50, max mem: 20.9 GB 
[12/06 03:02:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6771,	0.9001 s / batch. (data: 1.21e-02). ETA=5:10:44, max mem: 20.9 GB 
[12/06 03:04:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6100,	0.8288 s / batch. (data: 3.62e-04). ETA=4:44:43, max mem: 20.9 GB 
[12/06 03:06:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5255,	0.8480 s / batch. (data: 3.28e-04). ETA=4:49:56, max mem: 20.9 GB 
[12/06 03:07:08][INFO] visual_prompt:  217: Epoch 63 / 100: avg data time: 3.03e-01, avg batch time: 1.1366, average train loss: 0.7010
[12/06 03:08:13][INFO] visual_prompt:  316: Inference (val):avg data time: 5.90e-05, avg batch time: 0.3096, average loss: 0.6911
[12/06 03:08:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.62	
[12/06 03:08:13][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[12/06 03:10:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8437,	0.8564 s / batch. (data: 8.60e-04). ETA=4:50:36, max mem: 20.9 GB 
[12/06 03:12:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6842,	0.8440 s / batch. (data: 1.05e-02). ETA=4:44:59, max mem: 20.9 GB 
[12/06 03:13:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5233,	0.8440 s / batch. (data: 3.55e-04). ETA=4:43:35, max mem: 20.9 GB 
[12/06 03:15:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6871,	1.2326 s / batch. (data: 3.99e-01). ETA=6:52:06, max mem: 20.9 GB 
[12/06 03:17:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5603,	0.8573 s / batch. (data: 5.43e-03). ETA=4:45:11, max mem: 20.9 GB 
[12/06 03:18:43][INFO] visual_prompt:  217: Epoch 64 / 100: avg data time: 3.04e-01, avg batch time: 1.1374, average train loss: 0.7083
[12/06 03:19:49][INFO] visual_prompt:  316: Inference (val):avg data time: 5.91e-05, avg batch time: 0.3114, average loss: 0.6886
[12/06 03:19:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.79	
[12/06 03:19:49][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[12/06 03:21:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7370,	1.1179 s / batch. (data: 3.04e-01). ETA=6:09:03, max mem: 20.9 GB 
[12/06 03:23:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9248,	2.0480 s / batch. (data: 1.21e+00). ETA=11:12:41, max mem: 20.9 GB 
[12/06 03:25:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7521,	2.0277 s / batch. (data: 1.18e+00). ETA=11:02:38, max mem: 20.9 GB 
[12/06 03:27:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7131,	0.8507 s / batch. (data: 1.19e-02). ETA=4:36:35, max mem: 20.9 GB 
[12/06 03:29:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7658,	0.8194 s / batch. (data: 3.31e-04). ETA=4:25:03, max mem: 20.9 GB 
[12/06 03:30:17][INFO] visual_prompt:  217: Epoch 65 / 100: avg data time: 3.02e-01, avg batch time: 1.1348, average train loss: 0.7045
[12/06 03:31:24][INFO] visual_prompt:  316: Inference (val):avg data time: 6.58e-05, avg batch time: 0.3113, average loss: 0.6945
[12/06 03:31:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.11	
[12/06 03:31:24][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[12/06 03:33:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6853,	0.8152 s / batch. (data: 6.34e-04). ETA=4:21:36, max mem: 20.9 GB 
[12/06 03:35:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5670,	2.0293 s / batch. (data: 1.22e+00). ETA=10:47:51, max mem: 20.9 GB 
[12/06 03:37:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7208,	0.8336 s / batch. (data: 8.29e-04). ETA=4:24:43, max mem: 20.9 GB 
[12/06 03:39:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5719,	0.8501 s / batch. (data: 5.45e-03). ETA=4:28:33, max mem: 20.9 GB 
[12/06 03:40:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6654,	0.8471 s / batch. (data: 2.57e-02). ETA=4:26:12, max mem: 20.9 GB 
[12/06 03:41:53][INFO] visual_prompt:  217: Epoch 66 / 100: avg data time: 3.06e-01, avg batch time: 1.1383, average train loss: 0.7026
[12/06 03:43:00][INFO] visual_prompt:  316: Inference (val):avg data time: 6.51e-05, avg batch time: 0.3114, average loss: 0.6973
[12/06 03:43:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.93	
[12/06 03:43:00][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[12/06 03:45:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5923,	0.8810 s / batch. (data: 5.08e-02). ETA=4:34:35, max mem: 20.9 GB 
[12/06 03:46:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4781,	0.8229 s / batch. (data: 5.35e-04). ETA=4:15:08, max mem: 20.9 GB 
[12/06 03:48:44][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6979,	0.8371 s / batch. (data: 6.00e-03). ETA=4:18:07, max mem: 20.9 GB 
[12/06 03:50:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7418,	0.8240 s / batch. (data: 3.39e-04). ETA=4:12:43, max mem: 20.9 GB 
[12/06 03:52:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6958,	1.1925 s / batch. (data: 3.75e-01). ETA=6:03:44, max mem: 20.9 GB 
[12/06 03:53:28][INFO] visual_prompt:  217: Epoch 67 / 100: avg data time: 3.02e-01, avg batch time: 1.1344, average train loss: 0.6985
[12/06 03:54:34][INFO] visual_prompt:  316: Inference (val):avg data time: 5.88e-05, avg batch time: 0.3105, average loss: 0.6805
[12/06 03:54:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.88	
[12/06 03:54:34][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 0.02966316784621
[12/06 03:56:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7141,	0.8295 s / batch. (data: 4.10e-04). ETA=4:10:53, max mem: 20.9 GB 
[12/06 03:58:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6907,	1.7039 s / batch. (data: 8.76e-01). ETA=8:32:32, max mem: 20.9 GB 
[12/06 04:00:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6774,	0.8576 s / batch. (data: 3.87e-04). ETA=4:16:32, max mem: 20.9 GB 
[12/06 04:02:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6584,	0.8729 s / batch. (data: 3.29e-02). ETA=4:19:41, max mem: 20.9 GB 
[12/06 04:04:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6950,	0.8256 s / batch. (data: 7.58e-04). ETA=4:04:13, max mem: 20.9 GB 
[12/06 04:05:12][INFO] visual_prompt:  217: Epoch 68 / 100: avg data time: 3.20e-01, avg batch time: 1.1524, average train loss: 0.7021
[12/06 04:06:22][INFO] visual_prompt:  316: Inference (val):avg data time: 6.00e-05, avg batch time: 0.3114, average loss: 0.6763
[12/06 04:06:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.34	
[12/06 04:06:22][INFO] visual_prompt:   36: Best epoch 68: best metric: -0.676
[12/06 04:06:22][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[12/06 04:08:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7092,	0.8319 s / batch. (data: 4.91e-04). ETA=4:03:58, max mem: 20.9 GB 
[12/06 04:10:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7849,	0.8407 s / batch. (data: 7.93e-03). ETA=4:05:08, max mem: 20.9 GB 
[12/06 04:12:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5754,	0.8180 s / batch. (data: 3.27e-04). ETA=3:57:10, max mem: 20.9 GB 
[12/06 04:14:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6244,	0.8387 s / batch. (data: 8.93e-04). ETA=4:01:46, max mem: 20.9 GB 
[12/06 04:15:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9121,	0.8425 s / batch. (data: 7.90e-03). ETA=4:01:27, max mem: 20.9 GB 
[12/06 04:16:56][INFO] visual_prompt:  217: Epoch 69 / 100: avg data time: 3.14e-01, avg batch time: 1.1458, average train loss: 0.6989
[12/06 04:18:03][INFO] visual_prompt:  316: Inference (val):avg data time: 6.29e-05, avg batch time: 0.3105, average loss: 0.6932
[12/06 04:18:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.10	
[12/06 04:18:03][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[12/06 04:20:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6286,	0.8150 s / batch. (data: 3.66e-04). ETA=3:51:30, max mem: 20.9 GB 
[12/06 04:21:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8597,	1.5440 s / batch. (data: 6.81e-01). ETA=7:16:00, max mem: 20.9 GB 
[12/06 04:23:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7000,	1.9116 s / batch. (data: 1.04e+00). ETA=8:56:37, max mem: 20.9 GB 
[12/06 04:25:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6963,	1.4369 s / batch. (data: 6.07e-01). ETA=6:40:57, max mem: 20.9 GB 
[12/06 04:27:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7620,	0.8282 s / batch. (data: 1.19e-02). ETA=3:49:43, max mem: 20.9 GB 
[12/06 04:28:33][INFO] visual_prompt:  217: Epoch 70 / 100: avg data time: 3.05e-01, avg batch time: 1.1378, average train loss: 0.6949
[12/06 04:29:39][INFO] visual_prompt:  316: Inference (val):avg data time: 6.42e-05, avg batch time: 0.3110, average loss: 0.6806
[12/06 04:29:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.64	
[12/06 04:29:39][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[12/06 04:31:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7036,	0.8337 s / batch. (data: 8.17e-04). ETA=3:49:08, max mem: 20.9 GB 
[12/06 04:33:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6958,	0.8547 s / batch. (data: 9.86e-04). ETA=3:53:27, max mem: 20.9 GB 
[12/06 04:35:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9983,	0.8384 s / batch. (data: 9.19e-03). ETA=3:47:37, max mem: 20.9 GB 
[12/06 04:37:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6709,	0.8438 s / batch. (data: 5.85e-03). ETA=3:47:41, max mem: 20.9 GB 
[12/06 04:39:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7471,	0.8220 s / batch. (data: 5.46e-04). ETA=3:40:26, max mem: 20.9 GB 
[12/06 04:40:07][INFO] visual_prompt:  217: Epoch 71 / 100: avg data time: 3.03e-01, avg batch time: 1.1358, average train loss: 0.6908
[12/06 04:41:14][INFO] visual_prompt:  316: Inference (val):avg data time: 6.84e-05, avg batch time: 0.3096, average loss: 0.6776
[12/06 04:41:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 61.35	
[12/06 04:41:14][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[12/06 04:43:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8574,	1.2770 s / batch. (data: 4.57e-01). ETA=5:39:11, max mem: 20.9 GB 
[12/06 04:45:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6592,	0.8362 s / batch. (data: 3.28e-04). ETA=3:40:42, max mem: 20.9 GB 
[12/06 04:47:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7043,	0.8534 s / batch. (data: 1.18e-02). ETA=3:43:49, max mem: 20.9 GB 
[12/06 04:48:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7173,	2.7403 s / batch. (data: 1.93e+00). ETA=11:54:09, max mem: 20.9 GB 
[12/06 04:50:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7813,	1.4681 s / batch. (data: 6.24e-01). ETA=6:20:10, max mem: 20.9 GB 
[12/06 04:51:44][INFO] visual_prompt:  217: Epoch 72 / 100: avg data time: 3.05e-01, avg batch time: 1.1389, average train loss: 0.6919
[12/06 04:52:50][INFO] visual_prompt:  316: Inference (val):avg data time: 2.96e-04, avg batch time: 0.3119, average loss: 0.6902
[12/06 04:52:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 56.57	
[12/06 04:52:50][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[12/06 04:54:49][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9547,	0.8280 s / batch. (data: 6.20e-04). ETA=3:32:17, max mem: 20.9 GB 
[12/06 04:56:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7600,	0.8336 s / batch. (data: 3.84e-04). ETA=3:32:20, max mem: 20.9 GB 
[12/06 04:58:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6991,	0.8457 s / batch. (data: 3.48e-04). ETA=3:34:00, max mem: 20.9 GB 
[12/06 05:00:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6919,	0.8283 s / batch. (data: 3.37e-04). ETA=3:28:13, max mem: 20.9 GB 
[12/06 05:02:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6324,	0.8289 s / batch. (data: 1.00e-03). ETA=3:27:00, max mem: 20.9 GB 
[12/06 05:03:22][INFO] visual_prompt:  217: Epoch 73 / 100: avg data time: 3.09e-01, avg batch time: 1.1418, average train loss: 0.6958
[12/06 05:04:28][INFO] visual_prompt:  316: Inference (val):avg data time: 6.06e-04, avg batch time: 0.3108, average loss: 0.7087
[12/06 05:04:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.20	
[12/06 05:04:28][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[12/06 05:06:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7448,	0.8463 s / batch. (data: 1.06e-02). ETA=3:29:11, max mem: 20.9 GB 
[12/06 05:08:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7212,	0.8200 s / batch. (data: 3.28e-04). ETA=3:21:19, max mem: 20.9 GB 
[12/06 05:10:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6140,	0.8210 s / batch. (data: 1.37e-03). ETA=3:20:11, max mem: 20.9 GB 
[12/06 05:12:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6774,	1.4021 s / batch. (data: 5.79e-01). ETA=5:39:34, max mem: 20.9 GB 
[12/06 05:14:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6174,	2.3055 s / batch. (data: 1.48e+00). ETA=9:14:30, max mem: 20.9 GB 
[12/06 05:15:00][INFO] visual_prompt:  217: Epoch 74 / 100: avg data time: 3.11e-01, avg batch time: 1.1427, average train loss: 0.6879
[12/06 05:16:07][INFO] visual_prompt:  316: Inference (val):avg data time: 6.34e-05, avg batch time: 0.3103, average loss: 0.7188
[12/06 05:16:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.02	
[12/06 05:16:07][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[12/06 05:18:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7188,	2.2841 s / batch. (data: 1.47e+00). ETA=9:03:32, max mem: 20.9 GB 
[12/06 05:19:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8529,	0.8760 s / batch. (data: 3.04e-02). ETA=3:26:59, max mem: 20.9 GB 
[12/06 05:21:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9304,	0.8634 s / batch. (data: 1.14e-02). ETA=3:22:35, max mem: 20.9 GB 
[12/06 05:23:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9307,	2.9647 s / batch. (data: 2.15e+00). ETA=11:30:40, max mem: 20.9 GB 
[12/06 05:25:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6899,	0.8334 s / batch. (data: 1.71e-02). ETA=3:12:46, max mem: 20.9 GB 
[12/06 05:26:37][INFO] visual_prompt:  217: Epoch 75 / 100: avg data time: 3.07e-01, avg batch time: 1.1399, average train loss: 0.6735
[12/06 05:27:44][INFO] visual_prompt:  316: Inference (val):avg data time: 5.43e-05, avg batch time: 0.3122, average loss: 0.6614
[12/06 05:27:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.96	
[12/06 05:27:44][INFO] visual_prompt:   36: Best epoch 75: best metric: -0.661
[12/06 05:27:44][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[12/06 05:29:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7565,	0.8639 s / batch. (data: 1.58e-03). ETA=3:17:36, max mem: 20.9 GB 
[12/06 05:31:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6462,	1.3676 s / batch. (data: 5.25e-01). ETA=5:10:33, max mem: 20.9 GB 
[12/06 05:33:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6715,	0.8600 s / batch. (data: 3.50e-04). ETA=3:13:51, max mem: 20.9 GB 
[12/06 05:35:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6525,	0.8264 s / batch. (data: 6.41e-04). ETA=3:04:54, max mem: 20.9 GB 
[12/06 05:37:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6854,	0.8289 s / batch. (data: 3.88e-04). ETA=3:04:04, max mem: 20.9 GB 
[12/06 05:38:12][INFO] visual_prompt:  217: Epoch 76 / 100: avg data time: 3.04e-01, avg batch time: 1.1362, average train loss: 0.6777
[12/06 05:39:18][INFO] visual_prompt:  316: Inference (val):avg data time: 5.46e-05, avg batch time: 0.3110, average loss: 0.6805
[12/06 05:39:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.30	
[12/06 05:39:18][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[12/06 05:41:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6712,	1.0605 s / batch. (data: 2.15e-01). ETA=3:52:49, max mem: 20.9 GB 
[12/06 05:43:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7635,	0.8362 s / batch. (data: 4.90e-04). ETA=3:02:10, max mem: 20.9 GB 
[12/06 05:45:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4972,	0.8444 s / batch. (data: 1.30e-03). ETA=3:02:34, max mem: 20.9 GB 
[12/06 05:46:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5201,	0.8380 s / batch. (data: 3.35e-04). ETA=2:59:47, max mem: 20.9 GB 
[12/06 05:48:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5457,	0.8481 s / batch. (data: 1.20e-02). ETA=3:00:32, max mem: 20.9 GB 
[12/06 05:49:47][INFO] visual_prompt:  217: Epoch 77 / 100: avg data time: 3.03e-01, avg batch time: 1.1359, average train loss: 0.6717
[12/06 05:50:52][INFO] visual_prompt:  316: Inference (val):avg data time: 5.29e-05, avg batch time: 0.3129, average loss: 0.6536
[12/06 05:50:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.37	
[12/06 05:50:52][INFO] visual_prompt:   36: Best epoch 77: best metric: -0.654
[12/06 05:50:52][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[12/06 05:52:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5959,	0.8514 s / batch. (data: 6.97e-03). ETA=2:59:03, max mem: 20.9 GB 
[12/06 05:54:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7070,	0.8576 s / batch. (data: 9.70e-03). ETA=2:58:56, max mem: 20.9 GB 
[12/06 05:56:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0342,	0.8319 s / batch. (data: 5.99e-03). ETA=2:52:11, max mem: 20.9 GB 
[12/06 05:58:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7616,	0.8321 s / batch. (data: 3.18e-04). ETA=2:50:50, max mem: 20.9 GB 
[12/06 06:00:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7834,	0.8459 s / batch. (data: 7.97e-03). ETA=2:52:15, max mem: 20.9 GB 
[12/06 06:01:21][INFO] visual_prompt:  217: Epoch 78 / 100: avg data time: 3.03e-01, avg batch time: 1.1361, average train loss: 0.6668
[12/06 06:02:27][INFO] visual_prompt:  316: Inference (val):avg data time: 5.90e-05, avg batch time: 0.3103, average loss: 0.6347
[12/06 06:02:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.74	
[12/06 06:02:27][INFO] visual_prompt:   36: Best epoch 78: best metric: -0.635
[12/06 06:02:27][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[12/06 06:04:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6211,	0.8367 s / batch. (data: 7.75e-03). ETA=2:48:15, max mem: 20.9 GB 
[12/06 06:06:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7305,	0.8260 s / batch. (data: 3.93e-04). ETA=2:44:44, max mem: 20.9 GB 
[12/06 06:08:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7718,	1.1640 s / batch. (data: 3.33e-01). ETA=3:50:11, max mem: 20.9 GB 
[12/06 06:10:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4233,	0.8456 s / batch. (data: 9.29e-03). ETA=2:45:49, max mem: 20.9 GB 
[12/06 06:11:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9876,	0.8358 s / batch. (data: 9.08e-04). ETA=2:42:30, max mem: 20.9 GB 
[12/06 06:12:56][INFO] visual_prompt:  217: Epoch 79 / 100: avg data time: 3.05e-01, avg batch time: 1.1374, average train loss: 0.6712
[12/06 06:14:02][INFO] visual_prompt:  316: Inference (val):avg data time: 2.05e-04, avg batch time: 0.3117, average loss: 0.6835
[12/06 06:14:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.01	
[12/06 06:14:02][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[12/06 06:16:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5097,	0.8305 s / batch. (data: 7.88e-03). ETA=2:39:21, max mem: 20.9 GB 
[12/06 06:17:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4569,	0.8451 s / batch. (data: 7.85e-03). ETA=2:40:45, max mem: 20.9 GB 
[12/06 06:19:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7191,	1.8309 s / batch. (data: 9.97e-01). ETA=5:45:13, max mem: 20.9 GB 
[12/06 06:21:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7242,	0.8402 s / batch. (data: 7.95e-03). ETA=2:37:01, max mem: 20.9 GB 
[12/06 06:23:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6859,	0.8243 s / batch. (data: 7.96e-03). ETA=2:32:40, max mem: 20.9 GB 
[12/06 06:24:32][INFO] visual_prompt:  217: Epoch 80 / 100: avg data time: 3.06e-01, avg batch time: 1.1396, average train loss: 0.6637
[12/06 06:25:39][INFO] visual_prompt:  316: Inference (val):avg data time: 6.48e-05, avg batch time: 0.3104, average loss: 0.6688
[12/06 06:25:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.25	
[12/06 06:25:39][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[12/06 06:27:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8274,	0.8552 s / batch. (data: 1.16e-03). ETA=2:36:12, max mem: 20.9 GB 
[12/06 06:29:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6060,	0.8553 s / batch. (data: 1.10e-02). ETA=2:34:48, max mem: 20.9 GB 
[12/06 06:31:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3658,	0.8468 s / batch. (data: 6.82e-03). ETA=2:31:51, max mem: 20.9 GB 
[12/06 06:33:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7089,	1.8191 s / batch. (data: 9.97e-01). ETA=5:23:11, max mem: 20.9 GB 
[12/06 06:35:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8571,	2.6905 s / batch. (data: 1.85e+00). ETA=7:53:31, max mem: 20.9 GB 
[12/06 06:36:07][INFO] visual_prompt:  217: Epoch 81 / 100: avg data time: 3.02e-01, avg batch time: 1.1351, average train loss: 0.6597
[12/06 06:37:13][INFO] visual_prompt:  316: Inference (val):avg data time: 5.35e-05, avg batch time: 0.3113, average loss: 0.6753
[12/06 06:37:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 66.01	
[12/06 06:37:13][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[12/06 06:39:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4420,	0.8187 s / batch. (data: 8.96e-04). ETA=2:22:00, max mem: 20.9 GB 
[12/06 06:41:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8722,	1.0150 s / batch. (data: 1.91e-01). ETA=2:54:21, max mem: 20.9 GB 
[12/06 06:42:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8388,	2.5465 s / batch. (data: 1.73e+00). ETA=7:13:12, max mem: 20.9 GB 
[12/06 06:44:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4906,	1.9634 s / batch. (data: 1.14e+00). ETA=5:30:43, max mem: 20.9 GB 
[12/06 06:46:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5209,	0.8374 s / batch. (data: 2.21e-02). ETA=2:19:39, max mem: 20.9 GB 
[12/06 06:47:41][INFO] visual_prompt:  217: Epoch 82 / 100: avg data time: 3.03e-01, avg batch time: 1.1356, average train loss: 0.6531
[12/06 06:48:47][INFO] visual_prompt:  316: Inference (val):avg data time: 2.36e-04, avg batch time: 0.3106, average loss: 0.6501
[12/06 06:48:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.07	
[12/06 06:48:47][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[12/06 06:50:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8999,	0.8333 s / batch. (data: 5.47e-03). ETA=2:16:51, max mem: 20.9 GB 
[12/06 06:52:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5230,	0.8308 s / batch. (data: 3.59e-04). ETA=2:15:03, max mem: 20.9 GB 
[12/06 06:54:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5984,	0.8347 s / batch. (data: 3.39e-04). ETA=2:14:18, max mem: 20.9 GB 
[12/06 06:56:28][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6221,	0.8570 s / batch. (data: 1.06e-02). ETA=2:16:28, max mem: 20.9 GB 
[12/06 06:58:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7929,	0.8450 s / batch. (data: 6.15e-03). ETA=2:13:08, max mem: 20.9 GB 
[12/06 06:59:19][INFO] visual_prompt:  217: Epoch 83 / 100: avg data time: 3.09e-01, avg batch time: 1.1411, average train loss: 0.6471
[12/06 07:00:25][INFO] visual_prompt:  316: Inference (val):avg data time: 5.53e-05, avg batch time: 0.3107, average loss: 0.6321
[12/06 07:00:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.66	
[12/06 07:00:25][INFO] visual_prompt:   36: Best epoch 83: best metric: -0.632
[12/06 07:00:25][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[12/06 07:02:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5415,	0.8587 s / batch. (data: 5.56e-03). ETA=2:13:06, max mem: 20.9 GB 
[12/06 07:04:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9942,	2.0513 s / batch. (data: 1.23e+00). ETA=5:14:33, max mem: 20.9 GB 
[12/06 07:06:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7721,	0.8593 s / batch. (data: 2.73e-02). ETA=2:10:20, max mem: 20.9 GB 
[12/06 07:08:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8016,	0.8448 s / batch. (data: 8.74e-03). ETA=2:06:43, max mem: 20.9 GB 
[12/06 07:09:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3589,	0.8848 s / batch. (data: 4.57e-02). ETA=2:11:15, max mem: 20.9 GB 
[12/06 07:10:54][INFO] visual_prompt:  217: Epoch 84 / 100: avg data time: 3.05e-01, avg batch time: 1.1381, average train loss: 0.6462
[12/06 07:12:00][INFO] visual_prompt:  316: Inference (val):avg data time: 5.55e-05, avg batch time: 0.3101, average loss: 0.6240
[12/06 07:12:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.71	
[12/06 07:12:00][INFO] visual_prompt:   36: Best epoch 84: best metric: -0.624
[12/06 07:12:00][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[12/06 07:14:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6973,	3.3273 s / batch. (data: 2.50e+00). ETA=8:05:07, max mem: 20.9 GB 
[12/06 07:15:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7142,	0.8369 s / batch. (data: 5.44e-03). ETA=2:00:37, max mem: 20.9 GB 
[12/06 07:17:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5040,	0.8413 s / batch. (data: 1.62e-02). ETA=1:59:51, max mem: 20.9 GB 
[12/06 07:19:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8871,	0.8552 s / batch. (data: 5.48e-03). ETA=2:00:24, max mem: 20.9 GB 
[12/06 07:21:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6254,	0.8681 s / batch. (data: 2.07e-02). ETA=2:00:46, max mem: 20.9 GB 
[12/06 07:22:29][INFO] visual_prompt:  217: Epoch 85 / 100: avg data time: 3.04e-01, avg batch time: 1.1383, average train loss: 0.6350
[12/06 07:23:35][INFO] visual_prompt:  316: Inference (val):avg data time: 5.33e-05, avg batch time: 0.3096, average loss: 0.6468
[12/06 07:23:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 69.48	
[12/06 07:23:35][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[12/06 07:25:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7283,	3.9256 s / batch. (data: 3.09e+00). ETA=8:56:10, max mem: 20.9 GB 
[12/06 07:27:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6758,	0.8373 s / batch. (data: 3.60e-04). ETA=1:52:57, max mem: 20.9 GB 
[12/06 07:29:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7184,	0.8337 s / batch. (data: 1.30e-02). ETA=1:51:05, max mem: 20.9 GB 
[12/06 07:31:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6720,	0.8600 s / batch. (data: 3.97e-04). ETA=1:53:09, max mem: 20.9 GB 
[12/06 07:33:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4566,	0.8414 s / batch. (data: 2.09e-02). ETA=1:49:18, max mem: 20.9 GB 
[12/06 07:34:08][INFO] visual_prompt:  217: Epoch 86 / 100: avg data time: 3.11e-01, avg batch time: 1.1440, average train loss: 0.6298
[12/06 07:35:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.74e-05, avg batch time: 0.3111, average loss: 0.6228
[12/06 07:35:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.15	
[12/06 07:35:14][INFO] visual_prompt:   36: Best epoch 86: best metric: -0.623
[12/06 07:35:14][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[12/06 07:37:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5607,	0.8440 s / batch. (data: 7.97e-03). ETA=1:47:29, max mem: 20.9 GB 
[12/06 07:39:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3773,	0.8547 s / batch. (data: 1.47e-02). ETA=1:47:26, max mem: 20.9 GB 
[12/06 07:41:03][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7283,	2.0715 s / batch. (data: 1.24e+00). ETA=4:16:55, max mem: 20.9 GB 
[12/06 07:42:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6299,	0.8360 s / batch. (data: 3.32e-04). ETA=1:42:18, max mem: 20.9 GB 
[12/06 07:44:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8559,	0.8365 s / batch. (data: 3.34e-04). ETA=1:40:57, max mem: 20.9 GB 
[12/06 07:45:45][INFO] visual_prompt:  217: Epoch 87 / 100: avg data time: 3.09e-01, avg batch time: 1.1413, average train loss: 0.6290
[12/06 07:46:51][INFO] visual_prompt:  316: Inference (val):avg data time: 1.60e-04, avg batch time: 0.3104, average loss: 0.6814
[12/06 07:46:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.24	
[12/06 07:46:51][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[12/06 07:48:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2185,	0.8249 s / batch. (data: 6.84e-04). ETA=1:37:28, max mem: 20.9 GB 
[12/06 07:50:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3917,	0.8184 s / batch. (data: 6.50e-04). ETA=1:35:20, max mem: 20.9 GB 
[12/06 07:52:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2680,	0.8557 s / batch. (data: 1.99e-03). ETA=1:38:14, max mem: 20.9 GB 
[12/06 07:54:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6254,	2.9481 s / batch. (data: 2.14e+00). ETA=5:33:34, max mem: 20.9 GB 
[12/06 07:56:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9874,	2.0796 s / batch. (data: 1.26e+00). ETA=3:51:50, max mem: 20.9 GB 
[12/06 07:57:21][INFO] visual_prompt:  217: Epoch 88 / 100: avg data time: 3.06e-01, avg batch time: 1.1387, average train loss: 0.6257
[12/06 07:58:26][INFO] visual_prompt:  316: Inference (val):avg data time: 5.60e-05, avg batch time: 0.3103, average loss: 0.6612
[12/06 07:58:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.78	
[12/06 07:58:26][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[12/06 08:00:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6868,	0.8240 s / batch. (data: 3.65e-04). ETA=1:29:45, max mem: 20.9 GB 
[12/06 08:02:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6921,	0.8371 s / batch. (data: 1.32e-03). ETA=1:29:47, max mem: 20.9 GB 
[12/06 08:04:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6138,	0.8301 s / batch. (data: 4.30e-04). ETA=1:27:39, max mem: 20.9 GB 
[12/06 08:06:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7889,	0.8170 s / batch. (data: 7.43e-04). ETA=1:24:54, max mem: 20.9 GB 
[12/06 08:08:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6582,	0.8528 s / batch. (data: 1.06e-03). ETA=1:27:13, max mem: 20.9 GB 
[12/06 08:08:58][INFO] visual_prompt:  217: Epoch 89 / 100: avg data time: 3.09e-01, avg batch time: 1.1424, average train loss: 0.6135
[12/06 08:10:04][INFO] visual_prompt:  316: Inference (val):avg data time: 6.99e-05, avg batch time: 0.3124, average loss: 0.6239
[12/06 08:10:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.79	
[12/06 08:10:04][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[12/06 08:12:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7990,	0.8217 s / batch. (data: 1.11e-03). ETA=1:21:56, max mem: 20.9 GB 
[12/06 08:13:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5489,	1.1194 s / batch. (data: 3.03e-01). ETA=1:49:45, max mem: 20.9 GB 
[12/06 08:15:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1753,	0.8280 s / batch. (data: 4.16e-04). ETA=1:19:48, max mem: 20.9 GB 
[12/06 08:17:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9282,	1.2236 s / batch. (data: 4.11e-01). ETA=1:55:53, max mem: 20.9 GB 
[12/06 08:19:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8833,	0.8331 s / batch. (data: 1.03e-02). ETA=1:17:31, max mem: 20.9 GB 
[12/06 08:20:33][INFO] visual_prompt:  217: Epoch 90 / 100: avg data time: 3.03e-01, avg batch time: 1.1360, average train loss: 0.6146
[12/06 08:21:38][INFO] visual_prompt:  316: Inference (val):avg data time: 6.22e-05, avg batch time: 0.3104, average loss: 0.6210
[12/06 08:21:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.79	
[12/06 08:21:38][INFO] visual_prompt:   36: Best epoch 90: best metric: -0.621
[12/06 08:21:38][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[12/06 08:23:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7936,	0.8403 s / batch. (data: 3.37e-04). ETA=1:16:02, max mem: 20.9 GB 
[12/06 08:25:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6832,	0.8653 s / batch. (data: 6.47e-03). ETA=1:16:51, max mem: 20.9 GB 
[12/06 08:27:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9989,	0.8448 s / batch. (data: 5.94e-03). ETA=1:13:38, max mem: 20.9 GB 
[12/06 08:29:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4355,	2.2919 s / batch. (data: 1.46e+00). ETA=3:15:57, max mem: 20.9 GB 
[12/06 08:31:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7587,	1.0880 s / batch. (data: 2.52e-01). ETA=1:31:12, max mem: 20.9 GB 
[12/06 08:32:09][INFO] visual_prompt:  217: Epoch 91 / 100: avg data time: 3.07e-01, avg batch time: 1.1400, average train loss: 0.6012
[12/06 08:33:15][INFO] visual_prompt:  316: Inference (val):avg data time: 5.67e-05, avg batch time: 0.3101, average loss: 0.6313
[12/06 08:33:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.06	
[12/06 08:33:15][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[12/06 08:35:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4560,	2.0682 s / batch. (data: 1.20e+00). ETA=2:48:06, max mem: 20.9 GB 
[12/06 08:37:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7297,	0.8317 s / batch. (data: 9.27e-04). ETA=1:06:13, max mem: 20.9 GB 
[12/06 08:39:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7840,	0.8309 s / batch. (data: 3.39e-04). ETA=1:04:45, max mem: 20.9 GB 
[12/06 08:40:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6266,	0.8360 s / batch. (data: 3.71e-04). ETA=1:03:46, max mem: 20.9 GB 
[12/06 08:42:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4842,	0.8314 s / batch. (data: 3.47e-04). ETA=1:02:02, max mem: 20.9 GB 
[12/06 08:43:48][INFO] visual_prompt:  217: Epoch 92 / 100: avg data time: 3.12e-01, avg batch time: 1.1442, average train loss: 0.5935
[12/06 08:44:54][INFO] visual_prompt:  316: Inference (val):avg data time: 5.86e-05, avg batch time: 0.3102, average loss: 0.6178
[12/06 08:44:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.51	
[12/06 08:44:54][INFO] visual_prompt:   36: Best epoch 92: best metric: -0.618
[12/06 08:44:54][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[12/06 08:46:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3047,	1.2454 s / batch. (data: 4.13e-01). ETA=1:29:45, max mem: 20.9 GB 
[12/06 08:48:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2322,	1.9099 s / batch. (data: 1.07e+00). ETA=2:14:27, max mem: 20.9 GB 
[12/06 08:50:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7844,	0.8358 s / batch. (data: 6.09e-03). ETA=0:57:26, max mem: 20.9 GB 
[12/06 08:52:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5015,	1.5443 s / batch. (data: 7.07e-01). ETA=1:43:34, max mem: 20.9 GB 
[12/06 08:54:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6334,	0.8288 s / batch. (data: 3.57e-04). ETA=0:54:12, max mem: 20.9 GB 
[12/06 08:55:28][INFO] visual_prompt:  217: Epoch 93 / 100: avg data time: 3.13e-01, avg batch time: 1.1456, average train loss: 0.5838
[12/06 08:56:35][INFO] visual_prompt:  316: Inference (val):avg data time: 2.37e-04, avg batch time: 0.3097, average loss: 0.6257
[12/06 08:56:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.81	
[12/06 08:56:35][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[12/06 08:58:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4855,	1.2717 s / batch. (data: 4.49e-01). ETA=1:19:55, max mem: 20.9 GB 
[12/06 09:00:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6780,	1.9962 s / batch. (data: 1.16e+00). ETA=2:02:08, max mem: 20.9 GB 
[12/06 09:02:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7760,	0.8388 s / batch. (data: 1.06e-02). ETA=0:49:55, max mem: 20.9 GB 
[12/06 09:04:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8029,	1.1205 s / batch. (data: 2.76e-01). ETA=1:04:49, max mem: 20.9 GB 
[12/06 09:06:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3174,	1.1203 s / batch. (data: 2.73e-01). ETA=1:02:56, max mem: 20.9 GB 
[12/06 09:07:07][INFO] visual_prompt:  217: Epoch 94 / 100: avg data time: 3.09e-01, avg batch time: 1.1423, average train loss: 0.5703
[12/06 09:08:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.81e-04, avg batch time: 0.3105, average loss: 0.6862
[12/06 09:08:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.24	
[12/06 09:08:13][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[12/06 09:10:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6754,	0.8527 s / batch. (data: 3.47e-04). ETA=0:45:43, max mem: 20.9 GB 
[12/06 09:12:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3623,	1.3236 s / batch. (data: 5.05e-01). ETA=1:08:47, max mem: 20.9 GB 
[12/06 09:13:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5145,	1.9959 s / batch. (data: 1.17e+00). ETA=1:40:23, max mem: 20.9 GB 
[12/06 09:15:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6069,	2.6720 s / batch. (data: 1.84e+00). ETA=2:09:56, max mem: 20.9 GB 
[12/06 09:17:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6058,	0.8520 s / batch. (data: 5.31e-04). ETA=0:40:00, max mem: 20.9 GB 
[12/06 09:18:43][INFO] visual_prompt:  217: Epoch 95 / 100: avg data time: 3.05e-01, avg batch time: 1.1378, average train loss: 0.5738
[12/06 09:19:49][INFO] visual_prompt:  316: Inference (val):avg data time: 5.80e-05, avg batch time: 0.3115, average loss: 0.6335
[12/06 09:19:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.69	
[12/06 09:19:49][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[12/06 09:21:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6865,	0.8197 s / batch. (data: 4.43e-04). ETA=0:36:24, max mem: 20.9 GB 
[12/06 09:23:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3333,	0.8161 s / batch. (data: 3.46e-04). ETA=0:34:53, max mem: 20.9 GB 
[12/06 09:25:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4621,	1.3595 s / batch. (data: 5.19e-01). ETA=0:55:51, max mem: 20.9 GB 
[12/06 09:27:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4578,	0.9098 s / batch. (data: 8.02e-02). ETA=0:35:51, max mem: 20.9 GB 
[12/06 09:29:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6929,	0.8560 s / batch. (data: 3.32e-04). ETA=0:32:18, max mem: 20.9 GB 
[12/06 09:30:22][INFO] visual_prompt:  217: Epoch 96 / 100: avg data time: 3.10e-01, avg batch time: 1.1429, average train loss: 0.5517
[12/06 09:31:29][INFO] visual_prompt:  316: Inference (val):avg data time: 7.04e-05, avg batch time: 0.3107, average loss: 0.6301
[12/06 09:31:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.33	
[12/06 09:31:29][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[12/06 09:33:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4558,	0.8561 s / batch. (data: 1.51e-02). ETA=0:30:08, max mem: 20.9 GB 
[12/06 09:35:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3076,	0.8386 s / batch. (data: 2.25e-02). ETA=0:28:07, max mem: 20.9 GB 
[12/06 09:37:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3967,	0.8252 s / batch. (data: 3.17e-04). ETA=0:26:17, max mem: 20.9 GB 
[12/06 09:39:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4857,	0.8627 s / batch. (data: 3.32e-04). ETA=0:26:03, max mem: 20.9 GB 
[12/06 09:40:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9521,	0.8389 s / batch. (data: 1.11e-02). ETA=0:23:56, max mem: 20.9 GB 
[12/06 09:42:00][INFO] visual_prompt:  217: Epoch 97 / 100: avg data time: 3.08e-01, avg batch time: 1.1409, average train loss: 0.5425
[12/06 09:43:05][INFO] visual_prompt:  316: Inference (val):avg data time: 5.85e-05, avg batch time: 0.3105, average loss: 0.6247
[12/06 09:43:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.71	
[12/06 09:43:05][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[12/06 09:45:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3889,	0.8358 s / batch. (data: 5.64e-03). ETA=0:21:43, max mem: 20.9 GB 
[12/06 09:46:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5332,	0.8490 s / batch. (data: 5.53e-03). ETA=0:20:38, max mem: 20.9 GB 
[12/06 09:48:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2985,	2.8261 s / batch. (data: 2.00e+00). ETA=1:04:00, max mem: 20.9 GB 
[12/06 09:50:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3763,	1.8190 s / batch. (data: 9.85e-01). ETA=0:38:10, max mem: 20.9 GB 
[12/06 09:52:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6941,	0.8269 s / batch. (data: 4.23e-04). ETA=0:15:58, max mem: 20.9 GB 
[12/06 09:53:37][INFO] visual_prompt:  217: Epoch 98 / 100: avg data time: 3.08e-01, avg batch time: 1.1415, average train loss: 0.5337
[12/06 09:54:42][INFO] visual_prompt:  316: Inference (val):avg data time: 5.90e-05, avg batch time: 0.3099, average loss: 0.6820
[12/06 09:54:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.05	
[12/06 09:54:42][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[12/06 09:56:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4958,	0.8365 s / batch. (data: 7.95e-03). ETA=0:14:01, max mem: 20.9 GB 
[12/06 09:58:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3458,	0.8315 s / batch. (data: 1.13e-02). ETA=0:12:33, max mem: 20.9 GB 
[12/06 10:00:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9563,	2.1117 s / batch. (data: 1.29e+00). ETA=0:28:22, max mem: 20.9 GB 
[12/06 10:02:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4440,	0.8525 s / batch. (data: 3.41e-04). ETA=0:10:01, max mem: 20.9 GB 
[12/06 10:04:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4811,	1.4254 s / batch. (data: 5.82e-01). ETA=0:14:23, max mem: 20.9 GB 
[12/06 10:05:14][INFO] visual_prompt:  217: Epoch 99 / 100: avg data time: 3.10e-01, avg batch time: 1.1426, average train loss: 0.5168
[12/06 10:06:20][INFO] visual_prompt:  316: Inference (val):avg data time: 2.32e-04, avg batch time: 0.3133, average loss: 0.6611
[12/06 10:06:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 73.03	
[12/06 10:06:20][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[12/06 10:08:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5106,	1.7704 s / batch. (data: 9.36e-01). ETA=0:13:22, max mem: 20.9 GB 
[12/06 10:10:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2913,	1.5041 s / batch. (data: 6.75e-01). ETA=0:08:50, max mem: 20.9 GB 
[12/06 10:12:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2822,	0.8356 s / batch. (data: 3.81e-04). ETA=0:03:31, max mem: 20.9 GB 
[12/06 10:14:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5567,	0.8480 s / batch. (data: 5.46e-03). ETA=0:02:09, max mem: 20.9 GB 
[12/06 10:15:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2284,	0.8451 s / batch. (data: 6.68e-03). ETA=0:00:44, max mem: 20.9 GB 
[12/06 10:16:49][INFO] visual_prompt:  217: Epoch 100 / 100: avg data time: 3.04e-01, avg batch time: 1.1372, average train loss: 0.5202
[12/06 10:17:54][INFO] visual_prompt:  316: Inference (val):avg data time: 5.53e-05, avg batch time: 0.3114, average loss: 0.6902
[12/06 10:17:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.58	
