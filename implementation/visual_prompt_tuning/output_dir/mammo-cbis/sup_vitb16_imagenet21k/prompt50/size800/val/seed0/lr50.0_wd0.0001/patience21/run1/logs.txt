[11/23 14:46:06][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/23 14:46:06][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 14:46:06][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/23 14:46:06][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 14:46:06][INFO] visual_prompt:  108: Training with config:
[11/23 14:46:06][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr50.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/23 14:46:06][INFO] visual_prompt:   70: Loading training data...
[11/23 14:46:06][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/23 14:46:06][INFO] visual_prompt:   72: Loading validation data...
[11/23 14:46:06][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/23 14:46:07][INFO] visual_prompt:   36: Constructing models...
[11/23 14:46:16][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[11/23 14:46:16][INFO] visual_prompt:   54: tuned percent:0.525
[11/23 14:46:16][INFO] visual_prompt:   40: Device used for model: 0
[11/23 14:46:16][INFO] visual_prompt:   38: Setting up Evaluator...
[11/23 14:46:16][INFO] visual_prompt:   40: Setting up Trainer...
[11/23 14:46:16][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/23 14:46:16][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/23 14:47:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8197 s / batch. (data: 3.05e-04). ETA=12:34:05, max mem: 20.9 GB 
[11/23 14:49:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8320 s / batch. (data: 3.09e-04). ETA=12:44:03, max mem: 20.9 GB 
[11/23 14:51:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	0.8600 s / batch. (data: 1.60e-02). ETA=13:08:19, max mem: 20.9 GB 
[11/23 14:52:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8311 s / batch. (data: 3.32e-04). ETA=12:40:29, max mem: 20.9 GB 
[11/23 14:54:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8480 s / batch. (data: 8.02e-03). ETA=12:54:31, max mem: 20.9 GB 
[11/23 14:55:19][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 1.49e-01, avg batch time: 0.9820, average train loss: 1.5403
[11/23 14:56:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.05e-05, avg batch time: 0.3105, average loss: 1.5201
[11/23 14:56:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[11/23 14:56:15][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 5.0
[11/23 14:57:55][INFO] visual_prompt:  204: 	Training 100/553. train loss: 25.0325,	0.8695 s / batch. (data: 5.46e-03). ETA=13:11:57, max mem: 20.9 GB 
[11/23 14:59:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0000,	0.8240 s / batch. (data: 3.09e-04). ETA=12:29:07, max mem: 20.9 GB 
[11/23 15:01:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 7.4490,	1.0075 s / batch. (data: 1.76e-01). ETA=15:14:17, max mem: 20.9 GB 
[11/23 15:02:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 29.1996,	0.8729 s / batch. (data: 9.92e-03). ETA=13:10:38, max mem: 20.9 GB 
[11/23 15:04:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 80.6536,	0.8195 s / batch. (data: 3.38e-04). ETA=12:20:55, max mem: 20.9 GB 
[11/23 15:05:13][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 1.42e-01, avg batch time: 0.9730, average train loss: 26.5332
[11/23 15:06:08][INFO] visual_prompt:  316: Inference (val):avg data time: 3.16e-05, avg batch time: 0.3113, average loss: 67.9892
[11/23 15:06:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.61	
[11/23 15:06:08][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 10.0
[11/23 15:07:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 60.1347,	0.8237 s / batch. (data: 3.08e-04). ETA=12:22:38, max mem: 20.9 GB 
[11/23 15:09:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 29.4592,	0.8372 s / batch. (data: 5.58e-03). ETA=12:33:22, max mem: 20.9 GB 
[11/23 15:11:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 40.9004,	0.8240 s / batch. (data: 3.09e-04). ETA=12:20:08, max mem: 20.9 GB 
[11/23 15:12:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 14.7090,	0.8214 s / batch. (data: 3.13e-04). ETA=12:16:27, max mem: 20.9 GB 
[11/23 15:14:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 23.5847,	1.1563 s / batch. (data: 3.25e-01). ETA=17:14:45, max mem: 20.9 GB 
[11/23 15:15:07][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 1.44e-01, avg batch time: 0.9737, average train loss: 43.5661
[11/23 15:16:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.48e-05, avg batch time: 0.3113, average loss: 40.6659
[11/23 15:16:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.00	
[11/23 15:16:03][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 15.0
[11/23 15:17:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 39.0314,	0.8491 s / batch. (data: 1.05e-02). ETA=12:37:43, max mem: 20.9 GB 
[11/23 15:19:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 61.0410,	0.8610 s / batch. (data: 5.41e-03). ETA=12:46:53, max mem: 20.9 GB 
[11/23 15:21:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 14.5468,	1.2437 s / batch. (data: 4.18e-01). ETA=18:25:40, max mem: 20.9 GB 
[11/23 15:22:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 25.0609,	0.9840 s / batch. (data: 1.29e-01). ETA=14:33:07, max mem: 20.9 GB 
[11/23 15:24:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 145.8390,	3.1000 s / batch. (data: 2.27e+00). ETA=1 day, 21:45:35, max mem: 20.9 GB 
[11/23 15:25:04][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 1.48e-01, avg batch time: 0.9782, average train loss: 41.9266
[11/23 15:25:59][INFO] visual_prompt:  316: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3087, average loss: 32.3341
[11/23 15:25:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.60	
[11/23 15:25:59][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 20.0
[11/23 15:27:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 386.8663,	0.8320 s / batch. (data: 2.90e-04). ETA=12:14:47, max mem: 20.9 GB 
[11/23 15:29:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 53.7453,	0.9897 s / batch. (data: 1.80e-01). ETA=14:32:23, max mem: 20.9 GB 
[11/23 15:30:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 214.9673,	0.8513 s / batch. (data: 5.88e-03). ETA=12:28:59, max mem: 20.9 GB 
[11/23 15:32:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 27.8766,	0.8295 s / batch. (data: 2.89e-04). ETA=12:08:25, max mem: 20.9 GB 
[11/23 15:34:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 19.4011,	0.8560 s / batch. (data: 2.78e-04). ETA=12:30:15, max mem: 20.9 GB 
[11/23 15:34:55][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 1.43e-01, avg batch time: 0.9703, average train loss: 85.3709
[11/23 15:35:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.33e-05, avg batch time: 0.3086, average loss: 19.8969
[11/23 15:35:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.41	
[11/23 15:35:50][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 25.0
[11/23 15:37:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 88.2537,	0.8520 s / batch. (data: 3.60e-02). ETA=12:24:33, max mem: 20.9 GB 
[11/23 15:39:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 21.5776,	0.8176 s / batch. (data: 3.02e-04). ETA=11:53:06, max mem: 20.9 GB 
[11/23 15:40:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 217.9171,	0.8328 s / batch. (data: 7.96e-03). ETA=12:05:00, max mem: 20.9 GB 
[11/23 15:42:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.9724,	0.8320 s / batch. (data: 3.17e-04). ETA=12:02:57, max mem: 20.9 GB 
[11/23 15:43:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2620,	0.8200 s / batch. (data: 3.40e-04). ETA=11:51:07, max mem: 20.9 GB 
[11/23 15:44:49][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 1.47e-01, avg batch time: 0.9738, average train loss: 87.7367
[11/23 15:45:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.11e-05, avg batch time: 0.3097, average loss: 26.4101
[11/23 15:45:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.30	
[11/23 15:45:44][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 30.0
[11/23 15:47:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 50.2073,	0.8355 s / batch. (data: 7.95e-03). ETA=12:02:25, max mem: 20.9 GB 
[11/23 15:49:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 18.5600,	0.8600 s / batch. (data: 5.43e-03). ETA=12:22:11, max mem: 20.9 GB 
[11/23 15:50:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 4.7670,	1.5351 s / batch. (data: 7.14e-01). ETA=22:02:17, max mem: 20.9 GB 
[11/23 15:52:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 29.0680,	0.8280 s / batch. (data: 3.92e-04). ETA=11:51:50, max mem: 20.9 GB 
[11/23 15:53:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 176.5945,	0.8221 s / batch. (data: 4.30e-04). ETA=11:45:21, max mem: 20.9 GB 
[11/23 15:54:41][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.42e-01, avg batch time: 0.9697, average train loss: 99.9768
[11/23 15:55:36][INFO] visual_prompt:  316: Inference (val):avg data time: 8.39e-05, avg batch time: 0.3093, average loss: 111.2492
[11/23 15:55:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.62	
[11/23 15:55:36][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 35.0
[11/23 15:57:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 282.0644,	0.8465 s / batch. (data: 2.27e-02). ETA=12:04:09, max mem: 20.9 GB 
[11/23 15:58:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 32.4692,	0.8439 s / batch. (data: 7.50e-03). ETA=12:00:29, max mem: 20.9 GB 
[11/23 16:00:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 50.4068,	0.8396 s / batch. (data: 9.61e-03). ETA=11:55:27, max mem: 20.9 GB 
[11/23 16:02:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 234.5956,	0.8202 s / batch. (data: 3.29e-04). ETA=11:37:36, max mem: 20.9 GB 
[11/23 16:03:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 329.2100,	1.4310 s / batch. (data: 6.04e-01). ETA=20:14:38, max mem: 20.9 GB 
[11/23 16:04:37][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 1.50e-01, avg batch time: 0.9770, average train loss: 113.6568
[11/23 16:05:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-05, avg batch time: 0.3104, average loss: 4.6736
[11/23 16:05:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.02	
[11/23 16:05:32][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 40.0
[11/23 16:07:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 38.1540,	0.8520 s / batch. (data: 1.59e-02). ETA=12:00:59, max mem: 20.9 GB 
[11/23 16:08:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.7190,	0.8360 s / batch. (data: 2.98e-04). ETA=11:46:04, max mem: 20.9 GB 
[11/23 16:10:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 53.2733,	1.4560 s / batch. (data: 6.37e-01). ETA=20:27:18, max mem: 20.9 GB 
[11/23 16:12:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 240.5974,	0.8398 s / batch. (data: 7.83e-04). ETA=11:46:30, max mem: 20.9 GB 
[11/23 16:13:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 59.7817,	0.8486 s / batch. (data: 3.48e-02). ETA=11:52:29, max mem: 20.9 GB 
[11/23 16:14:25][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 1.37e-01, avg batch time: 0.9642, average train loss: 133.1418
[11/23 16:15:20][INFO] visual_prompt:  316: Inference (val):avg data time: 1.70e-04, avg batch time: 0.3091, average loss: 184.4700
[11/23 16:15:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.80	
[11/23 16:15:20][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 45.0
[11/23 16:17:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 277.8878,	0.8240 s / batch. (data: 2.87e-04). ETA=11:29:44, max mem: 20.9 GB 
[11/23 16:18:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 8.4880,	0.8451 s / batch. (data: 5.43e-03). ETA=11:45:58, max mem: 20.9 GB 
[11/23 16:20:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 49.5425,	1.2960 s / batch. (data: 4.56e-01). ETA=18:00:29, max mem: 20.9 GB 
[11/23 16:21:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 7.6892,	0.8477 s / batch. (data: 3.14e-04). ETA=11:45:19, max mem: 20.9 GB 
[11/23 16:23:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 26.2307,	0.8073 s / batch. (data: 3.48e-04). ETA=11:10:20, max mem: 20.9 GB 
[11/23 16:24:12][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 1.35e-01, avg batch time: 0.9619, average train loss: 164.3878
[11/23 16:25:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-05, avg batch time: 0.3103, average loss: 31.7203
[11/23 16:25:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.98	
[11/23 16:25:07][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 50.0
[11/23 16:26:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 9.9833,	0.8262 s / batch. (data: 1.02e-02). ETA=11:23:58, max mem: 20.9 GB 
[11/23 16:28:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 469.3429,	0.8405 s / batch. (data: 2.33e-02). ETA=11:34:23, max mem: 20.9 GB 
[11/23 16:30:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	1.9720 s / batch. (data: 1.14e+00). ETA=1 day, 3:05:54, max mem: 20.9 GB 
[11/23 16:31:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 100.8531,	0.8329 s / batch. (data: 7.82e-04). ETA=11:25:20, max mem: 20.9 GB 
[11/23 16:33:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 263.9169,	0.9840 s / batch. (data: 1.57e-01). ETA=13:28:01, max mem: 20.9 GB 
[11/23 16:34:06][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 1.47e-01, avg batch time: 0.9734, average train loss: 146.0352
[11/23 16:35:01][INFO] visual_prompt:  316: Inference (val):avg data time: 1.68e-04, avg batch time: 0.3095, average loss: 132.6761
[11/23 16:35:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.21	
[11/23 16:35:01][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/23 16:36:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 60.8919,	0.8410 s / batch. (data: 1.05e-02). ETA=11:28:29, max mem: 20.9 GB 
[11/23 16:38:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 56.2458,	1.0464 s / batch. (data: 2.18e-01). ETA=14:14:51, max mem: 20.9 GB 
[11/23 16:39:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 37.1902,	0.8240 s / batch. (data: 1.20e-02). ETA=11:11:47, max mem: 20.9 GB 
[11/23 16:41:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.3180,	0.8586 s / batch. (data: 5.25e-04). ETA=11:38:32, max mem: 20.9 GB 
[11/23 16:43:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 13.2477,	0.8277 s / batch. (data: 7.72e-04). ETA=11:12:02, max mem: 20.9 GB 
[11/23 16:44:00][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.49e-01, avg batch time: 0.9749, average train loss: 172.4881
[11/23 16:44:56][INFO] visual_prompt:  316: Inference (val):avg data time: 1.47e-04, avg batch time: 0.3108, average loss: 32.2117
[11/23 16:44:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.13	
[11/23 16:44:56][INFO] visual_prompt:   36: Best epoch 12: best metric: -32.212
[11/23 16:44:56][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/23 16:46:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 126.3914,	0.8035 s / batch. (data: 3.49e-04). ETA=10:50:21, max mem: 20.9 GB 
[11/23 16:48:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.3517,	0.8309 s / batch. (data: 1.05e-02). ETA=11:11:09, max mem: 20.9 GB 
[11/23 16:49:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 238.2179,	1.6805 s / batch. (data: 8.76e-01). ETA=22:34:37, max mem: 20.9 GB 
[11/23 16:51:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 48.1541,	0.8482 s / batch. (data: 1.63e-02). ETA=11:22:15, max mem: 20.9 GB 
[11/23 16:52:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 359.6395,	0.8637 s / batch. (data: 2.96e-04). ETA=11:33:18, max mem: 20.9 GB 
[11/23 16:53:49][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 1.37e-01, avg batch time: 0.9645, average train loss: 158.3108
[11/23 16:54:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.13e-05, avg batch time: 0.3115, average loss: 64.0487
[11/23 16:54:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.74	
[11/23 16:54:43][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/23 16:56:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 354.7159,	0.8390 s / batch. (data: 2.99e-04). ETA=11:11:22, max mem: 20.9 GB 
[11/23 16:57:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0000,	0.8444 s / batch. (data: 3.19e-02). ETA=11:14:17, max mem: 20.9 GB 
[11/23 16:59:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 281.6381,	0.8199 s / batch. (data: 2.93e-04). ETA=10:53:22, max mem: 20.9 GB 
[11/23 17:01:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 143.7888,	0.8214 s / batch. (data: 2.98e-04). ETA=10:53:09, max mem: 20.9 GB 
[11/23 17:02:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 306.5684,	0.8270 s / batch. (data: 5.42e-03). ETA=10:56:12, max mem: 20.9 GB 
[11/23 17:03:33][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 1.31e-01, avg batch time: 0.9569, average train loss: 151.1336
[11/23 17:04:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.3093, average loss: 183.7384
[11/23 17:04:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.66	
[11/23 17:04:27][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/23 17:06:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 105.0922,	1.5085 s / batch. (data: 7.01e-01). ETA=19:53:10, max mem: 20.9 GB 
[11/23 17:07:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1187.5264,	0.8240 s / batch. (data: 2.99e-04). ETA=10:50:22, max mem: 20.9 GB 
[11/23 17:09:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 32.1880,	0.8280 s / batch. (data: 3.06e-04). ETA=10:52:08, max mem: 20.9 GB 
[11/23 17:10:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 28.2467,	0.8960 s / batch. (data: 7.09e-02). ETA=11:44:12, max mem: 20.9 GB 
[11/23 17:12:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 68.7989,	0.8400 s / batch. (data: 7.96e-03). ETA=10:58:49, max mem: 20.9 GB 
[11/23 17:13:20][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.37e-01, avg batch time: 0.9640, average train loss: 206.1229
[11/23 17:14:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-05, avg batch time: 0.3110, average loss: 118.2958
[11/23 17:14:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.74	
[11/23 17:14:15][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/23 17:15:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 202.4007,	0.8265 s / batch. (data: 3.03e-04). ETA=10:46:09, max mem: 20.9 GB 
[11/23 17:17:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 48.7037,	0.8216 s / batch. (data: 9.58e-03). ETA=10:40:55, max mem: 20.9 GB 
[11/23 17:19:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 37.0103,	0.8280 s / batch. (data: 3.88e-04). ETA=10:44:30, max mem: 20.9 GB 
[11/23 17:20:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 27.4519,	0.8427 s / batch. (data: 2.49e-02). ETA=10:54:35, max mem: 20.9 GB 
[11/23 17:22:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 121.7329,	1.4128 s / batch. (data: 5.89e-01). ETA=18:15:03, max mem: 20.9 GB 
[11/23 17:23:10][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 1.41e-01, avg batch time: 0.9682, average train loss: 164.7299
[11/23 17:24:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.11e-05, avg batch time: 0.3107, average loss: 117.7863
[11/23 17:24:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.32	
[11/23 17:24:06][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/23 17:25:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 58.3650,	0.8355 s / batch. (data: 1.15e-02). ETA=10:45:25, max mem: 20.9 GB 
[11/23 17:27:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 227.1207,	0.8368 s / batch. (data: 1.05e-02). ETA=10:45:04, max mem: 20.9 GB 
[11/23 17:28:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 46.0636,	0.8332 s / batch. (data: 1.49e-02). ETA=10:40:53, max mem: 20.9 GB 
[11/23 17:30:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 114.2639,	1.1240 s / batch. (data: 2.83e-01). ETA=14:22:42, max mem: 20.9 GB 
[11/23 17:32:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 87.6181,	1.5366 s / batch. (data: 7.22e-01). ETA=19:36:47, max mem: 20.9 GB 
[11/23 17:33:01][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 1.42e-01, avg batch time: 0.9687, average train loss: 168.7049
[11/23 17:33:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.04e-05, avg batch time: 0.3085, average loss: 22.6526
[11/23 17:33:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.86	
[11/23 17:33:56][INFO] visual_prompt:   36: Best epoch 17: best metric: -22.653
[11/23 17:33:56][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/23 17:35:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 131.4120,	0.8284 s / batch. (data: 2.88e-04). ETA=10:32:18, max mem: 20.9 GB 
[11/23 17:37:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 82.1683,	0.8312 s / batch. (data: 8.80e-04). ETA=10:33:05, max mem: 20.9 GB 
[11/23 17:38:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 208.3451,	0.8318 s / batch. (data: 3.34e-04). ETA=10:32:10, max mem: 20.9 GB 
[11/23 17:40:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 118.2526,	0.8385 s / batch. (data: 3.11e-04). ETA=10:35:52, max mem: 20.9 GB 
[11/23 17:42:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 105.4762,	0.8318 s / batch. (data: 3.11e-04). ETA=10:29:23, max mem: 20.9 GB 
[11/23 17:42:53][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 1.44e-01, avg batch time: 0.9706, average train loss: 173.0700
[11/23 17:43:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3087, average loss: 234.8130
[11/23 17:43:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.62	
[11/23 17:43:50][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/23 17:45:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 102.9204,	0.8280 s / batch. (data: 3.08e-04). ETA=10:24:24, max mem: 20.9 GB 
[11/23 17:47:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 134.7831,	0.8234 s / batch. (data: 2.90e-04). ETA=10:19:35, max mem: 20.9 GB 
[11/23 17:48:44][INFO] visual_prompt:  204: 	Training 300/553. train loss: 185.0444,	0.8400 s / batch. (data: 2.94e-04). ETA=10:30:39, max mem: 20.9 GB 
[11/23 17:50:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 27.8588,	0.8058 s / batch. (data: 2.96e-04). ETA=10:03:38, max mem: 20.9 GB 
[11/23 17:51:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 32.7093,	0.8324 s / batch. (data: 5.39e-03). ETA=10:22:07, max mem: 20.9 GB 
[11/23 17:52:44][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.38e-01, avg batch time: 0.9640, average train loss: 148.0561
[11/23 17:53:38][INFO] visual_prompt:  316: Inference (val):avg data time: 2.12e-04, avg batch time: 0.3109, average loss: 392.9309
[11/23 17:53:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.46	
[11/23 17:53:38][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/23 17:55:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.1941,	0.8654 s / batch. (data: 4.93e-02). ETA=10:44:39, max mem: 20.9 GB 
[11/23 17:56:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8545,	0.8365 s / batch. (data: 2.95e-04). ETA=10:21:41, max mem: 20.9 GB 
[11/23 17:58:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 68.5057,	0.8440 s / batch. (data: 2.84e-04). ETA=10:25:52, max mem: 20.9 GB 
[11/23 18:00:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 805.9830,	0.8413 s / batch. (data: 5.41e-03). ETA=10:22:27, max mem: 20.9 GB 
[11/23 18:01:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 203.7889,	0.8400 s / batch. (data: 2.86e-04). ETA=10:20:06, max mem: 20.9 GB 
[11/23 18:02:33][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 1.40e-01, avg batch time: 0.9672, average train loss: 131.3989
[11/23 18:03:28][INFO] visual_prompt:  316: Inference (val):avg data time: 3.17e-05, avg batch time: 0.3087, average loss: 165.6595
[11/23 18:03:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.91	
[11/23 18:03:28][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/23 18:05:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 19.3996,	0.8095 s / batch. (data: 3.32e-04). ETA=9:55:31, max mem: 20.9 GB 
[11/23 18:06:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 379.2604,	0.8194 s / batch. (data: 5.35e-03). ETA=10:01:28, max mem: 20.9 GB 
[11/23 18:08:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 641.3419,	0.9480 s / batch. (data: 1.17e-01). ETA=11:34:16, max mem: 20.9 GB 
[11/23 18:09:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 61.0983,	0.8372 s / batch. (data: 2.81e-04). ETA=10:11:40, max mem: 20.9 GB 
[11/23 18:11:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 171.5970,	0.8280 s / batch. (data: 2.96e-04). ETA=10:03:38, max mem: 20.9 GB 
[11/23 18:12:23][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 1.40e-01, avg batch time: 0.9670, average train loss: 151.6709
[11/23 18:13:18][INFO] visual_prompt:  316: Inference (val):avg data time: 5.84e-04, avg batch time: 0.3112, average loss: 111.4839
[11/23 18:13:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.89	
[11/23 18:13:18][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/23 18:14:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 122.2994,	0.8274 s / batch. (data: 7.57e-03). ETA=10:01:02, max mem: 20.9 GB 
[11/23 18:16:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 80.7615,	0.8360 s / batch. (data: 2.82e-04). ETA=10:05:54, max mem: 20.9 GB 
[11/23 18:18:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8320 s / batch. (data: 3.07e-04). ETA=10:01:38, max mem: 20.9 GB 
[11/23 18:19:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 179.3458,	0.8557 s / batch. (data: 7.69e-03). ETA=10:17:21, max mem: 20.9 GB 
[11/23 18:21:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 114.1174,	0.8059 s / batch. (data: 3.11e-04). ETA=9:40:02, max mem: 20.9 GB 
[11/23 18:22:15][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 1.43e-01, avg batch time: 0.9702, average train loss: 152.8411
[11/23 18:23:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-05, avg batch time: 0.3101, average loss: 75.6044
[11/23 18:23:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.51	
[11/23 18:23:10][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/23 18:24:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 238.0629,	0.8140 s / batch. (data: 3.19e-04). ETA=9:43:50, max mem: 20.9 GB 
[11/23 18:26:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 108.5072,	0.8360 s / batch. (data: 1.60e-02). ETA=9:58:13, max mem: 20.9 GB 
[11/23 18:28:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 15.3152,	0.8535 s / batch. (data: 7.83e-04). ETA=10:09:16, max mem: 20.9 GB 
[11/23 18:29:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 370.6310,	0.8455 s / batch. (data: 2.86e-04). ETA=10:02:09, max mem: 20.9 GB 
[11/23 18:31:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0000,	0.8240 s / batch. (data: 2.86e-04). ETA=9:45:30, max mem: 20.9 GB 
[11/23 18:32:07][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 1.44e-01, avg batch time: 0.9707, average train loss: 164.8058
[11/23 18:33:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.15e-05, avg batch time: 0.3092, average loss: 19.6481
[11/23 18:33:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.39	
[11/23 18:33:02][INFO] visual_prompt:   36: Best epoch 23: best metric: -19.648
[11/23 18:33:02][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/23 18:34:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 220.7708,	0.8240 s / batch. (data: 7.95e-03). ETA=9:43:24, max mem: 20.9 GB 
[11/23 18:36:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 57.7030,	0.8497 s / batch. (data: 1.20e-02). ETA=10:00:11, max mem: 20.9 GB 
[11/23 18:37:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 165.2409,	0.8177 s / batch. (data: 8.45e-03). ETA=9:36:14, max mem: 20.9 GB 
[11/23 18:39:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 54.8669,	0.8423 s / batch. (data: 1.03e-02). ETA=9:52:09, max mem: 20.9 GB 
[11/23 18:41:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 233.0795,	0.8370 s / batch. (data: 5.41e-03). ETA=9:47:01, max mem: 20.9 GB 
[11/23 18:42:00][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 1.46e-01, avg batch time: 0.9728, average train loss: 146.3013
[11/23 18:42:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.3095, average loss: 171.0182
[11/23 18:42:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.56	
[11/23 18:42:55][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/23 18:44:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 15.2874,	0.8351 s / batch. (data: 3.01e-04). ETA=9:43:32, max mem: 20.9 GB 
[11/23 18:46:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 186.4530,	0.8361 s / batch. (data: 1.42e-02). ETA=9:42:52, max mem: 20.9 GB 
[11/23 18:47:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 25.8697,	0.8397 s / batch. (data: 3.17e-04). ETA=9:43:58, max mem: 20.9 GB 
[11/23 18:49:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 33.5844,	1.1930 s / batch. (data: 3.68e-01). ETA=13:47:42, max mem: 20.9 GB 
[11/23 18:51:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 120.7112,	1.4435 s / batch. (data: 6.15e-01). ETA=16:39:04, max mem: 20.9 GB 
[11/23 18:51:55][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 1.50e-01, avg batch time: 0.9761, average train loss: 152.1037
[11/23 18:52:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.36e-05, avg batch time: 0.3102, average loss: 209.1437
[11/23 18:52:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.07	
[11/23 18:52:50][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/23 18:54:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 83.1610,	0.8267 s / batch. (data: 9.58e-03). ETA=9:30:05, max mem: 20.9 GB 
[11/23 18:56:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 598.5208,	1.5891 s / batch. (data: 7.75e-01). ETA=18:13:08, max mem: 20.9 GB 
[11/23 18:57:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8154 s / batch. (data: 8.06e-04). ETA=9:19:32, max mem: 20.9 GB 
[11/23 18:59:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 457.4002,	0.8248 s / batch. (data: 4.28e-04). ETA=9:24:39, max mem: 20.9 GB 
[11/23 19:01:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 34.4658,	0.8480 s / batch. (data: 8.08e-04). ETA=9:39:06, max mem: 20.9 GB 
[11/23 19:01:50][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 1.49e-01, avg batch time: 0.9759, average train loss: 149.0037
[11/23 19:02:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3097, average loss: 44.7650
[11/23 19:02:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.99	
[11/23 19:02:46][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/23 19:04:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 14.7403,	0.8605 s / batch. (data: 4.68e-04). ETA=9:45:25, max mem: 20.9 GB 
[11/23 19:06:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 319.8436,	1.0278 s / batch. (data: 1.95e-01). ETA=11:37:33, max mem: 20.9 GB 
[11/23 19:07:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 199.6077,	0.8360 s / batch. (data: 7.95e-03). ETA=9:25:59, max mem: 20.9 GB 
[11/23 19:09:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2961,	0.8590 s / batch. (data: 5.91e-03). ETA=9:40:07, max mem: 20.9 GB 
[11/23 19:10:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 63.2854,	0.8280 s / batch. (data: 1.20e-02). ETA=9:17:48, max mem: 20.9 GB 
[11/23 19:11:46][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 1.49e-01, avg batch time: 0.9762, average train loss: 175.4549
[11/23 19:12:41][INFO] visual_prompt:  316: Inference (val):avg data time: 3.17e-05, avg batch time: 0.3088, average loss: 296.2717
[11/23 19:12:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 34.15	
[11/23 19:12:41][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/23 19:14:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8129 s / batch. (data: 3.05e-04). ETA=9:05:34, max mem: 20.9 GB 
[11/23 19:15:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 147.5573,	0.8271 s / batch. (data: 3.12e-04). ETA=9:13:45, max mem: 20.9 GB 
[11/23 19:17:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 39.2931,	1.2597 s / batch. (data: 4.55e-01). ETA=14:01:15, max mem: 20.9 GB 
[11/23 19:19:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 13.6634,	0.8292 s / batch. (data: 3.11e-04). ETA=9:12:20, max mem: 20.9 GB 
[11/23 19:20:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 440.2202,	0.8240 s / batch. (data: 5.42e-03). ETA=9:07:33, max mem: 20.9 GB 
[11/23 19:21:36][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.41e-01, avg batch time: 0.9678, average train loss: 158.8234
[11/23 19:22:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-05, avg batch time: 0.3120, average loss: 254.6606
[11/23 19:22:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.74	
[11/23 19:22:31][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/23 19:24:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8250 s / batch. (data: 2.91e-04). ETA=9:06:04, max mem: 20.9 GB 
[11/23 19:25:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 346.1683,	1.6812 s / batch. (data: 8.65e-01). ETA=18:30:01, max mem: 20.9 GB 
[11/23 19:27:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 34.8636,	0.8499 s / batch. (data: 6.87e-04). ETA=9:19:44, max mem: 20.9 GB 
[11/23 19:28:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 364.2102,	1.2079 s / batch. (data: 3.83e-01). ETA=13:13:30, max mem: 20.9 GB 
[11/23 19:30:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 46.9617,	0.8280 s / batch. (data: 3.15e-04). ETA=9:02:34, max mem: 20.9 GB 
[11/23 19:31:25][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 1.38e-01, avg batch time: 0.9652, average train loss: 139.2024
[11/23 19:32:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.06e-05, avg batch time: 0.3102, average loss: 19.5667
[11/23 19:32:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.65	
[11/23 19:32:20][INFO] visual_prompt:   36: Best epoch 29: best metric: -19.567
[11/23 19:32:20][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/23 19:33:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 154.6503,	0.8600 s / batch. (data: 7.96e-03). ETA=9:21:19, max mem: 20.9 GB 
[11/23 19:35:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 16.3775,	0.8250 s / batch. (data: 3.19e-03). ETA=8:57:07, max mem: 20.9 GB 
[11/23 19:37:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	1.3640 s / batch. (data: 5.31e-01). ETA=14:45:44, max mem: 20.9 GB 
[11/23 19:38:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 98.6266,	1.0874 s / batch. (data: 2.71e-01). ETA=11:44:18, max mem: 20.9 GB 
[11/23 19:40:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 48.5852,	1.3840 s / batch. (data: 5.34e-01). ETA=14:54:07, max mem: 20.9 GB 
[11/23 19:41:17][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 1.44e-01, avg batch time: 0.9716, average train loss: 140.6919
[11/23 19:42:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.31e-05, avg batch time: 0.3088, average loss: 85.6259
[11/23 19:42:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.40	
[11/23 19:42:13][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/23 19:43:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 122.3913,	0.8320 s / batch. (data: 3.37e-04). ETA=8:55:23, max mem: 20.9 GB 
[11/23 19:45:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 31.0906,	0.8412 s / batch. (data: 2.78e-04). ETA=8:59:55, max mem: 20.9 GB 
[11/23 19:47:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 229.8587,	0.8280 s / batch. (data: 3.21e-04). ETA=8:50:02, max mem: 20.9 GB 
[11/23 19:48:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 157.4476,	1.0440 s / batch. (data: 2.16e-01). ETA=11:06:35, max mem: 20.9 GB 
[11/23 19:50:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 97.8932,	0.8173 s / batch. (data: 3.13e-04). ETA=8:40:29, max mem: 20.9 GB 
[11/23 19:51:06][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 1.37e-01, avg batch time: 0.9642, average train loss: 142.1276
[11/23 19:52:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.14e-05, avg batch time: 0.3103, average loss: 81.8708
[11/23 19:52:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.45	
[11/23 19:52:01][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/23 19:53:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 165.4758,	0.8480 s / batch. (data: 7.57e-04). ETA=8:57:52, max mem: 20.9 GB 
[11/23 19:55:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 15.5328,	0.8300 s / batch. (data: 7.50e-04). ETA=8:45:05, max mem: 20.9 GB 
[11/23 19:56:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 174.6999,	0.8390 s / batch. (data: 1.05e-02). ETA=8:49:23, max mem: 20.9 GB 
[11/23 19:58:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 54.7532,	0.8320 s / batch. (data: 3.01e-04). ETA=8:43:33, max mem: 20.9 GB 
[11/23 20:00:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 37.7764,	0.8355 s / batch. (data: 2.93e-04). ETA=8:44:21, max mem: 20.9 GB 
[11/23 20:00:54][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 1.36e-01, avg batch time: 0.9638, average train loss: 139.3340
[11/23 20:01:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-05, avg batch time: 0.3107, average loss: 19.7126
[11/23 20:01:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.32	
[11/23 20:01:49][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/23 20:03:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.8962,	0.8520 s / batch. (data: 3.28e-04). ETA=8:52:33, max mem: 20.9 GB 
[11/23 20:05:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 18.0701,	0.9720 s / batch. (data: 1.35e-01). ETA=10:05:56, max mem: 20.9 GB 
[11/23 20:06:44][INFO] visual_prompt:  204: 	Training 300/553. train loss: 210.4590,	0.8455 s / batch. (data: 2.45e-04). ETA=8:45:41, max mem: 20.9 GB 
[11/23 20:08:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 330.1152,	0.8283 s / batch. (data: 3.32e-04). ETA=8:33:37, max mem: 20.9 GB 
[11/23 20:09:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 507.6531,	0.8245 s / batch. (data: 1.05e-02). ETA=8:29:50, max mem: 20.9 GB 
[11/23 20:10:48][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 1.45e-01, avg batch time: 0.9733, average train loss: 143.6312
[11/23 20:11:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.19e-05, avg batch time: 0.3093, average loss: 127.1067
[11/23 20:11:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.03	
[11/23 20:11:43][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/23 20:13:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 19.8462,	0.8309 s / batch. (data: 3.31e-04). ETA=8:31:41, max mem: 20.9 GB 
[11/23 20:15:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 18.9643,	0.8496 s / batch. (data: 5.43e-03). ETA=8:41:48, max mem: 20.9 GB 
[11/23 20:16:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 309.5136,	0.8383 s / batch. (data: 5.41e-03). ETA=8:33:28, max mem: 20.9 GB 
[11/23 20:18:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 8.1546,	0.8329 s / batch. (data: 3.45e-04). ETA=8:28:47, max mem: 20.9 GB 
[11/23 20:19:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 112.1696,	1.4725 s / batch. (data: 6.44e-01). ETA=14:57:01, max mem: 20.9 GB 
[11/23 20:20:43][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 1.50e-01, avg batch time: 0.9760, average train loss: 149.7802
[11/23 20:21:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.24e-05, avg batch time: 0.3113, average loss: 111.8793
[11/23 20:21:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.49	
[11/23 20:21:38][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/23 20:23:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 103.1113,	0.8429 s / batch. (data: 1.23e-02). ETA=8:31:18, max mem: 20.9 GB 
[11/23 20:25:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 27.2771,	0.8501 s / batch. (data: 3.76e-04). ETA=8:34:15, max mem: 20.9 GB 
[11/23 20:26:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 37.5424,	0.8615 s / batch. (data: 2.57e-02). ETA=8:39:46, max mem: 20.9 GB 
[11/23 20:28:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 14.9664,	0.8360 s / batch. (data: 2.95e-04). ETA=8:22:58, max mem: 20.9 GB 
[11/23 20:29:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 55.5980,	0.9902 s / batch. (data: 1.81e-01). ETA=9:54:05, max mem: 20.9 GB 
[11/23 20:30:38][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 1.49e-01, avg batch time: 0.9763, average train loss: 149.4510
[11/23 20:31:34][INFO] visual_prompt:  316: Inference (val):avg data time: 2.84e-04, avg batch time: 0.3104, average loss: 265.0159
[11/23 20:31:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.16	
[11/23 20:31:34][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/23 20:33:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 115.7175,	0.8139 s / batch. (data: 1.06e-02). ETA=8:06:15, max mem: 20.9 GB 
[11/23 20:34:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 506.0617,	0.8400 s / batch. (data: 1.20e-02). ETA=8:20:24, max mem: 20.9 GB 
[11/23 20:36:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8169 s / batch. (data: 5.44e-03). ETA=8:05:18, max mem: 20.9 GB 
[11/23 20:38:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 23.3570,	0.8342 s / batch. (data: 3.04e-04). ETA=8:14:10, max mem: 20.9 GB 
[11/23 20:39:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 290.1146,	0.8419 s / batch. (data: 3.08e-04). ETA=8:17:21, max mem: 20.9 GB 
[11/23 20:40:33][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 1.48e-01, avg batch time: 0.9748, average train loss: 140.2568
[11/23 20:41:28][INFO] visual_prompt:  316: Inference (val):avg data time: 2.28e-04, avg batch time: 0.3106, average loss: 111.5739
[11/23 20:41:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.40	
[11/23 20:41:28][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/23 20:43:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 141.5817,	0.8134 s / batch. (data: 3.13e-04). ETA=7:58:25, max mem: 20.9 GB 
[11/23 20:44:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 168.3323,	0.8455 s / batch. (data: 3.02e-04). ETA=8:15:55, max mem: 20.9 GB 
[11/23 20:46:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 281.6743,	1.2520 s / batch. (data: 4.01e-01). ETA=12:12:15, max mem: 20.9 GB 
[11/23 20:48:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.9071,	1.8665 s / batch. (data: 1.04e+00). ETA=18:08:32, max mem: 20.9 GB 
[11/23 20:49:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 34.7462,	0.9944 s / batch. (data: 1.66e-01). ETA=9:38:15, max mem: 20.9 GB 
[11/23 20:50:30][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 1.52e-01, avg batch time: 0.9784, average train loss: 140.7057
[11/23 20:51:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.24e-05, avg batch time: 0.3116, average loss: 52.1396
[11/23 20:51:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.22	
[11/23 20:51:25][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/23 20:53:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 6.9585,	0.8279 s / batch. (data: 5.44e-03). ETA=7:59:21, max mem: 20.9 GB 
[11/23 20:54:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 107.9177,	1.1703 s / batch. (data: 3.26e-01). ETA=11:15:37, max mem: 20.9 GB 
[11/23 20:56:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 33.5977,	0.8240 s / batch. (data: 3.09e-04). ETA=7:54:20, max mem: 20.9 GB 
[11/23 20:57:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 126.3971,	0.8210 s / batch. (data: 3.11e-04). ETA=7:51:13, max mem: 20.9 GB 
[11/23 20:59:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.5677,	0.8318 s / batch. (data: 3.27e-04). ETA=7:56:03, max mem: 20.9 GB 
[11/23 21:00:24][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 1.47e-01, avg batch time: 0.9737, average train loss: 140.6521
[11/23 21:01:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.05e-05, avg batch time: 0.3084, average loss: 276.6873
[11/23 21:01:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.70	
[11/23 21:01:19][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/23 21:02:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0002,	0.8264 s / batch. (data: 9.41e-03). ETA=7:50:52, max mem: 20.9 GB 
[11/23 21:04:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 413.8148,	0.8664 s / batch. (data: 3.84e-02). ETA=8:12:13, max mem: 20.9 GB 
[11/23 21:06:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 124.1934,	0.8440 s / batch. (data: 7.96e-03). ETA=7:58:04, max mem: 20.9 GB 
[11/23 21:07:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 115.5211,	1.2268 s / batch. (data: 4.21e-01). ETA=11:32:51, max mem: 20.9 GB 
[11/23 21:09:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 40.5285,	1.7160 s / batch. (data: 8.60e-01). ETA=16:06:16, max mem: 20.9 GB 
[11/23 21:10:19][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 1.49e-01, avg batch time: 0.9764, average train loss: 108.4750
[11/23 21:11:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.22e-05, avg batch time: 0.3099, average loss: 209.0526
[11/23 21:11:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.69	
[11/23 21:11:14][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/23 21:12:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 375.7561,	0.8280 s / batch. (data: 2.93e-04). ETA=7:44:07, max mem: 20.9 GB 
[11/23 21:14:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.0492,	0.8440 s / batch. (data: 7.95e-03). ETA=7:51:41, max mem: 20.9 GB 
[11/23 21:16:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 100.3886,	0.8321 s / batch. (data: 7.87e-04). ETA=7:43:40, max mem: 20.9 GB 
[11/23 21:17:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 117.8543,	0.8199 s / batch. (data: 1.05e-02). ETA=7:35:28, max mem: 20.9 GB 
[11/23 21:19:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0000,	0.8120 s / batch. (data: 3.15e-04). ETA=7:29:46, max mem: 20.9 GB 
[11/23 21:20:16][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 1.54e-01, avg batch time: 0.9799, average train loss: 132.2321
[11/23 21:21:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3105, average loss: 34.4287
[11/23 21:21:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.58	
[11/23 21:21:12][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 37.5
[11/23 21:22:57][INFO] visual_prompt:  204: 	Training 100/553. train loss: 74.8127,	0.8402 s / batch. (data: 3.11e-04). ETA=7:43:12, max mem: 20.9 GB 
[11/23 21:24:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 32.2467,	0.8094 s / batch. (data: 7.10e-04). ETA=7:24:53, max mem: 20.9 GB 
[11/23 21:26:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 170.9885,	0.8296 s / batch. (data: 4.06e-04). ETA=7:34:35, max mem: 20.9 GB 
[11/23 21:27:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 106.4628,	0.8228 s / batch. (data: 2.68e-04). ETA=7:29:30, max mem: 20.9 GB 
[11/23 21:29:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 99.3491,	0.8160 s / batch. (data: 3.04e-04). ETA=7:24:26, max mem: 20.9 GB 
[11/23 21:30:11][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 1.47e-01, avg batch time: 0.9744, average train loss: 141.9813
[11/23 21:31:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.49e-05, avg batch time: 0.3122, average loss: 86.1727
[11/23 21:31:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.03	
[11/23 21:31:07][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 36.736789069647266
[11/23 21:32:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 261.2810,	0.8201 s / batch. (data: 2.97e-04). ETA=7:24:35, max mem: 20.9 GB 
[11/23 21:34:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1197.9874,	0.8474 s / batch. (data: 3.14e-04). ETA=7:37:59, max mem: 20.9 GB 
[11/23 21:36:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 27.7327,	0.8440 s / batch. (data: 3.12e-04). ETA=7:34:44, max mem: 20.9 GB 
[11/23 21:37:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 58.5433,	0.8551 s / batch. (data: 2.98e-04). ETA=7:39:16, max mem: 20.9 GB 
[11/23 21:39:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5195,	0.8318 s / batch. (data: 1.41e-02). ETA=7:25:22, max mem: 20.9 GB 
[11/23 21:40:06][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 1.48e-01, avg batch time: 0.9751, average train loss: 173.6028
[11/23 21:41:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.20e-05, avg batch time: 0.3108, average loss: 80.3345
[11/23 21:41:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.94	
[11/23 21:41:01][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 35.959278669726935
[11/23 21:42:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 210.0464,	0.8290 s / batch. (data: 2.96e-04). ETA=7:21:46, max mem: 20.9 GB 
[11/23 21:44:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 132.1355,	0.8341 s / batch. (data: 6.02e-03). ETA=7:23:04, max mem: 20.9 GB 
[11/23 21:45:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 264.3711,	0.8440 s / batch. (data: 3.00e-04). ETA=7:26:57, max mem: 20.9 GB 
[11/23 21:47:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 103.4724,	0.8395 s / batch. (data: 5.41e-03). ETA=7:23:09, max mem: 20.9 GB 
[11/23 21:49:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 181.9322,	0.8476 s / batch. (data: 1.05e-02). ETA=7:26:02, max mem: 20.9 GB 
[11/23 21:50:01][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 1.50e-01, avg batch time: 0.9764, average train loss: 111.9246
[11/23 21:50:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-05, avg batch time: 0.3088, average loss: 79.2636
[11/23 21:50:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.53	
[11/23 21:50:57][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 35.16841607689501
[11/23 21:52:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 351.5696,	0.8258 s / batch. (data: 2.19e-02). ETA=7:12:27, max mem: 20.9 GB 
[11/23 21:54:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 40.4058,	0.8454 s / batch. (data: 2.14e-02). ETA=7:21:18, max mem: 20.9 GB 
[11/23 21:55:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 184.5063,	0.8353 s / batch. (data: 1.13e-02). ETA=7:14:40, max mem: 20.9 GB 
[11/23 21:57:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 34.6635,	0.8199 s / batch. (data: 2.98e-04). ETA=7:05:17, max mem: 20.9 GB 
[11/23 21:59:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.6811,	0.8277 s / batch. (data: 4.41e-04). ETA=7:07:57, max mem: 20.9 GB 
[11/23 21:59:52][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 1.41e-01, avg batch time: 0.9678, average train loss: 126.6946
[11/23 22:00:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-05, avg batch time: 0.3107, average loss: 172.6289
[11/23 22:00:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 55.42	
[11/23 22:00:47][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 34.365164835397806
[11/23 22:02:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.7575,	0.8145 s / batch. (data: 3.12e-04). ETA=6:59:02, max mem: 20.9 GB 
[11/23 22:04:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 76.7605,	0.8115 s / batch. (data: 5.45e-03). ETA=6:56:08, max mem: 20.9 GB 
[11/23 22:05:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 517.3029,	0.8550 s / batch. (data: 1.89e-02). ETA=7:17:00, max mem: 20.9 GB 
[11/23 22:07:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 17.2243,	0.8360 s / batch. (data: 3.34e-04). ETA=7:05:53, max mem: 20.9 GB 
[11/23 22:08:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 47.1717,	0.8207 s / batch. (data: 1.05e-02). ETA=6:56:45, max mem: 20.9 GB 
[11/23 22:09:41][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 1.37e-01, avg batch time: 0.9654, average train loss: 104.8145
[11/23 22:10:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.23e-05, avg batch time: 0.3095, average loss: 39.0389
[11/23 22:10:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.39	
[11/23 22:10:36][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 33.55050358314172
[11/23 22:12:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 97.2375,	0.8593 s / batch. (data: 2.45e-02). ETA=7:14:09, max mem: 20.9 GB 
[11/23 22:13:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1137.4886,	0.8599 s / batch. (data: 1.10e-02). ETA=7:13:00, max mem: 20.9 GB 
[11/23 22:15:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 211.1017,	0.8169 s / batch. (data: 5.45e-03). ETA=6:50:01, max mem: 20.9 GB 
[11/23 22:17:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 21.3189,	0.8335 s / batch. (data: 7.81e-04). ETA=6:56:57, max mem: 20.9 GB 
[11/23 22:18:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 243.4124,	0.8400 s / batch. (data: 3.19e-04). ETA=6:58:48, max mem: 20.9 GB 
[11/23 22:19:35][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 1.48e-01, avg batch time: 0.9749, average train loss: 112.3867
[11/23 22:20:30][INFO] visual_prompt:  316: Inference (val):avg data time: 2.92e-05, avg batch time: 0.3118, average loss: 77.4649
[11/23 22:20:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.69	
[11/23 22:20:30][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 32.72542485937369
[11/23 22:22:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 54.7013,	0.8240 s / batch. (data: 2.95e-04). ETA=6:48:44, max mem: 20.9 GB 
[11/23 22:23:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 237.6187,	1.2520 s / batch. (data: 4.08e-01). ETA=10:18:56, max mem: 20.9 GB 
[11/23 22:25:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.9041,	0.8520 s / batch. (data: 1.41e-02). ETA=6:59:46, max mem: 20.9 GB 
[11/23 22:26:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 57.4155,	0.8433 s / batch. (data: 8.29e-04). ETA=6:54:05, max mem: 20.9 GB 
[11/23 22:28:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 181.2313,	0.8200 s / batch. (data: 2.89e-04). ETA=6:41:17, max mem: 20.9 GB 
[11/23 22:29:22][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 1.34e-01, avg batch time: 0.9608, average train loss: 102.7517
[11/23 22:30:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3102, average loss: 113.9753
[11/23 22:30:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.59	
[11/23 22:30:16][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 31.89093389542498
[11/23 22:31:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 101.8445,	0.8341 s / batch. (data: 2.06e-02). ETA=6:46:03, max mem: 20.9 GB 
[11/23 22:33:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 83.2641,	0.8548 s / batch. (data: 1.05e-02). ETA=6:54:41, max mem: 20.9 GB 
[11/23 22:35:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 197.4628,	1.5880 s / batch. (data: 7.32e-01). ETA=12:47:45, max mem: 20.9 GB 
[11/23 22:36:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 575.2391,	0.8368 s / batch. (data: 7.96e-03). ETA=6:43:10, max mem: 20.9 GB 
[11/23 22:38:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 41.3837,	0.8271 s / batch. (data: 1.60e-02). ETA=6:37:07, max mem: 20.9 GB 
[11/23 22:39:08][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 1.36e-01, avg batch time: 0.9627, average train loss: 124.2199
[11/23 22:40:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.41e-05, avg batch time: 0.3079, average loss: 174.4985
[11/23 22:40:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.39	
[11/23 22:40:03][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 31.04804738999169
[11/23 22:41:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 109.8831,	0.8359 s / batch. (data: 1.50e-02). ETA=6:39:12, max mem: 20.9 GB 
[11/23 22:43:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 28.6203,	0.8425 s / batch. (data: 2.85e-04). ETA=6:40:58, max mem: 20.9 GB 
[11/23 22:44:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 182.3253,	0.8320 s / batch. (data: 2.77e-04). ETA=6:34:35, max mem: 20.9 GB 
[11/23 22:46:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 143.3421,	0.8216 s / batch. (data: 7.87e-04). ETA=6:28:17, max mem: 20.9 GB 
[11/23 22:48:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 57.9728,	0.8281 s / batch. (data: 2.72e-04). ETA=6:29:58, max mem: 20.9 GB 
[11/23 22:48:59][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 1.42e-01, avg batch time: 0.9690, average train loss: 106.7669
[11/23 22:49:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.16e-05, avg batch time: 0.3094, average loss: 70.2803
[11/23 22:49:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.07	
[11/23 22:49:54][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 30.19779227044398
[11/23 22:51:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 135.8259,	0.8240 s / batch. (data: 3.04e-04). ETA=6:25:56, max mem: 20.9 GB 
[11/23 22:53:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 353.7992,	0.8201 s / batch. (data: 3.02e-04). ETA=6:22:44, max mem: 20.9 GB 
[11/23 22:54:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 450.7252,	0.8440 s / batch. (data: 7.66e-04). ETA=6:32:29, max mem: 20.9 GB 
[11/23 22:56:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0000,	0.8441 s / batch. (data: 7.98e-03). ETA=6:31:07, max mem: 20.9 GB 
[11/23 22:57:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 85.6277,	0.8320 s / batch. (data: 3.04e-04). ETA=6:24:08, max mem: 20.9 GB 
[11/23 22:58:48][INFO] visual_prompt:  217: Epoch 50 / 100: avg data time: 1.39e-01, avg batch time: 0.9658, average train loss: 127.9936
[11/23 22:59:43][INFO] visual_prompt:  316: Inference (val):avg data time: 7.06e-05, avg batch time: 0.3088, average loss: 134.5663
[11/23 22:59:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.63	
[11/23 22:59:43][INFO] visual_prompt:   42: Stopping early.
