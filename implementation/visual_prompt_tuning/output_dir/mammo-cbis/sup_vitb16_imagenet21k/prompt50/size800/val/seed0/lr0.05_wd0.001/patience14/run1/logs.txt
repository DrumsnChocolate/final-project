[12/02 10:29:23][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[12/02 10:29:23][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 10:29:23][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[12/02 10:29:23][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 10:29:23][INFO] visual_prompt:  108: Training with config:
[12/02 10:29:23][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr0.05_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/02 10:29:23][INFO] visual_prompt:   55: Loading training data...
[12/02 10:29:23][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[12/02 10:29:23][INFO] visual_prompt:   57: Loading validation data...
[12/02 10:29:23][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[12/02 10:29:23][INFO] visual_prompt:   38: Constructing models...
[12/02 10:29:26][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[12/02 10:29:26][INFO] visual_prompt:   54: tuned percent:0.525
[12/02 10:29:26][INFO] visual_prompt:   40: Device used for model: 0
[12/02 10:29:26][INFO] visual_prompt:   40: Setting up Evaluator...
[12/02 10:29:26][INFO] visual_prompt:   42: Setting up Trainer...
[12/02 10:29:26][INFO] visual_prompt:   45: 	Setting up the optimizer...
[12/02 10:29:26][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[12/02 10:31:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8280 s / batch. (data: 2.90e-04). ETA=12:41:45, max mem: 20.9 GB 
[12/02 10:32:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8218 s / batch. (data: 2.92e-04). ETA=12:34:41, max mem: 20.9 GB 
[12/02 10:34:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	1.2519 s / batch. (data: 4.18e-01). ETA=19:07:35, max mem: 20.9 GB 
[12/02 10:36:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8236 s / batch. (data: 3.16e-04). ETA=12:33:33, max mem: 20.9 GB 
[12/02 10:38:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8240 s / batch. (data: 3.16e-04). ETA=12:32:34, max mem: 20.9 GB 
[12/02 10:39:02][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 2.17e-01, avg batch time: 1.0408, average train loss: 1.5403
[12/02 10:40:01][INFO] visual_prompt:  316: Inference (val):avg data time: 2.17e-04, avg batch time: 0.3087, average loss: 1.5201
[12/02 10:40:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[12/02 10:40:01][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/02 10:41:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7377,	0.8200 s / batch. (data: 3.22e-04). ETA=12:26:50, max mem: 20.9 GB 
[12/02 10:43:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4376,	0.8361 s / batch. (data: 3.13e-04). ETA=12:40:04, max mem: 20.9 GB 
[12/02 10:45:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7006,	1.2121 s / batch. (data: 3.92e-01). ETA=18:19:54, max mem: 20.9 GB 
[12/02 10:46:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7505,	0.8290 s / batch. (data: 2.94e-04). ETA=12:30:53, max mem: 20.9 GB 
[12/02 10:48:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6929,	0.8320 s / batch. (data: 3.24e-04). ETA=12:32:13, max mem: 20.9 GB 
[12/02 10:49:34][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 2.12e-01, avg batch time: 1.0356, average train loss: 0.7638
[12/02 10:50:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.75e-05, avg batch time: 0.3072, average loss: 0.7317
[12/02 10:50:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.88	
[12/02 10:50:33][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/02 10:52:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7687,	0.8160 s / batch. (data: 3.35e-04). ETA=12:15:39, max mem: 20.9 GB 
[12/02 10:54:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7558,	1.2445 s / batch. (data: 4.25e-01). ETA=18:39:55, max mem: 20.9 GB 
[12/02 10:55:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5115,	0.8400 s / batch. (data: 3.82e-04). ETA=12:34:29, max mem: 20.9 GB 
[12/02 10:57:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5871,	0.8154 s / batch. (data: 2.98e-04). ETA=12:11:03, max mem: 20.9 GB 
[12/02 10:59:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6927,	1.4720 s / batch. (data: 6.40e-01). ETA=21:57:18, max mem: 20.9 GB 
[12/02 11:00:06][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 2.11e-01, avg batch time: 1.0352, average train loss: 0.7450
[12/02 11:01:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.91e-05, avg batch time: 0.3076, average loss: 0.7359
[12/02 11:01:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.11	
[12/02 11:01:05][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.015
[12/02 11:02:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7596,	0.8083 s / batch. (data: 2.99e-04). ETA=12:01:18, max mem: 20.9 GB 
[12/02 11:04:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6530,	0.8320 s / batch. (data: 5.44e-03). ETA=12:21:03, max mem: 20.9 GB 
[12/02 11:06:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6034,	1.4464 s / batch. (data: 6.41e-01). ETA=21:25:53, max mem: 20.9 GB 
[12/02 11:07:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7585,	0.9740 s / batch. (data: 1.51e-01). ETA=14:24:15, max mem: 20.9 GB 
[12/02 11:09:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5431,	3.3676 s / batch. (data: 2.56e+00). ETA=2 days, 1:42:36, max mem: 20.9 GB 
[12/02 11:10:21][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 1.81e-01, avg batch time: 1.0045, average train loss: 0.7482
[12/02 11:11:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3063, average loss: 0.6863
[12/02 11:11:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 57.11	
[12/02 11:11:15][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/02 11:12:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4273,	0.8320 s / batch. (data: 2.99e-04). ETA=12:14:44, max mem: 20.9 GB 
[12/02 11:14:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7193,	1.0640 s / batch. (data: 2.36e-01). ETA=15:37:52, max mem: 20.9 GB 
[12/02 11:16:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8296,	0.8420 s / batch. (data: 2.26e-02). ETA=12:20:45, max mem: 20.9 GB 
[12/02 11:17:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5730,	0.8370 s / batch. (data: 5.48e-03). ETA=12:15:01, max mem: 20.9 GB 
[12/02 11:19:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6621,	0.8460 s / batch. (data: 2.19e-02). ETA=12:21:27, max mem: 20.9 GB 
[12/02 11:20:11][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 1.44e-01, avg batch time: 0.9676, average train loss: 0.7475
[12/02 11:21:05][INFO] visual_prompt:  316: Inference (val):avg data time: 2.04e-04, avg batch time: 0.3069, average loss: 0.6859
[12/02 11:21:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.79	
[12/02 11:21:05][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.025
[12/02 11:22:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5581,	0.8348 s / batch. (data: 7.60e-04). ETA=12:09:33, max mem: 20.9 GB 
[12/02 11:24:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7856,	0.8199 s / batch. (data: 7.96e-03). ETA=11:55:07, max mem: 20.9 GB 
[12/02 11:25:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5082,	0.8267 s / batch. (data: 5.44e-03). ETA=11:59:41, max mem: 20.9 GB 
[12/02 11:27:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6244,	0.8145 s / batch. (data: 3.13e-04). ETA=11:47:45, max mem: 20.9 GB 
[12/02 11:29:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6543,	0.8314 s / batch. (data: 9.72e-03). ETA=12:01:02, max mem: 20.9 GB 
[12/02 11:30:03][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 1.48e-01, avg batch time: 0.9723, average train loss: 0.7310
[12/02 11:30:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3072, average loss: 0.6828
[12/02 11:30:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 56.77	
[12/02 11:30:58][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.03
[12/02 11:32:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4717,	0.8400 s / batch. (data: 2.78e-04). ETA=12:06:21, max mem: 20.9 GB 
[12/02 11:34:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5221,	0.8069 s / batch. (data: 3.91e-04). ETA=11:36:22, max mem: 20.9 GB 
[12/02 11:35:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8645,	1.7740 s / batch. (data: 9.19e-01). ETA=1 day, 1:28:02, max mem: 20.9 GB 
[12/02 11:37:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7020,	1.9840 s / batch. (data: 1.17e+00). ETA=1 day, 4:25:37, max mem: 20.9 GB 
[12/02 11:39:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8363,	0.8229 s / batch. (data: 4.58e-04). ETA=11:46:05, max mem: 20.9 GB 
[12/02 11:39:53][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.44e-01, avg batch time: 0.9671, average train loss: 0.7344
[12/02 11:40:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.48e-05, avg batch time: 0.3056, average loss: 0.7813
[12/02 11:40:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.20	
[12/02 11:40:48][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/02 11:42:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7149,	0.8499 s / batch. (data: 2.07e-02). ETA=12:07:04, max mem: 20.9 GB 
[12/02 11:44:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1066,	0.8359 s / batch. (data: 1.56e-02). ETA=11:53:42, max mem: 20.9 GB 
[12/02 11:45:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6177,	0.8077 s / batch. (data: 3.02e-04). ETA=11:28:18, max mem: 20.9 GB 
[12/02 11:47:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7028,	0.8400 s / batch. (data: 2.97e-04). ETA=11:54:23, max mem: 20.9 GB 
[12/02 11:48:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7957,	0.9827 s / batch. (data: 1.76e-01). ETA=13:54:05, max mem: 20.9 GB 
[12/02 11:49:44][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 1.46e-01, avg batch time: 0.9682, average train loss: 0.7526
[12/02 11:50:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.54e-05, avg batch time: 0.3054, average loss: 0.7457
[12/02 11:50:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.94	
[12/02 11:50:39][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/02 11:52:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4952,	0.8534 s / batch. (data: 9.32e-03). ETA=12:02:10, max mem: 20.9 GB 
[12/02 11:53:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5725,	0.8177 s / batch. (data: 5.40e-03). ETA=11:30:38, max mem: 20.9 GB 
[12/02 11:55:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6663,	1.6657 s / batch. (data: 8.18e-01). ETA=23:24:05, max mem: 20.9 GB 
[12/02 11:57:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5779,	0.8480 s / batch. (data: 7.97e-03). ETA=11:53:24, max mem: 20.9 GB 
[12/02 11:58:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6268,	0.8487 s / batch. (data: 1.05e-02). ETA=11:52:35, max mem: 20.9 GB 
[12/02 11:59:32][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 1.41e-01, avg batch time: 0.9645, average train loss: 0.7348
[12/02 12:00:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.41e-05, avg batch time: 0.3064, average loss: 0.6957
[12/02 12:00:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 58.67	
[12/02 12:00:27][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/02 12:02:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6762,	0.8388 s / batch. (data: 7.45e-04). ETA=11:42:06, max mem: 20.9 GB 
[12/02 12:03:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6689,	0.8308 s / batch. (data: 7.95e-03). ETA=11:34:03, max mem: 20.9 GB 
[12/02 12:05:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7099,	0.8498 s / batch. (data: 2.18e-02). ETA=11:48:32, max mem: 20.9 GB 
[12/02 12:06:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8645,	0.8575 s / batch. (data: 9.50e-03). ETA=11:53:27, max mem: 20.9 GB 
[12/02 12:08:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9624,	0.8257 s / batch. (data: 2.96e-04). ETA=11:25:39, max mem: 20.9 GB 
[12/02 12:09:20][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 1.39e-01, avg batch time: 0.9635, average train loss: 0.7458
[12/02 12:10:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.3070, average loss: 0.8842
[12/02 12:10:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.55	
[12/02 12:10:14][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.05
[12/02 12:11:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6035,	0.8418 s / batch. (data: 1.56e-02). ETA=11:36:50, max mem: 20.9 GB 
[12/02 12:13:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2721,	0.8438 s / batch. (data: 2.94e-04). ETA=11:37:09, max mem: 20.9 GB 
[12/02 12:15:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4828,	1.9279 s / batch. (data: 1.09e+00). ETA=1 day, 2:29:33, max mem: 20.9 GB 
[12/02 12:16:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6977,	0.8189 s / batch. (data: 7.97e-03). ETA=11:13:50, max mem: 20.9 GB 
[12/02 12:18:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6663,	0.8359 s / batch. (data: 4.20e-04). ETA=11:26:26, max mem: 20.9 GB 
[12/02 12:19:08][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 1.40e-01, avg batch time: 0.9654, average train loss: 0.7363
[12/02 12:20:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3073, average loss: 0.6960
[12/02 12:20:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 65.81	
[12/02 12:20:03][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/02 12:21:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0449,	0.8103 s / batch. (data: 3.09e-04). ETA=11:03:17, max mem: 20.9 GB 
[12/02 12:23:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5499,	0.8194 s / batch. (data: 5.44e-03). ETA=11:09:22, max mem: 20.9 GB 
[12/02 12:24:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7099,	0.8188 s / batch. (data: 7.94e-03). ETA=11:07:33, max mem: 20.9 GB 
[12/02 12:26:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7403,	0.8449 s / batch. (data: 3.07e-02). ETA=11:27:25, max mem: 20.9 GB 
[12/02 12:28:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3390,	0.8389 s / batch. (data: 6.86e-04). ETA=11:21:08, max mem: 20.9 GB 
[12/02 12:29:01][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.49e-01, avg batch time: 0.9724, average train loss: 0.7357
[12/02 12:29:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.41e-05, avg batch time: 0.3062, average loss: 0.8484
[12/02 12:29:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.39	
[12/02 12:29:56][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/02 12:31:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6136,	0.8146 s / batch. (data: 3.08e-04). ETA=10:59:20, max mem: 20.9 GB 
[12/02 12:33:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7408,	0.8365 s / batch. (data: 5.46e-03). ETA=11:15:41, max mem: 20.9 GB 
[12/02 12:34:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6415,	1.7560 s / batch. (data: 9.24e-01). ETA=23:35:26, max mem: 20.9 GB 
[12/02 12:36:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9823,	0.8441 s / batch. (data: 3.21e-04). ETA=11:19:00, max mem: 20.9 GB 
[12/02 12:37:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7093,	0.8440 s / batch. (data: 2.85e-04). ETA=11:17:30, max mem: 20.9 GB 
[12/02 12:38:49][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 1.40e-01, avg batch time: 0.9638, average train loss: 0.7425
[12/02 12:39:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.39e-05, avg batch time: 0.3075, average loss: 0.6855
[12/02 12:39:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.59	
[12/02 12:39:43][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.685
[12/02 12:39:43][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/02 12:41:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8391,	0.8129 s / batch. (data: 4.84e-04). ETA=10:50:26, max mem: 20.9 GB 
[12/02 12:42:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6977,	0.8188 s / batch. (data: 5.42e-03). ETA=10:53:51, max mem: 20.9 GB 
[12/02 12:44:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6982,	0.8200 s / batch. (data: 3.10e-04). ETA=10:53:24, max mem: 20.9 GB 
[12/02 12:46:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6335,	0.8349 s / batch. (data: 1.19e-02). ETA=11:03:55, max mem: 20.9 GB 
[12/02 12:47:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8423,	0.8359 s / batch. (data: 1.55e-02). ETA=11:03:16, max mem: 20.9 GB 
[12/02 12:48:35][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 1.38e-01, avg batch time: 0.9617, average train loss: 0.7145
[12/02 12:49:30][INFO] visual_prompt:  316: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3053, average loss: 0.7704
[12/02 12:49:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.79	
[12/02 12:49:30][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/02 12:51:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6784,	0.8397 s / batch. (data: 2.49e-02). ETA=11:04:09, max mem: 20.9 GB 
[12/02 12:52:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6306,	0.8247 s / batch. (data: 3.26e-04). ETA=10:50:55, max mem: 20.9 GB 
[12/02 12:54:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7302,	0.8316 s / batch. (data: 8.01e-04). ETA=10:54:57, max mem: 20.9 GB 
[12/02 12:55:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5427,	1.1536 s / batch. (data: 3.20e-01). ETA=15:06:42, max mem: 20.9 GB 
[12/02 12:57:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9513,	1.3215 s / batch. (data: 5.02e-01). ETA=17:16:24, max mem: 20.9 GB 
[12/02 12:58:24][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.42e-01, avg batch time: 0.9652, average train loss: 0.7157
[12/02 12:59:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.58e-05, avg batch time: 0.3061, average loss: 0.6965
[12/02 12:59:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.65	
[12/02 12:59:18][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/02 13:00:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5941,	0.8163 s / batch. (data: 7.95e-03). ETA=10:38:09, max mem: 20.9 GB 
[12/02 13:02:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7367,	0.8200 s / batch. (data: 2.76e-04). ETA=10:39:40, max mem: 20.9 GB 
[12/02 13:04:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1750,	0.8296 s / batch. (data: 1.24e-02). ETA=10:45:48, max mem: 20.9 GB 
[12/02 13:05:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5177,	0.8445 s / batch. (data: 5.85e-03). ETA=10:55:59, max mem: 20.9 GB 
[12/02 13:07:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6695,	0.8180 s / batch. (data: 3.22e-04). ETA=10:34:01, max mem: 20.9 GB 
[12/02 13:08:11][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 1.39e-01, avg batch time: 0.9624, average train loss: 0.7071
[12/02 13:09:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.31e-05, avg batch time: 0.3065, average loss: 0.7639
[12/02 13:09:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.04	
[12/02 13:09:05][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/02 13:10:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4896,	0.8246 s / batch. (data: 5.48e-03). ETA=10:37:00, max mem: 20.9 GB 
[12/02 13:12:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6011,	0.8240 s / batch. (data: 1.20e-02). ETA=10:35:12, max mem: 20.9 GB 
[12/02 13:13:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9392,	0.8080 s / batch. (data: 3.01e-04). ETA=10:21:32, max mem: 20.9 GB 
[12/02 13:15:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5487,	1.1160 s / batch. (data: 2.82e-01). ETA=14:16:32, max mem: 20.9 GB 
[12/02 13:17:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6076,	1.5000 s / batch. (data: 6.78e-01). ETA=19:08:47, max mem: 20.9 GB 
[12/02 13:17:59][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 1.42e-01, avg batch time: 0.9647, average train loss: 0.7054
[12/02 13:18:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3076, average loss: 0.7308
[12/02 13:18:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.88	
[12/02 13:18:53][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/02 13:20:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6871,	0.8204 s / batch. (data: 4.38e-03). ETA=10:26:14, max mem: 20.9 GB 
[12/02 13:22:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7586,	0.8424 s / batch. (data: 7.66e-04). ETA=10:41:34, max mem: 20.9 GB 
[12/02 13:23:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5201,	0.8200 s / batch. (data: 3.24e-04). ETA=10:23:10, max mem: 20.9 GB 
[12/02 13:25:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6085,	0.8213 s / batch. (data: 2.98e-04). ETA=10:22:47, max mem: 20.9 GB 
[12/02 13:26:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7352,	0.8265 s / batch. (data: 3.44e-04). ETA=10:25:24, max mem: 20.9 GB 
[12/02 13:27:46][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 1.39e-01, avg batch time: 0.9634, average train loss: 0.7040
[12/02 13:28:41][INFO] visual_prompt:  316: Inference (val):avg data time: 3.57e-05, avg batch time: 0.3058, average loss: 0.6981
[12/02 13:28:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.49	
[12/02 13:28:41][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/02 13:30:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1094,	0.8354 s / batch. (data: 1.05e-02). ETA=10:29:57, max mem: 20.9 GB 
[12/02 13:31:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6763,	0.8213 s / batch. (data: 9.27e-03). ETA=10:18:00, max mem: 20.9 GB 
[12/02 13:33:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0866,	0.8151 s / batch. (data: 3.28e-04). ETA=10:11:57, max mem: 20.9 GB 
[12/02 13:35:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5175,	0.8065 s / batch. (data: 2.74e-04). ETA=10:04:09, max mem: 20.9 GB 
[12/02 13:36:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9461,	0.8290 s / batch. (data: 1.55e-02). ETA=10:19:38, max mem: 20.9 GB 
[12/02 13:37:32][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.35e-01, avg batch time: 0.9599, average train loss: 0.6995
[12/02 13:38:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3056, average loss: 0.6759
[12/02 13:38:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.89	
[12/02 13:38:27][INFO] visual_prompt:   36: Best epoch 19: best metric: -0.676
[12/02 13:38:27][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/02 13:40:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8614,	0.8336 s / batch. (data: 2.98e-04). ETA=10:20:55, max mem: 20.9 GB 
[12/02 13:41:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6265,	0.8320 s / batch. (data: 2.99e-04). ETA=10:18:21, max mem: 20.9 GB 
[12/02 13:43:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6069,	0.8240 s / batch. (data: 2.93e-04). ETA=10:11:01, max mem: 20.9 GB 
[12/02 13:44:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7811,	0.8153 s / batch. (data: 3.11e-04). ETA=10:03:13, max mem: 20.9 GB 
[12/02 13:46:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7462,	0.8400 s / batch. (data: 3.10e-04). ETA=10:20:05, max mem: 20.9 GB 
[12/02 13:47:20][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 1.40e-01, avg batch time: 0.9638, average train loss: 0.7158
[12/02 13:48:14][INFO] visual_prompt:  316: Inference (val):avg data time: 4.08e-04, avg batch time: 0.3055, average loss: 0.7135
[12/02 13:48:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 59.63	
[12/02 13:48:14][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/02 13:49:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5148,	0.8400 s / batch. (data: 3.05e-04). ETA=10:17:57, max mem: 20.9 GB 
[12/02 13:51:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6576,	0.8359 s / batch. (data: 2.88e-02). ETA=10:13:32, max mem: 20.9 GB 
[12/02 13:53:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7701,	0.8331 s / batch. (data: 9.05e-03). ETA=10:10:06, max mem: 20.9 GB 
[12/02 13:54:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6121,	0.8320 s / batch. (data: 2.85e-04). ETA=10:07:54, max mem: 20.9 GB 
[12/02 13:56:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7018,	0.8321 s / batch. (data: 7.96e-03). ETA=10:06:34, max mem: 20.9 GB 
[12/02 13:57:07][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 1.38e-01, avg batch time: 0.9621, average train loss: 0.7203
[12/02 13:58:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3080, average loss: 0.7989
[12/02 13:58:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.46	
[12/02 13:58:01][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/02 13:59:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6547,	0.8118 s / batch. (data: 2.63e-04). ETA=9:49:43, max mem: 20.9 GB 
[12/02 14:01:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5790,	0.8280 s / batch. (data: 2.88e-04). ETA=10:00:07, max mem: 20.9 GB 
[12/02 14:02:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4737,	0.8320 s / batch. (data: 3.04e-04). ETA=10:01:38, max mem: 20.9 GB 
[12/02 14:04:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6152,	0.8160 s / batch. (data: 2.89e-04). ETA=9:48:42, max mem: 20.9 GB 
[12/02 14:06:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8641,	0.8160 s / batch. (data: 2.98e-04). ETA=9:47:21, max mem: 20.9 GB 
[12/02 14:06:54][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 1.40e-01, avg batch time: 0.9640, average train loss: 0.7176
[12/02 14:07:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.48e-05, avg batch time: 0.3066, average loss: 0.7094
[12/02 14:07:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.11	
[12/02 14:07:49][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/02 14:09:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7815,	0.9621 s / batch. (data: 1.47e-01). ETA=11:30:04, max mem: 20.9 GB 
[12/02 14:11:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7190,	0.8239 s / batch. (data: 3.09e-04). ETA=9:49:34, max mem: 20.9 GB 
[12/02 14:12:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7676,	0.8160 s / batch. (data: 2.94e-04). ETA=9:42:31, max mem: 20.9 GB 
[12/02 14:14:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4908,	0.8132 s / batch. (data: 5.43e-03). ETA=9:39:10, max mem: 20.9 GB 
[12/02 14:15:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7832,	0.8200 s / batch. (data: 7.96e-03). ETA=9:42:39, max mem: 20.9 GB 
[12/02 14:16:44][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 1.43e-01, avg batch time: 0.9664, average train loss: 0.7149
[12/02 14:17:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3069, average loss: 0.6814
[12/02 14:17:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.36	
[12/02 14:17:39][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/02 14:19:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8074,	0.8453 s / batch. (data: 9.21e-03). ETA=9:58:27, max mem: 20.9 GB 
[12/02 14:20:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7910,	0.8160 s / batch. (data: 2.70e-04). ETA=9:36:23, max mem: 20.9 GB 
[12/02 14:22:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6703,	1.0467 s / batch. (data: 2.24e-01). ETA=12:17:36, max mem: 20.9 GB 
[12/02 14:24:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7196,	0.8069 s / batch. (data: 3.10e-04). ETA=9:27:15, max mem: 20.9 GB 
[12/02 14:25:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9053,	0.8480 s / batch. (data: 3.13e-04). ETA=9:54:44, max mem: 20.9 GB 
[12/02 14:26:32][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 1.39e-01, avg batch time: 0.9633, average train loss: 0.7228
[12/02 14:27:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3061, average loss: 0.6752
[12/02 14:27:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 61.10	
[12/02 14:27:26][INFO] visual_prompt:   36: Best epoch 24: best metric: -0.675
[12/02 14:27:26][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/02 14:29:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5708,	0.8353 s / batch. (data: 1.05e-02). ETA=9:43:40, max mem: 20.9 GB 
[12/02 14:30:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8857,	0.8480 s / batch. (data: 3.30e-02). ETA=9:51:09, max mem: 20.9 GB 
[12/02 14:32:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6814,	0.8214 s / batch. (data: 2.86e-04). ETA=9:31:15, max mem: 20.9 GB 
[12/02 14:33:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6599,	1.2442 s / batch. (data: 4.30e-01). ETA=14:23:11, max mem: 20.9 GB 
[12/02 14:35:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7255,	1.3959 s / batch. (data: 5.89e-01). ETA=16:06:08, max mem: 20.9 GB 
[12/02 14:36:22][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 1.42e-01, avg batch time: 0.9679, average train loss: 0.7036
[12/02 14:37:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.76e-05, avg batch time: 0.3076, average loss: 0.6781
[12/02 14:37:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 63.18	
[12/02 14:37:16][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/02 14:38:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5859,	0.8286 s / batch. (data: 1.05e-02). ETA=9:31:23, max mem: 20.9 GB 
[12/02 14:40:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5317,	1.5440 s / batch. (data: 7.22e-01). ETA=17:42:08, max mem: 20.9 GB 
[12/02 14:42:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5353,	0.8277 s / batch. (data: 5.91e-03). ETA=9:28:02, max mem: 20.9 GB 
[12/02 14:43:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5722,	0.8161 s / batch. (data: 2.67e-04). ETA=9:18:39, max mem: 20.9 GB 
[12/02 14:45:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7408,	0.8240 s / batch. (data: 2.47e-04). ETA=9:22:44, max mem: 20.9 GB 
[12/02 14:46:09][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 1.39e-01, avg batch time: 0.9624, average train loss: 0.7099
[12/02 14:47:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.43e-05, avg batch time: 0.3069, average loss: 0.7223
[12/02 14:47:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.64	
[12/02 14:47:03][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/02 14:48:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5194,	0.8121 s / batch. (data: 5.40e-03). ETA=9:12:33, max mem: 20.9 GB 
[12/02 14:50:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6762,	0.9024 s / batch. (data: 7.65e-02). ETA=10:12:28, max mem: 20.9 GB 
[12/02 14:51:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7751,	0.8127 s / batch. (data: 5.77e-03). ETA=9:10:12, max mem: 20.9 GB 
[12/02 14:53:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7658,	0.8476 s / batch. (data: 7.73e-04). ETA=9:32:24, max mem: 20.9 GB 
[12/02 14:55:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0038,	0.8541 s / batch. (data: 5.99e-03). ETA=9:35:24, max mem: 20.9 GB 
[12/02 14:55:56][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 1.41e-01, avg batch time: 0.9640, average train loss: 0.7126
[12/02 14:56:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.36e-05, avg batch time: 0.3062, average loss: 0.7041
[12/02 14:56:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 60.33	
[12/02 14:56:51][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/02 14:58:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5460,	0.8240 s / batch. (data: 3.01e-04). ETA=9:13:01, max mem: 20.9 GB 
[12/02 15:00:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4671,	0.8120 s / batch. (data: 2.87e-04). ETA=9:03:37, max mem: 20.9 GB 
[12/02 15:01:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6622,	1.2360 s / batch. (data: 4.01e-01). ETA=13:45:25, max mem: 20.9 GB 
[12/02 15:03:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8144,	0.8479 s / batch. (data: 1.02e-02). ETA=9:24:49, max mem: 20.9 GB 
[12/02 15:04:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4774,	0.8263 s / batch. (data: 5.42e-03). ETA=9:09:02, max mem: 20.9 GB 
[12/02 15:05:44][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.39e-01, avg batch time: 0.9628, average train loss: 0.7016
[12/02 15:06:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3090, average loss: 0.6792
[12/02 15:06:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.01	
[12/02 15:06:38][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/02 15:08:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4954,	0.8480 s / batch. (data: 3.15e-04). ETA=9:21:17, max mem: 20.9 GB 
[12/02 15:09:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7008,	1.7410 s / batch. (data: 9.02e-01). ETA=19:09:30, max mem: 20.9 GB 
[12/02 15:11:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6531,	0.8427 s / batch. (data: 2.06e-02). ETA=9:15:01, max mem: 20.9 GB 
[12/02 15:13:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6115,	1.2109 s / batch. (data: 3.84e-01). ETA=13:15:28, max mem: 20.9 GB 
[12/02 15:14:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6648,	0.8219 s / batch. (data: 5.50e-03). ETA=8:58:33, max mem: 20.9 GB 
[12/02 15:15:31][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 1.39e-01, avg batch time: 0.9636, average train loss: 0.7010
[12/02 15:16:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-05, avg batch time: 0.3065, average loss: 0.6879
[12/02 15:16:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.27	
[12/02 15:16:26][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/02 15:18:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7262,	0.8426 s / batch. (data: 1.05e-02). ETA=9:09:58, max mem: 20.9 GB 
[12/02 15:19:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5897,	0.8169 s / batch. (data: 3.00e-04). ETA=8:51:48, max mem: 20.9 GB 
[12/02 15:21:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7719,	1.2779 s / batch. (data: 4.70e-01). ETA=13:49:51, max mem: 20.9 GB 
[12/02 15:22:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7983,	1.1949 s / batch. (data: 3.63e-01). ETA=12:53:55, max mem: 20.9 GB 
[12/02 15:24:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5583,	1.3720 s / batch. (data: 5.39e-01). ETA=14:46:22, max mem: 20.9 GB 
[12/02 15:25:27][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 1.52e-01, avg batch time: 0.9780, average train loss: 0.7033
[12/02 15:26:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.73e-05, avg batch time: 0.3071, average loss: 0.6767
[12/02 15:26:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.39	
[12/02 15:26:21][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/02 15:28:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5774,	0.8300 s / batch. (data: 4.12e-04). ETA=8:54:05, max mem: 20.9 GB 
[12/02 15:29:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6788,	0.8234 s / batch. (data: 2.95e-04). ETA=8:48:27, max mem: 20.9 GB 
[12/02 15:31:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7060,	0.8192 s / batch. (data: 3.02e-04). ETA=8:44:23, max mem: 20.9 GB 
[12/02 15:32:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5595,	1.1770 s / batch. (data: 3.56e-01). ETA=12:31:31, max mem: 20.9 GB 
[12/02 15:34:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9313,	0.8533 s / batch. (data: 1.56e-02). ETA=9:03:26, max mem: 20.9 GB 
[12/02 15:35:17][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 1.45e-01, avg batch time: 0.9689, average train loss: 0.7032
[12/02 15:36:12][INFO] visual_prompt:  316: Inference (val):avg data time: 2.17e-04, avg batch time: 0.3070, average loss: 0.7206
[12/02 15:36:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.26	
[12/02 15:36:12][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/02 15:37:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0592,	0.8493 s / batch. (data: 2.82e-04). ETA=8:58:43, max mem: 20.9 GB 
[12/02 15:39:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6216,	0.8202 s / batch. (data: 1.05e-02). ETA=8:38:51, max mem: 20.9 GB 
[12/02 15:41:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7177,	0.8086 s / batch. (data: 3.16e-04). ETA=8:30:10, max mem: 20.9 GB 
[12/02 15:42:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8711,	0.8267 s / batch. (data: 7.95e-03). ETA=8:40:15, max mem: 20.9 GB 
[12/02 15:44:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7096,	0.8238 s / batch. (data: 2.90e-04). ETA=8:37:02, max mem: 20.9 GB 
[12/02 15:45:06][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 1.42e-01, avg batch time: 0.9651, average train loss: 0.7062
[12/02 15:46:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.55e-05, avg batch time: 0.3094, average loss: 0.6831
[12/02 15:46:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 62.71	
[12/02 15:46:00][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/02 15:47:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8688,	0.8377 s / batch. (data: 1.56e-02). ETA=8:43:36, max mem: 20.9 GB 
[12/02 15:49:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5514,	0.8296 s / batch. (data: 2.19e-02). ETA=8:37:10, max mem: 20.9 GB 
[12/02 15:50:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6120,	0.8401 s / batch. (data: 5.39e-03). ETA=8:42:18, max mem: 20.9 GB 
[12/02 15:52:28][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7258,	0.8440 s / batch. (data: 3.02e-04). ETA=8:43:20, max mem: 20.9 GB 
[12/02 15:54:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7402,	0.8215 s / batch. (data: 2.99e-04). ETA=8:28:00, max mem: 20.9 GB 
[12/02 15:54:54][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 1.40e-01, avg batch time: 0.9640, average train loss: 0.7120
[12/02 15:55:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.52e-05, avg batch time: 0.3053, average loss: 0.6715
[12/02 15:55:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.87	
[12/02 15:55:48][INFO] visual_prompt:   36: Best epoch 33: best metric: -0.672
[12/02 15:55:48][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/02 15:57:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7627,	1.0488 s / batch. (data: 2.31e-01). ETA=10:45:53, max mem: 20.9 GB 
[12/02 15:59:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7995,	0.8222 s / batch. (data: 3.89e-04). ETA=8:24:59, max mem: 20.9 GB 
[12/02 16:00:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5621,	0.8200 s / batch. (data: 3.22e-04). ETA=8:22:14, max mem: 20.9 GB 
[12/02 16:02:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8967,	0.8200 s / batch. (data: 3.11e-04). ETA=8:20:53, max mem: 20.9 GB 
[12/02 16:03:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8945,	1.3153 s / batch. (data: 5.00e-01). ETA=13:21:14, max mem: 20.9 GB 
[12/02 16:04:42][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 1.41e-01, avg batch time: 0.9650, average train loss: 0.6986
[12/02 16:05:37][INFO] visual_prompt:  316: Inference (val):avg data time: 2.22e-04, avg batch time: 0.3077, average loss: 0.6844
[12/02 16:05:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 60.98	
[12/02 16:05:37][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/02 16:07:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5672,	0.8280 s / batch. (data: 3.09e-04). ETA=8:22:17, max mem: 20.9 GB 
[12/02 16:08:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6980,	0.8280 s / batch. (data: 3.02e-04). ETA=8:20:55, max mem: 20.9 GB 
[12/02 16:10:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6637,	0.8242 s / batch. (data: 3.05e-04). ETA=8:17:13, max mem: 20.9 GB 
[12/02 16:12:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5880,	0.8309 s / batch. (data: 1.20e-02). ETA=8:19:54, max mem: 20.9 GB 
[12/02 16:13:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0165,	0.9488 s / batch. (data: 1.28e-01). ETA=9:29:15, max mem: 20.9 GB 
[12/02 16:14:31][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 1.42e-01, avg batch time: 0.9651, average train loss: 0.7095
[12/02 16:15:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.62e-05, avg batch time: 0.3064, average loss: 0.6787
[12/02 16:15:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.48	
[12/02 16:15:26][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/02 16:17:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8856,	0.8303 s / batch. (data: 1.19e-02). ETA=8:16:03, max mem: 20.9 GB 
[12/02 16:18:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7207,	0.8328 s / batch. (data: 2.99e-04). ETA=8:16:08, max mem: 20.9 GB 
[12/02 16:20:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3820,	0.8360 s / batch. (data: 2.76e-04). ETA=8:16:39, max mem: 20.9 GB 
[12/02 16:21:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7134,	0.8480 s / batch. (data: 3.75e-04). ETA=8:22:20, max mem: 20.9 GB 
[12/02 16:23:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7255,	0.9105 s / batch. (data: 1.03e-01). ETA=8:57:52, max mem: 20.9 GB 
[12/02 16:24:18][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 1.38e-01, avg batch time: 0.9621, average train loss: 0.7081
[12/02 16:25:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3070, average loss: 0.6905
[12/02 16:25:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 62.96	
[12/02 16:25:12][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/02 16:26:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8088,	0.8087 s / batch. (data: 3.20e-04). ETA=7:55:41, max mem: 20.9 GB 
[12/02 16:28:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8751,	0.8360 s / batch. (data: 2.80e-04). ETA=8:10:20, max mem: 20.9 GB 
[12/02 16:30:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7865,	1.2254 s / batch. (data: 4.12e-01). ETA=11:56:40, max mem: 20.9 GB 
[12/02 16:31:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9743,	1.7446 s / batch. (data: 9.38e-01). ETA=16:57:25, max mem: 20.9 GB 
[12/02 16:33:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8838,	1.0213 s / batch. (data: 2.00e-01). ETA=9:53:55, max mem: 20.9 GB 
[12/02 16:34:06][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 1.42e-01, avg batch time: 0.9656, average train loss: 0.7023
[12/02 16:35:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.3079, average loss: 0.6945
[12/02 16:35:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.18	
[12/02 16:35:01][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/02 16:36:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5124,	0.8177 s / batch. (data: 2.92e-04). ETA=7:53:25, max mem: 20.9 GB 
[12/02 16:38:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7186,	1.3680 s / batch. (data: 5.46e-01). ETA=13:09:45, max mem: 20.9 GB 
[12/02 16:39:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9361,	0.8415 s / batch. (data: 9.45e-03). ETA=8:04:24, max mem: 20.9 GB 
[12/02 16:41:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8336,	0.8403 s / batch. (data: 1.05e-02). ETA=8:02:20, max mem: 20.9 GB 
[12/02 16:43:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7320,	0.8261 s / batch. (data: 3.10e-04). ETA=7:52:47, max mem: 20.9 GB 
[12/02 16:43:52][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 1.37e-01, avg batch time: 0.9606, average train loss: 0.6978
[12/02 16:44:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3053, average loss: 0.6843
[12/02 16:44:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.47	
[12/02 16:44:47][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/02 16:46:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0024,	0.8156 s / batch. (data: 3.22e-04). ETA=7:44:40, max mem: 20.9 GB 
[12/02 16:48:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3242,	0.8223 s / batch. (data: 2.57e-04). ETA=7:47:08, max mem: 20.9 GB 
[12/02 16:49:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7315,	0.8177 s / batch. (data: 2.96e-04). ETA=7:43:11, max mem: 20.9 GB 
[12/02 16:51:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7436,	1.0048 s / batch. (data: 1.98e-01). ETA=9:27:28, max mem: 20.9 GB 
[12/02 16:52:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5805,	1.6827 s / batch. (data: 8.65e-01). ETA=15:47:31, max mem: 20.9 GB 
[12/02 16:53:40][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 1.39e-01, avg batch time: 0.9624, average train loss: 0.7032
[12/02 16:54:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3055, average loss: 0.6852
[12/02 16:54:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 63.49	
[12/02 16:54:34][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/02 16:56:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7330,	0.8256 s / batch. (data: 2.83e-04). ETA=7:42:48, max mem: 20.9 GB 
[12/02 16:57:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7018,	0.8240 s / batch. (data: 1.20e-02). ETA=7:40:31, max mem: 20.9 GB 
[12/02 16:59:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5690,	0.8383 s / batch. (data: 5.88e-03). ETA=7:47:08, max mem: 20.9 GB 
[12/02 17:01:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6396,	0.8204 s / batch. (data: 3.06e-04). ETA=7:35:47, max mem: 20.9 GB 
[12/02 17:02:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2389,	0.8537 s / batch. (data: 9.62e-03). ETA=7:52:50, max mem: 20.9 GB 
[12/02 17:03:30][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 1.45e-01, avg batch time: 0.9684, average train loss: 0.6965
[12/02 17:04:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.74e-05, avg batch time: 0.3096, average loss: 0.6768
[12/02 17:04:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.69	
[12/02 17:04:25][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[12/02 17:06:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8873,	0.8329 s / batch. (data: 2.74e-04). ETA=7:39:12, max mem: 20.9 GB 
[12/02 17:07:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6365,	0.8411 s / batch. (data: 8.00e-04). ETA=7:42:20, max mem: 20.9 GB 
[12/02 17:09:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6861,	0.8489 s / batch. (data: 2.02e-02). ETA=7:45:11, max mem: 20.9 GB 
[12/02 17:10:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7944,	0.8108 s / batch. (data: 2.73e-04). ETA=7:22:56, max mem: 20.9 GB 
[12/02 17:12:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6599,	0.8253 s / batch. (data: 1.06e-02). ETA=7:29:32, max mem: 20.9 GB 
[12/02 17:13:18][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 1.40e-01, avg batch time: 0.9644, average train loss: 0.6885
[12/02 17:14:13][INFO] visual_prompt:  316: Inference (val):avg data time: 5.49e-04, avg batch time: 0.3076, average loss: 0.6726
[12/02 17:14:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.58	
[12/02 17:14:13][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[12/02 17:15:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7014,	0.8324 s / batch. (data: 9.98e-03). ETA=7:31:14, max mem: 20.9 GB 
[12/02 17:17:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6569,	0.8403 s / batch. (data: 8.26e-03). ETA=7:34:08, max mem: 20.9 GB 
[12/02 17:19:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6434,	0.8400 s / batch. (data: 2.88e-04). ETA=7:32:34, max mem: 20.9 GB 
[12/02 17:20:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6949,	0.8638 s / batch. (data: 2.38e-02). ETA=7:43:57, max mem: 20.9 GB 
[12/02 17:22:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1970,	0.8320 s / batch. (data: 3.05e-04). ETA=7:25:29, max mem: 20.9 GB 
[12/02 17:23:05][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 1.40e-01, avg batch time: 0.9632, average train loss: 0.6871
[12/02 17:24:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.63e-05, avg batch time: 0.3077, average loss: 0.6655
[12/02 17:24:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 68.09	
[12/02 17:24:00][INFO] visual_prompt:   36: Best epoch 42: best metric: -0.665
[12/02 17:24:00][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[12/02 17:25:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6056,	0.8131 s / batch. (data: 3.08e-04). ETA=7:13:16, max mem: 20.9 GB 
[12/02 17:27:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7346,	0.8399 s / batch. (data: 4.69e-04). ETA=7:26:11, max mem: 20.9 GB 
[12/02 17:28:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9715,	0.8262 s / batch. (data: 3.27e-04). ETA=7:17:30, max mem: 20.9 GB 
[12/02 17:30:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5485,	0.8297 s / batch. (data: 1.19e-02). ETA=7:18:01, max mem: 20.9 GB 
[12/02 17:32:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5269,	0.8202 s / batch. (data: 1.03e-02). ETA=7:11:37, max mem: 20.9 GB 
[12/02 17:32:53][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 1.40e-01, avg batch time: 0.9638, average train loss: 0.6963
[12/02 17:33:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3058, average loss: 0.6629
[12/02 17:33:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.03	
[12/02 17:33:48][INFO] visual_prompt:   36: Best epoch 43: best metric: -0.663
[12/02 17:33:48][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[12/02 17:35:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7654,	1.4880 s / batch. (data: 6.64e-01). ETA=12:59:14, max mem: 20.9 GB 
[12/02 17:37:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6050,	0.8341 s / batch. (data: 5.40e-03). ETA=7:15:25, max mem: 20.9 GB 
[12/02 17:38:39][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5933,	0.8222 s / batch. (data: 2.78e-04). ETA=7:07:49, max mem: 20.9 GB 
[12/02 17:40:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7142,	0.8280 s / batch. (data: 3.21e-04). ETA=7:09:28, max mem: 20.9 GB 
[12/02 17:41:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9452,	0.8280 s / batch. (data: 2.91e-04). ETA=7:08:06, max mem: 20.9 GB 
[12/02 17:42:40][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 1.39e-01, avg batch time: 0.9627, average train loss: 0.6861
[12/02 17:43:35][INFO] visual_prompt:  316: Inference (val):avg data time: 5.51e-04, avg batch time: 0.3088, average loss: 0.6695
[12/02 17:43:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 65.20	
[12/02 17:43:35][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[12/02 17:45:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6884,	0.8280 s / batch. (data: 2.99e-04). ETA=7:05:58, max mem: 20.9 GB 
[12/02 17:46:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6038,	0.8400 s / batch. (data: 7.96e-03). ETA=7:10:45, max mem: 20.9 GB 
[12/02 17:48:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6559,	0.8517 s / batch. (data: 2.53e-02). ETA=7:15:19, max mem: 20.9 GB 
[12/02 17:49:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5605,	0.8214 s / batch. (data: 3.36e-04). ETA=6:58:29, max mem: 20.9 GB 
[12/02 17:51:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5664,	0.8224 s / batch. (data: 3.07e-04). ETA=6:57:38, max mem: 20.9 GB 
[12/02 17:52:27][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 1.39e-01, avg batch time: 0.9625, average train loss: 0.6787
[12/02 17:53:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.53e-05, avg batch time: 0.3066, average loss: 0.6501
[12/02 17:53:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 70.20	
[12/02 17:53:22][INFO] visual_prompt:   36: Best epoch 45: best metric: -0.650
[12/02 17:53:22][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[12/02 17:55:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6443,	1.3161 s / batch. (data: 4.86e-01). ETA=11:04:58, max mem: 20.9 GB 
[12/02 17:56:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6775,	0.8693 s / batch. (data: 5.91e-03). ETA=7:17:46, max mem: 20.9 GB 
[12/02 17:58:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7307,	0.8097 s / batch. (data: 3.17e-04). ETA=6:46:25, max mem: 20.9 GB 
[12/02 17:59:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7386,	0.8410 s / batch. (data: 1.55e-02). ETA=7:00:43, max mem: 20.9 GB 
[12/02 18:01:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8005,	0.8301 s / batch. (data: 3.19e-04). ETA=6:53:52, max mem: 20.9 GB 
[12/02 18:02:18][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 1.45e-01, avg batch time: 0.9701, average train loss: 0.6929
[12/02 18:03:14][INFO] visual_prompt:  316: Inference (val):avg data time: 1.54e-04, avg batch time: 0.3061, average loss: 0.6731
[12/02 18:03:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 65.70	
[12/02 18:03:14][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[12/02 18:04:55][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7459,	0.8360 s / batch. (data: 7.96e-03). ETA=6:54:40, max mem: 20.9 GB 
[12/02 18:06:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6560,	1.2974 s / batch. (data: 4.62e-01). ETA=10:41:24, max mem: 20.9 GB 
[12/02 18:08:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7775,	0.8525 s / batch. (data: 8.11e-04). ETA=7:00:01, max mem: 20.9 GB 
[12/02 18:09:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5610,	0.8489 s / batch. (data: 4.20e-02). ETA=6:56:49, max mem: 20.9 GB 
[12/02 18:11:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6118,	0.8258 s / batch. (data: 2.85e-04). ETA=6:44:07, max mem: 20.9 GB 
[12/02 18:12:10][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 1.44e-01, avg batch time: 0.9703, average train loss: 0.6992
[12/02 18:13:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.47e-05, avg batch time: 0.3047, average loss: 0.7558
[12/02 18:13:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.23	
[12/02 18:13:05][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[12/02 18:14:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7178,	0.8538 s / batch. (data: 7.39e-04). ETA=6:55:37, max mem: 20.9 GB 
[12/02 18:16:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5061,	0.8160 s / batch. (data: 2.78e-04). ETA=6:35:53, max mem: 20.9 GB 
[12/02 18:18:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5496,	1.6249 s / batch. (data: 8.04e-01). ETA=13:05:36, max mem: 20.9 GB 
[12/02 18:19:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7618,	0.8343 s / batch. (data: 3.02e-04). ETA=6:41:59, max mem: 20.9 GB 
[12/02 18:21:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7623,	0.8149 s / batch. (data: 3.04e-04). ETA=6:31:15, max mem: 20.9 GB 
[12/02 18:22:00][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 1.43e-01, avg batch time: 0.9666, average train loss: 0.6835
[12/02 18:22:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.63e-05, avg batch time: 0.3068, average loss: 0.6248
[12/02 18:22:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.69	
[12/02 18:22:55][INFO] visual_prompt:   36: Best epoch 48: best metric: -0.625
[12/02 18:22:55][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[12/02 18:24:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5532,	0.8091 s / batch. (data: 2.93e-04). ETA=6:26:26, max mem: 20.9 GB 
[12/02 18:26:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5371,	0.8407 s / batch. (data: 1.21e-02). ETA=6:40:06, max mem: 20.9 GB 
[12/02 18:27:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7849,	0.8414 s / batch. (data: 3.19e-04). ETA=6:39:03, max mem: 20.9 GB 
[12/02 18:29:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6285,	0.8360 s / batch. (data: 2.96e-04). ETA=6:35:04, max mem: 20.9 GB 
[12/02 18:31:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5296,	0.8480 s / batch. (data: 7.74e-04). ETA=6:39:21, max mem: 20.9 GB 
[12/02 18:31:55][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 1.51e-01, avg batch time: 0.9755, average train loss: 0.6772
[12/02 18:32:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.54e-05, avg batch time: 0.3064, average loss: 0.6350
[12/02 18:32:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.09	
[12/02 18:32:50][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[12/02 18:34:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7038,	0.8890 s / batch. (data: 3.29e-02). ETA=6:56:23, max mem: 20.9 GB 
[12/02 18:36:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7019,	0.8351 s / batch. (data: 7.17e-04). ETA=6:29:44, max mem: 20.9 GB 
[12/02 18:37:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5939,	0.8293 s / batch. (data: 7.59e-04). ETA=6:25:40, max mem: 20.9 GB 
[12/02 18:39:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6143,	0.8160 s / batch. (data: 2.58e-04). ETA=6:18:07, max mem: 20.9 GB 
[12/02 18:40:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7283,	0.8364 s / batch. (data: 1.09e-02). ETA=6:26:11, max mem: 20.9 GB 
[12/02 18:41:42][INFO] visual_prompt:  217: Epoch 50 / 100: avg data time: 1.38e-01, avg batch time: 0.9617, average train loss: 0.6808
[12/02 18:42:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.43e-05, avg batch time: 0.3079, average loss: 0.6452
[12/02 18:42:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.24	
[12/02 18:42:36][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[12/02 18:44:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7049,	0.8386 s / batch. (data: 3.00e-02). ETA=6:25:03, max mem: 20.9 GB 
[12/02 18:45:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5190,	0.8320 s / batch. (data: 2.84e-04). ETA=6:20:38, max mem: 20.9 GB 
[12/02 18:47:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4631,	0.8200 s / batch. (data: 3.07e-04). ETA=6:13:46, max mem: 20.9 GB 
[12/02 18:49:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8203,	1.2920 s / batch. (data: 4.82e-01). ETA=9:46:46, max mem: 20.9 GB 
[12/02 18:50:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6414,	0.8533 s / batch. (data: 1.05e-02). ETA=6:26:07, max mem: 20.9 GB 
[12/02 18:51:28][INFO] visual_prompt:  217: Epoch 51 / 100: avg data time: 1.39e-01, avg batch time: 0.9622, average train loss: 0.6740
[12/02 18:52:23][INFO] visual_prompt:  316: Inference (val):avg data time: 2.17e-04, avg batch time: 0.3079, average loss: 0.6507
[12/02 18:52:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 70.54	
[12/02 18:52:23][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[12/02 18:54:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5048,	0.8301 s / batch. (data: 2.87e-04). ETA=6:13:31, max mem: 20.9 GB 
[12/02 18:55:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8192,	0.8160 s / batch. (data: 3.00e-04). ETA=6:05:48, max mem: 20.9 GB 
[12/02 18:57:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0464,	0.8213 s / batch. (data: 2.66e-04). ETA=6:06:49, max mem: 20.9 GB 
[12/02 18:58:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2251,	0.8334 s / batch. (data: 3.04e-04). ETA=6:10:49, max mem: 20.9 GB 
[12/02 19:00:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3447,	0.8240 s / batch. (data: 2.70e-04). ETA=6:05:16, max mem: 20.9 GB 
[12/02 19:01:15][INFO] visual_prompt:  217: Epoch 52 / 100: avg data time: 1.38e-01, avg batch time: 0.9623, average train loss: 0.6724
[12/02 19:02:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3051, average loss: 0.6435
[12/02 19:02:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.86	
[12/02 19:02:10][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[12/02 19:03:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7283,	0.8120 s / batch. (data: 2.98e-04). ETA=5:57:52, max mem: 20.9 GB 
[12/02 19:05:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5327,	0.8348 s / batch. (data: 8.26e-04). ETA=6:06:32, max mem: 20.9 GB 
[12/02 19:07:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6229,	0.8297 s / batch. (data: 7.85e-04). ETA=6:02:55, max mem: 20.9 GB 
[12/02 19:08:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5039,	0.8074 s / batch. (data: 3.20e-04). ETA=5:51:48, max mem: 20.9 GB 
[12/02 19:10:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5270,	0.8360 s / batch. (data: 4.67e-04). ETA=6:02:52, max mem: 20.9 GB 
[12/02 19:11:05][INFO] visual_prompt:  217: Epoch 53 / 100: avg data time: 1.43e-01, avg batch time: 0.9672, average train loss: 0.6710
[12/02 19:11:59][INFO] visual_prompt:  316: Inference (val):avg data time: 2.14e-04, avg batch time: 0.3059, average loss: 0.7111
[12/02 19:11:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.45	
[12/02 19:11:59][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[12/02 19:13:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6739,	0.8616 s / batch. (data: 3.76e-02). ETA=6:11:48, max mem: 20.9 GB 
[12/02 19:15:17][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7392,	0.8292 s / batch. (data: 9.17e-03). ETA=5:56:26, max mem: 20.9 GB 
[12/02 19:16:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6568,	0.8114 s / batch. (data: 2.72e-04). ETA=5:47:24, max mem: 20.9 GB 
[12/02 19:18:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4353,	0.8320 s / batch. (data: 2.80e-04). ETA=5:54:51, max mem: 20.9 GB 
[12/02 19:20:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6393,	0.8360 s / batch. (data: 7.87e-04). ETA=5:55:10, max mem: 20.9 GB 
[12/02 19:20:53][INFO] visual_prompt:  217: Epoch 54 / 100: avg data time: 1.41e-01, avg batch time: 0.9653, average train loss: 0.6717
[12/02 19:21:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3048, average loss: 0.6804
[12/02 19:21:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.44	
[12/02 19:21:48][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[12/02 19:23:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7555,	0.8261 s / batch. (data: 7.95e-03). ETA=5:48:51, max mem: 20.9 GB 
[12/02 19:25:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7206,	0.8190 s / batch. (data: 3.08e-04). ETA=5:44:28, max mem: 20.9 GB 
[12/02 19:26:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6603,	0.8370 s / batch. (data: 1.05e-02). ETA=5:50:40, max mem: 20.9 GB 
[12/02 19:28:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6791,	0.8474 s / batch. (data: 1.53e-02). ETA=5:53:36, max mem: 20.9 GB 
[12/02 19:29:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6318,	0.8480 s / batch. (data: 7.97e-03). ETA=5:52:28, max mem: 20.9 GB 
[12/02 19:30:41][INFO] visual_prompt:  217: Epoch 55 / 100: avg data time: 1.40e-01, avg batch time: 0.9630, average train loss: 0.6666
[12/02 19:31:35][INFO] visual_prompt:  316: Inference (val):avg data time: 3.53e-05, avg batch time: 0.3067, average loss: 0.7112
[12/02 19:31:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 68.32	
[12/02 19:31:35][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 0.025
[12/02 19:33:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6438,	0.8360 s / batch. (data: 2.98e-04). ETA=5:45:20, max mem: 20.9 GB 
[12/02 19:34:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7112,	0.8183 s / batch. (data: 3.00e-04). ETA=5:36:38, max mem: 20.9 GB 
[12/02 19:36:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8154,	0.8560 s / batch. (data: 1.19e-02). ETA=5:50:45, max mem: 20.9 GB 
[12/02 19:38:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4764,	0.8066 s / batch. (data: 2.71e-04). ETA=5:29:09, max mem: 20.9 GB 
[12/02 19:39:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6675,	2.2446 s / batch. (data: 1.43e+00). ETA=15:12:14, max mem: 20.9 GB 
[12/02 19:40:31][INFO] visual_prompt:  217: Epoch 56 / 100: avg data time: 1.43e-01, avg batch time: 0.9677, average train loss: 0.6737
[12/02 19:41:26][INFO] visual_prompt:  316: Inference (val):avg data time: 1.50e-04, avg batch time: 0.3057, average loss: 0.6811
[12/02 19:41:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.86	
[12/02 19:41:26][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[12/02 19:43:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7633,	0.8218 s / batch. (data: 7.64e-04). ETA=5:31:53, max mem: 20.9 GB 
[12/02 19:44:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7227,	0.8280 s / batch. (data: 3.54e-04). ETA=5:33:00, max mem: 20.9 GB 
[12/02 19:46:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7641,	0.8400 s / batch. (data: 7.94e-03). ETA=5:36:26, max mem: 20.9 GB 
[12/02 19:47:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7435,	0.8160 s / batch. (data: 2.87e-04). ETA=5:25:28, max mem: 20.9 GB 
[12/02 19:49:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7633,	0.8165 s / batch. (data: 5.40e-03). ETA=5:24:19, max mem: 20.9 GB 
[12/02 19:50:19][INFO] visual_prompt:  217: Epoch 57 / 100: avg data time: 1.38e-01, avg batch time: 0.9632, average train loss: 0.6716
[12/02 19:51:14][INFO] visual_prompt:  316: Inference (val):avg data time: 1.72e-04, avg batch time: 0.3124, average loss: 0.6837
[12/02 19:51:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.77	
[12/02 19:51:14][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[12/02 19:52:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5639,	0.8200 s / batch. (data: 3.10e-04). ETA=5:23:36, max mem: 20.9 GB 
[12/02 19:54:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8568,	0.8440 s / batch. (data: 7.96e-03). ETA=5:31:40, max mem: 20.9 GB 
[12/02 19:56:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5713,	0.8320 s / batch. (data: 7.78e-04). ETA=5:25:34, max mem: 20.9 GB 
[12/02 19:57:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7063,	0.8264 s / batch. (data: 2.94e-04). ETA=5:22:01, max mem: 20.9 GB 
[12/02 19:59:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4108,	0.8171 s / batch. (data: 1.05e-02). ETA=5:17:02, max mem: 20.9 GB 
[12/02 20:00:06][INFO] visual_prompt:  217: Epoch 58 / 100: avg data time: 1.40e-01, avg batch time: 0.9624, average train loss: 0.6705
[12/02 20:01:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.32e-05, avg batch time: 0.3086, average loss: 0.6494
[12/02 20:01:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.16	
[12/02 20:01:01][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[12/02 20:02:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5040,	0.8288 s / batch. (data: 5.39e-03). ETA=5:19:26, max mem: 20.9 GB 
[12/02 20:04:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6030,	0.8219 s / batch. (data: 2.92e-04). ETA=5:15:26, max mem: 20.9 GB 
[12/02 20:06:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6547,	0.8079 s / batch. (data: 1.14e-03). ETA=5:08:42, max mem: 20.9 GB 
[12/02 20:07:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7734,	0.8058 s / batch. (data: 2.78e-04). ETA=5:06:34, max mem: 20.9 GB 
[12/02 20:09:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4916,	0.8133 s / batch. (data: 3.05e-04). ETA=5:08:03, max mem: 20.9 GB 
[12/02 20:10:40][INFO] visual_prompt:  217: Epoch 59 / 100: avg data time: 2.24e-01, avg batch time: 1.0475, average train loss: 0.6630
[12/02 20:11:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3070, average loss: 0.6250
[12/02 20:11:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.86	
[12/02 20:11:40][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[12/02 20:13:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6206,	0.8227 s / batch. (data: 4.10e-04). ETA=5:09:30, max mem: 20.9 GB 
[12/02 20:15:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5319,	0.8196 s / batch. (data: 5.46e-03). ETA=5:06:58, max mem: 20.9 GB 
[12/02 20:16:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5242,	2.0521 s / batch. (data: 1.22e+00). ETA=12:45:11, max mem: 20.9 GB 
[12/02 20:18:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9855,	1.3679 s / batch. (data: 5.35e-01). ETA=8:27:47, max mem: 20.9 GB 
[12/02 20:20:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7296,	0.8313 s / batch. (data: 3.06e-04). ETA=5:07:12, max mem: 20.9 GB 
[12/02 20:21:21][INFO] visual_prompt:  217: Epoch 60 / 100: avg data time: 2.25e-01, avg batch time: 1.0489, average train loss: 0.6718
[12/02 20:22:20][INFO] visual_prompt:  316: Inference (val):avg data time: 4.43e-05, avg batch time: 0.3065, average loss: 0.6441
[12/02 20:22:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.29	
[12/02 20:22:20][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[12/02 20:24:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5069,	0.8360 s / batch. (data: 3.20e-04). ETA=5:06:48, max mem: 20.9 GB 
[12/02 20:25:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7230,	0.8230 s / batch. (data: 3.31e-04). ETA=5:00:39, max mem: 20.9 GB 
[12/02 20:27:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6646,	0.8247 s / batch. (data: 8.77e-03). ETA=4:59:55, max mem: 20.9 GB 
[12/02 20:29:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6037,	0.8649 s / batch. (data: 5.49e-03). ETA=5:13:06, max mem: 20.9 GB 
[12/02 20:31:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8799,	2.8858 s / batch. (data: 2.06e+00). ETA=17:19:51, max mem: 20.9 GB 
[12/02 20:31:54][INFO] visual_prompt:  217: Epoch 61 / 100: avg data time: 2.13e-01, avg batch time: 1.0372, average train loss: 0.6641
[12/02 20:32:54][INFO] visual_prompt:  316: Inference (val):avg data time: 1.55e-04, avg batch time: 0.3060, average loss: 0.6371
[12/02 20:32:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.35	
[12/02 20:32:54][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[12/02 20:34:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5171,	0.8160 s / batch. (data: 2.91e-04). ETA=4:51:57, max mem: 20.9 GB 
[12/02 20:36:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6678,	0.8302 s / batch. (data: 5.51e-03). ETA=4:55:39, max mem: 20.9 GB 
[12/02 20:38:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4071,	0.8240 s / batch. (data: 3.96e-04). ETA=4:52:03, max mem: 20.9 GB 
[12/02 20:39:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8124,	0.8120 s / batch. (data: 3.36e-04). ETA=4:46:27, max mem: 20.9 GB 
[12/02 20:41:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6070,	0.8320 s / batch. (data: 3.35e-04). ETA=4:52:07, max mem: 20.9 GB 
[12/02 20:42:31][INFO] visual_prompt:  217: Epoch 62 / 100: avg data time: 2.19e-01, avg batch time: 1.0423, average train loss: 0.6592
[12/02 20:43:31][INFO] visual_prompt:  316: Inference (val):avg data time: 4.54e-05, avg batch time: 0.3075, average loss: 0.6414
[12/02 20:43:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.74	
[12/02 20:43:31][INFO] visual_prompt:   42: Stopping early.
