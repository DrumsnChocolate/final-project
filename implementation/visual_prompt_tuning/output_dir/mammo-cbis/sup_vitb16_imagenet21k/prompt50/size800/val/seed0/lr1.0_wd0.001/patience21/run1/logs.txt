[11/30 15:13:34][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/30 15:13:34][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 15:13:34][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 15:13:34][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 15:13:34][INFO] visual_prompt:  108: Training with config:
[11/30 15:13:34][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr1.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 15:13:34][INFO] visual_prompt:   70: Loading training data...
[11/30 15:13:34][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/30 15:13:34][INFO] visual_prompt:   72: Loading validation data...
[11/30 15:13:34][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/30 15:13:34][INFO] visual_prompt:   36: Constructing models...
[11/30 15:13:39][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[11/30 15:13:39][INFO] visual_prompt:   54: tuned percent:0.525
[11/30 15:13:39][INFO] visual_prompt:   40: Device used for model: 0
[11/30 15:13:39][INFO] visual_prompt:   38: Setting up Evaluator...
[11/30 15:13:39][INFO] visual_prompt:   40: Setting up Trainer...
[11/30 15:13:39][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/30 15:13:39][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/30 15:15:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8324 s / batch. (data: 8.05e-03). ETA=12:45:46, max mem: 20.9 GB 
[11/30 15:17:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8299 s / batch. (data: 6.67e-04). ETA=12:42:09, max mem: 20.9 GB 
[11/30 15:19:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	2.1629 s / batch. (data: 1.34e+00). ETA=1 day, 9:02:39, max mem: 20.9 GB 
[11/30 15:21:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8361 s / batch. (data: 9.61e-04). ETA=12:44:59, max mem: 20.9 GB 
[11/30 15:23:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8510 s / batch. (data: 1.10e-02). ETA=12:57:15, max mem: 20.9 GB 
[11/30 15:24:18][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 3.20e-01, avg batch time: 1.1553, average train loss: 1.5403
[11/30 15:25:26][INFO] visual_prompt:  316: Inference (val):avg data time: 7.29e-05, avg batch time: 0.3111, average loss: 1.5201
[11/30 15:25:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[11/30 15:25:26][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.1
[11/30 15:27:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7431,	1.1080 s / batch. (data: 2.88e-01). ETA=16:49:08, max mem: 20.9 GB 
[11/30 15:29:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0229,	0.8569 s / batch. (data: 1.21e-02). ETA=12:59:02, max mem: 20.9 GB 
[11/30 15:31:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7115,	1.5125 s / batch. (data: 6.64e-01). ETA=22:52:31, max mem: 20.9 GB 
[11/30 15:33:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0806,	0.8444 s / batch. (data: 5.97e-04). ETA=12:44:50, max mem: 20.9 GB 
[11/30 15:35:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6006,	0.8406 s / batch. (data: 1.08e-02). ETA=12:40:01, max mem: 20.9 GB 
[11/30 15:36:13][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.35e-01, avg batch time: 1.1704, average train loss: 0.9692
[11/30 15:37:21][INFO] visual_prompt:  316: Inference (val):avg data time: 8.71e-05, avg batch time: 0.3102, average loss: 1.2669
[11/30 15:37:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.96	
[11/30 15:37:21][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.2
[11/30 15:39:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2298,	0.9083 s / batch. (data: 7.53e-02). ETA=13:38:53, max mem: 20.9 GB 
[11/30 15:41:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9757,	1.9667 s / batch. (data: 1.13e+00). ETA=1 day, 5:29:50, max mem: 20.9 GB 
[11/30 15:43:25][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7386,	0.8520 s / batch. (data: 3.64e-04). ETA=12:45:18, max mem: 20.9 GB 
[11/30 15:45:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.2934,	0.8752 s / batch. (data: 1.47e-02). ETA=13:04:39, max mem: 20.9 GB 
[11/30 15:47:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6973,	2.5906 s / batch. (data: 1.73e+00). ETA=1 day, 14:38:19, max mem: 20.9 GB 
[11/30 15:49:04][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 4.21e-01, avg batch time: 1.2707, average train loss: 0.9728
[11/30 15:50:23][INFO] visual_prompt:  316: Inference (val):avg data time: 3.09e-04, avg batch time: 0.3280, average loss: 0.8207
[11/30 15:50:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.52	
[11/30 15:50:23][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.3
[11/30 15:52:49][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7498,	0.8701 s / batch. (data: 2.22e-02). ETA=12:56:26, max mem: 20.9 GB 
[11/30 15:54:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6275,	0.8820 s / batch. (data: 2.16e-03). ETA=13:05:34, max mem: 20.9 GB 
[11/30 15:57:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6057,	1.6892 s / batch. (data: 8.61e-01). ETA=1 day, 1:01:43, max mem: 20.9 GB 
[11/30 15:58:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5973,	2.2792 s / batch. (data: 1.37e+00). ETA=1 day, 9:42:24, max mem: 20.9 GB 
[11/30 16:00:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3909,	4.7560 s / batch. (data: 3.93e+00). ETA=2 days, 22:12:17, max mem: 20.9 GB 
[11/30 16:02:00][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 4.14e-01, avg batch time: 1.2603, average train loss: 1.0162
[11/30 16:03:13][INFO] visual_prompt:  316: Inference (val):avg data time: 1.21e-04, avg batch time: 0.3148, average loss: 0.6778
[11/30 16:03:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 58.80	
[11/30 16:03:13][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.4
[11/30 16:05:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.2099,	0.8396 s / batch. (data: 4.69e-04). ETA=12:21:30, max mem: 20.9 GB 
[11/30 16:07:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9763,	0.9280 s / batch. (data: 7.55e-02). ETA=13:37:58, max mem: 20.9 GB 
[11/30 16:09:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.7767,	0.8200 s / batch. (data: 4.91e-04). ETA=12:01:27, max mem: 20.9 GB 
[11/30 16:11:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.3731,	0.8523 s / batch. (data: 5.61e-03). ETA=12:28:25, max mem: 20.9 GB 
[11/30 16:13:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6466,	0.8280 s / batch. (data: 1.39e-03). ETA=12:05:40, max mem: 20.9 GB 
[11/30 16:14:18][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 3.65e-01, avg batch time: 1.2029, average train loss: 1.1417
[11/30 16:15:33][INFO] visual_prompt:  316: Inference (val):avg data time: 1.45e-04, avg batch time: 0.3158, average loss: 2.2109
[11/30 16:15:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.25	
[11/30 16:15:33][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.5
[11/30 16:17:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4888,	0.8142 s / batch. (data: 4.78e-04). ETA=11:51:31, max mem: 20.9 GB 
[11/30 16:19:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.5385,	0.8662 s / batch. (data: 1.36e-02). ETA=12:35:34, max mem: 20.9 GB 
[11/30 16:21:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6572,	0.8353 s / batch. (data: 3.47e-04). ETA=12:07:14, max mem: 20.9 GB 
[11/30 16:24:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.0656,	0.8755 s / batch. (data: 6.98e-03). ETA=12:40:42, max mem: 20.9 GB 
[11/30 16:26:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.2061,	1.5889 s / batch. (data: 7.60e-01). ETA=22:58:00, max mem: 20.9 GB 
[11/30 16:27:13][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 4.18e-01, avg batch time: 1.2642, average train loss: 1.4448
[11/30 16:28:29][INFO] visual_prompt:  316: Inference (val):avg data time: 1.52e-04, avg batch time: 0.3165, average loss: 0.7829
[11/30 16:28:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.25	
[11/30 16:28:29][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.6
[11/30 16:30:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1696,	0.8320 s / batch. (data: 1.19e-02). ETA=11:59:26, max mem: 20.9 GB 
[11/30 16:32:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5902,	0.8681 s / batch. (data: 2.77e-03). ETA=12:29:10, max mem: 20.9 GB 
[11/30 16:34:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1093,	2.6999 s / batch. (data: 1.87e+00). ETA=1 day, 14:45:37, max mem: 20.9 GB 
[11/30 16:36:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1678,	2.6679 s / batch. (data: 1.82e+00). ETA=1 day, 14:13:37, max mem: 20.9 GB 
[11/30 16:38:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6711,	2.1020 s / batch. (data: 1.26e+00). ETA=1 day, 6:03:34, max mem: 20.9 GB 
[11/30 16:39:55][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 3.96e-01, avg batch time: 1.2403, average train loss: 1.4688
[11/30 16:41:07][INFO] visual_prompt:  316: Inference (val):avg data time: 2.63e-04, avg batch time: 0.3114, average loss: 0.9110
[11/30 16:41:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.41	
[11/30 16:41:07][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.7
[11/30 16:43:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.7135,	0.8280 s / batch. (data: 5.38e-04). ETA=11:48:19, max mem: 20.9 GB 
[11/30 16:45:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6631,	0.8297 s / batch. (data: 1.74e-03). ETA=11:48:24, max mem: 20.9 GB 
[11/30 16:47:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.7093,	0.8255 s / batch. (data: 4.89e-04). ETA=11:43:25, max mem: 20.9 GB 
[11/30 16:49:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.7947,	1.6253 s / batch. (data: 8.05e-01). ETA=23:02:19, max mem: 20.9 GB 
[11/30 16:51:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.6051,	2.1709 s / batch. (data: 1.34e+00). ETA=1 day, 6:42:44, max mem: 20.9 GB 
[11/30 16:52:25][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 3.83e-01, avg batch time: 1.2255, average train loss: 1.9594
[11/30 16:53:35][INFO] visual_prompt:  316: Inference (val):avg data time: 1.15e-04, avg batch time: 0.3114, average loss: 0.8549
[11/30 16:53:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.46	
[11/30 16:53:35][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.8
[11/30 16:55:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9613,	0.8232 s / batch. (data: 6.29e-04). ETA=11:36:39, max mem: 20.9 GB 
[11/30 16:57:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5460,	0.8586 s / batch. (data: 7.93e-03). ETA=12:05:08, max mem: 20.9 GB 
[11/30 16:59:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7530,	2.0405 s / batch. (data: 1.17e+00). ETA=1 day, 4:40:00, max mem: 20.9 GB 
[11/30 17:01:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6412,	0.8850 s / batch. (data: 1.15e-02). ETA=12:24:29, max mem: 20.9 GB 
[11/30 17:03:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6179,	1.7787 s / batch. (data: 9.42e-01). ETA=1 day, 0:53:23, max mem: 20.9 GB 
[11/30 17:04:50][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 3.79e-01, avg batch time: 1.2188, average train loss: 1.6057
[11/30 17:06:01][INFO] visual_prompt:  316: Inference (val):avg data time: 1.19e-04, avg batch time: 0.3130, average loss: 0.8593
[11/30 17:06:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.55	
[11/30 17:06:01][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.9
[11/30 17:08:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.1423,	0.8675 s / batch. (data: 1.16e-02). ETA=12:06:06, max mem: 20.9 GB 
[11/30 17:10:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9189,	0.8478 s / batch. (data: 1.17e-02). ETA=11:48:16, max mem: 20.9 GB 
[11/30 17:12:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.8276,	0.8397 s / batch. (data: 4.13e-03). ETA=11:40:06, max mem: 20.9 GB 
[11/30 17:14:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.9134,	1.5610 s / batch. (data: 7.17e-01). ETA=21:38:51, max mem: 20.9 GB 
[11/30 17:16:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9033,	1.6684 s / batch. (data: 8.45e-01). ETA=23:05:26, max mem: 20.9 GB 
[11/30 17:17:17][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 3.82e-01, avg batch time: 1.2228, average train loss: 2.1337
[11/30 17:18:29][INFO] visual_prompt:  316: Inference (val):avg data time: 1.07e-04, avg batch time: 0.3137, average loss: 1.3788
[11/30 17:18:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.90	
[11/30 17:18:29][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 1.0
[11/30 17:20:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.5256,	0.8612 s / batch. (data: 2.90e-02). ETA=11:52:55, max mem: 20.9 GB 
[11/30 17:22:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4719,	0.8447 s / batch. (data: 9.98e-04). ETA=11:37:50, max mem: 20.9 GB 
[11/30 17:24:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0326,	1.4812 s / batch. (data: 6.64e-01). ETA=20:21:15, max mem: 20.9 GB 
[11/30 17:26:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0791,	0.9363 s / batch. (data: 2.23e-02). ETA=12:50:26, max mem: 20.9 GB 
[11/30 17:28:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.7138,	0.8879 s / batch. (data: 1.17e-02). ETA=12:09:05, max mem: 20.9 GB 
[11/30 17:29:59][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 4.03e-01, avg batch time: 1.2473, average train loss: 2.4819
[11/30 17:31:13][INFO] visual_prompt:  316: Inference (val):avg data time: 1.43e-04, avg batch time: 0.3134, average loss: 1.0858
[11/30 17:31:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.37	
[11/30 17:31:13][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/30 17:33:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6847,	1.4476 s / batch. (data: 6.12e-01). ETA=19:45:02, max mem: 20.9 GB 
[11/30 17:35:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5447,	0.8320 s / batch. (data: 1.75e-03). ETA=11:19:41, max mem: 20.9 GB 
[11/30 17:37:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9428,	0.8472 s / batch. (data: 1.57e-03). ETA=11:30:40, max mem: 20.9 GB 
[11/30 17:39:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3645,	0.8865 s / batch. (data: 1.80e-03). ETA=12:01:14, max mem: 20.9 GB 
[11/30 17:41:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.1667,	0.8683 s / batch. (data: 1.65e-02). ETA=11:45:00, max mem: 20.9 GB 
[11/30 17:42:36][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 3.92e-01, avg batch time: 1.2346, average train loss: 1.8395
[11/30 17:43:49][INFO] visual_prompt:  316: Inference (val):avg data time: 1.27e-04, avg batch time: 0.3123, average loss: 1.0636
[11/30 17:43:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.40	
[11/30 17:43:49][INFO] visual_prompt:   36: Best epoch 12: best metric: -1.064
[11/30 17:43:49][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/30 17:46:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5006,	0.8366 s / batch. (data: 5.02e-04). ETA=11:17:07, max mem: 20.9 GB 
[11/30 17:48:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7680,	0.8518 s / batch. (data: 1.09e-02). ETA=11:28:02, max mem: 20.9 GB 
[11/30 17:50:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7476,	2.5274 s / batch. (data: 1.68e+00). ETA=1 day, 9:57:16, max mem: 20.9 GB 
[11/30 17:52:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3625,	0.8720 s / batch. (data: 5.67e-03). ETA=11:41:28, max mem: 20.9 GB 
[11/30 17:54:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.0766,	0.8638 s / batch. (data: 1.73e-03). ETA=11:33:24, max mem: 20.9 GB 
[11/30 17:55:18][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 4.02e-01, avg batch time: 1.2460, average train loss: 2.0376
[11/30 17:56:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.58e-04, avg batch time: 0.3144, average loss: 0.8844
[11/30 17:56:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.78	
[11/30 17:56:33][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.884
[11/30 17:56:33][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/30 17:58:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 8.4550,	0.8314 s / batch. (data: 1.64e-03). ETA=11:05:16, max mem: 20.9 GB 
[11/30 18:00:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.1337,	1.2693 s / batch. (data: 4.16e-01). ETA=16:53:33, max mem: 20.9 GB 
[11/30 18:02:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7719,	1.3597 s / batch. (data: 5.27e-01). ETA=18:03:30, max mem: 20.9 GB 
[11/30 18:04:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6683,	0.8516 s / batch. (data: 1.17e-02). ETA=11:17:10, max mem: 20.9 GB 
[11/30 18:06:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.9133,	0.8626 s / batch. (data: 1.08e-02). ETA=11:24:30, max mem: 20.9 GB 
[11/30 18:07:40][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 3.65e-01, avg batch time: 1.2053, average train loss: 1.7534
[11/30 18:08:49][INFO] visual_prompt:  316: Inference (val):avg data time: 9.21e-05, avg batch time: 0.3120, average loss: 1.6784
[11/30 18:08:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.75	
[11/30 18:08:49][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/30 18:10:55][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9750,	0.8361 s / batch. (data: 4.67e-04). ETA=11:01:18, max mem: 20.9 GB 
[11/30 18:12:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 12.8571,	0.8297 s / batch. (data: 4.99e-04). ETA=10:54:52, max mem: 20.9 GB 
[11/30 18:14:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9245,	0.9006 s / batch. (data: 6.98e-03). ETA=11:49:20, max mem: 20.9 GB 
[11/30 18:16:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6197,	0.8815 s / batch. (data: 1.97e-03). ETA=11:32:49, max mem: 20.9 GB 
[11/30 18:18:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.6630,	0.8676 s / batch. (data: 1.19e-02). ETA=11:20:25, max mem: 20.9 GB 
[11/30 18:19:58][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 3.67e-01, avg batch time: 1.2083, average train loss: 2.6104
[11/30 18:21:10][INFO] visual_prompt:  316: Inference (val):avg data time: 1.25e-04, avg batch time: 0.3125, average loss: 2.2748
[11/30 18:21:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.09	
[11/30 18:21:10][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/30 18:23:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5710,	0.8610 s / batch. (data: 5.74e-04). ETA=11:13:04, max mem: 20.9 GB 
[11/30 18:25:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.6514,	0.8315 s / batch. (data: 1.34e-03). ETA=10:48:36, max mem: 20.9 GB 
[11/30 18:27:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.6168,	0.8480 s / batch. (data: 1.28e-03). ETA=11:00:06, max mem: 20.9 GB 
[11/30 18:29:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.9681,	0.8634 s / batch. (data: 1.72e-03). ETA=11:10:38, max mem: 20.9 GB 
[11/30 18:31:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8915,	1.6966 s / batch. (data: 8.49e-01). ETA=21:55:02, max mem: 20.9 GB 
[11/30 18:32:18][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 3.67e-01, avg batch time: 1.2077, average train loss: 2.6295
[11/30 18:33:27][INFO] visual_prompt:  316: Inference (val):avg data time: 2.81e-04, avg batch time: 0.3109, average loss: 0.7354
[11/30 18:33:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.72	
[11/30 18:33:27][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.735
[11/30 18:33:27][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/30 18:35:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5410,	0.8397 s / batch. (data: 1.27e-03). ETA=10:48:39, max mem: 20.9 GB 
[11/30 18:37:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8182,	0.8363 s / batch. (data: 3.63e-04). ETA=10:44:40, max mem: 20.9 GB 
[11/30 18:39:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0049,	0.8320 s / batch. (data: 7.88e-03). ETA=10:39:58, max mem: 20.9 GB 
[11/30 18:41:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.2289,	0.8361 s / batch. (data: 7.53e-04). ETA=10:41:44, max mem: 20.9 GB 
[11/30 18:43:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.5001,	2.2963 s / batch. (data: 1.45e+00). ETA=1 day, 5:18:38, max mem: 20.9 GB 
[11/30 18:44:32][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 3.62e-01, avg batch time: 1.2010, average train loss: 2.3484
[11/30 18:45:45][INFO] visual_prompt:  316: Inference (val):avg data time: 1.29e-04, avg batch time: 0.3163, average loss: 3.8605
[11/30 18:45:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.36	
[11/30 18:45:45][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/30 18:47:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 5.0259,	0.8353 s / batch. (data: 3.38e-03). ETA=10:37:34, max mem: 20.9 GB 
[11/30 18:49:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 16.7930,	0.8512 s / batch. (data: 1.28e-03). ETA=10:48:19, max mem: 20.9 GB 
[11/30 18:51:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7122,	0.8302 s / batch. (data: 1.19e-02). ETA=10:30:56, max mem: 20.9 GB 
[11/30 18:53:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0092,	0.8251 s / batch. (data: 5.72e-03). ETA=10:25:40, max mem: 20.9 GB 
[11/30 18:55:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7725,	0.8918 s / batch. (data: 1.59e-03). ETA=11:14:45, max mem: 20.9 GB 
[11/30 18:56:57][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 3.73e-01, avg batch time: 1.2138, average train loss: 3.1650
[11/30 18:58:07][INFO] visual_prompt:  316: Inference (val):avg data time: 9.84e-05, avg batch time: 0.3115, average loss: 0.9248
[11/30 18:58:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.60	
[11/30 18:58:07][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/30 19:00:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6262,	1.1195 s / batch. (data: 2.84e-01). ETA=14:04:10, max mem: 20.9 GB 
[11/30 19:02:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.7280,	0.8442 s / batch. (data: 1.48e-03). ETA=10:35:10, max mem: 20.9 GB 
[11/30 19:04:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.0892,	0.8395 s / batch. (data: 3.13e-03). ETA=10:30:16, max mem: 20.9 GB 
[11/30 19:06:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3262,	0.8359 s / batch. (data: 5.53e-04). ETA=10:26:08, max mem: 20.9 GB 
[11/30 19:08:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1437,	0.8560 s / batch. (data: 5.00e-04). ETA=10:39:48, max mem: 20.9 GB 
[11/30 19:09:18][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 3.72e-01, avg batch time: 1.2127, average train loss: 1.7645
[11/30 19:10:29][INFO] visual_prompt:  316: Inference (val):avg data time: 1.35e-04, avg batch time: 0.3151, average loss: 3.4530
[11/30 19:10:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.46	
[11/30 19:10:29][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/30 19:12:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5834,	1.1662 s / batch. (data: 3.39e-01). ETA=14:28:39, max mem: 20.9 GB 
[11/30 19:14:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6940,	0.8477 s / batch. (data: 5.48e-04). ETA=10:30:02, max mem: 20.9 GB 
[11/30 19:16:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.6089,	0.8304 s / batch. (data: 1.04e-03). ETA=10:15:46, max mem: 20.9 GB 
[11/30 19:18:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6775,	0.8280 s / batch. (data: 6.18e-04). ETA=10:12:38, max mem: 20.9 GB 
[11/30 19:20:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3922,	0.8449 s / batch. (data: 8.68e-03). ETA=10:23:41, max mem: 20.9 GB 
[11/30 19:21:40][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 3.71e-01, avg batch time: 1.2129, average train loss: 2.1300
[11/30 19:22:51][INFO] visual_prompt:  316: Inference (val):avg data time: 2.86e-04, avg batch time: 0.3129, average loss: 0.7118
[11/30 19:22:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.56	
[11/30 19:22:51][INFO] visual_prompt:   36: Best epoch 20: best metric: -0.712
[11/30 19:22:51][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/30 19:24:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5810,	1.0994 s / batch. (data: 2.70e-01). ETA=13:28:45, max mem: 20.9 GB 
[11/30 19:26:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.4126,	0.8307 s / batch. (data: 1.07e-02). ETA=10:09:42, max mem: 20.9 GB 
[11/30 19:28:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8785,	0.8561 s / batch. (data: 1.70e-03). ETA=10:26:54, max mem: 20.9 GB 
[11/30 19:31:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.0139,	0.8538 s / batch. (data: 1.26e-02). ETA=10:23:48, max mem: 20.9 GB 
[11/30 19:33:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.0082,	0.8218 s / batch. (data: 3.45e-04). ETA=9:59:05, max mem: 20.9 GB 
[11/30 19:34:03][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 3.72e-01, avg batch time: 1.2138, average train loss: 2.1354
[11/30 19:35:15][INFO] visual_prompt:  316: Inference (val):avg data time: 1.24e-04, avg batch time: 0.3122, average loss: 1.3491
[11/30 19:35:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.65	
[11/30 19:35:15][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/30 19:37:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.5063,	0.8999 s / batch. (data: 1.16e-02). ETA=10:53:44, max mem: 20.9 GB 
[11/30 19:39:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6319,	0.8376 s / batch. (data: 5.07e-04). ETA=10:07:04, max mem: 20.9 GB 
[11/30 19:41:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0657,	1.0602 s / batch. (data: 2.19e-01). ETA=12:46:36, max mem: 20.9 GB 
[11/30 19:43:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 10.1777,	0.8357 s / batch. (data: 7.65e-04). ETA=10:02:56, max mem: 20.9 GB 
[11/30 19:45:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8846,	0.8247 s / batch. (data: 5.70e-04). ETA=9:53:35, max mem: 20.9 GB 
[11/30 19:46:24][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 3.68e-01, avg batch time: 1.2081, average train loss: 1.8319
[11/30 19:47:33][INFO] visual_prompt:  316: Inference (val):avg data time: 8.80e-05, avg batch time: 0.3107, average loss: 3.1889
[11/30 19:47:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.64	
[11/30 19:47:33][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/30 19:49:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2534,	1.1175 s / batch. (data: 2.85e-01). ETA=13:21:32, max mem: 20.9 GB 
[11/30 19:51:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5634,	1.1560 s / batch. (data: 3.20e-01). ETA=13:47:12, max mem: 20.9 GB 
[11/30 19:53:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5942,	0.8361 s / batch. (data: 5.44e-04). ETA=9:56:54, max mem: 20.9 GB 
[11/30 19:55:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.5386,	0.8451 s / batch. (data: 1.09e-02). ETA=10:01:56, max mem: 20.9 GB 
[11/30 19:57:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0000,	0.8570 s / batch. (data: 8.66e-03). ETA=10:08:55, max mem: 20.9 GB 
[11/30 19:58:41][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 3.65e-01, avg batch time: 1.2066, average train loss: 2.2013
[11/30 19:59:49][INFO] visual_prompt:  316: Inference (val):avg data time: 8.93e-05, avg batch time: 0.3104, average loss: 2.4110
[11/30 19:59:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.72	
[11/30 19:59:49][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/30 20:01:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 6.5537,	0.8760 s / batch. (data: 1.19e-02). ETA=10:20:14, max mem: 20.9 GB 
[11/30 20:03:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6106,	0.8768 s / batch. (data: 1.41e-02). ETA=10:19:20, max mem: 20.9 GB 
[11/30 20:05:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3971,	1.5407 s / batch. (data: 7.04e-01). ETA=18:05:41, max mem: 20.9 GB 
[11/30 20:07:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6552,	0.8244 s / batch. (data: 7.91e-03). ETA=9:39:33, max mem: 20.9 GB 
[11/30 20:09:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9322,	0.8240 s / batch. (data: 5.20e-04). ETA=9:37:54, max mem: 20.9 GB 
[11/30 20:10:48][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 3.51e-01, avg batch time: 1.1903, average train loss: 2.2871
[11/30 20:11:58][INFO] visual_prompt:  316: Inference (val):avg data time: 1.88e-04, avg batch time: 0.3109, average loss: 0.7321
[11/30 20:11:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.61	
[11/30 20:11:58][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/30 20:14:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.2837,	0.8400 s / batch. (data: 8.07e-03). ETA=9:47:00, max mem: 20.9 GB 
[11/30 20:16:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1692,	1.1765 s / batch. (data: 3.41e-01). ETA=13:40:09, max mem: 20.9 GB 
[11/30 20:18:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5923,	1.6134 s / batch. (data: 7.62e-01). ETA=18:42:02, max mem: 20.9 GB 
[11/30 20:19:57][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2355,	1.6832 s / batch. (data: 8.52e-01). ETA=19:27:47, max mem: 20.9 GB 
[11/30 20:21:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7242,	2.3690 s / batch. (data: 1.53e+00). ETA=1 day, 3:19:40, max mem: 20.9 GB 
[11/30 20:22:58][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 3.53e-01, avg batch time: 1.1923, average train loss: 1.6836
[11/30 20:24:07][INFO] visual_prompt:  316: Inference (val):avg data time: 9.11e-05, avg batch time: 0.3121, average loss: 3.6299
[11/30 20:24:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.64	
[11/30 20:24:07][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/30 20:26:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.0128,	0.8347 s / batch. (data: 1.70e-03). ETA=9:35:34, max mem: 20.9 GB 
[11/30 20:28:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 11.8396,	2.6429 s / batch. (data: 1.82e+00). ETA=1 day, 6:18:04, max mem: 20.9 GB 
[11/30 20:30:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.1117,	0.8280 s / batch. (data: 1.20e-02). ETA=9:28:14, max mem: 20.9 GB 
[11/30 20:32:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5824,	0.8399 s / batch. (data: 7.98e-04). ETA=9:34:58, max mem: 20.9 GB 
[11/30 20:34:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.2843,	0.8360 s / batch. (data: 4.84e-04). ETA=9:30:54, max mem: 20.9 GB 
[11/30 20:35:08][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 3.56e-01, avg batch time: 1.1951, average train loss: 2.4047
[11/30 20:36:16][INFO] visual_prompt:  316: Inference (val):avg data time: 9.27e-05, avg batch time: 0.3110, average loss: 0.8601
[11/30 20:36:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.71	
[11/30 20:36:16][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/30 20:38:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6568,	0.8655 s / batch. (data: 1.23e-03). ETA=9:48:53, max mem: 20.9 GB 
[11/30 20:40:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 5.6375,	2.5520 s / batch. (data: 1.71e+00). ETA=1 day, 4:52:03, max mem: 20.9 GB 
[11/30 20:42:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6742,	1.2538 s / batch. (data: 3.86e-01). ETA=14:08:51, max mem: 20.9 GB 
[11/30 20:44:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 22.6630,	0.8799 s / batch. (data: 1.54e-02). ETA=9:54:13, max mem: 20.9 GB 
[11/30 20:46:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7050,	0.8641 s / batch. (data: 3.36e-03). ETA=9:42:09, max mem: 20.9 GB 
[11/30 20:47:13][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 3.48e-01, avg batch time: 1.1864, average train loss: 2.5300
[11/30 20:48:22][INFO] visual_prompt:  316: Inference (val):avg data time: 7.40e-04, avg batch time: 0.3129, average loss: 4.6716
[11/30 20:48:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.49	
[11/30 20:48:22][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/30 20:50:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8769 s / batch. (data: 5.63e-03). ETA=9:48:31, max mem: 20.9 GB 
[11/30 20:52:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6092,	0.8402 s / batch. (data: 9.42e-04). ETA=9:22:28, max mem: 20.9 GB 
[11/30 20:54:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.4800,	2.0994 s / batch. (data: 1.24e+00). ETA=23:22:01, max mem: 20.9 GB 
[11/30 20:56:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.4777,	0.8678 s / batch. (data: 1.85e-03). ETA=9:38:05, max mem: 20.9 GB 
[11/30 20:58:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.5916,	0.8459 s / batch. (data: 1.13e-02). ETA=9:22:04, max mem: 20.9 GB 
[11/30 20:59:18][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 3.49e-01, avg batch time: 1.1869, average train loss: 2.3100
[11/30 21:00:28][INFO] visual_prompt:  316: Inference (val):avg data time: 4.82e-04, avg batch time: 0.3128, average loss: 0.7591
[11/30 21:00:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.65	
[11/30 21:00:28][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/30 21:02:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.9452,	0.8640 s / batch. (data: 5.50e-04). ETA=9:31:53, max mem: 20.9 GB 
[11/30 21:04:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9163,	2.5196 s / batch. (data: 1.69e+00). ETA=1 day, 3:43:36, max mem: 20.9 GB 
[11/30 21:06:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0176,	0.8476 s / batch. (data: 8.53e-04). ETA=9:18:14, max mem: 20.9 GB 
[11/30 21:08:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.4156,	2.2046 s / batch. (data: 1.36e+00). ETA=1 day, 0:08:14, max mem: 20.9 GB 
[11/30 21:10:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.2743,	0.8284 s / batch. (data: 1.76e-03). ETA=9:02:48, max mem: 20.9 GB 
[11/30 21:11:38][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 3.69e-01, avg batch time: 1.2105, average train loss: 1.7621
[11/30 21:12:50][INFO] visual_prompt:  316: Inference (val):avg data time: 1.15e-04, avg batch time: 0.3130, average loss: 1.4689
[11/30 21:12:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.46	
[11/30 21:12:50][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/30 21:14:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3579,	0.8734 s / batch. (data: 5.67e-03). ETA=9:30:03, max mem: 20.9 GB 
[11/30 21:16:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.5283,	0.8701 s / batch. (data: 1.56e-03). ETA=9:26:27, max mem: 20.9 GB 
[11/30 21:18:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	1.2563 s / batch. (data: 4.38e-01). ETA=13:35:50, max mem: 20.9 GB 
[11/30 21:20:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8073,	2.0079 s / batch. (data: 1.15e+00). ETA=21:40:31, max mem: 20.9 GB 
[11/30 21:22:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.9417,	2.4055 s / batch. (data: 1.57e+00). ETA=1 day, 1:54:02, max mem: 20.9 GB 
[11/30 21:23:57][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 3.63e-01, avg batch time: 1.2051, average train loss: 1.7273
[11/30 21:25:09][INFO] visual_prompt:  316: Inference (val):avg data time: 1.15e-04, avg batch time: 0.3121, average loss: 0.7019
[11/30 21:25:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[11/30 21:25:09][INFO] visual_prompt:   36: Best epoch 30: best metric: -0.702
[11/30 21:25:09][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/30 21:27:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.5419,	0.8212 s / batch. (data: 1.06e-03). ETA=8:48:24, max mem: 20.9 GB 
[11/30 21:29:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.6897,	0.8742 s / batch. (data: 2.33e-03). ETA=9:21:05, max mem: 20.9 GB 
[11/30 21:31:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.9643,	0.8842 s / batch. (data: 1.15e-02). ETA=9:26:01, max mem: 20.9 GB 
[11/30 21:33:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2880,	1.4803 s / batch. (data: 6.46e-01). ETA=15:45:11, max mem: 20.9 GB 
[11/30 21:35:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6039,	0.8360 s / batch. (data: 1.53e-03). ETA=8:52:22, max mem: 20.9 GB 
[11/30 21:36:35][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 3.96e-01, avg batch time: 1.2406, average train loss: 2.2001
[11/30 21:37:46][INFO] visual_prompt:  316: Inference (val):avg data time: 1.07e-04, avg batch time: 0.3133, average loss: 0.8232
[11/30 21:37:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.39	
[11/30 21:37:46][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/30 21:39:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9455,	0.8845 s / batch. (data: 6.33e-04). ETA=9:21:00, max mem: 20.9 GB 
[11/30 21:42:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.8196,	0.8840 s / batch. (data: 1.92e-03). ETA=9:19:13, max mem: 20.9 GB 
[11/30 21:44:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.4443,	0.8271 s / batch. (data: 1.58e-03). ETA=8:41:50, max mem: 20.9 GB 
[11/30 21:46:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7317,	0.8253 s / batch. (data: 1.65e-03). ETA=8:39:20, max mem: 20.9 GB 
[11/30 21:48:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1630,	0.8640 s / batch. (data: 1.50e-03). ETA=9:02:15, max mem: 20.9 GB 
[11/30 21:49:27][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 4.20e-01, avg batch time: 1.2667, average train loss: 1.5822
[11/30 21:50:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.13e-04, avg batch time: 0.3138, average loss: 2.1389
[11/30 21:50:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.80	
[11/30 21:50:39][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/30 21:52:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0169,	1.8787 s / batch. (data: 1.03e+00). ETA=19:34:20, max mem: 20.9 GB 
[11/30 21:54:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2373,	2.6183 s / batch. (data: 1.79e+00). ETA=1 day, 3:12:14, max mem: 20.9 GB 
[11/30 21:56:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6407,	0.8624 s / batch. (data: 1.56e-03). ETA=8:56:09, max mem: 20.9 GB 
[11/30 21:59:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.1459,	0.8278 s / batch. (data: 1.52e-03). ETA=8:33:19, max mem: 20.9 GB 
[11/30 22:01:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8285,	0.8385 s / batch. (data: 1.32e-03). ETA=8:38:31, max mem: 20.9 GB 
[11/30 22:02:19][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 4.19e-01, avg batch time: 1.2649, average train loss: 2.2029
[11/30 22:03:30][INFO] visual_prompt:  316: Inference (val):avg data time: 2.51e-04, avg batch time: 0.3127, average loss: 1.7899
[11/30 22:03:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[11/30 22:03:31][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/30 22:05:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7802,	1.0314 s / batch. (data: 1.87e-01). ETA=10:35:12, max mem: 20.9 GB 
[11/30 22:07:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7059,	0.8241 s / batch. (data: 4.27e-04). ETA=8:26:08, max mem: 20.9 GB 
[11/30 22:09:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6871,	1.6155 s / batch. (data: 7.58e-01). ETA=16:29:31, max mem: 20.9 GB 
[11/30 22:11:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 8.1180,	0.8600 s / batch. (data: 2.34e-03). ETA=8:45:18, max mem: 20.9 GB 
[11/30 22:13:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1805,	2.4158 s / batch. (data: 1.59e+00). ETA=1 day, 0:31:39, max mem: 20.9 GB 
[11/30 22:14:42][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 3.72e-01, avg batch time: 1.2137, average train loss: 2.4220
[11/30 22:15:57][INFO] visual_prompt:  316: Inference (val):avg data time: 1.16e-03, avg batch time: 0.3165, average loss: 0.6973
[11/30 22:15:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.53	
[11/30 22:15:57][INFO] visual_prompt:   36: Best epoch 34: best metric: -0.697
[11/30 22:15:57][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/30 22:18:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.9472,	0.8634 s / batch. (data: 1.19e-02). ETA=8:43:46, max mem: 20.9 GB 
[11/30 22:20:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7024,	0.9537 s / batch. (data: 1.01e-01). ETA=9:36:56, max mem: 20.9 GB 
[11/30 22:22:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.0088,	0.8240 s / batch. (data: 5.30e-04). ETA=8:17:07, max mem: 20.9 GB 
[11/30 22:24:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.9492,	1.6443 s / batch. (data: 8.23e-01). ETA=16:29:14, max mem: 20.9 GB 
[11/30 22:26:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7027,	1.9105 s / batch. (data: 1.08e+00). ETA=19:06:12, max mem: 20.9 GB 
[11/30 22:27:07][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 3.70e-01, avg batch time: 1.2110, average train loss: 1.8787
[11/30 22:28:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-04, avg batch time: 0.3141, average loss: 4.9512
[11/30 22:28:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.78	
[11/30 22:28:18][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/30 22:30:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.8079,	0.8509 s / batch. (data: 1.73e-03). ETA=8:28:19, max mem: 20.9 GB 
[11/30 22:32:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.8903,	0.8721 s / batch. (data: 1.58e-02). ETA=8:39:33, max mem: 20.9 GB 
[11/30 22:34:25][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0066,	0.8613 s / batch. (data: 6.95e-03). ETA=8:31:40, max mem: 20.9 GB 
[11/30 22:36:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7187,	1.4318 s / batch. (data: 6.12e-01). ETA=14:08:13, max mem: 20.9 GB 
[11/30 22:38:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8388,	1.5121 s / batch. (data: 6.91e-01). ETA=14:53:14, max mem: 20.9 GB 
[11/30 22:39:19][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 3.55e-01, avg batch time: 1.1950, average train loss: 2.0146
[11/30 22:40:29][INFO] visual_prompt:  316: Inference (val):avg data time: 3.28e-04, avg batch time: 0.3147, average loss: 1.5923
[11/30 22:40:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.21	
[11/30 22:40:29][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/30 22:42:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5348,	0.8399 s / batch. (data: 1.47e-03). ETA=8:14:02, max mem: 20.9 GB 
[11/30 22:44:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8555,	0.8240 s / batch. (data: 4.93e-04). ETA=8:03:18, max mem: 20.9 GB 
[11/30 22:46:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.8998,	2.2000 s / batch. (data: 1.36e+00). ETA=21:26:43, max mem: 20.9 GB 
[11/30 22:48:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7419,	2.2363 s / batch. (data: 1.40e+00). ETA=21:44:12, max mem: 20.9 GB 
[11/30 22:50:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4059,	1.8487 s / batch. (data: 9.73e-01). ETA=17:55:04, max mem: 20.9 GB 
[11/30 22:51:28][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 3.53e-01, avg batch time: 1.1907, average train loss: 1.9589
[11/30 22:52:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.39e-04, avg batch time: 0.3144, average loss: 0.7793
[11/30 22:52:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.97	
[11/30 22:52:36][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/30 22:54:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5645,	0.8481 s / batch. (data: 6.50e-03). ETA=8:11:03, max mem: 20.9 GB 
[11/30 22:56:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0203,	2.0074 s / batch. (data: 1.16e+00). ETA=19:18:54, max mem: 20.9 GB 
[11/30 22:58:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.2659,	0.8525 s / batch. (data: 7.87e-03). ETA=8:10:44, max mem: 20.9 GB 
[11/30 23:00:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4156,	0.8273 s / batch. (data: 5.26e-04). ETA=7:54:50, max mem: 20.9 GB 
[11/30 23:02:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5712,	0.8709 s / batch. (data: 2.12e-03). ETA=8:18:24, max mem: 20.9 GB 
[11/30 23:03:31][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 3.45e-01, avg batch time: 1.1839, average train loss: 1.9836
[11/30 23:04:41][INFO] visual_prompt:  316: Inference (val):avg data time: 9.98e-05, avg batch time: 0.3121, average loss: 2.0595
[11/30 23:04:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.40	
[11/30 23:04:41][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/30 23:06:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0233,	0.8498 s / batch. (data: 5.70e-03). ETA=8:04:10, max mem: 20.9 GB 
[11/30 23:08:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2022,	0.8373 s / batch. (data: 5.92e-04). ETA=7:55:41, max mem: 20.9 GB 
[11/30 23:10:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.7887,	0.8440 s / batch. (data: 5.25e-04). ETA=7:58:04, max mem: 20.9 GB 
[11/30 23:12:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1589,	0.8484 s / batch. (data: 7.00e-04). ETA=7:59:10, max mem: 20.9 GB 
[11/30 23:14:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4047,	2.6127 s / batch. (data: 1.78e+00). ETA=1 day, 0:31:12, max mem: 20.9 GB 
[11/30 23:15:45][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 3.61e-01, avg batch time: 1.2002, average train loss: 1.9424
[11/30 23:16:54][INFO] visual_prompt:  316: Inference (val):avg data time: 9.74e-05, avg batch time: 0.3140, average loss: 0.6912
[11/30 23:16:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 49.58	
[11/30 23:16:54][INFO] visual_prompt:   36: Best epoch 39: best metric: -0.691
[11/30 23:16:54][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/30 23:19:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.9837,	0.8392 s / batch. (data: 3.45e-03). ETA=7:50:24, max mem: 20.9 GB 
[11/30 23:21:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2992,	0.8534 s / batch. (data: 1.92e-02). ETA=7:56:57, max mem: 20.9 GB 
[11/30 23:23:03][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.2350,	0.8360 s / batch. (data: 1.78e-03). ETA=7:45:49, max mem: 20.9 GB 
[11/30 23:25:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.3173,	0.8806 s / batch. (data: 1.10e-02). ETA=8:09:12, max mem: 20.9 GB 
[11/30 23:27:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2729,	0.8922 s / batch. (data: 3.56e-02). ETA=8:14:10, max mem: 20.9 GB 
[11/30 23:28:08][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 3.78e-01, avg batch time: 1.2187, average train loss: 2.1331
[11/30 23:29:20][INFO] visual_prompt:  316: Inference (val):avg data time: 4.52e-04, avg batch time: 0.3135, average loss: 0.6875
[11/30 23:29:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.70	
[11/30 23:29:20][INFO] visual_prompt:   36: Best epoch 40: best metric: -0.687
[11/30 23:29:20][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.75
[11/30 23:31:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0026,	0.8440 s / batch. (data: 5.51e-04). ETA=7:45:18, max mem: 20.9 GB 
[11/30 23:33:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5577,	0.8478 s / batch. (data: 6.33e-04). ETA=7:46:01, max mem: 20.9 GB 
[11/30 23:35:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8985,	0.8298 s / batch. (data: 5.90e-04). ETA=7:34:43, max mem: 20.9 GB 
[11/30 23:37:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7687,	0.8396 s / batch. (data: 1.18e-02). ETA=7:38:40, max mem: 20.9 GB 
[11/30 23:39:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9609,	0.8438 s / batch. (data: 1.44e-03). ETA=7:39:33, max mem: 20.9 GB 
[11/30 23:40:32][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 3.74e-01, avg batch time: 1.2158, average train loss: 1.8076
[11/30 23:41:41][INFO] visual_prompt:  316: Inference (val):avg data time: 2.98e-04, avg batch time: 0.3111, average loss: 0.8254
[11/30 23:41:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.25	
[11/30 23:41:41][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/30 23:43:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.5121,	0.8198 s / batch. (data: 5.68e-04). ETA=7:24:25, max mem: 20.9 GB 
[11/30 23:45:48][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.8598,	0.8168 s / batch. (data: 5.03e-04). ETA=7:21:27, max mem: 20.9 GB 
[11/30 23:47:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5575,	0.8694 s / batch. (data: 7.83e-03). ETA=7:48:24, max mem: 20.9 GB 
[11/30 23:49:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8109,	0.8610 s / batch. (data: 1.38e-02). ETA=7:42:28, max mem: 20.9 GB 
[11/30 23:51:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9449,	1.3200 s / batch. (data: 4.96e-01). ETA=11:46:46, max mem: 20.9 GB 
[11/30 23:52:51][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 3.69e-01, avg batch time: 1.2110, average train loss: 2.8876
[11/30 23:54:03][INFO] visual_prompt:  316: Inference (val):avg data time: 1.14e-04, avg batch time: 0.3118, average loss: 3.6646
[11/30 23:54:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.18	
[11/30 23:54:03][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/30 23:56:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5826,	0.8321 s / batch. (data: 1.19e-02). ETA=7:23:24, max mem: 20.9 GB 
[11/30 23:58:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.6250,	0.8603 s / batch. (data: 1.55e-03). ETA=7:36:59, max mem: 20.9 GB 
[12/01 00:00:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8087,	0.8521 s / batch. (data: 1.43e-02). ETA=7:31:15, max mem: 20.9 GB 
[12/01 00:02:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8170,	0.8364 s / batch. (data: 5.20e-04). ETA=7:21:32, max mem: 20.9 GB 
[12/01 00:04:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.3906,	0.8554 s / batch. (data: 5.21e-04). ETA=7:30:09, max mem: 20.9 GB 
[12/01 00:05:12][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 3.71e-01, avg batch time: 1.2088, average train loss: 1.7912
[12/01 00:06:22][INFO] visual_prompt:  316: Inference (val):avg data time: 8.67e-05, avg batch time: 0.3112, average loss: 0.7125
[12/01 00:06:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.82	
[12/01 00:06:22][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[12/01 00:08:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6620,	0.8319 s / batch. (data: 5.50e-04). ETA=7:15:39, max mem: 20.9 GB 
[12/01 00:10:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.5963,	0.8435 s / batch. (data: 5.47e-04). ETA=7:20:18, max mem: 20.9 GB 
[12/01 00:12:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1343,	0.8444 s / batch. (data: 7.89e-03). ETA=7:19:22, max mem: 20.9 GB 
[12/01 00:14:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7961,	0.8530 s / batch. (data: 1.58e-02). ETA=7:22:25, max mem: 20.9 GB 
[12/01 00:16:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4189,	0.8283 s / batch. (data: 1.62e-03). ETA=7:08:13, max mem: 20.9 GB 
[12/01 00:17:29][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 3.62e-01, avg batch time: 1.2044, average train loss: 1.7323
[12/01 00:18:41][INFO] visual_prompt:  316: Inference (val):avg data time: 1.90e-04, avg batch time: 0.3146, average loss: 3.6322
[12/01 00:18:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.28	
[12/01 00:18:41][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[12/01 00:20:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.9493,	0.8359 s / batch. (data: 1.25e-03). ETA=7:10:02, max mem: 20.9 GB 
[12/01 00:22:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.9173,	2.1401 s / batch. (data: 1.31e+00). ETA=18:17:25, max mem: 20.9 GB 
[12/01 00:24:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 4.5470,	0.8627 s / batch. (data: 1.06e-02). ETA=7:20:58, max mem: 20.9 GB 
[12/01 00:26:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9918,	0.8554 s / batch. (data: 6.27e-03). ETA=7:15:46, max mem: 20.9 GB 
[12/01 00:28:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5472,	0.8324 s / batch. (data: 7.72e-04). ETA=7:02:41, max mem: 20.9 GB 
[12/01 00:29:56][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 3.79e-01, avg batch time: 1.2203, average train loss: 1.2542
[12/01 00:31:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-04, avg batch time: 0.3134, average loss: 2.2121
[12/01 00:31:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.60	
[12/01 00:31:06][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[12/01 00:33:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0741,	1.9555 s / batch. (data: 1.12e+00). ETA=16:27:59, max mem: 20.9 GB 
[12/01 00:35:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3387,	0.8338 s / batch. (data: 5.19e-04). ETA=6:59:53, max mem: 20.9 GB 
[12/01 00:37:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0882,	0.8597 s / batch. (data: 6.84e-03). ETA=7:11:30, max mem: 20.9 GB 
[12/01 00:39:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.5967,	0.8440 s / batch. (data: 1.50e-03). ETA=7:02:13, max mem: 20.9 GB 
[12/01 00:41:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9018,	0.8486 s / batch. (data: 2.39e-02). ETA=7:03:05, max mem: 20.9 GB 
[12/01 00:42:16][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 3.70e-01, avg batch time: 1.2102, average train loss: 1.1625
[12/01 00:43:27][INFO] visual_prompt:  316: Inference (val):avg data time: 1.11e-04, avg batch time: 0.3127, average loss: 0.7888
[12/01 00:43:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.65	
[12/01 00:43:27][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[12/01 00:45:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3990,	0.8256 s / batch. (data: 6.40e-04). ETA=6:49:32, max mem: 20.9 GB 
[12/01 00:47:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.1580,	1.5682 s / batch. (data: 7.33e-01). ETA=12:55:17, max mem: 20.9 GB 
[12/01 00:49:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.5841,	0.8594 s / batch. (data: 6.10e-03). ETA=7:03:26, max mem: 20.9 GB 
[12/01 00:51:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3300,	0.8547 s / batch. (data: 2.58e-02). ETA=6:59:42, max mem: 20.9 GB 
[12/01 00:53:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0709,	0.8793 s / batch. (data: 6.84e-03). ETA=7:10:19, max mem: 20.9 GB 
[12/01 00:54:37][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 3.70e-01, avg batch time: 1.2120, average train loss: 1.8019
[12/01 00:55:46][INFO] visual_prompt:  316: Inference (val):avg data time: 8.18e-05, avg batch time: 0.3111, average loss: 1.6289
[12/01 00:55:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.55	
[12/01 00:55:46][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[12/01 00:57:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.5418,	0.8549 s / batch. (data: 5.59e-03). ETA=6:56:10, max mem: 20.9 GB 
[12/01 00:59:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.7255,	0.8283 s / batch. (data: 6.53e-04). ETA=6:41:51, max mem: 20.9 GB 
[12/01 01:01:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7735,	3.1916 s / batch. (data: 2.36e+00). ETA=1 day, 1:43:05, max mem: 20.9 GB 
[12/01 01:03:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0003,	1.0999 s / batch. (data: 2.70e-01). ETA=8:49:57, max mem: 20.9 GB 
[12/01 01:05:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8329,	0.8302 s / batch. (data: 7.09e-04). ETA=6:38:38, max mem: 20.9 GB 
[12/01 01:06:53][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 3.65e-01, avg batch time: 1.2057, average train loss: 1.3961
[12/01 01:08:02][INFO] visual_prompt:  316: Inference (val):avg data time: 2.69e-04, avg batch time: 0.3127, average loss: 1.5958
[12/01 01:08:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.42	
[12/01 01:08:02][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[12/01 01:10:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7296,	0.8696 s / batch. (data: 1.07e-02). ETA=6:55:18, max mem: 20.9 GB 
[12/01 01:12:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0577,	0.8245 s / batch. (data: 5.43e-04). ETA=6:32:25, max mem: 20.9 GB 
[12/01 01:14:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.9160,	0.8600 s / batch. (data: 7.74e-03). ETA=6:47:51, max mem: 20.9 GB 
[12/01 01:16:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8221,	0.8322 s / batch. (data: 9.08e-04). ETA=6:33:18, max mem: 20.9 GB 
[12/01 01:18:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5410,	0.8415 s / batch. (data: 1.02e-03). ETA=6:36:17, max mem: 20.9 GB 
[12/01 01:19:05][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 3.59e-01, avg batch time: 1.1975, average train loss: 1.3092
[12/01 01:20:14][INFO] visual_prompt:  316: Inference (val):avg data time: 8.33e-05, avg batch time: 0.3115, average loss: 1.1443
[12/01 01:20:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.26	
[12/01 01:20:14][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[12/01 01:22:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7521,	0.8815 s / batch. (data: 2.23e-02). ETA=6:52:52, max mem: 20.9 GB 
[12/01 01:24:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.1074,	0.8460 s / batch. (data: 5.50e-03). ETA=6:34:51, max mem: 20.9 GB 
[12/01 01:26:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7680,	0.8448 s / batch. (data: 8.68e-03). ETA=6:32:51, max mem: 20.9 GB 
[12/01 01:28:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1112,	0.8635 s / batch. (data: 1.21e-02). ETA=6:40:07, max mem: 20.9 GB 
[12/01 01:30:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.2906,	0.8773 s / batch. (data: 2.18e-02). ETA=6:45:04, max mem: 20.9 GB 
[12/01 01:31:22][INFO] visual_prompt:  217: Epoch 50 / 100: avg data time: 3.68e-01, avg batch time: 1.2085, average train loss: 1.3716
[12/01 01:32:33][INFO] visual_prompt:  316: Inference (val):avg data time: 1.22e-04, avg batch time: 0.3119, average loss: 1.5215
[12/01 01:32:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.37	
[12/01 01:32:33][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[12/01 01:34:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7612,	1.6640 s / batch. (data: 8.33e-01). ETA=12:44:02, max mem: 20.9 GB 
[12/01 01:36:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4728,	0.8498 s / batch. (data: 2.22e-02). ETA=6:28:46, max mem: 20.9 GB 
[12/01 01:38:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.2629,	2.1561 s / batch. (data: 1.29e+00). ETA=16:22:48, max mem: 20.9 GB 
[12/01 01:40:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.5016,	2.5584 s / batch. (data: 1.74e+00). ETA=19:21:56, max mem: 20.9 GB 
[12/01 01:42:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6205,	0.8639 s / batch. (data: 1.36e-03). ETA=6:30:54, max mem: 20.9 GB 
[12/01 01:43:45][INFO] visual_prompt:  217: Epoch 51 / 100: avg data time: 3.73e-01, avg batch time: 1.2137, average train loss: 1.2642
[12/01 01:44:56][INFO] visual_prompt:  316: Inference (val):avg data time: 1.17e-04, avg batch time: 0.3125, average loss: 0.7854
[12/01 01:44:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.11	
[12/01 01:44:56][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[12/01 01:47:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.8758,	0.8388 s / batch. (data: 1.47e-03). ETA=6:17:25, max mem: 20.9 GB 
[12/01 01:49:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7447,	0.8725 s / batch. (data: 5.87e-04). ETA=6:31:07, max mem: 20.9 GB 
[12/01 01:51:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9115,	0.8538 s / batch. (data: 1.60e-03). ETA=6:21:19, max mem: 20.9 GB 
[12/01 01:53:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0999,	0.8519 s / batch. (data: 1.37e-03). ETA=6:19:02, max mem: 20.9 GB 
[12/01 01:55:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4158,	0.8408 s / batch. (data: 5.24e-04). ETA=6:12:41, max mem: 20.9 GB 
[12/01 01:56:10][INFO] visual_prompt:  217: Epoch 52 / 100: avg data time: 3.77e-01, avg batch time: 1.2186, average train loss: 1.6700
[12/01 01:57:24][INFO] visual_prompt:  316: Inference (val):avg data time: 1.39e-04, avg batch time: 0.3154, average loss: 1.0005
[12/01 01:57:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.52	
[12/01 01:57:24][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[12/01 01:59:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1284,	0.8437 s / batch. (data: 7.92e-03). ETA=6:11:51, max mem: 20.9 GB 
[12/01 02:01:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5101,	0.8824 s / batch. (data: 1.06e-02). ETA=6:27:26, max mem: 20.9 GB 
[12/01 02:03:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8134,	0.8314 s / batch. (data: 4.66e-04). ETA=6:03:38, max mem: 20.9 GB 
[12/01 02:05:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8493,	1.7898 s / batch. (data: 9.71e-01). ETA=12:59:52, max mem: 20.9 GB 
[12/01 02:07:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.9513,	0.8582 s / batch. (data: 7.06e-03). ETA=6:12:30, max mem: 20.9 GB 
[12/01 02:08:30][INFO] visual_prompt:  217: Epoch 53 / 100: avg data time: 3.64e-01, avg batch time: 1.2043, average train loss: 1.3348
[12/01 02:09:40][INFO] visual_prompt:  316: Inference (val):avg data time: 2.73e-04, avg batch time: 0.3135, average loss: 8.3878
[12/01 02:09:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.33	
[12/01 02:09:40][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[12/01 02:11:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7603,	0.8521 s / batch. (data: 1.58e-02). ETA=6:07:42, max mem: 20.9 GB 
[12/01 02:13:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6690,	0.8402 s / batch. (data: 1.06e-03). ETA=6:01:09, max mem: 20.9 GB 
[12/01 02:15:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.4122,	1.6062 s / batch. (data: 7.72e-01). ETA=11:27:45, max mem: 20.9 GB 
[12/01 02:17:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.2229,	0.8486 s / batch. (data: 7.89e-03). ETA=6:01:55, max mem: 20.9 GB 
[12/01 02:19:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5575,	0.8367 s / batch. (data: 1.18e-02). ETA=5:55:29, max mem: 20.9 GB 
[12/01 02:20:47][INFO] visual_prompt:  217: Epoch 54 / 100: avg data time: 3.66e-01, avg batch time: 1.2058, average train loss: 1.5471
[12/01 02:21:59][INFO] visual_prompt:  316: Inference (val):avg data time: 2.87e-04, avg batch time: 0.3145, average loss: 3.9482
[12/01 02:21:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.72	
[12/01 02:21:59][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[12/01 02:24:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5613,	0.8527 s / batch. (data: 9.38e-03). ETA=6:00:06, max mem: 20.9 GB 
[12/01 02:26:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.3524,	0.8541 s / batch. (data: 7.84e-03). ETA=5:59:15, max mem: 20.9 GB 
[12/01 02:28:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6965,	0.8463 s / batch. (data: 1.59e-02). ETA=5:54:34, max mem: 20.9 GB 
[12/01 02:30:12][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.4366,	2.3233 s / batch. (data: 1.46e+00). ETA=16:09:29, max mem: 20.9 GB 
[12/01 02:32:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9577,	1.9786 s / batch. (data: 1.15e+00). ETA=13:42:23, max mem: 20.9 GB 
[12/01 02:33:18][INFO] visual_prompt:  217: Epoch 55 / 100: avg data time: 3.84e-01, avg batch time: 1.2278, average train loss: 1.4788
[12/01 02:34:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.12e-04, avg batch time: 0.3131, average loss: 1.8985
[12/01 02:34:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.87	
[12/01 02:34:27][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 0.5
[12/01 02:36:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.5224,	0.8286 s / batch. (data: 1.20e-02). ETA=5:42:17, max mem: 20.9 GB 
[12/01 02:38:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.1610,	0.8240 s / batch. (data: 5.37e-04). ETA=5:38:59, max mem: 20.9 GB 
[12/01 02:40:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9919,	0.8434 s / batch. (data: 7.82e-04). ETA=5:45:35, max mem: 20.9 GB 
[12/01 02:42:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7902,	0.8503 s / batch. (data: 1.22e-02). ETA=5:47:00, max mem: 20.9 GB 
[12/01 02:44:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3092,	3.6707 s / batch. (data: 2.84e+00). ETA=1 day, 0:51:49, max mem: 20.9 GB 
[12/01 02:45:38][INFO] visual_prompt:  217: Epoch 56 / 100: avg data time: 3.72e-01, avg batch time: 1.2126, average train loss: 1.6878
[12/01 02:46:49][INFO] visual_prompt:  316: Inference (val):avg data time: 1.05e-04, avg batch time: 0.3116, average loss: 1.0191
[12/01 02:46:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.40	
[12/01 02:46:49][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[12/01 02:48:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0296,	0.8786 s / batch. (data: 2.20e-02). ETA=5:54:50, max mem: 20.9 GB 
[12/01 02:50:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.5303,	1.2194 s / batch. (data: 3.95e-01). ETA=8:10:27, max mem: 20.9 GB 
[12/01 02:52:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3516,	0.8545 s / batch. (data: 5.92e-03). ETA=5:42:14, max mem: 20.9 GB 
[12/01 02:54:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0038,	0.8528 s / batch. (data: 5.97e-04). ETA=5:40:08, max mem: 20.9 GB 
[12/01 02:56:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0796,	0.8325 s / batch. (data: 5.30e-04). ETA=5:30:40, max mem: 20.9 GB 
[12/01 02:58:00][INFO] visual_prompt:  217: Epoch 57 / 100: avg data time: 3.72e-01, avg batch time: 1.2130, average train loss: 1.2450
[12/01 02:59:09][INFO] visual_prompt:  316: Inference (val):avg data time: 9.38e-05, avg batch time: 0.3112, average loss: 0.6973
[12/01 02:59:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[12/01 02:59:09][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[12/01 03:01:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9538,	1.9089 s / batch. (data: 1.10e+00). ETA=12:33:20, max mem: 20.9 GB 
[12/01 03:03:09][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7651,	0.8279 s / batch. (data: 6.87e-04). ETA=5:25:21, max mem: 20.9 GB 
[12/01 03:05:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8147,	0.8293 s / batch. (data: 1.44e-03). ETA=5:24:30, max mem: 20.9 GB 
[12/01 03:07:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8507,	0.8407 s / batch. (data: 4.50e-04). ETA=5:27:34, max mem: 20.9 GB 
[12/01 03:09:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7717,	0.8518 s / batch. (data: 1.42e-03). ETA=5:30:29, max mem: 20.9 GB 
[12/01 03:10:07][INFO] visual_prompt:  217: Epoch 58 / 100: avg data time: 3.51e-01, avg batch time: 1.1895, average train loss: 1.2145
[12/01 03:11:17][INFO] visual_prompt:  316: Inference (val):avg data time: 9.72e-05, avg batch time: 0.3106, average loss: 2.6693
[12/01 03:11:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.18	
[12/01 03:11:17][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[12/01 03:13:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6862,	0.8335 s / batch. (data: 6.12e-03). ETA=5:21:14, max mem: 20.9 GB 
[12/01 03:15:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0471,	0.8477 s / batch. (data: 7.27e-03). ETA=5:25:18, max mem: 20.9 GB 
[12/01 03:17:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.4638,	0.8870 s / batch. (data: 1.15e-02). ETA=5:38:54, max mem: 20.9 GB 
[12/01 03:19:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6033,	1.3094 s / batch. (data: 4.77e-01). ETA=8:18:08, max mem: 20.9 GB 
[12/01 03:21:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2148,	0.8559 s / batch. (data: 1.39e-03). ETA=5:24:11, max mem: 20.9 GB 
[12/01 03:22:21][INFO] visual_prompt:  217: Epoch 59 / 100: avg data time: 3.60e-01, avg batch time: 1.1998, average train loss: 1.2319
[12/01 03:23:31][INFO] visual_prompt:  316: Inference (val):avg data time: 1.18e-04, avg batch time: 0.3116, average loss: 1.1755
[12/01 03:23:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.31	
[12/01 03:23:31][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[12/01 03:25:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5628,	0.8548 s / batch. (data: 3.69e-02). ETA=5:21:34, max mem: 20.9 GB 
[12/01 03:27:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7739,	0.8580 s / batch. (data: 1.15e-03). ETA=5:21:20, max mem: 20.9 GB 
[12/01 03:29:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0036,	2.4261 s / batch. (data: 1.60e+00). ETA=15:04:38, max mem: 20.9 GB 
[12/01 03:31:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8494,	1.5774 s / batch. (data: 7.49e-01). ETA=9:45:32, max mem: 20.9 GB 
[12/01 03:33:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6277,	0.8491 s / batch. (data: 1.90e-03). ETA=5:13:47, max mem: 20.9 GB 
[12/01 03:34:36][INFO] visual_prompt:  217: Epoch 60 / 100: avg data time: 3.62e-01, avg batch time: 1.2022, average train loss: 1.0851
[12/01 03:35:46][INFO] visual_prompt:  316: Inference (val):avg data time: 2.24e-04, avg batch time: 0.3134, average loss: 0.9783
[12/01 03:35:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.83	
[12/01 03:35:46][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[12/01 03:37:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.6608,	0.8375 s / batch. (data: 4.62e-04). ETA=5:07:21, max mem: 20.9 GB 
[12/01 03:39:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1164,	0.8429 s / batch. (data: 1.19e-02). ETA=5:07:56, max mem: 20.9 GB 
[12/01 03:41:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1284,	1.3065 s / batch. (data: 4.60e-01). ETA=7:55:07, max mem: 20.9 GB 
[12/01 03:43:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9146,	0.8448 s / batch. (data: 5.69e-03). ETA=5:05:49, max mem: 20.9 GB 
[12/01 03:45:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.5714,	3.7240 s / batch. (data: 2.91e+00). ETA=22:21:53, max mem: 20.9 GB 
[12/01 03:46:51][INFO] visual_prompt:  217: Epoch 61 / 100: avg data time: 3.60e-01, avg batch time: 1.2012, average train loss: 1.0691
[12/01 03:48:02][INFO] visual_prompt:  316: Inference (val):avg data time: 2.44e-04, avg batch time: 0.3128, average loss: 0.6913
[12/01 03:48:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.51	
[12/01 03:48:02][INFO] visual_prompt:   42: Stopping early.
