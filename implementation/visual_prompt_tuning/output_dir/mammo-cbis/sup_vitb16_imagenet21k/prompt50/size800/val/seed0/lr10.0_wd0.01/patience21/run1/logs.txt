[11/25 14:04:35][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[11/25 14:04:35][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 14:04:35][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/25 14:04:35][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 14:04:35][INFO] visual_prompt:  108: Training with config:
[11/25 14:04:35][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr10.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/25 14:04:35][INFO] visual_prompt:   70: Loading training data...
[11/25 14:04:35][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[11/25 14:04:35][INFO] visual_prompt:   72: Loading validation data...
[11/25 14:04:35][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[11/25 14:04:35][INFO] visual_prompt:   36: Constructing models...
[11/25 14:04:40][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[11/25 14:04:40][INFO] visual_prompt:   54: tuned percent:0.525
[11/25 14:04:40][INFO] visual_prompt:   40: Device used for model: 0
[11/25 14:04:40][INFO] visual_prompt:   38: Setting up Evaluator...
[11/25 14:04:40][INFO] visual_prompt:   40: Setting up Trainer...
[11/25 14:04:40][INFO] visual_prompt:   45: 	Setting up the optimizer...
[11/25 14:04:40][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[11/25 14:06:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8266 s / batch. (data: 1.05e-02). ETA=12:40:25, max mem: 20.9 GB 
[11/25 14:07:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8440 s / batch. (data: 1.20e-02). ETA=12:55:05, max mem: 20.9 GB 
[11/25 14:09:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	1.5474 s / batch. (data: 6.86e-01). ETA=23:38:25, max mem: 20.9 GB 
[11/25 14:11:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8320 s / batch. (data: 3.10e-04). ETA=12:41:14, max mem: 20.9 GB 
[11/25 14:12:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8475 s / batch. (data: 7.20e-04). ETA=12:54:01, max mem: 20.9 GB 
[11/25 14:13:41][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 1.43e-01, avg batch time: 0.9769, average train loss: 1.5403
[11/25 14:14:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.22e-05, avg batch time: 0.3096, average loss: 1.5201
[11/25 14:14:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[11/25 14:14:36][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 1.0
[11/25 14:16:18][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.9190,	0.8339 s / batch. (data: 3.28e-04). ETA=12:39:31, max mem: 20.9 GB 
[11/25 14:17:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0037,	1.1952 s / batch. (data: 3.67e-01). ETA=18:06:33, max mem: 20.9 GB 
[11/25 14:19:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 7.8096,	0.8973 s / batch. (data: 7.27e-02). ETA=13:34:16, max mem: 20.9 GB 
[11/25 14:21:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6231,	0.8504 s / batch. (data: 3.03e-04). ETA=12:50:16, max mem: 20.9 GB 
[11/25 14:22:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.2929,	0.8207 s / batch. (data: 3.13e-04). ETA=12:22:00, max mem: 20.9 GB 
[11/25 14:23:35][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 1.40e-01, avg batch time: 0.9742, average train loss: 3.4209
[11/25 14:24:30][INFO] visual_prompt:  316: Inference (val):avg data time: 3.26e-05, avg batch time: 0.3121, average loss: 19.1750
[11/25 14:24:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.67	
[11/25 14:24:30][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 2.0
[11/25 14:26:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7196,	0.8360 s / batch. (data: 1.20e-02). ETA=12:33:42, max mem: 20.9 GB 
[11/25 14:27:48][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.8945,	1.0363 s / batch. (data: 2.08e-01). ETA=15:32:34, max mem: 20.9 GB 
[11/25 14:29:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 4.1691,	0.8423 s / batch. (data: 3.13e-04). ETA=12:36:32, max mem: 20.9 GB 
[11/25 14:31:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 55.2133,	0.8321 s / batch. (data: 3.08e-04). ETA=12:25:59, max mem: 20.9 GB 
[11/25 14:32:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 7.2534,	1.2394 s / batch. (data: 4.21e-01). ETA=18:29:08, max mem: 20.9 GB 
[11/25 14:33:30][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 1.43e-01, avg batch time: 0.9762, average train loss: 6.8817
[11/25 14:34:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3094, average loss: 4.1820
[11/25 14:34:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.68	
[11/25 14:34:26][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 3.0
[11/25 14:36:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 20.7751,	0.8260 s / batch. (data: 2.44e-04). ETA=12:17:02, max mem: 20.9 GB 
[11/25 14:37:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.4443,	0.8284 s / batch. (data: 5.44e-03). ETA=12:17:51, max mem: 20.9 GB 
[11/25 14:39:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.6300,	1.2156 s / batch. (data: 3.86e-01). ETA=18:00:41, max mem: 20.9 GB 
[11/25 14:40:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.1956,	1.3393 s / batch. (data: 5.14e-01). ETA=19:48:25, max mem: 20.9 GB 
[11/25 14:42:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 49.1465,	3.3321 s / batch. (data: 2.51e+00). ETA=2 days, 1:11:13, max mem: 20.9 GB 
[11/25 14:43:26][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 1.43e-01, avg batch time: 0.9770, average train loss: 9.3442
[11/25 14:44:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.3112, average loss: 2.7230
[11/25 14:44:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.14	
[11/25 14:44:21][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 4.0
[11/25 14:46:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3351,	0.8709 s / batch. (data: 1.49e-02). ETA=12:49:08, max mem: 20.9 GB 
[11/25 14:47:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 12.2037,	1.1255 s / batch. (data: 2.80e-01). ETA=16:32:07, max mem: 20.9 GB 
[11/25 14:49:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 47.6977,	0.8240 s / batch. (data: 4.23e-04). ETA=12:04:56, max mem: 20.9 GB 
[11/25 14:50:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 16.4583,	0.8429 s / batch. (data: 1.04e-02). ETA=12:20:11, max mem: 20.9 GB 
[11/25 14:52:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.7859,	0.8471 s / batch. (data: 3.06e-04). ETA=12:22:28, max mem: 20.9 GB 
[11/25 14:53:20][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 1.40e-01, avg batch time: 0.9743, average train loss: 13.9010
[11/25 14:54:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.15e-05, avg batch time: 0.3095, average loss: 92.5483
[11/25 14:54:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.76	
[11/25 14:54:16][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 5.0
[11/25 14:55:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.8484,	0.8280 s / batch. (data: 2.93e-04). ETA=12:03:36, max mem: 20.9 GB 
[11/25 14:57:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 11.7367,	0.8400 s / batch. (data: 5.43e-03). ETA=12:12:41, max mem: 20.9 GB 
[11/25 14:59:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.2738,	0.8376 s / batch. (data: 3.15e-04). ETA=12:09:11, max mem: 20.9 GB 
[11/25 15:00:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 8.4288,	0.8614 s / batch. (data: 4.82e-03). ETA=12:28:27, max mem: 20.9 GB 
[11/25 15:02:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.4603,	0.8360 s / batch. (data: 3.50e-04). ETA=12:05:01, max mem: 20.9 GB 
[11/25 15:03:19][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 1.49e-01, avg batch time: 0.9819, average train loss: 21.8691
[11/25 15:04:14][INFO] visual_prompt:  316: Inference (val):avg data time: 2.13e-04, avg batch time: 0.3108, average loss: 2.3365
[11/25 15:04:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.85	
[11/25 15:04:14][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 6.0
[11/25 15:05:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 13.2510,	0.8520 s / batch. (data: 3.35e-04). ETA=12:16:45, max mem: 20.9 GB 
[11/25 15:07:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 23.3658,	0.8440 s / batch. (data: 3.28e-04). ETA=12:08:24, max mem: 20.9 GB 
[11/25 15:09:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 12.4615,	1.7143 s / batch. (data: 8.81e-01). ETA=1 day, 0:36:38, max mem: 20.9 GB 
[11/25 15:10:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.6258,	1.9080 s / batch. (data: 1.08e+00). ETA=1 day, 3:20:17, max mem: 20.9 GB 
[11/25 15:12:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.9146,	0.8404 s / batch. (data: 1.20e-02). ETA=12:01:05, max mem: 20.9 GB 
[11/25 15:13:15][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.44e-01, avg batch time: 0.9777, average train loss: 20.0644
[11/25 15:14:11][INFO] visual_prompt:  316: Inference (val):avg data time: 2.16e-04, avg batch time: 0.3122, average loss: 8.4642
[11/25 15:14:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.60	
[11/25 15:14:11][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 7.0
[11/25 15:15:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 9.8224,	0.8598 s / batch. (data: 1.05e-02). ETA=12:15:33, max mem: 20.9 GB 
[11/25 15:17:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 39.4100,	0.8360 s / batch. (data: 3.30e-04). ETA=11:53:47, max mem: 20.9 GB 
[11/25 15:19:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 13.7431,	0.8257 s / batch. (data: 2.96e-04). ETA=11:43:37, max mem: 20.9 GB 
[11/25 15:20:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 51.2663,	0.8269 s / batch. (data: 1.05e-02). ETA=11:43:16, max mem: 20.9 GB 
[11/25 15:22:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 139.0039,	1.3386 s / batch. (data: 5.07e-01). ETA=18:56:12, max mem: 20.9 GB 
[11/25 15:23:11][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 1.44e-01, avg batch time: 0.9765, average train loss: 25.8392
[11/25 15:24:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3092, average loss: 7.0291
[11/25 15:24:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.43	
[11/25 15:24:06][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 8.0
[11/25 15:25:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8600 s / batch. (data: 3.02e-04). ETA=12:07:44, max mem: 20.9 GB 
[11/25 15:27:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 13.8168,	0.8440 s / batch. (data: 3.14e-04). ETA=11:52:51, max mem: 20.9 GB 
[11/25 15:29:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.5134,	1.6997 s / batch. (data: 8.68e-01). ETA=23:52:42, max mem: 20.9 GB 
[11/25 15:30:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 10.2903,	0.8360 s / batch. (data: 8.13e-04). ETA=11:43:18, max mem: 20.9 GB 
[11/25 15:32:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 21.3491,	0.8221 s / batch. (data: 3.37e-04). ETA=11:30:12, max mem: 20.9 GB 
[11/25 15:33:06][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 1.44e-01, avg batch time: 0.9769, average train loss: 23.0162
[11/25 15:34:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-05, avg batch time: 0.3099, average loss: 42.8388
[11/25 15:34:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.46	
[11/25 15:34:02][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 9.0
[11/25 15:35:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 12.5214,	0.8166 s / batch. (data: 3.06e-04). ETA=11:23:29, max mem: 20.9 GB 
[11/25 15:37:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.6046,	0.8280 s / batch. (data: 3.24e-04). ETA=11:31:41, max mem: 20.9 GB 
[11/25 15:38:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.6750,	2.0432 s / batch. (data: 1.22e+00). ETA=1 day, 4:23:26, max mem: 20.9 GB 
[11/25 15:40:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.2920,	0.8906 s / batch. (data: 5.43e-03). ETA=12:21:01, max mem: 20.9 GB 
[11/25 15:42:12][INFO] visual_prompt:  204: 	Training 500/553. train loss: 19.9925,	0.8320 s / batch. (data: 3.20e-04). ETA=11:30:53, max mem: 20.9 GB 
[11/25 15:43:03][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 1.45e-01, avg batch time: 0.9781, average train loss: 30.4111
[11/25 15:43:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.23e-05, avg batch time: 0.3086, average loss: 0.9898
[11/25 15:43:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.75	
[11/25 15:43:58][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 10.0
[11/25 15:45:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 15.8778,	0.8440 s / batch. (data: 2.88e-04). ETA=11:38:41, max mem: 20.9 GB 
[11/25 15:47:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 24.1415,	0.8393 s / batch. (data: 2.98e-04). ETA=11:33:22, max mem: 20.9 GB 
[11/25 15:48:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	2.0113 s / batch. (data: 1.17e+00). ETA=1 day, 3:38:19, max mem: 20.9 GB 
[11/25 15:50:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 43.0872,	0.8402 s / batch. (data: 5.92e-03). ETA=11:31:20, max mem: 20.9 GB 
[11/25 15:52:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 45.0347,	0.8170 s / batch. (data: 2.67e-04). ETA=11:10:55, max mem: 20.9 GB 
[11/25 15:52:59][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 1.45e-01, avg batch time: 0.9772, average train loss: 34.2581
[11/25 15:53:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3089, average loss: 21.7759
[11/25 15:53:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.63	
[11/25 15:53:54][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/25 15:55:36][INFO] visual_prompt:  204: 	Training 100/553. train loss: 39.2219,	0.8247 s / batch. (data: 2.50e-04). ETA=11:15:08, max mem: 20.9 GB 
[11/25 15:57:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 7.6297,	0.8400 s / batch. (data: 3.13e-04). ETA=11:26:14, max mem: 20.9 GB 
[11/25 15:58:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 12.9869,	0.8386 s / batch. (data: 1.56e-02). ETA=11:23:43, max mem: 20.9 GB 
[11/25 16:00:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 20.0534,	0.8230 s / batch. (data: 3.27e-04). ETA=11:09:37, max mem: 20.9 GB 
[11/25 16:02:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 7.4051,	0.8634 s / batch. (data: 8.34e-04). ETA=11:41:04, max mem: 20.9 GB 
[11/25 16:02:53][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.43e-01, avg batch time: 0.9749, average train loss: 34.2184
[11/25 16:03:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3106, average loss: 33.8616
[11/25 16:03:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.16	
[11/25 16:03:49][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/25 16:05:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 18.5837,	0.8480 s / batch. (data: 3.42e-04). ETA=11:26:22, max mem: 20.9 GB 
[11/25 16:07:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 119.0935,	0.8283 s / batch. (data: 3.22e-04). ETA=11:09:04, max mem: 20.9 GB 
[11/25 16:08:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 21.8950,	1.6888 s / batch. (data: 8.53e-01). ETA=22:41:18, max mem: 20.9 GB 
[11/25 16:10:21][INFO] visual_prompt:  204: 	Training 400/553. train loss: 13.5954,	0.8292 s / batch. (data: 9.15e-03). ETA=11:07:00, max mem: 20.9 GB 
[11/25 16:11:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 20.9357,	0.8771 s / batch. (data: 5.43e-03). ETA=11:44:04, max mem: 20.9 GB 
[11/25 16:12:49][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 1.45e-01, avg batch time: 0.9773, average train loss: 36.6054
[11/25 16:13:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.33e-05, avg batch time: 0.3110, average loss: 12.1257
[11/25 16:13:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.44	
[11/25 16:13:45][INFO] visual_prompt:   36: Best epoch 13: best metric: -12.126
[11/25 16:13:45][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/25 16:15:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.8615,	0.8321 s / batch. (data: 1.57e-02). ETA=11:05:48, max mem: 20.9 GB 
[11/25 16:17:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.4021,	0.8880 s / batch. (data: 5.78e-02). ETA=11:49:05, max mem: 20.9 GB 
[11/25 16:18:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 68.5546,	0.8253 s / batch. (data: 9.25e-03). ETA=10:57:37, max mem: 20.9 GB 
[11/25 16:20:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.1330,	0.8297 s / batch. (data: 5.44e-03). ETA=10:59:46, max mem: 20.9 GB 
[11/25 16:21:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 9.8359,	0.8190 s / batch. (data: 3.02e-04). ETA=10:49:52, max mem: 20.9 GB 
[11/25 16:22:45][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 1.44e-01, avg batch time: 0.9764, average train loss: 32.7403
[11/25 16:23:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3116, average loss: 76.2857
[11/25 16:23:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.90	
[11/25 16:23:40][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/25 16:25:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 58.4551,	0.8282 s / batch. (data: 1.56e-02). ETA=10:55:06, max mem: 20.9 GB 
[11/25 16:26:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 188.4184,	0.8360 s / batch. (data: 2.91e-04). ETA=10:59:51, max mem: 20.9 GB 
[11/25 16:28:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 24.2248,	0.8451 s / batch. (data: 7.01e-04). ETA=11:05:37, max mem: 20.9 GB 
[11/25 16:30:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 5.2649,	1.1640 s / batch. (data: 2.92e-01). ETA=15:14:50, max mem: 20.9 GB 
[11/25 16:31:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 15.9856,	0.8255 s / batch. (data: 3.34e-04). ETA=10:47:26, max mem: 20.9 GB 
[11/25 16:32:39][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.43e-01, avg batch time: 0.9746, average train loss: 36.2378
[11/25 16:33:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3123, average loss: 21.1190
[11/25 16:33:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.29	
[11/25 16:33:34][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/25 16:35:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 136.7389,	0.8357 s / batch. (data: 3.82e-04). ETA=10:53:17, max mem: 20.9 GB 
[11/25 16:36:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 59.3486,	0.8440 s / batch. (data: 2.93e-04). ETA=10:58:22, max mem: 20.9 GB 
[11/25 16:38:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 30.4218,	0.8552 s / batch. (data: 1.05e-02). ETA=11:05:44, max mem: 20.9 GB 
[11/25 16:40:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 17.3393,	0.8272 s / batch. (data: 5.43e-03). ETA=10:42:33, max mem: 20.9 GB 
[11/25 16:41:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 11.4081,	0.8467 s / batch. (data: 1.05e-02). ETA=10:56:15, max mem: 20.9 GB 
[11/25 16:42:32][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 1.39e-01, avg batch time: 0.9717, average train loss: 32.5930
[11/25 16:43:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.3118, average loss: 44.3229
[11/25 16:43:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.94	
[11/25 16:43:27][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/25 16:45:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 55.8716,	0.8320 s / batch. (data: 2.91e-04). ETA=10:42:45, max mem: 20.9 GB 
[11/25 16:46:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 54.9315,	0.8321 s / batch. (data: 2.83e-04). ETA=10:41:25, max mem: 20.9 GB 
[11/25 16:48:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 15.8055,	0.8488 s / batch. (data: 2.40e-02). ETA=10:52:51, max mem: 20.9 GB 
[11/25 16:50:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.8833,	1.0400 s / batch. (data: 1.86e-01). ETA=13:18:14, max mem: 20.9 GB 
[11/25 16:51:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.9224,	1.3881 s / batch. (data: 5.69e-01). ETA=17:43:04, max mem: 20.9 GB 
[11/25 16:52:28][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 1.46e-01, avg batch time: 0.9783, average train loss: 31.9066
[11/25 16:53:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.19e-05, avg batch time: 0.3098, average loss: 22.5387
[11/25 16:53:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.52	
[11/25 16:53:26][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/25 16:55:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 33.3468,	0.8165 s / batch. (data: 6.96e-04). ETA=10:23:16, max mem: 20.9 GB 
[11/25 16:57:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 15.3985,	0.8316 s / batch. (data: 5.90e-03). ETA=10:33:22, max mem: 20.9 GB 
[11/25 16:58:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 36.3336,	0.8670 s / batch. (data: 3.10e-04). ETA=10:58:56, max mem: 20.9 GB 
[11/25 17:00:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 26.4739,	0.8473 s / batch. (data: 1.19e-02). ETA=10:42:29, max mem: 20.9 GB 
[11/25 17:02:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 26.0536,	1.0160 s / batch. (data: 1.81e-01). ETA=12:48:44, max mem: 20.9 GB 
[11/25 17:03:02][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 2.11e-01, avg batch time: 1.0417, average train loss: 32.3624
[11/25 17:03:58][INFO] visual_prompt:  316: Inference (val):avg data time: 6.07e-04, avg batch time: 0.3083, average loss: 28.3415
[11/25 17:03:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.76	
[11/25 17:03:58][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/25 17:05:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 73.0952,	0.8222 s / batch. (data: 3.24e-04). ETA=10:20:03, max mem: 20.9 GB 
[11/25 17:07:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 18.0639,	0.8211 s / batch. (data: 2.96e-04). ETA=10:17:50, max mem: 20.9 GB 
[11/25 17:08:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0051,	0.8587 s / batch. (data: 3.50e-02). ETA=10:44:41, max mem: 20.9 GB 
[11/25 17:10:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 8.9777,	0.8344 s / batch. (data: 2.99e-04). ETA=10:25:02, max mem: 20.9 GB 
[11/25 17:12:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 29.4289,	0.8239 s / batch. (data: 5.42e-03). ETA=10:15:48, max mem: 20.9 GB 
[11/25 17:12:57][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.42e-01, avg batch time: 0.9741, average train loss: 37.7777
[11/25 17:13:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.09e-05, avg batch time: 0.3114, average loss: 163.5188
[11/25 17:13:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.06	
[11/25 17:13:52][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/25 17:15:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 11.4015,	0.8480 s / batch. (data: 7.95e-03). ETA=10:31:38, max mem: 20.9 GB 
[11/25 17:17:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 34.3164,	0.8078 s / batch. (data: 3.31e-04). ETA=10:00:21, max mem: 20.9 GB 
[11/25 17:18:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 34.0807,	0.8440 s / batch. (data: 2.98e-04). ETA=10:25:51, max mem: 20.9 GB 
[11/25 17:20:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3187,	0.8286 s / batch. (data: 3.39e-04). ETA=10:13:03, max mem: 20.9 GB 
[11/25 17:22:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 16.2321,	0.8360 s / batch. (data: 3.07e-04). ETA=10:17:07, max mem: 20.9 GB 
[11/25 17:22:54][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 1.47e-01, avg batch time: 0.9792, average train loss: 33.0191
[11/25 17:23:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.19e-05, avg batch time: 0.3099, average loss: 21.6157
[11/25 17:23:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.95	
[11/25 17:23:49][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/25 17:25:34][INFO] visual_prompt:  204: 	Training 100/553. train loss: 13.6234,	0.8154 s / batch. (data: 2.68e-04). ETA=9:59:51, max mem: 20.9 GB 
[11/25 17:27:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 70.9600,	0.8208 s / batch. (data: 5.44e-03). ETA=10:02:28, max mem: 20.9 GB 
[11/25 17:28:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 131.5904,	1.0255 s / batch. (data: 2.01e-01). ETA=12:31:00, max mem: 20.9 GB 
[11/25 17:30:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.7542,	0.8202 s / batch. (data: 3.04e-04). ETA=9:59:17, max mem: 20.9 GB 
[11/25 17:32:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.1656,	0.8318 s / batch. (data: 5.42e-03). ETA=10:06:22, max mem: 20.9 GB 
[11/25 17:32:51][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 1.47e-01, avg batch time: 0.9786, average train loss: 32.3908
[11/25 17:33:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.23e-05, avg batch time: 0.3088, average loss: 59.2093
[11/25 17:33:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/25 17:33:46][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/25 17:35:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 74.4270,	0.8520 s / batch. (data: 3.06e-04). ETA=10:18:55, max mem: 20.9 GB 
[11/25 17:37:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.8805,	0.8381 s / batch. (data: 1.05e-02). ETA=10:07:26, max mem: 20.9 GB 
[11/25 17:38:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8292 s / batch. (data: 3.17e-04). ETA=9:59:38, max mem: 20.9 GB 
[11/25 17:40:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 60.2997,	0.8359 s / batch. (data: 3.05e-04). ETA=10:03:04, max mem: 20.9 GB 
[11/25 17:41:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 14.4501,	0.8552 s / batch. (data: 3.21e-04). ETA=10:15:33, max mem: 20.9 GB 
[11/25 17:42:46][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 1.45e-01, avg batch time: 0.9776, average train loss: 31.3885
[11/25 17:43:42][INFO] visual_prompt:  316: Inference (val):avg data time: 3.15e-05, avg batch time: 0.3129, average loss: 37.5095
[11/25 17:43:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.10	
[11/25 17:43:42][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/25 17:45:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 14.7998,	0.8294 s / batch. (data: 5.44e-03). ETA=9:54:51, max mem: 20.9 GB 
[11/25 17:47:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 26.9610,	0.8508 s / batch. (data: 1.56e-02). ETA=10:08:46, max mem: 20.9 GB 
[11/25 17:48:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 38.7181,	0.8594 s / batch. (data: 5.84e-03). ETA=10:13:31, max mem: 20.9 GB 
[11/25 17:50:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 20.7494,	0.8440 s / batch. (data: 7.62e-04). ETA=10:01:08, max mem: 20.9 GB 
[11/25 17:51:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.8258,	0.8238 s / batch. (data: 2.85e-04). ETA=9:45:24, max mem: 20.9 GB 
[11/25 17:52:44][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 1.48e-01, avg batch time: 0.9794, average train loss: 30.7184
[11/25 17:53:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3097, average loss: 31.7203
[11/25 17:53:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.50	
[11/25 17:53:39][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/25 17:55:18][INFO] visual_prompt:  204: 	Training 100/553. train loss: 21.1932,	0.8440 s / batch. (data: 3.01e-04). ETA=9:57:33, max mem: 20.9 GB 
[11/25 17:56:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.5434,	0.8320 s / batch. (data: 3.00e-04). ETA=9:47:41, max mem: 20.9 GB 
[11/25 17:58:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.0614,	0.8667 s / batch. (data: 3.14e-02). ETA=10:10:45, max mem: 20.9 GB 
[11/25 18:00:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 27.5653,	0.8669 s / batch. (data: 1.05e-02). ETA=10:09:25, max mem: 20.9 GB 
[11/25 18:01:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 37.7972,	0.8369 s / batch. (data: 1.05e-02). ETA=9:46:57, max mem: 20.9 GB 
[11/25 18:02:41][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 1.47e-01, avg batch time: 0.9795, average train loss: 29.8137
[11/25 18:03:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.28e-05, avg batch time: 0.3111, average loss: 7.4391
[11/25 18:03:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.25	
[11/25 18:03:36][INFO] visual_prompt:   36: Best epoch 24: best metric: -7.439
[11/25 18:03:36][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/25 18:05:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 53.5473,	0.8290 s / batch. (data: 3.08e-04). ETA=9:39:18, max mem: 20.9 GB 
[11/25 18:06:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 11.9055,	0.8443 s / batch. (data: 1.05e-02). ETA=9:48:35, max mem: 20.9 GB 
[11/25 18:08:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.0566,	0.8629 s / batch. (data: 3.29e-04). ETA=10:00:08, max mem: 20.9 GB 
[11/25 18:10:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.4415,	1.2073 s / batch. (data: 3.72e-01). ETA=13:57:36, max mem: 20.9 GB 
[11/25 18:11:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 11.4700,	1.2607 s / batch. (data: 4.31e-01). ETA=14:32:33, max mem: 20.9 GB 
[11/25 18:12:40][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 1.51e-01, avg batch time: 0.9831, average train loss: 32.5727
[11/25 18:13:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.17e-05, avg batch time: 0.3105, average loss: 24.6369
[11/25 18:13:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.47	
[11/25 18:13:36][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/25 18:15:18][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.8801,	0.8516 s / batch. (data: 5.56e-03). ETA=9:47:16, max mem: 20.9 GB 
[11/25 18:16:57][INFO] visual_prompt:  204: 	Training 200/553. train loss: 21.5737,	1.7960 s / batch. (data: 9.90e-01). ETA=20:35:31, max mem: 20.9 GB 
[11/25 18:18:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 17.6660,	0.8480 s / batch. (data: 2.73e-04). ETA=9:41:57, max mem: 20.9 GB 
[11/25 18:20:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 17.7804,	0.8395 s / batch. (data: 7.40e-03). ETA=9:34:41, max mem: 20.9 GB 
[11/25 18:21:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 55.5703,	0.8361 s / batch. (data: 7.97e-03). ETA=9:31:00, max mem: 20.9 GB 
[11/25 18:22:40][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 1.52e-01, avg batch time: 0.9845, average train loss: 29.8481
[11/25 18:23:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3093, average loss: 8.4448
[11/25 18:23:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.15	
[11/25 18:23:36][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/25 18:25:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 73.5949,	0.8565 s / batch. (data: 2.44e-02). ETA=9:42:42, max mem: 20.9 GB 
[11/25 18:26:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 44.7822,	0.9610 s / batch. (data: 1.34e-01). ETA=10:52:12, max mem: 20.9 GB 
[11/25 18:28:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 13.6333,	0.8552 s / batch. (data: 2.11e-02). ETA=9:39:00, max mem: 20.9 GB 
[11/25 18:30:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 92.7445,	0.8328 s / batch. (data: 7.23e-04). ETA=9:22:28, max mem: 20.9 GB 
[11/25 18:31:44][INFO] visual_prompt:  204: 	Training 500/553. train loss: 17.2910,	0.8594 s / batch. (data: 1.45e-02). ETA=9:38:57, max mem: 20.9 GB 
[11/25 18:32:33][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 1.40e-01, avg batch time: 0.9720, average train loss: 31.4765
[11/25 18:33:29][INFO] visual_prompt:  316: Inference (val):avg data time: 1.28e-04, avg batch time: 0.3108, average loss: 15.9482
[11/25 18:33:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.11	
[11/25 18:33:29][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/25 18:35:09][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8370 s / batch. (data: 3.18e-04). ETA=9:21:45, max mem: 20.9 GB 
[11/25 18:36:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 32.3063,	0.8379 s / batch. (data: 1.60e-02). ETA=9:20:55, max mem: 20.9 GB 
[11/25 18:38:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 14.7498,	1.5160 s / batch. (data: 6.99e-01). ETA=16:52:25, max mem: 20.9 GB 
[11/25 18:40:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 76.6420,	0.8600 s / batch. (data: 1.20e-02). ETA=9:32:53, max mem: 20.9 GB 
[11/25 18:41:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 21.1955,	0.8680 s / batch. (data: 3.15e-04). ETA=9:36:45, max mem: 20.9 GB 
[11/25 18:42:29][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.44e-01, avg batch time: 0.9766, average train loss: 31.9558
[11/25 18:43:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.16e-05, avg batch time: 0.3115, average loss: 46.2851
[11/25 18:43:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.27	
[11/25 18:43:25][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/25 18:45:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 59.1458,	0.8312 s / batch. (data: 2.86e-04). ETA=9:10:10, max mem: 20.9 GB 
[11/25 18:46:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 37.0747,	1.8074 s / batch. (data: 9.56e-01). ETA=19:53:23, max mem: 20.9 GB 
[11/25 18:48:25][INFO] visual_prompt:  204: 	Training 300/553. train loss: 23.9400,	0.8431 s / batch. (data: 1.16e-02). ETA=9:15:15, max mem: 20.9 GB 
[11/25 18:49:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.1341,	0.8437 s / batch. (data: 5.47e-03). ETA=9:14:16, max mem: 20.9 GB 
[11/25 18:51:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 5.2619,	0.8371 s / batch. (data: 3.24e-04). ETA=9:08:32, max mem: 20.9 GB 
[11/25 18:52:27][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 1.48e-01, avg batch time: 0.9799, average train loss: 37.2370
[11/25 18:53:22][INFO] visual_prompt:  316: Inference (val):avg data time: 1.76e-04, avg batch time: 0.3095, average loss: 36.1800
[11/25 18:53:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.64	
[11/25 18:53:22][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/25 18:55:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 57.3054,	0.8231 s / batch. (data: 1.05e-02). ETA=8:57:14, max mem: 20.9 GB 
[11/25 18:56:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 20.0120,	0.8280 s / batch. (data: 4.86e-04). ETA=8:59:02, max mem: 20.9 GB 
[11/25 18:58:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 58.9110,	1.8745 s / batch. (data: 1.04e+00). ETA=20:17:17, max mem: 20.9 GB 
[11/25 18:59:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 32.9440,	1.0800 s / batch. (data: 2.37e-01). ETA=11:39:33, max mem: 20.9 GB 
[11/25 19:01:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 113.4729,	1.4240 s / batch. (data: 5.94e-01). ETA=15:19:57, max mem: 20.9 GB 
[11/25 19:02:25][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 1.49e-01, avg batch time: 0.9808, average train loss: 28.7434
[11/25 19:03:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.3094, average loss: 22.9904
[11/25 19:03:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.86	
[11/25 19:03:20][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/25 19:05:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 23.2558,	0.8400 s / batch. (data: 3.09e-04). ETA=9:00:32, max mem: 20.9 GB 
[11/25 19:06:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 109.4730,	0.8120 s / batch. (data: 2.99e-04). ETA=8:41:11, max mem: 20.9 GB 
[11/25 19:08:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 45.3426,	0.8280 s / batch. (data: 3.16e-04). ETA=8:50:03, max mem: 20.9 GB 
[11/25 19:09:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 52.4664,	0.8515 s / batch. (data: 5.41e-03). ETA=9:03:41, max mem: 20.9 GB 
[11/25 19:11:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 31.6548,	0.8437 s / batch. (data: 4.08e-03). ETA=8:57:18, max mem: 20.9 GB 
[11/25 19:12:21][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 1.45e-01, avg batch time: 0.9777, average train loss: 26.0752
[11/25 19:13:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.51e-05, avg batch time: 0.3111, average loss: 31.8197
[11/25 19:13:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.21	
[11/25 19:13:16][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/25 19:14:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 25.7262,	0.8360 s / batch. (data: 3.02e-04). ETA=8:50:17, max mem: 20.9 GB 
[11/25 19:16:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 15.7171,	0.8366 s / batch. (data: 8.18e-04). ETA=8:49:14, max mem: 20.9 GB 
[11/25 19:18:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 92.0406,	0.8238 s / batch. (data: 2.73e-04). ETA=8:39:45, max mem: 20.9 GB 
[11/25 19:19:54][INFO] visual_prompt:  204: 	Training 400/553. train loss: 13.8397,	0.8185 s / batch. (data: 3.45e-04). ETA=8:35:03, max mem: 20.9 GB 
[11/25 19:21:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 23.7470,	0.8307 s / batch. (data: 5.41e-03). ETA=8:41:21, max mem: 20.9 GB 
[11/25 19:22:18][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 1.48e-01, avg batch time: 0.9799, average train loss: 30.6038
[11/25 19:23:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.29e-05, avg batch time: 0.3095, average loss: 15.6869
[11/25 19:23:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.55	
[11/25 19:23:14][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/25 19:24:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 30.3722,	1.4107 s / batch. (data: 5.79e-01). ETA=14:41:48, max mem: 20.9 GB 
[11/25 19:26:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 36.4146,	1.3277 s / batch. (data: 5.20e-01). ETA=13:47:41, max mem: 20.9 GB 
[11/25 19:28:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 26.4358,	0.8309 s / batch. (data: 5.42e-03). ETA=8:36:34, max mem: 20.9 GB 
[11/25 19:29:52][INFO] visual_prompt:  204: 	Training 400/553. train loss: 7.8397,	0.8400 s / batch. (data: 4.08e-04). ETA=8:40:50, max mem: 20.9 GB 
[11/25 19:31:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 13.7290,	0.8320 s / batch. (data: 3.21e-04). ETA=8:34:29, max mem: 20.9 GB 
[11/25 19:32:21][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 1.59e-01, avg batch time: 0.9901, average train loss: 29.5350
[11/25 19:33:18][INFO] visual_prompt:  316: Inference (val):avg data time: 1.64e-04, avg batch time: 0.3133, average loss: 87.5976
[11/25 19:33:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.27	
[11/25 19:33:18][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/25 19:35:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 15.7223,	0.8177 s / batch. (data: 3.57e-04). ETA=8:23:33, max mem: 20.9 GB 
[11/25 19:36:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 19.8765,	0.8320 s / batch. (data: 3.19e-04). ETA=8:31:01, max mem: 20.9 GB 
[11/25 19:38:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 59.4217,	0.8206 s / batch. (data: 7.96e-03). ETA=8:22:39, max mem: 20.9 GB 
[11/25 19:39:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 37.4711,	0.8466 s / batch. (data: 3.08e-04). ETA=8:37:10, max mem: 20.9 GB 
[11/25 19:41:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 44.6877,	1.4380 s / batch. (data: 6.33e-01). ETA=14:36:02, max mem: 20.9 GB 
[11/25 19:42:20][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 1.48e-01, avg batch time: 0.9800, average train loss: 30.3251
[11/25 19:43:15][INFO] visual_prompt:  316: Inference (val):avg data time: 2.79e-04, avg batch time: 0.3113, average loss: 19.5082
[11/25 19:43:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.82	
[11/25 19:43:15][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/25 19:44:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 28.2258,	0.8178 s / batch. (data: 4.75e-04). ETA=8:16:05, max mem: 20.9 GB 
[11/25 19:46:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 40.1643,	0.8440 s / batch. (data: 3.41e-04). ETA=8:30:34, max mem: 20.9 GB 
[11/25 19:48:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 20.8998,	0.8206 s / batch. (data: 3.15e-04). ETA=8:15:04, max mem: 20.9 GB 
[11/25 19:49:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 16.4035,	0.8201 s / batch. (data: 2.98e-04). ETA=8:13:24, max mem: 20.9 GB 
[11/25 19:51:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 92.4864,	1.0732 s / batch. (data: 2.47e-01). ETA=10:43:52, max mem: 20.9 GB 
[11/25 19:52:17][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 1.47e-01, avg batch time: 0.9788, average train loss: 32.1592
[11/25 19:53:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.36e-05, avg batch time: 0.3103, average loss: 29.1534
[11/25 19:53:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.99	
[11/25 19:53:12][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/25 19:54:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 5.5278,	0.8284 s / batch. (data: 1.20e-02). ETA=8:14:53, max mem: 20.9 GB 
[11/25 19:56:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 61.8225,	0.8395 s / batch. (data: 1.56e-02). ETA=8:20:08, max mem: 20.9 GB 
[11/25 19:58:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8394 s / batch. (data: 7.40e-03). ETA=8:18:42, max mem: 20.9 GB 
[11/25 19:59:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 26.8228,	0.8399 s / batch. (data: 3.14e-04). ETA=8:17:35, max mem: 20.9 GB 
[11/25 20:01:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 8.0681,	0.9135 s / batch. (data: 5.65e-02). ETA=8:59:38, max mem: 20.9 GB 
[11/25 20:02:12][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 1.43e-01, avg batch time: 0.9755, average train loss: 27.7423
[11/25 20:03:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.36e-05, avg batch time: 0.3111, average loss: 88.0162
[11/25 20:03:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.70	
[11/25 20:03:07][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/25 20:04:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 7.0561,	0.8175 s / batch. (data: 3.32e-04). ETA=8:00:52, max mem: 20.9 GB 
[11/25 20:06:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 14.3619,	0.8360 s / batch. (data: 3.18e-04). ETA=8:10:20, max mem: 20.9 GB 
[11/25 20:08:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 26.8646,	1.3281 s / batch. (data: 4.95e-01). ETA=12:56:44, max mem: 20.9 GB 
[11/25 20:09:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 46.8616,	1.8938 s / batch. (data: 1.07e+00). ETA=18:24:26, max mem: 20.9 GB 
[11/25 20:11:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 29.4414,	0.9584 s / batch. (data: 1.21e-01). ETA=9:17:19, max mem: 20.9 GB 
[11/25 20:12:08][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 1.45e-01, avg batch time: 0.9778, average train loss: 24.0381
[11/25 20:13:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.04e-05, avg batch time: 0.3103, average loss: 10.0697
[11/25 20:13:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.56	
[11/25 20:13:03][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/25 20:14:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 12.8534,	0.8432 s / batch. (data: 5.44e-03). ETA=8:08:10, max mem: 20.9 GB 
[11/25 20:16:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 10.3631,	1.3982 s / batch. (data: 5.78e-01). ETA=13:27:12, max mem: 20.9 GB 
[11/25 20:18:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 28.5636,	0.8127 s / batch. (data: 2.98e-04). ETA=7:47:49, max mem: 20.9 GB 
[11/25 20:19:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0000,	0.8360 s / batch. (data: 3.13e-04). ETA=7:59:51, max mem: 20.9 GB 
[11/25 20:21:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.4356,	0.8336 s / batch. (data: 3.34e-04). ETA=7:57:04, max mem: 20.9 GB 
[11/25 20:22:04][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 1.46e-01, avg batch time: 0.9781, average train loss: 25.6685
[11/25 20:23:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.20e-05, avg batch time: 0.3110, average loss: 5.1620
[11/25 20:23:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 53.38	
[11/25 20:23:00][INFO] visual_prompt:   36: Best epoch 38: best metric: -5.162
[11/25 20:23:00][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/25 20:24:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8480 s / batch. (data: 3.11e-04). ETA=8:03:09, max mem: 20.9 GB 
[11/25 20:26:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 40.6512,	0.8240 s / batch. (data: 3.06e-04). ETA=7:48:08, max mem: 20.9 GB 
[11/25 20:28:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 23.4809,	0.8280 s / batch. (data: 2.78e-04). ETA=7:49:01, max mem: 20.9 GB 
[11/25 20:29:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3322,	0.8270 s / batch. (data: 3.27e-04). ETA=7:47:05, max mem: 20.9 GB 
[11/25 20:31:13][INFO] visual_prompt:  204: 	Training 500/553. train loss: 21.3553,	1.6247 s / batch. (data: 7.81e-01). ETA=15:14:50, max mem: 20.9 GB 
[11/25 20:32:01][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 1.46e-01, avg batch time: 0.9789, average train loss: 22.3797
[11/25 20:32:56][INFO] visual_prompt:  316: Inference (val):avg data time: 1.65e-04, avg batch time: 0.3103, average loss: 9.7386
[11/25 20:32:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.07	
[11/25 20:32:56][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/25 20:34:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 39.0284,	0.8264 s / batch. (data: 2.98e-04). ETA=7:43:15, max mem: 20.9 GB 
[11/25 20:36:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 44.7136,	0.8470 s / batch. (data: 1.05e-02). ETA=7:53:24, max mem: 20.9 GB 
[11/25 20:37:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.4765,	0.8563 s / batch. (data: 1.60e-02). ETA=7:57:09, max mem: 20.9 GB 
[11/25 20:39:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 12.7666,	0.8334 s / batch. (data: 3.02e-04). ETA=7:43:00, max mem: 20.9 GB 
[11/25 20:41:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0000,	0.8182 s / batch. (data: 3.01e-04). ETA=7:33:12, max mem: 20.9 GB 
[11/25 20:42:00][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 1.50e-01, avg batch time: 0.9822, average train loss: 26.6628
[11/25 20:42:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.41e-05, avg batch time: 0.3104, average loss: 21.7155
[11/25 20:42:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 39.32	
[11/25 20:42:56][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 7.5
[11/25 20:44:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 26.5522,	0.8399 s / batch. (data: 5.25e-04). ETA=7:43:03, max mem: 20.9 GB 
[11/25 20:46:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 25.0975,	0.8343 s / batch. (data: 1.60e-02). ETA=7:38:33, max mem: 20.9 GB 
[11/25 20:48:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 8.7110,	0.8389 s / batch. (data: 3.16e-04). ETA=7:39:41, max mem: 20.9 GB 
[11/25 20:49:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 24.0848,	0.8196 s / batch. (data: 2.99e-04). ETA=7:27:47, max mem: 20.9 GB 
[11/25 20:51:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.9224,	0.8498 s / batch. (data: 1.12e-03). ETA=7:42:52, max mem: 20.9 GB 
[11/25 20:52:09][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 1.68e-01, avg batch time: 0.9997, average train loss: 26.3409
[11/25 20:53:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.3092, average loss: 32.4843
[11/25 20:53:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.24	
[11/25 20:53:05][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/25 20:54:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 15.6477,	0.8328 s / batch. (data: 5.42e-03). ETA=7:31:28, max mem: 20.9 GB 
[11/25 20:56:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 18.8049,	0.8323 s / batch. (data: 5.44e-03). ETA=7:29:47, max mem: 20.9 GB 
[11/25 20:58:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.5058,	0.8440 s / batch. (data: 3.10e-04). ETA=7:34:44, max mem: 20.9 GB 
[11/25 20:59:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 17.2064,	0.8598 s / batch. (data: 1.98e-02). ETA=7:41:48, max mem: 20.9 GB 
[11/25 21:01:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 91.9209,	0.8320 s / batch. (data: 7.95e-03). ETA=7:25:29, max mem: 20.9 GB 
[11/25 21:02:06][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 1.46e-01, avg batch time: 0.9785, average train loss: 24.4209
[11/25 21:03:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3107, average loss: 36.9176
[11/25 21:03:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.04	
[11/25 21:03:02][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/25 21:04:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 7.3888,	0.8246 s / batch. (data: 8.58e-03). ETA=7:19:25, max mem: 20.9 GB 
[11/25 21:06:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 115.5747,	0.8251 s / batch. (data: 3.29e-04). ETA=7:18:19, max mem: 20.9 GB 
[11/25 21:07:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 42.1443,	0.8374 s / batch. (data: 7.95e-03). ETA=7:23:26, max mem: 20.9 GB 
[11/25 21:09:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 59.4686,	0.8480 s / batch. (data: 7.95e-03). ETA=7:27:39, max mem: 20.9 GB 
[11/25 21:11:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 38.3393,	0.8320 s / batch. (data: 3.26e-04). ETA=7:17:49, max mem: 20.9 GB 
[11/25 21:12:04][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 1.48e-01, avg batch time: 0.9803, average train loss: 26.1458
[11/25 21:13:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.3100, average loss: 18.0466
[11/25 21:13:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.67	
[11/25 21:13:00][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/25 21:14:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 41.6996,	1.3181 s / batch. (data: 4.89e-01). ETA=11:30:15, max mem: 20.9 GB 
[11/25 21:16:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 24.9968,	0.8227 s / batch. (data: 3.00e-04). ETA=7:09:26, max mem: 20.9 GB 
[11/25 21:17:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 40.6746,	0.8240 s / batch. (data: 3.18e-04). ETA=7:08:44, max mem: 20.9 GB 
[11/25 21:19:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 50.0597,	0.8699 s / batch. (data: 1.56e-02). ETA=7:31:12, max mem: 20.9 GB 
[11/25 21:21:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 11.9130,	0.8212 s / batch. (data: 3.24e-04). ETA=7:04:34, max mem: 20.9 GB 
[11/25 21:21:59][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 1.42e-01, avg batch time: 0.9748, average train loss: 26.5415
[11/25 21:22:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.14e-05, avg batch time: 0.3099, average loss: 106.2100
[11/25 21:22:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.68	
[11/25 21:22:54][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/25 21:24:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 18.1458,	0.8554 s / batch. (data: 2.02e-02). ETA=7:20:05, max mem: 20.9 GB 
[11/25 21:26:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2040,	1.2249 s / batch. (data: 3.99e-01). ETA=10:28:08, max mem: 20.9 GB 
[11/25 21:27:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 35.3088,	0.8341 s / batch. (data: 8.24e-04). ETA=7:06:20, max mem: 20.9 GB 
[11/25 21:29:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 11.2677,	0.8382 s / batch. (data: 1.20e-02). ETA=7:07:01, max mem: 20.9 GB 
[11/25 21:31:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 35.0762,	0.8322 s / batch. (data: 5.44e-03). ETA=7:02:35, max mem: 20.9 GB 
[11/25 21:31:56][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 1.46e-01, avg batch time: 0.9787, average train loss: 21.2374
[11/25 21:32:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.23e-05, avg batch time: 0.3115, average loss: 8.9792
[11/25 21:32:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.90	
[11/25 21:32:51][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/25 21:34:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5297,	1.1732 s / batch. (data: 3.26e-01). ETA=9:52:47, max mem: 20.9 GB 
[11/25 21:36:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.9668,	0.8375 s / batch. (data: 7.79e-04). ETA=7:01:43, max mem: 20.9 GB 
[11/25 21:37:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 76.9602,	0.8520 s / batch. (data: 5.47e-03). ETA=7:07:37, max mem: 20.9 GB 
[11/25 21:39:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 27.3665,	0.8468 s / batch. (data: 7.76e-04). ETA=7:03:36, max mem: 20.9 GB 
[11/25 21:40:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6555,	0.8285 s / batch. (data: 2.86e-04). ETA=6:53:03, max mem: 20.9 GB 
[11/25 21:41:51][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 1.44e-01, avg batch time: 0.9759, average train loss: 24.1686
[11/25 21:42:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3112, average loss: 13.5975
[11/25 21:42:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.89	
[11/25 21:42:45][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 6.545084971874737
[11/25 21:44:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 10.5285,	0.8400 s / batch. (data: 4.10e-04). ETA=6:56:38, max mem: 20.9 GB 
[11/25 21:46:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 78.0075,	1.2420 s / batch. (data: 4.28e-01). ETA=10:13:58, max mem: 20.9 GB 
[11/25 21:47:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.8748,	0.8179 s / batch. (data: 3.35e-04). ETA=6:42:58, max mem: 20.9 GB 
[11/25 21:49:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 41.5618,	0.8148 s / batch. (data: 3.11e-04). ETA=6:40:05, max mem: 20.9 GB 
[11/25 21:50:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 12.8149,	0.8476 s / batch. (data: 3.29e-04). ETA=6:54:45, max mem: 20.9 GB 
[11/25 21:51:46][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 1.44e-01, avg batch time: 0.9769, average train loss: 22.0154
[11/25 21:52:41][INFO] visual_prompt:  316: Inference (val):avg data time: 4.83e-05, avg batch time: 0.3092, average loss: 19.2693
[11/25 21:52:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.64	
[11/25 21:52:41][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 6.378186779084995
[11/25 21:54:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 67.7261,	0.8496 s / batch. (data: 2.06e-02). ETA=6:53:37, max mem: 20.9 GB 
[11/25 21:56:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.7868,	0.8244 s / batch. (data: 3.32e-04). ETA=6:39:56, max mem: 20.9 GB 
[11/25 21:57:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6299,	1.5837 s / batch. (data: 7.52e-01). ETA=12:45:42, max mem: 20.9 GB 
[11/25 21:59:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0083,	0.8280 s / batch. (data: 3.18e-04). ETA=6:38:56, max mem: 20.9 GB 
[11/25 22:00:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 20.4112,	0.8260 s / batch. (data: 5.46e-03). ETA=6:36:35, max mem: 20.9 GB 
[11/25 22:01:40][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 1.41e-01, avg batch time: 0.9743, average train loss: 20.5710
[11/25 22:02:35][INFO] visual_prompt:  316: Inference (val):avg data time: 4.71e-04, avg batch time: 0.3106, average loss: 63.7910
[11/25 22:02:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.25	
[11/25 22:02:35][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 6.209609477998338
[11/25 22:04:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0000,	0.8207 s / batch. (data: 3.07e-04). ETA=6:31:58, max mem: 20.9 GB 
[11/25 22:05:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 20.9715,	0.8280 s / batch. (data: 2.95e-04). ETA=6:34:04, max mem: 20.9 GB 
[11/25 22:07:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8362 s / batch. (data: 3.29e-04). ETA=6:36:34, max mem: 20.9 GB 
[11/25 22:09:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.9353,	0.8531 s / batch. (data: 1.30e-02). ETA=6:43:09, max mem: 20.9 GB 
[11/25 22:10:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 14.3700,	0.8174 s / batch. (data: 2.64e-04). ETA=6:24:57, max mem: 20.9 GB 
[11/25 22:11:37][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 1.46e-01, avg batch time: 0.9788, average train loss: 21.5894
[11/25 22:12:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-05, avg batch time: 0.3095, average loss: 18.1432
[11/25 22:12:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/25 22:12:32][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 6.039558454088796
[11/25 22:14:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 13.4888,	0.8278 s / batch. (data: 2.87e-04). ETA=6:27:44, max mem: 20.9 GB 
[11/25 22:15:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 18.3344,	0.8311 s / batch. (data: 3.28e-04). ETA=6:27:52, max mem: 20.9 GB 
[11/25 22:17:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 32.4627,	0.8239 s / batch. (data: 3.19e-04). ETA=6:23:09, max mem: 20.9 GB 
[11/25 22:19:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0000,	0.8280 s / batch. (data: 7.95e-03). ETA=6:23:41, max mem: 20.9 GB 
[11/25 22:20:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 30.3753,	0.8520 s / batch. (data: 3.14e-04). ETA=6:33:23, max mem: 20.9 GB 
[11/25 22:21:32][INFO] visual_prompt:  217: Epoch 50 / 100: avg data time: 1.44e-01, avg batch time: 0.9762, average train loss: 20.2678
[11/25 22:22:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3109, average loss: 19.8499
[11/25 22:22:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[11/25 22:22:27][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 5.868240888334652
[11/25 22:24:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 18.9532,	1.0145 s / batch. (data: 1.64e-01). ETA=7:45:50, max mem: 20.9 GB 
[11/25 22:25:45][INFO] visual_prompt:  204: 	Training 200/553. train loss: 28.8640,	0.8203 s / batch. (data: 3.32e-04). ETA=6:15:17, max mem: 20.9 GB 
[11/25 22:27:23][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.2775,	0.8280 s / batch. (data: 3.25e-04). ETA=6:17:26, max mem: 20.9 GB 
[11/25 22:29:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.9341,	1.2972 s / batch. (data: 4.73e-01). ETA=9:49:07, max mem: 20.9 GB 
[11/25 22:30:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 17.1177,	0.8199 s / batch. (data: 2.68e-04). ETA=6:11:00, max mem: 20.9 GB 
[11/25 22:31:27][INFO] visual_prompt:  217: Epoch 51 / 100: avg data time: 1.44e-01, avg batch time: 0.9768, average train loss: 19.0705
[11/25 22:32:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3093, average loss: 5.8342
[11/25 22:32:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.24	
[11/25 22:32:22][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 5.695865504800327
[11/25 22:34:07][INFO] visual_prompt:  204: 	Training 100/553. train loss: 12.4204,	0.8361 s / batch. (data: 5.93e-03). ETA=6:16:11, max mem: 20.9 GB 
[11/25 22:35:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 8.5228,	0.8480 s / batch. (data: 2.93e-04). ETA=6:20:08, max mem: 20.9 GB 
[11/25 22:37:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 41.9723,	0.8276 s / batch. (data: 3.14e-04). ETA=6:09:36, max mem: 20.9 GB 
[11/25 22:38:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 88.8701,	0.8520 s / batch. (data: 7.95e-03). ETA=6:19:05, max mem: 20.9 GB 
[11/25 22:40:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.0000,	0.8366 s / batch. (data: 5.49e-03). ETA=6:10:50, max mem: 20.9 GB 
[11/25 22:41:20][INFO] visual_prompt:  217: Epoch 52 / 100: avg data time: 1.38e-01, avg batch time: 0.9714, average train loss: 21.3370
[11/25 22:42:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.14e-05, avg batch time: 0.3091, average loss: 3.1040
[11/25 22:42:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.22	
[11/25 22:42:15][INFO] visual_prompt:   36: Best epoch 52: best metric: -3.104
[11/25 22:42:15][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 5.522642316338268
[11/25 22:43:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 34.9381,	0.8234 s / batch. (data: 2.73e-04). ETA=6:02:52, max mem: 20.9 GB 
[11/25 22:45:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 59.1264,	0.8534 s / batch. (data: 7.70e-04). ETA=6:14:42, max mem: 20.9 GB 
[11/25 22:47:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 30.7643,	0.8520 s / batch. (data: 7.73e-04). ETA=6:12:39, max mem: 20.9 GB 
[11/25 22:48:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 6.2285,	0.8633 s / batch. (data: 2.13e-02). ETA=6:16:10, max mem: 20.9 GB 
[11/25 22:50:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 28.4080,	0.8197 s / batch. (data: 3.02e-04). ETA=5:55:47, max mem: 20.9 GB 
[11/25 22:51:18][INFO] visual_prompt:  217: Epoch 53 / 100: avg data time: 1.49e-01, avg batch time: 0.9818, average train loss: 19.9654
[11/25 22:52:13][INFO] visual_prompt:  316: Inference (val):avg data time: 1.34e-04, avg batch time: 0.3108, average loss: 10.2193
[11/25 22:52:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.50	
[11/25 22:52:13][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[11/25 22:53:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3219,	0.8280 s / batch. (data: 3.06e-04). ETA=5:57:17, max mem: 20.9 GB 
[11/25 22:55:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.3546,	0.8556 s / batch. (data: 5.43e-03). ETA=6:07:46, max mem: 20.9 GB 
[11/25 22:57:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 41.7299,	0.8196 s / batch. (data: 3.23e-04). ETA=5:50:55, max mem: 20.9 GB 
[11/25 22:58:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 34.6027,	0.8356 s / batch. (data: 1.05e-02). ETA=5:56:24, max mem: 20.9 GB 
[11/25 23:00:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 15.0122,	0.8326 s / batch. (data: 3.30e-04). ETA=5:53:44, max mem: 20.9 GB 
[11/25 23:01:14][INFO] visual_prompt:  217: Epoch 54 / 100: avg data time: 1.45e-01, avg batch time: 0.9788, average train loss: 20.5318
[11/25 23:02:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-05, avg batch time: 0.3120, average loss: 55.9242
[11/25 23:02:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.39	
[11/25 23:02:10][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 5.174497483512505
[11/25 23:03:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7116,	0.8280 s / batch. (data: 5.44e-03). ETA=5:49:39, max mem: 20.9 GB 
[11/25 23:05:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.7196,	0.8328 s / batch. (data: 1.06e-02). ETA=5:50:18, max mem: 20.9 GB 
[11/25 23:07:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 17.1665,	0.8610 s / batch. (data: 2.39e-02). ETA=6:00:44, max mem: 20.9 GB 
[11/25 23:08:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.7559,	0.8638 s / batch. (data: 3.09e-04). ETA=6:00:27, max mem: 20.9 GB 
[11/25 23:10:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 7.0962,	1.1773 s / batch. (data: 3.48e-01). ETA=8:09:19, max mem: 20.9 GB 
[11/25 23:11:10][INFO] visual_prompt:  217: Epoch 55 / 100: avg data time: 1.44e-01, avg batch time: 0.9767, average train loss: 18.2025
[11/25 23:12:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.19e-05, avg batch time: 0.3092, average loss: 2.4929
[11/25 23:12:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.29	
[11/25 23:12:05][INFO] visual_prompt:   36: Best epoch 55: best metric: -2.493
[11/25 23:12:05][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 5.0
[11/25 23:13:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9013,	0.8451 s / batch. (data: 1.56e-02). ETA=5:49:05, max mem: 20.9 GB 
[11/25 23:15:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.3837,	0.8554 s / batch. (data: 2.26e-02). ETA=5:51:56, max mem: 20.9 GB 
[11/25 23:17:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 17.0712,	0.8290 s / batch. (data: 3.29e-04). ETA=5:39:40, max mem: 20.9 GB 
[11/25 23:18:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 7.0236,	0.8480 s / batch. (data: 3.18e-04). ETA=5:46:02, max mem: 20.9 GB 
[11/25 23:20:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 19.5637,	2.0555 s / batch. (data: 1.23e+00). ETA=13:55:23, max mem: 20.9 GB 
[11/25 23:21:05][INFO] visual_prompt:  217: Epoch 56 / 100: avg data time: 1.43e-01, avg batch time: 0.9762, average train loss: 15.3884
[11/25 23:22:01][INFO] visual_prompt:  316: Inference (val):avg data time: 3.31e-05, avg batch time: 0.3106, average loss: 25.3055
[11/25 23:22:01][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.47	
[11/25 23:22:01][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[11/25 23:23:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 15.1756,	0.8252 s / batch. (data: 3.18e-04). ETA=5:33:17, max mem: 20.9 GB 
[11/25 23:25:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 45.6182,	0.8240 s / batch. (data: 3.42e-04). ETA=5:31:24, max mem: 20.9 GB 
[11/25 23:26:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.0000,	0.8320 s / batch. (data: 7.95e-03). ETA=5:33:14, max mem: 20.9 GB 
[11/25 23:28:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 7.1038,	0.8331 s / batch. (data: 6.27e-04). ETA=5:32:18, max mem: 20.9 GB 
[11/25 23:30:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 67.1635,	0.8362 s / batch. (data: 5.45e-03). ETA=5:32:07, max mem: 20.9 GB 
[11/25 23:31:00][INFO] visual_prompt:  217: Epoch 57 / 100: avg data time: 1.42e-01, avg batch time: 0.9756, average train loss: 15.5547
[11/25 23:31:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.22e-05, avg batch time: 0.3100, average loss: 5.7535
[11/25 23:31:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.17	
[11/25 23:31:56][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 4.651217631279374
[11/25 23:33:36][INFO] visual_prompt:  204: 	Training 100/553. train loss: 7.4500,	0.8245 s / batch. (data: 3.09e-04). ETA=5:25:23, max mem: 20.9 GB 
[11/25 23:35:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.8628,	0.8557 s / batch. (data: 1.17e-02). ETA=5:36:16, max mem: 20.9 GB 
[11/25 23:36:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 24.6648,	0.8191 s / batch. (data: 3.17e-04). ETA=5:20:31, max mem: 20.9 GB 
[11/25 23:38:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 8.5359,	0.8436 s / batch. (data: 3.12e-04). ETA=5:28:41, max mem: 20.9 GB 
[11/25 23:40:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 185.6109,	0.8292 s / batch. (data: 3.22e-04). ETA=5:21:43, max mem: 20.9 GB 
[11/25 23:40:55][INFO] visual_prompt:  217: Epoch 58 / 100: avg data time: 1.41e-01, avg batch time: 0.9742, average train loss: 17.6176
[11/25 23:41:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.23e-05, avg batch time: 0.3096, average loss: 7.0374
[11/25 23:41:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.23	
[11/25 23:41:50][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 4.477357683661733
[11/25 23:43:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1424,	0.8355 s / batch. (data: 7.96e-04). ETA=5:22:01, max mem: 20.9 GB 
[11/25 23:45:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 5.8374,	0.8483 s / batch. (data: 5.43e-03). ETA=5:25:33, max mem: 20.9 GB 
[11/25 23:46:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 27.1948,	0.8397 s / batch. (data: 3.30e-04). ETA=5:20:51, max mem: 20.9 GB 
[11/25 23:48:23][INFO] visual_prompt:  204: 	Training 400/553. train loss: 11.9470,	0.8334 s / batch. (data: 3.17e-04). ETA=5:17:03, max mem: 20.9 GB 
[11/25 23:50:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 6.1322,	0.8427 s / batch. (data: 8.41e-04). ETA=5:19:12, max mem: 20.9 GB 
[11/25 23:50:52][INFO] visual_prompt:  217: Epoch 59 / 100: avg data time: 1.46e-01, avg batch time: 0.9797, average train loss: 17.8184
[11/25 23:51:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.28e-05, avg batch time: 0.3113, average loss: 3.6967
[11/25 23:51:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.48	
[11/25 23:51:47][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[11/25 23:53:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.9260,	0.8221 s / batch. (data: 5.55e-03). ETA=5:09:16, max mem: 20.9 GB 
[11/25 23:55:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 42.8757,	0.8314 s / batch. (data: 7.30e-03). ETA=5:11:23, max mem: 20.9 GB 
[11/25 23:56:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 38.8731,	2.2961 s / batch. (data: 1.47e+00). ETA=14:16:10, max mem: 20.9 GB 
[11/25 23:58:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8077,	1.0080 s / batch. (data: 1.52e-01). ETA=6:14:11, max mem: 20.9 GB 
[11/25 23:59:58][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.3147,	0.8483 s / batch. (data: 3.62e-04). ETA=5:13:28, max mem: 20.9 GB 
[11/26 00:00:49][INFO] visual_prompt:  217: Epoch 60 / 100: avg data time: 1.47e-01, avg batch time: 0.9796, average train loss: 15.8165
[11/26 00:01:44][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.3096, average loss: 15.3824
[11/26 00:01:44][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.05	
[11/26 00:01:44][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 4.131759111665349
[11/26 00:03:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 29.5074,	0.8351 s / batch. (data: 1.20e-02). ETA=5:06:29, max mem: 20.9 GB 
[11/26 00:05:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 20.0876,	0.8476 s / batch. (data: 9.24e-03). ETA=5:09:39, max mem: 20.9 GB 
[11/26 00:06:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 8.4036,	0.8440 s / batch. (data: 5.43e-03). ETA=5:06:55, max mem: 20.9 GB 
[11/26 00:08:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 16.5174,	0.8427 s / batch. (data: 5.41e-03). ETA=5:05:04, max mem: 20.9 GB 
[11/26 00:09:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 34.2611,	1.9835 s / batch. (data: 1.15e+00). ETA=11:54:44, max mem: 20.9 GB 
[11/26 00:10:44][INFO] visual_prompt:  217: Epoch 61 / 100: avg data time: 1.42e-01, avg batch time: 0.9747, average train loss: 15.8167
[11/26 00:11:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.26e-05, avg batch time: 0.3102, average loss: 10.9515
[11/26 00:11:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.38	
[11/26 00:11:39][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 3.960441545911204
[11/26 00:13:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 22.4552,	0.8440 s / batch. (data: 3.04e-04). ETA=5:01:58, max mem: 20.9 GB 
[11/26 00:14:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 10.1873,	0.8335 s / batch. (data: 1.11e-02). ETA=4:56:48, max mem: 20.9 GB 
[11/26 00:16:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 27.1875,	0.8962 s / batch. (data: 3.62e-02). ETA=5:17:39, max mem: 20.9 GB 
[11/26 00:18:11][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.0329,	0.8243 s / batch. (data: 2.97e-04). ETA=4:50:47, max mem: 20.9 GB 
[11/26 00:19:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 14.9380,	0.8360 s / batch. (data: 3.14e-04). ETA=4:53:32, max mem: 20.9 GB 
[11/26 00:20:39][INFO] visual_prompt:  217: Epoch 62 / 100: avg data time: 1.43e-01, avg batch time: 0.9760, average train loss: 13.4324
[11/26 00:21:35][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-05, avg batch time: 0.3096, average loss: 13.0417
[11/26 00:21:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/26 00:21:35][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 3.790390522001662
[11/26 00:23:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1797,	0.8271 s / batch. (data: 3.20e-04). ETA=4:48:18, max mem: 20.9 GB 
[11/26 00:25:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 5.8354,	0.8320 s / batch. (data: 2.88e-04). ETA=4:48:37, max mem: 20.9 GB 
[11/26 00:26:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.0536,	0.8400 s / batch. (data: 3.62e-04). ETA=4:49:59, max mem: 20.9 GB 
[11/26 00:28:08][INFO] visual_prompt:  204: 	Training 400/553. train loss: 11.0377,	0.8251 s / batch. (data: 7.95e-03). ETA=4:43:28, max mem: 20.9 GB 
[11/26 00:29:43][INFO] visual_prompt:  204: 	Training 500/553. train loss: 7.3771,	0.8466 s / batch. (data: 1.88e-02). ETA=4:49:27, max mem: 20.9 GB 
[11/26 00:30:32][INFO] visual_prompt:  217: Epoch 63 / 100: avg data time: 1.38e-01, avg batch time: 0.9719, average train loss: 12.5359
[11/26 00:31:28][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3106, average loss: 14.8224
[11/26 00:31:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.12	
[11/26 00:31:28][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[11/26 00:33:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 4.9937,	0.8520 s / batch. (data: 7.71e-04). ETA=4:49:07, max mem: 20.9 GB 
[11/26 00:34:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 66.3867,	0.8124 s / batch. (data: 3.15e-04). ETA=4:34:20, max mem: 20.9 GB 
[11/26 00:36:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 8.0966,	0.8320 s / batch. (data: 7.97e-03). ETA=4:39:33, max mem: 20.9 GB 
[11/26 00:38:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.2367,	0.8920 s / batch. (data: 5.96e-02). ETA=4:58:14, max mem: 20.9 GB 
[11/26 00:39:38][INFO] visual_prompt:  204: 	Training 500/553. train loss: 31.7402,	0.8258 s / batch. (data: 7.56e-03). ETA=4:34:43, max mem: 20.9 GB 
[11/26 00:40:28][INFO] visual_prompt:  217: Epoch 64 / 100: avg data time: 1.44e-01, avg batch time: 0.9777, average train loss: 12.2981
[11/26 00:41:24][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3096, average loss: 4.9562
[11/26 00:41:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[11/26 00:41:24][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 3.454915028125263
[11/26 00:43:08][INFO] visual_prompt:  204: 	Training 100/553. train loss: 8.1335,	1.1200 s / batch. (data: 2.72e-01). ETA=6:09:44, max mem: 20.9 GB 
[11/26 00:44:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.1695,	0.8287 s / batch. (data: 3.30e-04). ETA=4:32:11, max mem: 20.9 GB 
[11/26 00:46:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 17.0906,	0.8257 s / batch. (data: 2.90e-04). ETA=4:29:50, max mem: 20.9 GB 
[11/26 00:47:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 9.3688,	0.8248 s / batch. (data: 2.54e-04). ETA=4:28:10, max mem: 20.9 GB 
[11/26 00:49:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 17.0593,	0.8249 s / batch. (data: 5.41e-03). ETA=4:26:48, max mem: 20.9 GB 
[11/26 00:50:23][INFO] visual_prompt:  217: Epoch 65 / 100: avg data time: 1.41e-01, avg batch time: 0.9751, average train loss: 11.4889
[11/26 00:51:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-05, avg batch time: 0.3104, average loss: 7.8149
[11/26 00:51:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.17	
[11/26 00:51:19][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 3.289899283371657
[11/26 00:52:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 6.1508,	0.8177 s / batch. (data: 3.01e-04). ETA=4:22:25, max mem: 20.9 GB 
[11/26 00:54:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.5804,	1.5136 s / batch. (data: 6.88e-01). ETA=8:03:13, max mem: 20.9 GB 
[11/26 00:56:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.7337,	0.8393 s / batch. (data: 5.41e-03). ETA=4:26:33, max mem: 20.9 GB 
[11/26 00:57:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 7.5557,	0.8331 s / batch. (data: 7.32e-04). ETA=4:23:11, max mem: 20.9 GB 
[11/26 00:59:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 17.6168,	0.8412 s / batch. (data: 5.41e-03). ETA=4:24:19, max mem: 20.9 GB 
[11/26 01:00:19][INFO] visual_prompt:  217: Epoch 66 / 100: avg data time: 1.43e-01, avg batch time: 0.9765, average train loss: 10.6113
[11/26 01:01:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3111, average loss: 6.4178
[11/26 01:01:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.53	
[11/26 01:01:14][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[11/26 01:02:57][INFO] visual_prompt:  204: 	Training 100/553. train loss: 12.9475,	0.8600 s / batch. (data: 2.80e-02). ETA=4:28:03, max mem: 20.9 GB 
[11/26 01:04:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0000,	0.8595 s / batch. (data: 1.05e-02). ETA=4:26:29, max mem: 20.9 GB 
[11/26 01:06:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 14.8793,	0.8360 s / batch. (data: 3.12e-04). ETA=4:17:47, max mem: 20.9 GB 
[11/26 01:07:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 13.0800,	0.8600 s / batch. (data: 1.20e-02). ETA=4:23:45, max mem: 20.9 GB 
[11/26 01:09:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 14.7161,	1.4829 s / batch. (data: 6.66e-01). ETA=7:32:20, max mem: 20.9 GB 
[11/26 01:10:15][INFO] visual_prompt:  217: Epoch 67 / 100: avg data time: 1.44e-01, avg batch time: 0.9776, average train loss: 9.5718
[11/26 01:11:10][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-05, avg batch time: 0.3096, average loss: 7.2660
[11/26 01:11:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 37.47	
[11/26 01:11:10][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[11/26 01:12:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9755,	0.8165 s / batch. (data: 2.90e-04). ETA=4:06:57, max mem: 20.9 GB 
[11/26 01:14:30][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0000,	1.0279 s / batch. (data: 1.83e-01). ETA=5:09:12, max mem: 20.9 GB 
[11/26 01:16:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.9514,	0.8337 s / batch. (data: 1.05e-02). ETA=4:09:23, max mem: 20.9 GB 
[11/26 01:17:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 15.7196,	0.8423 s / batch. (data: 6.22e-04). ETA=4:10:33, max mem: 20.9 GB 
[11/26 01:19:19][INFO] visual_prompt:  204: 	Training 500/553. train loss: 13.9565,	0.8605 s / batch. (data: 8.46e-03). ETA=4:14:32, max mem: 20.9 GB 
[11/26 01:20:10][INFO] visual_prompt:  217: Epoch 68 / 100: avg data time: 1.42e-01, avg batch time: 0.9763, average train loss: 9.5590
[11/26 01:21:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.22e-05, avg batch time: 0.3100, average loss: 2.5293
[11/26 01:21:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.56	
[11/26 01:21:05][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[11/26 01:22:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 10.2932,	0.8480 s / batch. (data: 2.95e-04). ETA=4:08:41, max mem: 20.9 GB 
[11/26 01:24:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.0000,	0.8320 s / batch. (data: 3.02e-04). ETA=4:02:36, max mem: 20.9 GB 
[11/26 01:25:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 17.7103,	0.8475 s / batch. (data: 1.05e-02). ETA=4:05:43, max mem: 20.9 GB 
[11/26 01:27:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 21.1518,	0.8366 s / batch. (data: 3.07e-04). ETA=4:01:09, max mem: 20.9 GB 
[11/26 01:29:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 9.3876,	0.8254 s / batch. (data: 3.03e-04). ETA=3:56:33, max mem: 20.9 GB 
[11/26 01:30:02][INFO] visual_prompt:  217: Epoch 69 / 100: avg data time: 1.38e-01, avg batch time: 0.9713, average train loss: 9.4999
[11/26 01:30:58][INFO] visual_prompt:  316: Inference (val):avg data time: 1.48e-04, avg batch time: 0.3124, average loss: 5.6805
[11/26 01:30:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.36	
[11/26 01:30:58][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[11/26 01:32:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 8.5869,	0.8720 s / batch. (data: 7.96e-03). ETA=4:07:41, max mem: 20.9 GB 
[11/26 01:34:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.5892,	0.9162 s / batch. (data: 9.74e-02). ETA=4:18:43, max mem: 20.9 GB 
[11/26 01:35:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 36.9494,	0.8416 s / batch. (data: 1.20e-02). ETA=3:56:15, max mem: 20.9 GB 
[11/26 01:37:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.9782,	0.8763 s / batch. (data: 2.36e-02). ETA=4:04:32, max mem: 20.9 GB 
[11/26 01:39:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 12.8219,	0.8360 s / batch. (data: 5.42e-03). ETA=3:51:53, max mem: 20.9 GB 
[11/26 01:39:55][INFO] visual_prompt:  217: Epoch 70 / 100: avg data time: 1.39e-01, avg batch time: 0.9723, average train loss: 8.2492
[11/26 01:40:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.30e-05, avg batch time: 0.3091, average loss: 10.5187
[11/26 01:40:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.50	
[11/26 01:40:51][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 2.500000000000001
[11/26 01:42:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 11.1027,	0.8568 s / batch. (data: 5.44e-03). ETA=3:55:28, max mem: 20.9 GB 
[11/26 01:44:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.1218,	0.9768 s / batch. (data: 1.31e-01). ETA=4:26:50, max mem: 20.9 GB 
[11/26 01:45:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.3976,	0.8443 s / batch. (data: 9.39e-03). ETA=3:49:14, max mem: 20.9 GB 
[11/26 01:47:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 19.4440,	0.8520 s / batch. (data: 1.06e-02). ETA=3:49:53, max mem: 20.9 GB 
[11/26 01:49:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.8120,	0.9200 s / batch. (data: 6.71e-02). ETA=4:06:43, max mem: 20.9 GB 
[11/26 01:49:52][INFO] visual_prompt:  217: Epoch 71 / 100: avg data time: 1.43e-01, avg batch time: 0.9773, average train loss: 7.4976
[11/26 01:50:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.31e-05, avg batch time: 0.3107, average loss: 6.8668
[11/26 01:50:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.44	
[11/26 01:50:47][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 2.350403678833976
[11/26 01:52:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 6.5432,	1.0640 s / batch. (data: 2.38e-01). ETA=4:42:37, max mem: 20.9 GB 
[11/26 01:54:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.2367,	0.8409 s / batch. (data: 3.08e-04). ETA=3:41:57, max mem: 20.9 GB 
[11/26 01:55:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8036,	0.8279 s / batch. (data: 3.22e-04). ETA=3:37:09, max mem: 20.9 GB 
[11/26 01:57:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.9885,	0.8188 s / batch. (data: 3.50e-04). ETA=3:33:23, max mem: 20.9 GB 
[11/26 01:59:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.0142,	0.8458 s / batch. (data: 3.17e-04). ETA=3:39:00, max mem: 20.9 GB 
[11/26 02:00:06][INFO] visual_prompt:  217: Epoch 72 / 100: avg data time: 1.77e-01, avg batch time: 1.0104, average train loss: 7.0124
[11/26 02:01:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.20e-05, avg batch time: 0.3106, average loss: 1.4174
[11/26 02:01:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.01	
[11/26 02:01:02][INFO] visual_prompt:   36: Best epoch 72: best metric: -1.417
[11/26 02:01:02][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[11/26 02:02:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.6359,	0.8440 s / batch. (data: 7.95e-03). ETA=3:36:24, max mem: 20.9 GB 
[11/26 02:04:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.5473,	0.8240 s / batch. (data: 2.91e-04). ETA=3:29:54, max mem: 20.9 GB 
[11/26 02:06:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 5.9879,	0.8440 s / batch. (data: 3.09e-04). ETA=3:33:35, max mem: 20.9 GB 
[11/26 02:07:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 11.5023,	0.8510 s / batch. (data: 3.37e-04). ETA=3:33:56, max mem: 20.9 GB 
[11/26 02:09:32][INFO] visual_prompt:  204: 	Training 500/553. train loss: 10.1057,	0.8314 s / batch. (data: 5.43e-03). ETA=3:27:37, max mem: 20.9 GB 
[11/26 02:10:23][INFO] visual_prompt:  217: Epoch 73 / 100: avg data time: 1.82e-01, avg batch time: 1.0141, average train loss: 7.5758
[11/26 02:11:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.3108, average loss: 2.7755
[11/26 02:11:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.55	
[11/26 02:11:19][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 2.061073738537635
[11/26 02:13:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 5.8129,	1.4880 s / batch. (data: 6.37e-01). ETA=6:07:48, max mem: 20.9 GB 
[11/26 02:14:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6464,	0.8474 s / batch. (data: 7.10e-04). ETA=3:28:03, max mem: 20.9 GB 
[11/26 02:16:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5511,	0.8360 s / batch. (data: 3.55e-04). ETA=3:23:51, max mem: 20.9 GB 
[11/26 02:17:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 16.4838,	0.8465 s / batch. (data: 8.87e-03). ETA=3:25:00, max mem: 20.9 GB 
[11/26 02:19:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.7205,	1.5533 s / batch. (data: 7.29e-01). ETA=6:13:35, max mem: 20.9 GB 
[11/26 02:20:21][INFO] visual_prompt:  217: Epoch 74 / 100: avg data time: 1.47e-01, avg batch time: 0.9807, average train loss: 6.5521
[11/26 02:21:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.3095, average loss: 5.0643
[11/26 02:21:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.67	
[11/26 02:21:17][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[11/26 02:22:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 5.9551,	0.8400 s / batch. (data: 3.20e-04). ETA=3:19:53, max mem: 20.9 GB 
[11/26 02:24:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 8.2169,	0.8240 s / batch. (data: 3.10e-04). ETA=3:14:42, max mem: 20.9 GB 
[11/26 02:26:14][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0150,	0.8786 s / batch. (data: 2.95e-02). ETA=3:26:09, max mem: 20.9 GB 
[11/26 02:27:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 16.9524,	1.8832 s / batch. (data: 1.05e+00). ETA=7:18:42, max mem: 20.9 GB 
[11/26 02:29:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 6.7834,	0.8360 s / batch. (data: 2.87e-04). ETA=3:13:22, max mem: 20.9 GB 
[11/26 02:30:20][INFO] visual_prompt:  217: Epoch 75 / 100: avg data time: 1.48e-01, avg batch time: 0.9815, average train loss: 5.1183
[11/26 02:31:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.32e-05, avg batch time: 0.3110, average loss: 1.4458
[11/26 02:31:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.30	
[11/26 02:31:15][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[11/26 02:32:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 13.9413,	0.8438 s / batch. (data: 8.23e-04). ETA=3:13:00, max mem: 20.9 GB 
[11/26 02:34:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.9527,	0.8176 s / batch. (data: 3.33e-04). ETA=3:05:40, max mem: 20.9 GB 
[11/26 02:36:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9832,	0.8311 s / batch. (data: 3.05e-04). ETA=3:07:20, max mem: 20.9 GB 
[11/26 02:37:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 7.1801,	0.8541 s / batch. (data: 3.01e-02). ETA=3:11:05, max mem: 20.9 GB 
[11/26 02:39:24][INFO] visual_prompt:  204: 	Training 500/553. train loss: 4.4765,	0.8361 s / batch. (data: 7.71e-04). ETA=3:05:41, max mem: 20.9 GB 
[11/26 02:40:16][INFO] visual_prompt:  217: Epoch 76 / 100: avg data time: 1.45e-01, avg batch time: 0.9779, average train loss: 5.7713
[11/26 02:41:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3101, average loss: 4.5829
[11/26 02:41:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.87	
[11/26 02:41:12][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[11/26 02:42:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.0491,	1.1826 s / batch. (data: 3.54e-01). ETA=4:19:37, max mem: 20.9 GB 
[11/26 02:44:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 5.3014,	0.8400 s / batch. (data: 3.32e-04). ETA=3:03:00, max mem: 20.9 GB 
[11/26 02:46:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.1961,	0.8294 s / batch. (data: 3.24e-04). ETA=2:59:19, max mem: 20.9 GB 
[11/26 02:47:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.6444,	0.8200 s / batch. (data: 3.17e-04). ETA=2:55:54, max mem: 20.9 GB 
[11/26 02:49:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8237,	0.8533 s / batch. (data: 5.40e-03). ETA=3:01:38, max mem: 20.9 GB 
[11/26 02:50:11][INFO] visual_prompt:  217: Epoch 77 / 100: avg data time: 1.42e-01, avg batch time: 0.9759, average train loss: 4.3626
[11/26 02:51:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3103, average loss: 0.7304
[11/26 02:51:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.36	
[11/26 02:51:07][INFO] visual_prompt:   36: Best epoch 77: best metric: -0.730
[11/26 02:51:07][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[11/26 02:52:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.0175,	0.8280 s / batch. (data: 3.00e-04). ETA=2:54:08, max mem: 20.9 GB 
[11/26 02:54:24][INFO] visual_prompt:  204: 	Training 200/553. train loss: 16.9373,	0.8605 s / batch. (data: 1.05e-02). ETA=2:59:32, max mem: 20.9 GB 
[11/26 02:56:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.0199,	0.8438 s / batch. (data: 1.92e-02). ETA=2:54:39, max mem: 20.9 GB 
[11/26 02:57:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.3504,	0.8267 s / batch. (data: 7.96e-03). ETA=2:49:44, max mem: 20.9 GB 
[11/26 02:59:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.7894,	0.8325 s / batch. (data: 3.24e-04). ETA=2:49:32, max mem: 20.9 GB 
[11/26 03:00:07][INFO] visual_prompt:  217: Epoch 78 / 100: avg data time: 1.42e-01, avg batch time: 0.9755, average train loss: 4.6980
[11/26 03:01:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.3103, average loss: 1.2920
[11/26 03:01:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.01	
[11/26 03:01:02][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 1.403300998306745
[11/26 03:02:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5852,	0.8175 s / batch. (data: 3.09e-04). ETA=2:44:23, max mem: 20.9 GB 
[11/26 03:04:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.9634,	0.8376 s / batch. (data: 1.05e-02). ETA=2:47:02, max mem: 20.9 GB 
[11/26 03:05:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8293,	1.0816 s / batch. (data: 2.64e-01). ETA=3:33:54, max mem: 20.9 GB 
[11/26 03:07:36][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0083,	0.8240 s / batch. (data: 3.13e-04). ETA=2:41:35, max mem: 20.9 GB 
[11/26 03:09:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 10.3924,	0.8625 s / batch. (data: 7.72e-04). ETA=2:47:42, max mem: 20.9 GB 
[11/26 03:10:03][INFO] visual_prompt:  217: Epoch 79 / 100: avg data time: 1.43e-01, avg batch time: 0.9779, average train loss: 4.3958
[11/26 03:10:59][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-05, avg batch time: 0.3117, average loss: 7.9201
[11/26 03:10:59][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.35	
[11/26 03:10:59][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[11/26 03:12:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8313,	0.8440 s / batch. (data: 3.46e-04). ETA=2:41:56, max mem: 20.9 GB 
[11/26 03:14:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8927,	0.8509 s / batch. (data: 1.05e-02). ETA=2:41:51, max mem: 20.9 GB 
[11/26 03:15:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.7040,	1.3160 s / batch. (data: 4.60e-01). ETA=4:08:07, max mem: 20.9 GB 
[11/26 03:17:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 14.2382,	1.3320 s / batch. (data: 5.10e-01). ETA=4:08:55, max mem: 20.9 GB 
[11/26 03:19:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 11.6514,	1.0647 s / batch. (data: 2.39e-01). ETA=3:17:11, max mem: 20.9 GB 
[11/26 03:19:58][INFO] visual_prompt:  217: Epoch 80 / 100: avg data time: 1.41e-01, avg batch time: 0.9749, average train loss: 3.7876
[11/26 03:20:54][INFO] visual_prompt:  316: Inference (val):avg data time: 3.31e-05, avg batch time: 0.3094, average loss: 4.9617
[11/26 03:20:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.33	
[11/26 03:20:54][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[11/26 03:22:36][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7479,	0.8399 s / batch. (data: 3.12e-04). ETA=2:33:25, max mem: 20.9 GB 
[11/26 03:24:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 10.2824,	0.8754 s / batch. (data: 1.56e-02). ETA=2:38:26, max mem: 20.9 GB 
[11/26 03:25:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.4862,	0.8480 s / batch. (data: 3.24e-04). ETA=2:32:04, max mem: 20.9 GB 
[11/26 03:27:28][INFO] visual_prompt:  204: 	Training 400/553. train loss: 4.9085,	1.5447 s / batch. (data: 7.18e-01). ETA=4:34:26, max mem: 20.9 GB 
[11/26 03:29:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2232,	1.9243 s / batch. (data: 1.09e+00). ETA=5:38:41, max mem: 20.9 GB 
[11/26 03:29:55][INFO] visual_prompt:  217: Epoch 81 / 100: avg data time: 1.45e-01, avg batch time: 0.9777, average train loss: 3.2534
[11/26 03:30:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.24e-05, avg batch time: 0.3104, average loss: 1.6483
[11/26 03:30:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.38	
[11/26 03:30:51][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[11/26 03:32:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8718,	0.8308 s / batch. (data: 3.26e-04). ETA=2:24:05, max mem: 20.9 GB 
[11/26 03:34:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0874,	0.8399 s / batch. (data: 3.24e-04). ETA=2:24:17, max mem: 20.9 GB 
[11/26 03:35:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8942,	1.8360 s / batch. (data: 1.02e+00). ETA=5:12:19, max mem: 20.9 GB 
[11/26 03:37:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 2.0164,	1.9044 s / batch. (data: 1.08e+00). ETA=5:20:47, max mem: 20.9 GB 
[11/26 03:39:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6835,	0.8351 s / batch. (data: 5.42e-03). ETA=2:19:16, max mem: 20.9 GB 
[11/26 03:39:50][INFO] visual_prompt:  217: Epoch 82 / 100: avg data time: 1.42e-01, avg batch time: 0.9759, average train loss: 2.6596
[11/26 03:40:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3083, average loss: 3.6602
[11/26 03:40:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.97	
[11/26 03:40:46][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[11/26 03:42:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 3.3865,	0.8639 s / batch. (data: 1.55e-03). ETA=2:21:53, max mem: 20.9 GB 
[11/26 03:44:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 19.2810,	0.8407 s / batch. (data: 1.95e-02). ETA=2:16:40, max mem: 20.9 GB 
[11/26 03:45:44][INFO] visual_prompt:  204: 	Training 300/553. train loss: 6.4987,	0.8600 s / batch. (data: 2.96e-04). ETA=2:18:22, max mem: 20.9 GB 
[11/26 03:47:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.1918,	0.8520 s / batch. (data: 2.92e-04). ETA=2:15:39, max mem: 20.9 GB 
[11/26 03:49:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7034,	0.8468 s / batch. (data: 2.28e-02). ETA=2:13:25, max mem: 20.9 GB 
[11/26 03:49:49][INFO] visual_prompt:  217: Epoch 83 / 100: avg data time: 1.48e-01, avg batch time: 0.9816, average train loss: 2.7616
[11/26 03:50:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.27e-05, avg batch time: 0.3088, average loss: 3.2479
[11/26 03:50:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.66	
[11/26 03:50:45][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[11/26 03:52:27][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7517,	0.8249 s / batch. (data: 3.27e-04). ETA=2:07:52, max mem: 20.9 GB 
[11/26 03:54:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 6.3723,	1.6167 s / batch. (data: 7.75e-01). ETA=4:07:55, max mem: 20.9 GB 
[11/26 03:55:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7850,	0.8245 s / batch. (data: 3.07e-04). ETA=2:05:04, max mem: 20.9 GB 
[11/26 03:57:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5892,	0.8393 s / batch. (data: 2.99e-04). ETA=2:05:54, max mem: 20.9 GB 
[11/26 03:58:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3949,	0.8669 s / batch. (data: 1.06e-02). ETA=2:08:36, max mem: 20.9 GB 
[11/26 03:59:47][INFO] visual_prompt:  217: Epoch 84 / 100: avg data time: 1.48e-01, avg batch time: 0.9808, average train loss: 2.4993
[11/26 04:00:43][INFO] visual_prompt:  316: Inference (val):avg data time: 1.48e-04, avg batch time: 0.3109, average loss: 2.2649
[11/26 04:00:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.07	
[11/26 04:00:43][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[11/26 04:02:26][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3921,	2.9444 s / batch. (data: 2.13e+00). ETA=7:09:17, max mem: 20.9 GB 
[11/26 04:04:02][INFO] visual_prompt:  204: 	Training 200/553. train loss: 4.1894,	1.0017 s / batch. (data: 1.60e-01). ETA=2:24:22, max mem: 20.9 GB 
[11/26 04:05:39][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.8140,	0.8366 s / batch. (data: 3.23e-04). ETA=1:59:11, max mem: 20.9 GB 
[11/26 04:07:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 3.1759,	0.8287 s / batch. (data: 5.45e-03). ETA=1:56:40, max mem: 20.9 GB 
[11/26 04:08:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.5262,	0.8322 s / batch. (data: 2.88e-04). ETA=1:55:46, max mem: 20.9 GB 
[11/26 04:09:44][INFO] visual_prompt:  217: Epoch 85 / 100: avg data time: 1.46e-01, avg batch time: 0.9787, average train loss: 1.9503
[11/26 04:10:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.41e-05, avg batch time: 0.3073, average loss: 2.5191
[11/26 04:10:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.71	
[11/26 04:10:39][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[11/26 04:12:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4905,	2.9187 s / batch. (data: 2.10e+00). ETA=6:38:38, max mem: 20.9 GB 
[11/26 04:13:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5548,	0.8360 s / batch. (data: 3.35e-04). ETA=1:52:47, max mem: 20.9 GB 
[11/26 04:15:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 3.0682,	0.8756 s / batch. (data: 3.39e-04). ETA=1:56:40, max mem: 20.9 GB 
[11/26 04:17:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0020,	0.8633 s / batch. (data: 1.53e-02). ETA=1:53:35, max mem: 20.9 GB 
[11/26 04:18:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.6574,	0.8640 s / batch. (data: 1.20e-02). ETA=1:52:14, max mem: 20.9 GB 
[11/26 04:19:43][INFO] visual_prompt:  217: Epoch 86 / 100: avg data time: 1.48e-01, avg batch time: 0.9822, average train loss: 1.7409
[11/26 04:20:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.33e-05, avg batch time: 0.3096, average loss: 0.8590
[11/26 04:20:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 54.43	
[11/26 04:20:38][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[11/26 04:22:21][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8736,	0.8373 s / batch. (data: 3.19e-04). ETA=1:46:38, max mem: 20.9 GB 
[11/26 04:24:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 3.4571,	0.8511 s / batch. (data: 1.05e-02). ETA=1:46:59, max mem: 20.9 GB 
[11/26 04:25:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0294,	1.5461 s / batch. (data: 7.14e-01). ETA=3:11:45, max mem: 20.9 GB 
[11/26 04:27:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6380,	0.8500 s / batch. (data: 2.87e-04). ETA=1:44:00, max mem: 20.9 GB 
[11/26 04:28:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9471,	0.8433 s / batch. (data: 1.20e-02). ETA=1:41:47, max mem: 20.9 GB 
[11/26 04:29:41][INFO] visual_prompt:  217: Epoch 87 / 100: avg data time: 1.46e-01, avg batch time: 0.9806, average train loss: 1.5781
[11/26 04:30:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.38e-05, avg batch time: 0.3095, average loss: 1.7448
[11/26 04:30:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.57	
[11/26 04:30:36][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[11/26 04:32:17][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0008,	0.8360 s / batch. (data: 3.15e-04). ETA=1:38:46, max mem: 20.9 GB 
[11/26 04:33:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.7567,	0.8244 s / batch. (data: 5.47e-03). ETA=1:36:01, max mem: 20.9 GB 
[11/26 04:35:34][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4015,	0.8360 s / batch. (data: 3.14e-04). ETA=1:35:59, max mem: 20.9 GB 
[11/26 04:37:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1784,	2.2543 s / batch. (data: 1.42e+00). ETA=4:15:04, max mem: 20.9 GB 
[11/26 04:38:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 3.3776,	0.8480 s / batch. (data: 3.15e-04). ETA=1:34:32, max mem: 20.9 GB 
[11/26 04:39:39][INFO] visual_prompt:  217: Epoch 88 / 100: avg data time: 1.48e-01, avg batch time: 0.9814, average train loss: 1.7065
[11/26 04:40:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3089, average loss: 0.7878
[11/26 04:40:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.60	
[11/26 04:40:34][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[11/26 04:42:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7130,	0.8462 s / batch. (data: 3.28e-04). ETA=1:32:10, max mem: 20.9 GB 
[11/26 04:43:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5703,	0.8480 s / batch. (data: 3.00e-04). ETA=1:30:57, max mem: 20.9 GB 
[11/26 04:45:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.2648,	0.8360 s / batch. (data: 3.16e-04). ETA=1:28:17, max mem: 20.9 GB 
[11/26 04:47:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.1427,	0.8714 s / batch. (data: 1.56e-02). ETA=1:30:33, max mem: 20.9 GB 
[11/26 04:48:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.9255,	0.8320 s / batch. (data: 2.73e-04). ETA=1:25:05, max mem: 20.9 GB 
[11/26 04:49:35][INFO] visual_prompt:  217: Epoch 89 / 100: avg data time: 1.44e-01, avg batch time: 0.9783, average train loss: 1.1049
[11/26 04:50:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3114, average loss: 0.6922
[11/26 04:50:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.77	
[11/26 04:50:31][INFO] visual_prompt:   36: Best epoch 89: best metric: -0.692
[11/26 04:50:31][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[11/26 04:52:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7318,	0.8480 s / batch. (data: 2.92e-04). ETA=1:24:33, max mem: 20.9 GB 
[11/26 04:53:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9195,	1.4843 s / batch. (data: 6.63e-01). ETA=2:25:32, max mem: 20.9 GB 
[11/26 04:55:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.4238,	0.8481 s / batch. (data: 2.70e-04). ETA=1:21:44, max mem: 20.9 GB 
[11/26 04:57:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5415,	1.3955 s / batch. (data: 5.79e-01). ETA=2:12:10, max mem: 20.9 GB 
[11/26 04:58:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6259,	0.8183 s / batch. (data: 2.58e-04). ETA=1:16:08, max mem: 20.9 GB 
[11/26 04:59:31][INFO] visual_prompt:  217: Epoch 90 / 100: avg data time: 1.44e-01, avg batch time: 0.9777, average train loss: 1.1953
[11/26 05:00:27][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.3108, average loss: 0.7164
[11/26 05:00:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.27	
[11/26 05:00:27][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[11/26 05:02:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7038,	0.8311 s / batch. (data: 5.43e-03). ETA=1:15:13, max mem: 20.9 GB 
[11/26 05:03:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1274,	0.8405 s / batch. (data: 1.05e-02). ETA=1:14:40, max mem: 20.9 GB 
[11/26 05:05:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7324,	0.8400 s / batch. (data: 2.93e-04). ETA=1:13:13, max mem: 20.9 GB 
[11/26 05:07:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8049,	1.5724 s / batch. (data: 7.56e-01). ETA=2:14:26, max mem: 20.9 GB 
[11/26 05:08:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6277,	0.8442 s / batch. (data: 2.06e-02). ETA=1:10:46, max mem: 20.9 GB 
[11/26 05:09:31][INFO] visual_prompt:  217: Epoch 91 / 100: avg data time: 1.48e-01, avg batch time: 0.9834, average train loss: 1.0164
[11/26 05:10:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3110, average loss: 0.7110
[11/26 05:10:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/26 05:10:26][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[11/26 05:12:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6237,	1.8240 s / batch. (data: 9.99e-01). ETA=2:28:15, max mem: 20.9 GB 
[11/26 05:13:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5295,	0.8399 s / batch. (data: 3.00e-04). ETA=1:06:52, max mem: 20.9 GB 
[11/26 05:15:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6465,	0.8505 s / batch. (data: 1.05e-02). ETA=1:06:17, max mem: 20.9 GB 
[11/26 05:17:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7094,	0.8522 s / batch. (data: 2.41e-02). ETA=1:05:00, max mem: 20.9 GB 
[11/26 05:18:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9332,	0.8322 s / batch. (data: 1.05e-02). ETA=1:02:05, max mem: 20.9 GB 
[11/26 05:19:28][INFO] visual_prompt:  217: Epoch 92 / 100: avg data time: 1.45e-01, avg batch time: 0.9787, average train loss: 0.9226
[11/26 05:20:23][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-05, avg batch time: 0.3109, average loss: 1.0049
[11/26 05:20:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.61	
[11/26 05:20:23][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[11/26 05:22:04][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9730,	0.8633 s / batch. (data: 1.55e-02). ETA=1:02:13, max mem: 20.9 GB 
[11/26 05:23:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7291,	0.9801 s / batch. (data: 1.48e-01). ETA=1:08:59, max mem: 20.9 GB 
[11/26 05:25:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5906,	0.8305 s / batch. (data: 1.28e-02). ETA=0:57:04, max mem: 20.9 GB 
[11/26 05:26:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9301,	0.8295 s / batch. (data: 5.43e-03). ETA=0:55:37, max mem: 20.9 GB 
[11/26 05:28:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6078,	0.8317 s / batch. (data: 2.92e-04). ETA=0:54:23, max mem: 20.9 GB 
[11/26 05:29:26][INFO] visual_prompt:  217: Epoch 93 / 100: avg data time: 1.47e-01, avg batch time: 0.9809, average train loss: 0.9613
[11/26 05:30:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-05, avg batch time: 0.3098, average loss: 0.6954
[11/26 05:30:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.57	
[11/26 05:30:21][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[11/26 05:32:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8118,	0.9976 s / batch. (data: 1.53e-01). ETA=1:02:41, max mem: 20.9 GB 
[11/26 05:33:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7761,	0.8360 s / batch. (data: 3.20e-04). ETA=0:51:08, max mem: 20.9 GB 
[11/26 05:35:19][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7036,	0.8177 s / batch. (data: 3.12e-04). ETA=0:48:39, max mem: 20.9 GB 
[11/26 05:36:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7895,	0.8720 s / batch. (data: 3.43e-02). ETA=0:50:26, max mem: 20.9 GB 
[11/26 05:38:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8331,	0.8400 s / batch. (data: 3.06e-04). ETA=0:47:11, max mem: 20.9 GB 
[11/26 05:39:24][INFO] visual_prompt:  217: Epoch 94 / 100: avg data time: 1.48e-01, avg batch time: 0.9810, average train loss: 0.8435
[11/26 05:40:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3102, average loss: 0.7070
[11/26 05:40:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.32	
[11/26 05:40:19][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[11/26 05:42:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6114,	0.8520 s / batch. (data: 3.05e-04). ETA=0:45:41, max mem: 20.9 GB 
[11/26 05:43:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4697,	0.8478 s / batch. (data: 1.84e-02). ETA=0:44:03, max mem: 20.9 GB 
[11/26 05:45:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8146,	1.7080 s / batch. (data: 8.71e-01). ETA=1:25:54, max mem: 20.9 GB 
[11/26 05:46:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1747,	1.6420 s / batch. (data: 8.08e-01). ETA=1:19:51, max mem: 20.9 GB 
[11/26 05:48:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2609,	0.8333 s / batch. (data: 7.95e-03). ETA=0:39:08, max mem: 20.9 GB 
[11/26 05:49:21][INFO] visual_prompt:  217: Epoch 95 / 100: avg data time: 1.47e-01, avg batch time: 0.9805, average train loss: 0.7454
[11/26 05:50:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.59e-04, avg batch time: 0.3109, average loss: 0.7121
[11/26 05:50:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.12	
[11/26 05:50:17][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[11/26 05:52:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6479,	0.8240 s / batch. (data: 3.09e-04). ETA=0:36:35, max mem: 20.9 GB 
[11/26 05:53:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7923,	0.8564 s / batch. (data: 1.09e-02). ETA=0:36:36, max mem: 20.9 GB 
[11/26 05:55:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7058,	0.8495 s / batch. (data: 1.05e-02). ETA=0:34:54, max mem: 20.9 GB 
[11/26 05:56:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8523,	0.8374 s / batch. (data: 5.43e-03). ETA=0:33:00, max mem: 20.9 GB 
[11/26 05:58:30][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8478,	0.8600 s / batch. (data: 3.40e-04). ETA=0:32:27, max mem: 20.9 GB 
[11/26 05:59:19][INFO] visual_prompt:  217: Epoch 96 / 100: avg data time: 1.46e-01, avg batch time: 0.9806, average train loss: 0.7558
[11/26 06:00:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.23e-05, avg batch time: 0.3106, average loss: 0.7252
[11/26 06:00:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.07	
[11/26 06:00:15][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[11/26 06:01:55][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7071,	0.8361 s / batch. (data: 1.64e-02). ETA=0:29:25, max mem: 20.9 GB 
[11/26 06:03:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5797,	0.8205 s / batch. (data: 3.08e-04). ETA=0:27:30, max mem: 20.9 GB 
[11/26 06:05:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6748,	0.8354 s / batch. (data: 3.12e-04). ETA=0:26:37, max mem: 20.9 GB 
[11/26 06:06:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5209,	0.8764 s / batch. (data: 6.96e-04). ETA=0:26:28, max mem: 20.9 GB 
[11/26 06:08:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9771,	0.8349 s / batch. (data: 7.56e-04). ETA=0:23:49, max mem: 20.9 GB 
[11/26 06:09:18][INFO] visual_prompt:  217: Epoch 97 / 100: avg data time: 1.48e-01, avg batch time: 0.9821, average train loss: 0.7416
[11/26 06:10:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.35e-05, avg batch time: 0.3098, average loss: 0.7607
[11/26 06:10:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.37	
[11/26 06:10:13][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[11/26 06:11:57][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7290,	0.8312 s / batch. (data: 7.90e-04). ETA=0:21:35, max mem: 20.9 GB 
[11/26 06:13:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6622,	0.8704 s / batch. (data: 7.95e-03). ETA=0:21:09, max mem: 20.9 GB 
[11/26 06:15:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6998,	2.2000 s / batch. (data: 1.36e+00). ETA=0:49:49, max mem: 20.9 GB 
[11/26 06:16:48][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6972,	1.4651 s / batch. (data: 6.40e-01). ETA=0:30:44, max mem: 20.9 GB 
[11/26 06:18:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6701,	0.8222 s / batch. (data: 2.94e-04). ETA=0:15:52, max mem: 20.9 GB 
[11/26 06:19:16][INFO] visual_prompt:  217: Epoch 98 / 100: avg data time: 1.47e-01, avg batch time: 0.9812, average train loss: 0.7065
[11/26 06:20:12][INFO] visual_prompt:  316: Inference (val):avg data time: 2.12e-04, avg batch time: 0.3096, average loss: 0.6931
[11/26 06:20:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.29	
[11/26 06:20:12][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[11/26 06:21:53][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6800,	0.8450 s / batch. (data: 8.89e-03). ETA=0:14:10, max mem: 20.9 GB 
[11/26 06:23:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7118,	0.8427 s / batch. (data: 1.05e-02). ETA=0:12:43, max mem: 20.9 GB 
[11/26 06:25:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6977,	1.3773 s / batch. (data: 5.61e-01). ETA=0:18:30, max mem: 20.9 GB 
[11/26 06:26:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5337,	0.8276 s / batch. (data: 9.27e-03). ETA=0:09:44, max mem: 20.9 GB 
[11/26 06:28:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6920,	0.8480 s / batch. (data: 1.20e-02). ETA=0:08:33, max mem: 20.9 GB 
[11/26 06:29:14][INFO] visual_prompt:  217: Epoch 99 / 100: avg data time: 1.46e-01, avg batch time: 0.9799, average train loss: 0.6978
[11/26 06:30:09][INFO] visual_prompt:  316: Inference (val):avg data time: 4.09e-04, avg batch time: 0.3103, average loss: 0.7010
[11/26 06:30:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.53	
[11/26 06:30:09][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[11/26 06:31:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7001,	0.8400 s / batch. (data: 3.41e-04). ETA=0:06:20, max mem: 20.9 GB 
[11/26 06:33:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6907,	0.8317 s / batch. (data: 3.35e-04). ETA=0:04:53, max mem: 20.9 GB 
[11/26 06:35:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6684,	0.8440 s / batch. (data: 1.60e-02). ETA=0:03:33, max mem: 20.9 GB 
[11/26 06:36:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8026,	0.8400 s / batch. (data: 2.96e-04). ETA=0:02:08, max mem: 20.9 GB 
[11/26 06:38:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6228,	0.8440 s / batch. (data: 3.16e-04). ETA=0:00:44, max mem: 20.9 GB 
[11/26 06:39:12][INFO] visual_prompt:  217: Epoch 100 / 100: avg data time: 1.49e-01, avg batch time: 0.9822, average train loss: 0.6925
[11/26 06:40:08][INFO] visual_prompt:  316: Inference (val):avg data time: 3.21e-05, avg batch time: 0.3102, average loss: 0.6868
[11/26 06:40:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.97	
[11/26 06:40:08][INFO] visual_prompt:   36: Best epoch 100: best metric: -0.687
