[12/04 03:44:24][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[12/04 03:44:24][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 03:44:24][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/04 03:44:24][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 03:44:24][INFO] visual_prompt:  108: Training with config:
[12/04 03:44:24][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr0.25_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/04 03:44:24][INFO] visual_prompt:   70: Loading training data...
[12/04 03:44:24][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[12/04 03:44:24][INFO] visual_prompt:   72: Loading validation data...
[12/04 03:44:24][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[12/04 03:44:24][INFO] visual_prompt:   36: Constructing models...
[12/04 03:44:27][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[12/04 03:44:27][INFO] visual_prompt:   54: tuned percent:0.525
[12/04 03:44:28][INFO] visual_prompt:   40: Device used for model: 0
[12/04 03:44:28][INFO] visual_prompt:   38: Setting up Evaluator...
[12/04 03:44:28][INFO] visual_prompt:   40: Setting up Trainer...
[12/04 03:44:28][INFO] visual_prompt:   45: 	Setting up the optimizer...
[12/04 03:44:28][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[12/04 03:46:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8185 s / batch. (data: 3.12e-04). ETA=12:33:02, max mem: 20.9 GB 
[12/04 03:48:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8588 s / batch. (data: 2.19e-02). ETA=13:08:38, max mem: 20.9 GB 
[12/04 03:50:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	2.7356 s / batch. (data: 1.90e+00). ETA=1 day, 17:47:36, max mem: 20.9 GB 
[12/04 03:52:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8926 s / batch. (data: 2.06e-02). ETA=13:36:43, max mem: 20.9 GB 
[12/04 03:53:59][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8472 s / batch. (data: 3.64e-04). ETA=12:53:46, max mem: 20.9 GB 
[12/04 03:54:58][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 3.07e-01, avg batch time: 1.1403, average train loss: 1.5403
[12/04 03:56:04][INFO] visual_prompt:  316: Inference (val):avg data time: 6.02e-05, avg batch time: 0.3085, average loss: 1.5201
[12/04 03:56:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[12/04 03:56:04][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.025
[12/04 03:58:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7428,	0.8614 s / batch. (data: 1.05e-02). ETA=13:04:34, max mem: 20.9 GB 
[12/04 03:59:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2153,	0.8646 s / batch. (data: 5.48e-03). ETA=13:05:59, max mem: 20.9 GB 
[12/04 04:01:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9035,	1.4828 s / batch. (data: 6.50e-01). ETA=22:25:36, max mem: 20.9 GB 
[12/04 04:03:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0799,	0.8480 s / batch. (data: 3.66e-04). ETA=12:48:05, max mem: 20.9 GB 
[12/04 04:05:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6557,	0.8232 s / batch. (data: 7.96e-03). ETA=12:24:16, max mem: 20.9 GB 
[12/04 04:06:34][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 3.06e-01, avg batch time: 1.1385, average train loss: 0.8338
[12/04 04:07:39][INFO] visual_prompt:  316: Inference (val):avg data time: 5.33e-05, avg batch time: 0.3087, average loss: 0.7538
[12/04 04:07:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.77	
[12/04 04:07:39][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.05
[12/04 04:09:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7588,	0.8283 s / batch. (data: 9.65e-03). ETA=12:26:44, max mem: 20.9 GB 
[12/04 04:11:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6979,	0.8681 s / batch. (data: 4.36e-02). ETA=13:01:09, max mem: 20.9 GB 
[12/04 04:13:21][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6494,	0.8628 s / batch. (data: 1.18e-02). ETA=12:54:58, max mem: 20.9 GB 
[12/04 04:15:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6664,	0.8381 s / batch. (data: 3.41e-04). ETA=12:31:24, max mem: 20.9 GB 
[12/04 04:17:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7062,	1.8760 s / batch. (data: 1.03e+00). ETA=1 day, 3:58:51, max mem: 20.9 GB 
[12/04 04:18:07][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 3.02e-01, avg batch time: 1.1356, average train loss: 0.7698
[12/04 04:19:13][INFO] visual_prompt:  316: Inference (val):avg data time: 6.58e-05, avg batch time: 0.3115, average loss: 0.7097
[12/04 04:19:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 57.19	
[12/04 04:19:13][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.075
[12/04 04:21:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7156,	0.8233 s / batch. (data: 5.27e-04). ETA=12:14:38, max mem: 20.9 GB 
[12/04 04:23:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4199,	0.8440 s / batch. (data: 3.46e-04). ETA=12:31:44, max mem: 20.9 GB 
[12/04 04:24:59][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6373,	2.3143 s / batch. (data: 1.47e+00). ETA=1 day, 10:17:26, max mem: 20.9 GB 
[12/04 04:26:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5697,	1.8040 s / batch. (data: 9.76e-01). ETA=1 day, 2:40:46, max mem: 20.9 GB 
[12/04 04:28:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7092,	4.2596 s / batch. (data: 3.44e+00). ETA=2 days, 14:52:37, max mem: 20.9 GB 
[12/04 04:29:41][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 3.03e-01, avg batch time: 1.1353, average train loss: 0.8536
[12/04 04:30:48][INFO] visual_prompt:  316: Inference (val):avg data time: 1.63e-04, avg batch time: 0.3116, average loss: 0.8408
[12/04 04:30:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[12/04 04:30:48][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.1
[12/04 04:32:45][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4815,	0.8263 s / batch. (data: 5.91e-04). ETA=12:09:42, max mem: 20.9 GB 
[12/04 04:34:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6136,	1.6322 s / batch. (data: 8.09e-01). ETA=23:58:41, max mem: 20.9 GB 
[12/04 04:36:20][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3234,	0.8285 s / batch. (data: 2.94e-04). ETA=12:08:55, max mem: 20.9 GB 
[12/04 04:37:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1613,	0.8200 s / batch. (data: 2.88e-04). ETA=12:00:05, max mem: 20.9 GB 
[12/04 04:39:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5823,	0.8199 s / batch. (data: 3.12e-04). ETA=11:58:34, max mem: 20.9 GB 
[12/04 04:40:22][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 2.05e-01, avg batch time: 1.0379, average train loss: 0.8950
[12/04 04:41:17][INFO] visual_prompt:  316: Inference (val):avg data time: 3.41e-05, avg batch time: 0.3100, average loss: 0.7901
[12/04 04:41:17][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.59	
[12/04 04:41:17][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.125
[12/04 04:43:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5826,	0.8545 s / batch. (data: 7.61e-04). ETA=12:26:45, max mem: 20.9 GB 
[12/04 04:44:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6062,	0.8518 s / batch. (data: 3.96e-03). ETA=12:23:00, max mem: 20.9 GB 
[12/04 04:46:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5727,	0.8194 s / batch. (data: 2.97e-04). ETA=11:53:23, max mem: 20.9 GB 
[12/04 04:47:51][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5861,	0.8245 s / batch. (data: 3.50e-04). ETA=11:56:26, max mem: 20.9 GB 
[12/04 04:49:25][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8666,	0.8600 s / batch. (data: 3.21e-04). ETA=12:25:50, max mem: 20.9 GB 
[12/04 04:50:15][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 1.37e-01, avg batch time: 0.9717, average train loss: 0.7715
[12/04 04:51:10][INFO] visual_prompt:  316: Inference (val):avg data time: 1.17e-04, avg batch time: 0.3121, average loss: 0.6998
[12/04 04:51:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.70	
[12/04 04:51:10][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.15
[12/04 04:52:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7248,	0.8280 s / batch. (data: 2.95e-04). ETA=11:55:58, max mem: 20.9 GB 
[12/04 04:54:23][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5871,	0.8200 s / batch. (data: 2.98e-04). ETA=11:47:40, max mem: 20.9 GB 
[12/04 04:56:01][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6997,	1.3143 s / batch. (data: 4.88e-01). ETA=18:52:04, max mem: 20.9 GB 
[12/04 04:57:37][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6116,	1.7360 s / batch. (data: 9.04e-01). ETA=1 day, 0:52:25, max mem: 20.9 GB 
[12/04 04:59:11][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1290,	0.8451 s / batch. (data: 5.43e-03). ETA=12:05:09, max mem: 20.9 GB 
[12/04 05:00:01][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 1.25e-01, avg batch time: 0.9598, average train loss: 0.7805
[12/04 05:00:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.59e-05, avg batch time: 0.3087, average loss: 0.7299
[12/04 05:00:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.11	
[12/04 05:00:56][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.175
[12/04 05:02:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7028,	0.8583 s / batch. (data: 1.43e-02). ETA=12:14:17, max mem: 20.9 GB 
[12/04 05:04:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2375,	0.8544 s / batch. (data: 1.56e-02). ETA=12:09:31, max mem: 20.9 GB 
[12/04 05:05:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9843,	0.8564 s / batch. (data: 1.10e-02). ETA=12:09:45, max mem: 20.9 GB 
[12/04 05:07:25][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7567,	0.8440 s / batch. (data: 5.44e-03). ETA=11:57:49, max mem: 20.9 GB 
[12/04 05:09:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0193,	1.2830 s / batch. (data: 4.56e-01). ETA=18:09:02, max mem: 20.9 GB 
[12/04 05:09:53][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 1.36e-01, avg batch time: 0.9705, average train loss: 0.8128
[12/04 05:10:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.33e-05, avg batch time: 0.3112, average loss: 0.8603
[12/04 05:10:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.03	
[12/04 05:10:48][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.2
[12/04 05:12:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5982,	0.8440 s / batch. (data: 3.34e-04). ETA=11:54:14, max mem: 20.9 GB 
[12/04 05:14:04][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6442,	0.8468 s / batch. (data: 2.06e-02). ETA=11:55:10, max mem: 20.9 GB 
[12/04 05:15:41][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6454,	1.6280 s / batch. (data: 7.78e-01). ETA=22:52:16, max mem: 20.9 GB 
[12/04 05:17:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5966,	0.8840 s / batch. (data: 7.60e-04). ETA=12:23:40, max mem: 20.9 GB 
[12/04 05:18:55][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6879,	0.8264 s / batch. (data: 4.10e-04). ETA=11:33:48, max mem: 20.9 GB 
[12/04 05:19:44][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 1.35e-01, avg batch time: 0.9702, average train loss: 0.7972
[12/04 05:20:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3111, average loss: 1.0446
[12/04 05:20:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.04	
[12/04 05:20:39][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.225
[12/04 05:22:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9860,	0.8318 s / batch. (data: 8.31e-04). ETA=11:36:17, max mem: 20.9 GB 
[12/04 05:23:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5646,	0.8303 s / batch. (data: 3.10e-04). ETA=11:33:39, max mem: 20.9 GB 
[12/04 05:25:30][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6824,	1.5120 s / batch. (data: 6.79e-01). ETA=21:00:35, max mem: 20.9 GB 
[12/04 05:27:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9630,	0.8377 s / batch. (data: 3.18e-04). ETA=11:36:59, max mem: 20.9 GB 
[12/04 05:28:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9114,	0.8478 s / batch. (data: 5.44e-03). ETA=11:44:00, max mem: 20.9 GB 
[12/04 05:29:30][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 1.25e-01, avg batch time: 0.9593, average train loss: 0.9018
[12/04 05:30:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.73e-05, avg batch time: 0.3099, average loss: 0.8534
[12/04 05:30:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.42	
[12/04 05:30:25][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.25
[12/04 05:32:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7061,	0.8240 s / batch. (data: 3.05e-04). ETA=11:22:07, max mem: 20.9 GB 
[12/04 05:33:43][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.2222,	0.8320 s / batch. (data: 3.04e-04). ETA=11:27:22, max mem: 20.9 GB 
[12/04 05:35:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.1973,	1.8759 s / batch. (data: 1.04e+00). ETA=1 day, 1:46:41, max mem: 20.9 GB 
[12/04 05:36:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5758,	0.8290 s / batch. (data: 3.13e-04). ETA=11:22:05, max mem: 20.9 GB 
[12/04 05:38:27][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7289,	0.8480 s / batch. (data: 5.46e-03). ETA=11:36:21, max mem: 20.9 GB 
[12/04 05:39:17][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 1.29e-01, avg batch time: 0.9626, average train loss: 0.8837
[12/04 05:40:12][INFO] visual_prompt:  316: Inference (val):avg data time: 5.57e-05, avg batch time: 0.3111, average loss: 0.8879
[12/04 05:40:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.53	
[12/04 05:40:12][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/04 05:41:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7659,	0.8285 s / batch. (data: 3.24e-04). ETA=11:18:13, max mem: 20.9 GB 
[12/04 05:43:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8116,	1.4600 s / batch. (data: 6.39e-01). ETA=19:52:44, max mem: 20.9 GB 
[12/04 05:45:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6508,	0.8480 s / batch. (data: 3.24e-04). ETA=11:31:20, max mem: 20.9 GB 
[12/04 05:46:42][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0739,	0.8206 s / batch. (data: 4.52e-04). ETA=11:07:39, max mem: 20.9 GB 
[12/04 05:48:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.8426,	0.8280 s / batch. (data: 7.70e-04). ETA=11:12:15, max mem: 20.9 GB 
[12/04 05:49:08][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 1.34e-01, avg batch time: 0.9683, average train loss: 0.8246
[12/04 05:50:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.49e-05, avg batch time: 0.3111, average loss: 1.5140
[12/04 05:50:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[12/04 05:50:02][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/04 05:51:43][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6790,	0.8399 s / batch. (data: 3.16e-04). ETA=11:19:51, max mem: 20.9 GB 
[12/04 05:53:18][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7078,	0.8360 s / batch. (data: 7.95e-03). ETA=11:15:15, max mem: 20.9 GB 
[12/04 05:54:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6904,	1.6000 s / batch. (data: 7.80e-01). ETA=21:29:42, max mem: 20.9 GB 
[12/04 05:56:29][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1358,	0.8400 s / batch. (data: 2.82e-04). ETA=11:15:41, max mem: 20.9 GB 
[12/04 05:58:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7014,	0.8592 s / batch. (data: 2.64e-02). ETA=11:29:44, max mem: 20.9 GB 
[12/04 05:58:55][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 1.29e-01, avg batch time: 0.9631, average train loss: 0.8478
[12/04 05:59:49][INFO] visual_prompt:  316: Inference (val):avg data time: 8.95e-05, avg batch time: 0.3094, average loss: 0.7749
[12/04 05:59:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.02	
[12/04 05:59:49][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.775
[12/04 05:59:49][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/04 06:01:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6213,	0.8251 s / batch. (data: 8.72e-03). ETA=11:00:14, max mem: 20.9 GB 
[12/04 06:03:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1663,	0.8237 s / batch. (data: 5.45e-03). ETA=10:57:44, max mem: 20.9 GB 
[12/04 06:04:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7462,	0.8642 s / batch. (data: 7.95e-03). ETA=11:28:38, max mem: 20.9 GB 
[12/04 06:06:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8124,	0.8427 s / batch. (data: 3.14e-04). ETA=11:10:07, max mem: 20.9 GB 
[12/04 06:07:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1173,	0.8440 s / batch. (data: 2.80e-04). ETA=11:09:43, max mem: 20.9 GB 
[12/04 06:08:41][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 1.26e-01, avg batch time: 0.9605, average train loss: 0.7847
[12/04 06:09:35][INFO] visual_prompt:  316: Inference (val):avg data time: 1.53e-04, avg batch time: 0.3098, average loss: 0.6897
[12/04 06:09:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.63	
[12/04 06:09:35][INFO] visual_prompt:   36: Best epoch 14: best metric: -0.690
[12/04 06:09:35][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/04 06:11:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7982,	0.8320 s / batch. (data: 3.23e-04). ETA=10:58:05, max mem: 20.9 GB 
[12/04 06:12:49][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8254,	0.8480 s / batch. (data: 2.63e-04). ETA=11:09:21, max mem: 20.9 GB 
[12/04 06:14:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6573,	0.8275 s / batch. (data: 2.88e-04). ETA=10:51:43, max mem: 20.9 GB 
[12/04 06:15:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7014,	1.0225 s / batch. (data: 2.01e-01). ETA=13:23:38, max mem: 20.9 GB 
[12/04 06:17:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7251,	0.8421 s / batch. (data: 1.05e-02). ETA=11:00:26, max mem: 20.9 GB 
[12/04 06:18:26][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 1.25e-01, avg batch time: 0.9593, average train loss: 0.9029
[12/04 06:19:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.69e-05, avg batch time: 0.3105, average loss: 0.8379
[12/04 06:19:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.61	
[12/04 06:19:20][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/04 06:20:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5627,	0.8560 s / batch. (data: 1.20e-02). ETA=11:09:09, max mem: 20.9 GB 
[12/04 06:22:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0237,	0.8480 s / batch. (data: 2.89e-04). ETA=11:01:29, max mem: 20.9 GB 
[12/04 06:24:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9025,	0.8313 s / batch. (data: 3.10e-04). ETA=10:47:07, max mem: 20.9 GB 
[12/04 06:25:45][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6871,	0.8483 s / batch. (data: 1.64e-02). ETA=10:58:54, max mem: 20.9 GB 
[12/04 06:27:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7218,	1.5249 s / batch. (data: 7.02e-01). ETA=19:41:53, max mem: 20.9 GB 
[12/04 06:28:10][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 1.24e-01, avg batch time: 0.9590, average train loss: 0.8325
[12/04 06:29:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.68e-05, avg batch time: 0.3090, average loss: 0.6887
[12/04 06:29:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.81	
[12/04 06:29:05][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.689
[12/04 06:29:05][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/04 06:30:44][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5818,	0.8174 s / batch. (data: 3.64e-04). ETA=10:31:26, max mem: 20.9 GB 
[12/04 06:32:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.9924,	0.8227 s / batch. (data: 3.86e-04). ETA=10:34:09, max mem: 20.9 GB 
[12/04 06:33:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.7095,	0.8249 s / batch. (data: 2.91e-04). ETA=10:34:29, max mem: 20.9 GB 
[12/04 06:35:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6308,	1.2200 s / batch. (data: 3.60e-01). ETA=15:36:21, max mem: 20.9 GB 
[12/04 06:37:05][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0265,	1.0666 s / batch. (data: 2.46e-01). ETA=13:36:50, max mem: 20.9 GB 
[12/04 06:37:56][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 1.27e-01, avg batch time: 0.9603, average train loss: 0.9583
[12/04 06:38:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.57e-05, avg batch time: 0.3098, average loss: 0.7726
[12/04 06:38:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.10	
[12/04 06:38:51][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/04 06:40:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7899,	0.8541 s / batch. (data: 1.60e-02). ETA=10:51:58, max mem: 20.9 GB 
[12/04 06:42:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8118,	0.8324 s / batch. (data: 5.42e-03). ETA=10:34:00, max mem: 20.9 GB 
[12/04 06:43:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6788,	0.8187 s / batch. (data: 2.94e-04). ETA=10:22:09, max mem: 20.9 GB 
[12/04 06:45:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7317,	0.8360 s / batch. (data: 1.20e-02). ETA=10:33:56, max mem: 20.9 GB 
[12/04 06:46:54][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1800,	0.8663 s / batch. (data: 1.56e-02). ETA=10:55:28, max mem: 20.9 GB 
[12/04 06:47:42][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 1.28e-01, avg batch time: 0.9617, average train loss: 1.0210
[12/04 06:48:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3113, average loss: 0.9951
[12/04 06:48:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.00	
[12/04 06:48:37][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/04 06:50:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5707,	0.8280 s / batch. (data: 3.20e-04). ETA=10:24:24, max mem: 20.9 GB 
[12/04 06:51:53][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5834,	0.8297 s / batch. (data: 2.79e-04). ETA=10:24:15, max mem: 20.9 GB 
[12/04 06:53:28][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9944,	1.1002 s / batch. (data: 2.66e-01). ETA=13:45:58, max mem: 20.9 GB 
[12/04 06:55:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6432,	0.8583 s / batch. (data: 5.93e-03). ETA=10:42:56, max mem: 20.9 GB 
[12/04 06:56:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6219,	0.8332 s / batch. (data: 2.82e-04). ETA=10:22:44, max mem: 20.9 GB 
[12/04 06:57:26][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 1.22e-01, avg batch time: 0.9570, average train loss: 0.8275
[12/04 06:58:21][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.3095, average loss: 1.2959
[12/04 06:58:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.96	
[12/04 06:58:21][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/04 06:59:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5875,	0.8323 s / batch. (data: 3.10e-04). ETA=10:19:56, max mem: 20.9 GB 
[12/04 07:01:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5600,	0.8480 s / batch. (data: 5.43e-03). ETA=10:30:15, max mem: 20.9 GB 
[12/04 07:03:11][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9484,	0.8560 s / batch. (data: 1.59e-02). ETA=10:34:45, max mem: 20.9 GB 
[12/04 07:04:46][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6638,	0.8440 s / batch. (data: 7.95e-03). ETA=10:24:27, max mem: 20.9 GB 
[12/04 07:06:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7173,	0.8336 s / batch. (data: 9.61e-03). ETA=10:15:24, max mem: 20.9 GB 
[12/04 07:07:11][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 1.24e-01, avg batch time: 0.9592, average train loss: 0.8286
[12/04 07:08:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.53e-05, avg batch time: 0.3106, average loss: 0.9962
[12/04 07:08:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[12/04 07:08:06][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/04 07:09:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5715,	0.8280 s / batch. (data: 1.20e-02). ETA=10:09:09, max mem: 20.9 GB 
[12/04 07:11:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9737,	0.8196 s / batch. (data: 2.89e-04). ETA=10:01:33, max mem: 20.9 GB 
[12/04 07:12:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 2.0618,	0.8673 s / batch. (data: 3.75e-02). ETA=10:35:09, max mem: 20.9 GB 
[12/04 07:14:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.4197,	0.8293 s / batch. (data: 1.05e-02). ETA=10:05:57, max mem: 20.9 GB 
[12/04 07:16:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6889,	0.8253 s / batch. (data: 3.26e-04). ETA=10:01:37, max mem: 20.9 GB 
[12/04 07:16:56][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 1.26e-01, avg batch time: 0.9589, average train loss: 0.8497
[12/04 07:17:51][INFO] visual_prompt:  316: Inference (val):avg data time: 3.62e-05, avg batch time: 0.3091, average loss: 0.6998
[12/04 07:17:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.33	
[12/04 07:17:51][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/04 07:19:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.6218,	0.8247 s / batch. (data: 2.87e-04). ETA=9:59:05, max mem: 20.9 GB 
[12/04 07:21:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8761,	0.8379 s / batch. (data: 2.87e-04). ETA=10:07:17, max mem: 20.9 GB 
[12/04 07:22:38][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.3297,	0.8445 s / batch. (data: 5.44e-03). ETA=10:10:38, max mem: 20.9 GB 
[12/04 07:24:14][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7813,	0.8315 s / batch. (data: 2.90e-04). ETA=9:59:55, max mem: 20.9 GB 
[12/04 07:25:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7249,	0.8410 s / batch. (data: 2.88e-04). ETA=10:05:21, max mem: 20.9 GB 
[12/04 07:26:40][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 1.25e-01, avg batch time: 0.9578, average train loss: 0.8943
[12/04 07:27:35][INFO] visual_prompt:  316: Inference (val):avg data time: 3.63e-05, avg batch time: 0.3105, average loss: 0.7687
[12/04 07:27:35][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.40	
[12/04 07:27:35][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/04 07:29:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9184,	0.8400 s / batch. (data: 3.60e-04). ETA=10:02:28, max mem: 20.9 GB 
[12/04 07:30:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7380,	0.8443 s / batch. (data: 1.05e-02). ETA=10:04:10, max mem: 20.9 GB 
[12/04 07:32:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5879,	0.8209 s / batch. (data: 2.93e-04). ETA=9:46:01, max mem: 20.9 GB 
[12/04 07:34:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5716,	0.8556 s / batch. (data: 7.62e-04). ETA=10:09:25, max mem: 20.9 GB 
[12/04 07:35:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2949,	0.8245 s / batch. (data: 3.04e-04). ETA=9:45:49, max mem: 20.9 GB 
[12/04 07:36:25][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 1.25e-01, avg batch time: 0.9592, average train loss: 0.8408
[12/04 07:37:20][INFO] visual_prompt:  316: Inference (val):avg data time: 3.63e-05, avg batch time: 0.3106, average loss: 1.0228
[12/04 07:37:20][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.63	
[12/04 07:37:20][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/04 07:38:57][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.3352,	0.8524 s / batch. (data: 1.20e-02). ETA=10:03:31, max mem: 20.9 GB 
[12/04 07:40:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7216,	0.8493 s / batch. (data: 1.55e-02). ETA=9:59:53, max mem: 20.9 GB 
[12/04 07:42:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7101,	0.8600 s / batch. (data: 3.24e-04). ETA=10:06:01, max mem: 20.9 GB 
[12/04 07:43:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5791,	0.8200 s / batch. (data: 3.24e-04). ETA=9:36:28, max mem: 20.9 GB 
[12/04 07:45:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7199,	0.8600 s / batch. (data: 7.96e-03). ETA=10:03:10, max mem: 20.9 GB 
[12/04 07:46:11][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 1.26e-01, avg batch time: 0.9598, average train loss: 0.8738
[12/04 07:47:05][INFO] visual_prompt:  316: Inference (val):avg data time: 3.47e-05, avg batch time: 0.3107, average loss: 0.7540
[12/04 07:47:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.62	
[12/04 07:47:05][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/04 07:48:47][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6102,	0.8205 s / batch. (data: 2.77e-04). ETA=9:33:23, max mem: 20.9 GB 
[12/04 07:50:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1837,	1.0113 s / batch. (data: 1.72e-01). ETA=11:45:01, max mem: 20.9 GB 
[12/04 07:51:54][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7502,	1.0689 s / batch. (data: 2.20e-01). ETA=12:23:24, max mem: 20.9 GB 
[12/04 07:53:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9394,	1.1200 s / batch. (data: 2.83e-01). ETA=12:57:02, max mem: 20.9 GB 
[12/04 07:55:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1250,	1.1613 s / batch. (data: 3.42e-01). ETA=13:23:45, max mem: 20.9 GB 
[12/04 07:55:56][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 1.27e-01, avg batch time: 0.9606, average train loss: 0.8454
[12/04 07:56:51][INFO] visual_prompt:  316: Inference (val):avg data time: 1.59e-04, avg batch time: 0.3108, average loss: 1.0285
[12/04 07:56:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.67	
[12/04 07:56:51][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/04 07:58:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5638,	0.8342 s / batch. (data: 1.55e-02). ETA=9:35:14, max mem: 20.9 GB 
[12/04 08:00:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9088,	1.5380 s / batch. (data: 7.22e-01). ETA=17:38:00, max mem: 20.9 GB 
[12/04 08:01:43][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9618,	0.8370 s / batch. (data: 7.86e-04). ETA=9:34:24, max mem: 20.9 GB 
[12/04 08:03:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.3372,	0.8320 s / batch. (data: 3.99e-04). ETA=9:29:32, max mem: 20.9 GB 
[12/04 08:04:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8878,	0.8440 s / batch. (data: 5.45e-03). ETA=9:36:22, max mem: 20.9 GB 
[12/04 08:05:41][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 1.24e-01, avg batch time: 0.9594, average train loss: 0.8429
[12/04 08:06:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.57e-05, avg batch time: 0.3109, average loss: 0.6883
[12/04 08:06:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.49	
[12/04 08:06:36][INFO] visual_prompt:   36: Best epoch 26: best metric: -0.688
[12/04 08:06:36][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/04 08:08:16][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6208,	0.8565 s / batch. (data: 1.06e-02). ETA=9:42:44, max mem: 20.9 GB 
[12/04 08:09:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9432,	1.0480 s / batch. (data: 1.95e-01). ETA=11:51:17, max mem: 20.9 GB 
[12/04 08:11:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5772,	0.8250 s / batch. (data: 2.90e-04). ETA=9:18:34, max mem: 20.9 GB 
[12/04 08:13:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7051,	0.8346 s / batch. (data: 9.44e-04). ETA=9:23:41, max mem: 20.9 GB 
[12/04 08:14:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6068,	0.8320 s / batch. (data: 1.53e-02). ETA=9:20:32, max mem: 20.9 GB 
[12/04 08:15:27][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 1.26e-01, avg batch time: 0.9610, average train loss: 0.8669
[12/04 08:16:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3109, average loss: 0.7804
[12/04 08:16:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.34	
[12/04 08:16:22][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/04 08:18:01][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.0619,	0.8480 s / batch. (data: 7.97e-03). ETA=9:29:08, max mem: 20.9 GB 
[12/04 08:19:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 2.5732,	0.8489 s / batch. (data: 1.55e-02). ETA=9:28:18, max mem: 20.9 GB 
[12/04 08:21:12][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0202,	1.2487 s / batch. (data: 4.22e-01). ETA=13:53:52, max mem: 20.9 GB 
[12/04 08:22:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7207,	0.8186 s / batch. (data: 2.91e-04). ETA=9:05:19, max mem: 20.9 GB 
[12/04 08:24:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9087,	0.8408 s / batch. (data: 2.45e-04). ETA=9:18:43, max mem: 20.9 GB 
[12/04 08:25:12][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 1.24e-01, avg batch time: 0.9583, average train loss: 1.0145
[12/04 08:26:06][INFO] visual_prompt:  316: Inference (val):avg data time: 1.72e-04, avg batch time: 0.3092, average loss: 0.7389
[12/04 08:26:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.30	
[12/04 08:26:06][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/04 08:27:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8489,	0.8360 s / batch. (data: 2.69e-04). ETA=9:13:22, max mem: 20.9 GB 
[12/04 08:29:26][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8727,	1.5040 s / batch. (data: 6.87e-01). ETA=16:33:01, max mem: 20.9 GB 
[12/04 08:31:00][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7270,	0.8328 s / batch. (data: 1.08e-02). ETA=9:08:29, max mem: 20.9 GB 
[12/04 08:32:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5946,	0.8458 s / batch. (data: 2.62e-02). ETA=9:15:38, max mem: 20.9 GB 
[12/04 08:34:08][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1133,	0.8793 s / batch. (data: 2.73e-02). ETA=9:36:09, max mem: 20.9 GB 
[12/04 08:34:57][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 1.26e-01, avg batch time: 0.9602, average train loss: 0.9752
[12/04 08:35:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.55e-05, avg batch time: 0.3098, average loss: 1.2719
[12/04 08:35:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.75	
[12/04 08:35:52][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/04 08:37:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6954,	0.8360 s / batch. (data: 2.92e-04). ETA=9:05:40, max mem: 20.9 GB 
[12/04 08:39:06][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2975,	0.8292 s / batch. (data: 5.40e-03). ETA=8:59:50, max mem: 20.9 GB 
[12/04 08:40:40][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2771,	1.8519 s / batch. (data: 9.94e-01). ETA=20:02:36, max mem: 20.9 GB 
[12/04 08:42:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0932,	0.9747 s / batch. (data: 1.45e-01). ETA=10:31:18, max mem: 20.9 GB 
[12/04 08:43:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5604,	1.3360 s / batch. (data: 4.87e-01). ETA=14:23:07, max mem: 20.9 GB 
[12/04 08:44:43][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 1.26e-01, avg batch time: 0.9602, average train loss: 0.8724
[12/04 08:45:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.38e-05, avg batch time: 0.3112, average loss: 0.7306
[12/04 08:45:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.75	
[12/04 08:45:37][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/04 08:47:19][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6002,	0.8308 s / batch. (data: 5.41e-03). ETA=8:54:38, max mem: 20.9 GB 
[12/04 08:48:56][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9437,	0.8592 s / batch. (data: 3.00e-04). ETA=9:11:26, max mem: 20.9 GB 
[12/04 08:50:29][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7611,	0.8517 s / batch. (data: 6.45e-03). ETA=9:05:15, max mem: 20.9 GB 
[12/04 08:52:04][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5838,	0.9901 s / batch. (data: 1.20e-01). ETA=10:32:10, max mem: 20.9 GB 
[12/04 08:53:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5712,	0.8480 s / batch. (data: 2.93e-04). ETA=9:00:01, max mem: 20.9 GB 
[12/04 08:54:28][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 1.24e-01, avg batch time: 0.9588, average train loss: 0.8127
[12/04 08:55:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.54e-05, avg batch time: 0.3119, average loss: 0.7037
[12/04 08:55:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.84	
[12/04 08:55:22][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/04 08:57:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5703,	0.8720 s / batch. (data: 7.31e-04). ETA=9:13:05, max mem: 20.9 GB 
[12/04 08:58:40][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5599,	0.8187 s / batch. (data: 2.97e-04). ETA=8:37:55, max mem: 20.9 GB 
[12/04 09:00:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9876,	0.8440 s / batch. (data: 5.58e-03). ETA=8:52:31, max mem: 20.9 GB 
[12/04 09:01:55][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7702,	0.8627 s / batch. (data: 2.00e-04). ETA=9:02:53, max mem: 20.9 GB 
[12/04 09:03:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7157,	0.8328 s / batch. (data: 5.42e-03). ETA=8:42:39, max mem: 20.9 GB 
[12/04 09:04:17][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 1.34e-01, avg batch time: 0.9666, average train loss: 0.8455
[12/04 09:05:12][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3114, average loss: 0.6885
[12/04 09:05:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[12/04 09:05:12][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[12/04 09:06:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.7185,	0.8256 s / batch. (data: 2.85e-04). ETA=8:36:03, max mem: 20.9 GB 
[12/04 09:08:28][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0941,	1.0680 s / batch. (data: 2.45e-01). ETA=11:05:47, max mem: 20.9 GB 
[12/04 09:10:03][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8596,	0.8842 s / batch. (data: 2.06e-02). ETA=9:09:45, max mem: 20.9 GB 
[12/04 09:11:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7348,	0.8200 s / batch. (data: 3.23e-04). ETA=8:28:28, max mem: 20.9 GB 
[12/04 09:13:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4949,	0.8400 s / batch. (data: 2.99e-04). ETA=8:39:27, max mem: 20.9 GB 
[12/04 09:14:05][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 1.30e-01, avg batch time: 0.9637, average train loss: 0.8833
[12/04 09:15:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.32e-05, avg batch time: 0.3110, average loss: 1.1352
[12/04 09:15:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.71	
[12/04 09:15:00][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[12/04 09:16:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9046,	0.8840 s / batch. (data: 5.09e-02). ETA=9:04:24, max mem: 20.9 GB 
[12/04 09:18:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7317,	0.8520 s / batch. (data: 3.12e-04). ETA=8:43:16, max mem: 20.9 GB 
[12/04 09:19:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7164,	0.8187 s / batch. (data: 3.56e-04). ETA=8:21:29, max mem: 20.9 GB 
[12/04 09:21:28][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9245,	0.8480 s / batch. (data: 2.88e-04). ETA=8:38:00, max mem: 20.9 GB 
[12/04 09:23:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5839,	1.1160 s / batch. (data: 2.72e-01). ETA=11:19:51, max mem: 20.9 GB 
[12/04 09:23:54][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 1.30e-01, avg batch time: 0.9653, average train loss: 0.8411
[12/04 09:24:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3114, average loss: 0.7324
[12/04 09:24:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.46	
[12/04 09:24:49][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[12/04 09:26:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5990,	0.8551 s / batch. (data: 5.16e-03). ETA=8:38:44, max mem: 20.9 GB 
[12/04 09:28:10][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6983,	0.8364 s / batch. (data: 3.44e-04). ETA=8:25:59, max mem: 20.9 GB 
[12/04 09:29:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6906,	0.8312 s / batch. (data: 3.00e-04). ETA=8:21:28, max mem: 20.9 GB 
[12/04 09:31:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6172,	0.8266 s / batch. (data: 3.22e-04). ETA=8:17:17, max mem: 20.9 GB 
[12/04 09:32:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7756,	0.8296 s / batch. (data: 3.10e-04). ETA=8:17:45, max mem: 20.9 GB 
[12/04 09:33:47][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 1.40e-01, avg batch time: 0.9735, average train loss: 0.8366
[12/04 09:34:42][INFO] visual_prompt:  316: Inference (val):avg data time: 3.62e-05, avg batch time: 0.3092, average loss: 0.6925
[12/04 09:34:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.68	
[12/04 09:34:42][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[12/04 09:36:23][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5637,	0.8247 s / batch. (data: 3.32e-04). ETA=8:12:42, max mem: 20.9 GB 
[12/04 09:38:01][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3438,	0.8481 s / batch. (data: 3.07e-04). ETA=8:25:14, max mem: 20.9 GB 
[12/04 09:39:39][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.1058,	0.8543 s / batch. (data: 2.29e-02). ETA=8:27:32, max mem: 20.9 GB 
[12/04 09:41:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2804,	0.8209 s / batch. (data: 2.96e-04). ETA=8:06:17, max mem: 20.9 GB 
[12/04 09:42:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5630,	1.0398 s / batch. (data: 2.00e-01). ETA=10:14:16, max mem: 20.9 GB 
[12/04 09:43:39][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 1.38e-01, avg batch time: 0.9715, average train loss: 0.9216
[12/04 09:44:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.3100, average loss: 0.7603
[12/04 09:44:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[12/04 09:44:34][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[12/04 09:46:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.1110,	0.8355 s / batch. (data: 3.63e-04). ETA=8:11:25, max mem: 20.9 GB 
[12/04 09:47:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7657,	0.8240 s / batch. (data: 2.87e-04). ETA=8:03:19, max mem: 20.9 GB 
[12/04 09:49:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9095,	1.1814 s / batch. (data: 3.56e-01). ETA=11:30:58, max mem: 20.9 GB 
[12/04 09:51:05][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6366,	1.2877 s / batch. (data: 4.70e-01). ETA=12:30:57, max mem: 20.9 GB 
[12/04 09:52:37][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0428,	0.9640 s / batch. (data: 1.11e-01). ETA=9:20:36, max mem: 20.9 GB 
[12/04 09:53:29][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 1.32e-01, avg batch time: 0.9661, average train loss: 0.8099
[12/04 09:54:23][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-05, avg batch time: 0.3122, average loss: 0.7743
[12/04 09:54:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.74	
[12/04 09:54:23][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[12/04 09:56:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6800,	0.8394 s / batch. (data: 3.01e-04). ETA=8:05:59, max mem: 20.9 GB 
[12/04 09:57:38][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7833,	0.8471 s / batch. (data: 1.06e-02). ETA=8:09:01, max mem: 20.9 GB 
[12/04 09:59:16][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5706,	0.8250 s / batch. (data: 4.34e-04). ETA=7:54:54, max mem: 20.9 GB 
[12/04 10:00:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5608,	0.8279 s / batch. (data: 3.39e-04). ETA=7:55:10, max mem: 20.9 GB 
[12/04 10:02:28][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6420,	0.8267 s / batch. (data: 5.69e-03). ETA=7:53:08, max mem: 20.9 GB 
[12/04 10:03:17][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 1.30e-01, avg batch time: 0.9640, average train loss: 0.8278
[12/04 10:04:11][INFO] visual_prompt:  316: Inference (val):avg data time: 1.74e-04, avg batch time: 0.3102, average loss: 0.8743
[12/04 10:04:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.12	
[12/04 10:04:11][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[12/04 10:05:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2804,	0.8366 s / batch. (data: 3.18e-04). ETA=7:56:39, max mem: 20.9 GB 
[12/04 10:07:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0423,	0.8211 s / batch. (data: 2.86e-04). ETA=7:46:27, max mem: 20.9 GB 
[12/04 10:09:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.9020,	0.8360 s / batch. (data: 7.96e-03). ETA=7:53:32, max mem: 20.9 GB 
[12/04 10:10:40][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6270,	1.2977 s / batch. (data: 4.71e-01). ETA=12:12:54, max mem: 20.9 GB 
[12/04 10:12:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7777,	1.4834 s / batch. (data: 6.38e-01). ETA=13:55:16, max mem: 20.9 GB 
[12/04 10:13:03][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 1.27e-01, avg batch time: 0.9609, average train loss: 0.8609
[12/04 10:13:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3113, average loss: 0.9256
[12/04 10:13:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.24	
[12/04 10:13:57][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[12/04 10:15:38][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.0909,	0.8360 s / batch. (data: 3.16e-04). ETA=7:48:36, max mem: 20.9 GB 
[12/04 10:17:13][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2362,	0.8347 s / batch. (data: 2.95e-04). ETA=7:46:30, max mem: 20.9 GB 
[12/04 10:18:50][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3966,	0.8163 s / batch. (data: 3.02e-04). ETA=7:34:52, max mem: 20.9 GB 
[12/04 10:20:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1069,	0.8360 s / batch. (data: 7.80e-04). ETA=7:44:25, max mem: 20.9 GB 
[12/04 10:22:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7662,	0.8352 s / batch. (data: 1.30e-02). ETA=7:42:34, max mem: 20.9 GB 
[12/04 10:22:52][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 1.32e-01, avg batch time: 0.9657, average train loss: 0.9662
[12/04 10:23:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3089, average loss: 0.7024
[12/04 10:23:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.97	
[12/04 10:23:46][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.1875
[12/04 10:25:30][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6272,	0.8408 s / batch. (data: 2.92e-04). ETA=7:43:34, max mem: 20.9 GB 
[12/04 10:27:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1757,	0.8315 s / batch. (data: 7.20e-04). ETA=7:37:01, max mem: 20.9 GB 
[12/04 10:28:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7744,	0.8389 s / batch. (data: 3.69e-04). ETA=7:39:43, max mem: 20.9 GB 
[12/04 10:30:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7777,	0.8400 s / batch. (data: 2.86e-04). ETA=7:38:54, max mem: 20.9 GB 
[12/04 10:31:49][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4933,	0.8479 s / batch. (data: 4.39e-04). ETA=7:41:50, max mem: 20.9 GB 
[12/04 10:32:37][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 1.25e-01, avg batch time: 0.9603, average train loss: 0.8583
[12/04 10:33:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.65e-05, avg batch time: 0.3108, average loss: 0.7902
[12/04 10:33:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.68	
[12/04 10:33:31][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[12/04 10:35:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7258,	0.8360 s / batch. (data: 5.42e-03). ETA=7:33:12, max mem: 20.9 GB 
[12/04 10:36:47][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.2320,	0.8515 s / batch. (data: 1.56e-02). ETA=7:40:11, max mem: 20.9 GB 
[12/04 10:38:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9843,	0.8394 s / batch. (data: 2.89e-04). ETA=7:32:16, max mem: 20.9 GB 
[12/04 10:39:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7143,	0.8507 s / batch. (data: 1.05e-02). ETA=7:36:55, max mem: 20.9 GB 
[12/04 10:41:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8898,	0.8363 s / batch. (data: 1.05e-02). ETA=7:27:46, max mem: 20.9 GB 
[12/04 10:42:31][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 1.41e-01, avg batch time: 0.9751, average train loss: 0.8540
[12/04 10:44:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.44e-05, avg batch time: 0.3065, average loss: 0.7190
[12/04 10:44:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.46	
[12/04 10:44:03][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[12/04 10:46:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8209,	0.8090 s / batch. (data: 2.32e-04). ETA=7:11:05, max mem: 20.9 GB 
[12/04 10:49:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7926,	0.8472 s / batch. (data: 2.38e-03). ETA=7:30:04, max mem: 20.9 GB 
[12/04 10:52:36][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7415,	0.8136 s / batch. (data: 2.16e-04). ETA=7:10:50, max mem: 20.9 GB 
[12/04 10:55:20][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8829,	0.8364 s / batch. (data: 3.16e-04). ETA=7:21:31, max mem: 20.9 GB 
[12/04 10:57:52][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5658,	0.8110 s / batch. (data: 2.69e-04). ETA=7:06:45, max mem: 20.9 GB 
[12/04 10:59:18][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 8.37e-01, avg batch time: 1.6548, average train loss: 0.8125
[12/04 11:00:14][INFO] visual_prompt:  316: Inference (val):avg data time: 2.09e-04, avg batch time: 0.3063, average loss: 0.7209
[12/04 11:00:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.73	
[12/04 11:00:14][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[12/04 11:01:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5748,	0.8195 s / batch. (data: 3.02e-04). ETA=7:09:09, max mem: 20.9 GB 
[12/04 11:03:32][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6390,	0.8523 s / batch. (data: 7.88e-04). ETA=7:24:56, max mem: 20.9 GB 
[12/04 11:05:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5694,	0.8320 s / batch. (data: 2.79e-04). ETA=7:12:55, max mem: 20.9 GB 
[12/04 11:06:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7306,	0.8441 s / batch. (data: 3.14e-04). ETA=7:17:48, max mem: 20.9 GB 
[12/04 11:08:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7828,	0.8363 s / batch. (data: 3.04e-04). ETA=7:12:22, max mem: 20.9 GB 
[12/04 11:09:05][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 1.26e-01, avg batch time: 0.9606, average train loss: 0.7939
[12/04 11:10:04][INFO] visual_prompt:  316: Inference (val):avg data time: 2.26e-04, avg batch time: 0.3102, average loss: 0.7000
[12/04 11:10:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.13	
[12/04 11:10:04][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[12/04 11:12:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7212,	0.8115 s / batch. (data: 3.11e-04). ETA=6:57:30, max mem: 20.9 GB 
[12/04 11:14:35][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7743,	4.9367 s / batch. (data: 4.12e+00). ETA=1 day, 18:11:33, max mem: 20.9 GB 
[12/04 11:16:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9352,	0.8372 s / batch. (data: 3.02e-04). ETA=7:07:56, max mem: 20.9 GB 
[12/04 11:18:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8498,	0.8405 s / batch. (data: 8.24e-04). ETA=7:08:11, max mem: 20.9 GB 
[12/04 11:20:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9335,	0.8456 s / batch. (data: 3.00e-04). ETA=7:09:25, max mem: 20.9 GB 
[12/04 11:21:50][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 4.54e-01, avg batch time: 1.2775, average train loss: 0.7626
[12/04 11:23:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.15e-05, avg batch time: 0.3042, average loss: 1.1311
[12/04 11:23:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.29	
[12/04 11:23:09][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[12/04 11:25:00][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9157,	0.8280 s / batch. (data: 3.09e-04). ETA=6:58:20, max mem: 20.9 GB 
[12/04 11:26:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.4457,	0.8181 s / batch. (data: 3.09e-04). ETA=6:51:58, max mem: 20.9 GB 
[12/04 11:28:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7079,	0.8517 s / batch. (data: 1.17e-02). ETA=7:07:29, max mem: 20.9 GB 
[12/04 11:30:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9115,	0.8171 s / batch. (data: 2.95e-04). ETA=6:48:46, max mem: 20.9 GB 
[12/04 11:31:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3124,	0.8209 s / batch. (data: 3.71e-03). ETA=6:49:16, max mem: 20.9 GB 
[12/04 11:32:36][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 1.94e-01, avg batch time: 1.0236, average train loss: 1.0036
[12/04 11:33:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.48e-05, avg batch time: 0.3089, average loss: 0.6927
[12/04 11:33:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.21	
[12/04 11:33:33][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[12/04 11:35:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7017,	0.8354 s / batch. (data: 3.46e-04). ETA=6:54:23, max mem: 20.9 GB 
[12/04 11:36:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7019,	1.0943 s / batch. (data: 2.52e-01). ETA=9:00:59, max mem: 20.9 GB 
[12/04 11:38:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6901,	0.8255 s / batch. (data: 3.03e-04). ETA=6:46:43, max mem: 20.9 GB 
[12/04 11:40:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7228,	0.8176 s / batch. (data: 2.90e-04). ETA=6:41:27, max mem: 20.9 GB 
[12/04 11:41:50][INFO] visual_prompt:  204: 	Training 500/553. train loss: 2.2719,	0.8407 s / batch. (data: 4.66e-03). ETA=6:51:24, max mem: 20.9 GB 
[12/04 11:42:51][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 1.77e-01, avg batch time: 1.0088, average train loss: 0.8582
[12/04 11:43:52][INFO] visual_prompt:  316: Inference (val):avg data time: 3.42e-05, avg batch time: 0.3076, average loss: 0.7338
[12/04 11:43:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.27	
[12/04 11:43:52][INFO] visual_prompt:   42: Stopping early.
