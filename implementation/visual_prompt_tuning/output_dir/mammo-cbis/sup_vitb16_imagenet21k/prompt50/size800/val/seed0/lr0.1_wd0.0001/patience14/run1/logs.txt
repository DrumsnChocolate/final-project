[12/01 12:41:39][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[12/01 12:41:39][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 12:41:39][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '4', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '800', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[12/01 12:41:39][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 12:41:39][INFO] visual_prompt:  108: Training with config:
[12/01 12:41:39][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size800/val/seed0/lr0.1_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 800, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 4, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/01 12:41:39][INFO] visual_prompt:   55: Loading training data...
[12/01 12:41:39][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[12/01 12:41:39][INFO] visual_prompt:   57: Loading validation data...
[12/01 12:41:39][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[12/01 12:41:39][INFO] visual_prompt:   38: Constructing models...
[12/01 12:41:48][INFO] visual_prompt:   52: Total Parameters: 88030466	 Gradient Parameters: 462338
[12/01 12:41:48][INFO] visual_prompt:   54: tuned percent:0.525
[12/01 12:41:48][INFO] visual_prompt:   40: Device used for model: 0
[12/01 12:41:48][INFO] visual_prompt:   40: Setting up Evaluator...
[12/01 12:41:48][INFO] visual_prompt:   42: Setting up Trainer...
[12/01 12:41:48][INFO] visual_prompt:   45: 	Setting up the optimizer...
[12/01 12:41:48][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[12/01 12:43:35][INFO] visual_prompt:  204: 	Training 100/553. train loss: 2.1087,	0.8098 s / batch. (data: 2.86e-04). ETA=12:25:01, max mem: 20.9 GB 
[12/01 12:45:16][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3578,	0.8397 s / batch. (data: 1.24e-02). ETA=12:51:09, max mem: 20.9 GB 
[12/01 12:47:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.3905,	1.4120 s / batch. (data: 5.76e-01). ETA=21:34:17, max mem: 20.9 GB 
[12/01 12:48:44][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.0383,	0.8360 s / batch. (data: 3.07e-04). ETA=12:44:56, max mem: 20.9 GB 
[12/01 12:50:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9538,	0.8278 s / batch. (data: 5.42e-03). ETA=12:36:02, max mem: 20.9 GB 
[12/01 12:51:23][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 2.15e-01, avg batch time: 1.0398, average train loss: 1.5403
[12/01 12:52:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.96e-05, avg batch time: 0.3050, average loss: 1.5201
[12/01 12:52:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.08	
[12/01 12:52:23][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/01 12:54:10][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6265,	1.5330 s / batch. (data: 6.90e-01). ETA=23:16:14, max mem: 20.9 GB 
[12/01 12:55:52][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2616,	1.4520 s / batch. (data: 6.21e-01). ETA=22:00:04, max mem: 20.9 GB 
[12/01 12:57:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7625,	1.1760 s / batch. (data: 3.41e-01). ETA=17:47:08, max mem: 20.9 GB 
[12/01 12:59:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9386,	0.8228 s / batch. (data: 2.91e-04). ETA=12:25:15, max mem: 20.9 GB 
[12/01 13:01:03][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6741,	0.8426 s / batch. (data: 2.10e-02). ETA=12:41:47, max mem: 20.9 GB 
[12/01 13:01:56][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 2.12e-01, avg batch time: 1.0365, average train loss: 0.7773
[12/01 13:02:55][INFO] visual_prompt:  316: Inference (val):avg data time: 3.86e-05, avg batch time: 0.3081, average loss: 0.7351
[12/01 13:02:55][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[12/01 13:02:55][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/01 13:04:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8010,	0.8200 s / batch. (data: 3.04e-04). ETA=12:19:17, max mem: 20.9 GB 
[12/01 13:06:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7660,	0.8154 s / batch. (data: 7.95e-03). ETA=12:13:48, max mem: 20.9 GB 
[12/01 13:08:06][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5735,	0.8383 s / batch. (data: 1.59e-02). ETA=12:32:56, max mem: 20.9 GB 
[12/01 13:09:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.6354,	0.8320 s / batch. (data: 3.12e-04). ETA=12:25:55, max mem: 20.9 GB 
[12/01 13:11:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8072,	1.4246 s / batch. (data: 6.18e-01). ETA=21:14:50, max mem: 20.9 GB 
[12/01 13:12:26][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 2.09e-01, avg batch time: 1.0331, average train loss: 0.7552
[12/01 13:13:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.92e-05, avg batch time: 0.3066, average loss: 0.7268
[12/01 13:13:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 58.34	
[12/01 13:13:26][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.03
[12/01 13:15:14][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6764,	0.8139 s / batch. (data: 2.48e-03). ETA=12:06:15, max mem: 20.9 GB 
[12/01 13:16:58][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4517,	0.8278 s / batch. (data: 5.47e-03). ETA=12:17:16, max mem: 20.9 GB 
[12/01 13:18:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6148,	1.6080 s / batch. (data: 7.92e-01). ETA=23:49:33, max mem: 20.9 GB 
[12/01 13:20:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5692,	1.5824 s / batch. (data: 7.64e-01). ETA=23:24:09, max mem: 20.9 GB 
[12/01 13:22:07][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9406,	3.7480 s / batch. (data: 2.93e+00). ETA=2 days, 7:19:31, max mem: 20.9 GB 
[12/01 13:23:01][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 2.17e-01, avg batch time: 1.0403, average train loss: 0.8193
[12/01 13:24:00][INFO] visual_prompt:  316: Inference (val):avg data time: 4.12e-05, avg batch time: 0.3054, average loss: 0.7209
[12/01 13:24:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.16	
[12/01 13:24:00][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/01 13:25:46][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4178,	0.8280 s / batch. (data: 3.48e-04). ETA=12:11:13, max mem: 20.9 GB 
[12/01 13:27:29][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7487,	1.3588 s / batch. (data: 5.40e-01). ETA=19:57:45, max mem: 20.9 GB 
[12/01 13:29:13][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9754,	0.8406 s / batch. (data: 4.16e-04). ETA=12:19:35, max mem: 20.9 GB 
[12/01 13:30:56][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9884,	0.8112 s / batch. (data: 2.70e-04). ETA=11:52:20, max mem: 20.9 GB 
[12/01 13:32:39][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5832,	0.8226 s / batch. (data: 3.04e-04). ETA=12:01:00, max mem: 20.9 GB 
[12/01 13:33:34][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 2.13e-01, avg batch time: 1.0364, average train loss: 0.8314
[12/01 13:34:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.3082, average loss: 0.6827
[12/01 13:34:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 56.66	
[12/01 13:34:33][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.05
[12/01 13:36:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6242,	0.8320 s / batch. (data: 3.19e-04). ETA=12:07:06, max mem: 20.9 GB 
[12/01 13:38:05][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5877,	0.8473 s / batch. (data: 1.64e-02). ETA=12:19:03, max mem: 20.9 GB 
[12/01 13:39:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5429,	0.8522 s / batch. (data: 1.56e-02). ETA=12:21:55, max mem: 20.9 GB 
[12/01 13:41:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5565,	0.8321 s / batch. (data: 1.19e-02). ETA=12:02:59, max mem: 20.9 GB 
[12/01 13:43:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8099,	0.8196 s / batch. (data: 1.05e-02). ETA=11:50:47, max mem: 20.9 GB 
[12/01 13:44:08][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 2.14e-01, avg batch time: 1.0389, average train loss: 0.7602
[12/01 13:45:07][INFO] visual_prompt:  316: Inference (val):avg data time: 3.57e-05, avg batch time: 0.3055, average loss: 0.6798
[12/01 13:45:07][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 60.56	
[12/01 13:45:07][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.06
[12/01 13:46:52][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6582,	0.8315 s / batch. (data: 1.19e-02). ETA=11:59:00, max mem: 20.9 GB 
[12/01 13:48:36][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5005,	0.8236 s / batch. (data: 1.18e-02). ETA=11:50:48, max mem: 20.9 GB 
[12/01 13:50:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7510,	1.8520 s / batch. (data: 9.97e-01). ETA=1 day, 2:35:14, max mem: 20.9 GB 
[12/01 13:52:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6171,	0.9536 s / batch. (data: 1.18e-01). ETA=13:39:46, max mem: 20.9 GB 
[12/01 13:53:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1128,	0.8231 s / batch. (data: 1.59e-02). ETA=11:46:12, max mem: 20.9 GB 
[12/01 13:54:38][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 2.09e-01, avg batch time: 1.0325, average train loss: 0.7771
[12/01 13:55:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.69e-05, avg batch time: 0.3062, average loss: 0.7506
[12/01 13:55:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.39	
[12/01 13:55:37][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/01 13:57:22][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7150,	0.8122 s / batch. (data: 3.65e-04). ETA=11:34:50, max mem: 20.9 GB 
[12/01 13:59:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3153,	0.8165 s / batch. (data: 3.16e-04). ETA=11:37:08, max mem: 20.9 GB 
[12/01 14:00:51][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8282,	0.8480 s / batch. (data: 3.04e-04). ETA=12:02:38, max mem: 20.9 GB 
[12/01 14:02:34][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6084,	0.8211 s / batch. (data: 3.09e-04). ETA=11:38:19, max mem: 20.9 GB 
[12/01 14:04:17][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9699,	1.5972 s / batch. (data: 7.47e-01). ETA=22:35:42, max mem: 20.9 GB 
[12/01 14:05:11][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 2.13e-01, avg batch time: 1.0376, average train loss: 0.7740
[12/01 14:06:10][INFO] visual_prompt:  316: Inference (val):avg data time: 1.65e-04, avg batch time: 0.3070, average loss: 0.8966
[12/01 14:06:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.31	
[12/01 14:06:10][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/01 14:07:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6805,	0.8361 s / batch. (data: 2.70e-02). ETA=11:47:35, max mem: 20.9 GB 
[12/01 14:09:39][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6354,	0.8207 s / batch. (data: 1.29e-02). ETA=11:33:07, max mem: 20.9 GB 
[12/01 14:11:24][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6115,	1.5503 s / batch. (data: 7.27e-01). ETA=21:46:49, max mem: 20.9 GB 
[12/01 14:13:07][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5351,	0.8120 s / batch. (data: 3.07e-04). ETA=11:23:06, max mem: 20.9 GB 
[12/01 14:14:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9439,	1.0823 s / batch. (data: 2.44e-01). ETA=15:08:42, max mem: 20.9 GB 
[12/01 14:15:44][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 2.13e-01, avg batch time: 1.0371, average train loss: 0.7596
[12/01 14:16:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.3072, average loss: 0.7185
[12/01 14:16:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 64.10	
[12/01 14:16:43][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/01 14:18:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6646,	0.8370 s / batch. (data: 1.05e-02). ETA=11:40:38, max mem: 20.9 GB 
[12/01 14:20:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5143,	0.8280 s / batch. (data: 7.94e-03). ETA=11:31:41, max mem: 20.9 GB 
[12/01 14:21:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4989,	1.5961 s / batch. (data: 7.81e-01). ETA=22:10:43, max mem: 20.9 GB 
[12/01 14:23:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6560,	0.9320 s / batch. (data: 9.11e-02). ETA=12:55:28, max mem: 20.9 GB 
[12/01 14:25:22][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.9120,	1.0913 s / batch. (data: 2.48e-01). ETA=15:06:13, max mem: 20.9 GB 
[12/01 14:26:17][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 2.14e-01, avg batch time: 1.0371, average train loss: 0.7746
[12/01 14:27:16][INFO] visual_prompt:  316: Inference (val):avg data time: 3.40e-04, avg batch time: 0.3064, average loss: 1.0198
[12/01 14:27:16][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.63	
[12/01 14:27:16][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.1
[12/01 14:29:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5947,	0.8160 s / batch. (data: 3.49e-04). ETA=11:15:31, max mem: 20.9 GB 
[12/01 14:30:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.8940,	0.8164 s / batch. (data: 7.95e-03). ETA=11:14:29, max mem: 20.9 GB 
[12/01 14:32:33][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7495,	1.3063 s / batch. (data: 4.88e-01). ETA=17:57:04, max mem: 20.9 GB 
[12/01 14:34:15][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7169,	0.8280 s / batch. (data: 3.42e-04). ETA=11:21:18, max mem: 20.9 GB 
[12/01 14:35:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6069,	0.8112 s / batch. (data: 2.95e-04). ETA=11:06:09, max mem: 20.9 GB 
[12/01 14:36:50][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 2.13e-01, avg batch time: 1.0367, average train loss: 0.7998
[12/01 14:37:49][INFO] visual_prompt:  316: Inference (val):avg data time: 3.70e-05, avg batch time: 0.3052, average loss: 0.7757
[12/01 14:37:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 64.18	
[12/01 14:37:49][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/01 14:39:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7897,	0.9553 s / batch. (data: 1.36e-01). ETA=13:01:59, max mem: 20.9 GB 
[12/01 14:41:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6715,	0.8331 s / batch. (data: 5.48e-03). ETA=11:20:34, max mem: 20.9 GB 
[12/01 14:43:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6489,	0.8279 s / batch. (data: 4.02e-04). ETA=11:15:00, max mem: 20.9 GB 
[12/01 14:44:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.0776,	0.8184 s / batch. (data: 4.18e-04). ETA=11:05:51, max mem: 20.9 GB 
[12/01 14:46:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2660,	0.8331 s / batch. (data: 8.09e-04). ETA=11:16:24, max mem: 20.9 GB 
[12/01 14:47:23][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 2.15e-01, avg batch time: 1.0383, average train loss: 0.7510
[12/01 14:48:22][INFO] visual_prompt:  316: Inference (val):avg data time: 4.09e-05, avg batch time: 0.3068, average loss: 1.2077
[12/01 14:48:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.69	
[12/01 14:48:22][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/01 14:50:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7846,	0.8256 s / batch. (data: 9.51e-03). ETA=11:08:12, max mem: 20.9 GB 
[12/01 14:51:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6277,	0.8229 s / batch. (data: 3.74e-04). ETA=11:04:38, max mem: 20.9 GB 
[12/01 14:53:35][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7024,	1.9200 s / batch. (data: 1.10e+00). ETA=1 day, 1:47:40, max mem: 20.9 GB 
[12/01 14:55:17][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9833,	0.8340 s / batch. (data: 5.44e-03). ETA=11:10:51, max mem: 20.9 GB 
[12/01 14:57:01][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6022,	0.8143 s / batch. (data: 3.10e-04). ETA=10:53:39, max mem: 20.9 GB 
[12/01 14:57:54][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 2.08e-01, avg batch time: 1.0335, average train loss: 0.7644
[12/01 14:58:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.66e-05, avg batch time: 0.3061, average loss: 0.6954
[12/01 14:58:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.55	
[12/01 14:58:53][INFO] visual_prompt:   36: Best epoch 13: best metric: -0.695
[12/01 14:58:53][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/01 15:00:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7094,	0.8647 s / batch. (data: 2.06e-02). ETA=11:31:53, max mem: 20.9 GB 
[12/01 15:02:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5219,	1.3956 s / batch. (data: 5.83e-01). ETA=18:34:24, max mem: 20.9 GB 
[12/01 15:04:07][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7927,	0.8540 s / batch. (data: 3.15e-02). ETA=11:20:28, max mem: 20.9 GB 
[12/01 15:05:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8142,	0.8387 s / batch. (data: 6.58e-03). ETA=11:06:55, max mem: 20.9 GB 
[12/01 15:07:33][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9324,	0.8234 s / batch. (data: 5.53e-03). ETA=10:53:23, max mem: 20.9 GB 
[12/01 15:08:26][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 2.11e-01, avg batch time: 1.0351, average train loss: 0.7312
[12/01 15:09:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.60e-05, avg batch time: 0.3070, average loss: 0.7078
[12/01 15:09:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.65	
[12/01 15:09:25][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/01 15:11:12][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8414,	0.8331 s / batch. (data: 3.36e-04). ETA=10:58:56, max mem: 20.9 GB 
[12/01 15:12:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0052,	0.8353 s / batch. (data: 5.46e-03). ETA=10:59:17, max mem: 20.9 GB 
[12/01 15:14:39][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4177,	0.8342 s / batch. (data: 5.47e-03). ETA=10:57:03, max mem: 20.9 GB 
[12/01 15:16:19][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3850,	0.8280 s / batch. (data: 3.09e-04). ETA=10:50:47, max mem: 20.9 GB 
[12/01 15:18:04][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.8735,	0.8211 s / batch. (data: 2.97e-04). ETA=10:44:00, max mem: 20.9 GB 
[12/01 15:18:58][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 2.13e-01, avg batch time: 1.0358, average train loss: 0.7632
[12/01 15:19:57][INFO] visual_prompt:  316: Inference (val):avg data time: 3.51e-05, avg batch time: 0.3069, average loss: 0.8663
[12/01 15:19:57][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.07	
[12/01 15:19:57][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/01 15:21:42][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4721,	0.8309 s / batch. (data: 1.48e-02). ETA=10:49:33, max mem: 20.9 GB 
[12/01 15:23:27][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.0872,	0.8168 s / batch. (data: 9.64e-03). ETA=10:37:08, max mem: 20.9 GB 
[12/01 15:25:10][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.1451,	0.8816 s / batch. (data: 2.56e-02). ETA=11:26:16, max mem: 20.9 GB 
[12/01 15:26:53][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3235,	0.8344 s / batch. (data: 8.99e-04). ETA=10:48:06, max mem: 20.9 GB 
[12/01 15:28:35][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.2523,	1.3519 s / batch. (data: 5.43e-01). ETA=17:27:47, max mem: 20.9 GB 
[12/01 15:29:29][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 2.10e-01, avg batch time: 1.0348, average train loss: 0.7254
[12/01 15:30:29][INFO] visual_prompt:  316: Inference (val):avg data time: 3.71e-05, avg batch time: 0.3078, average loss: 0.6363
[12/01 15:30:29][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.57	
[12/01 15:30:29][INFO] visual_prompt:   36: Best epoch 16: best metric: -0.636
[12/01 15:30:29][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/01 15:32:15][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3604,	0.8243 s / batch. (data: 4.76e-04). ETA=10:36:47, max mem: 20.9 GB 
[12/01 15:34:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.9815,	0.8109 s / batch. (data: 4.16e-04). ETA=10:25:04, max mem: 20.9 GB 
[12/01 15:35:42][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.2304,	0.8193 s / batch. (data: 3.34e-04). ETA=10:30:12, max mem: 20.9 GB 
[12/01 15:37:24][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6718,	1.2320 s / batch. (data: 4.14e-01). ETA=15:45:35, max mem: 20.9 GB 
[12/01 15:39:06][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5687,	1.8767 s / batch. (data: 1.05e+00). ETA=23:57:16, max mem: 20.9 GB 
[12/01 15:40:01][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 2.10e-01, avg batch time: 1.0352, average train loss: 0.6980
[12/01 15:41:00][INFO] visual_prompt:  316: Inference (val):avg data time: 4.00e-05, avg batch time: 0.3057, average loss: 0.7770
[12/01 15:41:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.62	
[12/01 15:41:00][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/01 15:42:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5526,	0.8381 s / batch. (data: 7.08e-04). ETA=10:39:44, max mem: 20.9 GB 
[12/01 15:44:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6147,	0.8559 s / batch. (data: 1.03e-03). ETA=10:51:55, max mem: 20.9 GB 
[12/01 15:46:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4375,	0.8210 s / batch. (data: 1.32e-02). ETA=10:23:55, max mem: 20.9 GB 
[12/01 15:48:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7208,	0.8348 s / batch. (data: 1.05e-02). ETA=10:33:04, max mem: 20.9 GB 
[12/01 15:49:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6741,	0.8241 s / batch. (data: 1.55e-02). ETA=10:23:34, max mem: 20.9 GB 
[12/01 15:50:35][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 2.14e-01, avg batch time: 1.0380, average train loss: 0.7153
[12/01 15:51:34][INFO] visual_prompt:  316: Inference (val):avg data time: 4.60e-04, avg batch time: 0.3071, average loss: 0.6302
[12/01 15:51:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.32	
[12/01 15:51:34][INFO] visual_prompt:   36: Best epoch 18: best metric: -0.630
[12/01 15:51:34][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/01 15:53:20][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2634,	0.9120 s / batch. (data: 7.90e-02). ETA=11:27:43, max mem: 20.9 GB 
[12/01 15:55:03][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5345,	0.8108 s / batch. (data: 3.06e-04). ETA=10:10:04, max mem: 20.9 GB 
[12/01 15:56:47][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4904,	0.8227 s / batch. (data: 1.13e-02). ETA=10:17:40, max mem: 20.9 GB 
[12/01 15:58:32][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3932,	0.8136 s / batch. (data: 3.24e-04). ETA=10:09:29, max mem: 20.9 GB 
[12/01 16:00:10][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7870,	0.8697 s / batch. (data: 1.37e-02). ETA=10:50:04, max mem: 20.9 GB 
[12/01 16:01:04][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 2.06e-01, avg batch time: 1.0309, average train loss: 0.7050
[12/01 16:02:03][INFO] visual_prompt:  316: Inference (val):avg data time: 3.56e-05, avg batch time: 0.3067, average loss: 0.7530
[12/01 16:02:03][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.12	
[12/01 16:02:03][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/01 16:03:48][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.6583,	0.8428 s / batch. (data: 1.06e-02). ETA=10:27:45, max mem: 20.9 GB 
[12/01 16:05:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3161,	0.8240 s / batch. (data: 3.13e-04). ETA=10:12:24, max mem: 20.9 GB 
[12/01 16:07:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7349,	0.8232 s / batch. (data: 3.67e-04). ETA=10:10:24, max mem: 20.9 GB 
[12/01 16:08:59][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6471,	0.8335 s / batch. (data: 3.32e-04). ETA=10:16:40, max mem: 20.9 GB 
[12/01 16:10:41][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3095,	0.8186 s / batch. (data: 2.90e-04). ETA=10:04:17, max mem: 20.9 GB 
[12/01 16:11:36][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 2.13e-01, avg batch time: 1.0363, average train loss: 0.7344
[12/01 16:12:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.55e-05, avg batch time: 0.3066, average loss: 0.6733
[12/01 16:12:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.66	
[12/01 16:12:36][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/01 16:14:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4429,	1.6457 s / batch. (data: 8.18e-01). ETA=20:10:41, max mem: 20.9 GB 
[12/01 16:16:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3585,	0.8091 s / batch. (data: 3.62e-04). ETA=9:53:54, max mem: 20.9 GB 
[12/01 16:17:49][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0149,	1.0880 s / batch. (data: 2.54e-01). ETA=13:16:46, max mem: 20.9 GB 
[12/01 16:19:31][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5129,	0.8240 s / batch. (data: 3.04e-04). ETA=10:02:04, max mem: 20.9 GB 
[12/01 16:21:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6940,	0.8400 s / batch. (data: 2.55e-04). ETA=10:12:21, max mem: 20.9 GB 
[12/01 16:22:09][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 2.12e-01, avg batch time: 1.0354, average train loss: 0.6990
[12/01 16:23:08][INFO] visual_prompt:  316: Inference (val):avg data time: 3.68e-05, avg batch time: 0.3044, average loss: 0.6145
[12/01 16:23:08][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.59	
[12/01 16:23:08][INFO] visual_prompt:   36: Best epoch 21: best metric: -0.614
[12/01 16:23:08][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/01 16:24:54][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7278,	0.8424 s / batch. (data: 1.05e-02). ETA=10:11:56, max mem: 20.9 GB 
[12/01 16:26:37][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4200,	0.8440 s / batch. (data: 3.61e-04). ETA=10:11:43, max mem: 20.9 GB 
[12/01 16:28:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2538,	0.8191 s / batch. (data: 3.11e-04). ETA=9:52:17, max mem: 20.9 GB 
[12/01 16:30:02][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7925,	0.8234 s / batch. (data: 3.12e-04). ETA=9:54:04, max mem: 20.9 GB 
[12/01 16:31:45][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0197,	0.8400 s / batch. (data: 2.97e-04). ETA=10:04:37, max mem: 20.9 GB 
[12/01 16:32:40][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 2.10e-01, avg batch time: 1.0348, average train loss: 0.7016
[12/01 16:33:39][INFO] visual_prompt:  316: Inference (val):avg data time: 2.19e-04, avg batch time: 0.3054, average loss: 0.6464
[12/01 16:33:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 73.45	
[12/01 16:33:39][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/01 16:35:28][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8485,	0.8160 s / batch. (data: 4.10e-04). ETA=9:45:14, max mem: 20.9 GB 
[12/01 16:37:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6734,	0.8677 s / batch. (data: 5.66e-02). ETA=10:20:54, max mem: 20.9 GB 
[12/01 16:38:57][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.5267,	0.8640 s / batch. (data: 2.97e-04). ETA=10:16:48, max mem: 20.9 GB 
[12/01 16:40:38][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5009,	0.8267 s / batch. (data: 3.12e-04). ETA=9:48:49, max mem: 20.9 GB 
[12/01 16:42:20][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5974,	0.8455 s / batch. (data: 1.05e-02). ETA=10:00:45, max mem: 20.9 GB 
[12/01 16:43:13][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 2.14e-01, avg batch time: 1.0383, average train loss: 0.6758
[12/01 16:44:13][INFO] visual_prompt:  316: Inference (val):avg data time: 3.61e-05, avg batch time: 0.3035, average loss: 0.6746
[12/01 16:44:13][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 72.25	
[12/01 16:44:13][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/01 16:45:58][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.9864,	0.8094 s / batch. (data: 3.05e-04). ETA=9:33:05, max mem: 20.9 GB 
[12/01 16:47:42][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8586,	0.8397 s / batch. (data: 5.81e-03). ETA=9:53:05, max mem: 20.9 GB 
[12/01 16:49:27][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6382,	1.1446 s / batch. (data: 3.02e-01). ETA=13:26:35, max mem: 20.9 GB 
[12/01 16:51:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3481,	0.8146 s / batch. (data: 3.06e-04). ETA=9:32:40, max mem: 20.9 GB 
[12/01 16:52:56][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5297,	0.8385 s / batch. (data: 3.29e-04). ETA=9:48:05, max mem: 20.9 GB 
[12/01 16:53:51][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 2.20e-01, avg batch time: 1.0433, average train loss: 0.7003
[12/01 16:54:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3059, average loss: 0.6441
[12/01 16:54:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.99	
[12/01 16:54:50][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/01 16:56:40][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6753,	0.8240 s / batch. (data: 3.02e-04). ETA=9:35:48, max mem: 20.9 GB 
[12/01 16:58:21][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3931,	0.8920 s / batch. (data: 6.83e-02). ETA=10:21:49, max mem: 20.9 GB 
[12/01 17:00:04][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5303,	0.8363 s / batch. (data: 5.45e-03). ETA=9:41:38, max mem: 20.9 GB 
[12/01 17:01:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.7206,	0.8246 s / batch. (data: 5.55e-03). ETA=9:32:06, max mem: 20.9 GB 
[12/01 17:03:31][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7247,	0.8361 s / batch. (data: 1.05e-02). ETA=9:38:41, max mem: 20.9 GB 
[12/01 17:04:26][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 2.18e-01, avg batch time: 1.0414, average train loss: 0.6811
[12/01 17:05:26][INFO] visual_prompt:  316: Inference (val):avg data time: 3.71e-05, avg batch time: 0.3054, average loss: 0.6921
[12/01 17:05:26][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.80	
[12/01 17:05:26][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/01 17:07:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2271,	0.8241 s / batch. (data: 1.07e-02). ETA=9:28:18, max mem: 20.9 GB 
[12/01 17:09:00][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6226,	1.9900 s / batch. (data: 1.17e+00). ETA=22:48:55, max mem: 20.9 GB 
[12/01 17:10:45][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7106,	0.8400 s / batch. (data: 3.86e-04). ETA=9:36:26, max mem: 20.9 GB 
[12/01 17:12:27][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5168,	0.8529 s / batch. (data: 9.03e-03). ETA=9:43:50, max mem: 20.9 GB 
[12/01 17:14:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4132,	0.8181 s / batch. (data: 2.99e-04). ETA=9:18:41, max mem: 20.9 GB 
[12/01 17:15:03][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 2.21e-01, avg batch time: 1.0440, average train loss: 0.6779
[12/01 17:16:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.90e-05, avg batch time: 0.3065, average loss: 0.6556
[12/01 17:16:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.91	
[12/01 17:16:02][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/01 17:17:50][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6711,	0.8400 s / batch. (data: 3.14e-04). ETA=9:31:30, max mem: 20.9 GB 
[12/01 17:19:33][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5084,	1.6331 s / batch. (data: 8.18e-01). ETA=18:28:22, max mem: 20.9 GB 
[12/01 17:21:18][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6906,	0.8097 s / batch. (data: 3.86e-04). ETA=9:08:11, max mem: 20.9 GB 
[12/01 17:23:01][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8445,	0.8519 s / batch. (data: 1.10e-03). ETA=9:35:21, max mem: 20.9 GB 
[12/01 17:24:46][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7647,	0.8400 s / batch. (data: 7.78e-04). ETA=9:25:53, max mem: 20.9 GB 
[12/01 17:25:38][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 2.16e-01, avg batch time: 1.0405, average train loss: 0.6682
[12/01 17:26:37][INFO] visual_prompt:  316: Inference (val):avg data time: 3.73e-05, avg batch time: 0.3057, average loss: 0.7004
[12/01 17:26:37][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 75.26	
[12/01 17:26:37][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/01 17:28:24][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.1672,	0.8271 s / batch. (data: 3.05e-04). ETA=9:15:05, max mem: 20.9 GB 
[12/01 17:30:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3424,	0.8183 s / batch. (data: 3.49e-04). ETA=9:07:49, max mem: 20.9 GB 
[12/01 17:31:52][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6658,	1.6560 s / batch. (data: 8.12e-01). ETA=18:25:53, max mem: 20.9 GB 
[12/01 17:33:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5723,	0.8200 s / batch. (data: 3.37e-04). ETA=9:06:14, max mem: 20.9 GB 
[12/01 17:35:16][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.4167,	0.8084 s / batch. (data: 3.34e-04). ETA=8:57:09, max mem: 20.9 GB 
[12/01 17:36:10][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 2.11e-01, avg batch time: 1.0354, average train loss: 0.6667
[12/01 17:37:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.94e-05, avg batch time: 0.3062, average loss: 0.7336
[12/01 17:37:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 72.38	
[12/01 17:37:09][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/01 17:39:03][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4591,	0.8120 s / batch. (data: 4.54e-04). ETA=8:57:27, max mem: 20.9 GB 
[12/01 17:40:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5330,	1.9732 s / batch. (data: 1.15e+00). ETA=21:42:51, max mem: 20.9 GB 
[12/01 17:42:26][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.6950,	0.8440 s / batch. (data: 7.48e-04). ETA=9:15:51, max mem: 20.9 GB 
[12/01 17:44:06][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.5692,	0.8154 s / batch. (data: 4.65e-04). ETA=8:55:39, max mem: 20.9 GB 
[12/01 17:45:51][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5814,	0.8313 s / batch. (data: 5.43e-03). ETA=9:04:44, max mem: 20.9 GB 
[12/01 17:46:44][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 2.17e-01, avg batch time: 1.0395, average train loss: 0.6651
[12/01 17:47:45][INFO] visual_prompt:  316: Inference (val):avg data time: 3.66e-05, avg batch time: 0.3057, average loss: 0.6405
[12/01 17:47:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.70	
[12/01 17:47:45][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/01 17:49:31][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7716,	0.8232 s / batch. (data: 3.08e-04). ETA=8:57:20, max mem: 20.9 GB 
[12/01 17:51:15][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6805,	0.8319 s / batch. (data: 6.36e-04). ETA=9:01:38, max mem: 20.9 GB 
[12/01 17:52:56][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.1207,	1.7551 s / batch. (data: 9.40e-01). ETA=18:59:45, max mem: 20.9 GB 
[12/01 17:54:41][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.9391,	1.3240 s / batch. (data: 5.02e-01). ETA=14:17:34, max mem: 20.9 GB 
[12/01 17:56:23][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3889,	1.5760 s / batch. (data: 7.59e-01). ETA=16:58:10, max mem: 20.9 GB 
[12/01 17:57:19][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 2.13e-01, avg batch time: 1.0374, average train loss: 0.6630
[12/01 17:58:18][INFO] visual_prompt:  316: Inference (val):avg data time: 3.73e-05, avg batch time: 0.3060, average loss: 0.6492
[12/01 17:58:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 74.81	
[12/01 17:58:18][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/01 18:00:06][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6291,	0.8240 s / batch. (data: 3.81e-04). ETA=8:50:13, max mem: 20.9 GB 
[12/01 18:01:51][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7452,	0.8280 s / batch. (data: 2.94e-04). ETA=8:51:26, max mem: 20.9 GB 
[12/01 18:03:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.8310,	0.8229 s / batch. (data: 5.42e-03). ETA=8:46:47, max mem: 20.9 GB 
[12/01 18:05:13][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4101,	1.0188 s / batch. (data: 2.02e-01). ETA=10:50:32, max mem: 20.9 GB 
[12/01 18:06:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.6200,	0.8155 s / batch. (data: 2.33e-04). ETA=8:39:21, max mem: 20.9 GB 
[12/01 18:07:49][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 2.08e-01, avg batch time: 1.0323, average train loss: 0.6558
[12/01 18:08:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.85e-05, avg batch time: 0.3062, average loss: 0.7192
[12/01 18:08:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.56	
[12/01 18:08:48][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/01 18:10:37][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6730,	0.8077 s / batch. (data: 3.22e-04). ETA=8:32:18, max mem: 20.9 GB 
[12/01 18:12:19][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.1892,	0.8280 s / batch. (data: 7.98e-03). ETA=8:43:47, max mem: 20.9 GB 
[12/01 18:14:05][INFO] visual_prompt:  204: 	Training 300/553. train loss: 1.0313,	0.8170 s / batch. (data: 5.45e-03). ETA=8:35:27, max mem: 20.9 GB 
[12/01 18:15:49][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.2480,	0.8083 s / batch. (data: 3.10e-04). ETA=8:28:37, max mem: 20.9 GB 
[12/01 18:17:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.0696,	0.8222 s / batch. (data: 7.89e-03). ETA=8:35:59, max mem: 20.9 GB 
[12/01 18:18:20][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 2.10e-01, avg batch time: 1.0346, average train loss: 0.6372
[12/01 18:19:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.71e-05, avg batch time: 0.3078, average loss: 0.7771
[12/01 18:19:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 73.26	
[12/01 18:19:19][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/01 18:21:05][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.4604,	0.8243 s / batch. (data: 1.22e-02). ETA=8:35:14, max mem: 20.9 GB 
[12/01 18:22:50][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2550,	1.7520 s / batch. (data: 9.05e-01). ETA=18:12:11, max mem: 20.9 GB 
[12/01 18:24:32][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4907,	0.8320 s / batch. (data: 3.81e-04). ETA=8:37:16, max mem: 20.9 GB 
[12/01 18:26:16][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4753,	0.8160 s / batch. (data: 3.46e-04). ETA=8:25:56, max mem: 20.9 GB 
[12/01 18:27:57][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5817,	0.8188 s / batch. (data: 5.46e-03). ETA=8:26:21, max mem: 20.9 GB 
[12/01 18:28:52][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 2.10e-01, avg batch time: 1.0349, average train loss: 0.6314
[12/01 18:29:51][INFO] visual_prompt:  316: Inference (val):avg data time: 4.05e-05, avg batch time: 0.3068, average loss: 0.6186
[12/01 18:29:51][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 72.70	
[12/01 18:29:51][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[12/01 18:31:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8224,	0.8222 s / batch. (data: 3.69e-04). ETA=8:26:22, max mem: 20.9 GB 
[12/01 18:33:20][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.1634,	0.8320 s / batch. (data: 5.44e-03). ETA=8:31:01, max mem: 20.9 GB 
[12/01 18:35:02][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5540,	0.9280 s / batch. (data: 9.25e-02). ETA=9:28:23, max mem: 20.9 GB 
[12/01 18:36:47][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4083,	0.8306 s / batch. (data: 3.13e-04). ETA=8:27:21, max mem: 20.9 GB 
[12/01 18:38:29][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2077,	1.6575 s / batch. (data: 8.30e-01). ETA=16:49:43, max mem: 20.9 GB 
[12/01 18:39:23][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 2.09e-01, avg batch time: 1.0346, average train loss: 0.6117
[12/01 18:40:22][INFO] visual_prompt:  316: Inference (val):avg data time: 1.16e-04, avg batch time: 0.3071, average loss: 0.6200
[12/01 18:40:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 70.73	rocauc: 75.07	
[12/01 18:40:22][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[12/01 18:42:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8216,	0.8440 s / batch. (data: 3.10e-04). ETA=8:32:00, max mem: 20.9 GB 
[12/01 18:43:55][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.8303,	0.8091 s / batch. (data: 3.34e-04). ETA=8:09:29, max mem: 20.9 GB 
[12/01 18:45:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4385,	0.8476 s / batch. (data: 1.16e-02). ETA=8:31:20, max mem: 20.9 GB 
[12/01 18:47:18][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3192,	0.8711 s / batch. (data: 4.14e-02). ETA=8:44:05, max mem: 20.9 GB 
[12/01 18:49:00][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.1367,	1.2075 s / batch. (data: 3.93e-01). ETA=12:04:28, max mem: 20.9 GB 
[12/01 18:49:54][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 2.09e-01, avg batch time: 1.0335, average train loss: 0.6135
[12/01 18:50:53][INFO] visual_prompt:  316: Inference (val):avg data time: 3.50e-05, avg batch time: 0.3054, average loss: 0.6024
[12/01 18:50:53][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.87	
[12/01 18:50:53][INFO] visual_prompt:   36: Best epoch 35: best metric: -0.602
[12/01 18:50:53][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[12/01 18:52:39][INFO] visual_prompt:  204: 	Training 100/553. train loss: 1.2477,	0.8448 s / batch. (data: 1.06e-02). ETA=8:24:41, max mem: 20.9 GB 
[12/01 18:54:22][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7733,	0.8267 s / batch. (data: 3.20e-04). ETA=8:12:29, max mem: 20.9 GB 
[12/01 18:56:08][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2850,	0.8293 s / batch. (data: 3.09e-04). ETA=8:12:38, max mem: 20.9 GB 
[12/01 18:57:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1896,	0.8160 s / batch. (data: 2.84e-04). ETA=8:03:25, max mem: 20.9 GB 
[12/01 18:59:34][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7816,	1.1800 s / batch. (data: 3.42e-01). ETA=11:37:04, max mem: 20.9 GB 
[12/01 19:00:24][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 2.08e-01, avg batch time: 1.0324, average train loss: 0.6499
[12/01 19:01:24][INFO] visual_prompt:  316: Inference (val):avg data time: 3.79e-05, avg batch time: 0.3064, average loss: 0.6201
[12/01 19:01:24][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.90	
[12/01 19:01:24][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[12/01 19:03:11][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.7566,	0.8707 s / batch. (data: 1.05e-02). ETA=8:32:09, max mem: 20.9 GB 
[12/01 19:04:54][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5564,	0.8360 s / batch. (data: 1.59e-02). ETA=8:10:19, max mem: 20.9 GB 
[12/01 19:06:37][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.9255,	1.8588 s / batch. (data: 1.02e+00). ETA=18:07:08, max mem: 20.9 GB 
[12/01 19:08:22][INFO] visual_prompt:  204: 	Training 400/553. train loss: 1.1941,	2.0421 s / batch. (data: 1.22e+00). ETA=19:50:56, max mem: 20.9 GB 
[12/01 19:10:02][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3860,	1.3328 s / batch. (data: 5.02e-01). ETA=12:55:05, max mem: 20.9 GB 
[12/01 19:10:57][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 2.11e-01, avg batch time: 1.0361, average train loss: 0.6255
[12/01 19:11:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.88e-05, avg batch time: 0.3064, average loss: 0.6049
[12/01 19:11:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 73.68	
[12/01 19:11:56][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[12/01 19:13:41][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.2538,	0.9750 s / batch. (data: 1.44e-01). ETA=9:24:30, max mem: 20.9 GB 
[12/01 19:15:25][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2592,	1.3511 s / batch. (data: 5.34e-01). ETA=13:00:00, max mem: 20.9 GB 
[12/01 19:17:09][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.7076,	0.8480 s / batch. (data: 3.09e-04). ETA=8:08:09, max mem: 20.9 GB 
[12/01 19:18:50][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.8075,	0.8191 s / batch. (data: 7.06e-03). ETA=7:50:09, max mem: 20.9 GB 
[12/01 19:20:36][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7657,	0.8312 s / batch. (data: 7.93e-03). ETA=7:55:41, max mem: 20.9 GB 
[12/01 19:21:28][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 2.09e-01, avg batch time: 1.0339, average train loss: 0.5917
[12/01 19:22:27][INFO] visual_prompt:  316: Inference (val):avg data time: 8.91e-05, avg batch time: 0.3078, average loss: 0.6607
[12/01 19:22:27][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.35	
[12/01 19:22:27][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[12/01 19:24:13][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8202,	0.8332 s / batch. (data: 9.12e-03). ETA=7:54:43, max mem: 20.9 GB 
[12/01 19:25:59][INFO] visual_prompt:  204: 	Training 200/553. train loss: 1.3855,	0.8161 s / batch. (data: 3.20e-04). ETA=7:43:37, max mem: 20.9 GB 
[12/01 19:27:46][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4088,	0.8152 s / batch. (data: 5.42e-03). ETA=7:41:44, max mem: 20.9 GB 
[12/01 19:29:26][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.4465,	0.8456 s / batch. (data: 3.14e-04). ETA=7:57:32, max mem: 20.9 GB 
[12/01 19:31:09][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3880,	1.8680 s / batch. (data: 1.04e+00). ETA=17:31:51, max mem: 20.9 GB 
[12/01 19:32:01][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 2.12e-01, avg batch time: 1.0372, average train loss: 0.6085
[12/01 19:33:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.83e-05, avg batch time: 0.3075, average loss: 0.6282
[12/01 19:33:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.41	
[12/01 19:33:00][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[12/01 19:34:49][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4259,	0.8563 s / batch. (data: 2.44e-02). ETA=7:59:58, max mem: 20.9 GB 
[12/01 19:36:31][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6338,	0.8111 s / batch. (data: 3.06e-04). ETA=7:33:19, max mem: 20.9 GB 
[12/01 19:38:15][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5498,	0.8416 s / batch. (data: 1.05e-02). ETA=7:48:55, max mem: 20.9 GB 
[12/01 19:39:58][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6076,	0.8359 s / batch. (data: 3.85e-04). ETA=7:44:24, max mem: 20.9 GB 
[12/01 19:41:40][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.1317,	0.8360 s / batch. (data: 5.42e-03). ETA=7:43:03, max mem: 20.9 GB 
[12/01 19:42:35][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 2.16e-01, avg batch time: 1.0393, average train loss: 0.5967
[12/01 19:43:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.72e-05, avg batch time: 0.3071, average loss: 0.6193
[12/01 19:43:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 74.90	
[12/01 19:43:34][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[12/01 19:45:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8991,	0.8125 s / batch. (data: 3.38e-04). ETA=7:27:56, max mem: 20.9 GB 
[12/01 19:47:11][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7590,	0.8222 s / batch. (data: 3.27e-04). ETA=7:31:54, max mem: 20.9 GB 
[12/01 19:48:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5127,	0.8360 s / batch. (data: 2.99e-04). ETA=7:38:09, max mem: 20.9 GB 
[12/01 19:50:35][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3045,	0.8180 s / batch. (data: 8.81e-03). ETA=7:26:52, max mem: 20.9 GB 
[12/01 19:52:15][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.4666,	0.8520 s / batch. (data: 7.06e-04). ETA=7:44:03, max mem: 20.9 GB 
[12/01 19:53:06][INFO] visual_prompt:  217: Epoch 41 / 100: avg data time: 2.09e-01, avg batch time: 1.0343, average train loss: 0.5887
[12/01 19:54:05][INFO] visual_prompt:  316: Inference (val):avg data time: 1.16e-04, avg batch time: 0.3082, average loss: 0.6687
[12/01 19:54:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.86	
[12/01 19:54:05][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[12/01 19:55:51][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4649,	0.8360 s / batch. (data: 1.59e-02). ETA=7:33:12, max mem: 20.9 GB 
[12/01 19:57:34][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4693,	0.8320 s / batch. (data: 3.05e-04). ETA=7:29:39, max mem: 20.9 GB 
[12/01 19:59:17][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4378,	0.8282 s / batch. (data: 1.21e-02). ETA=7:26:13, max mem: 20.9 GB 
[12/01 20:01:00][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3856,	0.8272 s / batch. (data: 5.44e-03). ETA=7:24:16, max mem: 20.9 GB 
[12/01 20:02:42][INFO] visual_prompt:  204: 	Training 500/553. train loss: 1.3251,	0.8200 s / batch. (data: 3.50e-04). ETA=7:19:04, max mem: 20.9 GB 
[12/01 20:03:37][INFO] visual_prompt:  217: Epoch 42 / 100: avg data time: 2.10e-01, avg batch time: 1.0339, average train loss: 0.5687
[12/01 20:04:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.87e-05, avg batch time: 0.3076, average loss: 0.6667
[12/01 20:04:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.25	
[12/01 20:04:36][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[12/01 20:06:25][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5184,	0.8160 s / batch. (data: 2.91e-04). ETA=7:14:50, max mem: 20.9 GB 
[12/01 20:08:07][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.4220,	0.8327 s / batch. (data: 8.62e-03). ETA=7:22:20, max mem: 20.9 GB 
[12/01 20:09:48][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.5956,	0.8160 s / batch. (data: 3.36e-04). ETA=7:12:07, max mem: 20.9 GB 
[12/01 20:11:30][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6648,	0.8568 s / batch. (data: 3.28e-02). ETA=7:32:18, max mem: 20.9 GB 
[12/01 20:13:14][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.2228,	0.8371 s / batch. (data: 2.10e-02). ETA=7:20:31, max mem: 20.9 GB 
[12/01 20:14:10][INFO] visual_prompt:  217: Epoch 43 / 100: avg data time: 2.12e-01, avg batch time: 1.0369, average train loss: 0.5796
[12/01 20:15:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.3078, average loss: 0.6104
[12/01 20:15:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.50	
[12/01 20:15:09][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[12/01 20:16:56][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.8414,	0.8224 s / batch. (data: 3.76e-04). ETA=7:10:40, max mem: 20.9 GB 
[12/01 20:18:41][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.7200,	0.8337 s / batch. (data: 5.54e-03). ETA=7:15:11, max mem: 20.9 GB 
[12/01 20:20:22][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2111,	0.8275 s / batch. (data: 3.27e-04). ETA=7:10:35, max mem: 20.9 GB 
[12/01 20:22:03][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6514,	0.8313 s / batch. (data: 3.16e-04). ETA=7:11:10, max mem: 20.9 GB 
[12/01 20:23:47][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.7602,	0.8182 s / batch. (data: 2.98e-04). ETA=7:03:00, max mem: 20.9 GB 
[12/01 20:24:41][INFO] visual_prompt:  217: Epoch 44 / 100: avg data time: 2.09e-01, avg batch time: 1.0340, average train loss: 0.5640
[12/01 20:25:40][INFO] visual_prompt:  316: Inference (val):avg data time: 3.64e-05, avg batch time: 0.3051, average loss: 0.6419
[12/01 20:25:40][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.80	
[12/01 20:25:40][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[12/01 20:27:29][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.6635,	0.8400 s / batch. (data: 3.27e-04). ETA=7:12:08, max mem: 20.9 GB 
[12/01 20:29:08][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.6023,	0.8165 s / batch. (data: 2.84e-04). ETA=6:58:41, max mem: 20.9 GB 
[12/01 20:30:53][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4939,	0.8093 s / batch. (data: 3.14e-04). ETA=6:53:38, max mem: 20.9 GB 
[12/01 20:32:33][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.1208,	0.8387 s / batch. (data: 3.01e-04). ETA=7:07:16, max mem: 20.9 GB 
[12/01 20:34:18][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.5563,	0.8320 s / batch. (data: 7.95e-03). ETA=7:02:30, max mem: 20.9 GB 
[12/01 20:35:12][INFO] visual_prompt:  217: Epoch 45 / 100: avg data time: 2.10e-01, avg batch time: 1.0344, average train loss: 0.5637
[12/01 20:36:11][INFO] visual_prompt:  316: Inference (val):avg data time: 3.57e-05, avg batch time: 0.3060, average loss: 0.6215
[12/01 20:36:11][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.98	
[12/01 20:36:11][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[12/01 20:37:59][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4795,	1.4681 s / batch. (data: 6.48e-01). ETA=12:21:45, max mem: 20.9 GB 
[12/01 20:39:44][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.3399,	0.8427 s / batch. (data: 1.10e-02). ETA=7:04:21, max mem: 20.9 GB 
[12/01 20:41:25][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4394,	0.8322 s / batch. (data: 5.42e-03). ETA=6:57:40, max mem: 20.9 GB 
[12/01 20:43:09][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.6162,	0.8279 s / batch. (data: 1.05e-02). ETA=6:54:09, max mem: 20.9 GB 
[12/01 20:44:48][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9253,	0.8239 s / batch. (data: 3.89e-04). ETA=6:50:48, max mem: 20.9 GB 
[12/01 20:45:44][INFO] visual_prompt:  217: Epoch 46 / 100: avg data time: 2.11e-01, avg batch time: 1.0359, average train loss: 0.5497
[12/01 20:46:43][INFO] visual_prompt:  316: Inference (val):avg data time: 3.80e-05, avg batch time: 0.3068, average loss: 0.6153
[12/01 20:46:43][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.10	
[12/01 20:46:43][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[12/01 20:48:32][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.3108,	0.8268 s / batch. (data: 5.58e-03). ETA=6:50:06, max mem: 20.9 GB 
[12/01 20:50:12][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5368,	1.4960 s / batch. (data: 6.73e-01). ETA=12:19:34, max mem: 20.9 GB 
[12/01 20:51:55][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4414,	0.8300 s / batch. (data: 2.99e-04). ETA=6:48:57, max mem: 20.9 GB 
[12/01 20:53:39][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.3589,	0.8126 s / batch. (data: 3.18e-04). ETA=6:39:02, max mem: 20.9 GB 
[12/01 20:55:21][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3077,	0.8337 s / batch. (data: 5.65e-03). ETA=6:47:58, max mem: 20.9 GB 
[12/01 20:56:15][INFO] visual_prompt:  217: Epoch 47 / 100: avg data time: 2.10e-01, avg batch time: 1.0341, average train loss: 0.5530
[12/01 20:57:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.47e-05, avg batch time: 0.3071, average loss: 0.7137
[12/01 20:57:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 71.47	
[12/01 20:57:15][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[12/01 20:59:02][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.4117,	0.8434 s / batch. (data: 1.13e-02). ETA=6:50:35, max mem: 20.9 GB 
[12/01 21:00:46][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.2178,	0.8094 s / batch. (data: 3.37e-04). ETA=6:32:40, max mem: 20.9 GB 
[12/01 21:02:31][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.2766,	2.0380 s / batch. (data: 1.23e+00). ETA=16:25:19, max mem: 20.9 GB 
[12/01 21:04:10][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.1586,	0.8212 s / batch. (data: 9.39e-03). ETA=6:35:40, max mem: 20.9 GB 
[12/01 21:05:53][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.9005,	0.8320 s / batch. (data: 3.06e-04). ETA=6:39:29, max mem: 20.9 GB 
[12/01 21:06:47][INFO] visual_prompt:  217: Epoch 48 / 100: avg data time: 2.09e-01, avg batch time: 1.0343, average train loss: 0.5116
[12/01 21:07:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.57e-05, avg batch time: 0.3061, average loss: 0.7663
[12/01 21:07:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 73.94	
[12/01 21:07:46][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[12/01 21:09:33][INFO] visual_prompt:  204: 	Training 100/553. train loss: 0.5904,	0.8280 s / batch. (data: 9.55e-04). ETA=6:35:26, max mem: 20.9 GB 
[12/01 21:11:14][INFO] visual_prompt:  204: 	Training 200/553. train loss: 0.5196,	0.8242 s / batch. (data: 5.41e-03). ETA=6:32:17, max mem: 20.9 GB 
[12/01 21:12:58][INFO] visual_prompt:  204: 	Training 300/553. train loss: 0.4563,	0.8280 s / batch. (data: 5.43e-03). ETA=6:32:42, max mem: 20.9 GB 
[12/01 21:14:43][INFO] visual_prompt:  204: 	Training 400/553. train loss: 0.2141,	0.8091 s / batch. (data: 2.98e-04). ETA=6:22:23, max mem: 20.9 GB 
[12/01 21:16:26][INFO] visual_prompt:  204: 	Training 500/553. train loss: 0.3784,	0.8520 s / batch. (data: 8.25e-04). ETA=6:41:13, max mem: 20.9 GB 
[12/01 21:17:20][INFO] visual_prompt:  217: Epoch 49 / 100: avg data time: 2.14e-01, avg batch time: 1.0378, average train loss: 0.5127
[12/01 21:18:19][INFO] visual_prompt:  316: Inference (val):avg data time: 3.89e-05, avg batch time: 0.3080, average loss: 1.0521
[12/01 21:18:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.40	
[12/01 21:18:19][INFO] visual_prompt:   42: Stopping early.
