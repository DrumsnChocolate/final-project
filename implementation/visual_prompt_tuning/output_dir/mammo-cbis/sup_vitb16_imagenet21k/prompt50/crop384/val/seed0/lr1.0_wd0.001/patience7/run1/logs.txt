[10/26 06:24:18][INFO] visual_prompt:   95: Rank of current process: 0. World size: 1
[10/26 06:24:18][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/26 06:24:18][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '16', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '384', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/26 06:24:18][INFO] visual_prompt:  101: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/26 06:24:18][INFO] visual_prompt:  108: Training with config:
[10/26 06:24:18][INFO] visual_prompt:  109: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop384/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 384, 'NO_TEST': False, 'BATCH_SIZE': 16, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/26 06:24:18][INFO] visual_prompt:   55: Loading training data...
[10/26 06:24:18][INFO] visual_prompt:   28: Constructing mammo-cbis dataset train...
[10/26 06:24:18][INFO] visual_prompt:   57: Loading validation data...
[10/26 06:24:18][INFO] visual_prompt:   28: Constructing mammo-cbis dataset val...
[10/26 06:24:18][INFO] visual_prompt:   38: Constructing models...
[10/26 06:24:20][INFO] visual_prompt:   52: Total Parameters: 86552834	 Gradient Parameters: 462338
[10/26 06:24:20][INFO] visual_prompt:   54: tuned percent:0.534
[10/26 06:24:21][INFO] visual_prompt:   40: Device used for model: 0
[10/26 06:24:21][INFO] visual_prompt:   40: Setting up Evaluator...
[10/26 06:24:21][INFO] visual_prompt:   42: Setting up Trainer...
[10/26 06:24:21][INFO] visual_prompt:   45: 	Setting up the optimizer...
[10/26 06:24:21][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[10/26 06:29:27][INFO] visual_prompt:  204: 	Training 100/139. train loss: 1.2978,	0.9258 s / batch. (data: 1.06e-03). ETA=3:32:55, max mem: 7.6 GB 
[10/26 06:31:17][INFO] visual_prompt:  217: Epoch 1 / 100: avg data time: 2.12e+00, avg batch time: 2.9950, average train loss: 1.3980
[10/26 06:32:04][INFO] visual_prompt:  316: Inference (val):avg data time: 2.98e-05, avg batch time: 0.4600, average loss: 1.3816
[10/26 06:32:04][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.22	
[10/26 06:32:04][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.1
[10/26 06:37:10][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7200,	0.8882 s / batch. (data: 2.93e-04). ETA=3:22:14, max mem: 7.6 GB 
[10/26 06:39:01][INFO] visual_prompt:  217: Epoch 2 / 100: avg data time: 2.12e+00, avg batch time: 2.9957, average train loss: 0.9858
[10/26 06:39:48][INFO] visual_prompt:  316: Inference (val):avg data time: 3.16e-05, avg batch time: 0.4616, average loss: 0.8108
[10/26 06:39:48][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.76	
[10/26 06:39:48][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.2
[10/26 06:44:55][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6939,	0.9120 s / batch. (data: 2.91e-04). ETA=3:25:31, max mem: 7.6 GB 
[10/26 06:46:45][INFO] visual_prompt:  217: Epoch 3 / 100: avg data time: 2.12e+00, avg batch time: 2.9965, average train loss: 0.8016
[10/26 06:47:32][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.4566, average loss: 0.9717
[10/26 06:47:32][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.21	
[10/26 06:47:32][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.3
[10/26 06:52:33][INFO] visual_prompt:  204: 	Training 100/139. train loss: 1.2038,	0.8624 s / batch. (data: 2.95e-04). ETA=3:12:21, max mem: 7.6 GB 
[10/26 06:54:28][INFO] visual_prompt:  217: Epoch 4 / 100: avg data time: 2.12e+00, avg batch time: 2.9945, average train loss: 0.8114
[10/26 06:55:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.37e-05, avg batch time: 0.4580, average loss: 0.6916
[10/26 06:55:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 57.87	
[10/26 06:55:15][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.4
[10/26 07:00:25][INFO] visual_prompt:  204: 	Training 100/139. train loss: 1.3243,	10.8376 s / batch. (data: 9.97e+00). ETA=1 day, 15:52:12, max mem: 7.6 GB 
[10/26 07:02:13][INFO] visual_prompt:  217: Epoch 5 / 100: avg data time: 2.13e+00, avg batch time: 3.0044, average train loss: 0.8644
[10/26 07:03:00][INFO] visual_prompt:  316: Inference (val):avg data time: 3.15e-05, avg batch time: 0.4594, average loss: 0.7176
[10/26 07:03:00][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.55	
[10/26 07:03:00][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.5
[10/26 07:08:06][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6234,	0.9084 s / batch. (data: 1.57e-02). ETA=3:18:24, max mem: 7.6 GB 
[10/26 07:09:57][INFO] visual_prompt:  217: Epoch 6 / 100: avg data time: 2.12e+00, avg batch time: 2.9977, average train loss: 0.9246
[10/26 07:10:45][INFO] visual_prompt:  316: Inference (val):avg data time: 2.98e-05, avg batch time: 0.4595, average loss: 0.6926
[10/26 07:10:45][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.99	
[10/26 07:10:45][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.6
[10/26 07:15:52][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7532,	0.8920 s / batch. (data: 2.85e-04). ETA=3:12:45, max mem: 7.6 GB 
[10/26 07:17:40][INFO] visual_prompt:  217: Epoch 7 / 100: avg data time: 2.12e+00, avg batch time: 2.9898, average train loss: 0.7706
[10/26 07:18:28][INFO] visual_prompt:  316: Inference (val):avg data time: 3.28e-05, avg batch time: 0.4608, average loss: 0.7299
[10/26 07:18:28][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.39	
[10/26 07:18:28][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.7
[10/26 07:23:35][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6929,	0.9000 s / batch. (data: 7.95e-03). ETA=3:12:24, max mem: 7.6 GB 
[10/26 07:25:25][INFO] visual_prompt:  217: Epoch 8 / 100: avg data time: 2.13e+00, avg batch time: 3.0020, average train loss: 1.0830
[10/26 07:26:12][INFO] visual_prompt:  316: Inference (val):avg data time: 2.96e-05, avg batch time: 0.4639, average loss: 0.9035
[10/26 07:26:12][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[10/26 07:26:12][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.8
[10/26 07:31:22][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.9273,	0.8794 s / batch. (data: 2.77e-04). ETA=3:05:57, max mem: 7.6 GB 
[10/26 07:33:09][INFO] visual_prompt:  217: Epoch 9 / 100: avg data time: 2.12e+00, avg batch time: 2.9966, average train loss: 0.9820
[10/26 07:33:56][INFO] visual_prompt:  316: Inference (val):avg data time: 3.31e-05, avg batch time: 0.4555, average loss: 0.7709
[10/26 07:33:56][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.40	
[10/26 07:33:56][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.9
[10/26 07:39:02][INFO] visual_prompt:  204: 	Training 100/139. train loss: 1.2031,	0.8865 s / batch. (data: 5.42e-03). ETA=3:05:24, max mem: 7.6 GB 
[10/26 07:40:52][INFO] visual_prompt:  217: Epoch 10 / 100: avg data time: 2.12e+00, avg batch time: 2.9923, average train loss: 1.1216
[10/26 07:41:39][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-05, avg batch time: 0.4621, average loss: 1.1171
[10/26 07:41:39][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.19	
[10/26 07:41:39][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 1.0
[10/26 07:46:45][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7641,	0.8880 s / batch. (data: 3.01e-04). ETA=3:03:40, max mem: 7.6 GB 
[10/26 07:48:35][INFO] visual_prompt:  217: Epoch 11 / 100: avg data time: 2.12e+00, avg batch time: 2.9921, average train loss: 0.9092
[10/26 07:49:23][INFO] visual_prompt:  316: Inference (val):avg data time: 3.02e-05, avg batch time: 0.4613, average loss: 0.7366
[10/26 07:49:23][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.87	
[10/26 07:49:23][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/26 07:54:28][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7452,	1.2920 s / batch. (data: 4.09e-01). ETA=4:24:14, max mem: 7.6 GB 
[10/26 07:56:19][INFO] visual_prompt:  217: Epoch 12 / 100: avg data time: 2.12e+00, avg batch time: 2.9939, average train loss: 0.9308
[10/26 07:57:06][INFO] visual_prompt:  316: Inference (val):avg data time: 3.04e-05, avg batch time: 0.4595, average loss: 0.7050
[10/26 07:57:06][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.05	
[10/26 07:57:06][INFO] visual_prompt:   36: Best epoch 12: best metric: -0.705
[10/26 07:57:06][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/26 08:02:15][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7638,	0.8887 s / batch. (data: 2.30e-04). ETA=2:59:41, max mem: 7.6 GB 
[10/26 08:04:03][INFO] visual_prompt:  217: Epoch 13 / 100: avg data time: 2.12e+00, avg batch time: 2.9972, average train loss: 0.9359
[10/26 08:04:50][INFO] visual_prompt:  316: Inference (val):avg data time: 3.05e-05, avg batch time: 0.4595, average loss: 0.7086
[10/26 08:04:50][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.23	
[10/26 08:04:50][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/26 08:10:00][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7420,	0.9160 s / batch. (data: 7.25e-04). ETA=3:03:05, max mem: 7.6 GB 
[10/26 08:11:47][INFO] visual_prompt:  217: Epoch 14 / 100: avg data time: 2.12e+00, avg batch time: 2.9979, average train loss: 1.2503
[10/26 08:12:34][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-05, avg batch time: 0.4600, average loss: 1.6155
[10/26 08:12:34][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.71	
[10/26 08:12:34][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/26 08:17:47][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7683,	9.5680 s / batch. (data: 8.68e+00). ETA=1 day, 7:30:19, max mem: 7.6 GB 
[10/26 08:19:32][INFO] visual_prompt:  217: Epoch 15 / 100: avg data time: 2.12e+00, avg batch time: 2.9995, average train loss: 1.1127
[10/26 08:20:19][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-05, avg batch time: 0.4608, average loss: 0.9706
[10/26 08:20:19][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.58	
[10/26 08:20:19][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/26 08:25:25][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7826,	0.9163 s / batch. (data: 2.56e-02). ETA=2:58:54, max mem: 7.6 GB 
[10/26 08:27:15][INFO] visual_prompt:  217: Epoch 16 / 100: avg data time: 2.12e+00, avg batch time: 2.9935, average train loss: 0.8691
[10/26 08:28:02][INFO] visual_prompt:  316: Inference (val):avg data time: 3.02e-05, avg batch time: 0.4589, average loss: 0.8548
[10/26 08:28:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.43	
[10/26 08:28:02][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/26 08:33:08][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7608,	3.0800 s / batch. (data: 2.19e+00). ETA=9:54:13, max mem: 7.6 GB 
[10/26 08:34:59][INFO] visual_prompt:  217: Epoch 17 / 100: avg data time: 2.12e+00, avg batch time: 2.9939, average train loss: 0.8056
[10/26 08:35:46][INFO] visual_prompt:  316: Inference (val):avg data time: 3.39e-05, avg batch time: 0.4622, average loss: 0.7540
[10/26 08:35:46][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.31	
[10/26 08:35:46][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/26 08:40:54][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6873,	3.0000 s / batch. (data: 2.12e+00). ETA=9:31:51, max mem: 7.6 GB 
[10/26 08:42:43][INFO] visual_prompt:  217: Epoch 18 / 100: avg data time: 2.12e+00, avg batch time: 2.9987, average train loss: 0.8560
[10/26 08:43:30][INFO] visual_prompt:  316: Inference (val):avg data time: 6.47e-04, avg batch time: 0.4627, average loss: 1.0237
[10/26 08:43:30][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.15	
[10/26 08:43:30][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/26 08:48:44][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7887,	10.9759 s / batch. (data: 1.01e+01). ETA=1 day, 10:26:45, max mem: 7.6 GB 
[10/26 08:50:27][INFO] visual_prompt:  217: Epoch 19 / 100: avg data time: 2.13e+00, avg batch time: 3.0029, average train loss: 0.9223
[10/26 08:51:15][INFO] visual_prompt:  316: Inference (val):avg data time: 3.34e-05, avg batch time: 0.4611, average loss: 0.6933
[10/26 08:51:15][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.03	
[10/26 08:51:15][INFO] visual_prompt:   36: Best epoch 19: best metric: -0.693
[10/26 08:51:15][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/26 08:56:19][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6241,	0.8760 s / batch. (data: 2.97e-04). ETA=2:42:55, max mem: 7.6 GB 
[10/26 08:58:11][INFO] visual_prompt:  217: Epoch 20 / 100: avg data time: 2.12e+00, avg batch time: 2.9919, average train loss: 0.9429
[10/26 08:58:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.09e-05, avg batch time: 0.4564, average loss: 0.8041
[10/26 08:58:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.67	
[10/26 08:58:58][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/26 09:04:04][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.8663,	0.8810 s / batch. (data: 7.96e-03). ETA=2:41:48, max mem: 7.6 GB 
[10/26 09:05:54][INFO] visual_prompt:  217: Epoch 21 / 100: avg data time: 2.12e+00, avg batch time: 2.9936, average train loss: 0.8885
[10/26 09:06:41][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-05, avg batch time: 0.4569, average loss: 1.5617
[10/26 09:06:41][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.50	
[10/26 09:06:41][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/26 09:11:44][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6668,	0.8800 s / batch. (data: 2.87e-04). ETA=2:39:35, max mem: 7.6 GB 
[10/26 09:13:38][INFO] visual_prompt:  217: Epoch 22 / 100: avg data time: 2.12e+00, avg batch time: 2.9985, average train loss: 0.9420
[10/26 09:14:25][INFO] visual_prompt:  316: Inference (val):avg data time: 3.18e-05, avg batch time: 0.4539, average loss: 1.7386
[10/26 09:14:25][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.53	
[10/26 09:14:25][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/26 09:19:31][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7684,	1.5800 s / batch. (data: 7.06e-01). ETA=4:42:52, max mem: 7.6 GB 
[10/26 09:21:22][INFO] visual_prompt:  217: Epoch 23 / 100: avg data time: 2.12e+00, avg batch time: 2.9981, average train loss: 1.1908
[10/26 09:22:10][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-05, avg batch time: 0.4577, average loss: 0.7394
[10/26 09:22:10][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.72	
[10/26 09:22:10][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/26 09:27:20][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7049,	0.8844 s / batch. (data: 5.90e-03). ETA=2:36:17, max mem: 7.6 GB 
[10/26 09:29:07][INFO] visual_prompt:  217: Epoch 24 / 100: avg data time: 2.13e+00, avg batch time: 3.0005, average train loss: 0.9487
[10/26 09:29:54][INFO] visual_prompt:  316: Inference (val):avg data time: 4.83e-04, avg batch time: 0.4608, average loss: 0.7168
[10/26 09:29:54][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.85	
[10/26 09:29:54][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/26 09:35:02][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6970,	0.8899 s / batch. (data: 5.43e-03). ETA=2:35:11, max mem: 7.6 GB 
[10/26 09:36:51][INFO] visual_prompt:  217: Epoch 25 / 100: avg data time: 2.12e+00, avg batch time: 2.9972, average train loss: 0.7817
[10/26 09:37:38][INFO] visual_prompt:  316: Inference (val):avg data time: 3.04e-05, avg batch time: 0.4601, average loss: 0.7087
[10/26 09:37:38][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.12	
[10/26 09:37:38][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/26 09:42:45][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.5754,	2.3520 s / batch. (data: 1.48e+00). ETA=6:44:44, max mem: 7.6 GB 
[10/26 09:44:34][INFO] visual_prompt:  217: Epoch 26 / 100: avg data time: 2.12e+00, avg batch time: 2.9931, average train loss: 0.8331
[10/26 09:45:22][INFO] visual_prompt:  316: Inference (val):avg data time: 3.13e-05, avg batch time: 0.4612, average loss: 0.6931
[10/26 09:45:22][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.88	
[10/26 09:45:22][INFO] visual_prompt:   36: Best epoch 26: best metric: -0.693
[10/26 09:45:22][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/26 09:50:34][INFO] visual_prompt:  204: 	Training 100/139. train loss: 1.0361,	9.4000 s / batch. (data: 8.53e+00). ETA=1 day, 2:35:48, max mem: 7.6 GB 
[10/26 09:52:21][INFO] visual_prompt:  217: Epoch 27 / 100: avg data time: 2.14e+00, avg batch time: 3.0180, average train loss: 0.9117
[10/26 09:53:09][INFO] visual_prompt:  316: Inference (val):avg data time: 3.00e-05, avg batch time: 0.4593, average loss: 0.7061
[10/26 09:53:09][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.20	
[10/26 09:53:09][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/26 09:58:13][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.8767,	0.8649 s / batch. (data: 2.80e-04). ETA=2:24:49, max mem: 7.6 GB 
[10/26 10:00:05][INFO] visual_prompt:  217: Epoch 28 / 100: avg data time: 2.12e+00, avg batch time: 2.9967, average train loss: 0.8004
[10/26 10:00:52][INFO] visual_prompt:  316: Inference (val):avg data time: 2.95e-05, avg batch time: 0.4608, average loss: 1.2841
[10/26 10:00:52][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[10/26 10:00:52][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[10/26 10:05:55][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6796,	0.8956 s / batch. (data: 1.04e-02). ETA=2:27:53, max mem: 7.6 GB 
[10/26 10:07:48][INFO] visual_prompt:  217: Epoch 29 / 100: avg data time: 2.11e+00, avg batch time: 2.9897, average train loss: 0.8211
[10/26 10:08:36][INFO] visual_prompt:  316: Inference (val):avg data time: 3.22e-05, avg batch time: 0.4595, average loss: 0.8018
[10/26 10:08:36][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.63	
[10/26 10:08:36][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[10/26 10:13:45][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7286,	0.9072 s / batch. (data: 2.96e-04). ETA=2:27:42, max mem: 7.6 GB 
[10/26 10:15:33][INFO] visual_prompt:  217: Epoch 30 / 100: avg data time: 2.13e+00, avg batch time: 3.0044, average train loss: 1.0815
[10/26 10:16:21][INFO] visual_prompt:  316: Inference (val):avg data time: 2.88e-05, avg batch time: 0.4623, average loss: 0.6982
[10/26 10:16:21][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.46	
[10/26 10:16:21][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.883022221559489
[10/26 10:21:33][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.8247,	0.9043 s / batch. (data: 2.34e-04). ETA=2:25:08, max mem: 7.6 GB 
[10/26 10:23:18][INFO] visual_prompt:  217: Epoch 31 / 100: avg data time: 2.13e+00, avg batch time: 3.0018, average train loss: 0.8380
[10/26 10:24:05][INFO] visual_prompt:  316: Inference (val):avg data time: 2.74e-05, avg batch time: 0.4627, average loss: 0.6884
[10/26 10:24:05][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.46	
[10/26 10:24:05][INFO] visual_prompt:   36: Best epoch 31: best metric: -0.688
[10/26 10:24:05][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[10/26 10:29:15][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.9264,	7.4219 s / batch. (data: 6.55e+00). ETA=19:34:00, max mem: 7.6 GB 
[10/26 10:31:01][INFO] visual_prompt:  217: Epoch 32 / 100: avg data time: 2.12e+00, avg batch time: 2.9931, average train loss: 0.8364
[10/26 10:31:49][INFO] visual_prompt:  316: Inference (val):avg data time: 2.95e-05, avg batch time: 0.4584, average loss: 1.6162
[10/26 10:31:49][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.75	
[10/26 10:31:49][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[10/26 10:36:56][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.7361,	0.8960 s / batch. (data: 7.69e-04). ETA=2:19:39, max mem: 7.6 GB 
[10/26 10:38:46][INFO] visual_prompt:  217: Epoch 33 / 100: avg data time: 2.13e+00, avg batch time: 3.0017, average train loss: 0.9762
[10/26 10:39:33][INFO] visual_prompt:  316: Inference (val):avg data time: 3.25e-05, avg batch time: 0.4634, average loss: 0.6881
[10/26 10:39:33][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.88	
[10/26 10:39:33][INFO] visual_prompt:   36: Best epoch 33: best metric: -0.688
[10/26 10:39:33][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[10/26 10:44:42][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6994,	3.5114 s / batch. (data: 2.60e+00). ETA=8:59:10, max mem: 7.6 GB 
[10/26 10:46:31][INFO] visual_prompt:  217: Epoch 34 / 100: avg data time: 2.13e+00, avg batch time: 3.0007, average train loss: 0.7849
[10/26 10:47:18][INFO] visual_prompt:  316: Inference (val):avg data time: 2.99e-05, avg batch time: 0.4584, average loss: 0.9819
[10/26 10:47:18][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.00	
[10/26 10:47:18][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[10/26 10:52:27][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.3764,	0.8831 s / batch. (data: 4.41e-04). ETA=2:13:33, max mem: 7.6 GB 
[10/26 10:54:15][INFO] visual_prompt:  217: Epoch 35 / 100: avg data time: 2.12e+00, avg batch time: 2.9956, average train loss: 1.2223
[10/26 10:55:02][INFO] visual_prompt:  316: Inference (val):avg data time: 2.91e-05, avg batch time: 0.4634, average loss: 0.9885
[10/26 10:55:02][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.69	
[10/26 10:55:02][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[10/26 11:00:12][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6447,	0.9151 s / batch. (data: 1.55e-02). ETA=2:16:16, max mem: 7.6 GB 
[10/26 11:01:59][INFO] visual_prompt:  217: Epoch 36 / 100: avg data time: 2.13e+00, avg batch time: 3.0025, average train loss: 0.9840
[10/26 11:02:47][INFO] visual_prompt:  316: Inference (val):avg data time: 3.07e-05, avg batch time: 0.4612, average loss: 0.7382
[10/26 11:02:47][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.98	
[10/26 11:02:47][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[10/26 11:07:53][INFO] visual_prompt:  204: 	Training 100/139. train loss: 1.1714,	0.8880 s / batch. (data: 2.74e-04). ETA=2:10:10, max mem: 7.6 GB 
[10/26 11:09:43][INFO] visual_prompt:  217: Epoch 37 / 100: avg data time: 2.12e+00, avg batch time: 2.9983, average train loss: 0.8395
[10/26 11:10:31][INFO] visual_prompt:  316: Inference (val):avg data time: 3.13e-05, avg batch time: 0.4592, average loss: 0.7616
[10/26 11:10:31][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.77	
[10/26 11:10:31][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[10/26 11:15:40][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6837,	6.8317 s / batch. (data: 5.94e+00). ETA=16:25:41, max mem: 7.6 GB 
[10/26 11:17:27][INFO] visual_prompt:  217: Epoch 38 / 100: avg data time: 2.12e+00, avg batch time: 2.9943, average train loss: 0.8953
[10/26 11:18:14][INFO] visual_prompt:  316: Inference (val):avg data time: 3.03e-05, avg batch time: 0.4583, average loss: 1.3395
[10/26 11:18:14][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[10/26 11:18:14][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[10/26 11:23:26][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6679,	0.8759 s / batch. (data: 2.97e-04). ETA=2:04:21, max mem: 7.6 GB 
[10/26 11:25:11][INFO] visual_prompt:  217: Epoch 39 / 100: avg data time: 2.12e+00, avg batch time: 2.9980, average train loss: 1.2093
[10/26 11:25:58][INFO] visual_prompt:  316: Inference (val):avg data time: 3.20e-05, avg batch time: 0.4614, average loss: 1.5052
[10/26 11:25:58][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.60	
[10/26 11:25:58][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[10/26 11:31:06][INFO] visual_prompt:  204: 	Training 100/139. train loss: 0.6636,	0.8723 s / batch. (data: 2.84e-04). ETA=2:01:48, max mem: 7.6 GB 
[10/26 11:32:55][INFO] visual_prompt:  217: Epoch 40 / 100: avg data time: 2.12e+00, avg batch time: 2.9978, average train loss: 0.9446
[10/26 11:33:42][INFO] visual_prompt:  316: Inference (val):avg data time: 3.02e-05, avg batch time: 0.4590, average loss: 1.2511
[10/26 11:33:42][INFO] visual_prompt:  113: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.57	
[10/26 11:33:42][INFO] visual_prompt:   42: Stopping early.
