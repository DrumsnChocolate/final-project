[09/16 10:30:25][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/16 10:30:26][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 10:30:26][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-svhn', 'DATA.NUMBER_CLASSES', '10', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/16 10:30:26][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 10:30:26][INFO] visual_prompt:  108: Training with config:
[09/16 10:30:26][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-svhn',
          'NO_TEST': False,
          'NUMBER_CLASSES': 10,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-svhn/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 10:30:26][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/16 10:30:37][INFO] visual_prompt:   69: Constructing vtab-svhn dataset trainval...
[09/16 10:30:39][INFO] visual_prompt:   88: Number of images: 1000
[09/16 10:30:39][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 10:30:39][INFO] visual_prompt:   70: Loading validation data...
[09/16 10:30:39][INFO] visual_prompt:   69: Constructing vtab-svhn dataset val...
[09/16 10:30:39][INFO] visual_prompt:   88: Number of images: 200
[09/16 10:30:39][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 10:30:39][INFO] visual_prompt:   73: Loading test data...
[09/16 10:30:39][INFO] visual_prompt:   69: Constructing vtab-svhn dataset test...
[09/16 10:31:11][INFO] visual_prompt:   88: Number of images: 26032
[09/16 10:31:11][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 10:31:11][INFO] visual_prompt:  100: Constructing models...
[09/16 10:31:13][INFO] visual_prompt:   53: Total Parameters: 86727946	 Gradient Parameters: 929290
[09/16 10:31:13][INFO] visual_prompt:   54: tuned percent:1.072
[09/16 10:31:16][INFO] visual_prompt:   40: Device used for model: 0
[09/16 10:31:16][INFO] visual_prompt:  103: Setting up Evalutator...
[09/16 10:31:16][INFO] visual_prompt:  105: Setting up Trainer...
[09/16 10:31:16][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/16 10:31:16][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/16 10:31:28][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 1.49e-01, avg batch time: 0.6321, average train loss: 2.4384
[09/16 10:31:32][INFO] visual_prompt:  324: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1414, average loss: 2.4273
[09/16 10:31:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 54.00	
[09/16 10:31:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.448, 0.2076 s / batch. (data: 2.69e-02)max mem: 17.22449 GB 
[09/16 10:32:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.444, 0.2080 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 10:32:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.432, 0.1819 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 10:32:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.453, 0.1827 s / batch. (data: 2.57e-05)max mem: 17.22449 GB 
[09/16 10:32:55][INFO] visual_prompt:  324: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1937, average loss: 2.4596
[09/16 10:32:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 10.66	top5: 50.76	
[09/16 10:32:55][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.120
[09/16 10:32:55][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/16 10:33:06][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 1.48e-01, avg batch time: 0.5505, average train loss: 2.7828
[09/16 10:33:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1425, average loss: 2.3508
[09/16 10:33:10][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 60.00	
[09/16 10:33:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.442, 0.1841 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 10:33:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.441, 0.1878 s / batch. (data: 5.15e-03)max mem: 17.22449 GB 
[09/16 10:34:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.331, 0.1976 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 10:34:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.429, 0.1826 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 10:34:34][INFO] visual_prompt:  324: Inference (test):avg data time: 6.84e-03, avg batch time: 0.1942, average loss: 2.3448
[09/16 10:34:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 59.67	
[09/16 10:34:34][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/16 10:34:44][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 1.40e-01, avg batch time: 0.5425, average train loss: 2.4086
[09/16 10:34:49][INFO] visual_prompt:  324: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1426, average loss: 2.3648
[09/16 10:34:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 48.50	
[09/16 10:35:10][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.400, 0.1894 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 10:35:30][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.415, 0.2165 s / batch. (data: 8.03e-05)max mem: 17.22449 GB 
[09/16 10:35:49][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.295, 0.1864 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 10:36:09][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.317, 0.1825 s / batch. (data: 2.50e-05)max mem: 17.22449 GB 
[09/16 10:36:12][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1937, average loss: 2.3401
[09/16 10:36:12][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 52.56	
[09/16 10:36:12][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/16 10:36:23][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.47e-01, avg batch time: 0.5493, average train loss: 2.4940
[09/16 10:36:27][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1424, average loss: 2.3985
[09/16 10:36:27][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 60.50	
[09/16 10:36:49][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.499, 0.1826 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 10:37:08][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.564, 0.1922 s / batch. (data: 1.04e-02)max mem: 17.22449 GB 
[09/16 10:37:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.259, 0.1981 s / batch. (data: 1.55e-02)max mem: 17.22449 GB 
[09/16 10:37:47][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.338, 0.1827 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 10:37:50][INFO] visual_prompt:  324: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1936, average loss: 2.3768
[09/16 10:37:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 61.97	
[09/16 10:37:50][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/16 10:38:01][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.44e-01, avg batch time: 0.5457, average train loss: 2.4137
[09/16 10:38:05][INFO] visual_prompt:  324: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1426, average loss: 2.5167
[09/16 10:38:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 55.00	
[09/16 10:38:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.462, 0.1895 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 10:38:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.525, 0.1826 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 10:39:06][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.538, 0.1833 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 10:39:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.483, 0.1829 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 10:39:29][INFO] visual_prompt:  324: Inference (test):avg data time: 6.90e-03, avg batch time: 0.1945, average loss: 2.4865
[09/16 10:39:29][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 54.10	
[09/16 10:39:29][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/16 10:39:39][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 1.48e-01, avg batch time: 0.5488, average train loss: 2.4390
[09/16 10:39:44][INFO] visual_prompt:  324: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1441, average loss: 2.7078
[09/16 10:39:44][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 56.50	
[09/16 10:40:06][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.794, 0.1949 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 10:40:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.642, 0.1933 s / batch. (data: 1.12e-02)max mem: 17.22449 GB 
[09/16 10:40:45][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.889, 0.1950 s / batch. (data: 1.27e-02)max mem: 17.22449 GB 
[09/16 10:41:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.725, 0.1823 s / batch. (data: 3.67e-05)max mem: 17.22449 GB 
[09/16 10:41:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1931, average loss: 2.7157
[09/16 10:41:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 53.44	
[09/16 10:41:07][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/16 10:41:17][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.53e-01, avg batch time: 0.5548, average train loss: 2.9170
[09/16 10:41:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1425, average loss: 2.8666
[09/16 10:41:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 57.50	
[09/16 10:41:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.003, 0.1974 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 10:42:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.212, 0.1951 s / batch. (data: 1.26e-02)max mem: 17.22449 GB 
[09/16 10:42:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.538, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 10:42:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.878, 0.1826 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 10:42:45][INFO] visual_prompt:  324: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1939, average loss: 2.9354
[09/16 10:42:45][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 52.39	
[09/16 10:42:45][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/16 10:42:56][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.36e-01, avg batch time: 0.5397, average train loss: 3.9574
[09/16 10:43:00][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1424, average loss: 3.9146
[09/16 10:43:00][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 62.00	
[09/16 10:43:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.209, 0.1823 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 10:43:41][INFO] visual_prompt:  314: 	Test 200/407. loss: 4.393, 0.1960 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 10:44:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.441, 0.1827 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 10:44:20][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.933, 0.1821 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 10:44:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1926, average loss: 3.8046
[09/16 10:44:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 62.13	
[09/16 10:44:23][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/16 10:44:33][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.39e-01, avg batch time: 0.5412, average train loss: 3.5399
[09/16 10:44:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1425, average loss: 2.3837
[09/16 10:44:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.00	
[09/16 10:44:59][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.767, 0.2030 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 10:45:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.702, 0.2081 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 10:45:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.464, 0.1969 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 10:45:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.505, 0.1825 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 10:46:01][INFO] visual_prompt:  324: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1943, average loss: 2.4760
[09/16 10:46:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.25	
[09/16 10:46:01][INFO] visual_prompt:  246: Best epoch 9: best metric: 0.230
[09/16 10:46:01][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/16 10:46:11][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.45e-01, avg batch time: 0.5473, average train loss: 3.7889
[09/16 10:46:16][INFO] visual_prompt:  324: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1426, average loss: 3.8237
[09/16 10:46:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 41.50	
[09/16 10:46:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.252, 0.1999 s / batch. (data: 1.85e-02)max mem: 17.22449 GB 
[09/16 10:46:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.337, 0.2312 s / batch. (data: 3.30e-02)max mem: 17.22449 GB 
[09/16 10:47:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.761, 0.1826 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 10:47:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.432, 0.1845 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 10:47:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1927, average loss: 3.6247
[09/16 10:47:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 47.29	
[09/16 10:47:39][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[09/16 10:47:50][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.47e-01, avg batch time: 0.5485, average train loss: 10.8087
[09/16 10:47:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1427, average loss: 19.7975
[09/16 10:47:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 58.00	
[09/16 10:48:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 23.608, 0.2024 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 10:48:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 21.965, 0.1960 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 10:48:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 22.560, 0.1936 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 10:49:15][INFO] visual_prompt:  314: 	Test 400/407. loss: 21.328, 0.1827 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 10:49:18][INFO] visual_prompt:  324: Inference (test):avg data time: 7.31e-03, avg batch time: 0.1954, average loss: 21.0838
[09/16 10:49:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 53.54	
[09/16 10:49:19][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 10:49:29][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 1.50e-01, avg batch time: 0.5510, average train loss: 24.4532
[09/16 10:49:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1424, average loss: 32.1398
[09/16 10:49:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 52.50	
[09/16 10:49:55][INFO] visual_prompt:  314: 	Test 100/407. loss: 35.352, 0.1959 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 10:50:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 33.059, 0.2078 s / batch. (data: 2.62e-02)max mem: 17.22449 GB 
[09/16 10:50:34][INFO] visual_prompt:  314: 	Test 300/407. loss: 33.712, 0.1828 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 10:50:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 34.246, 0.1836 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 10:50:56][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1934, average loss: 33.5498
[09/16 10:50:57][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 49.95	
[09/16 10:50:57][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 10:51:07][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.44e-01, avg batch time: 0.5451, average train loss: 22.8183
[09/16 10:51:11][INFO] visual_prompt:  324: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1425, average loss: 23.1833
[09/16 10:51:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 60.00	
[09/16 10:51:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 21.402, 0.1822 s / batch. (data: 1.52e-04)max mem: 17.22449 GB 
[09/16 10:51:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 23.402, 0.1831 s / batch. (data: 1.58e-04)max mem: 17.22449 GB 
[09/16 10:52:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 20.633, 0.1830 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 10:52:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 21.377, 0.1825 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 10:52:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.15e-03, avg batch time: 0.1948, average loss: 23.0830
[09/16 10:52:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 60.57	
[09/16 10:52:35][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 10:52:45][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 1.46e-01, avg batch time: 0.5469, average train loss: 15.7300
[09/16 10:52:50][INFO] visual_prompt:  324: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1430, average loss: 13.2177
[09/16 10:52:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.50	
[09/16 10:53:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 12.087, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 10:53:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 14.354, 0.1824 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 10:53:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 12.395, 0.1953 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 10:54:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 13.799, 0.1833 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 10:54:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1940, average loss: 13.1458
[09/16 10:54:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.14	
[09/16 10:54:13][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 10:54:24][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.42e-01, avg batch time: 0.5467, average train loss: 17.0017
[09/16 10:54:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1423, average loss: 17.8752
[09/16 10:54:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 57.50	
[09/16 10:54:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 20.151, 0.1834 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 10:55:09][INFO] visual_prompt:  314: 	Test 200/407. loss: 17.528, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 10:55:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 19.302, 0.1826 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 10:55:48][INFO] visual_prompt:  314: 	Test 400/407. loss: 17.453, 0.1825 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 10:55:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1945, average loss: 17.9141
[09/16 10:55:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 54.07	
[09/16 10:55:52][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 10:56:02][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 1.45e-01, avg batch time: 0.5465, average train loss: 19.1380
[09/16 10:56:06][INFO] visual_prompt:  324: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1424, average loss: 22.0697
[09/16 10:56:06][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.50	
[09/16 10:56:28][INFO] visual_prompt:  314: 	Test 100/407. loss: 27.320, 0.1966 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 10:56:48][INFO] visual_prompt:  314: 	Test 200/407. loss: 26.603, 0.1826 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 10:57:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 24.537, 0.2322 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 10:57:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 25.670, 0.1823 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 10:57:31][INFO] visual_prompt:  324: Inference (test):avg data time: 8.58e-03, avg batch time: 0.1958, average loss: 24.7265
[09/16 10:57:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.39	
[09/16 10:57:31][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 10:57:41][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.43e-01, avg batch time: 0.5432, average train loss: 13.3782
[09/16 10:57:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1423, average loss: 9.0408
[09/16 10:57:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 65.00	
[09/16 10:58:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 9.662, 0.1851 s / batch. (data: 8.56e-05)max mem: 17.22449 GB 
[09/16 10:58:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.912, 0.1824 s / batch. (data: 8.32e-05)max mem: 17.22449 GB 
[09/16 10:58:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.788, 0.1951 s / batch. (data: 1.28e-02)max mem: 17.22449 GB 
[09/16 10:59:06][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.938, 0.1827 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 10:59:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1931, average loss: 8.9398
[09/16 10:59:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 61.59	
[09/16 10:59:09][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 10:59:20][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.49e-01, avg batch time: 0.5491, average train loss: 11.1720
[09/16 10:59:24][INFO] visual_prompt:  324: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1426, average loss: 12.4530
[09/16 10:59:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 39.50	
[09/16 10:59:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 11.612, 0.1841 s / batch. (data: 1.97e-03)max mem: 17.22449 GB 
[09/16 11:00:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.619, 0.1828 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 11:00:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 12.426, 0.1827 s / batch. (data: 1.55e-04)max mem: 17.22449 GB 
[09/16 11:00:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 11.301, 0.1826 s / batch. (data: 2.60e-05)max mem: 17.22449 GB 
[09/16 11:00:47][INFO] visual_prompt:  324: Inference (test):avg data time: 8.57e-03, avg batch time: 0.1935, average loss: 11.5931
[09/16 11:00:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 44.83	
[09/16 11:00:47][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 11:00:58][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 1.54e-01, avg batch time: 0.5609, average train loss: 13.0142
[09/16 11:01:02][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1426, average loss: 6.9906
[09/16 11:01:02][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 57.50	
[09/16 11:01:24][INFO] visual_prompt:  314: 	Test 100/407. loss: 8.272, 0.1824 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 11:01:43][INFO] visual_prompt:  314: 	Test 200/407. loss: 7.605, 0.1969 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 11:02:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.584, 0.1975 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 11:02:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 7.789, 0.1827 s / batch. (data: 3.50e-05)max mem: 17.22449 GB 
[09/16 11:02:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1954, average loss: 7.3224
[09/16 11:02:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 54.32	
[09/16 11:02:26][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 11:02:37][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.49e-01, avg batch time: 0.5499, average train loss: 6.7343
[09/16 11:02:41][INFO] visual_prompt:  324: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1431, average loss: 6.1179
[09/16 11:02:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 60.50	
[09/16 11:03:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.634, 0.1875 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 11:03:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.040, 0.1830 s / batch. (data: 1.64e-04)max mem: 17.22449 GB 
[09/16 11:03:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 6.320, 0.1827 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 11:04:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.687, 0.1827 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 11:04:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1939, average loss: 6.1128
[09/16 11:04:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 57.08	
[09/16 11:04:05][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 11:04:15][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.51e-01, avg batch time: 0.5515, average train loss: 6.4673
[09/16 11:04:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1426, average loss: 10.0285
[09/16 11:04:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 47.00	
[09/16 11:04:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 10.110, 0.1826 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 11:05:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.109, 0.1960 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 11:05:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 9.869, 0.2080 s / batch. (data: 2.60e-02)max mem: 17.22449 GB 
[09/16 11:05:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 9.115, 0.1830 s / batch. (data: 2.81e-05)max mem: 17.22449 GB 
[09/16 11:05:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1925, average loss: 9.6981
[09/16 11:05:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 50.58	
[09/16 11:05:42][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 11:05:53][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 1.46e-01, avg batch time: 0.5463, average train loss: 10.3753
[09/16 11:05:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1428, average loss: 12.9345
[09/16 11:05:57][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 64.00	
[09/16 11:06:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 14.129, 0.1824 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 11:06:38][INFO] visual_prompt:  314: 	Test 200/407. loss: 14.707, 0.2040 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 11:06:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 12.088, 0.2039 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 11:07:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 12.920, 0.1866 s / batch. (data: 2.62e-05)max mem: 17.22449 GB 
[09/16 11:07:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1940, average loss: 12.8722
[09/16 11:07:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 63.35	
[09/16 11:07:21][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 11:07:31][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.37e-01, avg batch time: 0.5404, average train loss: 10.1350
[09/16 11:07:35][INFO] visual_prompt:  324: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1445, average loss: 10.8426
[09/16 11:07:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 56.00	
[09/16 11:07:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 14.136, 0.1972 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 11:08:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 12.050, 0.1923 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 11:08:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.954, 0.1823 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 11:08:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 9.720, 0.1824 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 11:08:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1932, average loss: 11.0407
[09/16 11:08:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 55.95	
[09/16 11:08:59][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 11:09:09][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 1.44e-01, avg batch time: 0.5459, average train loss: 12.5541
[09/16 11:09:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1424, average loss: 13.1405
[09/16 11:09:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 44.50	
[09/16 11:09:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 12.769, 0.1830 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 11:09:54][INFO] visual_prompt:  314: 	Test 200/407. loss: 12.833, 0.2074 s / batch. (data: 2.58e-02)max mem: 17.22449 GB 
[09/16 11:10:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 12.143, 0.1941 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 11:10:33][INFO] visual_prompt:  314: 	Test 400/407. loss: 12.332, 0.1826 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 11:10:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1928, average loss: 12.8791
[09/16 11:10:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 47.27	
[09/16 11:10:37][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 11:10:47][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 1.48e-01, avg batch time: 0.5535, average train loss: 9.6730
[09/16 11:10:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1423, average loss: 8.9742
[09/16 11:10:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 42.50	
[09/16 11:11:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 6.963, 0.1831 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 11:11:33][INFO] visual_prompt:  314: 	Test 200/407. loss: 7.094, 0.1820 s / batch. (data: 1.03e-04)max mem: 17.22449 GB 
[09/16 11:11:52][INFO] visual_prompt:  314: 	Test 300/407. loss: 9.045, 0.2217 s / batch. (data: 1.47e-02)max mem: 17.22449 GB 
[09/16 11:12:12][INFO] visual_prompt:  314: 	Test 400/407. loss: 7.600, 0.1834 s / batch. (data: 2.77e-05)max mem: 17.22449 GB 
[09/16 11:12:15][INFO] visual_prompt:  324: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1931, average loss: 8.3318
[09/16 11:12:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 47.61	
[09/16 11:12:15][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 11:12:25][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.47e-01, avg batch time: 0.5485, average train loss: 6.8016
[09/16 11:12:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1425, average loss: 5.7510
[09/16 11:12:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 47.00	
[09/16 11:12:51][INFO] visual_prompt:  314: 	Test 100/407. loss: 5.569, 0.1968 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 11:13:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 5.826, 0.2142 s / batch. (data: 2.79e-02)max mem: 17.22449 GB 
[09/16 11:13:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 5.663, 0.1979 s / batch. (data: 1.74e-04)max mem: 17.22449 GB 
[09/16 11:13:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.109, 0.1821 s / batch. (data: 4.03e-05)max mem: 17.22449 GB 
[09/16 11:13:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1934, average loss: 5.6629
[09/16 11:13:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.76	top5: 50.58	
[09/16 11:13:53][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 11:14:03][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 1.37e-01, avg batch time: 0.5399, average train loss: 4.4049
[09/16 11:14:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1426, average loss: 3.8788
[09/16 11:14:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 61.50	
[09/16 11:14:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.853, 0.1971 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 11:14:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.729, 0.1943 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 11:15:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.884, 0.1828 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 11:15:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.640, 0.1832 s / batch. (data: 2.98e-05)max mem: 17.22449 GB 
[09/16 11:15:32][INFO] visual_prompt:  324: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1958, average loss: 3.7740
[09/16 11:15:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 62.68	
[09/16 11:15:32][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 11:15:42][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 1.46e-01, avg batch time: 0.5480, average train loss: 3.4659
[09/16 11:15:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1425, average loss: 3.0399
[09/16 11:15:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 62.00	
[09/16 11:16:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.533, 0.1828 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 11:16:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.505, 0.1917 s / batch. (data: 9.70e-05)max mem: 17.22449 GB 
[09/16 11:16:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.072, 0.1819 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 11:17:06][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.308, 0.1826 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 11:17:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1934, average loss: 3.1107
[09/16 11:17:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.52	top5: 61.88	
[09/16 11:17:10][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 11:17:20][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.50e-01, avg batch time: 0.5523, average train loss: 3.3449
[09/16 11:17:25][INFO] visual_prompt:  324: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1428, average loss: 2.6316
[09/16 11:17:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 58.50	
[09/16 11:17:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.874, 0.1831 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 11:18:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.977, 0.1957 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 11:18:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.611, 0.1835 s / batch. (data: 1.47e-04)max mem: 17.22449 GB 
[09/16 11:18:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.933, 0.1827 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 11:18:48][INFO] visual_prompt:  324: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1937, average loss: 2.7611
[09/16 11:18:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.40	top5: 53.95	
[09/16 11:18:48][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 11:18:58][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 1.49e-01, avg batch time: 0.5508, average train loss: 2.7234
[09/16 11:19:03][INFO] visual_prompt:  324: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1427, average loss: 3.1239
[09/16 11:19:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.50	
[09/16 11:19:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.667, 0.2035 s / batch. (data: 2.13e-02)max mem: 17.22449 GB 
[09/16 11:19:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.335, 0.1823 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 11:20:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.217, 0.1846 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 11:20:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.072, 0.1830 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 11:20:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1927, average loss: 3.1984
[09/16 11:20:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.09	
[09/16 11:20:26][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 11:20:36][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 1.48e-01, avg batch time: 0.5498, average train loss: 3.2442
[09/16 11:20:41][INFO] visual_prompt:  324: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1428, average loss: 3.4241
[09/16 11:20:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 62.50	
[09/16 11:21:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.106, 0.1828 s / batch. (data: 1.51e-04)max mem: 17.22449 GB 
[09/16 11:21:22][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.909, 0.1990 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 11:21:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.589, 0.2113 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 11:22:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.664, 0.1825 s / batch. (data: 3.77e-05)max mem: 17.22449 GB 
[09/16 11:22:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1933, average loss: 3.5680
[09/16 11:22:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.99	
[09/16 11:22:04][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 11:22:15][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 1.50e-01, avg batch time: 0.5524, average train loss: 3.0758
[09/16 11:22:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1425, average loss: 2.8207
[09/16 11:22:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.00	
[09/16 11:22:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.133, 0.1836 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 11:23:01][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.931, 0.1859 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 11:23:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.664, 0.1967 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 11:23:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.624, 0.1822 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 11:23:43][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1938, average loss: 2.8275
[09/16 11:23:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 60.57	
[09/16 11:23:43][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 11:23:53][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 1.44e-01, avg batch time: 0.5450, average train loss: 2.8597
[09/16 11:23:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1427, average loss: 3.1056
[09/16 11:23:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.50	top5: 57.50	
[09/16 11:24:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.653, 0.1831 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 11:24:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.213, 0.2020 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 11:24:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.225, 0.1826 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 11:25:17][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.967, 0.1834 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 11:25:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1931, average loss: 3.2283
[09/16 11:25:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 8.75	top5: 52.37	
[09/16 11:25:21][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 11:25:31][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 1.45e-01, avg batch time: 0.5458, average train loss: 2.7643
[09/16 11:25:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1425, average loss: 2.5811
[09/16 11:25:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 44.00	
[09/16 11:25:57][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.546, 0.1824 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 11:26:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.641, 0.2044 s / batch. (data: 2.27e-02)max mem: 17.22449 GB 
[09/16 11:26:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.610, 0.1993 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 11:26:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.580, 0.1877 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 11:26:59][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1940, average loss: 2.6077
[09/16 11:26:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.57	top5: 43.80	
[09/16 11:26:59][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 11:27:10][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 1.48e-01, avg batch time: 0.5488, average train loss: 2.7457
[09/16 11:27:15][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1425, average loss: 2.6541
[09/16 11:27:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 58.50	
[09/16 11:27:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.882, 0.1857 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 11:27:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.914, 0.1832 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 11:28:16][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.682, 0.1983 s / batch. (data: 1.61e-02)max mem: 17.22449 GB 
[09/16 11:28:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.779, 0.1837 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 11:28:38][INFO] visual_prompt:  324: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1941, average loss: 2.6952
[09/16 11:28:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 55.91	
[09/16 11:28:38][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 11:28:49][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 1.51e-01, avg batch time: 0.5515, average train loss: 2.5345
[09/16 11:28:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1424, average loss: 2.7355
[09/16 11:28:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 63.50	
[09/16 11:29:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.065, 0.1834 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 11:29:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.910, 0.1981 s / batch. (data: 1.10e-04)max mem: 17.22449 GB 
[09/16 11:29:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.874, 0.1984 s / batch. (data: 1.58e-02)max mem: 17.22449 GB 
[09/16 11:30:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.778, 0.1829 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 11:30:16][INFO] visual_prompt:  324: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1932, average loss: 2.7649
[09/16 11:30:16][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 62.75	
[09/16 11:30:16][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 11:30:27][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.50e-01, avg batch time: 0.5526, average train loss: 2.5831
[09/16 11:30:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1425, average loss: 2.2745
[09/16 11:30:31][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 59.00	
[09/16 11:30:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.445, 0.1829 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 11:31:12][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.446, 0.1834 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 11:31:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.361, 0.1829 s / batch. (data: 9.23e-05)max mem: 17.22449 GB 
[09/16 11:31:51][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.382, 0.1832 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 11:31:54][INFO] visual_prompt:  324: Inference (test):avg data time: 6.94e-03, avg batch time: 0.1924, average loss: 2.3262
[09/16 11:31:54][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.33	
[09/16 11:31:54][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 11:32:04][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 1.40e-01, avg batch time: 0.5444, average train loss: 2.5141
[09/16 11:32:09][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1425, average loss: 2.5267
[09/16 11:32:09][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 10.50	top5: 57.50	
[09/16 11:32:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.427, 0.1834 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 11:32:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.616, 0.1825 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 11:33:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.358, 0.1828 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 11:33:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.399, 0.1893 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 11:33:32][INFO] visual_prompt:  324: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1939, average loss: 2.4978
[09/16 11:33:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.60	top5: 57.64	
[09/16 11:33:32][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 11:33:42][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 1.34e-01, avg batch time: 0.5362, average train loss: 2.5056
[09/16 11:33:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1427, average loss: 2.2866
[09/16 11:33:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.50	top5: 56.00	
[09/16 11:34:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.358, 0.1946 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 11:34:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.432, 0.1830 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 11:34:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.329, 0.1870 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 11:35:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.362, 0.1818 s / batch. (data: 3.46e-05)max mem: 17.22449 GB 
[09/16 11:35:10][INFO] visual_prompt:  324: Inference (test):avg data time: 8.80e-03, avg batch time: 0.1944, average loss: 2.3335
[09/16 11:35:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.73	top5: 55.09	
[09/16 11:35:10][INFO] visual_prompt:  246: Best epoch 39: best metric: 0.235
[09/16 11:35:10][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 11:35:21][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 1.49e-01, avg batch time: 0.5511, average train loss: 2.3993
[09/16 11:35:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1425, average loss: 2.3068
[09/16 11:35:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.50	
[09/16 11:35:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.568, 0.1823 s / batch. (data: 9.37e-05)max mem: 17.22449 GB 
[09/16 11:36:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.524, 0.2036 s / batch. (data: 2.17e-02)max mem: 17.22449 GB 
[09/16 11:36:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.434, 0.2014 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 11:36:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.467, 0.1827 s / batch. (data: 3.00e-05)max mem: 17.22449 GB 
[09/16 11:36:49][INFO] visual_prompt:  324: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1935, average loss: 2.4261
[09/16 11:36:49][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.52	top5: 51.03	
[09/16 11:36:49][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 3.75
[09/16 11:36:59][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 1.50e-01, avg batch time: 0.5514, average train loss: 2.4786
[09/16 11:37:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1425, average loss: 2.5350
[09/16 11:37:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.00	
[09/16 11:37:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.592, 0.1934 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 11:37:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.573, 0.1829 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 11:38:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.622, 0.1827 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 11:38:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.578, 0.1827 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 11:38:27][INFO] visual_prompt:  324: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1933, average loss: 2.5669
[09/16 11:38:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.48	top5: 52.93	
[09/16 11:38:27][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 11:38:37][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 1.48e-01, avg batch time: 0.5494, average train loss: 2.5571
[09/16 11:38:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1425, average loss: 2.6631
[09/16 11:38:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 60.50	
[09/16 11:39:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.681, 0.1963 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 11:39:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.006, 0.1823 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 11:39:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.362, 0.1827 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 11:40:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.730, 0.1836 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 11:40:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1921, average loss: 2.6790
[09/16 11:40:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 60.03	
[09/16 11:40:05][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 11:40:15][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 1.47e-01, avg batch time: 0.5494, average train loss: 2.5198
[09/16 11:40:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1425, average loss: 2.4434
[09/16 11:40:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 65.00	
[09/16 11:40:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.620, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 11:41:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.580, 0.2021 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 11:41:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.529, 0.1992 s / batch. (data: 1.41e-02)max mem: 17.22449 GB 
[09/16 11:41:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.497, 0.1821 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 11:41:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.00e-03, avg batch time: 0.1924, average loss: 2.4635
[09/16 11:41:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.02	top5: 62.18	
[09/16 11:41:42][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 11:41:53][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 1.46e-01, avg batch time: 0.5469, average train loss: 2.4357
[09/16 11:41:57][INFO] visual_prompt:  324: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1427, average loss: 2.2985
[09/16 11:41:57][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.50	
[09/16 11:42:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.427, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 11:42:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.512, 0.2280 s / batch. (data: 2.50e-02)max mem: 17.22449 GB 
[09/16 11:42:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.290, 0.1914 s / batch. (data: 1.54e-04)max mem: 17.22449 GB 
[09/16 11:43:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.413, 0.1822 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 11:43:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1954, average loss: 2.3691
[09/16 11:43:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.29	top5: 53.95	
[09/16 11:43:21][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 11:43:32][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.46e-01, avg batch time: 0.5477, average train loss: 2.3914
[09/16 11:43:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1425, average loss: 2.2960
[09/16 11:43:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.50	
[09/16 11:43:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.358, 0.1827 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 11:44:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.431, 0.1976 s / batch. (data: 1.57e-02)max mem: 17.22449 GB 
[09/16 11:44:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.276, 0.1936 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 11:44:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.300, 0.1831 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 11:44:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1935, average loss: 2.3218
[09/16 11:44:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 18.25	top5: 61.01	
[09/16 11:44:59][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 11:45:10][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.52e-01, avg batch time: 0.5514, average train loss: 2.4144
[09/16 11:45:14][INFO] visual_prompt:  324: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1425, average loss: 2.3338
[09/16 11:45:14][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 59.50	
[09/16 11:45:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.500, 0.1832 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 11:45:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.409, 0.1831 s / batch. (data: 9.18e-05)max mem: 17.22449 GB 
[09/16 11:46:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.429, 0.1828 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 11:46:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.349, 0.1823 s / batch. (data: 3.98e-05)max mem: 17.22449 GB 
[09/16 11:46:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1925, average loss: 2.3824
[09/16 11:46:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.55	top5: 58.83	
[09/16 11:46:37][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 11:46:47][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 1.45e-01, avg batch time: 0.5466, average train loss: 2.4009
[09/16 11:46:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1425, average loss: 2.5875
[09/16 11:46:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 65.00	
[09/16 11:47:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.730, 0.1824 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 11:47:33][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.736, 0.1891 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 11:47:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.655, 0.1929 s / batch. (data: 1.08e-02)max mem: 17.22449 GB 
[09/16 11:48:12][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.532, 0.1825 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 11:48:15][INFO] visual_prompt:  324: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1943, average loss: 2.6046
[09/16 11:48:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 64.17	
[09/16 11:48:15][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 11:48:26][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 1.54e-01, avg batch time: 0.5551, average train loss: 2.4568
[09/16 11:48:31][INFO] visual_prompt:  324: Inference (val):avg data time: 4.21e-04, avg batch time: 0.2736, average loss: 2.5327
[09/16 11:48:31][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 48.50	
[09/16 11:48:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.436, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 11:49:12][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.476, 0.1839 s / batch. (data: 1.47e-04)max mem: 17.22449 GB 
[09/16 11:49:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.446, 0.1890 s / batch. (data: 9.80e-05)max mem: 17.22449 GB 
[09/16 11:49:51][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.436, 0.1826 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 11:49:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1942, average loss: 2.5103
[09/16 11:49:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 50.39	
[09/16 11:49:55][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 11:50:05][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 1.51e-01, avg batch time: 0.5520, average train loss: 2.4639
[09/16 11:50:09][INFO] visual_prompt:  324: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1429, average loss: 2.2527
[09/16 11:50:09][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.50	top5: 66.50	
[09/16 11:50:31][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.481, 0.1913 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 11:50:51][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.583, 0.1936 s / batch. (data: 1.12e-02)max mem: 17.22449 GB 
[09/16 11:51:10][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.222, 0.1833 s / batch. (data: 1.55e-04)max mem: 17.22449 GB 
[09/16 11:51:30][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.391, 0.1824 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 11:51:33][INFO] visual_prompt:  324: Inference (test):avg data time: 8.68e-03, avg batch time: 0.1941, average loss: 2.3335
[09/16 11:51:33][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.44	top5: 61.46	
[09/16 11:51:33][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 11:51:43][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 1.49e-01, avg batch time: 0.5502, average train loss: 2.3219
[09/16 11:51:48][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1425, average loss: 2.2667
[09/16 11:51:48][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.50	top5: 66.50	
[09/16 11:52:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.443, 0.1819 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 11:52:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.528, 0.1864 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 11:52:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.191, 0.1829 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 11:53:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.313, 0.1877 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 11:53:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1923, average loss: 2.3183
[09/16 11:53:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.54	top5: 61.99	
[09/16 11:53:11][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 11:53:21][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.45e-01, avg batch time: 0.5468, average train loss: 2.2997
[09/16 11:53:25][INFO] visual_prompt:  324: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1426, average loss: 2.3576
[09/16 11:53:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 22.50	top5: 63.00	
[09/16 11:53:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.579, 0.1974 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 11:54:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.663, 0.2052 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 11:54:26][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.316, 0.1835 s / batch. (data: 1.37e-04)max mem: 17.22449 GB 
[09/16 11:54:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.508, 0.1901 s / batch. (data: 3.50e-05)max mem: 17.22449 GB 
[09/16 11:54:48][INFO] visual_prompt:  324: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1924, average loss: 2.4180
[09/16 11:54:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 18.28	top5: 58.17	
[09/16 11:54:48][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 11:54:59][INFO] visual_prompt:  219: Epoch 52 / 100: avg data time: 1.46e-01, avg batch time: 0.5469, average train loss: 2.3485
[09/16 11:55:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1426, average loss: 2.3519
[09/16 11:55:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 13.50	top5: 62.00	
[09/16 11:55:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.589, 0.1966 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 11:55:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.523, 0.1955 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 11:56:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.443, 0.1958 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 11:56:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.364, 0.1827 s / batch. (data: 3.17e-05)max mem: 17.22449 GB 
[09/16 11:56:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1935, average loss: 2.4355
[09/16 11:56:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 10.28	top5: 57.50	
[09/16 11:56:27][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 11:56:37][INFO] visual_prompt:  219: Epoch 53 / 100: avg data time: 1.42e-01, avg batch time: 0.5433, average train loss: 2.4165
[09/16 11:56:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1425, average loss: 2.3517
[09/16 11:56:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 13.00	top5: 59.00	
[09/16 11:57:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.320, 0.2078 s / batch. (data: 2.57e-02)max mem: 17.22449 GB 
[09/16 11:57:22][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.406, 0.1830 s / batch. (data: 1.04e-04)max mem: 17.22449 GB 
[09/16 11:57:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.370, 0.1878 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 11:58:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.394, 0.1828 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 11:58:05][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1933, average loss: 2.3677
[09/16 11:58:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.90	top5: 57.20	
[09/16 11:58:05][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 11:58:15][INFO] visual_prompt:  219: Epoch 54 / 100: avg data time: 1.54e-01, avg batch time: 0.5567, average train loss: 2.3359
[09/16 11:58:20][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1424, average loss: 2.1930
[09/16 11:58:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 26.00	top5: 67.00	
[09/16 11:58:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.404, 0.1829 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 11:59:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.432, 0.1864 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 11:59:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.230, 0.1834 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 11:59:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.255, 0.1829 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 11:59:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1924, average loss: 2.2639
[09/16 11:59:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 18.19	top5: 63.35	
[09/16 11:59:42][INFO] visual_prompt:  246: Best epoch 54: best metric: 0.260
[09/16 11:59:42][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 11:59:53][INFO] visual_prompt:  219: Epoch 55 / 100: avg data time: 1.47e-01, avg batch time: 0.5483, average train loss: 2.2996
[09/16 11:59:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1426, average loss: 2.2392
[09/16 11:59:57][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 19.00	top5: 64.50	
[09/16 12:00:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.389, 0.1830 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 12:00:38][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.471, 0.1821 s / batch. (data: 9.39e-05)max mem: 17.22449 GB 
[09/16 12:00:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.260, 0.1828 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 12:01:17][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.326, 0.1826 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 12:01:20][INFO] visual_prompt:  324: Inference (test):avg data time: 7.33e-03, avg batch time: 0.1928, average loss: 2.3457
[09/16 12:01:20][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 12.54	top5: 56.91	
[09/16 12:01:20][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 2.5
[09/16 12:01:31][INFO] visual_prompt:  219: Epoch 56 / 100: avg data time: 1.44e-01, avg batch time: 0.5450, average train loss: 2.3186
[09/16 12:01:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1426, average loss: 2.1764
[09/16 12:01:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 24.50	top5: 65.50	
[09/16 12:01:57][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.455, 0.1820 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 12:02:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.505, 0.2195 s / batch. (data: 3.73e-02)max mem: 17.22449 GB 
[09/16 12:02:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.212, 0.1826 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 12:02:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.285, 0.1819 s / batch. (data: 3.62e-05)max mem: 17.22449 GB 
[09/16 12:02:58][INFO] visual_prompt:  324: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1934, average loss: 2.2729
[09/16 12:02:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 18.35	top5: 62.51	
[09/16 12:02:58][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 12:03:09][INFO] visual_prompt:  219: Epoch 57 / 100: avg data time: 1.51e-01, avg batch time: 0.5553, average train loss: 2.3086
[09/16 12:03:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1423, average loss: 2.2901
[09/16 12:03:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 24.50	top5: 64.00	
[09/16 12:03:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.453, 0.1853 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 12:03:54][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.483, 0.1960 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 12:04:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.329, 0.1826 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 12:04:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.420, 0.1820 s / batch. (data: 2.57e-05)max mem: 17.22449 GB 
[09/16 12:04:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1947, average loss: 2.3514
[09/16 12:04:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 16.74	top5: 58.68	
[09/16 12:04:37][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 12:04:47][INFO] visual_prompt:  219: Epoch 58 / 100: avg data time: 1.44e-01, avg batch time: 0.5487, average train loss: 2.3812
[09/16 12:04:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1425, average loss: 2.4025
[09/16 12:04:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 6.00	top5: 60.00	
[09/16 12:05:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.415, 0.1822 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 12:05:33][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.497, 0.1973 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 12:05:52][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.399, 0.1963 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 12:06:12][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.496, 0.1827 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 12:06:15][INFO] visual_prompt:  324: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1937, average loss: 2.4557
[09/16 12:06:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 6.38	top5: 54.39	
[09/16 12:06:15][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 12:06:26][INFO] visual_prompt:  219: Epoch 59 / 100: avg data time: 1.54e-01, avg batch time: 0.5559, average train loss: 2.4279
[09/16 12:06:30][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1425, average loss: 2.3009
[09/16 12:06:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 19.00	top5: 61.50	
[09/16 12:06:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.532, 0.1952 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 12:07:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.573, 0.2070 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 12:07:30][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.282, 0.2067 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 12:07:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.465, 0.1908 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 12:07:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.06e-03, avg batch time: 0.1926, average loss: 2.3768
[09/16 12:07:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.70	top5: 55.60	
[09/16 12:07:53][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 12:08:03][INFO] visual_prompt:  219: Epoch 60 / 100: avg data time: 1.44e-01, avg batch time: 0.5446, average train loss: 2.3106
[09/16 12:08:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1425, average loss: 2.2885
[09/16 12:08:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 18.00	top5: 66.00	
[09/16 12:08:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.438, 0.2042 s / batch. (data: 2.28e-02)max mem: 17.22449 GB 
[09/16 12:08:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.534, 0.1827 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 12:09:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.224, 0.1827 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 12:09:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.276, 0.1822 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 12:09:31][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1941, average loss: 2.3463
[09/16 12:09:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 13.24	top5: 64.35	
[09/16 12:09:32][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 12:09:42][INFO] visual_prompt:  219: Epoch 61 / 100: avg data time: 1.51e-01, avg batch time: 0.5563, average train loss: 2.3093
[09/16 12:09:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1426, average loss: 2.3424
[09/16 12:09:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 22.50	top5: 59.00	
[09/16 12:10:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.563, 0.1826 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 12:10:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.481, 0.2021 s / batch. (data: 2.03e-02)max mem: 17.22449 GB 
[09/16 12:10:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.602, 0.1831 s / batch. (data: 1.51e-04)max mem: 17.22449 GB 
[09/16 12:11:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.522, 0.1830 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 12:11:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1945, average loss: 2.4575
[09/16 12:11:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.30	top5: 55.89	
[09/16 12:11:10][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 12:11:21][INFO] visual_prompt:  219: Epoch 62 / 100: avg data time: 1.48e-01, avg batch time: 0.5503, average train loss: 2.3303
[09/16 12:11:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1434, average loss: 2.2673
[09/16 12:11:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 17.00	top5: 62.00	
[09/16 12:11:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.408, 0.1819 s / batch. (data: 1.04e-04)max mem: 17.22449 GB 
[09/16 12:12:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.407, 0.1962 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 12:12:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.332, 0.1837 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 12:12:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.315, 0.1831 s / batch. (data: 2.72e-05)max mem: 17.22449 GB 
[09/16 12:12:48][INFO] visual_prompt:  324: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1935, average loss: 2.3549
[09/16 12:12:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.98	top5: 57.32	
[09/16 12:12:48][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 12:13:00][INFO] visual_prompt:  219: Epoch 63 / 100: avg data time: 1.52e-01, avg batch time: 0.6157, average train loss: 2.3045
[09/16 12:13:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1436, average loss: 2.2092
[09/16 12:13:04][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 67.00	
[09/16 12:13:26][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.478, 0.2033 s / batch. (data: 1.47e-02)max mem: 17.22449 GB 
[09/16 12:13:45][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.426, 0.2040 s / batch. (data: 7.26e-03)max mem: 17.22449 GB 
[09/16 12:14:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.324, 0.1993 s / batch. (data: 1.70e-02)max mem: 17.22449 GB 
[09/16 12:14:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.278, 0.1827 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 12:14:27][INFO] visual_prompt:  324: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1928, average loss: 2.3085
[09/16 12:14:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.40	top5: 62.27	
[09/16 12:14:27][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 12:14:38][INFO] visual_prompt:  219: Epoch 64 / 100: avg data time: 1.52e-01, avg batch time: 0.5535, average train loss: 2.2492
[09/16 12:14:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1434, average loss: 2.2989
[09/16 12:14:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 65.50	
[09/16 12:15:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.397, 0.1983 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 12:15:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.445, 0.1963 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 12:15:44][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.316, 0.1824 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 12:16:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.279, 0.1827 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 12:16:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1962, average loss: 2.3760
[09/16 12:16:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.96	top5: 56.33	
[09/16 12:16:07][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 12:16:17][INFO] visual_prompt:  219: Epoch 65 / 100: avg data time: 1.54e-01, avg batch time: 0.5551, average train loss: 2.3070
[09/16 12:16:22][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1426, average loss: 2.1887
[09/16 12:16:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.50	top5: 69.00	
[09/16 12:16:43][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.514, 0.1952 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 12:17:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.501, 0.1958 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 12:17:22][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.263, 0.2066 s / batch. (data: 2.49e-02)max mem: 17.22449 GB 
[09/16 12:17:41][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.279, 0.1835 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 12:17:45][INFO] visual_prompt:  324: Inference (test):avg data time: 6.93e-03, avg batch time: 0.1923, average loss: 2.2980
[09/16 12:17:45][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.61	top5: 61.97	
[09/16 12:17:45][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 12:17:55][INFO] visual_prompt:  219: Epoch 66 / 100: avg data time: 1.35e-01, avg batch time: 0.5372, average train loss: 2.2665
[09/16 12:18:00][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1426, average loss: 2.2647
[09/16 12:18:00][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.00	
[09/16 12:18:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.544, 0.2156 s / batch. (data: 2.08e-02)max mem: 17.22449 GB 
[09/16 12:18:41][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.517, 0.1826 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 12:19:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.402, 0.1835 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 12:19:20][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.356, 0.1827 s / batch. (data: 3.12e-05)max mem: 17.22449 GB 
[09/16 12:19:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1944, average loss: 2.3880
[09/16 12:19:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.58	top5: 57.29	
[09/16 12:19:23][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 12:19:34][INFO] visual_prompt:  219: Epoch 67 / 100: avg data time: 1.52e-01, avg batch time: 0.5537, average train loss: 2.2775
[09/16 12:19:38][INFO] visual_prompt:  324: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1426, average loss: 2.2247
[09/16 12:19:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 22.00	top5: 67.50	
[09/16 12:20:00][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.375, 0.1952 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 12:20:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.475, 0.1828 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 12:20:39][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.247, 0.1958 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 12:20:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.265, 0.1833 s / batch. (data: 4.55e-05)max mem: 17.22449 GB 
[09/16 12:21:01][INFO] visual_prompt:  324: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1930, average loss: 2.3341
[09/16 12:21:02][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 18.86	top5: 61.50	
[09/16 12:21:02][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 12:21:12][INFO] visual_prompt:  219: Epoch 68 / 100: avg data time: 1.45e-01, avg batch time: 0.5569, average train loss: 2.2441
[09/16 12:21:16][INFO] visual_prompt:  324: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1427, average loss: 2.1679
[09/16 12:21:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 26.00	top5: 67.50	
[09/16 12:21:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.380, 0.1829 s / batch. (data: 1.47e-04)max mem: 17.22449 GB 
[09/16 12:21:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.462, 0.1829 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 12:22:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.260, 0.1824 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 12:22:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.268, 0.1822 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 12:22:40][INFO] visual_prompt:  324: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1935, average loss: 2.2945
[09/16 12:22:40][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.35	top5: 64.31	
[09/16 12:22:40][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 12:22:50][INFO] visual_prompt:  219: Epoch 69 / 100: avg data time: 1.41e-01, avg batch time: 0.5418, average train loss: 2.2725
[09/16 12:22:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1427, average loss: 2.1718
[09/16 12:22:54][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 28.00	top5: 64.50	
[09/16 12:23:16][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.470, 0.2014 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 12:23:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.542, 0.2066 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 12:23:55][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.219, 0.1843 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 12:24:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.275, 0.1820 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 12:24:18][INFO] visual_prompt:  324: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1932, average loss: 2.2977
[09/16 12:24:18][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 18.78	top5: 65.39	
[09/16 12:24:18][INFO] visual_prompt:  246: Best epoch 69: best metric: 0.280
[09/16 12:24:18][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 12:24:28][INFO] visual_prompt:  219: Epoch 70 / 100: avg data time: 1.52e-01, avg batch time: 0.5570, average train loss: 2.2652
[09/16 12:24:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1425, average loss: 2.2009
[09/16 12:24:33][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 70.50	
[09/16 12:24:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.557, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 12:25:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.609, 0.1827 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 12:25:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.305, 0.1835 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 12:25:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.354, 0.1823 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 12:25:56][INFO] visual_prompt:  324: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1940, average loss: 2.3521
[09/16 12:25:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.57	top5: 63.63	
[09/16 12:25:56][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 12:26:07][INFO] visual_prompt:  219: Epoch 71 / 100: avg data time: 1.57e-01, avg batch time: 0.5578, average train loss: 2.2311
[09/16 12:26:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1428, average loss: 2.3144
[09/16 12:26:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 17.00	top5: 57.00	
[09/16 12:26:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.328, 0.1820 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 12:26:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.374, 0.2064 s / batch. (data: 2.44e-02)max mem: 17.22449 GB 
[09/16 12:27:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.357, 0.1909 s / batch. (data: 9.14e-03)max mem: 17.22449 GB 
[09/16 12:27:32][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.261, 0.1825 s / batch. (data: 3.86e-05)max mem: 17.22449 GB 
[09/16 12:27:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1947, average loss: 2.3753
[09/16 12:27:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 12.55	top5: 53.34	
[09/16 12:27:35][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 12:27:45][INFO] visual_prompt:  219: Epoch 72 / 100: avg data time: 1.49e-01, avg batch time: 0.5491, average train loss: 2.1849
[09/16 12:27:50][INFO] visual_prompt:  324: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1426, average loss: 2.0674
[09/16 12:27:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 28.50	top5: 71.50	
[09/16 12:28:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.329, 0.1950 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 12:28:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.388, 0.1829 s / batch. (data: 1.76e-04)max mem: 17.22449 GB 
[09/16 12:28:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.268, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 12:29:09][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.181, 0.1822 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 12:29:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1923, average loss: 2.2585
[09/16 12:29:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.54	top5: 60.21	
[09/16 12:29:13][INFO] visual_prompt:  246: Best epoch 72: best metric: 0.285
[09/16 12:29:13][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 12:29:23][INFO] visual_prompt:  219: Epoch 73 / 100: avg data time: 1.47e-01, avg batch time: 0.5490, average train loss: 2.1812
[09/16 12:29:28][INFO] visual_prompt:  324: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1427, average loss: 2.2185
[09/16 12:29:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 17.50	top5: 67.00	
[09/16 12:29:49][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.518, 0.1827 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 12:30:09][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.482, 0.1827 s / batch. (data: 1.05e-04)max mem: 17.22449 GB 
[09/16 12:30:28][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.327, 0.1824 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 12:30:48][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.291, 0.1828 s / batch. (data: 2.77e-05)max mem: 17.22449 GB 
[09/16 12:30:51][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1938, average loss: 2.3536
[09/16 12:30:51][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.81	top5: 60.87	
[09/16 12:30:51][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 12:31:02][INFO] visual_prompt:  219: Epoch 74 / 100: avg data time: 1.48e-01, avg batch time: 0.5511, average train loss: 2.2055
[09/16 12:31:06][INFO] visual_prompt:  324: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1441, average loss: 2.1219
[09/16 12:31:06][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.50	top5: 69.00	
[09/16 12:31:28][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.362, 0.1961 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 12:31:47][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.481, 0.1997 s / batch. (data: 1.80e-02)max mem: 17.22449 GB 
[09/16 12:32:07][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.167, 0.1831 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 12:32:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.193, 0.1830 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 12:32:29][INFO] visual_prompt:  324: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1932, average loss: 2.2631
[09/16 12:32:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 20.62	top5: 65.07	
[09/16 12:32:30][INFO] visual_prompt:  246: Best epoch 74: best metric: 0.295
[09/16 12:32:30][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 12:32:40][INFO] visual_prompt:  219: Epoch 75 / 100: avg data time: 1.50e-01, avg batch time: 0.5516, average train loss: 2.1559
[09/16 12:32:44][INFO] visual_prompt:  324: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1424, average loss: 2.0292
[09/16 12:32:44][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 32.00	top5: 75.50	
[09/16 12:33:06][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.267, 0.1828 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 12:33:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.338, 0.1979 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 12:33:44][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.110, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 12:34:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.125, 0.1824 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 12:34:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.09e-03, avg batch time: 0.1928, average loss: 2.1845
[09/16 12:34:08][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 21.76	top5: 66.97	
[09/16 12:34:08][INFO] visual_prompt:  246: Best epoch 75: best metric: 0.320
[09/16 12:34:08][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 12:34:18][INFO] visual_prompt:  219: Epoch 76 / 100: avg data time: 1.54e-01, avg batch time: 0.5565, average train loss: 2.0764
[09/16 12:34:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1425, average loss: 1.8885
[09/16 12:34:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 35.00	top5: 77.50	
[09/16 12:34:45][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.311, 0.1983 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 12:35:04][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.327, 0.1829 s / batch. (data: 9.61e-05)max mem: 17.22449 GB 
[09/16 12:35:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.082, 0.1833 s / batch. (data: 1.72e-04)max mem: 17.22449 GB 
[09/16 12:35:43][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.024, 0.1825 s / batch. (data: 3.03e-05)max mem: 17.22449 GB 
[09/16 12:35:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1938, average loss: 2.0883
[09/16 12:35:46][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 26.25	top5: 69.21	
[09/16 12:35:46][INFO] visual_prompt:  246: Best epoch 76: best metric: 0.350
[09/16 12:35:46][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 12:35:56][INFO] visual_prompt:  219: Epoch 77 / 100: avg data time: 1.58e-01, avg batch time: 0.5586, average train loss: 2.0993
[09/16 12:36:01][INFO] visual_prompt:  324: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1427, average loss: 2.6597
[09/16 12:36:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 64.00	
[09/16 12:36:23][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.073, 0.1917 s / batch. (data: 1.02e-04)max mem: 17.22449 GB 
[09/16 12:36:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.034, 0.1825 s / batch. (data: 1.17e-04)max mem: 17.22449 GB 
[09/16 12:37:01][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.662, 0.1998 s / batch. (data: 1.71e-02)max mem: 17.22449 GB 
[09/16 12:37:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.770, 0.1814 s / batch. (data: 2.62e-05)max mem: 17.22449 GB 
[09/16 12:37:24][INFO] visual_prompt:  324: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1935, average loss: 2.7485
[09/16 12:37:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 60.33	
[09/16 12:37:24][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 12:37:35][INFO] visual_prompt:  219: Epoch 78 / 100: avg data time: 1.49e-01, avg batch time: 0.5837, average train loss: 2.2064
[09/16 12:37:40][INFO] visual_prompt:  324: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1425, average loss: 1.9524
[09/16 12:37:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 31.50	top5: 73.50	
[09/16 12:38:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.297, 0.1986 s / batch. (data: 1.58e-02)max mem: 17.22449 GB 
[09/16 12:38:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.225, 0.1976 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 12:38:40][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.038, 0.1970 s / batch. (data: 1.04e-04)max mem: 17.22449 GB 
[09/16 12:39:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.074, 0.1820 s / batch. (data: 2.67e-05)max mem: 17.22449 GB 
[09/16 12:39:03][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1929, average loss: 2.1040
[09/16 12:39:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 25.67	top5: 68.50	
[09/16 12:39:03][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 12:39:13][INFO] visual_prompt:  219: Epoch 79 / 100: avg data time: 1.50e-01, avg batch time: 0.5520, average train loss: 1.9357
[09/16 12:39:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1425, average loss: 1.7448
[09/16 12:39:18][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 35.50	top5: 83.50	
[09/16 12:39:40][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.987, 0.2081 s / batch. (data: 5.23e-03)max mem: 17.22449 GB 
[09/16 12:39:59][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.013, 0.1822 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 12:40:19][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.788, 0.2245 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 12:40:38][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.845, 0.1822 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 12:40:41][INFO] visual_prompt:  324: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1936, average loss: 1.9322
[09/16 12:40:41][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 29.03	top5: 75.67	
[09/16 12:40:41][INFO] visual_prompt:  246: Best epoch 79: best metric: 0.355
[09/16 12:40:41][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 12:40:52][INFO] visual_prompt:  219: Epoch 80 / 100: avg data time: 1.48e-01, avg batch time: 0.5575, average train loss: 1.9476
[09/16 12:40:56][INFO] visual_prompt:  324: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1426, average loss: 1.9851
[09/16 12:40:56][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 27.50	top5: 72.50	
[09/16 12:41:18][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.214, 0.2060 s / batch. (data: 2.46e-02)max mem: 17.22449 GB 
[09/16 12:41:37][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.212, 0.2060 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 12:41:57][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.029, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 12:42:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.114, 0.1825 s / batch. (data: 4.17e-05)max mem: 17.22449 GB 
[09/16 12:42:20][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1937, average loss: 2.0931
[09/16 12:42:20][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 22.32	top5: 66.93	
[09/16 12:42:20][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 12:42:30][INFO] visual_prompt:  219: Epoch 81 / 100: avg data time: 1.44e-01, avg batch time: 0.5477, average train loss: 1.9040
[09/16 12:42:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1426, average loss: 1.6772
[09/16 12:42:34][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 40.50	top5: 80.00	
[09/16 12:42:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.860, 0.1824 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 12:43:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.955, 0.1937 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 12:43:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.668, 0.1927 s / batch. (data: 1.07e-02)max mem: 17.22449 GB 
[09/16 12:43:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.765, 0.1824 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 12:43:59][INFO] visual_prompt:  324: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1950, average loss: 1.8606
[09/16 12:43:59][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 33.91	top5: 76.69	
[09/16 12:43:59][INFO] visual_prompt:  246: Best epoch 81: best metric: 0.405
[09/16 12:43:59][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 12:44:09][INFO] visual_prompt:  219: Epoch 82 / 100: avg data time: 1.39e-01, avg batch time: 0.5421, average train loss: 1.8641
[09/16 12:44:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1434, average loss: 1.8462
[09/16 12:44:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 36.00	top5: 80.50	
[09/16 12:44:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.108, 0.1838 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 12:44:54][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.150, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 12:45:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.869, 0.1958 s / batch. (data: 1.36e-02)max mem: 17.22449 GB 
[09/16 12:45:33][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.046, 0.1869 s / batch. (data: 3.55e-05)max mem: 17.22449 GB 
[09/16 12:45:37][INFO] visual_prompt:  324: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1933, average loss: 2.0643
[09/16 12:45:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 24.30	top5: 72.13	
[09/16 12:45:37][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 12:45:47][INFO] visual_prompt:  219: Epoch 83 / 100: avg data time: 1.36e-01, avg batch time: 0.5398, average train loss: 1.8614
[09/16 12:45:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1425, average loss: 1.8792
[09/16 12:45:51][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 35.00	top5: 75.00	
[09/16 12:46:13][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.118, 0.1938 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 12:46:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.391, 0.1829 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 12:46:52][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.878, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 12:47:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.155, 0.1824 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 12:47:15][INFO] visual_prompt:  324: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1934, average loss: 2.1796
[09/16 12:47:15][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 24.55	top5: 71.96	
[09/16 12:47:15][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 12:47:26][INFO] visual_prompt:  219: Epoch 84 / 100: avg data time: 1.54e-01, avg batch time: 0.5876, average train loss: 1.7264
[09/16 12:47:30][INFO] visual_prompt:  324: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1431, average loss: 1.7309
[09/16 12:47:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 36.00	top5: 85.00	
[09/16 12:47:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.081, 0.1823 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 12:48:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.192, 0.1994 s / batch. (data: 1.18e-04)max mem: 17.22449 GB 
[09/16 12:48:31][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.767, 0.1951 s / batch. (data: 1.27e-02)max mem: 17.22449 GB 
[09/16 12:48:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.890, 0.1823 s / batch. (data: 4.29e-05)max mem: 17.22449 GB 
[09/16 12:48:53][INFO] visual_prompt:  324: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1935, average loss: 1.9162
[09/16 12:48:54][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 31.52	top5: 80.62	
[09/16 12:48:54][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 12:49:04][INFO] visual_prompt:  219: Epoch 85 / 100: avg data time: 1.50e-01, avg batch time: 0.5592, average train loss: 1.7947
[09/16 12:49:08][INFO] visual_prompt:  324: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1425, average loss: 1.6953
[09/16 12:49:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 38.00	top5: 85.00	
[09/16 12:49:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.017, 0.1957 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 12:49:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.022, 0.2247 s / batch. (data: 3.67e-02)max mem: 17.22449 GB 
[09/16 12:50:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.734, 0.1998 s / batch. (data: 1.80e-02)max mem: 17.22449 GB 
[09/16 12:50:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.896, 0.1847 s / batch. (data: 3.46e-05)max mem: 17.22449 GB 
[09/16 12:50:31][INFO] visual_prompt:  324: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1928, average loss: 1.9438
[09/16 12:50:31][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 30.49	top5: 76.83	
[09/16 12:50:31][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 12:50:42][INFO] visual_prompt:  219: Epoch 86 / 100: avg data time: 1.56e-01, avg batch time: 0.5551, average train loss: 1.6475
[09/16 12:50:46][INFO] visual_prompt:  324: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1424, average loss: 1.4821
[09/16 12:50:46][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 46.00	top5: 88.50	
[09/16 12:51:08][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.907, 0.1824 s / batch. (data: 9.89e-05)max mem: 17.22449 GB 
[09/16 12:51:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.839, 0.2075 s / batch. (data: 2.58e-02)max mem: 17.22449 GB 
[09/16 12:51:47][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.621, 0.1819 s / batch. (data: 8.61e-05)max mem: 17.22449 GB 
[09/16 12:52:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.685, 0.1819 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 12:52:10][INFO] visual_prompt:  324: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1934, average loss: 1.7324
[09/16 12:52:10][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 37.61	top5: 83.36	
[09/16 12:52:10][INFO] visual_prompt:  246: Best epoch 86: best metric: 0.460
[09/16 12:52:10][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 12:52:21][INFO] visual_prompt:  219: Epoch 87 / 100: avg data time: 1.50e-01, avg batch time: 0.5528, average train loss: 1.5343
[09/16 12:52:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1423, average loss: 1.4178
[09/16 12:52:25][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 50.00	top5: 92.50	
[09/16 12:52:47][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.733, 0.1962 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 12:53:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.764, 0.1826 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 12:53:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.591, 0.2108 s / batch. (data: 2.11e-02)max mem: 17.22449 GB 
[09/16 12:53:45][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.653, 0.1828 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 12:53:48][INFO] visual_prompt:  324: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1933, average loss: 1.7074
[09/16 12:53:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 38.97	top5: 85.41	
[09/16 12:53:48][INFO] visual_prompt:  246: Best epoch 87: best metric: 0.500
[09/16 12:53:48][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 12:53:58][INFO] visual_prompt:  219: Epoch 88 / 100: avg data time: 1.46e-01, avg batch time: 0.5467, average train loss: 1.4337
[09/16 12:54:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1426, average loss: 1.3044
[09/16 12:54:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 55.00	top5: 92.00	
[09/16 12:54:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.742, 0.2061 s / batch. (data: 1.29e-02)max mem: 17.22449 GB 
[09/16 12:54:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.708, 0.1978 s / batch. (data: 3.58e-05)max mem: 17.22449 GB 
[09/16 12:55:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.557, 0.1984 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 12:55:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.580, 0.1827 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 12:55:27][INFO] visual_prompt:  324: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1943, average loss: 1.6835
[09/16 12:55:27][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 39.84	top5: 85.79	
[09/16 12:55:27][INFO] visual_prompt:  246: Best epoch 88: best metric: 0.550
[09/16 12:55:27][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 12:55:37][INFO] visual_prompt:  219: Epoch 89 / 100: avg data time: 1.49e-01, avg batch time: 0.5522, average train loss: 1.3745
[09/16 12:55:41][INFO] visual_prompt:  324: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1423, average loss: 1.2765
[09/16 12:55:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 52.50	top5: 95.00	
[09/16 12:56:03][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.715, 0.2045 s / batch. (data: 2.27e-02)max mem: 17.22449 GB 
[09/16 12:56:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.742, 0.1965 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 12:56:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.563, 0.1832 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 12:57:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.612, 0.1826 s / batch. (data: 3.31e-05)max mem: 17.22449 GB 
[09/16 12:57:05][INFO] visual_prompt:  324: Inference (test):avg data time: 8.81e-03, avg batch time: 0.1945, average loss: 1.6718
[09/16 12:57:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 40.77	top5: 86.62	
[09/16 12:57:05][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 12:57:16][INFO] visual_prompt:  219: Epoch 90 / 100: avg data time: 1.57e-01, avg batch time: 0.5566, average train loss: 1.2811
[09/16 12:57:20][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1425, average loss: 1.1569
[09/16 12:57:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 58.00	top5: 94.50	
[09/16 12:57:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.684, 0.1889 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 12:58:01][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.657, 0.2125 s / batch. (data: 1.56e-02)max mem: 17.22449 GB 
[09/16 12:58:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.524, 0.2069 s / batch. (data: 2.53e-02)max mem: 17.22449 GB 
[09/16 12:58:40][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.534, 0.1830 s / batch. (data: 3.43e-05)max mem: 17.22449 GB 
[09/16 12:58:44][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1942, average loss: 1.6206
[09/16 12:58:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 43.62	top5: 86.49	
[09/16 12:58:44][INFO] visual_prompt:  246: Best epoch 90: best metric: 0.580
[09/16 12:58:44][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 12:58:54][INFO] visual_prompt:  219: Epoch 91 / 100: avg data time: 1.51e-01, avg batch time: 0.5517, average train loss: 1.2088
[09/16 12:58:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1428, average loss: 1.1222
[09/16 12:58:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 59.50	top5: 95.50	
[09/16 12:59:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.708, 0.1951 s / batch. (data: 1.28e-02)max mem: 17.22449 GB 
[09/16 12:59:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.539, 0.1977 s / batch. (data: 9.44e-05)max mem: 17.22449 GB 
[09/16 12:59:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.587, 0.1964 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 13:00:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.623, 0.1822 s / batch. (data: 2.69e-05)max mem: 17.22449 GB 
[09/16 13:00:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1932, average loss: 1.6376
[09/16 13:00:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 42.78	top5: 86.56	
[09/16 13:00:22][INFO] visual_prompt:  246: Best epoch 91: best metric: 0.595
[09/16 13:00:22][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 13:00:32][INFO] visual_prompt:  219: Epoch 92 / 100: avg data time: 1.50e-01, avg batch time: 0.5530, average train loss: 1.1504
[09/16 13:00:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1424, average loss: 1.0036
[09/16 13:00:37][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 63.00	top5: 98.50	
[09/16 13:00:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.672, 0.1829 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 13:01:18][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.540, 0.1833 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 13:01:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.423, 0.2018 s / batch. (data: 1.49e-02)max mem: 17.22449 GB 
[09/16 13:01:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.463, 0.1824 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 13:02:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1933, average loss: 1.5922
[09/16 13:02:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 45.18	top5: 87.27	
[09/16 13:02:00][INFO] visual_prompt:  246: Best epoch 92: best metric: 0.630
[09/16 13:02:00][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 13:02:10][INFO] visual_prompt:  219: Epoch 93 / 100: avg data time: 1.49e-01, avg batch time: 0.5500, average train loss: 1.0703
[09/16 13:02:15][INFO] visual_prompt:  324: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1426, average loss: 0.9453
[09/16 13:02:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 67.00	top5: 97.50	
[09/16 13:02:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.699, 0.1955 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 13:02:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.677, 0.1970 s / batch. (data: 1.51e-02)max mem: 17.22449 GB 
[09/16 13:03:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.485, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22449 GB 
[09/16 13:03:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.485, 0.1825 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 13:03:38][INFO] visual_prompt:  324: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1932, average loss: 1.6030
[09/16 13:03:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 45.83	top5: 88.10	
[09/16 13:03:38][INFO] visual_prompt:  246: Best epoch 93: best metric: 0.670
[09/16 13:03:38][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 13:03:48][INFO] visual_prompt:  219: Epoch 94 / 100: avg data time: 1.54e-01, avg batch time: 0.5548, average train loss: 1.0144
[09/16 13:03:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1427, average loss: 0.9119
[09/16 13:03:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 67.00	top5: 99.00	
[09/16 13:04:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.714, 0.1825 s / batch. (data: 1.62e-04)max mem: 17.22449 GB 
[09/16 13:04:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.560, 0.1823 s / batch. (data: 8.80e-05)max mem: 17.22449 GB 
[09/16 13:04:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.509, 0.1936 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 13:05:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.597, 0.1822 s / batch. (data: 3.67e-05)max mem: 17.22449 GB 
[09/16 13:05:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1946, average loss: 1.6150
[09/16 13:05:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 44.60	top5: 87.80	
[09/16 13:05:17][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 13:05:27][INFO] visual_prompt:  219: Epoch 95 / 100: avg data time: 1.46e-01, avg batch time: 0.5494, average train loss: 0.9466
[09/16 13:05:32][INFO] visual_prompt:  324: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1426, average loss: 0.8296
[09/16 13:05:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 71.00	top5: 98.50	
[09/16 13:05:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.663, 0.1831 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 13:06:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.583, 0.2170 s / batch. (data: 3.52e-02)max mem: 17.22449 GB 
[09/16 13:06:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.452, 0.1916 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 13:06:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.514, 0.1832 s / batch. (data: 3.70e-05)max mem: 17.22449 GB 
[09/16 13:06:55][INFO] visual_prompt:  324: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1936, average loss: 1.6161
[09/16 13:06:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 46.45	top5: 87.78	
[09/16 13:06:55][INFO] visual_prompt:  246: Best epoch 95: best metric: 0.710
[09/16 13:06:55][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 13:07:05][INFO] visual_prompt:  219: Epoch 96 / 100: avg data time: 1.34e-01, avg batch time: 0.5367, average train loss: 0.8959
[09/16 13:07:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1427, average loss: 0.7606
[09/16 13:07:10][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 75.00	top5: 99.50	
[09/16 13:07:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.693, 0.1954 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 13:07:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.561, 0.1957 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 13:08:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.469, 0.1973 s / batch. (data: 1.52e-02)max mem: 17.22449 GB 
[09/16 13:08:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.480, 0.1821 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 13:08:34][INFO] visual_prompt:  324: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1949, average loss: 1.5937
[09/16 13:08:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 48.11	top5: 88.46	
[09/16 13:08:34][INFO] visual_prompt:  246: Best epoch 96: best metric: 0.750
[09/16 13:08:34][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 13:08:44][INFO] visual_prompt:  219: Epoch 97 / 100: avg data time: 1.50e-01, avg batch time: 0.5517, average train loss: 0.8443
[09/16 13:08:49][INFO] visual_prompt:  324: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1425, average loss: 0.7541
[09/16 13:08:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 73.50	top5: 99.00	
[09/16 13:09:10][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.761, 0.1832 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 13:09:30][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.639, 0.1825 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 13:09:49][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.439, 0.2081 s / batch. (data: 2.57e-02)max mem: 17.22449 GB 
[09/16 13:10:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.488, 0.1997 s / batch. (data: 8.63e-05)max mem: 17.22449 GB 
[09/16 13:10:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1921, average loss: 1.6465
[09/16 13:10:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 47.36	top5: 87.60	
[09/16 13:10:11][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 13:10:22][INFO] visual_prompt:  219: Epoch 98 / 100: avg data time: 1.52e-01, avg batch time: 0.5525, average train loss: 0.8288
[09/16 13:10:27][INFO] visual_prompt:  324: Inference (val):avg data time: 3.37e-04, avg batch time: 0.2116, average loss: 0.7134
[09/16 13:10:27][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 74.00	top5: 99.50	
[09/16 13:10:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.735, 0.1827 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 13:11:08][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.592, 0.1909 s / batch. (data: 3.93e-05)max mem: 17.22449 GB 
[09/16 13:11:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.461, 0.2053 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 13:11:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.492, 0.1823 s / batch. (data: 3.79e-05)max mem: 17.22449 GB 
[09/16 13:11:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1928, average loss: 1.6377
[09/16 13:11:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 48.04	top5: 88.24	
[09/16 13:11:50][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 13:12:00][INFO] visual_prompt:  219: Epoch 99 / 100: avg data time: 1.47e-01, avg batch time: 0.5476, average train loss: 0.7974
[09/16 13:12:05][INFO] visual_prompt:  324: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1423, average loss: 0.7217
[09/16 13:12:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 75.00	top5: 100.00	
[09/16 13:12:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.752, 0.1826 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 13:12:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.643, 0.1826 s / batch. (data: 1.90e-04)max mem: 17.22449 GB 
[09/16 13:13:06][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.581, 0.1825 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 13:13:25][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.538, 0.1826 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 13:13:28][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1934, average loss: 1.6557
[09/16 13:13:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 47.14	top5: 88.39	
[09/16 13:13:28][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 13:13:39][INFO] visual_prompt:  219: Epoch 100 / 100: avg data time: 1.36e-01, avg batch time: 0.5378, average train loss: 0.7887
[09/16 13:13:43][INFO] visual_prompt:  324: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1426, average loss: 0.7076
[09/16 13:13:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 75.00	top5: 99.50	
[09/16 13:14:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.730, 0.1835 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 13:14:24][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.626, 0.1833 s / batch. (data: 1.09e-04)max mem: 17.22449 GB 
[09/16 13:14:43][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.538, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 13:15:03][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.516, 0.1816 s / batch. (data: 4.96e-05)max mem: 17.22449 GB 
[09/16 13:15:06][INFO] visual_prompt:  324: Inference (test):avg data time: 7.03e-03, avg batch time: 0.1923, average loss: 1.6465
[09/16 13:15:06][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 47.57	top5: 88.41	
