[09/19 10:16:16][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/19 10:16:19][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/19 10:16:19][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/19 10:16:19][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/19 10:16:19][INFO] visual_prompt:  108: Training with config:
[09/19 10:16:19][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/19 10:16:19][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/19 10:17:19][INFO] visual_prompt:   69: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset trainval...
[09/19 10:17:24][INFO] visual_prompt:   88: Number of images: 1000
[09/19 10:17:24][INFO] visual_prompt:   90: Number of classes: 16 / 16
[09/19 10:17:24][INFO] visual_prompt:   70: Loading validation data...
[09/19 10:17:24][INFO] visual_prompt:   69: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset val...
[09/19 10:17:24][INFO] visual_prompt:   88: Number of images: 200
[09/19 10:17:24][INFO] visual_prompt:   90: Number of classes: 16 / 16
[09/19 10:17:24][INFO] visual_prompt:   73: Loading test data...
[09/19 10:17:24][INFO] visual_prompt:   69: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset test...
[09/19 10:18:56][INFO] visual_prompt:   88: Number of images: 73728
[09/19 10:18:56][INFO] visual_prompt:   90: Number of classes: 16 / 16
[09/19 10:18:56][INFO] visual_prompt:  100: Constructing models...
[09/19 10:19:06][INFO] visual_prompt:   53: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/19 10:19:06][INFO] visual_prompt:   54: tuned percent:1.077
[09/19 10:19:31][INFO] visual_prompt:   40: Device used for model: 0
[09/19 10:19:31][INFO] visual_prompt:  103: Setting up Evalutator...
[09/19 10:19:31][INFO] visual_prompt:  105: Setting up Trainer...
[09/19 10:19:31][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/19 10:19:31][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/19 10:19:48][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 2.27e-01, avg batch time: 0.8940, average train loss: 2.9562
[09/19 10:19:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1416, average loss: 2.8999
[09/19 10:19:54][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 35.50	
[09/19 10:20:17][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.019, 0.1955 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 10:20:36][INFO] visual_prompt:  314: 	Test 200/1152. loss: 2.876, 0.1822 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 10:20:55][INFO] visual_prompt:  314: 	Test 300/1152. loss: 2.953, 0.1843 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:21:15][INFO] visual_prompt:  314: 	Test 400/1152. loss: 2.817, 0.2079 s / batch. (data: 1.84e-02)max mem: 17.22454 GB 
[09/19 10:21:34][INFO] visual_prompt:  314: 	Test 500/1152. loss: 2.875, 0.1980 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:21:54][INFO] visual_prompt:  314: 	Test 600/1152. loss: 2.950, 0.1843 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 10:22:14][INFO] visual_prompt:  314: 	Test 700/1152. loss: 2.945, 0.2094 s / batch. (data: 1.68e-02)max mem: 17.22454 GB 
[09/19 10:22:33][INFO] visual_prompt:  314: 	Test 800/1152. loss: 2.961, 0.1960 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:22:53][INFO] visual_prompt:  314: 	Test 900/1152. loss: 2.940, 0.2104 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 10:23:12][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 2.870, 0.1843 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:23:32][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.125, 0.1997 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 10:23:46][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1943, average loss: 2.9411
[09/19 10:23:46][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.27	top5: 31.21	
[09/19 10:23:46][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.060
[09/19 10:23:46][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/19 10:23:59][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 2.05e-01, avg batch time: 0.6058, average train loss: 3.1723
[09/19 10:24:05][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1426, average loss: 3.0093
[09/19 10:24:05][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 33.00	
[09/19 10:24:28][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.072, 0.1932 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:24:47][INFO] visual_prompt:  314: 	Test 200/1152. loss: 2.919, 0.1829 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 10:25:07][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.114, 0.1823 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 10:25:26][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.121, 0.1835 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:25:46][INFO] visual_prompt:  314: 	Test 500/1152. loss: 2.892, 0.2185 s / batch. (data: 3.62e-02)max mem: 17.22454 GB 
[09/19 10:26:05][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.015, 0.2195 s / batch. (data: 3.73e-02)max mem: 17.22454 GB 
[09/19 10:26:25][INFO] visual_prompt:  314: 	Test 700/1152. loss: 3.127, 0.1933 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 10:26:44][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.053, 0.2035 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 10:27:04][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.189, 0.1986 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 10:27:23][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 2.998, 0.1952 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 10:27:43][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.087, 0.1830 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:27:57][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1942, average loss: 3.0286
[09/19 10:27:57][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.13	top5: 31.12	
[09/19 10:27:57][INFO] visual_prompt:  246: Best epoch 2: best metric: 0.095
[09/19 10:27:57][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/19 10:28:10][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 2.05e-01, avg batch time: 0.6059, average train loss: 2.9460
[09/19 10:28:17][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1422, average loss: 3.0380
[09/19 10:28:17][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 26.00	
[09/19 10:28:39][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.104, 0.2070 s / batch. (data: 2.47e-02)max mem: 17.22454 GB 
[09/19 10:28:58][INFO] visual_prompt:  314: 	Test 200/1152. loss: 2.965, 0.1815 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:29:18][INFO] visual_prompt:  314: 	Test 300/1152. loss: 2.996, 0.1841 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 10:29:37][INFO] visual_prompt:  314: 	Test 400/1152. loss: 2.888, 0.1919 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:29:56][INFO] visual_prompt:  314: 	Test 500/1152. loss: 2.842, 0.1946 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 10:30:16][INFO] visual_prompt:  314: 	Test 600/1152. loss: 2.891, 0.1825 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 10:30:35][INFO] visual_prompt:  314: 	Test 700/1152. loss: 2.803, 0.1931 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 10:30:55][INFO] visual_prompt:  314: 	Test 800/1152. loss: 2.994, 0.1952 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 10:31:14][INFO] visual_prompt:  314: 	Test 900/1152. loss: 2.809, 0.1975 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:31:34][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 2.835, 0.1899 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:31:54][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 2.913, 0.1981 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 10:32:08][INFO] visual_prompt:  324: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1941, average loss: 2.9477
[09/19 10:32:09][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.34	top5: 31.26	
[09/19 10:32:09][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/19 10:32:22][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 2.38e-01, avg batch time: 0.6777, average train loss: 3.0404
[09/19 10:32:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1817, average loss: 3.0678
[09/19 10:32:29][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 35.50	
[09/19 10:32:51][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.303, 0.1947 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 10:33:11][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.108, 0.2137 s / batch. (data: 3.20e-02)max mem: 17.22454 GB 
[09/19 10:33:30][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.121, 0.1814 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 10:33:50][INFO] visual_prompt:  314: 	Test 400/1152. loss: 2.982, 0.1826 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 10:34:09][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.373, 0.1930 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 10:34:28][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.335, 0.1932 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 10:34:48][INFO] visual_prompt:  314: 	Test 700/1152. loss: 3.158, 0.1929 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/19 10:35:07][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.057, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 10:35:27][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.263, 0.2082 s / batch. (data: 2.61e-02)max mem: 17.22454 GB 
[09/19 10:35:47][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 3.058, 0.1831 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 10:36:06][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.139, 0.1972 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 10:36:20][INFO] visual_prompt:  324: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1939, average loss: 3.1379
[09/19 10:36:20][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.13	top5: 31.09	
[09/19 10:36:20][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/19 10:36:33][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 2.12e-01, avg batch time: 0.6118, average train loss: 3.2249
[09/19 10:36:39][INFO] visual_prompt:  324: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1422, average loss: 3.0126
[09/19 10:36:39][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 33.00	
[09/19 10:37:02][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.075, 0.2212 s / batch. (data: 4.01e-02)max mem: 17.22454 GB 
[09/19 10:37:21][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.140, 0.1912 s / batch. (data: 8.54e-05)max mem: 17.22454 GB 
[09/19 10:37:41][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.006, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 10:38:00][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.075, 0.1833 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 10:38:20][INFO] visual_prompt:  314: 	Test 500/1152. loss: 2.997, 0.1833 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:38:39][INFO] visual_prompt:  314: 	Test 600/1152. loss: 2.952, 0.2090 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 10:38:59][INFO] visual_prompt:  314: 	Test 700/1152. loss: 2.935, 0.1963 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 10:39:18][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.092, 0.1922 s / batch. (data: 1.00e-02)max mem: 17.22454 GB 
[09/19 10:39:37][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.015, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:39:57][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 3.081, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 10:40:17][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.152, 0.1879 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 10:40:31][INFO] visual_prompt:  324: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1939, average loss: 3.0615
[09/19 10:40:31][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.36	
[09/19 10:40:31][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/19 10:40:44][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 2.20e-01, avg batch time: 0.6269, average train loss: 3.1016
[09/19 10:40:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1426, average loss: 3.0836
[09/19 10:40:50][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 38.50	
[09/19 10:41:13][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.062, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 10:41:32][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.288, 0.2051 s / batch. (data: 2.30e-02)max mem: 17.22454 GB 
[09/19 10:41:51][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.284, 0.1825 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:42:11][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.193, 0.1827 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:42:30][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.313, 0.1821 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:42:50][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.487, 0.1820 s / batch. (data: 4.34e-05)max mem: 17.22454 GB 
[09/19 10:43:09][INFO] visual_prompt:  314: 	Test 700/1152. loss: 3.080, 0.2062 s / batch. (data: 2.43e-02)max mem: 17.22454 GB 
[09/19 10:43:28][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.223, 0.1881 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 10:43:48][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.269, 0.1831 s / batch. (data: 9.06e-05)max mem: 17.22454 GB 
[09/19 10:44:07][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 3.216, 0.1920 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:44:27][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.181, 0.1825 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:44:41][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1934, average loss: 3.2095
[09/19 10:44:41][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.35	top5: 31.15	
[09/19 10:44:41][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/19 10:44:53][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.94e-01, avg batch time: 0.5983, average train loss: 3.2028
[09/19 10:44:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1425, average loss: 3.0998
[09/19 10:44:59][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 32.00	
[09/19 10:45:22][INFO] visual_prompt:  314: 	Test 100/1152. loss: 2.929, 0.1944 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 10:45:41][INFO] visual_prompt:  314: 	Test 200/1152. loss: 2.955, 0.1999 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:46:01][INFO] visual_prompt:  314: 	Test 300/1152. loss: 2.947, 0.1825 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:46:20][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.026, 0.1965 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 10:46:39][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.034, 0.1979 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:46:59][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.100, 0.1825 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 10:47:18][INFO] visual_prompt:  314: 	Test 700/1152. loss: 2.938, 0.1828 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:47:37][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.073, 0.1824 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/19 10:47:57][INFO] visual_prompt:  314: 	Test 900/1152. loss: 2.952, 0.1829 s / batch. (data: 9.73e-05)max mem: 17.22454 GB 
[09/19 10:48:16][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 2.831, 0.2039 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 10:48:36][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.111, 0.1835 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 10:48:49][INFO] visual_prompt:  324: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1932, average loss: 3.0175
[09/19 10:48:49][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 31.21	
[09/19 10:48:49][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/19 10:49:02][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.99e-01, avg batch time: 0.6012, average train loss: 3.1232
[09/19 10:49:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1421, average loss: 3.1102
[09/19 10:49:08][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 30.00	
[09/19 10:49:31][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.064, 0.2073 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 10:49:50][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.065, 0.1952 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 10:50:09][INFO] visual_prompt:  314: 	Test 300/1152. loss: 2.986, 0.1872 s / batch. (data: 2.96e-05)max mem: 17.22454 GB 
[09/19 10:50:29][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.137, 0.1825 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:50:48][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.163, 0.1995 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:51:07][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.059, 0.1832 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/19 10:51:27][INFO] visual_prompt:  314: 	Test 700/1152. loss: 2.947, 0.1834 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 10:51:46][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.014, 0.1832 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 10:52:06][INFO] visual_prompt:  314: 	Test 900/1152. loss: 2.929, 0.1821 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 10:52:25][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 2.765, 0.1880 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:52:45][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.005, 0.2000 s / batch. (data: 1.75e-02)max mem: 17.22454 GB 
[09/19 10:52:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1935, average loss: 3.0452
[09/19 10:52:59][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.17	top5: 31.07	
[09/19 10:52:59][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/19 10:53:11][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.91e-01, avg batch time: 0.5928, average train loss: 3.1113
[09/19 10:53:17][INFO] visual_prompt:  324: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1435, average loss: 3.2305
[09/19 10:53:17][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 26.50	
[09/19 10:53:40][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.269, 0.1835 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 10:53:59][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.131, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 10:54:18][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.435, 0.1825 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 10:54:38][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.243, 0.1828 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 10:54:57][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.233, 0.1969 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 10:55:17][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.264, 0.1825 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:55:36][INFO] visual_prompt:  314: 	Test 700/1152. loss: 3.192, 0.1879 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:55:55][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.169, 0.1833 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:56:15][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.079, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:56:35][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 3.130, 0.1954 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 10:56:54][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.016, 0.1838 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 10:57:08][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1936, average loss: 3.2024
[09/19 10:57:08][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.33	top5: 31.20	
[09/19 10:57:08][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/19 10:57:21][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 2.09e-01, avg batch time: 0.6118, average train loss: 3.1227
[09/19 10:57:27][INFO] visual_prompt:  324: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1423, average loss: 3.2203
[09/19 10:57:27][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.50	top5: 28.50	
[09/19 10:57:49][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.436, 0.1954 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 10:58:09][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.219, 0.1972 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:58:28][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.226, 0.1987 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 10:58:47][INFO] visual_prompt:  314: 	Test 400/1152. loss: 3.073, 0.1990 s / batch. (data: 1.73e-02)max mem: 17.22454 GB 
[09/19 10:59:07][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.102, 0.1941 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 10:59:26][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.034, 0.2280 s / batch. (data: 4.19e-02)max mem: 17.22454 GB 
[09/19 10:59:46][INFO] visual_prompt:  314: 	Test 700/1152. loss: 3.216, 0.1975 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 11:00:05][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.213, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 11:00:25][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.152, 0.1824 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:00:44][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 3.188, 0.2056 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 11:01:04][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 2.980, 0.2232 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
