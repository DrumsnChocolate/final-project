[09/17 02:15:07][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/17 02:15:07][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 02:15:07][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_elevation")', 'DATA.NUMBER_CLASSES', '9', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/17 02:15:07][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 02:15:07][INFO] visual_prompt:  108: Training with config:
[09/17 02:15:07][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-smallnorb(predicted_attribute="label_elevation")',
          'NO_TEST': False,
          'NUMBER_CLASSES': 9,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-smallnorb(predicted_attribute="label_elevation")/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 02:15:07][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/17 02:15:11][INFO] visual_prompt:   69: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset trainval...
[09/17 02:15:12][INFO] visual_prompt:   88: Number of images: 1000
[09/17 02:15:12][INFO] visual_prompt:   90: Number of classes: 9 / 9
[09/17 02:15:12][INFO] visual_prompt:   70: Loading validation data...
[09/17 02:15:12][INFO] visual_prompt:   69: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset val...
[09/17 02:15:13][INFO] visual_prompt:   88: Number of images: 200
[09/17 02:15:13][INFO] visual_prompt:   90: Number of classes: 9 / 9
[09/17 02:15:13][INFO] visual_prompt:   73: Loading test data...
[09/17 02:15:13][INFO] visual_prompt:   69: Constructing vtab-smallnorb(predicted_attribute="label_elevation") dataset test...
[09/17 02:15:30][INFO] visual_prompt:   88: Number of images: 12150
[09/17 02:15:30][INFO] visual_prompt:   90: Number of classes: 9 / 9
[09/17 02:15:30][INFO] visual_prompt:  100: Constructing models...
[09/17 02:15:33][INFO] visual_prompt:   53: Total Parameters: 86727177	 Gradient Parameters: 928521
[09/17 02:15:33][INFO] visual_prompt:   54: tuned percent:1.071
[09/17 02:15:35][INFO] visual_prompt:   40: Device used for model: 0
[09/17 02:15:35][INFO] visual_prompt:  103: Setting up Evalutator...
[09/17 02:15:35][INFO] visual_prompt:  105: Setting up Trainer...
[09/17 02:15:35][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/17 02:15:35][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/17 02:15:46][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 1.27e-01, avg batch time: 0.6000, average train loss: 2.7858
[09/17 02:15:49][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1418, average loss: 2.7724
[09/17 02:15:49][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 8.00	top5: 54.50	
[09/17 02:16:10][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.636, 0.1816 s / batch. (data: 1.18e-04)max mem: 17.22448 GB 
[09/17 02:16:29][INFO] visual_prompt:  324: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1916, average loss: 2.6964
[09/17 02:16:29][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 57.05	
[09/17 02:16:29][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.080
[09/17 02:16:29][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/17 02:16:38][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 1.11e-01, avg batch time: 0.5148, average train loss: 4.5295
[09/17 02:16:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1422, average loss: 3.4546
[09/17 02:16:41][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 57.00	
[09/17 02:17:02][INFO] visual_prompt:  314: 	Test 100/190. loss: 3.771, 0.1825 s / batch. (data: 3.41e-05)max mem: 17.22448 GB 
[09/17 02:17:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1934, average loss: 3.8787
[09/17 02:17:21][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 55.06	
[09/17 02:17:21][INFO] visual_prompt:  246: Best epoch 2: best metric: 0.095
[09/17 02:17:21][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/17 02:17:30][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 1.08e-01, avg batch time: 0.5110, average train loss: 2.6608
[09/17 02:17:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1426, average loss: 2.3056
[09/17 02:17:33][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 61.50	
[09/17 02:17:54][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.397, 0.1850 s / batch. (data: 1.29e-04)max mem: 17.22448 GB 
[09/17 02:18:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1933, average loss: 2.3858
[09/17 02:18:13][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.28	
[09/17 02:18:13][INFO] visual_prompt:  246: Best epoch 3: best metric: 0.130
[09/17 02:18:13][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/17 02:18:22][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.02e-01, avg batch time: 0.5030, average train loss: 2.3682
[09/17 02:18:25][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1428, average loss: 2.4468
[09/17 02:18:25][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 58.00	
[09/17 02:18:47][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.512, 0.1931 s / batch. (data: 1.05e-02)max mem: 17.22448 GB 
[09/17 02:19:06][INFO] visual_prompt:  324: Inference (test):avg data time: 6.63e-03, avg batch time: 0.1978, average loss: 2.5239
[09/17 02:19:06][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.08	top5: 55.04	
[09/17 02:19:06][INFO] visual_prompt:  246: Best epoch 4: best metric: 0.145
[09/17 02:19:06][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/17 02:19:15][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.14e-01, avg batch time: 0.5334, average train loss: 2.4060
[09/17 02:19:19][INFO] visual_prompt:  324: Inference (val):avg data time: 3.66e-05, avg batch time: 0.2370, average loss: 2.4192
[09/17 02:19:19][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 58.00	
[09/17 02:19:40][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.458, 0.1902 s / batch. (data: 1.39e-04)max mem: 17.22448 GB 
[09/17 02:19:58][INFO] visual_prompt:  324: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1938, average loss: 2.4782
[09/17 02:19:59][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.77	top5: 55.34	
[09/17 02:19:59][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/17 02:20:08][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 1.19e-01, avg batch time: 0.5185, average train loss: 2.5297
[09/17 02:20:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1424, average loss: 2.5876
[09/17 02:20:11][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 54.50	
[09/17 02:20:32][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.434, 0.1826 s / batch. (data: 1.03e-04)max mem: 17.22448 GB 
[09/17 02:20:51][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1931, average loss: 2.5989
[09/17 02:20:51][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 60.21	
[09/17 02:20:51][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/17 02:21:00][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.17e-01, avg batch time: 0.5178, average train loss: 2.6000
[09/17 02:21:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1425, average loss: 2.5855
[09/17 02:21:03][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.00	top5: 54.00	
[09/17 02:21:24][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.553, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22448 GB 
[09/17 02:21:43][INFO] visual_prompt:  324: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1927, average loss: 2.5551
[09/17 02:21:43][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.55	top5: 58.63	
[09/17 02:21:43][INFO] visual_prompt:  246: Best epoch 7: best metric: 0.200
[09/17 02:21:43][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/17 02:21:52][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.11e-01, avg batch time: 0.5119, average train loss: 3.4991
[09/17 02:21:55][INFO] visual_prompt:  324: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1425, average loss: 5.1213
[09/17 02:21:55][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 55.00	
[09/17 02:22:16][INFO] visual_prompt:  314: 	Test 100/190. loss: 4.849, 0.1831 s / batch. (data: 1.54e-04)max mem: 17.22448 GB 
[09/17 02:22:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1924, average loss: 5.2091
[09/17 02:22:34][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.21	top5: 55.88	
[09/17 02:22:34][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/17 02:22:44][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.08e-01, avg batch time: 0.5101, average train loss: 11.7999
[09/17 02:22:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1427, average loss: 16.1357
[09/17 02:22:47][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 7.00	top5: 52.50	
[09/17 02:23:08][INFO] visual_prompt:  314: 	Test 100/190. loss: 16.481, 0.1824 s / batch. (data: 1.12e-04)max mem: 17.22448 GB 
[09/17 02:23:27][INFO] visual_prompt:  324: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1937, average loss: 15.8407
[09/17 02:23:27][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.40	top5: 55.35	
[09/17 02:23:27][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/17 02:23:36][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.11e-01, avg batch time: 0.5118, average train loss: 10.2443
[09/17 02:23:39][INFO] visual_prompt:  324: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1426, average loss: 8.3810
[09/17 02:23:39][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 7.00	top5: 58.50	
[09/17 02:24:00][INFO] visual_prompt:  314: 	Test 100/190. loss: 8.841, 0.2101 s / batch. (data: 1.35e-02)max mem: 17.22448 GB 
[09/17 02:24:19][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1929, average loss: 8.4705
[09/17 02:24:19][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.40	top5: 55.96	
[09/17 02:24:19][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[09/17 02:24:28][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.15e-01, avg batch time: 0.5171, average train loss: 8.1706
[09/17 02:24:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1428, average loss: 8.3384
[09/17 02:24:31][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 52.00	
[09/17 02:24:52][INFO] visual_prompt:  314: 	Test 100/190. loss: 8.350, 0.1825 s / batch. (data: 1.03e-04)max mem: 17.22448 GB 
[09/17 02:25:11][INFO] visual_prompt:  324: Inference (test):avg data time: 6.76e-03, avg batch time: 0.1924, average loss: 8.1324
[09/17 02:25:11][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 55.52	
[09/17 02:25:11][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/17 02:25:20][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 9.56e-02, avg batch time: 0.4996, average train loss: 6.2669
[09/17 02:25:23][INFO] visual_prompt:  324: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1427, average loss: 5.5687
[09/17 02:25:23][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 7.00	top5: 55.00	
[09/17 02:25:44][INFO] visual_prompt:  314: 	Test 100/190. loss: 6.416, 0.1817 s / batch. (data: 1.22e-04)max mem: 17.22448 GB 
[09/17 02:26:03][INFO] visual_prompt:  324: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1932, average loss: 5.4124
[09/17 02:26:03][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.40	top5: 56.02	
[09/17 02:26:03][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/17 02:26:12][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.08e-01, avg batch time: 0.5098, average train loss: 5.4905
[09/17 02:26:15][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1429, average loss: 4.4260
[09/17 02:26:15][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 55.50	
[09/17 02:26:36][INFO] visual_prompt:  314: 	Test 100/190. loss: 4.773, 0.2128 s / batch. (data: 1.21e-04)max mem: 17.22448 GB 
[09/17 02:26:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.06e-03, avg batch time: 0.1918, average loss: 4.4925
[09/17 02:26:55][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.45	
[09/17 02:26:55][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/17 02:27:04][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 1.16e-01, avg batch time: 0.5189, average train loss: 5.8249
[09/17 02:27:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1426, average loss: 6.1886
[09/17 02:27:07][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 56.50	
[09/17 02:27:29][INFO] visual_prompt:  314: 	Test 100/190. loss: 6.285, 0.1936 s / batch. (data: 1.10e-04)max mem: 17.22448 GB 
[09/17 02:27:47][INFO] visual_prompt:  324: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1962, average loss: 6.2701
[09/17 02:27:47][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 56.42	
[09/17 02:27:47][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/17 02:27:57][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.17e-01, avg batch time: 0.5225, average train loss: 5.6383
[09/17 02:28:00][INFO] visual_prompt:  324: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1426, average loss: 3.5873
[09/17 02:28:00][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 58.00	
[09/17 02:28:21][INFO] visual_prompt:  314: 	Test 100/190. loss: 3.587, 0.1828 s / batch. (data: 1.55e-04)max mem: 17.22448 GB 
[09/17 02:28:40][INFO] visual_prompt:  324: Inference (test):avg data time: 6.80e-03, avg batch time: 0.1936, average loss: 3.6655
[09/17 02:28:40][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 55.11	
[09/17 02:28:40][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/17 02:28:49][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 1.21e-01, avg batch time: 0.5234, average train loss: 3.6558
[09/17 02:28:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1425, average loss: 3.1166
[09/17 02:28:52][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 54.50	
[09/17 02:29:13][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.841, 0.1998 s / batch. (data: 1.37e-02)max mem: 17.22448 GB 
[09/17 02:29:32][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1920, average loss: 3.1227
[09/17 02:29:32][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 55.24	
[09/17 02:29:32][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/17 02:29:41][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.12e-01, avg batch time: 0.5147, average train loss: 2.8680
[09/17 02:29:44][INFO] visual_prompt:  324: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1426, average loss: 2.6599
[09/17 02:29:44][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 51.50	
[09/17 02:30:05][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.753, 0.1965 s / batch. (data: 1.44e-02)max mem: 17.22448 GB 
[09/17 02:30:24][INFO] visual_prompt:  324: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1931, average loss: 2.5958
[09/17 02:30:24][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.79	
[09/17 02:30:24][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/17 02:30:33][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.18e-01, avg batch time: 0.5186, average train loss: 2.7387
[09/17 02:30:36][INFO] visual_prompt:  324: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1427, average loss: 2.6892
[09/17 02:30:36][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 56.50	
[09/17 02:30:58][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.756, 0.1977 s / batch. (data: 1.54e-02)max mem: 17.22448 GB 
[09/17 02:31:16][INFO] visual_prompt:  324: Inference (test):avg data time: 8.13e-03, avg batch time: 0.1929, average loss: 2.6916
[09/17 02:31:16][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 55.09	
[09/17 02:31:16][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/17 02:31:26][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 1.19e-01, avg batch time: 0.5294, average train loss: 2.6033
[09/17 02:31:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1426, average loss: 2.7454
[09/17 02:31:29][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.50	top5: 54.50	
[09/17 02:31:50][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.660, 0.1843 s / batch. (data: 1.61e-04)max mem: 17.22448 GB 
[09/17 02:32:08][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1929, average loss: 2.6245
[09/17 02:32:08][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.17	top5: 56.02	
[09/17 02:32:08][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/17 02:32:17][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.01e-01, avg batch time: 0.5007, average train loss: 2.5399
[09/17 02:32:21][INFO] visual_prompt:  324: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1427, average loss: 2.3373
[09/17 02:32:21][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 60.50	
[09/17 02:32:42][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.405, 0.1966 s / batch. (data: 1.43e-02)max mem: 17.22448 GB 
[09/17 02:33:00][INFO] visual_prompt:  324: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1925, average loss: 2.3927
[09/17 02:33:00][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 56.30	
[09/17 02:33:00][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/17 02:33:10][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.15e-01, avg batch time: 0.5159, average train loss: 2.5197
[09/17 02:33:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1428, average loss: 2.6578
[09/17 02:33:13][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 48.50	
[09/17 02:33:34][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.515, 0.1963 s / batch. (data: 1.40e-02)max mem: 17.22448 GB 
[09/17 02:33:52][INFO] visual_prompt:  324: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1928, average loss: 2.5888
[09/17 02:33:52][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 55.51	
[09/17 02:33:52][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/17 02:34:01][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 9.96e-02, avg batch time: 0.5024, average train loss: 2.5907
[09/17 02:34:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1426, average loss: 2.5831
[09/17 02:34:04][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 50.50	
[09/17 02:34:26][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.381, 0.1967 s / batch. (data: 1.51e-04)max mem: 17.22448 GB 
[09/17 02:34:45][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1964, average loss: 2.5175
[09/17 02:34:45][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 55.43	
[09/17 02:34:45][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/17 02:34:54][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.06e-01, avg batch time: 0.5098, average train loss: 2.7717
[09/17 02:34:57][INFO] visual_prompt:  324: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1453, average loss: 2.6983
[09/17 02:34:57][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 53.50	
[09/17 02:35:19][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.714, 0.1825 s / batch. (data: 1.26e-04)max mem: 17.22448 GB 
[09/17 02:35:37][INFO] visual_prompt:  324: Inference (test):avg data time: 6.14e-03, avg batch time: 0.1946, average loss: 2.6964
[09/17 02:35:37][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.85	
[09/17 02:35:37][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/17 02:35:47][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 1.15e-01, avg batch time: 0.5149, average train loss: 2.6204
[09/17 02:35:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1428, average loss: 3.1234
[09/17 02:35:50][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 55.00	
[09/17 02:36:11][INFO] visual_prompt:  314: 	Test 100/190. loss: 3.095, 0.1830 s / batch. (data: 1.49e-04)max mem: 17.22448 GB 
[09/17 02:36:30][INFO] visual_prompt:  324: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1944, average loss: 3.0647
[09/17 02:36:30][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 56.11	
[09/17 02:36:30][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/17 02:36:39][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 9.94e-02, avg batch time: 0.5027, average train loss: 2.6253
[09/17 02:36:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1454, average loss: 2.5756
[09/17 02:36:42][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 55.00	
[09/17 02:37:03][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.632, 0.1833 s / batch. (data: 1.44e-04)max mem: 17.22448 GB 
[09/17 02:37:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1931, average loss: 2.5612
[09/17 02:37:22][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 56.03	
[09/17 02:37:22][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/17 02:37:31][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.13e-01, avg batch time: 0.5137, average train loss: 2.4428
[09/17 02:37:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1425, average loss: 2.5612
[09/17 02:37:34][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 15.00	top5: 56.00	
[09/17 02:37:55][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.571, 0.2063 s / batch. (data: 1.03e-02)max mem: 17.22448 GB 
[09/17 02:38:14][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1933, average loss: 2.5246
[09/17 02:38:14][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.23	top5: 55.33	
[09/17 02:38:14][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/17 02:38:23][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 9.61e-02, avg batch time: 0.4999, average train loss: 2.4065
[09/17 02:38:26][INFO] visual_prompt:  324: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1432, average loss: 2.6657
[09/17 02:38:26][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 54.00	
[09/17 02:38:47][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.488, 0.1827 s / batch. (data: 1.41e-04)max mem: 17.22448 GB 
[09/17 02:39:06][INFO] visual_prompt:  324: Inference (test):avg data time: 6.90e-03, avg batch time: 0.1930, average loss: 2.6126
[09/17 02:39:06][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 55.59	
[09/17 02:39:06][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/17 02:39:15][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 1.10e-01, avg batch time: 0.5135, average train loss: 2.4714
[09/17 02:39:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1426, average loss: 2.5893
[09/17 02:39:18][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.50	top5: 56.00	
[09/17 02:39:40][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.422, 0.1979 s / batch. (data: 1.62e-02)max mem: 17.22448 GB 
[09/17 02:39:59][INFO] visual_prompt:  324: Inference (test):avg data time: 8.85e-03, avg batch time: 0.1949, average loss: 2.5380
[09/17 02:39:59][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.71	top5: 59.23	
[09/17 02:39:59][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/17 02:40:08][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.09e-01, avg batch time: 0.5097, average train loss: 2.6231
[09/17 02:40:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1424, average loss: 2.5346
[09/17 02:40:11][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 54.50	
[09/17 02:40:32][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.448, 0.1983 s / batch. (data: 1.51e-02)max mem: 17.22448 GB 
[09/17 02:40:51][INFO] visual_prompt:  324: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1965, average loss: 2.5475
[09/17 02:40:51][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 55.24	
[09/17 02:40:51][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/17 02:41:01][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 1.15e-01, avg batch time: 0.5162, average train loss: 2.4019
[09/17 02:41:04][INFO] visual_prompt:  324: Inference (val):avg data time: 1.11e-04, avg batch time: 0.2264, average loss: 2.4008
[09/17 02:41:04][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 53.50	
[09/17 02:41:25][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.341, 0.1826 s / batch. (data: 1.24e-04)max mem: 17.22448 GB 
[09/17 02:41:44][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1928, average loss: 2.4039
[09/17 02:41:44][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.21	top5: 55.62	
[09/17 02:41:44][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/17 02:41:53][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 1.16e-01, avg batch time: 0.5166, average train loss: 2.4054
[09/17 02:41:56][INFO] visual_prompt:  324: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1426, average loss: 2.3971
[09/17 02:41:56][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 61.50	
[09/17 02:42:17][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.482, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22448 GB 
[09/17 02:42:36][INFO] visual_prompt:  324: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1929, average loss: 2.4771
[09/17 02:42:36][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 59.80	
[09/17 02:42:36][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/17 02:42:45][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 1.08e-01, avg batch time: 0.5081, average train loss: 2.5771
[09/17 02:42:48][INFO] visual_prompt:  324: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1427, average loss: 2.4634
[09/17 02:42:48][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 52.00	
[09/17 02:43:09][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.324, 0.1897 s / batch. (data: 1.21e-04)max mem: 17.22448 GB 
[09/17 02:43:28][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1924, average loss: 2.4111
[09/17 02:43:28][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 55.69	
[09/17 02:43:28][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/17 02:43:37][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 1.03e-01, avg batch time: 0.5056, average train loss: 2.4513
[09/17 02:43:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1426, average loss: 2.6486
[09/17 02:43:40][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 59.50	
[09/17 02:44:01][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.517, 0.1826 s / batch. (data: 1.84e-04)max mem: 17.22448 GB 
[09/17 02:44:20][INFO] visual_prompt:  324: Inference (test):avg data time: 6.79e-03, avg batch time: 0.1924, average loss: 2.6318
[09/17 02:44:20][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 58.64	
[09/17 02:44:20][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/17 02:44:29][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 9.79e-02, avg batch time: 0.5020, average train loss: 2.4061
[09/17 02:44:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1426, average loss: 2.2059
[09/17 02:44:32][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 59.50	
[09/17 02:44:53][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.245, 0.1823 s / batch. (data: 1.31e-04)max mem: 17.22448 GB 
[09/17 02:45:12][INFO] visual_prompt:  324: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1936, average loss: 2.2347
[09/17 02:45:12][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 55.28	
[09/17 02:45:12][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/17 02:45:21][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 9.55e-02, avg batch time: 0.4979, average train loss: 2.3706
[09/17 02:45:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1428, average loss: 2.5109
[09/17 02:45:24][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 63.00	
[09/17 02:45:46][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.407, 0.2002 s / batch. (data: 1.41e-04)max mem: 17.22448 GB 
[09/17 02:46:04][INFO] visual_prompt:  324: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1947, average loss: 2.5500
[09/17 02:46:04][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 60.26	
[09/17 02:46:04][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/17 02:46:13][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 9.45e-02, avg batch time: 0.5005, average train loss: 2.5228
[09/17 02:46:17][INFO] visual_prompt:  324: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1428, average loss: 2.3401
[09/17 02:46:17][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 61.50	
[09/17 02:46:38][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.501, 0.1823 s / batch. (data: 1.51e-04)max mem: 17.22448 GB 
[09/17 02:46:57][INFO] visual_prompt:  324: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1955, average loss: 2.4460
[09/17 02:46:57][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 55.19	
[09/17 02:46:57][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/17 02:47:06][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.14e-01, avg batch time: 0.5133, average train loss: 2.9158
[09/17 02:47:09][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1426, average loss: 2.5746
[09/17 02:47:09][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 59.00	
[09/17 02:47:30][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.847, 0.2360 s / batch. (data: 5.45e-02)max mem: 17.22448 GB 
[09/17 02:47:48][INFO] visual_prompt:  324: Inference (test):avg data time: 8.42e-03, avg batch time: 0.1932, average loss: 2.7013
[09/17 02:47:48][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.08	top5: 55.54	
[09/17 02:47:48][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/17 02:47:58][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 1.07e-01, avg batch time: 0.5095, average train loss: 2.5812
[09/17 02:48:01][INFO] visual_prompt:  324: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1426, average loss: 2.3459
[09/17 02:48:01][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 56.00	
[09/17 02:48:22][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.362, 0.1840 s / batch. (data: 1.14e-04)max mem: 17.22448 GB 
[09/17 02:48:40][INFO] visual_prompt:  324: Inference (test):avg data time: 6.28e-03, avg batch time: 0.1908, average loss: 2.3570
[09/17 02:48:40][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 55.33	
[09/17 02:48:40][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/17 02:48:50][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 1.13e-01, avg batch time: 0.5128, average train loss: 2.7185
[09/17 02:48:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1427, average loss: 2.2940
[09/17 02:48:53][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 61.50	
[09/17 02:49:14][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.265, 0.2041 s / batch. (data: 2.22e-02)max mem: 17.22448 GB 
[09/17 02:49:32][INFO] visual_prompt:  324: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1930, average loss: 2.3466
[09/17 02:49:32][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.22	top5: 55.28	
[09/17 02:49:32][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/17 02:49:42][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 1.18e-01, avg batch time: 0.5188, average train loss: 2.3597
[09/17 02:49:45][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1426, average loss: 2.3100
[09/17 02:49:45][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 57.50	
[09/17 02:50:06][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.365, 0.1821 s / batch. (data: 1.19e-04)max mem: 17.22448 GB 
[09/17 02:50:25][INFO] visual_prompt:  324: Inference (test):avg data time: 7.04e-03, avg batch time: 0.1957, average loss: 2.3457
[09/17 02:50:25][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.68	
[09/17 02:50:25][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 3.75
[09/17 02:50:34][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 1.10e-01, avg batch time: 0.5113, average train loss: 2.4442
[09/17 02:50:37][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1426, average loss: 2.2477
[09/17 02:50:37][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 58.50	
[09/17 02:50:58][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.290, 0.1980 s / batch. (data: 1.51e-02)max mem: 17.22448 GB 
[09/17 02:51:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1928, average loss: 2.2746
[09/17 02:51:17][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.08	top5: 55.98	
[09/17 02:51:17][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/17 02:51:26][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 1.11e-01, avg batch time: 0.5119, average train loss: 2.4253
[09/17 02:51:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1428, average loss: 2.5185
[09/17 02:51:29][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 57.00	
[09/17 02:51:50][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.440, 0.1962 s / batch. (data: 1.40e-02)max mem: 17.22448 GB 
[09/17 02:52:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1925, average loss: 2.4813
[09/17 02:52:09][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 55.62	
[09/17 02:52:09][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/17 02:52:18][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 1.07e-01, avg batch time: 0.5081, average train loss: 2.5607
[09/17 02:52:21][INFO] visual_prompt:  324: Inference (val):avg data time: 3.64e-04, avg batch time: 0.2037, average loss: 2.3623
[09/17 02:52:21][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 9.50	top5: 59.00	
[09/17 02:52:42][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.191, 0.1869 s / batch. (data: 1.40e-04)max mem: 17.22448 GB 
[09/17 02:53:01][INFO] visual_prompt:  324: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1935, average loss: 2.3445
[09/17 02:53:01][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.97	top5: 55.70	
[09/17 02:53:01][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/17 02:53:10][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 1.14e-01, avg batch time: 0.5138, average train loss: 2.3781
[09/17 02:53:13][INFO] visual_prompt:  324: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1428, average loss: 2.2623
[09/17 02:53:13][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 53.50	
[09/17 02:53:34][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.242, 0.1955 s / batch. (data: 1.37e-02)max mem: 17.22448 GB 
[09/17 02:53:53][INFO] visual_prompt:  324: Inference (test):avg data time: 6.19e-03, avg batch time: 0.1913, average loss: 2.2772
[09/17 02:53:53][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.08	top5: 55.62	
[09/17 02:53:53][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/17 02:54:02][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.14e-01, avg batch time: 0.5177, average train loss: 2.3868
[09/17 02:54:05][INFO] visual_prompt:  324: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1427, average loss: 2.3444
[09/17 02:54:05][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.50	top5: 58.00	
[09/17 02:54:26][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.272, 0.1858 s / batch. (data: 1.57e-04)max mem: 17.22448 GB 
[09/17 02:54:44][INFO] visual_prompt:  324: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1925, average loss: 2.3859
[09/17 02:54:45][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.08	top5: 55.19	
[09/17 02:54:45][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/17 02:54:54][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.14e-01, avg batch time: 0.5152, average train loss: 2.3459
[09/17 02:54:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1424, average loss: 2.4907
[09/17 02:54:57][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 13.00	top5: 51.50	
[09/17 02:55:18][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.435, 0.2156 s / batch. (data: 2.31e-02)max mem: 17.22448 GB 
[09/17 02:55:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1934, average loss: 2.4125
[09/17 02:55:37][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.05	top5: 55.86	
[09/17 02:55:37][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/17 02:55:46][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 1.13e-01, avg batch time: 0.5149, average train loss: 2.4150
[09/17 02:55:49][INFO] visual_prompt:  324: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1424, average loss: 2.4948
[09/17 02:55:49][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 7.00	top5: 52.00	
[09/17 02:56:10][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.443, 0.1821 s / batch. (data: 1.28e-04)max mem: 17.22448 GB 
[09/17 02:56:29][INFO] visual_prompt:  324: Inference (test):avg data time: 8.85e-03, avg batch time: 0.1942, average loss: 2.4128
[09/17 02:56:29][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.40	top5: 55.52	
[09/17 02:56:29][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/17 02:56:38][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 1.04e-01, avg batch time: 0.5053, average train loss: 2.3187
[09/17 02:56:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1449, average loss: 2.3442
[09/17 02:56:41][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 61.00	
[09/17 02:57:02][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.571, 0.2016 s / batch. (data: 1.31e-02)max mem: 17.22448 GB 
[09/17 02:57:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1955, average loss: 2.5035
[09/17 02:57:21][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 55.46	
[09/17 02:57:21][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/17 02:57:31][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 1.14e-01, avg batch time: 0.5178, average train loss: 2.3829
[09/17 02:57:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1426, average loss: 2.3585
[09/17 02:57:34][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 59.50	
[09/17 02:57:55][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.251, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22448 GB 
[09/17 02:58:14][INFO] visual_prompt:  324: Inference (test):avg data time: 6.98e-03, avg batch time: 0.1921, average loss: 2.3144
[09/17 02:58:14][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 61.51	
[09/17 02:58:14][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/17 02:58:23][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 9.91e-02, avg batch time: 0.5003, average train loss: 2.4685
[09/17 02:58:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1426, average loss: 2.5447
[09/17 02:58:26][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.00	top5: 57.50	
[09/17 02:58:47][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.555, 0.2162 s / batch. (data: 1.37e-04)max mem: 17.22448 GB 
[09/17 02:59:06][INFO] visual_prompt:  324: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1955, average loss: 2.6222
[09/17 02:59:06][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 10.71	top5: 56.09	
[09/17 02:59:06][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/17 02:59:15][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.09e-01, avg batch time: 0.5122, average train loss: 2.3020
[09/17 02:59:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1424, average loss: 2.0885
[09/17 02:59:18][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 73.50	
[09/17 02:59:39][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.034, 0.1959 s / batch. (data: 1.41e-02)max mem: 17.22448 GB 
[09/17 02:59:58][INFO] visual_prompt:  324: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1925, average loss: 2.1054
[09/17 02:59:58][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.49	top5: 70.64	
[09/17 02:59:58][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/17 03:00:07][INFO] visual_prompt:  219: Epoch 52 / 100: avg data time: 9.25e-02, avg batch time: 0.4949, average train loss: 2.2861
[09/17 03:00:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1427, average loss: 2.3925
[09/17 03:00:10][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 59.50	
[09/17 03:00:31][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.256, 0.1973 s / batch. (data: 1.51e-02)max mem: 17.22448 GB 
[09/17 03:00:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1925, average loss: 2.3967
[09/17 03:00:50][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.23	top5: 62.39	
[09/17 03:00:50][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/17 03:00:59][INFO] visual_prompt:  219: Epoch 53 / 100: avg data time: 1.11e-01, avg batch time: 0.5192, average train loss: 2.3382
[09/17 03:01:02][INFO] visual_prompt:  324: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1427, average loss: 2.6204
[09/17 03:01:02][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.00	top5: 48.50	
[09/17 03:01:23][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.484, 0.1830 s / batch. (data: 1.43e-04)max mem: 17.22448 GB 
[09/17 03:01:42][INFO] visual_prompt:  324: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1930, average loss: 2.5079
[09/17 03:01:42][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 11.14	top5: 55.44	
[09/17 03:01:42][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/17 03:01:51][INFO] visual_prompt:  219: Epoch 54 / 100: avg data time: 1.01e-01, avg batch time: 0.5062, average train loss: 2.3472
[09/17 03:01:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1426, average loss: 2.2750
[09/17 03:01:54][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 61.50	
[09/17 03:02:15][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.248, 0.1855 s / batch. (data: 1.27e-04)max mem: 17.22448 GB 
[09/17 03:02:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.02e-03, avg batch time: 0.1930, average loss: 2.2636
[09/17 03:02:34][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 15.32	top5: 63.20	
[09/17 03:02:34][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/17 03:02:43][INFO] visual_prompt:  219: Epoch 55 / 100: avg data time: 1.07e-01, avg batch time: 0.5085, average train loss: 2.2431
[09/17 03:02:46][INFO] visual_prompt:  324: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1467, average loss: 2.1017
[09/17 03:02:46][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 12.50	top5: 76.50	
[09/17 03:03:08][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.029, 0.1973 s / batch. (data: 1.51e-02)max mem: 17.22448 GB 
[09/17 03:03:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1946, average loss: 2.1083
[09/17 03:03:26][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 14.91	top5: 74.50	
[09/17 03:03:26][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 2.5
[09/17 03:03:35][INFO] visual_prompt:  219: Epoch 56 / 100: avg data time: 1.01e-01, avg batch time: 0.5032, average train loss: 2.1058
[09/17 03:03:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1427, average loss: 2.1335
[09/17 03:03:38][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.50	top5: 79.50	
[09/17 03:03:59][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.173, 0.2246 s / batch. (data: 4.31e-02)max mem: 17.22448 GB 
[09/17 03:04:18][INFO] visual_prompt:  324: Inference (test):avg data time: 8.62e-03, avg batch time: 0.1945, average loss: 2.1645
[09/17 03:04:18][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.37	top5: 78.12	
[09/17 03:04:18][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/17 03:04:27][INFO] visual_prompt:  219: Epoch 57 / 100: avg data time: 9.84e-02, avg batch time: 0.5017, average train loss: 2.2760
[09/17 03:04:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1427, average loss: 2.0510
[09/17 03:04:30][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.00	top5: 82.50	
[09/17 03:04:51][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.187, 0.1942 s / batch. (data: 1.24e-02)max mem: 17.22448 GB 
[09/17 03:05:10][INFO] visual_prompt:  324: Inference (test):avg data time: 6.64e-03, avg batch time: 0.1926, average loss: 2.1396
[09/17 03:05:10][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.35	top5: 77.56	
[09/17 03:05:10][INFO] visual_prompt:  246: Best epoch 57: best metric: 0.220
[09/17 03:05:10][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/17 03:05:19][INFO] visual_prompt:  219: Epoch 58 / 100: avg data time: 1.04e-01, avg batch time: 0.5116, average train loss: 2.1575
[09/17 03:05:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1426, average loss: 2.1562
[09/17 03:05:22][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.50	top5: 66.00	
[09/17 03:05:43][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.338, 0.2019 s / batch. (data: 1.99e-02)max mem: 17.22448 GB 
[09/17 03:06:02][INFO] visual_prompt:  324: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1925, average loss: 2.2711
[09/17 03:06:02][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 16.56	top5: 62.30	
[09/17 03:06:02][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/17 03:06:11][INFO] visual_prompt:  219: Epoch 59 / 100: avg data time: 1.12e-01, avg batch time: 0.5300, average train loss: 2.0876
[09/17 03:06:14][INFO] visual_prompt:  324: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1426, average loss: 1.9132
[09/17 03:06:14][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.00	top5: 82.50	
[09/17 03:06:35][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.833, 0.1859 s / batch. (data: 1.01e-04)max mem: 17.22448 GB 
[09/17 03:06:54][INFO] visual_prompt:  324: Inference (test):avg data time: 8.80e-03, avg batch time: 0.1946, average loss: 1.9454
[09/17 03:06:54][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.62	top5: 82.46	
[09/17 03:06:54][INFO] visual_prompt:  246: Best epoch 59: best metric: 0.240
[09/17 03:06:54][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/17 03:07:03][INFO] visual_prompt:  219: Epoch 60 / 100: avg data time: 1.10e-01, avg batch time: 0.5112, average train loss: 2.0137
[09/17 03:07:06][INFO] visual_prompt:  324: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1428, average loss: 1.8951
[09/17 03:07:06][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.50	top5: 87.50	
[09/17 03:07:28][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.060, 0.1951 s / batch. (data: 1.34e-02)max mem: 17.22448 GB 
[09/17 03:07:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1920, average loss: 2.0343
[09/17 03:07:46][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.02	top5: 81.44	
[09/17 03:07:46][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/17 03:07:55][INFO] visual_prompt:  219: Epoch 61 / 100: avg data time: 1.14e-01, avg batch time: 0.5140, average train loss: 2.0259
[09/17 03:07:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1427, average loss: 1.8579
[09/17 03:07:58][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.00	top5: 84.50	
[09/17 03:08:19][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.916, 0.1977 s / batch. (data: 1.56e-02)max mem: 17.22448 GB 
[09/17 03:08:38][INFO] visual_prompt:  324: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1933, average loss: 2.0215
[09/17 03:08:38][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.57	top5: 78.13	
[09/17 03:08:38][INFO] visual_prompt:  246: Best epoch 61: best metric: 0.280
[09/17 03:08:38][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/17 03:08:47][INFO] visual_prompt:  219: Epoch 62 / 100: avg data time: 1.15e-01, avg batch time: 0.5162, average train loss: 2.0235
[09/17 03:08:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1427, average loss: 2.2805
[09/17 03:08:50][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.00	top5: 76.50	
[09/17 03:09:11][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.482, 0.1827 s / batch. (data: 1.20e-04)max mem: 17.22448 GB 
[09/17 03:09:30][INFO] visual_prompt:  324: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1952, average loss: 2.3748
[09/17 03:09:30][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 15.44	top5: 76.30	
[09/17 03:09:30][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/17 03:09:39][INFO] visual_prompt:  219: Epoch 63 / 100: avg data time: 1.01e-01, avg batch time: 0.5028, average train loss: 2.0744
[09/17 03:09:42][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1428, average loss: 1.9115
[09/17 03:09:42][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.00	top5: 85.50	
[09/17 03:10:04][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.867, 0.2050 s / batch. (data: 1.24e-02)max mem: 17.22448 GB 
[09/17 03:10:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1929, average loss: 2.0147
[09/17 03:10:22][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.37	top5: 84.21	
[09/17 03:10:22][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/17 03:10:31][INFO] visual_prompt:  219: Epoch 64 / 100: avg data time: 1.05e-01, avg batch time: 0.5078, average train loss: 1.9008
[09/17 03:10:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1427, average loss: 1.8690
[09/17 03:10:34][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.50	top5: 91.50	
[09/17 03:10:55][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.047, 0.1952 s / batch. (data: 1.10e-04)max mem: 17.22448 GB 
[09/17 03:11:14][INFO] visual_prompt:  324: Inference (test):avg data time: 6.43e-03, avg batch time: 0.1920, average loss: 2.0226
[09/17 03:11:14][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 19.41	top5: 84.72	
[09/17 03:11:14][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/17 03:11:23][INFO] visual_prompt:  219: Epoch 65 / 100: avg data time: 1.11e-01, avg batch time: 0.5128, average train loss: 2.1043
[09/17 03:11:27][INFO] visual_prompt:  324: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1427, average loss: 2.0713
[09/17 03:11:27][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.50	top5: 76.50	
[09/17 03:11:48][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.163, 0.1982 s / batch. (data: 1.49e-04)max mem: 17.22448 GB 
[09/17 03:12:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1954, average loss: 2.1895
[09/17 03:12:07][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 17.80	top5: 71.76	
[09/17 03:12:07][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/17 03:12:16][INFO] visual_prompt:  219: Epoch 66 / 100: avg data time: 1.04e-01, avg batch time: 0.5062, average train loss: 2.0201
[09/17 03:12:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1426, average loss: 1.9207
[09/17 03:12:19][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.00	top5: 87.50	
[09/17 03:12:41][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.009, 0.1977 s / batch. (data: 1.37e-02)max mem: 17.22448 GB 
[09/17 03:12:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1937, average loss: 2.0498
[09/17 03:12:59][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.29	top5: 84.27	
[09/17 03:12:59][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/17 03:13:09][INFO] visual_prompt:  219: Epoch 67 / 100: avg data time: 9.66e-02, avg batch time: 0.4987, average train loss: 1.8240
[09/17 03:13:12][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1427, average loss: 2.0603
[09/17 03:13:12][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 18.00	top5: 81.50	
[09/17 03:13:33][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.135, 0.1962 s / batch. (data: 1.40e-02)max mem: 17.22448 GB 
[09/17 03:13:52][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1938, average loss: 2.1882
[09/17 03:13:52][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 20.15	top5: 79.37	
[09/17 03:13:52][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/17 03:14:01][INFO] visual_prompt:  219: Epoch 68 / 100: avg data time: 1.14e-01, avg batch time: 0.5154, average train loss: 1.8298
[09/17 03:14:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1425, average loss: 1.6697
[09/17 03:14:04][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.50	top5: 93.00	
[09/17 03:14:25][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.809, 0.1890 s / batch. (data: 1.12e-04)max mem: 17.22448 GB 
[09/17 03:14:44][INFO] visual_prompt:  324: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1927, average loss: 1.8666
[09/17 03:14:44][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.07	top5: 86.70	
[09/17 03:14:44][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/17 03:14:53][INFO] visual_prompt:  219: Epoch 69 / 100: avg data time: 1.17e-01, avg batch time: 0.5185, average train loss: 1.6988
[09/17 03:14:56][INFO] visual_prompt:  324: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1425, average loss: 1.6105
[09/17 03:14:56][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.00	top5: 97.50	
[09/17 03:15:17][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.773, 0.1829 s / batch. (data: 1.07e-04)max mem: 17.22448 GB 
[09/17 03:15:36][INFO] visual_prompt:  324: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1925, average loss: 1.8838
[09/17 03:15:36][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.65	top5: 89.53	
[09/17 03:15:36][INFO] visual_prompt:  246: Best epoch 69: best metric: 0.300
[09/17 03:15:36][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/17 03:15:45][INFO] visual_prompt:  219: Epoch 70 / 100: avg data time: 1.01e-01, avg batch time: 0.5081, average train loss: 1.7126
[09/17 03:15:48][INFO] visual_prompt:  324: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1427, average loss: 1.6849
[09/17 03:15:48][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.50	top5: 94.00	
[09/17 03:16:09][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.817, 0.1832 s / batch. (data: 9.13e-05)max mem: 17.22448 GB 
[09/17 03:16:28][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1924, average loss: 1.8932
[09/17 03:16:28][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.74	top5: 87.10	
[09/17 03:16:28][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/17 03:16:37][INFO] visual_prompt:  219: Epoch 71 / 100: avg data time: 1.08e-01, avg batch time: 0.5080, average train loss: 1.7234
[09/17 03:16:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1428, average loss: 1.6238
[09/17 03:16:40][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.00	top5: 94.00	
[09/17 03:17:01][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.757, 0.1831 s / batch. (data: 1.27e-04)max mem: 17.22448 GB 
[09/17 03:17:20][INFO] visual_prompt:  324: Inference (test):avg data time: 8.53e-03, avg batch time: 0.1931, average loss: 1.8470
[09/17 03:17:20][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 23.93	top5: 88.95	
[09/17 03:17:20][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/17 03:17:29][INFO] visual_prompt:  219: Epoch 72 / 100: avg data time: 1.04e-01, avg batch time: 0.5038, average train loss: 1.7089
[09/17 03:17:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1428, average loss: 1.5985
[09/17 03:17:32][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 34.50	top5: 95.50	
[09/17 03:17:53][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.799, 0.2063 s / batch. (data: 1.41e-02)max mem: 17.22448 GB 
[09/17 03:18:12][INFO] visual_prompt:  324: Inference (test):avg data time: 8.59e-03, avg batch time: 0.1931, average loss: 1.8296
[09/17 03:18:12][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.24	top5: 89.05	
[09/17 03:18:12][INFO] visual_prompt:  246: Best epoch 72: best metric: 0.345
[09/17 03:18:12][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/17 03:18:21][INFO] visual_prompt:  219: Epoch 73 / 100: avg data time: 1.11e-01, avg batch time: 0.5133, average train loss: 1.6090
[09/17 03:18:25][INFO] visual_prompt:  324: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1426, average loss: 1.8488
[09/17 03:18:25][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.50	top5: 92.00	
[09/17 03:18:46][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.977, 0.1967 s / batch. (data: 1.47e-02)max mem: 17.22448 GB 
[09/17 03:19:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1933, average loss: 2.2034
[09/17 03:19:04][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 21.42	top5: 84.63	
[09/17 03:19:04][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/17 03:19:14][INFO] visual_prompt:  219: Epoch 74 / 100: avg data time: 1.13e-01, avg batch time: 0.5154, average train loss: 1.7082
[09/17 03:19:17][INFO] visual_prompt:  324: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1425, average loss: 1.6693
[09/17 03:19:17][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.50	top5: 94.00	
[09/17 03:19:38][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.835, 0.1962 s / batch. (data: 1.30e-04)max mem: 17.22448 GB 
[09/17 03:19:57][INFO] visual_prompt:  324: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1930, average loss: 2.0280
[09/17 03:19:57][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.01	top5: 86.70	
[09/17 03:19:57][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/17 03:20:06][INFO] visual_prompt:  219: Epoch 75 / 100: avg data time: 1.16e-01, avg batch time: 0.5161, average train loss: 1.6468
[09/17 03:20:09][INFO] visual_prompt:  324: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1426, average loss: 1.6091
[09/17 03:20:09][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.00	top5: 92.00	
[09/17 03:20:30][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.848, 0.1825 s / batch. (data: 1.03e-04)max mem: 17.22448 GB 
[09/17 03:20:49][INFO] visual_prompt:  324: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1930, average loss: 2.0102
[09/17 03:20:49][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 22.52	top5: 86.49	
[09/17 03:20:49][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/17 03:20:58][INFO] visual_prompt:  219: Epoch 76 / 100: avg data time: 1.09e-01, avg batch time: 0.5114, average train loss: 1.5637
[09/17 03:21:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1426, average loss: 1.4616
[09/17 03:21:01][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.00	top5: 98.00	
[09/17 03:21:22][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.755, 0.1963 s / batch. (data: 1.39e-02)max mem: 17.22448 GB 
[09/17 03:21:41][INFO] visual_prompt:  324: Inference (test):avg data time: 7.05e-03, avg batch time: 0.1921, average loss: 1.8837
[09/17 03:21:41][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 26.37	top5: 89.96	
[09/17 03:21:41][INFO] visual_prompt:  246: Best epoch 76: best metric: 0.400
[09/17 03:21:41][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/17 03:21:50][INFO] visual_prompt:  219: Epoch 77 / 100: avg data time: 1.14e-01, avg batch time: 0.5158, average train loss: 1.4946
[09/17 03:21:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1427, average loss: 1.3302
[09/17 03:21:53][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 37.00	top5: 99.00	
[09/17 03:22:14][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.842, 0.1877 s / batch. (data: 5.35e-03)max mem: 17.22448 GB 
[09/17 03:22:33][INFO] visual_prompt:  324: Inference (test):avg data time: 8.66e-03, avg batch time: 0.1936, average loss: 1.9078
[09/17 03:22:33][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.52	top5: 90.71	
[09/17 03:22:33][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/17 03:22:42][INFO] visual_prompt:  219: Epoch 78 / 100: avg data time: 1.12e-01, avg batch time: 0.5137, average train loss: 1.5277
[09/17 03:22:46][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1429, average loss: 1.3529
[09/17 03:22:46][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.50	top5: 99.00	
[09/17 03:23:07][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.570, 0.1913 s / batch. (data: 1.30e-04)max mem: 17.22448 GB 
[09/17 03:23:25][INFO] visual_prompt:  324: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1929, average loss: 1.8249
[09/17 03:23:25][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.98	top5: 90.16	
[09/17 03:23:25][INFO] visual_prompt:  246: Best epoch 78: best metric: 0.415
[09/17 03:23:25][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/17 03:23:34][INFO] visual_prompt:  219: Epoch 79 / 100: avg data time: 1.15e-01, avg batch time: 0.5156, average train loss: 1.4563
[09/17 03:23:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1426, average loss: 1.4414
[09/17 03:23:38][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 35.00	top5: 98.50	
[09/17 03:23:59][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.781, 0.1851 s / batch. (data: 1.55e-04)max mem: 17.22448 GB 
[09/17 03:24:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1931, average loss: 1.8740
[09/17 03:24:17][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.08	top5: 90.12	
[09/17 03:24:17][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/17 03:24:27][INFO] visual_prompt:  219: Epoch 80 / 100: avg data time: 1.11e-01, avg batch time: 0.5157, average train loss: 1.3932
[09/17 03:24:30][INFO] visual_prompt:  324: Inference (val):avg data time: 4.47e-05, avg batch time: 0.1445, average loss: 1.2642
[09/17 03:24:30][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 45.00	top5: 99.50	
[09/17 03:24:51][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.722, 0.1944 s / batch. (data: 1.23e-02)max mem: 17.22448 GB 
[09/17 03:25:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1931, average loss: 1.8604
[09/17 03:25:09][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.84	top5: 91.12	
[09/17 03:25:09][INFO] visual_prompt:  246: Best epoch 80: best metric: 0.450
[09/17 03:25:09][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/17 03:25:19][INFO] visual_prompt:  219: Epoch 81 / 100: avg data time: 1.04e-01, avg batch time: 0.5049, average train loss: 1.3514
[09/17 03:25:22][INFO] visual_prompt:  324: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1427, average loss: 1.3733
[09/17 03:25:22][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 33.00	top5: 99.50	
[09/17 03:25:43][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.794, 0.1826 s / batch. (data: 1.17e-04)max mem: 17.22448 GB 
[09/17 03:26:01][INFO] visual_prompt:  324: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1932, average loss: 2.1137
[09/17 03:26:01][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.21	top5: 88.58	
[09/17 03:26:01][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/17 03:26:11][INFO] visual_prompt:  219: Epoch 82 / 100: avg data time: 1.08e-01, avg batch time: 0.5101, average train loss: 1.2901
[09/17 03:26:14][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1429, average loss: 1.2426
[09/17 03:26:14][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 41.50	top5: 99.00	
[09/17 03:26:35][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.868, 0.1965 s / batch. (data: 6.37e-03)max mem: 17.22448 GB 
[09/17 03:26:54][INFO] visual_prompt:  324: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1931, average loss: 1.9380
[09/17 03:26:54][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 27.65	top5: 91.14	
[09/17 03:26:54][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/17 03:27:03][INFO] visual_prompt:  219: Epoch 83 / 100: avg data time: 1.13e-01, avg batch time: 0.5146, average train loss: 1.2676
[09/17 03:27:06][INFO] visual_prompt:  324: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1426, average loss: 1.1521
[09/17 03:27:06][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 51.50	top5: 99.50	
[09/17 03:27:27][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.818, 0.2099 s / batch. (data: 2.80e-02)max mem: 17.22448 GB 
[09/17 03:27:46][INFO] visual_prompt:  324: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1926, average loss: 2.0379
[09/17 03:27:46][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.47	top5: 90.77	
[09/17 03:27:46][INFO] visual_prompt:  246: Best epoch 83: best metric: 0.515
[09/17 03:27:46][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/17 03:27:55][INFO] visual_prompt:  219: Epoch 84 / 100: avg data time: 1.03e-01, avg batch time: 0.5089, average train loss: 1.2539
[09/17 03:27:58][INFO] visual_prompt:  324: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1427, average loss: 1.2841
[09/17 03:27:58][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 40.50	top5: 99.00	
[09/17 03:28:19][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.839, 0.1829 s / batch. (data: 1.11e-04)max mem: 17.22448 GB 
[09/17 03:28:38][INFO] visual_prompt:  324: Inference (test):avg data time: 8.62e-03, avg batch time: 0.1943, average loss: 2.0963
[09/17 03:28:38][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 25.95	top5: 89.26	
[09/17 03:28:38][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/17 03:28:47][INFO] visual_prompt:  219: Epoch 85 / 100: avg data time: 1.01e-01, avg batch time: 0.5058, average train loss: 1.3686
[09/17 03:28:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1425, average loss: 1.3454
[09/17 03:28:50][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 38.50	top5: 99.50	
[09/17 03:29:11][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.862, 0.1942 s / batch. (data: 1.25e-02)max mem: 17.22448 GB 
[09/17 03:29:30][INFO] visual_prompt:  324: Inference (test):avg data time: 6.06e-03, avg batch time: 0.1920, average loss: 2.0839
[09/17 03:29:30][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 24.64	top5: 89.49	
[09/17 03:29:30][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/17 03:29:39][INFO] visual_prompt:  219: Epoch 86 / 100: avg data time: 1.20e-01, avg batch time: 0.5199, average train loss: 1.3347
[09/17 03:29:42][INFO] visual_prompt:  324: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1428, average loss: 1.1451
[09/17 03:29:42][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 49.00	top5: 100.00	
[09/17 03:30:04][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.602, 0.1878 s / batch. (data: 1.64e-04)max mem: 17.22448 GB 
[09/17 03:30:22][INFO] visual_prompt:  324: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1935, average loss: 1.8871
[09/17 03:30:22][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.47	top5: 90.53	
[09/17 03:30:22][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/17 03:30:31][INFO] visual_prompt:  219: Epoch 87 / 100: avg data time: 9.85e-02, avg batch time: 0.5038, average train loss: 1.1786
[09/17 03:30:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1427, average loss: 1.1111
[09/17 03:30:35][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 50.50	top5: 100.00	
[09/17 03:30:56][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.763, 0.1903 s / batch. (data: 1.52e-04)max mem: 17.22448 GB 
[09/17 03:31:14][INFO] visual_prompt:  324: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1939, average loss: 1.9669
[09/17 03:31:14][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.53	top5: 91.28	
[09/17 03:31:14][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/17 03:31:24][INFO] visual_prompt:  219: Epoch 88 / 100: avg data time: 1.06e-01, avg batch time: 0.5125, average train loss: 1.1022
[09/17 03:31:27][INFO] visual_prompt:  324: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1428, average loss: 1.0594
[09/17 03:31:27][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 51.00	top5: 100.00	
[09/17 03:31:48][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.863, 0.1947 s / batch. (data: 1.28e-04)max mem: 17.22448 GB 
[09/17 03:32:06][INFO] visual_prompt:  324: Inference (test):avg data time: 7.15e-03, avg batch time: 0.1928, average loss: 2.2067
[09/17 03:32:06][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.76	top5: 90.49	
[09/17 03:32:06][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/17 03:32:15][INFO] visual_prompt:  219: Epoch 89 / 100: avg data time: 9.68e-02, avg batch time: 0.5044, average train loss: 1.1273
[09/17 03:32:18][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1427, average loss: 1.0881
[09/17 03:32:18][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 50.00	top5: 100.00	
[09/17 03:32:40][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.090, 0.1823 s / batch. (data: 4.27e-05)max mem: 17.22448 GB 
[09/17 03:32:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1933, average loss: 2.1682
[09/17 03:32:58][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 28.09	top5: 90.43	
[09/17 03:32:58][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/17 03:33:08][INFO] visual_prompt:  219: Epoch 90 / 100: avg data time: 1.24e-01, avg batch time: 0.5260, average train loss: 1.0922
[09/17 03:33:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1427, average loss: 0.9526
[09/17 03:33:11][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 59.50	top5: 100.00	
[09/17 03:33:32][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.916, 0.1860 s / batch. (data: 9.97e-05)max mem: 17.22448 GB 
[09/17 03:33:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1924, average loss: 2.2325
[09/17 03:33:50][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.79	top5: 90.56	
[09/17 03:33:50][INFO] visual_prompt:  246: Best epoch 90: best metric: 0.595
[09/17 03:33:50][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/17 03:34:00][INFO] visual_prompt:  219: Epoch 91 / 100: avg data time: 1.09e-01, avg batch time: 0.5112, average train loss: 0.9731
[09/17 03:34:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1428, average loss: 0.9562
[09/17 03:34:03][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 56.50	top5: 100.00	
[09/17 03:34:24][INFO] visual_prompt:  314: 	Test 100/190. loss: 1.987, 0.1952 s / batch. (data: 1.25e-02)max mem: 17.22448 GB 
[09/17 03:34:43][INFO] visual_prompt:  324: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1928, average loss: 2.3432
[09/17 03:34:43][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.00	top5: 90.82	
[09/17 03:34:43][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/17 03:34:52][INFO] visual_prompt:  219: Epoch 92 / 100: avg data time: 1.06e-01, avg batch time: 0.5089, average train loss: 0.9677
[09/17 03:34:55][INFO] visual_prompt:  324: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1429, average loss: 0.8485
[09/17 03:34:55][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 65.00	top5: 100.00	
[09/17 03:35:16][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.023, 0.1822 s / batch. (data: 9.23e-05)max mem: 17.22448 GB 
[09/17 03:35:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1923, average loss: 2.3623
[09/17 03:35:34][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.75	top5: 91.28	
[09/17 03:35:34][INFO] visual_prompt:  246: Best epoch 92: best metric: 0.650
[09/17 03:35:34][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/17 03:35:43][INFO] visual_prompt:  219: Epoch 93 / 100: avg data time: 1.07e-01, avg batch time: 0.5091, average train loss: 0.8801
[09/17 03:35:47][INFO] visual_prompt:  324: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1441, average loss: 0.8663
[09/17 03:35:47][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 63.00	top5: 100.00	
[09/17 03:36:08][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.053, 0.1945 s / batch. (data: 1.25e-02)max mem: 17.22448 GB 
[09/17 03:36:27][INFO] visual_prompt:  324: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1937, average loss: 2.5047
[09/17 03:36:27][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.98	top5: 90.84	
[09/17 03:36:27][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/17 03:36:36][INFO] visual_prompt:  219: Epoch 94 / 100: avg data time: 1.13e-01, avg batch time: 0.5147, average train loss: 0.8622
[09/17 03:36:39][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1426, average loss: 0.8003
[09/17 03:36:39][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 65.50	top5: 100.00	
[09/17 03:37:00][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.152, 0.1981 s / batch. (data: 1.25e-04)max mem: 17.22448 GB 
[09/17 03:37:19][INFO] visual_prompt:  324: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1936, average loss: 2.6164
[09/17 03:37:19][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.01	top5: 90.80	
[09/17 03:37:19][INFO] visual_prompt:  246: Best epoch 94: best metric: 0.655
[09/17 03:37:19][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/17 03:37:28][INFO] visual_prompt:  219: Epoch 95 / 100: avg data time: 9.61e-02, avg batch time: 0.5036, average train loss: 0.8857
[09/17 03:37:31][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1428, average loss: 0.7738
[09/17 03:37:31][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 73.00	top5: 100.00	
[09/17 03:37:52][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.235, 0.1881 s / batch. (data: 5.97e-03)max mem: 17.22448 GB 
[09/17 03:38:11][INFO] visual_prompt:  324: Inference (test):avg data time: 6.30e-03, avg batch time: 0.1927, average loss: 2.5446
[09/17 03:38:11][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.30	top5: 91.19	
[09/17 03:38:11][INFO] visual_prompt:  246: Best epoch 95: best metric: 0.730
[09/17 03:38:11][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/17 03:38:20][INFO] visual_prompt:  219: Epoch 96 / 100: avg data time: 1.08e-01, avg batch time: 0.5099, average train loss: 0.7961
[09/17 03:38:23][INFO] visual_prompt:  324: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1426, average loss: 0.7894
[09/17 03:38:23][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 68.00	top5: 100.00	
[09/17 03:38:44][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.263, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22448 GB 
[09/17 03:39:02][INFO] visual_prompt:  324: Inference (test):avg data time: 8.59e-03, avg batch time: 0.1933, average loss: 2.6455
[09/17 03:39:02][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.86	top5: 91.00	
[09/17 03:39:02][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/17 03:39:11][INFO] visual_prompt:  219: Epoch 97 / 100: avg data time: 9.57e-02, avg batch time: 0.4992, average train loss: 0.7710
[09/17 03:39:15][INFO] visual_prompt:  324: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1428, average loss: 0.7852
[09/17 03:39:15][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 70.00	top5: 100.00	
[09/17 03:39:36][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.324, 0.1953 s / batch. (data: 1.34e-02)max mem: 17.22448 GB 
[09/17 03:39:54][INFO] visual_prompt:  324: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1922, average loss: 2.7003
[09/17 03:39:54][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 29.79	top5: 90.86	
[09/17 03:39:54][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/17 03:40:03][INFO] visual_prompt:  219: Epoch 98 / 100: avg data time: 1.05e-01, avg batch time: 0.5301, average train loss: 0.7643
[09/17 03:40:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1431, average loss: 0.7837
[09/17 03:40:07][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 69.50	top5: 100.00	
[09/17 03:40:28][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.348, 0.1829 s / batch. (data: 1.68e-04)max mem: 17.22448 GB 
[09/17 03:40:46][INFO] visual_prompt:  324: Inference (test):avg data time: 8.42e-03, avg batch time: 0.1932, average loss: 2.7326
[09/17 03:40:46][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.03	top5: 90.87	
[09/17 03:40:46][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/17 03:40:56][INFO] visual_prompt:  219: Epoch 99 / 100: avg data time: 1.15e-01, avg batch time: 0.5173, average train loss: 0.7786
[09/17 03:40:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1425, average loss: 0.7801
[09/17 03:40:59][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 72.00	top5: 100.00	
[09/17 03:41:20][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.360, 0.1829 s / batch. (data: 1.04e-04)max mem: 17.22448 GB 
[09/17 03:41:39][INFO] visual_prompt:  324: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1940, average loss: 2.7268
[09/17 03:41:39][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.05	top5: 90.90	
[09/17 03:41:39][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/17 03:41:48][INFO] visual_prompt:  219: Epoch 100 / 100: avg data time: 9.51e-02, avg batch time: 0.4981, average train loss: 0.7595
[09/17 03:41:51][INFO] visual_prompt:  324: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1430, average loss: 0.7781
[09/17 03:41:51][INFO] visual_prompt:  113: Classification results with val_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 69.50	top5: 100.00	
[09/17 03:42:12][INFO] visual_prompt:  314: 	Test 100/190. loss: 2.348, 0.1830 s / batch. (data: 1.18e-04)max mem: 17.22448 GB 
[09/17 03:42:31][INFO] visual_prompt:  324: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1928, average loss: 2.7478
[09/17 03:42:31][INFO] visual_prompt:  113: Classification results with test_vtab-smallnorb(predicted_attribute="label_elevation"): top1: 30.00	top5: 90.78	
