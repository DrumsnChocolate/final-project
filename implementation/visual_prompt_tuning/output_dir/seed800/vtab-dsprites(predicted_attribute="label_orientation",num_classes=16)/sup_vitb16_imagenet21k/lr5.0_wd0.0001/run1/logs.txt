[09/17 06:57:18][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/17 06:57:18][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/17 06:57:18][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/17 06:57:18][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/17 06:57:18][INFO] visual_prompt:  108: Training with config:
[09/17 06:57:18][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/17 06:57:18][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/17 06:57:23][INFO] visual_prompt:   69: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset trainval...
[09/17 06:57:25][INFO] visual_prompt:   88: Number of images: 1000
[09/17 06:57:25][INFO] visual_prompt:   90: Number of classes: 16 / 16
[09/17 06:57:25][INFO] visual_prompt:   70: Loading validation data...
[09/17 06:57:25][INFO] visual_prompt:   69: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset val...
[09/17 06:57:25][INFO] visual_prompt:   88: Number of images: 200
[09/17 06:57:25][INFO] visual_prompt:   90: Number of classes: 16 / 16
[09/17 06:57:25][INFO] visual_prompt:   73: Loading test data...
[09/17 06:57:25][INFO] visual_prompt:   69: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset test...
[09/17 06:58:57][INFO] visual_prompt:   88: Number of images: 73728
[09/17 06:58:57][INFO] visual_prompt:   90: Number of classes: 16 / 16
[09/17 06:58:57][INFO] visual_prompt:  100: Constructing models...
[09/17 06:59:00][INFO] visual_prompt:   53: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/17 06:59:00][INFO] visual_prompt:   54: tuned percent:1.077
[09/17 06:59:05][INFO] visual_prompt:   40: Device used for model: 0
[09/17 06:59:05][INFO] visual_prompt:  103: Setting up Evalutator...
[09/17 06:59:05][INFO] visual_prompt:  105: Setting up Trainer...
[09/17 06:59:05][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/17 06:59:05][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/17 06:59:21][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 2.94e-01, avg batch time: 0.7836, average train loss: 3.0733
[09/17 06:59:33][INFO] visual_prompt:  324: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1572, average loss: 3.0998
[09/17 06:59:33][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 25.00	
[09/17 06:59:57][INFO] visual_prompt:  314: 	Test 100/1152. loss: 3.054, 0.1969 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/17 07:00:17][INFO] visual_prompt:  314: 	Test 200/1152. loss: 3.001, 0.1963 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/17 07:00:36][INFO] visual_prompt:  314: 	Test 300/1152. loss: 3.102, 0.1833 s / batch. (data: 1.73e-03)max mem: 17.22454 GB 
[09/17 07:00:56][INFO] visual_prompt:  314: 	Test 400/1152. loss: 2.974, 0.2298 s / batch. (data: 4.82e-02)max mem: 17.22454 GB 
[09/17 07:01:15][INFO] visual_prompt:  314: 	Test 500/1152. loss: 3.142, 0.2029 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/17 07:01:35][INFO] visual_prompt:  314: 	Test 600/1152. loss: 3.139, 0.1829 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/17 07:01:54][INFO] visual_prompt:  314: 	Test 700/1152. loss: 3.123, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/17 07:02:14][INFO] visual_prompt:  314: 	Test 800/1152. loss: 3.167, 0.1829 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/17 07:02:38][INFO] visual_prompt:  314: 	Test 900/1152. loss: 3.019, 0.1924 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/17 07:02:58][INFO] visual_prompt:  314: 	Test 1000/1152. loss: 3.012, 0.1952 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/17 07:03:17][INFO] visual_prompt:  314: 	Test 1100/1152. loss: 3.238, 0.2104 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/17 07:03:32][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1985, average loss: 3.0932
[09/17 07:03:32][INFO] visual_prompt:  113: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 27.49	
[09/17 07:03:32][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.090
[09/17 07:03:32][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/17 07:03:47][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 2.72e-01, avg batch time: 0.6770, average train loss: 3.5412
[09/17 07:03:55][INFO] visual_prompt:  324: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1421, average loss: 2.8391
[09/17 07:03:55][INFO] visual_prompt:  113: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.00	
[09/17 07:04:19][INFO] visual_prompt:  314: 	Test 100/1152. loss: 2.963, 0.2007 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/17 07:04:38][INFO] visual_prompt:  314: 	Test 200/1152. loss: 2.762, 0.1819 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/17 07:04:57][INFO] visual_prompt:  314: 	Test 300/1152. loss: 2.821, 0.1813 s / batch. (data: 3.39e-05)max mem: 17.22454 GB 
[09/17 07:05:17][INFO] visual_prompt:  314: 	Test 400/1152. loss: 2.878, 0.1829 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/17 07:05:36][INFO] visual_prompt:  314: 	Test 500/1152. loss: 2.910, 0.2220 s / batch. (data: 3.99e-02)max mem: 17.22454 GB 
