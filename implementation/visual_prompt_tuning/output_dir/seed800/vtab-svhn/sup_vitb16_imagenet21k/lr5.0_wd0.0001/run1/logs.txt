[09/16 18:46:36][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[09/16 18:46:36][INFO] visual_prompt:   97: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 18:46:36][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-svhn', 'DATA.NUMBER_CLASSES', '10', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/16 18:46:36][INFO] visual_prompt:  104: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 18:46:36][INFO] visual_prompt:  108: Training with config:
[09/16 18:46:36][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-svhn',
          'NO_TEST': False,
          'NUMBER_CLASSES': 10,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-svhn/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 18:46:36][INFO] visual_prompt:   64: Loading training data (final training data for vtab)...
[09/16 18:46:39][INFO] visual_prompt:   69: Constructing vtab-svhn dataset trainval...
[09/16 18:46:41][INFO] visual_prompt:   88: Number of images: 1000
[09/16 18:46:41][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 18:46:41][INFO] visual_prompt:   70: Loading validation data...
[09/16 18:46:41][INFO] visual_prompt:   69: Constructing vtab-svhn dataset val...
[09/16 18:46:41][INFO] visual_prompt:   88: Number of images: 200
[09/16 18:46:41][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 18:46:41][INFO] visual_prompt:   73: Loading test data...
[09/16 18:46:41][INFO] visual_prompt:   69: Constructing vtab-svhn dataset test...
[09/16 18:47:13][INFO] visual_prompt:   88: Number of images: 26032
[09/16 18:47:13][INFO] visual_prompt:   90: Number of classes: 10 / 10
[09/16 18:47:13][INFO] visual_prompt:  100: Constructing models...
[09/16 18:47:16][INFO] visual_prompt:   53: Total Parameters: 86727946	 Gradient Parameters: 929290
[09/16 18:47:16][INFO] visual_prompt:   54: tuned percent:1.072
[09/16 18:47:18][INFO] visual_prompt:   40: Device used for model: 0
[09/16 18:47:18][INFO] visual_prompt:  103: Setting up Evalutator...
[09/16 18:47:18][INFO] visual_prompt:  105: Setting up Trainer...
[09/16 18:47:18][INFO] visual_prompt:   44: 	Setting up the optimizer...
[09/16 18:47:18][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[09/16 18:47:30][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 1.59e-01, avg batch time: 0.6378, average train loss: 2.4125
[09/16 18:47:35][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1418, average loss: 2.3973
[09/16 18:47:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 55.50	
[09/16 18:47:57][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.419, 0.1812 s / batch. (data: 1.14e-04)max mem: 17.22449 GB 
[09/16 18:48:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.453, 0.2055 s / batch. (data: 1.32e-02)max mem: 17.22449 GB 
[09/16 18:48:36][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.412, 0.2035 s / batch. (data: 2.16e-02)max mem: 17.22449 GB 
[09/16 18:48:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.506, 0.1825 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 18:48:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1937, average loss: 2.4224
[09/16 18:48:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.56	top5: 58.21	
[09/16 18:48:58][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.230
[09/16 18:48:58][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.5
[09/16 18:49:09][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 1.64e-01, avg batch time: 0.5636, average train loss: 2.8168
[09/16 18:49:14][INFO] visual_prompt:  324: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1427, average loss: 2.3250
[09/16 18:49:14][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 57.50	
[09/16 18:49:36][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.419, 0.2096 s / batch. (data: 2.72e-02)max mem: 17.22449 GB 
[09/16 18:49:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.415, 0.1964 s / batch. (data: 1.50e-02)max mem: 17.22449 GB 
[09/16 18:50:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.316, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 18:50:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.374, 0.1828 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 18:50:38][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1952, average loss: 2.3358
[09/16 18:50:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 59.19	
[09/16 18:50:38][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 1.0
[09/16 18:50:49][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 1.55e-01, avg batch time: 0.5560, average train loss: 2.3804
[09/16 18:50:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1424, average loss: 2.3755
[09/16 18:50:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.00	
[09/16 18:51:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.409, 0.2082 s / batch. (data: 1.13e-02)max mem: 17.22449 GB 
[09/16 18:51:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.498, 0.1877 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 18:51:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.226, 0.1957 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 18:52:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.293, 0.1892 s / batch. (data: 2.79e-05)max mem: 17.22449 GB 
[09/16 18:52:16][INFO] visual_prompt:  324: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1938, average loss: 2.3438
[09/16 18:52:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 62.23	
[09/16 18:52:17][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 1.5
[09/16 18:52:27][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.49e-01, avg batch time: 0.5516, average train loss: 2.3622
[09/16 18:52:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1426, average loss: 2.4732
[09/16 18:52:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 49.00	
[09/16 18:52:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.380, 0.1830 s / batch. (data: 1.63e-04)max mem: 17.22449 GB 
[09/16 18:53:14][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.452, 0.2142 s / batch. (data: 3.26e-02)max mem: 17.22449 GB 
[09/16 18:53:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.456, 0.1918 s / batch. (data: 6.77e-05)max mem: 17.22449 GB 
[09/16 18:53:53][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.422, 0.1826 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 18:53:56][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1942, average loss: 2.4542
[09/16 18:53:56][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 49.49	
[09/16 18:53:56][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 2.0
[09/16 18:54:07][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.44e-01, avg batch time: 0.5467, average train loss: 2.5292
[09/16 18:54:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1424, average loss: 2.5351
[09/16 18:54:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 18:54:33][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.884, 0.2037 s / batch. (data: 1.11e-02)max mem: 17.22449 GB 
[09/16 18:54:53][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.911, 0.1914 s / batch. (data: 9.50e-03)max mem: 17.22449 GB 
[09/16 18:55:12][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.442, 0.1915 s / batch. (data: 1.50e-04)max mem: 17.22449 GB 
[09/16 18:55:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.549, 0.1829 s / batch. (data: 2.48e-05)max mem: 17.22449 GB 
[09/16 18:55:35][INFO] visual_prompt:  324: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1937, average loss: 2.5700
[09/16 18:55:35][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 63.51	
[09/16 18:55:35][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 2.5
[09/16 18:55:45][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 1.65e-01, avg batch time: 0.5639, average train loss: 2.8409
[09/16 18:55:50][INFO] visual_prompt:  324: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1425, average loss: 2.5586
[09/16 18:55:50][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 62.50	
[09/16 18:56:12][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.006, 0.1820 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 18:56:32][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.977, 0.2067 s / batch. (data: 2.54e-02)max mem: 17.22449 GB 
[09/16 18:56:51][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.486, 0.1821 s / batch. (data: 1.11e-04)max mem: 17.22449 GB 
[09/16 18:57:11][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.652, 0.1827 s / batch. (data: 3.19e-05)max mem: 17.22449 GB 
[09/16 18:57:14][INFO] visual_prompt:  324: Inference (test):avg data time: 8.86e-03, avg batch time: 0.1959, average loss: 2.6478
[09/16 18:57:14][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.11	top5: 61.05	
[09/16 18:57:14][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 3.0
[09/16 18:57:25][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 1.59e-01, avg batch time: 0.5632, average train loss: 3.5154
[09/16 18:57:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1425, average loss: 3.7652
[09/16 18:57:30][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 47.00	
[09/16 18:57:52][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.453, 0.1824 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 18:58:11][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.958, 0.1966 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 18:58:31][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.964, 0.2127 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 18:58:50][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.404, 0.1821 s / batch. (data: 4.46e-05)max mem: 17.22449 GB 
[09/16 18:58:53][INFO] visual_prompt:  324: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1942, average loss: 3.6445
[09/16 18:58:53][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 48.56	
[09/16 18:58:53][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 3.5
[09/16 18:59:04][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 1.49e-01, avg batch time: 0.5508, average train loss: 3.9284
[09/16 18:59:08][INFO] visual_prompt:  324: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1423, average loss: 6.4322
[09/16 18:59:08][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 56.00	
[09/16 18:59:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.304, 0.1822 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 18:59:50][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.618, 0.1819 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:00:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.100, 0.1833 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 19:00:29][INFO] visual_prompt:  314: 	Test 400/407. loss: 6.859, 0.1819 s / batch. (data: 3.74e-05)max mem: 17.22449 GB 
[09/16 19:00:32][INFO] visual_prompt:  324: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1938, average loss: 6.7342
[09/16 19:00:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 51.33	
[09/16 19:00:32][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 4.0
[09/16 19:00:42][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 1.51e-01, avg batch time: 0.5517, average train loss: 11.3125
[09/16 19:00:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1426, average loss: 13.0491
[09/16 19:00:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.00	
[09/16 19:01:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 12.798, 0.1824 s / batch. (data: 1.55e-04)max mem: 17.22449 GB 
[09/16 19:01:28][INFO] visual_prompt:  314: 	Test 200/407. loss: 13.404, 0.1825 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 19:01:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.983, 0.1877 s / batch. (data: 5.20e-03)max mem: 17.22449 GB 
[09/16 19:02:07][INFO] visual_prompt:  314: 	Test 400/407. loss: 11.605, 0.1827 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 19:02:10][INFO] visual_prompt:  324: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1934, average loss: 12.4620
[09/16 19:02:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 64.04	
[09/16 19:02:11][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 4.5
[09/16 19:02:21][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.53e-01, avg batch time: 0.5555, average train loss: 24.6459
[09/16 19:02:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1422, average loss: 21.6044
[09/16 19:02:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 64.50	
[09/16 19:02:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 26.380, 0.1823 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 19:03:07][INFO] visual_prompt:  314: 	Test 200/407. loss: 27.289, 0.1822 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 19:03:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 20.679, 0.1851 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 19:03:46][INFO] visual_prompt:  314: 	Test 400/407. loss: 23.122, 0.1829 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 19:03:50][INFO] visual_prompt:  324: Inference (test):avg data time: 6.59e-03, avg batch time: 0.1949, average loss: 22.9406
[09/16 19:03:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 63.51	
[09/16 19:03:50][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 5.0
[09/16 19:04:00][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.58e-01, avg batch time: 0.5581, average train loss: 18.4852
[09/16 19:04:05][INFO] visual_prompt:  324: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1425, average loss: 12.5475
[09/16 19:04:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.00	top5: 49.00	
[09/16 19:04:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 13.451, 0.2085 s / batch. (data: 2.69e-02)max mem: 17.22449 GB 
[09/16 19:04:46][INFO] visual_prompt:  314: 	Test 200/407. loss: 13.293, 0.1825 s / batch. (data: 8.27e-05)max mem: 17.22449 GB 
[09/16 19:05:05][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.276, 0.1965 s / batch. (data: 1.40e-02)max mem: 17.22449 GB 
[09/16 19:05:24][INFO] visual_prompt:  314: 	Test 400/407. loss: 10.242, 0.1831 s / batch. (data: 3.36e-05)max mem: 17.22449 GB 
[09/16 19:05:28][INFO] visual_prompt:  324: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1915, average loss: 12.4611
[09/16 19:05:28][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 7.59	top5: 52.05	
[09/16 19:05:28][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 19:05:39][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 1.61e-01, avg batch time: 0.5901, average train loss: 21.8724
[09/16 19:05:43][INFO] visual_prompt:  324: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1424, average loss: 12.2111
[09/16 19:05:43][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.50	
[09/16 19:06:05][INFO] visual_prompt:  314: 	Test 100/407. loss: 17.213, 0.1981 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:06:25][INFO] visual_prompt:  314: 	Test 200/407. loss: 17.794, 0.1952 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 19:06:45][INFO] visual_prompt:  314: 	Test 300/407. loss: 9.556, 0.1863 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 19:07:04][INFO] visual_prompt:  314: 	Test 400/407. loss: 14.435, 0.1829 s / batch. (data: 3.48e-05)max mem: 17.22449 GB 
[09/16 19:07:07][INFO] visual_prompt:  324: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1944, average loss: 13.3470
[09/16 19:07:07][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 51.24	
[09/16 19:07:07][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 19:07:18][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.61e-01, avg batch time: 0.5639, average train loss: 21.5759
[09/16 19:07:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1424, average loss: 16.4765
[09/16 19:07:22][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.50	
[09/16 19:07:44][INFO] visual_prompt:  314: 	Test 100/407. loss: 19.303, 0.2195 s / batch. (data: 2.51e-02)max mem: 17.22449 GB 
[09/16 19:08:03][INFO] visual_prompt:  314: 	Test 200/407. loss: 18.197, 0.1945 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 19:08:23][INFO] visual_prompt:  314: 	Test 300/407. loss: 17.585, 0.1836 s / batch. (data: 1.45e-04)max mem: 17.22449 GB 
[09/16 19:08:42][INFO] visual_prompt:  314: 	Test 400/407. loss: 16.899, 0.1824 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 19:08:45][INFO] visual_prompt:  324: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1918, average loss: 16.5578
[09/16 19:08:45][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 58.04	
[09/16 19:08:45][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 19:08:56][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 1.54e-01, avg batch time: 0.5543, average train loss: 18.2841
[09/16 19:09:01][INFO] visual_prompt:  324: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1446, average loss: 21.4449
[09/16 19:09:01][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.00	
[09/16 19:09:22][INFO] visual_prompt:  314: 	Test 100/407. loss: 22.166, 0.2037 s / batch. (data: 1.92e-02)max mem: 17.22449 GB 
[09/16 19:09:42][INFO] visual_prompt:  314: 	Test 200/407. loss: 25.188, 0.1828 s / batch. (data: 9.06e-05)max mem: 17.22449 GB 
[09/16 19:10:01][INFO] visual_prompt:  314: 	Test 300/407. loss: 18.686, 0.1969 s / batch. (data: 1.48e-02)max mem: 17.22449 GB 
[09/16 19:10:21][INFO] visual_prompt:  314: 	Test 400/407. loss: 20.557, 0.1823 s / batch. (data: 4.24e-05)max mem: 17.22449 GB 
[09/16 19:10:24][INFO] visual_prompt:  324: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1945, average loss: 21.4891
[09/16 19:10:24][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.13	
[09/16 19:10:24][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 19:10:35][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.44e-01, avg batch time: 0.5450, average train loss: 20.0974
[09/16 19:10:40][INFO] visual_prompt:  324: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1424, average loss: 20.1185
[09/16 19:10:40][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 51.50	
[09/16 19:11:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 22.374, 0.2008 s / batch. (data: 1.94e-02)max mem: 17.22449 GB 
[09/16 19:11:21][INFO] visual_prompt:  314: 	Test 200/407. loss: 22.239, 0.1996 s / batch. (data: 1.44e-02)max mem: 17.22449 GB 
[09/16 19:11:40][INFO] visual_prompt:  314: 	Test 300/407. loss: 20.423, 0.1966 s / batch. (data: 1.46e-02)max mem: 17.22449 GB 
[09/16 19:12:00][INFO] visual_prompt:  314: 	Test 400/407. loss: 22.250, 0.1824 s / batch. (data: 4.74e-05)max mem: 17.22449 GB 
[09/16 19:12:03][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1933, average loss: 21.1774
[09/16 19:12:03][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 47.44	
[09/16 19:12:03][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 19:12:14][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 1.56e-01, avg batch time: 0.5564, average train loss: 18.8822
[09/16 19:12:18][INFO] visual_prompt:  324: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1461, average loss: 16.9706
[09/16 19:12:18][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 64.50	
[09/16 19:12:40][INFO] visual_prompt:  314: 	Test 100/407. loss: 17.120, 0.1826 s / batch. (data: 1.38e-04)max mem: 17.22449 GB 
[09/16 19:13:00][INFO] visual_prompt:  314: 	Test 200/407. loss: 21.362, 0.1918 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 19:13:19][INFO] visual_prompt:  314: 	Test 300/407. loss: 14.702, 0.1892 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 19:13:38][INFO] visual_prompt:  314: 	Test 400/407. loss: 17.465, 0.1824 s / batch. (data: 3.00e-05)max mem: 17.22449 GB 
[09/16 19:13:42][INFO] visual_prompt:  324: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1930, average loss: 16.8413
[09/16 19:13:42][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 63.51	
[09/16 19:13:42][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 19:13:52][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.53e-01, avg batch time: 0.5591, average train loss: 16.1904
[09/16 19:13:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1426, average loss: 9.8088
[09/16 19:13:57][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 9.00	top5: 60.50	
[09/16 19:14:19][INFO] visual_prompt:  314: 	Test 100/407. loss: 10.997, 0.2067 s / batch. (data: 1.60e-02)max mem: 17.22449 GB 
[09/16 19:14:38][INFO] visual_prompt:  314: 	Test 200/407. loss: 12.404, 0.2157 s / batch. (data: 1.92e-02)max mem: 17.22449 GB 
[09/16 19:14:58][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.606, 0.1959 s / batch. (data: 1.22e-02)max mem: 17.22449 GB 
[09/16 19:15:17][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.952, 0.1826 s / batch. (data: 3.43e-05)max mem: 17.22449 GB 
[09/16 19:15:21][INFO] visual_prompt:  324: Inference (test):avg data time: 7.09e-03, avg batch time: 0.1934, average loss: 9.7777
[09/16 19:15:21][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.16	top5: 57.10	
[09/16 19:15:21][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 19:15:31][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.57e-01, avg batch time: 0.5558, average train loss: 14.4130
[09/16 19:15:36][INFO] visual_prompt:  324: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1475, average loss: 13.5248
[09/16 19:15:36][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.50	
[09/16 19:15:58][INFO] visual_prompt:  314: 	Test 100/407. loss: 14.783, 0.1955 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 19:16:17][INFO] visual_prompt:  314: 	Test 200/407. loss: 15.813, 0.1847 s / batch. (data: 1.33e-04)max mem: 17.22449 GB 
[09/16 19:16:37][INFO] visual_prompt:  314: 	Test 300/407. loss: 11.150, 0.1944 s / batch. (data: 1.12e-04)max mem: 17.22449 GB 
[09/16 19:16:56][INFO] visual_prompt:  314: 	Test 400/407. loss: 12.799, 0.1821 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 19:16:59][INFO] visual_prompt:  324: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1937, average loss: 13.3371
[09/16 19:17:00][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 60.48	
[09/16 19:17:00][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 19:17:10][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 1.56e-01, avg batch time: 0.5578, average train loss: 12.4957
[09/16 19:17:15][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1425, average loss: 9.9539
[09/16 19:17:15][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 61.00	
[09/16 19:17:37][INFO] visual_prompt:  314: 	Test 100/407. loss: 13.572, 0.1867 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 19:17:56][INFO] visual_prompt:  314: 	Test 200/407. loss: 12.480, 0.2245 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 19:18:15][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.814, 0.1831 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 19:18:35][INFO] visual_prompt:  314: 	Test 400/407. loss: 9.779, 0.1822 s / batch. (data: 3.08e-05)max mem: 17.22449 GB 
[09/16 19:18:38][INFO] visual_prompt:  324: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1928, average loss: 10.1353
[09/16 19:18:38][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 60.32	
[09/16 19:18:38][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 19:18:49][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.62e-01, avg batch time: 0.5628, average train loss: 8.5313
[09/16 19:18:53][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1425, average loss: 8.6166
[09/16 19:18:53][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.00	
[09/16 19:19:15][INFO] visual_prompt:  314: 	Test 100/407. loss: 9.974, 0.1825 s / batch. (data: 1.42e-04)max mem: 17.22449 GB 
[09/16 19:19:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 10.182, 0.1981 s / batch. (data: 1.35e-02)max mem: 17.22449 GB 
[09/16 19:19:54][INFO] visual_prompt:  314: 	Test 300/407. loss: 8.859, 0.1832 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 19:20:14][INFO] visual_prompt:  314: 	Test 400/407. loss: 8.609, 0.1826 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 19:20:17][INFO] visual_prompt:  324: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1939, average loss: 8.7647
[09/16 19:20:17][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.13	
[09/16 19:20:17][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 19:20:27][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.53e-01, avg batch time: 0.5549, average train loss: 7.7299
[09/16 19:20:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1426, average loss: 6.4770
[09/16 19:20:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 58.00	
[09/16 19:20:54][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.496, 0.1851 s / batch. (data: 1.13e-04)max mem: 17.22449 GB 
[09/16 19:21:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 7.382, 0.1959 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 19:21:33][INFO] visual_prompt:  314: 	Test 300/407. loss: 7.053, 0.1828 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 19:21:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 6.823, 0.1825 s / batch. (data: 3.10e-05)max mem: 17.22449 GB 
[09/16 19:21:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1930, average loss: 6.7575
[09/16 19:21:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 54.23	
[09/16 19:21:55][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 19:22:06][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 1.56e-01, avg batch time: 0.5556, average train loss: 6.0891
[09/16 19:22:11][INFO] visual_prompt:  324: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1426, average loss: 6.0550
[09/16 19:22:11][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 63.50	
[09/16 19:22:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 7.128, 0.2011 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 19:22:52][INFO] visual_prompt:  314: 	Test 200/407. loss: 6.822, 0.1923 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 19:23:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 5.227, 0.1919 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:23:30][INFO] visual_prompt:  314: 	Test 400/407. loss: 5.626, 0.1827 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 19:23:34][INFO] visual_prompt:  324: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1928, average loss: 6.1566
[09/16 19:23:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 11.07	top5: 61.95	
[09/16 19:23:34][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 19:23:44][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.59e-01, avg batch time: 0.5599, average train loss: 5.7555
[09/16 19:23:49][INFO] visual_prompt:  324: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1425, average loss: 3.2392
[09/16 19:23:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 54.50	
[09/16 19:24:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.317, 0.1827 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 19:24:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.456, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:24:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.370, 0.1828 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 19:25:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.533, 0.1826 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 19:25:13][INFO] visual_prompt:  324: Inference (test):avg data time: 8.75e-03, avg batch time: 0.1948, average loss: 3.3429
[09/16 19:25:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.41	
[09/16 19:25:13][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 19:25:24][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 1.60e-01, avg batch time: 0.5618, average train loss: 2.6478
[09/16 19:25:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1424, average loss: 2.3804
[09/16 19:25:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 13.00	top5: 49.50	
[09/16 19:25:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.399, 0.1895 s / batch. (data: 1.32e-04)max mem: 17.22449 GB 
[09/16 19:26:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.382, 0.2277 s / batch. (data: 4.63e-02)max mem: 17.22449 GB 
[09/16 19:26:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.340, 0.1970 s / batch. (data: 1.45e-02)max mem: 17.22449 GB 
[09/16 19:26:48][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.284, 0.1820 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 19:26:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1929, average loss: 2.3817
[09/16 19:26:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 10.46	top5: 52.08	
[09/16 19:26:52][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 19:27:03][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 1.65e-01, avg batch time: 0.5648, average train loss: 2.5245
[09/16 19:27:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1423, average loss: 2.6493
[09/16 19:27:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 56.00	
[09/16 19:27:30][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.998, 0.1933 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 19:27:49][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.860, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22449 GB 
[09/16 19:28:09][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.838, 0.2178 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 19:28:28][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.907, 0.1823 s / batch. (data: 2.31e-05)max mem: 17.22449 GB 
[09/16 19:28:32][INFO] visual_prompt:  324: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1948, average loss: 2.7566
[09/16 19:28:32][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 52.74	
[09/16 19:28:32][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 19:28:42][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.51e-01, avg batch time: 0.5519, average train loss: 2.7049
[09/16 19:28:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1425, average loss: 2.5122
[09/16 19:28:47][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 12.00	top5: 45.00	
[09/16 19:29:09][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.427, 0.5925 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 19:29:29][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.427, 0.2079 s / batch. (data: 1.91e-02)max mem: 17.22449 GB 
[09/16 19:29:48][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.425, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22449 GB 
[09/16 19:30:08][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.344, 0.1827 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 19:30:11][INFO] visual_prompt:  324: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1950, average loss: 2.4783
[09/16 19:30:11][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 15.94	top5: 47.19	
[09/16 19:30:11][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 19:30:22][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 1.46e-01, avg batch time: 0.5479, average train loss: 2.6415
[09/16 19:30:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1424, average loss: 2.5330
[09/16 19:30:26][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 61.50	
[09/16 19:30:48][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.902, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 19:31:08][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.881, 0.1827 s / batch. (data: 1.15e-04)max mem: 17.22449 GB 
[09/16 19:31:27][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.515, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22449 GB 
[09/16 19:31:47][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.685, 0.1829 s / batch. (data: 3.84e-05)max mem: 17.22449 GB 
[09/16 19:31:50][INFO] visual_prompt:  324: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1939, average loss: 2.6023
[09/16 19:31:50][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 62.67	
[09/16 19:31:50][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 19:32:01][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 1.58e-01, avg batch time: 0.5589, average train loss: 2.5957
[09/16 19:32:05][INFO] visual_prompt:  324: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1425, average loss: 3.5700
[09/16 19:32:05][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 23.00	top5: 60.50	
[09/16 19:32:27][INFO] visual_prompt:  314: 	Test 100/407. loss: 4.239, 0.1936 s / batch. (data: 1.23e-02)max mem: 17.22449 GB 
[09/16 19:32:47][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.944, 0.2102 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 19:33:07][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.853, 0.2028 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:33:26][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.736, 0.1823 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 19:33:29][INFO] visual_prompt:  324: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1953, average loss: 3.7418
[09/16 19:33:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 19.59	top5: 56.14	
[09/16 19:33:30][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 19:33:40][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.59e-01, avg batch time: 0.5597, average train loss: 3.1754
[09/16 19:33:45][INFO] visual_prompt:  324: Inference (val):avg data time: 4.31e-05, avg batch time: 0.1432, average loss: 3.4217
[09/16 19:33:45][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 8.50	top5: 58.00	
[09/16 19:34:07][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.559, 0.1833 s / batch. (data: 1.34e-04)max mem: 17.22449 GB 
[09/16 19:34:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.472, 0.1829 s / batch. (data: 8.70e-05)max mem: 17.22449 GB 
[09/16 19:34:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 3.616, 0.1954 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 19:35:06][INFO] visual_prompt:  314: 	Test 400/407. loss: 3.559, 0.1822 s / batch. (data: 2.84e-05)max mem: 17.22449 GB 
[09/16 19:35:09][INFO] visual_prompt:  324: Inference (test):avg data time: 8.47e-03, avg batch time: 0.1938, average loss: 3.5100
[09/16 19:35:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 9.69	top5: 54.56	
[09/16 19:35:09][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 19:35:20][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 1.54e-01, avg batch time: 0.5533, average train loss: 2.8575
[09/16 19:35:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1426, average loss: 2.3713
[09/16 19:35:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 32.00	top5: 66.50	
[09/16 19:35:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.397, 0.1827 s / batch. (data: 1.44e-04)max mem: 17.22449 GB 
[09/16 19:36:06][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.549, 0.1824 s / batch. (data: 9.37e-05)max mem: 17.22449 GB 
[09/16 19:36:25][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.278, 0.1820 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 19:36:44][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.365, 0.1826 s / batch. (data: 4.10e-05)max mem: 17.22449 GB 
[09/16 19:36:47][INFO] visual_prompt:  324: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1926, average loss: 2.4293
[09/16 19:36:48][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 31.44	top5: 67.44	
[09/16 19:36:48][INFO] visual_prompt:  246: Best epoch 30: best metric: 0.320
[09/16 19:36:48][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 19:36:58][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 1.53e-01, avg batch time: 0.5546, average train loss: 2.6576
[09/16 19:37:03][INFO] visual_prompt:  324: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1425, average loss: 2.5072
[09/16 19:37:03][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 25.00	top5: 63.00	
[09/16 19:37:25][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.978, 0.1830 s / batch. (data: 9.66e-05)max mem: 17.22449 GB 
[09/16 19:37:44][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.658, 0.1960 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:38:04][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.959, 0.1964 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:38:23][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.724, 0.1827 s / batch. (data: 3.81e-05)max mem: 17.22449 GB 
[09/16 19:38:26][INFO] visual_prompt:  324: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1935, average loss: 2.6657
[09/16 19:38:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 20.12	top5: 55.88	
[09/16 19:38:26][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 19:38:37][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 1.57e-01, avg batch time: 0.5566, average train loss: 2.8470
[09/16 19:38:42][INFO] visual_prompt:  324: Inference (val):avg data time: 3.21e-04, avg batch time: 0.2330, average loss: 2.3454
[09/16 19:38:42][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 26.50	top5: 67.00	
[09/16 19:39:04][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.950, 0.1959 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 19:39:23][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.693, 0.2090 s / batch. (data: 2.74e-02)max mem: 17.22449 GB 
[09/16 19:39:42][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.475, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:40:02][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.540, 0.1971 s / batch. (data: 2.93e-05)max mem: 17.22449 GB 
[09/16 19:40:05][INFO] visual_prompt:  324: Inference (test):avg data time: 6.62e-03, avg batch time: 0.1928, average loss: 2.4547
[09/16 19:40:05][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 21.82	top5: 63.35	
[09/16 19:40:05][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 19:40:16][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 1.50e-01, avg batch time: 0.5508, average train loss: 2.1806
[09/16 19:40:20][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1425, average loss: 1.7552
[09/16 19:40:20][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 43.50	top5: 82.00	
[09/16 19:40:42][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.220, 0.1937 s / batch. (data: 1.65e-04)max mem: 17.22449 GB 
[09/16 19:41:02][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.160, 0.1858 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 19:41:21][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.807, 0.1964 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:41:41][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.890, 0.1834 s / batch. (data: 2.91e-05)max mem: 17.22449 GB 
[09/16 19:41:44][INFO] visual_prompt:  324: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1939, average loss: 1.9122
[09/16 19:41:44][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 38.53	top5: 73.64	
[09/16 19:41:44][INFO] visual_prompt:  246: Best epoch 33: best metric: 0.435
[09/16 19:41:44][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 19:41:55][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 1.52e-01, avg batch time: 0.5541, average train loss: 1.8856
[09/16 19:41:59][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1424, average loss: 2.1389
[09/16 19:41:59][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 29.50	top5: 69.50	
[09/16 19:42:21][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.400, 0.2077 s / batch. (data: 2.59e-02)max mem: 17.22449 GB 
[09/16 19:42:40][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.237, 0.1909 s / batch. (data: 1.39e-04)max mem: 17.22449 GB 
[09/16 19:43:00][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.262, 0.1960 s / batch. (data: 1.28e-04)max mem: 17.22449 GB 
[09/16 19:43:19][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.060, 0.1828 s / batch. (data: 3.34e-05)max mem: 17.22449 GB 
[09/16 19:43:23][INFO] visual_prompt:  324: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1933, average loss: 2.3232
[09/16 19:43:23][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 25.41	top5: 67.84	
[09/16 19:43:23][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 19:43:33][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 1.53e-01, avg batch time: 0.5537, average train loss: 1.8900
[09/16 19:43:38][INFO] visual_prompt:  324: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1425, average loss: 1.7525
[09/16 19:43:38][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 40.00	top5: 86.50	
[09/16 19:44:00][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.356, 0.1819 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 19:44:19][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.061, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22449 GB 
[09/16 19:44:38][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.066, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22449 GB 
[09/16 19:44:58][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.217, 0.1828 s / batch. (data: 2.72e-05)max mem: 17.22449 GB 
[09/16 19:45:01][INFO] visual_prompt:  324: Inference (test):avg data time: 7.22e-03, avg batch time: 0.1926, average loss: 2.0328
[09/16 19:45:01][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 33.26	top5: 80.64	
[09/16 19:45:01][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 19:45:12][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 1.55e-01, avg batch time: 0.5554, average train loss: 3.3360
[09/16 19:45:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1425, average loss: 3.8184
[09/16 19:45:16][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 32.00	top5: 67.00	
[09/16 19:45:38][INFO] visual_prompt:  314: 	Test 100/407. loss: 3.564, 0.1955 s / batch. (data: 1.38e-02)max mem: 17.22449 GB 
[09/16 19:45:57][INFO] visual_prompt:  314: 	Test 200/407. loss: 3.752, 0.1828 s / batch. (data: 1.06e-04)max mem: 17.22449 GB 
[09/16 19:46:17][INFO] visual_prompt:  314: 	Test 300/407. loss: 4.282, 0.1830 s / batch. (data: 9.32e-05)max mem: 17.22449 GB 
[09/16 19:46:36][INFO] visual_prompt:  314: 	Test 400/407. loss: 4.329, 0.1828 s / batch. (data: 3.27e-05)max mem: 17.22449 GB 
[09/16 19:46:39][INFO] visual_prompt:  324: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1924, average loss: 4.0538
[09/16 19:46:39][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 26.20	top5: 62.35	
[09/16 19:46:39][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 19:46:50][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.48e-01, avg batch time: 0.5475, average train loss: 2.8794
[09/16 19:46:55][INFO] visual_prompt:  324: Inference (val):avg data time: 3.45e-04, avg batch time: 0.2144, average loss: 2.2933
[09/16 19:46:55][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 37.00	top5: 76.50	
[09/16 19:47:17][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.864, 0.2265 s / batch. (data: 1.25e-02)max mem: 17.22449 GB 
[09/16 19:47:36][INFO] visual_prompt:  314: 	Test 200/407. loss: 2.931, 0.2115 s / batch. (data: 2.97e-02)max mem: 17.22449 GB 
[09/16 19:47:56][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.159, 0.1918 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 19:48:16][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.301, 0.1827 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 19:48:19][INFO] visual_prompt:  324: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1958, average loss: 2.4030
[09/16 19:48:19][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 35.09	top5: 73.99	
[09/16 19:48:19][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 19:48:30][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 1.47e-01, avg batch time: 0.5504, average train loss: 1.9991
[09/16 19:48:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1425, average loss: 1.5338
[09/16 19:48:35][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 43.00	top5: 85.50	
[09/16 19:48:56][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.897, 0.1822 s / batch. (data: 1.46e-04)max mem: 17.22449 GB 
[09/16 19:49:16][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.873, 0.1978 s / batch. (data: 1.59e-02)max mem: 17.22449 GB 
[09/16 19:49:35][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.551, 0.1961 s / batch. (data: 1.43e-02)max mem: 17.22449 GB 
[09/16 19:49:55][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.696, 0.1818 s / batch. (data: 3.29e-05)max mem: 17.22449 GB 
[09/16 19:49:58][INFO] visual_prompt:  324: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1938, average loss: 1.6714
[09/16 19:49:58][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 42.52	top5: 84.62	
[09/16 19:49:58][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 19:50:09][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 1.53e-01, avg batch time: 0.5550, average train loss: 1.7989
[09/16 19:50:13][INFO] visual_prompt:  324: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1463, average loss: 1.6788
[09/16 19:50:13][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 38.00	top5: 85.50	
[09/16 19:50:35][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.866, 0.1825 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 19:50:55][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.845, 0.2088 s / batch. (data: 2.72e-02)max mem: 17.22449 GB 
[09/16 19:51:14][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.881, 0.1826 s / batch. (data: 1.49e-04)max mem: 17.22449 GB 
[09/16 19:51:34][INFO] visual_prompt:  314: 	Test 400/407. loss: 2.035, 0.1823 s / batch. (data: 2.88e-05)max mem: 17.22449 GB 
[09/16 19:51:37][INFO] visual_prompt:  324: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1935, average loss: 1.8831
[09/16 19:51:37][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 32.79	top5: 83.62	
[09/16 19:51:37][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 19:51:48][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 1.59e-01, avg batch time: 0.5598, average train loss: 1.7003
[09/16 19:51:52][INFO] visual_prompt:  324: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1425, average loss: 1.3770
[09/16 19:51:52][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 48.50	top5: 88.50	
[09/16 19:52:14][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.835, 0.1882 s / batch. (data: 1.22e-04)max mem: 17.22449 GB 
[09/16 19:52:34][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.861, 0.2119 s / batch. (data: 1.63e-02)max mem: 17.22449 GB 
[09/16 19:52:53][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.403, 0.1827 s / batch. (data: 1.20e-04)max mem: 17.22449 GB 
[09/16 19:53:13][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.778, 0.1826 s / batch. (data: 3.41e-05)max mem: 17.22449 GB 
[09/16 19:53:16][INFO] visual_prompt:  324: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1938, average loss: 1.6090
[09/16 19:53:16][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 44.00	top5: 85.71	
[09/16 19:53:16][INFO] visual_prompt:  246: Best epoch 40: best metric: 0.485
[09/16 19:53:16][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 3.75
[09/16 19:53:27][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 1.53e-01, avg batch time: 0.5726, average train loss: 1.4142
[09/16 19:53:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1424, average loss: 1.3811
[09/16 19:53:32][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 52.50	top5: 92.00	
[09/16 19:53:53][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.990, 0.1823 s / batch. (data: 1.19e-04)max mem: 17.22449 GB 
[09/16 19:54:13][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.730, 0.1824 s / batch. (data: 1.53e-04)max mem: 17.22449 GB 
[09/16 19:54:32][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.619, 0.1824 s / batch. (data: 1.26e-04)max mem: 17.22449 GB 
[09/16 19:54:52][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.732, 0.1825 s / batch. (data: 3.24e-05)max mem: 17.22449 GB 
[09/16 19:54:55][INFO] visual_prompt:  324: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1937, average loss: 1.6486
[09/16 19:54:55][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 49.45	top5: 86.29	
[09/16 19:54:55][INFO] visual_prompt:  246: Best epoch 41: best metric: 0.525
[09/16 19:54:55][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 19:55:06][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 1.57e-01, avg batch time: 0.5614, average train loss: 1.2554
[09/16 19:55:10][INFO] visual_prompt:  324: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1424, average loss: 1.1154
[09/16 19:55:10][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 59.50	top5: 94.00	
[09/16 19:55:32][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.752, 0.1829 s / batch. (data: 1.69e-04)max mem: 17.22449 GB 
[09/16 19:55:51][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.466, 0.2098 s / batch. (data: 1.54e-02)max mem: 17.22449 GB 
[09/16 19:56:11][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.388, 0.1968 s / batch. (data: 1.07e-04)max mem: 17.22449 GB 
[09/16 19:56:31][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.621, 0.1832 s / batch. (data: 3.15e-05)max mem: 17.22449 GB 
[09/16 19:56:34][INFO] visual_prompt:  324: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1939, average loss: 1.5067
[09/16 19:56:34][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 52.07	top5: 89.46	
[09/16 19:56:34][INFO] visual_prompt:  246: Best epoch 42: best metric: 0.595
[09/16 19:56:34][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 19:56:44][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 1.54e-01, avg batch time: 0.5526, average train loss: 1.0744
[09/16 19:56:49][INFO] visual_prompt:  324: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1427, average loss: 0.9259
[09/16 19:56:49][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 72.00	top5: 98.00	
[09/16 19:57:11][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.462, 0.2050 s / batch. (data: 2.33e-02)max mem: 17.22449 GB 
[09/16 19:57:31][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.253, 0.2122 s / batch. (data: 3.09e-02)max mem: 17.22449 GB 
[09/16 19:57:50][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.152, 0.1950 s / batch. (data: 1.01e-04)max mem: 17.22449 GB 
[09/16 19:58:10][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.293, 0.1839 s / batch. (data: 4.94e-05)max mem: 17.22449 GB 
[09/16 19:58:13][INFO] visual_prompt:  324: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1949, average loss: 1.3409
[09/16 19:58:13][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 56.88	top5: 92.90	
[09/16 19:58:13][INFO] visual_prompt:  246: Best epoch 43: best metric: 0.720
[09/16 19:58:13][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 19:58:24][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 1.57e-01, avg batch time: 0.5583, average train loss: 0.8649
[09/16 19:58:28][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1426, average loss: 0.6868
[09/16 19:58:28][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 77.50	top5: 98.50	
[09/16 19:58:50][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.570, 0.1978 s / batch. (data: 1.08e-04)max mem: 17.22449 GB 
[09/16 19:59:10][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.120, 0.1926 s / batch. (data: 1.03e-02)max mem: 17.22449 GB 
[09/16 19:59:29][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.333, 0.2045 s / batch. (data: 2.28e-02)max mem: 17.22449 GB 
[09/16 19:59:48][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.414, 0.1825 s / batch. (data: 3.60e-05)max mem: 17.22449 GB 
[09/16 19:59:52][INFO] visual_prompt:  324: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1937, average loss: 1.3052
[09/16 19:59:52][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 58.58	top5: 92.06	
[09/16 19:59:52][INFO] visual_prompt:  246: Best epoch 44: best metric: 0.775
[09/16 19:59:52][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 20:00:02][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.44e-01, avg batch time: 0.5475, average train loss: 0.9301
[09/16 20:00:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1427, average loss: 1.0891
[09/16 20:00:07][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 60.50	top5: 96.00	
[09/16 20:00:29][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.167, 0.1824 s / batch. (data: 1.36e-04)max mem: 17.22449 GB 
[09/16 20:00:48][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.683, 0.1954 s / batch. (data: 1.30e-02)max mem: 17.22449 GB 
[09/16 20:01:08][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.547, 0.1975 s / batch. (data: 1.62e-02)max mem: 17.22449 GB 
[09/16 20:01:27][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.830, 0.1829 s / batch. (data: 2.86e-05)max mem: 17.22449 GB 
[09/16 20:01:30][INFO] visual_prompt:  324: Inference (test):avg data time: 8.47e-03, avg batch time: 0.1937, average loss: 1.6799
[09/16 20:01:30][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 47.84	top5: 91.29	
[09/16 20:01:30][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 20:01:41][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.50e-01, avg batch time: 0.5511, average train loss: 0.8331
[09/16 20:01:45][INFO] visual_prompt:  324: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1424, average loss: 1.1147
[09/16 20:01:45][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 60.50	top5: 98.50	
[09/16 20:02:07][INFO] visual_prompt:  314: 	Test 100/407. loss: 2.374, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22449 GB 
[09/16 20:02:27][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.911, 0.1863 s / batch. (data: 1.27e-04)max mem: 17.22449 GB 
[09/16 20:02:46][INFO] visual_prompt:  314: 	Test 300/407. loss: 2.133, 0.1830 s / batch. (data: 5.13e-05)max mem: 17.22449 GB 
[09/16 20:03:05][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.870, 0.1859 s / batch. (data: 4.53e-05)max mem: 17.22449 GB 
[09/16 20:03:09][INFO] visual_prompt:  324: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1926, average loss: 1.9018
[09/16 20:03:09][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 48.52	top5: 90.29	
[09/16 20:03:09][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 20:03:19][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 1.57e-01, avg batch time: 0.5649, average train loss: 0.7507
[09/16 20:03:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1426, average loss: 0.4204
[09/16 20:03:24][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 87.50	top5: 99.50	
[09/16 20:03:46][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.138, 0.1823 s / batch. (data: 1.04e-04)max mem: 17.22449 GB 
[09/16 20:04:05][INFO] visual_prompt:  314: 	Test 200/407. loss: 0.960, 0.1822 s / batch. (data: 1.23e-04)max mem: 17.22449 GB 
[09/16 20:04:24][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.791, 0.1826 s / batch. (data: 1.30e-04)max mem: 17.22449 GB 
[09/16 20:04:43][INFO] visual_prompt:  314: 	Test 400/407. loss: 0.902, 0.1830 s / batch. (data: 4.43e-05)max mem: 17.22449 GB 
[09/16 20:04:47][INFO] visual_prompt:  324: Inference (test):avg data time: 6.89e-03, avg batch time: 0.1917, average loss: 0.8861
[09/16 20:04:47][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 72.59	top5: 95.77	
[09/16 20:04:47][INFO] visual_prompt:  246: Best epoch 47: best metric: 0.875
[09/16 20:04:47][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 20:04:58][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 1.48e-01, avg batch time: 0.5690, average train loss: 0.5995
[09/16 20:05:02][INFO] visual_prompt:  324: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1444, average loss: 0.6671
[09/16 20:05:02][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 82.50	top5: 95.50	
[09/16 20:05:24][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.556, 0.2162 s / batch. (data: 3.49e-02)max mem: 17.22449 GB 
[09/16 20:05:43][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.242, 0.2092 s / batch. (data: 2.75e-02)max mem: 17.22449 GB 
[09/16 20:06:03][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.171, 0.1959 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 20:06:22][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.387, 0.1826 s / batch. (data: 3.22e-05)max mem: 17.22449 GB 
[09/16 20:06:25][INFO] visual_prompt:  324: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1929, average loss: 1.2745
[09/16 20:06:26][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 65.57	top5: 93.12	
[09/16 20:06:26][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 20:06:36][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 1.59e-01, avg batch time: 0.5625, average train loss: 0.5431
[09/16 20:06:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1426, average loss: 0.3655
[09/16 20:06:41][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 87.00	top5: 100.00	
[09/16 20:07:02][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.150, 0.1982 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:07:22][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.151, 0.1947 s / batch. (data: 1.33e-02)max mem: 17.22449 GB 
[09/16 20:07:41][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.143, 0.1843 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:08:01][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.287, 0.1827 s / batch. (data: 3.05e-05)max mem: 17.22449 GB 
[09/16 20:08:04][INFO] visual_prompt:  324: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1928, average loss: 1.0770
[09/16 20:08:04][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 70.45	top5: 95.18	
[09/16 20:08:04][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 20:08:15][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 1.64e-01, avg batch time: 0.5649, average train loss: 0.4585
[09/16 20:08:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1423, average loss: 0.4601
[09/16 20:08:19][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 84.00	top5: 99.50	
[09/16 20:08:41][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.208, 0.2003 s / batch. (data: 1.34e-02)max mem: 17.22449 GB 
[09/16 20:09:01][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.090, 0.1974 s / batch. (data: 1.56e-02)max mem: 17.22449 GB 
[09/16 20:09:20][INFO] visual_prompt:  314: 	Test 300/407. loss: 0.911, 0.1880 s / batch. (data: 1.24e-04)max mem: 17.22449 GB 
[09/16 20:09:39][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.215, 0.1823 s / batch. (data: 3.70e-05)max mem: 17.22449 GB 
[09/16 20:09:43][INFO] visual_prompt:  324: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1931, average loss: 1.0417
[09/16 20:09:43][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 71.17	top5: 96.44	
[09/16 20:09:43][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 20:09:53][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.60e-01, avg batch time: 0.5612, average train loss: 0.3389
[09/16 20:09:58][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1427, average loss: 0.6124
[09/16 20:09:58][INFO] visual_prompt:  113: Classification results with val_vtab-svhn: top1: 77.00	top5: 100.00	
[09/16 20:10:20][INFO] visual_prompt:  314: 	Test 100/407. loss: 1.889, 0.1961 s / batch. (data: 1.42e-02)max mem: 17.22449 GB 
[09/16 20:10:39][INFO] visual_prompt:  314: 	Test 200/407. loss: 1.587, 0.1831 s / batch. (data: 1.35e-04)max mem: 17.22449 GB 
[09/16 20:10:59][INFO] visual_prompt:  314: 	Test 300/407. loss: 1.537, 0.1958 s / batch. (data: 1.43e-04)max mem: 17.22449 GB 
[09/16 20:11:18][INFO] visual_prompt:  314: 	Test 400/407. loss: 1.419, 0.1819 s / batch. (data: 3.91e-05)max mem: 17.22449 GB 
[09/16 20:11:22][INFO] visual_prompt:  324: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1932, average loss: 1.4774
[09/16 20:11:22][INFO] visual_prompt:  113: Classification results with test_vtab-svhn: top1: 62.39	top5: 94.56	
[09/16 20:11:22][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 2.8479327524001636
