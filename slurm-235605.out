[09/18 13:01:35 visual_prompt]: Rank of current process: 0. World size: 1
[09/18 13:01:35 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/18 13:01:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/18 13:01:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/18 13:01:35 visual_prompt]: Training with config:
[09/18 13:01:35 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/18 13:01:35 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-18 13:01:35.507526: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-18 13:01:35.671136: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-18 13:01:36.643079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:36.643159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:36.643167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-18 13:01:38.953040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:38.953153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:38.953168: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/18 13:01:38 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-18 13:01:39.028995: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 13:01:41 visual_prompt]: Number of images: 1000
[09/18 13:01:41 visual_prompt]: Number of classes: 16 / 16
[09/18 13:01:41 visual_prompt]: Loading validation data...
[09/18 13:01:41 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 13:01:41 visual_prompt]: Number of images: 200
[09/18 13:01:41 visual_prompt]: Number of classes: 16 / 16
[09/18 13:01:41 visual_prompt]: Loading test data...
[09/18 13:01:41 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 13:03:12 visual_prompt]: Number of images: 73728
[09/18 13:03:12 visual_prompt]: Number of classes: 16 / 16
[09/18 13:03:12 visual_prompt]: Constructing models...
[09/18 13:03:15 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/18 13:03:15 visual_prompt]: tuned percent:1.077
[09/18 13:03:17 visual_prompt]: Device used for model: 0
[09/18 13:03:17 visual_prompt]: Setting up Evalutator...
[09/18 13:03:17 visual_prompt]: Setting up Trainer...
[09/18 13:03:17 visual_prompt]: 	Setting up the optimizer...
[09/18 13:03:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/18 13:03:32 visual_prompt]: Epoch 1 / 100: avg data time: 2.29e-01, avg batch time: 0.7192, average train loss: 3.0505
[09/18 13:03:39 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1451, average loss: 3.0537
[09/18 13:03:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 28.00	
[09/18 13:04:02 visual_prompt]: 	Test 100/1152. loss: 3.086, 0.1814 s / batch. (data: 9.30e-05)max mem: 17.22454 GB 
[09/18 13:04:21 visual_prompt]: 	Test 200/1152. loss: 3.107, 0.2090 s / batch. (data: 2.75e-02)max mem: 17.22454 GB 
[09/18 13:04:40 visual_prompt]: 	Test 300/1152. loss: 3.076, 0.1829 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 13:05:00 visual_prompt]: 	Test 400/1152. loss: 3.233, 0.1846 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 13:05:20 visual_prompt]: 	Test 500/1152. loss: 3.181, 0.1981 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 13:05:39 visual_prompt]: 	Test 600/1152. loss: 3.015, 0.1846 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:05:59 visual_prompt]: 	Test 700/1152. loss: 3.012, 0.1844 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 13:06:18 visual_prompt]: 	Test 800/1152. loss: 3.129, 0.2133 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 13:06:38 visual_prompt]: 	Test 900/1152. loss: 3.093, 0.1852 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/18 13:06:58 visual_prompt]: 	Test 1000/1152. loss: 3.037, 0.1843 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 13:07:17 visual_prompt]: 	Test 1100/1152. loss: 2.991, 0.1875 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/18 13:07:31 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1942, average loss: 3.0773
[09/18 13:07:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.33	top5: 31.30	
[09/18 13:07:32 visual_prompt]: Best epoch 1: best metric: 0.060
[09/18 13:07:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/18 13:07:45 visual_prompt]: Epoch 2 / 100: avg data time: 2.35e-01, avg batch time: 0.6364, average train loss: 3.4369
[09/18 13:07:52 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1427, average loss: 3.0679
[09/18 13:07:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 35.00	
[09/18 13:08:15 visual_prompt]: 	Test 100/1152. loss: 3.035, 0.2123 s / batch. (data: 3.01e-02)max mem: 17.22454 GB 
[09/18 13:08:34 visual_prompt]: 	Test 200/1152. loss: 3.278, 0.1962 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 13:08:54 visual_prompt]: 	Test 300/1152. loss: 3.195, 0.1835 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:09:13 visual_prompt]: 	Test 400/1152. loss: 3.068, 0.2091 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 13:09:33 visual_prompt]: 	Test 500/1152. loss: 2.856, 0.1942 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 13:09:52 visual_prompt]: 	Test 600/1152. loss: 3.093, 0.1833 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 13:10:12 visual_prompt]: 	Test 700/1152. loss: 3.128, 0.1957 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:10:31 visual_prompt]: 	Test 800/1152. loss: 3.229, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 13:10:51 visual_prompt]: 	Test 900/1152. loss: 3.219, 0.1960 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 13:11:10 visual_prompt]: 	Test 1000/1152. loss: 3.180, 0.2237 s / batch. (data: 4.19e-02)max mem: 17.22454 GB 
[09/18 13:11:30 visual_prompt]: 	Test 1100/1152. loss: 3.267, 0.1985 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 13:11:44 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1941, average loss: 3.1428
[09/18 13:11:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.24	top5: 31.31	
[09/18 13:11:44 visual_prompt]: Best epoch 2: best metric: 0.080
[09/18 13:11:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/18 13:11:57 visual_prompt]: Epoch 3 / 100: avg data time: 2.23e-01, avg batch time: 0.6264, average train loss: 3.0478
[09/18 13:12:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1421, average loss: 2.9814
[09/18 13:12:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 34.00	
[09/18 13:12:27 visual_prompt]: 	Test 100/1152. loss: 3.010, 0.2083 s / batch. (data: 2.69e-02)max mem: 17.22454 GB 
[09/18 13:12:46 visual_prompt]: 	Test 200/1152. loss: 2.926, 0.1822 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 13:13:06 visual_prompt]: 	Test 300/1152. loss: 2.925, 0.1829 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 13:13:25 visual_prompt]: 	Test 400/1152. loss: 3.052, 0.1830 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 13:13:45 visual_prompt]: 	Test 500/1152. loss: 3.206, 0.1981 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 13:14:04 visual_prompt]: 	Test 600/1152. loss: 3.076, 0.2081 s / batch. (data: 2.62e-02)max mem: 17.22454 GB 
[09/18 13:14:24 visual_prompt]: 	Test 700/1152. loss: 3.115, 0.2073 s / batch. (data: 2.47e-02)max mem: 17.22454 GB 
[09/18 13:14:43 visual_prompt]: 	Test 800/1152. loss: 2.846, 0.1833 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:15:02 visual_prompt]: 	Test 900/1152. loss: 2.980, 0.2118 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 13:15:22 visual_prompt]: 	Test 1000/1152. loss: 3.060, 0.1830 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 13:15:41 visual_prompt]: 	Test 1100/1152. loss: 2.863, 0.1943 s / batch. (data: 1.21e-02)max mem: 17.22454 GB 
[09/18 13:15:55 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1934, average loss: 2.9820
[09/18 13:15:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.17	
[09/18 13:15:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/18 13:16:08 visual_prompt]: Epoch 4 / 100: avg data time: 2.25e-01, avg batch time: 0.6269, average train loss: 3.0956
[09/18 13:16:16 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1434, average loss: 3.1891
[09/18 13:16:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 3.50	top5: 28.00	
[09/18 13:16:38 visual_prompt]: 	Test 100/1152. loss: 3.113, 0.1828 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 13:16:58 visual_prompt]: 	Test 200/1152. loss: 3.098, 0.2093 s / batch. (data: 2.79e-02)max mem: 17.22454 GB 
[09/18 13:17:17 visual_prompt]: 	Test 300/1152. loss: 3.336, 0.1833 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 13:17:36 visual_prompt]: 	Test 400/1152. loss: 3.166, 0.2197 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 13:17:56 visual_prompt]: 	Test 500/1152. loss: 2.959, 0.2075 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 13:18:15 visual_prompt]: 	Test 600/1152. loss: 3.159, 0.1828 s / batch. (data: 3.84e-05)max mem: 17.22454 GB 
[09/18 13:18:35 visual_prompt]: 	Test 700/1152. loss: 2.998, 0.1947 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 13:18:54 visual_prompt]: 	Test 800/1152. loss: 3.158, 0.2093 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 13:19:13 visual_prompt]: 	Test 900/1152. loss: 3.121, 0.1960 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 13:19:33 visual_prompt]: 	Test 1000/1152. loss: 3.045, 0.1947 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 13:19:52 visual_prompt]: 	Test 1100/1152. loss: 3.035, 0.1823 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:20:06 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1934, average loss: 3.1442
[09/18 13:20:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.14	
[09/18 13:20:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/18 13:20:20 visual_prompt]: Epoch 5 / 100: avg data time: 2.17e-01, avg batch time: 0.6209, average train loss: 3.1925
[09/18 13:20:27 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1428, average loss: 3.4503
[09/18 13:20:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 28.50	
[09/18 13:20:49 visual_prompt]: 	Test 100/1152. loss: 3.584, 0.1824 s / batch. (data: 9.78e-05)max mem: 17.22454 GB 
[09/18 13:21:09 visual_prompt]: 	Test 200/1152. loss: 3.146, 0.1906 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 13:21:28 visual_prompt]: 	Test 300/1152. loss: 3.259, 0.1840 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 13:21:47 visual_prompt]: 	Test 400/1152. loss: 3.081, 0.1977 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/18 13:22:06 visual_prompt]: 	Test 500/1152. loss: 3.421, 0.2013 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 13:22:26 visual_prompt]: 	Test 600/1152. loss: 3.271, 0.1879 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 13:22:45 visual_prompt]: 	Test 700/1152. loss: 3.451, 0.1970 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 13:23:05 visual_prompt]: 	Test 800/1152. loss: 3.385, 0.2067 s / batch. (data: 2.46e-02)max mem: 17.22454 GB 
[09/18 13:23:24 visual_prompt]: 	Test 900/1152. loss: 3.175, 0.2054 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 13:23:44 visual_prompt]: 	Test 1000/1152. loss: 3.259, 0.1957 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 13:24:03 visual_prompt]: 	Test 1100/1152. loss: 3.476, 0.2101 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 13:24:18 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1933, average loss: 3.3094
[09/18 13:24:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.21	
[09/18 13:24:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/18 13:24:31 visual_prompt]: Epoch 6 / 100: avg data time: 2.28e-01, avg batch time: 0.6318, average train loss: 3.1555
[09/18 13:24:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1423, average loss: 3.2055
[09/18 13:24:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 31.50	
[09/18 13:25:01 visual_prompt]: 	Test 100/1152. loss: 3.403, 0.1823 s / batch. (data: 9.20e-05)max mem: 17.22454 GB 
[09/18 13:25:20 visual_prompt]: 	Test 200/1152. loss: 3.313, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 13:25:39 visual_prompt]: 	Test 300/1152. loss: 3.151, 0.2008 s / batch. (data: 1.76e-02)max mem: 17.22454 GB 
[09/18 13:25:59 visual_prompt]: 	Test 400/1152. loss: 3.355, 0.1970 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 13:26:18 visual_prompt]: 	Test 500/1152. loss: 3.275, 0.2060 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 13:26:38 visual_prompt]: 	Test 600/1152. loss: 3.263, 0.1970 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 13:26:57 visual_prompt]: 	Test 700/1152. loss: 3.085, 0.1949 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 13:27:17 visual_prompt]: 	Test 800/1152. loss: 3.201, 0.1828 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 13:27:36 visual_prompt]: 	Test 900/1152. loss: 3.363, 0.1826 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 13:27:56 visual_prompt]: 	Test 1000/1152. loss: 3.072, 0.1971 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 13:28:15 visual_prompt]: 	Test 1100/1152. loss: 3.302, 0.1827 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 13:28:29 visual_prompt]: Inference (test):avg data time: 8.49e-03, avg batch time: 0.1936, average loss: 3.2404
[09/18 13:28:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.13	top5: 31.13	
[09/18 13:28:29 visual_prompt]: Best epoch 6: best metric: 0.095
[09/18 13:28:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/18 13:28:42 visual_prompt]: Epoch 7 / 100: avg data time: 2.26e-01, avg batch time: 0.6282, average train loss: 3.3809
[09/18 13:28:50 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1421, average loss: 3.0886
[09/18 13:28:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 32.50	
[09/18 13:29:12 visual_prompt]: 	Test 100/1152. loss: 3.143, 0.1955 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 13:29:32 visual_prompt]: 	Test 200/1152. loss: 3.102, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 13:29:51 visual_prompt]: 	Test 300/1152. loss: 3.106, 0.1827 s / batch. (data: 7.27e-04)max mem: 17.22454 GB 
[09/18 13:30:11 visual_prompt]: 	Test 400/1152. loss: 2.920, 0.1831 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:30:30 visual_prompt]: 	Test 500/1152. loss: 3.025, 0.1986 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 13:30:50 visual_prompt]: 	Test 600/1152. loss: 3.154, 0.1977 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 13:31:09 visual_prompt]: 	Test 700/1152. loss: 3.089, 0.2067 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 13:31:29 visual_prompt]: 	Test 800/1152. loss: 3.102, 0.1827 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:31:48 visual_prompt]: 	Test 900/1152. loss: 3.174, 0.2129 s / batch. (data: 3.11e-02)max mem: 17.22454 GB 
[09/18 13:32:08 visual_prompt]: 	Test 1000/1152. loss: 3.262, 0.1936 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 13:32:27 visual_prompt]: 	Test 1100/1152. loss: 3.136, 0.1961 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 13:32:41 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1939, average loss: 3.0887
[09/18 13:32:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.35	top5: 31.29	
[09/18 13:32:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/18 13:32:55 visual_prompt]: Epoch 8 / 100: avg data time: 2.24e-01, avg batch time: 0.6272, average train loss: 3.4617
[09/18 13:33:02 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1424, average loss: 3.0997
[09/18 13:33:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.50	top5: 29.00	
[09/18 13:33:25 visual_prompt]: 	Test 100/1152. loss: 3.205, 0.1821 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 13:33:44 visual_prompt]: 	Test 200/1152. loss: 3.102, 0.1965 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 13:34:03 visual_prompt]: 	Test 300/1152. loss: 3.170, 0.1837 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 13:34:23 visual_prompt]: 	Test 400/1152. loss: 3.097, 0.1895 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 13:34:43 visual_prompt]: 	Test 500/1152. loss: 3.312, 0.1984 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 13:35:02 visual_prompt]: 	Test 600/1152. loss: 3.309, 0.1963 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 13:35:22 visual_prompt]: 	Test 700/1152. loss: 3.325, 0.1823 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 13:35:41 visual_prompt]: 	Test 800/1152. loss: 3.073, 0.1831 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 13:36:01 visual_prompt]: 	Test 900/1152. loss: 3.036, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 13:36:20 visual_prompt]: 	Test 1000/1152. loss: 3.094, 0.2001 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 13:36:40 visual_prompt]: 	Test 1100/1152. loss: 3.171, 0.1826 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:36:54 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1941, average loss: 3.1484
[09/18 13:36:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.43	top5: 31.06	
[09/18 13:36:54 visual_prompt]: Best epoch 8: best metric: 0.125
[09/18 13:36:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/18 13:37:07 visual_prompt]: Epoch 9 / 100: avg data time: 2.26e-01, avg batch time: 0.6294, average train loss: 3.3946
[09/18 13:37:15 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1421, average loss: 3.2126
[09/18 13:37:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 38.00	
[09/18 13:37:37 visual_prompt]: 	Test 100/1152. loss: 2.962, 0.1956 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 13:37:57 visual_prompt]: 	Test 200/1152. loss: 3.217, 0.1954 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 13:38:16 visual_prompt]: 	Test 300/1152. loss: 3.154, 0.1824 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 13:38:35 visual_prompt]: 	Test 400/1152. loss: 3.252, 0.1833 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 13:38:55 visual_prompt]: 	Test 500/1152. loss: 3.293, 0.1917 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:39:14 visual_prompt]: 	Test 600/1152. loss: 3.339, 0.1982 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 13:39:34 visual_prompt]: 	Test 700/1152. loss: 3.143, 0.1833 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 13:39:53 visual_prompt]: 	Test 800/1152. loss: 3.093, 0.1827 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 13:40:13 visual_prompt]: 	Test 900/1152. loss: 3.301, 0.1910 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:40:32 visual_prompt]: 	Test 1000/1152. loss: 3.284, 0.2006 s / batch. (data: 1.91e-02)max mem: 17.22454 GB 
[09/18 13:40:52 visual_prompt]: 	Test 1100/1152. loss: 3.089, 0.1823 s / batch. (data: 9.44e-05)max mem: 17.22454 GB 
[09/18 13:41:06 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1937, average loss: 3.2208
[09/18 13:41:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 36.84	
[09/18 13:41:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/18 13:41:19 visual_prompt]: Epoch 10 / 100: avg data time: 2.20e-01, avg batch time: 0.6232, average train loss: 3.3593
[09/18 13:41:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1420, average loss: 3.8208
[09/18 13:41:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 5.00	top5: 50.50	
[09/18 13:41:50 visual_prompt]: 	Test 100/1152. loss: 4.254, 0.1913 s / batch. (data: 8.37e-05)max mem: 17.22454 GB 
[09/18 13:42:09 visual_prompt]: 	Test 200/1152. loss: 3.200, 0.1838 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 13:42:28 visual_prompt]: 	Test 300/1152. loss: 3.205, 0.1833 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 13:42:48 visual_prompt]: 	Test 400/1152. loss: 4.334, 0.1946 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 13:43:07 visual_prompt]: 	Test 500/1152. loss: 4.487, 0.1828 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:43:27 visual_prompt]: 	Test 600/1152. loss: 3.339, 0.1826 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 13:43:46 visual_prompt]: 	Test 700/1152. loss: 4.364, 0.1966 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 13:44:06 visual_prompt]: 	Test 800/1152. loss: 3.466, 0.1959 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 13:44:25 visual_prompt]: 	Test 900/1152. loss: 3.057, 0.1924 s / batch. (data: 4.39e-05)max mem: 17.22454 GB 
[09/18 13:44:45 visual_prompt]: 	Test 1000/1152. loss: 2.605, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 13:45:04 visual_prompt]: 	Test 1100/1152. loss: 3.840, 0.1933 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/18 13:45:18 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1936, average loss: 3.6388
[09/18 13:45:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.75	top5: 51.74	
[09/18 13:45:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/18 13:45:32 visual_prompt]: Epoch 11 / 100: avg data time: 2.26e-01, avg batch time: 0.6281, average train loss: 3.7209
[09/18 13:45:39 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1422, average loss: 3.5114
[09/18 13:45:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 15.50	top5: 50.00	
[09/18 13:46:02 visual_prompt]: 	Test 100/1152. loss: 3.596, 0.1979 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/18 13:46:21 visual_prompt]: 	Test 200/1152. loss: 3.216, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 13:46:40 visual_prompt]: 	Test 300/1152. loss: 3.235, 0.1830 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:47:00 visual_prompt]: 	Test 400/1152. loss: 3.336, 0.2084 s / batch. (data: 2.67e-02)max mem: 17.22454 GB 
[09/18 13:47:19 visual_prompt]: 	Test 500/1152. loss: 4.061, 0.1926 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:47:39 visual_prompt]: 	Test 600/1152. loss: 3.979, 0.1932 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 13:47:58 visual_prompt]: 	Test 700/1152. loss: 3.675, 0.2069 s / batch. (data: 2.51e-02)max mem: 17.22454 GB 
[09/18 13:48:17 visual_prompt]: 	Test 800/1152. loss: 3.154, 0.1830 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:48:37 visual_prompt]: 	Test 900/1152. loss: 3.680, 0.1895 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 13:48:56 visual_prompt]: 	Test 1000/1152. loss: 3.272, 0.1836 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 13:49:16 visual_prompt]: 	Test 1100/1152. loss: 3.462, 0.1826 s / batch. (data: 9.16e-05)max mem: 17.22454 GB 
[09/18 13:49:30 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1932, average loss: 3.4400
[09/18 13:49:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.40	top5: 49.80	
[09/18 13:49:30 visual_prompt]: Best epoch 11: best metric: 0.155
[09/18 13:49:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/18 13:49:43 visual_prompt]: Epoch 12 / 100: avg data time: 2.31e-01, avg batch time: 0.6326, average train loss: 2.9085
[09/18 13:49:50 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1445, average loss: 2.4714
[09/18 13:49:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 17.00	top5: 69.50	
[09/18 13:50:13 visual_prompt]: 	Test 100/1152. loss: 2.383, 0.1966 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 13:50:33 visual_prompt]: 	Test 200/1152. loss: 2.582, 0.2061 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 13:50:52 visual_prompt]: 	Test 300/1152. loss: 2.510, 0.1947 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/18 13:51:12 visual_prompt]: 	Test 400/1152. loss: 2.394, 0.1833 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 13:51:31 visual_prompt]: 	Test 500/1152. loss: 2.172, 0.1977 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 13:51:50 visual_prompt]: 	Test 600/1152. loss: 2.305, 0.1827 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 13:52:10 visual_prompt]: 	Test 700/1152. loss: 2.683, 0.2196 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 13:52:29 visual_prompt]: 	Test 800/1152. loss: 2.609, 0.1834 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:52:49 visual_prompt]: 	Test 900/1152. loss: 2.686, 0.2096 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/18 13:53:08 visual_prompt]: 	Test 1000/1152. loss: 2.771, 0.1910 s / batch. (data: 9.20e-05)max mem: 17.22454 GB 
[09/18 13:53:28 visual_prompt]: 	Test 1100/1152. loss: 2.513, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 13:53:42 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1936, average loss: 2.4994
[09/18 13:53:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.49	top5: 69.69	
[09/18 13:53:42 visual_prompt]: Best epoch 12: best metric: 0.170
[09/18 13:53:42 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/18 13:53:55 visual_prompt]: Epoch 13 / 100: avg data time: 2.25e-01, avg batch time: 0.6265, average train loss: 2.6292
[09/18 13:54:02 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1421, average loss: 2.3453
[09/18 13:54:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.00	top5: 70.50	
[09/18 13:54:25 visual_prompt]: 	Test 100/1152. loss: 2.245, 0.1831 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:54:44 visual_prompt]: 	Test 200/1152. loss: 2.364, 0.1831 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:55:04 visual_prompt]: 	Test 300/1152. loss: 2.435, 0.1829 s / batch. (data: 9.94e-05)max mem: 17.22454 GB 
[09/18 13:55:23 visual_prompt]: 	Test 400/1152. loss: 2.320, 0.1931 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 13:55:42 visual_prompt]: 	Test 500/1152. loss: 2.305, 0.1829 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:56:02 visual_prompt]: 	Test 600/1152. loss: 2.459, 0.2031 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:56:21 visual_prompt]: 	Test 700/1152. loss: 2.665, 0.2231 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:56:41 visual_prompt]: 	Test 800/1152. loss: 2.327, 0.1828 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:57:00 visual_prompt]: 	Test 900/1152. loss: 2.557, 0.1830 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 13:57:19 visual_prompt]: 	Test 1000/1152. loss: 2.604, 0.1960 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 13:57:39 visual_prompt]: 	Test 1100/1152. loss: 2.388, 0.2001 s / batch. (data: 1.76e-02)max mem: 17.22454 GB 
[09/18 13:57:53 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1930, average loss: 2.3751
[09/18 13:57:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.37	top5: 68.84	
[09/18 13:57:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/18 13:58:06 visual_prompt]: Epoch 14 / 100: avg data time: 2.23e-01, avg batch time: 0.6269, average train loss: 2.3003
[09/18 13:58:13 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1449, average loss: 2.1468
[09/18 13:58:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 21.00	top5: 82.00	
[09/18 13:58:36 visual_prompt]: 	Test 100/1152. loss: 2.328, 0.1838 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:58:55 visual_prompt]: 	Test 200/1152. loss: 1.890, 0.1902 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 13:59:14 visual_prompt]: 	Test 300/1152. loss: 2.032, 0.1831 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:59:34 visual_prompt]: 	Test 400/1152. loss: 1.972, 0.1970 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 13:59:53 visual_prompt]: 	Test 500/1152. loss: 2.297, 0.1827 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 14:00:13 visual_prompt]: 	Test 600/1152. loss: 2.117, 0.1852 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 14:00:32 visual_prompt]: 	Test 700/1152. loss: 1.968, 0.1941 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 14:00:52 visual_prompt]: 	Test 800/1152. loss: 2.129, 0.1834 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:01:11 visual_prompt]: 	Test 900/1152. loss: 2.122, 0.1846 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 14:01:31 visual_prompt]: 	Test 1000/1152. loss: 2.050, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 14:01:50 visual_prompt]: 	Test 1100/1152. loss: 2.144, 0.1834 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 14:02:04 visual_prompt]: Inference (test):avg data time: 8.52e-03, avg batch time: 0.1936, average loss: 2.0828
[09/18 14:02:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 21.63	top5: 82.36	
[09/18 14:02:05 visual_prompt]: Best epoch 14: best metric: 0.210
[09/18 14:02:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/18 14:02:18 visual_prompt]: Epoch 15 / 100: avg data time: 2.26e-01, avg batch time: 0.6278, average train loss: 2.2631
[09/18 14:02:25 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1433, average loss: 2.5826
[09/18 14:02:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 26.50	top5: 77.50	
[09/18 14:02:48 visual_prompt]: 	Test 100/1152. loss: 2.605, 0.1827 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 14:03:07 visual_prompt]: 	Test 200/1152. loss: 3.353, 0.1981 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 14:03:26 visual_prompt]: 	Test 300/1152. loss: 2.785, 0.1941 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 14:03:46 visual_prompt]: 	Test 400/1152. loss: 2.517, 0.1822 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:04:05 visual_prompt]: 	Test 500/1152. loss: 2.576, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 14:04:25 visual_prompt]: 	Test 600/1152. loss: 2.657, 0.1823 s / batch. (data: 9.89e-05)max mem: 17.22454 GB 
[09/18 14:04:44 visual_prompt]: 	Test 700/1152. loss: 2.353, 0.1831 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 14:05:04 visual_prompt]: 	Test 800/1152. loss: 2.706, 0.1985 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 14:05:23 visual_prompt]: 	Test 900/1152. loss: 2.729, 0.2083 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 14:05:43 visual_prompt]: 	Test 1000/1152. loss: 2.946, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 14:06:02 visual_prompt]: 	Test 1100/1152. loss: 2.518, 0.1982 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 14:06:16 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1934, average loss: 2.7779
[09/18 14:06:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 23.69	top5: 76.27	
[09/18 14:06:16 visual_prompt]: Best epoch 15: best metric: 0.265
[09/18 14:06:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/18 14:06:29 visual_prompt]: Epoch 16 / 100: avg data time: 2.27e-01, avg batch time: 0.6285, average train loss: 2.2959
[09/18 14:06:37 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1419, average loss: 2.4477
[09/18 14:06:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 15.00	top5: 79.00	
[09/18 14:06:59 visual_prompt]: 	Test 100/1152. loss: 2.421, 0.1828 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 14:07:19 visual_prompt]: 	Test 200/1152. loss: 2.630, 0.2062 s / batch. (data: 2.44e-02)max mem: 17.22454 GB 
[09/18 14:07:38 visual_prompt]: 	Test 300/1152. loss: 2.519, 0.1838 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 14:07:57 visual_prompt]: 	Test 400/1152. loss: 2.660, 0.2064 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 14:08:17 visual_prompt]: 	Test 500/1152. loss: 2.476, 0.1821 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 14:08:36 visual_prompt]: 	Test 600/1152. loss: 2.310, 0.1834 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 14:08:56 visual_prompt]: 	Test 700/1152. loss: 2.609, 0.1855 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 14:09:15 visual_prompt]: 	Test 800/1152. loss: 2.296, 0.1830 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 14:09:35 visual_prompt]: 	Test 900/1152. loss: 2.512, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 14:09:54 visual_prompt]: 	Test 1000/1152. loss: 2.626, 0.1827 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 14:10:13 visual_prompt]: 	Test 1100/1152. loss: 2.362, 0.1830 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 14:10:27 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1933, average loss: 2.5149
[09/18 14:10:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.58	top5: 76.24	
[09/18 14:10:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/18 14:10:41 visual_prompt]: Epoch 17 / 100: avg data time: 2.31e-01, avg batch time: 0.6319, average train loss: 2.2824
[09/18 14:10:48 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1421, average loss: 2.3434
[09/18 14:10:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 26.50	top5: 88.50	
[09/18 14:11:11 visual_prompt]: 	Test 100/1152. loss: 2.225, 0.1944 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 14:11:30 visual_prompt]: 	Test 200/1152. loss: 2.560, 0.1826 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 14:11:49 visual_prompt]: 	Test 300/1152. loss: 2.318, 0.1972 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 14:12:09 visual_prompt]: 	Test 400/1152. loss: 2.626, 0.2119 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 14:12:28 visual_prompt]: 	Test 500/1152. loss: 2.431, 0.1967 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 14:12:48 visual_prompt]: 	Test 600/1152. loss: 2.266, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 14:13:07 visual_prompt]: 	Test 700/1152. loss: 2.251, 0.1880 s / batch. (data: 9.58e-05)max mem: 17.22454 GB 
[09/18 14:13:27 visual_prompt]: 	Test 800/1152. loss: 2.197, 0.1960 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 14:13:46 visual_prompt]: 	Test 900/1152. loss: 2.000, 0.1827 s / batch. (data: 9.87e-05)max mem: 17.22454 GB 
[09/18 14:14:06 visual_prompt]: 	Test 1000/1152. loss: 2.296, 0.2094 s / batch. (data: 2.74e-02)max mem: 17.22454 GB 
[09/18 14:14:25 visual_prompt]: 	Test 1100/1152. loss: 2.337, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 14:14:39 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1936, average loss: 2.3947
[09/18 14:14:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 24.32	top5: 85.53	
[09/18 14:14:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/18 14:14:52 visual_prompt]: Epoch 18 / 100: avg data time: 2.21e-01, avg batch time: 0.6242, average train loss: 2.1578
[09/18 14:14:59 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1420, average loss: 1.9344
[09/18 14:14:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.00	top5: 92.50	
[09/18 14:15:22 visual_prompt]: 	Test 100/1152. loss: 1.525, 0.1964 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 14:15:42 visual_prompt]: 	Test 200/1152. loss: 2.330, 0.1963 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 14:16:01 visual_prompt]: 	Test 300/1152. loss: 2.048, 0.1856 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 14:16:20 visual_prompt]: 	Test 400/1152. loss: 1.859, 0.1826 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:16:40 visual_prompt]: 	Test 500/1152. loss: 1.995, 0.1979 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 14:16:59 visual_prompt]: 	Test 600/1152. loss: 2.071, 0.1830 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 14:17:19 visual_prompt]: 	Test 700/1152. loss: 1.604, 0.1833 s / batch. (data: 9.25e-05)max mem: 17.22454 GB 
[09/18 14:17:38 visual_prompt]: 	Test 800/1152. loss: 1.958, 0.1957 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 14:17:57 visual_prompt]: 	Test 900/1152. loss: 1.994, 0.1932 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/18 14:18:17 visual_prompt]: 	Test 1000/1152. loss: 2.151, 0.1834 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 14:18:36 visual_prompt]: 	Test 1100/1152. loss: 1.886, 0.1831 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 14:18:51 visual_prompt]: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1934, average loss: 1.9764
[09/18 14:18:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 30.57	top5: 93.32	
[09/18 14:18:51 visual_prompt]: Best epoch 18: best metric: 0.320
[09/18 14:18:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/18 14:19:04 visual_prompt]: Epoch 19 / 100: avg data time: 2.21e-01, avg batch time: 0.6250, average train loss: 2.9401
[09/18 14:19:11 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1447, average loss: 2.5992
[09/18 14:19:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 20.50	top5: 73.50	
[09/18 14:19:34 visual_prompt]: 	Test 100/1152. loss: 2.399, 0.1913 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 14:19:53 visual_prompt]: 	Test 200/1152. loss: 2.600, 0.1857 s / batch. (data: 9.11e-05)max mem: 17.22454 GB 
[09/18 14:20:12 visual_prompt]: 	Test 300/1152. loss: 2.979, 0.2039 s / batch. (data: 2.23e-02)max mem: 17.22454 GB 
[09/18 14:20:32 visual_prompt]: 	Test 400/1152. loss: 2.385, 0.1917 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 14:20:52 visual_prompt]: 	Test 500/1152. loss: 2.095, 0.1979 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 14:21:11 visual_prompt]: 	Test 600/1152. loss: 2.616, 0.1946 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 14:21:30 visual_prompt]: 	Test 700/1152. loss: 2.437, 0.1930 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 14:21:50 visual_prompt]: 	Test 800/1152. loss: 2.651, 0.1974 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 14:22:09 visual_prompt]: 	Test 900/1152. loss: 2.478, 0.2061 s / batch. (data: 2.43e-02)max mem: 17.22454 GB 
[09/18 14:22:28 visual_prompt]: 	Test 1000/1152. loss: 2.540, 0.1834 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 14:22:48 visual_prompt]: 	Test 1100/1152. loss: 2.446, 0.1965 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 14:23:02 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1933, average loss: 2.5464
[09/18 14:23:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 19.05	top5: 76.20	
[09/18 14:23:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/18 14:23:16 visual_prompt]: Epoch 20 / 100: avg data time: 2.36e-01, avg batch time: 0.6369, average train loss: 2.0825
[09/18 14:23:23 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1423, average loss: 2.3338
[09/18 14:23:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 31.00	top5: 80.00	
[09/18 14:23:46 visual_prompt]: 	Test 100/1152. loss: 1.953, 0.1825 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 14:24:05 visual_prompt]: 	Test 200/1152. loss: 2.250, 0.1967 s / batch. (data: 3.86e-05)max mem: 17.22454 GB 
[09/18 14:24:24 visual_prompt]: 	Test 300/1152. loss: 1.977, 0.1829 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 14:24:44 visual_prompt]: 	Test 400/1152. loss: 2.434, 0.1832 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 14:25:03 visual_prompt]: 	Test 500/1152. loss: 2.413, 0.2166 s / batch. (data: 3.48e-02)max mem: 17.22454 GB 
[09/18 14:25:23 visual_prompt]: 	Test 600/1152. loss: 2.138, 0.1954 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 14:25:42 visual_prompt]: 	Test 700/1152. loss: 1.994, 0.1938 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 14:26:02 visual_prompt]: 	Test 800/1152. loss: 2.184, 0.1970 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 14:26:21 visual_prompt]: 	Test 900/1152. loss: 2.086, 0.1965 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 14:26:40 visual_prompt]: 	Test 1000/1152. loss: 2.257, 0.2035 s / batch. (data: 2.13e-02)max mem: 17.22454 GB 
[09/18 14:27:00 visual_prompt]: 	Test 1100/1152. loss: 2.052, 0.1830 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 14:27:14 visual_prompt]: Inference (test):avg data time: 8.27e-03, avg batch time: 0.1936, average loss: 2.2298
[09/18 14:27:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 26.94	top5: 82.83	
[09/18 14:27:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/18 14:27:27 visual_prompt]: Epoch 21 / 100: avg data time: 2.25e-01, avg batch time: 0.6284, average train loss: 1.9767
[09/18 14:27:34 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1425, average loss: 1.8989
[09/18 14:27:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.00	top5: 96.50	
[09/18 14:27:57 visual_prompt]: 	Test 100/1152. loss: 2.287, 0.2086 s / batch. (data: 4.60e-05)max mem: 17.22454 GB 
[09/18 14:28:17 visual_prompt]: 	Test 200/1152. loss: 1.740, 0.2042 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 14:28:36 visual_prompt]: 	Test 300/1152. loss: 2.262, 0.1829 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 14:28:55 visual_prompt]: 	Test 400/1152. loss: 1.721, 0.1971 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 14:29:15 visual_prompt]: 	Test 500/1152. loss: 1.857, 0.1823 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 14:29:34 visual_prompt]: 	Test 600/1152. loss: 2.111, 0.1991 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 14:29:54 visual_prompt]: 	Test 700/1152. loss: 1.857, 0.1967 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 14:30:13 visual_prompt]: 	Test 800/1152. loss: 1.799, 0.1972 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 14:30:33 visual_prompt]: 	Test 900/1152. loss: 2.157, 0.1977 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 14:30:52 visual_prompt]: 	Test 1000/1152. loss: 2.020, 0.2004 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 14:31:11 visual_prompt]: 	Test 1100/1152. loss: 1.778, 0.1834 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 14:31:25 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1935, average loss: 1.9640
[09/18 14:31:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.87	top5: 95.59	
[09/18 14:31:26 visual_prompt]: Best epoch 21: best metric: 0.360
[09/18 14:31:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/18 14:31:39 visual_prompt]: Epoch 22 / 100: avg data time: 2.25e-01, avg batch time: 0.6267, average train loss: 1.6384
[09/18 14:31:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1423, average loss: 1.7895
[09/18 14:31:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 39.50	top5: 96.00	
[09/18 14:32:09 visual_prompt]: 	Test 100/1152. loss: 2.037, 0.1953 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 14:32:28 visual_prompt]: 	Test 200/1152. loss: 1.647, 0.1971 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 14:32:48 visual_prompt]: 	Test 300/1152. loss: 1.813, 0.1825 s / batch. (data: 8.73e-05)max mem: 17.22454 GB 
[09/18 14:33:07 visual_prompt]: 	Test 400/1152. loss: 2.038, 0.1911 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 14:33:27 visual_prompt]: 	Test 500/1152. loss: 2.182, 0.1828 s / batch. (data: 9.73e-05)max mem: 17.22454 GB 
[09/18 14:33:46 visual_prompt]: 	Test 600/1152. loss: 1.869, 0.1828 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 14:34:05 visual_prompt]: 	Test 700/1152. loss: 2.200, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 14:34:25 visual_prompt]: 	Test 800/1152. loss: 1.757, 0.1839 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 14:34:44 visual_prompt]: 	Test 900/1152. loss: 1.740, 0.1827 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 14:35:04 visual_prompt]: 	Test 1000/1152. loss: 1.589, 0.1956 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 14:35:23 visual_prompt]: 	Test 1100/1152. loss: 2.078, 0.1946 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/18 14:35:37 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1937, average loss: 1.8971
[09/18 14:35:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 33.49	top5: 96.98	
[09/18 14:35:38 visual_prompt]: Best epoch 22: best metric: 0.395
[09/18 14:35:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/18 14:35:51 visual_prompt]: Epoch 23 / 100: avg data time: 2.26e-01, avg batch time: 0.6269, average train loss: 1.9377
[09/18 14:35:58 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1437, average loss: 1.9852
[09/18 14:35:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 35.00	top5: 93.00	
[09/18 14:36:21 visual_prompt]: 	Test 100/1152. loss: 2.143, 0.1824 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 14:36:40 visual_prompt]: 	Test 200/1152. loss: 1.928, 0.1922 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/18 14:36:59 visual_prompt]: 	Test 300/1152. loss: 2.217, 0.1830 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 14:37:19 visual_prompt]: 	Test 400/1152. loss: 1.984, 0.1820 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 14:37:38 visual_prompt]: 	Test 500/1152. loss: 2.251, 0.1829 s / batch. (data: 5.05e-05)max mem: 17.22454 GB 
[09/18 14:37:58 visual_prompt]: 	Test 600/1152. loss: 2.400, 0.1975 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 14:38:17 visual_prompt]: 	Test 700/1152. loss: 2.221, 0.1917 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 14:38:36 visual_prompt]: 	Test 800/1152. loss: 2.184, 0.2003 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 14:38:56 visual_prompt]: 	Test 900/1152. loss: 2.337, 0.1834 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 14:39:15 visual_prompt]: 	Test 1000/1152. loss: 2.069, 0.1935 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 14:39:34 visual_prompt]: 	Test 1100/1152. loss: 2.218, 0.1947 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 14:39:49 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1930, average loss: 2.1401
[09/18 14:39:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.01	top5: 88.55	
[09/18 14:39:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/18 14:40:02 visual_prompt]: Epoch 24 / 100: avg data time: 2.28e-01, avg batch time: 0.6323, average train loss: 2.0871
[09/18 14:40:09 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1420, average loss: 2.0864
[09/18 14:40:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.00	top5: 93.00	
[09/18 14:40:32 visual_prompt]: 	Test 100/1152. loss: 1.888, 0.2002 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 14:40:52 visual_prompt]: 	Test 200/1152. loss: 2.237, 0.2023 s / batch. (data: 2.06e-02)max mem: 17.22454 GB 
[09/18 14:41:11 visual_prompt]: 	Test 300/1152. loss: 1.827, 0.2174 s / batch. (data: 3.56e-02)max mem: 17.22454 GB 
[09/18 14:41:30 visual_prompt]: 	Test 400/1152. loss: 2.185, 0.1833 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 14:41:50 visual_prompt]: 	Test 500/1152. loss: 2.218, 0.1956 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 14:42:09 visual_prompt]: 	Test 600/1152. loss: 1.924, 0.1832 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 14:42:28 visual_prompt]: 	Test 700/1152. loss: 2.067, 0.1837 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 14:42:48 visual_prompt]: 	Test 800/1152. loss: 2.193, 0.2062 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/18 14:43:07 visual_prompt]: 	Test 900/1152. loss: 2.490, 0.1828 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 14:43:27 visual_prompt]: 	Test 1000/1152. loss: 2.157, 0.1836 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 14:43:46 visual_prompt]: 	Test 1100/1152. loss: 2.338, 0.1974 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 14:44:00 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1934, average loss: 2.1190
[09/18 14:44:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.23	top5: 94.09	
[09/18 14:44:00 visual_prompt]: Best epoch 24: best metric: 0.400
[09/18 14:44:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/18 14:44:14 visual_prompt]: Epoch 25 / 100: avg data time: 2.32e-01, avg batch time: 0.6324, average train loss: 1.6566
[09/18 14:44:21 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1473, average loss: 1.4823
[09/18 14:44:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.50	top5: 100.00	
[09/18 14:44:44 visual_prompt]: 	Test 100/1152. loss: 1.400, 0.2022 s / batch. (data: 2.06e-02)max mem: 17.22454 GB 
[09/18 14:45:03 visual_prompt]: 	Test 200/1152. loss: 1.471, 0.1845 s / batch. (data: 2.79e-05)max mem: 17.22454 GB 
[09/18 14:45:22 visual_prompt]: 	Test 300/1152. loss: 1.408, 0.2218 s / batch. (data: 2.48e-02)max mem: 17.22454 GB 
[09/18 14:45:42 visual_prompt]: 	Test 400/1152. loss: 1.605, 0.1947 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 14:46:01 visual_prompt]: 	Test 500/1152. loss: 1.630, 0.1835 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 14:46:21 visual_prompt]: 	Test 600/1152. loss: 1.524, 0.1826 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 14:46:40 visual_prompt]: 	Test 700/1152. loss: 1.362, 0.1975 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 14:47:00 visual_prompt]: 	Test 800/1152. loss: 1.438, 0.1984 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 14:47:19 visual_prompt]: 	Test 900/1152. loss: 1.512, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 14:47:38 visual_prompt]: 	Test 1000/1152. loss: 1.364, 0.1828 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 14:47:58 visual_prompt]: 	Test 1100/1152. loss: 1.450, 0.1970 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 14:48:12 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1933, average loss: 1.4873
[09/18 14:48:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.38	top5: 99.82	
[09/18 14:48:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/18 14:48:25 visual_prompt]: Epoch 26 / 100: avg data time: 2.29e-01, avg batch time: 0.6329, average train loss: 1.3706
[09/18 14:48:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1423, average loss: 1.5372
[09/18 14:48:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 41.50	top5: 99.50	
[09/18 14:48:55 visual_prompt]: 	Test 100/1152. loss: 1.663, 0.2038 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 14:49:14 visual_prompt]: 	Test 200/1152. loss: 1.495, 0.1969 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 14:49:34 visual_prompt]: 	Test 300/1152. loss: 1.381, 0.1830 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 14:49:53 visual_prompt]: 	Test 400/1152. loss: 1.560, 0.1889 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 14:50:13 visual_prompt]: 	Test 500/1152. loss: 1.807, 0.2013 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 14:50:32 visual_prompt]: 	Test 600/1152. loss: 1.679, 0.1969 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 14:50:52 visual_prompt]: 	Test 700/1152. loss: 1.585, 0.1901 s / batch. (data: 8.89e-05)max mem: 17.22454 GB 
[09/18 14:51:11 visual_prompt]: 	Test 800/1152. loss: 1.454, 0.2101 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 14:51:31 visual_prompt]: 	Test 900/1152. loss: 1.731, 0.1827 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 14:51:50 visual_prompt]: 	Test 1000/1152. loss: 1.385, 0.1962 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 14:52:09 visual_prompt]: 	Test 1100/1152. loss: 1.723, 0.1832 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 14:52:24 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1935, average loss: 1.5923
[09/18 14:52:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 42.34	top5: 99.35	
[09/18 14:52:24 visual_prompt]: Best epoch 26: best metric: 0.415
[09/18 14:52:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/18 14:52:37 visual_prompt]: Epoch 27 / 100: avg data time: 2.25e-01, avg batch time: 0.6281, average train loss: 1.6246
[09/18 14:52:44 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1429, average loss: 1.6971
[09/18 14:52:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 43.00	top5: 99.50	
[09/18 14:53:07 visual_prompt]: 	Test 100/1152. loss: 1.768, 0.1934 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 14:53:26 visual_prompt]: 	Test 200/1152. loss: 1.455, 0.1917 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:53:45 visual_prompt]: 	Test 300/1152. loss: 1.502, 0.1973 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 14:54:05 visual_prompt]: 	Test 400/1152. loss: 1.669, 0.1820 s / batch. (data: 8.32e-05)max mem: 17.22454 GB 
[09/18 14:54:24 visual_prompt]: 	Test 500/1152. loss: 1.596, 0.1831 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 14:54:43 visual_prompt]: 	Test 600/1152. loss: 1.426, 0.2052 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 14:55:03 visual_prompt]: 	Test 700/1152. loss: 1.688, 0.1831 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 14:55:22 visual_prompt]: 	Test 800/1152. loss: 1.700, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 14:55:42 visual_prompt]: 	Test 900/1152. loss: 1.346, 0.1841 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 14:56:01 visual_prompt]: 	Test 1000/1152. loss: 1.265, 0.1841 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 14:56:21 visual_prompt]: 	Test 1100/1152. loss: 1.702, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 14:56:35 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1933, average loss: 1.6172
[09/18 14:56:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 41.76	top5: 99.54	
[09/18 14:56:35 visual_prompt]: Best epoch 27: best metric: 0.430
[09/18 14:56:35 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/18 14:56:48 visual_prompt]: Epoch 28 / 100: avg data time: 2.27e-01, avg batch time: 0.6289, average train loss: 1.3105
[09/18 14:56:55 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1423, average loss: 1.1696
[09/18 14:56:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 62.00	top5: 100.00	
[09/18 14:57:18 visual_prompt]: 	Test 100/1152. loss: 1.101, 0.1967 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 14:57:37 visual_prompt]: 	Test 200/1152. loss: 1.217, 0.1961 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 14:57:56 visual_prompt]: 	Test 300/1152. loss: 1.390, 0.2078 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 14:58:16 visual_prompt]: 	Test 400/1152. loss: 1.576, 0.1961 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 14:58:35 visual_prompt]: 	Test 500/1152. loss: 1.273, 0.1820 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/18 14:58:55 visual_prompt]: 	Test 600/1152. loss: 1.330, 0.1830 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 14:59:14 visual_prompt]: 	Test 700/1152. loss: 1.173, 0.1821 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 14:59:34 visual_prompt]: 	Test 800/1152. loss: 1.430, 0.1966 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 14:59:53 visual_prompt]: 	Test 900/1152. loss: 1.673, 0.1943 s / batch. (data: 1.20e-02)max mem: 17.22454 GB 
[09/18 15:00:12 visual_prompt]: 	Test 1000/1152. loss: 1.609, 0.1988 s / batch. (data: 1.68e-02)max mem: 17.22454 GB 
[09/18 15:00:32 visual_prompt]: 	Test 1100/1152. loss: 1.600, 0.1832 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 15:00:46 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1930, average loss: 1.4214
[09/18 15:00:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.59	top5: 99.82	
[09/18 15:00:46 visual_prompt]: Best epoch 28: best metric: 0.620
[09/18 15:00:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/18 15:00:59 visual_prompt]: Epoch 29 / 100: avg data time: 2.16e-01, avg batch time: 0.6185, average train loss: 1.1993
[09/18 15:01:06 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1421, average loss: 1.6680
[09/18 15:01:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.50	top5: 99.50	
[09/18 15:01:29 visual_prompt]: 	Test 100/1152. loss: 2.020, 0.1826 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 15:01:48 visual_prompt]: 	Test 200/1152. loss: 2.082, 0.1831 s / batch. (data: 9.92e-05)max mem: 17.22454 GB 
[09/18 15:02:07 visual_prompt]: 	Test 300/1152. loss: 1.973, 0.2113 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 15:02:27 visual_prompt]: 	Test 400/1152. loss: 1.670, 0.1829 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 15:02:46 visual_prompt]: 	Test 500/1152. loss: 1.862, 0.2192 s / batch. (data: 3.71e-02)max mem: 17.22454 GB 
[09/18 15:03:05 visual_prompt]: 	Test 600/1152. loss: 1.955, 0.1828 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/18 15:03:25 visual_prompt]: 	Test 700/1152. loss: 1.656, 0.2007 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:03:44 visual_prompt]: 	Test 800/1152. loss: 1.709, 0.1966 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 15:04:04 visual_prompt]: 	Test 900/1152. loss: 2.013, 0.1971 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 15:04:23 visual_prompt]: 	Test 1000/1152. loss: 1.995, 0.1969 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 15:04:43 visual_prompt]: 	Test 1100/1152. loss: 1.389, 0.1834 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 15:04:57 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1935, average loss: 1.7833
[09/18 15:04:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.11	top5: 99.01	
[09/18 15:04:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/18 15:05:10 visual_prompt]: Epoch 30 / 100: avg data time: 2.22e-01, avg batch time: 0.6241, average train loss: 1.2518
[09/18 15:05:17 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1423, average loss: 1.2435
[09/18 15:05:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 47.00	top5: 98.50	
[09/18 15:05:40 visual_prompt]: 	Test 100/1152. loss: 1.443, 0.2008 s / batch. (data: 1.62e-02)max mem: 17.22454 GB 
[09/18 15:06:00 visual_prompt]: 	Test 200/1152. loss: 1.643, 0.1930 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 15:06:19 visual_prompt]: 	Test 300/1152. loss: 1.619, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:06:38 visual_prompt]: 	Test 400/1152. loss: 1.283, 0.1960 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 15:06:58 visual_prompt]: 	Test 500/1152. loss: 0.968, 0.1859 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/18 15:07:17 visual_prompt]: 	Test 600/1152. loss: 1.189, 0.1831 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:07:37 visual_prompt]: 	Test 700/1152. loss: 1.267, 0.2048 s / batch. (data: 1.21e-02)max mem: 17.22454 GB 
[09/18 15:07:56 visual_prompt]: 	Test 800/1152. loss: 1.309, 0.2045 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/18 15:08:15 visual_prompt]: 	Test 900/1152. loss: 1.535, 0.1826 s / batch. (data: 4.60e-05)max mem: 17.22454 GB 
[09/18 15:08:35 visual_prompt]: 	Test 1000/1152. loss: 1.414, 0.1903 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 15:08:54 visual_prompt]: 	Test 1100/1152. loss: 1.228, 0.2209 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 15:09:08 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1933, average loss: 1.4020
[09/18 15:09:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.98	top5: 98.87	
[09/18 15:09:09 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/18 15:09:22 visual_prompt]: Epoch 31 / 100: avg data time: 2.26e-01, avg batch time: 0.6260, average train loss: 1.5858
[09/18 15:09:29 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1428, average loss: 1.4745
[09/18 15:09:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.00	top5: 99.50	
[09/18 15:09:52 visual_prompt]: 	Test 100/1152. loss: 1.694, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:10:11 visual_prompt]: 	Test 200/1152. loss: 1.405, 0.1926 s / batch. (data: 1.04e-02)max mem: 17.22454 GB 
[09/18 15:10:30 visual_prompt]: 	Test 300/1152. loss: 1.616, 0.1951 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 15:10:50 visual_prompt]: 	Test 400/1152. loss: 1.463, 0.1834 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 15:11:09 visual_prompt]: 	Test 500/1152. loss: 1.572, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:11:29 visual_prompt]: 	Test 600/1152. loss: 1.636, 0.1829 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:11:48 visual_prompt]: 	Test 700/1152. loss: 1.842, 0.1829 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 15:12:07 visual_prompt]: 	Test 800/1152. loss: 1.681, 0.1829 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 15:12:27 visual_prompt]: 	Test 900/1152. loss: 1.824, 0.1872 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 15:12:46 visual_prompt]: 	Test 1000/1152. loss: 1.888, 0.1986 s / batch. (data: 1.66e-02)max mem: 17.22454 GB 
[09/18 15:13:05 visual_prompt]: 	Test 1100/1152. loss: 1.800, 0.2061 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 15:13:19 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1930, average loss: 1.6493
[09/18 15:13:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 44.23	top5: 99.42	
[09/18 15:13:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/18 15:13:33 visual_prompt]: Epoch 32 / 100: avg data time: 2.19e-01, avg batch time: 0.6214, average train loss: 1.4050
[09/18 15:13:40 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1422, average loss: 1.6569
[09/18 15:13:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 39.50	top5: 100.00	
[09/18 15:14:03 visual_prompt]: 	Test 100/1152. loss: 1.664, 0.1959 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 15:14:22 visual_prompt]: 	Test 200/1152. loss: 1.630, 0.2021 s / batch. (data: 2.04e-02)max mem: 17.22454 GB 
[09/18 15:14:41 visual_prompt]: 	Test 300/1152. loss: 2.101, 0.1905 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 15:15:01 visual_prompt]: 	Test 400/1152. loss: 1.814, 0.1821 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 15:15:20 visual_prompt]: 	Test 500/1152. loss: 1.385, 0.1828 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 15:15:40 visual_prompt]: 	Test 600/1152. loss: 1.761, 0.1993 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 15:15:59 visual_prompt]: 	Test 700/1152. loss: 1.676, 0.1834 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/18 15:16:19 visual_prompt]: 	Test 800/1152. loss: 2.072, 0.1888 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 15:16:38 visual_prompt]: 	Test 900/1152. loss: 1.949, 0.1826 s / batch. (data: 7.68e-05)max mem: 17.22454 GB 
[09/18 15:16:57 visual_prompt]: 	Test 1000/1152. loss: 1.811, 0.1830 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 15:17:17 visual_prompt]: 	Test 1100/1152. loss: 1.907, 0.1834 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 15:17:31 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1935, average loss: 1.7907
[09/18 15:17:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 38.26	top5: 99.95	
[09/18 15:17:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/18 15:17:44 visual_prompt]: Epoch 33 / 100: avg data time: 2.21e-01, avg batch time: 0.6235, average train loss: 1.6243
[09/18 15:17:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1422, average loss: 1.4622
[09/18 15:17:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 38.50	top5: 96.50	
[09/18 15:18:14 visual_prompt]: 	Test 100/1152. loss: 1.567, 0.2046 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 15:18:33 visual_prompt]: 	Test 200/1152. loss: 1.836, 0.1830 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 15:18:53 visual_prompt]: 	Test 300/1152. loss: 1.808, 0.1959 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 15:19:12 visual_prompt]: 	Test 400/1152. loss: 1.501, 0.1974 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 15:19:31 visual_prompt]: 	Test 500/1152. loss: 1.431, 0.2122 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 15:19:51 visual_prompt]: 	Test 600/1152. loss: 1.416, 0.1830 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 15:20:10 visual_prompt]: 	Test 700/1152. loss: 1.399, 0.1871 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 15:20:30 visual_prompt]: 	Test 800/1152. loss: 1.565, 0.2037 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 15:20:49 visual_prompt]: 	Test 900/1152. loss: 1.467, 0.1978 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 15:21:09 visual_prompt]: 	Test 1000/1152. loss: 1.746, 0.1902 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/18 15:21:28 visual_prompt]: 	Test 1100/1152. loss: 1.280, 0.2053 s / batch. (data: 5.13e-03)max mem: 17.22454 GB 
[09/18 15:21:42 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1935, average loss: 1.5905
[09/18 15:21:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 39.50	top5: 97.02	
[09/18 15:21:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/18 15:21:55 visual_prompt]: Epoch 34 / 100: avg data time: 2.26e-01, avg batch time: 0.6304, average train loss: 1.2258
[09/18 15:22:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1420, average loss: 1.0614
[09/18 15:22:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 53.50	top5: 100.00	
[09/18 15:22:25 visual_prompt]: 	Test 100/1152. loss: 1.148, 0.1917 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:22:44 visual_prompt]: 	Test 200/1152. loss: 1.151, 0.1910 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 15:23:03 visual_prompt]: 	Test 300/1152. loss: 1.140, 0.2066 s / batch. (data: 2.49e-02)max mem: 17.22454 GB 
[09/18 15:23:23 visual_prompt]: 	Test 400/1152. loss: 0.957, 0.1828 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 15:23:42 visual_prompt]: 	Test 500/1152. loss: 1.069, 0.1833 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:24:01 visual_prompt]: 	Test 600/1152. loss: 1.117, 0.1863 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 15:24:21 visual_prompt]: 	Test 700/1152. loss: 1.303, 0.1828 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/18 15:24:40 visual_prompt]: 	Test 800/1152. loss: 0.941, 0.1950 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 15:25:00 visual_prompt]: 	Test 900/1152. loss: 1.193, 0.1832 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 15:25:19 visual_prompt]: 	Test 1000/1152. loss: 1.358, 0.2285 s / batch. (data: 4.67e-02)max mem: 17.22454 GB 
[09/18 15:25:39 visual_prompt]: 	Test 1100/1152. loss: 0.879, 0.2204 s / batch. (data: 3.19e-02)max mem: 17.22454 GB 
[09/18 15:25:52 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1928, average loss: 1.1366
[09/18 15:25:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.70	top5: 100.00	
[09/18 15:25:53 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/18 15:26:06 visual_prompt]: Epoch 35 / 100: avg data time: 2.25e-01, avg batch time: 0.6243, average train loss: 1.0842
[09/18 15:26:13 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1422, average loss: 1.3720
[09/18 15:26:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.00	top5: 100.00	
[09/18 15:26:36 visual_prompt]: 	Test 100/1152. loss: 1.699, 0.2079 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 15:26:55 visual_prompt]: 	Test 200/1152. loss: 1.226, 0.1959 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 15:27:14 visual_prompt]: 	Test 300/1152. loss: 1.603, 0.1909 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 15:27:34 visual_prompt]: 	Test 400/1152. loss: 1.368, 0.1964 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 15:27:53 visual_prompt]: 	Test 500/1152. loss: 1.637, 0.1825 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 15:28:13 visual_prompt]: 	Test 600/1152. loss: 1.462, 0.2049 s / batch. (data: 1.78e-02)max mem: 17.22454 GB 
[09/18 15:28:32 visual_prompt]: 	Test 700/1152. loss: 1.634, 0.1989 s / batch. (data: 1.63e-02)max mem: 17.22454 GB 
[09/18 15:28:51 visual_prompt]: 	Test 800/1152. loss: 1.349, 0.1957 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 15:29:11 visual_prompt]: 	Test 900/1152. loss: 1.742, 0.1849 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 15:29:30 visual_prompt]: 	Test 1000/1152. loss: 1.561, 0.1973 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 15:29:50 visual_prompt]: 	Test 1100/1152. loss: 1.643, 0.2120 s / batch. (data: 3.01e-02)max mem: 17.22454 GB 
[09/18 15:30:04 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1934, average loss: 1.5558
[09/18 15:30:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.42	top5: 98.36	
[09/18 15:30:04 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/18 15:30:17 visual_prompt]: Epoch 36 / 100: avg data time: 2.29e-01, avg batch time: 0.6306, average train loss: 1.2527
[09/18 15:30:24 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1424, average loss: 0.9233
[09/18 15:30:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.50	top5: 100.00	
[09/18 15:30:47 visual_prompt]: 	Test 100/1152. loss: 1.097, 0.1822 s / batch. (data: 8.51e-05)max mem: 17.22454 GB 
[09/18 15:31:06 visual_prompt]: 	Test 200/1152. loss: 1.207, 0.1822 s / batch. (data: 8.73e-05)max mem: 17.22454 GB 
[09/18 15:31:26 visual_prompt]: 	Test 300/1152. loss: 1.323, 0.1838 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 15:31:45 visual_prompt]: 	Test 400/1152. loss: 1.114, 0.1833 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 15:32:05 visual_prompt]: 	Test 500/1152. loss: 1.214, 0.1979 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 15:32:24 visual_prompt]: 	Test 600/1152. loss: 1.244, 0.1955 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:32:44 visual_prompt]: 	Test 700/1152. loss: 1.138, 0.1829 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 15:33:03 visual_prompt]: 	Test 800/1152. loss: 1.193, 0.1824 s / batch. (data: 8.73e-05)max mem: 17.22454 GB 
[09/18 15:33:22 visual_prompt]: 	Test 900/1152. loss: 1.362, 0.1988 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:33:42 visual_prompt]: 	Test 1000/1152. loss: 1.136, 0.2062 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:34:01 visual_prompt]: 	Test 1100/1152. loss: 1.249, 0.1982 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 15:34:15 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1935, average loss: 1.1928
[09/18 15:34:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.71	top5: 100.00	
[09/18 15:34:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/18 15:34:29 visual_prompt]: Epoch 37 / 100: avg data time: 2.30e-01, avg batch time: 0.6291, average train loss: 1.2763
[09/18 15:34:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1432, average loss: 1.1269
[09/18 15:34:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.00	top5: 100.00	
[09/18 15:34:59 visual_prompt]: 	Test 100/1152. loss: 1.389, 0.1824 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 15:35:18 visual_prompt]: 	Test 200/1152. loss: 1.584, 0.1956 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 15:35:37 visual_prompt]: 	Test 300/1152. loss: 1.435, 0.1831 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:35:57 visual_prompt]: 	Test 400/1152. loss: 1.301, 0.1828 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 15:36:16 visual_prompt]: 	Test 500/1152. loss: 1.412, 0.1964 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 15:36:36 visual_prompt]: 	Test 600/1152. loss: 1.456, 0.2066 s / batch. (data: 2.46e-02)max mem: 17.22454 GB 
[09/18 15:36:55 visual_prompt]: 	Test 700/1152. loss: 1.074, 0.1830 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 15:37:14 visual_prompt]: 	Test 800/1152. loss: 1.154, 0.1831 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 15:37:34 visual_prompt]: 	Test 900/1152. loss: 1.624, 0.2031 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:37:54 visual_prompt]: 	Test 1000/1152. loss: 1.537, 0.1829 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 15:38:13 visual_prompt]: 	Test 1100/1152. loss: 1.250, 0.1853 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 15:38:27 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1934, average loss: 1.3288
[09/18 15:38:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 42.80	top5: 99.21	
[09/18 15:38:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/18 15:38:40 visual_prompt]: Epoch 38 / 100: avg data time: 2.33e-01, avg batch time: 0.6333, average train loss: 0.9652
[09/18 15:38:48 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1421, average loss: 0.6871
[09/18 15:38:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.50	top5: 100.00	
[09/18 15:39:10 visual_prompt]: 	Test 100/1152. loss: 0.805, 0.1960 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 15:39:30 visual_prompt]: 	Test 200/1152. loss: 0.992, 0.1826 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 15:39:49 visual_prompt]: 	Test 300/1152. loss: 1.050, 0.1836 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 15:40:09 visual_prompt]: 	Test 400/1152. loss: 0.947, 0.2056 s / batch. (data: 1.70e-02)max mem: 17.22454 GB 
[09/18 15:40:28 visual_prompt]: 	Test 500/1152. loss: 0.868, 0.2040 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 15:40:48 visual_prompt]: 	Test 600/1152. loss: 1.105, 0.1832 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:41:07 visual_prompt]: 	Test 700/1152. loss: 0.840, 0.1825 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 15:41:27 visual_prompt]: 	Test 800/1152. loss: 0.940, 0.1828 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 15:41:46 visual_prompt]: 	Test 900/1152. loss: 1.129, 0.1826 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 15:42:05 visual_prompt]: 	Test 1000/1152. loss: 0.946, 0.1919 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 15:42:25 visual_prompt]: 	Test 1100/1152. loss: 0.950, 0.1952 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 15:42:39 visual_prompt]: Inference (test):avg data time: 8.64e-03, avg batch time: 0.1938, average loss: 0.9593
[09/18 15:42:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.90	top5: 100.00	
[09/18 15:42:39 visual_prompt]: Best epoch 38: best metric: 0.725
[09/18 15:42:39 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/18 15:42:53 visual_prompt]: Epoch 39 / 100: avg data time: 2.29e-01, avg batch time: 0.6314, average train loss: 0.8857
[09/18 15:43:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1443, average loss: 0.7887
[09/18 15:43:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 62.50	top5: 100.00	
[09/18 15:43:22 visual_prompt]: 	Test 100/1152. loss: 0.964, 0.1825 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 15:43:42 visual_prompt]: 	Test 200/1152. loss: 0.981, 0.1905 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:44:01 visual_prompt]: 	Test 300/1152. loss: 0.984, 0.1964 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 15:44:20 visual_prompt]: 	Test 400/1152. loss: 0.858, 0.2000 s / batch. (data: 1.76e-02)max mem: 17.22454 GB 
[09/18 15:44:40 visual_prompt]: 	Test 500/1152. loss: 0.747, 0.1830 s / batch. (data: 9.11e-05)max mem: 17.22454 GB 
[09/18 15:44:59 visual_prompt]: 	Test 600/1152. loss: 0.857, 0.1952 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 15:45:19 visual_prompt]: 	Test 700/1152. loss: 0.906, 0.1977 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 15:45:38 visual_prompt]: 	Test 800/1152. loss: 0.815, 0.1833 s / batch. (data: 9.54e-05)max mem: 17.22454 GB 
[09/18 15:45:57 visual_prompt]: 	Test 900/1152. loss: 1.005, 0.1830 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:46:17 visual_prompt]: 	Test 1000/1152. loss: 1.031, 0.1984 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 15:46:36 visual_prompt]: 	Test 1100/1152. loss: 0.764, 0.1830 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 15:46:51 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1931, average loss: 0.9233
[09/18 15:46:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 58.42	top5: 100.00	
[09/18 15:46:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/18 15:47:04 visual_prompt]: Epoch 40 / 100: avg data time: 2.26e-01, avg batch time: 0.6277, average train loss: 0.9680
[09/18 15:47:11 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1450, average loss: 1.0322
[09/18 15:47:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 54.50	top5: 100.00	
[09/18 15:47:34 visual_prompt]: 	Test 100/1152. loss: 1.199, 0.1827 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 15:47:53 visual_prompt]: 	Test 200/1152. loss: 1.249, 0.2061 s / batch. (data: 2.45e-02)max mem: 17.22454 GB 
[09/18 15:48:12 visual_prompt]: 	Test 300/1152. loss: 1.449, 0.1824 s / batch. (data: 9.54e-05)max mem: 17.22454 GB 
[09/18 15:48:32 visual_prompt]: 	Test 400/1152. loss: 0.939, 0.1979 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 15:48:51 visual_prompt]: 	Test 500/1152. loss: 1.070, 0.2033 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 15:49:11 visual_prompt]: 	Test 600/1152. loss: 1.098, 0.2145 s / batch. (data: 3.29e-02)max mem: 17.22454 GB 
[09/18 15:49:30 visual_prompt]: 	Test 700/1152. loss: 0.922, 0.1954 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 15:49:50 visual_prompt]: 	Test 800/1152. loss: 0.921, 0.1946 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 15:50:09 visual_prompt]: 	Test 900/1152. loss: 1.166, 0.1824 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 15:50:29 visual_prompt]: 	Test 1000/1152. loss: 1.144, 0.2075 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/18 15:50:48 visual_prompt]: 	Test 1100/1152. loss: 1.046, 0.2153 s / batch. (data: 3.36e-02)max mem: 17.22454 GB 
[09/18 15:51:03 visual_prompt]: Inference (test):avg data time: 8.90e-03, avg batch time: 0.1939, average loss: 1.1371
[09/18 15:51:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 54.37	top5: 99.99	
[09/18 15:51:03 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/18 15:51:16 visual_prompt]: Epoch 41 / 100: avg data time: 2.33e-01, avg batch time: 0.6332, average train loss: 0.9655
[09/18 15:51:23 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1421, average loss: 0.9060
[09/18 15:51:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.50	top5: 100.00	
[09/18 15:51:46 visual_prompt]: 	Test 100/1152. loss: 1.121, 0.1828 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 15:52:05 visual_prompt]: 	Test 200/1152. loss: 1.233, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 15:52:25 visual_prompt]: 	Test 300/1152. loss: 1.121, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 15:52:44 visual_prompt]: 	Test 400/1152. loss: 1.089, 0.1833 s / batch. (data: 9.16e-05)max mem: 17.22454 GB 
[09/18 15:53:04 visual_prompt]: 	Test 500/1152. loss: 0.895, 0.1832 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 15:53:23 visual_prompt]: 	Test 600/1152. loss: 1.063, 0.1947 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 15:53:43 visual_prompt]: 	Test 700/1152. loss: 1.193, 0.1881 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 15:54:02 visual_prompt]: 	Test 800/1152. loss: 0.900, 0.1969 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 15:54:21 visual_prompt]: 	Test 900/1152. loss: 1.294, 0.1837 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 15:54:41 visual_prompt]: 	Test 1000/1152. loss: 1.475, 0.1946 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 15:55:00 visual_prompt]: 	Test 1100/1152. loss: 0.866, 0.2241 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 15:55:14 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1933, average loss: 1.0850
[09/18 15:55:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 58.39	top5: 100.00	
[09/18 15:55:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/18 15:55:28 visual_prompt]: Epoch 42 / 100: avg data time: 2.36e-01, avg batch time: 0.6364, average train loss: 1.0774
[09/18 15:55:35 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1422, average loss: 1.2471
[09/18 15:55:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 48.00	top5: 100.00	
[09/18 15:55:58 visual_prompt]: 	Test 100/1152. loss: 1.041, 0.1832 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 15:56:17 visual_prompt]: 	Test 200/1152. loss: 1.115, 0.1829 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 15:56:36 visual_prompt]: 	Test 300/1152. loss: 1.311, 0.1828 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 15:56:56 visual_prompt]: 	Test 400/1152. loss: 1.187, 0.1823 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 15:57:15 visual_prompt]: 	Test 500/1152. loss: 1.269, 0.1971 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 15:57:35 visual_prompt]: 	Test 600/1152. loss: 1.279, 0.1826 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/18 15:57:54 visual_prompt]: 	Test 700/1152. loss: 1.135, 0.1857 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:58:14 visual_prompt]: 	Test 800/1152. loss: 1.218, 0.1920 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/18 15:58:33 visual_prompt]: 	Test 900/1152. loss: 1.092, 0.1918 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 15:58:52 visual_prompt]: 	Test 1000/1152. loss: 1.083, 0.2001 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 15:59:12 visual_prompt]: 	Test 1100/1152. loss: 1.140, 0.1965 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 15:59:26 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1934, average loss: 1.2201
[09/18 15:59:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 46.86	top5: 100.00	
[09/18 15:59:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/18 15:59:39 visual_prompt]: Epoch 43 / 100: avg data time: 2.20e-01, avg batch time: 0.6211, average train loss: 1.1876
[09/18 15:59:46 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1422, average loss: 1.0974
[09/18 15:59:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.00	top5: 99.00	
[09/18 16:00:09 visual_prompt]: 	Test 100/1152. loss: 1.110, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 16:00:28 visual_prompt]: 	Test 200/1152. loss: 1.305, 0.1824 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 16:00:48 visual_prompt]: 	Test 300/1152. loss: 1.303, 0.1824 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 16:01:07 visual_prompt]: 	Test 400/1152. loss: 1.191, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 16:01:27 visual_prompt]: 	Test 500/1152. loss: 1.147, 0.1972 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 16:01:46 visual_prompt]: 	Test 600/1152. loss: 1.239, 0.2084 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/18 16:02:06 visual_prompt]: 	Test 700/1152. loss: 0.963, 0.1984 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 16:02:25 visual_prompt]: 	Test 800/1152. loss: 1.368, 0.1980 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 16:02:44 visual_prompt]: 	Test 900/1152. loss: 1.487, 0.2014 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/18 16:03:04 visual_prompt]: 	Test 1000/1152. loss: 1.317, 0.1985 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 16:03:23 visual_prompt]: 	Test 1100/1152. loss: 1.354, 0.1827 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 16:03:37 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1936, average loss: 1.2918
[09/18 16:03:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 47.74	top5: 97.56	
[09/18 16:03:38 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/18 16:03:51 visual_prompt]: Epoch 44 / 100: avg data time: 2.23e-01, avg batch time: 0.6260, average train loss: 0.8815
[09/18 16:03:58 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1422, average loss: 1.2590
[09/18 16:03:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 53.00	top5: 100.00	
[09/18 16:04:20 visual_prompt]: 	Test 100/1152. loss: 1.610, 0.1823 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 16:04:40 visual_prompt]: 	Test 200/1152. loss: 1.586, 0.1827 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:04:59 visual_prompt]: 	Test 300/1152. loss: 1.352, 0.1961 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 16:05:19 visual_prompt]: 	Test 400/1152. loss: 1.047, 0.1891 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 16:05:38 visual_prompt]: 	Test 500/1152. loss: 1.408, 0.1831 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 16:05:57 visual_prompt]: 	Test 600/1152. loss: 1.630, 0.1876 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 16:06:17 visual_prompt]: 	Test 700/1152. loss: 1.195, 0.1995 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 16:06:37 visual_prompt]: 	Test 800/1152. loss: 1.159, 0.1934 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/18 16:06:56 visual_prompt]: 	Test 900/1152. loss: 1.810, 0.2199 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/18 16:07:16 visual_prompt]: 	Test 1000/1152. loss: 1.422, 0.1829 s / batch. (data: 3.00e-05)max mem: 17.22454 GB 
[09/18 16:07:35 visual_prompt]: 	Test 1100/1152. loss: 1.320, 0.1957 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 16:07:49 visual_prompt]: Inference (test):avg data time: 8.77e-03, avg batch time: 0.1940, average loss: 1.3913
[09/18 16:07:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.01	top5: 99.79	
[09/18 16:07:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/18 16:08:02 visual_prompt]: Epoch 45 / 100: avg data time: 2.27e-01, avg batch time: 0.6296, average train loss: 1.0286
[09/18 16:08:09 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1423, average loss: 1.0541
[09/18 16:08:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.00	top5: 100.00	
[09/18 16:08:33 visual_prompt]: 	Test 100/1152. loss: 1.339, 0.1821 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/18 16:08:52 visual_prompt]: 	Test 200/1152. loss: 1.587, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:09:11 visual_prompt]: 	Test 300/1152. loss: 1.714, 0.1902 s / batch. (data: 8.00e-03)max mem: 17.22454 GB 
[09/18 16:09:30 visual_prompt]: 	Test 400/1152. loss: 1.192, 0.2051 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 16:09:50 visual_prompt]: 	Test 500/1152. loss: 1.004, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 16:10:09 visual_prompt]: 	Test 600/1152. loss: 1.575, 0.1831 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 16:10:28 visual_prompt]: 	Test 700/1152. loss: 1.488, 0.1845 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 16:10:48 visual_prompt]: 	Test 800/1152. loss: 1.541, 0.2074 s / batch. (data: 2.51e-02)max mem: 17.22454 GB 
[09/18 16:11:07 visual_prompt]: 	Test 900/1152. loss: 1.867, 0.1832 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 16:11:27 visual_prompt]: 	Test 1000/1152. loss: 1.707, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 16:11:46 visual_prompt]: 	Test 1100/1152. loss: 1.579, 0.1963 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 16:12:01 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1934, average loss: 1.4690
[09/18 16:12:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 54.95	top5: 99.98	
[09/18 16:12:01 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/18 16:12:14 visual_prompt]: Epoch 46 / 100: avg data time: 2.24e-01, avg batch time: 0.6262, average train loss: 0.9512
[09/18 16:12:21 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1434, average loss: 1.0163
[09/18 16:12:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.50	top5: 100.00	
[09/18 16:12:44 visual_prompt]: 	Test 100/1152. loss: 1.091, 0.1829 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 16:13:03 visual_prompt]: 	Test 200/1152. loss: 1.284, 0.1985 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 16:13:22 visual_prompt]: 	Test 300/1152. loss: 1.126, 0.1968 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 16:13:42 visual_prompt]: 	Test 400/1152. loss: 1.157, 0.1856 s / batch. (data: 3.29e-05)max mem: 17.22454 GB 
[09/18 16:14:01 visual_prompt]: 	Test 500/1152. loss: 1.081, 0.2015 s / batch. (data: 1.70e-02)max mem: 17.22454 GB 
[09/18 16:14:21 visual_prompt]: 	Test 600/1152. loss: 1.081, 0.1866 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 16:14:40 visual_prompt]: 	Test 700/1152. loss: 1.158, 0.1829 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 16:14:59 visual_prompt]: 	Test 800/1152. loss: 1.060, 0.2210 s / batch. (data: 2.44e-02)max mem: 17.22454 GB 
[09/18 16:15:19 visual_prompt]: 	Test 900/1152. loss: 1.124, 0.1840 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 16:15:38 visual_prompt]: 	Test 1000/1152. loss: 1.044, 0.1960 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 16:15:57 visual_prompt]: 	Test 1100/1152. loss: 1.063, 0.1836 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:16:11 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1928, average loss: 1.1661
[09/18 16:16:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 48.04	top5: 99.86	
[09/18 16:16:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/18 16:16:25 visual_prompt]: Epoch 47 / 100: avg data time: 2.19e-01, avg batch time: 0.6240, average train loss: 0.8782
[09/18 16:16:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1469, average loss: 0.9412
[09/18 16:16:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.00	top5: 100.00	
[09/18 16:16:55 visual_prompt]: 	Test 100/1152. loss: 1.096, 0.1903 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 16:17:14 visual_prompt]: 	Test 200/1152. loss: 1.346, 0.1826 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 16:17:34 visual_prompt]: 	Test 300/1152. loss: 1.433, 0.1968 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 16:17:53 visual_prompt]: 	Test 400/1152. loss: 1.305, 0.1839 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 16:18:12 visual_prompt]: 	Test 500/1152. loss: 1.037, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 16:18:32 visual_prompt]: 	Test 600/1152. loss: 1.287, 0.1917 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 16:18:51 visual_prompt]: 	Test 700/1152. loss: 1.046, 0.2000 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 16:19:11 visual_prompt]: 	Test 800/1152. loss: 1.326, 0.2080 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/18 16:19:30 visual_prompt]: 	Test 900/1152. loss: 1.975, 0.2095 s / batch. (data: 2.76e-02)max mem: 17.22454 GB 
[09/18 16:19:49 visual_prompt]: 	Test 1000/1152. loss: 1.629, 0.1966 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 16:20:09 visual_prompt]: 	Test 1100/1152. loss: 1.433, 0.2058 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 16:20:23 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1932, average loss: 1.3742
[09/18 16:20:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 54.93	top5: 99.97	
[09/18 16:20:23 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/18 16:20:36 visual_prompt]: Epoch 48 / 100: avg data time: 2.34e-01, avg batch time: 0.6357, average train loss: 0.9852
[09/18 16:20:43 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1425, average loss: 1.0276
[09/18 16:20:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 64.50	top5: 100.00	
[09/18 16:21:06 visual_prompt]: 	Test 100/1152. loss: 1.209, 0.1959 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 16:21:25 visual_prompt]: 	Test 200/1152. loss: 0.925, 0.1832 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 16:21:45 visual_prompt]: 	Test 300/1152. loss: 1.337, 0.1825 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 16:22:04 visual_prompt]: 	Test 400/1152. loss: 1.013, 0.2213 s / batch. (data: 3.93e-02)max mem: 17.22454 GB 
[09/18 16:22:24 visual_prompt]: 	Test 500/1152. loss: 1.026, 0.2064 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 16:22:43 visual_prompt]: 	Test 600/1152. loss: 1.123, 0.1957 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 16:23:02 visual_prompt]: 	Test 700/1152. loss: 1.210, 0.2252 s / batch. (data: 3.80e-02)max mem: 17.22454 GB 
[09/18 16:23:22 visual_prompt]: 	Test 800/1152. loss: 1.021, 0.1824 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:23:41 visual_prompt]: 	Test 900/1152. loss: 1.236, 0.1826 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 16:24:01 visual_prompt]: 	Test 1000/1152. loss: 1.219, 0.1920 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 16:24:20 visual_prompt]: 	Test 1100/1152. loss: 0.875, 0.1930 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 16:24:34 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1933, average loss: 1.1248
[09/18 16:24:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.46	top5: 99.68	
[09/18 16:24:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/18 16:24:48 visual_prompt]: Epoch 49 / 100: avg data time: 2.26e-01, avg batch time: 0.6271, average train loss: 1.0606
[09/18 16:24:55 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1421, average loss: 1.2365
[09/18 16:24:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.50	top5: 100.00	
[09/18 16:25:18 visual_prompt]: 	Test 100/1152. loss: 1.445, 0.1825 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/18 16:25:37 visual_prompt]: 	Test 200/1152. loss: 1.307, 0.2100 s / batch. (data: 2.80e-02)max mem: 17.22454 GB 
[09/18 16:25:56 visual_prompt]: 	Test 300/1152. loss: 1.625, 0.1961 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 16:26:16 visual_prompt]: 	Test 400/1152. loss: 1.413, 0.1934 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 16:26:35 visual_prompt]: 	Test 500/1152. loss: 1.217, 0.1973 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 16:26:55 visual_prompt]: 	Test 600/1152. loss: 1.221, 0.1826 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 16:27:14 visual_prompt]: 	Test 700/1152. loss: 1.203, 0.1872 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 16:27:33 visual_prompt]: 	Test 800/1152. loss: 1.209, 0.1827 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 16:27:53 visual_prompt]: 	Test 900/1152. loss: 1.334, 0.2088 s / batch. (data: 2.65e-02)max mem: 17.22454 GB 
[09/18 16:28:12 visual_prompt]: 	Test 1000/1152. loss: 1.491, 0.1834 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:28:32 visual_prompt]: 	Test 1100/1152. loss: 1.194, 0.1898 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 16:28:46 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1935, average loss: 1.4009
[09/18 16:28:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 46.33	top5: 99.93	
[09/18 16:28:46 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/18 16:28:59 visual_prompt]: Epoch 50 / 100: avg data time: 2.23e-01, avg batch time: 0.6265, average train loss: 0.9790
[09/18 16:29:06 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1428, average loss: 0.5367
[09/18 16:29:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.00	top5: 100.00	
[09/18 16:29:29 visual_prompt]: 	Test 100/1152. loss: 0.802, 0.2097 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/18 16:29:48 visual_prompt]: 	Test 200/1152. loss: 0.784, 0.1968 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 16:30:08 visual_prompt]: 	Test 300/1152. loss: 0.946, 0.2286 s / batch. (data: 4.21e-02)max mem: 17.22454 GB 
[09/18 16:30:27 visual_prompt]: 	Test 400/1152. loss: 0.638, 0.2014 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 16:30:47 visual_prompt]: 	Test 500/1152. loss: 0.592, 0.1833 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 16:31:06 visual_prompt]: 	Test 600/1152. loss: 0.789, 0.2161 s / batch. (data: 2.01e-02)max mem: 17.22454 GB 
[09/18 16:31:26 visual_prompt]: 	Test 700/1152. loss: 0.665, 0.1827 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 16:31:45 visual_prompt]: 	Test 800/1152. loss: 0.687, 0.1827 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 16:32:05 visual_prompt]: 	Test 900/1152. loss: 0.890, 0.2035 s / batch. (data: 1.63e-02)max mem: 17.22454 GB 
[09/18 16:32:24 visual_prompt]: 	Test 1000/1152. loss: 0.837, 0.1876 s / batch. (data: 9.01e-05)max mem: 17.22454 GB 
[09/18 16:32:44 visual_prompt]: 	Test 1100/1152. loss: 0.544, 0.1965 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 16:32:58 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1937, average loss: 0.7420
[09/18 16:32:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.37	top5: 100.00	
[09/18 16:32:58 visual_prompt]: Best epoch 50: best metric: 0.780
[09/18 16:32:58 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/18 16:33:11 visual_prompt]: Epoch 51 / 100: avg data time: 2.26e-01, avg batch time: 0.6284, average train loss: 0.7344
[09/18 16:33:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1422, average loss: 0.6342
[09/18 16:33:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.50	top5: 100.00	
[09/18 16:33:41 visual_prompt]: 	Test 100/1152. loss: 0.743, 0.1918 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 16:34:00 visual_prompt]: 	Test 200/1152. loss: 0.754, 0.1827 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 16:34:19 visual_prompt]: 	Test 300/1152. loss: 0.902, 0.1831 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 16:34:39 visual_prompt]: 	Test 400/1152. loss: 0.713, 0.1820 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 16:34:58 visual_prompt]: 	Test 500/1152. loss: 0.805, 0.1970 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 16:35:18 visual_prompt]: 	Test 600/1152. loss: 0.986, 0.1826 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 16:35:37 visual_prompt]: 	Test 700/1152. loss: 0.646, 0.2081 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/18 16:35:57 visual_prompt]: 	Test 800/1152. loss: 0.779, 0.1826 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:36:16 visual_prompt]: 	Test 900/1152. loss: 0.948, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 16:36:35 visual_prompt]: 	Test 1000/1152. loss: 0.933, 0.2028 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 16:36:55 visual_prompt]: 	Test 1100/1152. loss: 0.749, 0.2084 s / batch. (data: 2.63e-02)max mem: 17.22454 GB 
[09/18 16:37:09 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1933, average loss: 0.8186
[09/18 16:37:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.66	top5: 100.00	
[09/18 16:37:09 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/18 16:37:22 visual_prompt]: Epoch 52 / 100: avg data time: 2.35e-01, avg batch time: 0.6368, average train loss: 0.6720
[09/18 16:37:29 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1423, average loss: 0.7190
[09/18 16:37:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.50	top5: 100.00	
[09/18 16:37:52 visual_prompt]: 	Test 100/1152. loss: 0.867, 0.1950 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 16:38:11 visual_prompt]: 	Test 200/1152. loss: 0.922, 0.1960 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 16:38:31 visual_prompt]: 	Test 300/1152. loss: 0.949, 0.1828 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 16:38:50 visual_prompt]: 	Test 400/1152. loss: 1.009, 0.1826 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 16:39:10 visual_prompt]: 	Test 500/1152. loss: 0.869, 0.1827 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:39:29 visual_prompt]: 	Test 600/1152. loss: 0.896, 0.2090 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 16:39:49 visual_prompt]: 	Test 700/1152. loss: 1.013, 0.2109 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 16:40:08 visual_prompt]: 	Test 800/1152. loss: 0.797, 0.1889 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 16:40:28 visual_prompt]: 	Test 900/1152. loss: 0.980, 0.1954 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 16:40:47 visual_prompt]: 	Test 1000/1152. loss: 1.005, 0.1967 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 16:41:07 visual_prompt]: 	Test 1100/1152. loss: 0.988, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:41:21 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1937, average loss: 0.9924
[09/18 16:41:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.98	top5: 99.99	
[09/18 16:41:21 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/18 16:41:34 visual_prompt]: Epoch 53 / 100: avg data time: 2.26e-01, avg batch time: 0.6288, average train loss: 0.7345
[09/18 16:41:41 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1423, average loss: 0.9260
[09/18 16:41:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.50	top5: 100.00	
[09/18 16:42:04 visual_prompt]: 	Test 100/1152. loss: 1.237, 0.1828 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:42:23 visual_prompt]: 	Test 200/1152. loss: 0.994, 0.2084 s / batch. (data: 2.69e-02)max mem: 17.22454 GB 
[09/18 16:42:42 visual_prompt]: 	Test 300/1152. loss: 1.302, 0.2020 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/18 16:43:02 visual_prompt]: 	Test 400/1152. loss: 0.706, 0.2222 s / batch. (data: 4.02e-02)max mem: 17.22454 GB 
[09/18 16:43:21 visual_prompt]: 	Test 500/1152. loss: 1.155, 0.2079 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/18 16:43:41 visual_prompt]: 	Test 600/1152. loss: 1.357, 0.1947 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 16:44:01 visual_prompt]: 	Test 700/1152. loss: 1.056, 0.1961 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 16:44:20 visual_prompt]: 	Test 800/1152. loss: 0.919, 0.1940 s / batch. (data: 1.21e-02)max mem: 17.22454 GB 
[09/18 16:44:40 visual_prompt]: 	Test 900/1152. loss: 1.305, 0.1830 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:44:59 visual_prompt]: 	Test 1000/1152. loss: 1.031, 0.1946 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 16:45:18 visual_prompt]: 	Test 1100/1152. loss: 0.934, 0.1880 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:45:33 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1936, average loss: 1.0830
[09/18 16:45:33 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.70	top5: 100.00	
[09/18 16:45:33 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/18 16:45:46 visual_prompt]: Epoch 54 / 100: avg data time: 2.23e-01, avg batch time: 0.6247, average train loss: 0.8093
[09/18 16:45:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1420, average loss: 0.6818
[09/18 16:45:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/18 16:46:16 visual_prompt]: 	Test 100/1152. loss: 0.859, 0.1834 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 16:46:35 visual_prompt]: 	Test 200/1152. loss: 0.758, 0.1843 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 16:46:54 visual_prompt]: 	Test 300/1152. loss: 0.919, 0.1870 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 16:47:14 visual_prompt]: 	Test 400/1152. loss: 0.912, 0.1823 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:47:33 visual_prompt]: 	Test 500/1152. loss: 0.887, 0.2087 s / batch. (data: 2.32e-02)max mem: 17.22454 GB 
[09/18 16:47:53 visual_prompt]: 	Test 600/1152. loss: 1.065, 0.2079 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/18 16:48:13 visual_prompt]: 	Test 700/1152. loss: 0.850, 0.1998 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 16:48:32 visual_prompt]: 	Test 800/1152. loss: 0.713, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 16:48:51 visual_prompt]: 	Test 900/1152. loss: 1.083, 0.1960 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 16:49:10 visual_prompt]: 	Test 1000/1152. loss: 0.928, 0.1831 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 16:49:30 visual_prompt]: 	Test 1100/1152. loss: 0.653, 0.1829 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 16:49:44 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1934, average loss: 0.8895
[09/18 16:49:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.20	top5: 99.99	
[09/18 16:49:44 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/18 16:49:57 visual_prompt]: Epoch 55 / 100: avg data time: 2.21e-01, avg batch time: 0.6254, average train loss: 0.9010
[09/18 16:50:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1423, average loss: 0.5909
[09/18 16:50:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/18 16:50:27 visual_prompt]: 	Test 100/1152. loss: 0.931, 0.2004 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 16:50:47 visual_prompt]: 	Test 200/1152. loss: 0.889, 0.1823 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 16:51:06 visual_prompt]: 	Test 300/1152. loss: 1.033, 0.2074 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/18 16:51:25 visual_prompt]: 	Test 400/1152. loss: 0.705, 0.1846 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 16:51:45 visual_prompt]: 	Test 500/1152. loss: 0.702, 0.1915 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 16:52:04 visual_prompt]: 	Test 600/1152. loss: 0.945, 0.1948 s / batch. (data: 1.21e-02)max mem: 17.22454 GB 
[09/18 16:52:24 visual_prompt]: 	Test 700/1152. loss: 0.672, 0.1829 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:52:43 visual_prompt]: 	Test 800/1152. loss: 0.745, 0.2040 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 16:53:02 visual_prompt]: 	Test 900/1152. loss: 1.055, 0.1832 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:53:22 visual_prompt]: 	Test 1000/1152. loss: 0.837, 0.1828 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 16:53:41 visual_prompt]: 	Test 1100/1152. loss: 0.689, 0.1830 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:53:55 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1933, average loss: 0.8697
[09/18 16:53:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 64.40	top5: 99.83	
[09/18 16:53:55 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/18 16:54:08 visual_prompt]: Epoch 56 / 100: avg data time: 2.24e-01, avg batch time: 0.6284, average train loss: 0.6796
[09/18 16:54:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1422, average loss: 0.5256
[09/18 16:54:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.50	top5: 100.00	
[09/18 16:54:38 visual_prompt]: 	Test 100/1152. loss: 0.666, 0.1830 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 16:54:58 visual_prompt]: 	Test 200/1152. loss: 0.998, 0.1946 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:55:17 visual_prompt]: 	Test 300/1152. loss: 1.063, 0.1963 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 16:55:36 visual_prompt]: 	Test 400/1152. loss: 0.744, 0.1826 s / batch. (data: 9.37e-05)max mem: 17.22454 GB 
[09/18 16:55:56 visual_prompt]: 	Test 500/1152. loss: 0.666, 0.1824 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 16:56:15 visual_prompt]: 	Test 600/1152. loss: 0.981, 0.1983 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 16:56:35 visual_prompt]: 	Test 700/1152. loss: 0.853, 0.1837 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:56:54 visual_prompt]: 	Test 800/1152. loss: 0.620, 0.1980 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/18 16:57:14 visual_prompt]: 	Test 900/1152. loss: 1.088, 0.1962 s / batch. (data: 9.97e-05)max mem: 17.22454 GB 
[09/18 16:57:33 visual_prompt]: 	Test 1000/1152. loss: 0.876, 0.1824 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 16:57:53 visual_prompt]: 	Test 1100/1152. loss: 0.779, 0.1997 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 16:58:07 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1935, average loss: 0.8649
[09/18 16:58:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.30	top5: 100.00	
[09/18 16:58:07 visual_prompt]: Best epoch 56: best metric: 0.795
[09/18 16:58:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/18 16:58:20 visual_prompt]: Epoch 57 / 100: avg data time: 2.28e-01, avg batch time: 0.6327, average train loss: 0.8048
[09/18 16:58:27 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1421, average loss: 0.8638
[09/18 16:58:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.00	top5: 100.00	
[09/18 16:58:50 visual_prompt]: 	Test 100/1152. loss: 1.057, 0.1826 s / batch. (data: 9.30e-05)max mem: 17.22454 GB 
[09/18 16:59:10 visual_prompt]: 	Test 200/1152. loss: 1.003, 0.1966 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 16:59:29 visual_prompt]: 	Test 300/1152. loss: 1.170, 0.1954 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 16:59:48 visual_prompt]: 	Test 400/1152. loss: 0.938, 0.1867 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:00:08 visual_prompt]: 	Test 500/1152. loss: 1.343, 0.1821 s / batch. (data: 9.13e-05)max mem: 17.22454 GB 
[09/18 17:00:27 visual_prompt]: 	Test 600/1152. loss: 1.165, 0.1835 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:00:47 visual_prompt]: 	Test 700/1152. loss: 1.098, 0.2077 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 17:01:06 visual_prompt]: 	Test 800/1152. loss: 0.959, 0.1828 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 17:01:26 visual_prompt]: 	Test 900/1152. loss: 0.970, 0.1982 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 17:01:45 visual_prompt]: 	Test 1000/1152. loss: 1.209, 0.1927 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/18 17:02:04 visual_prompt]: 	Test 1100/1152. loss: 0.882, 0.2405 s / batch. (data: 5.63e-02)max mem: 17.22454 GB 
[09/18 17:02:18 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1934, average loss: 1.0793
[09/18 17:02:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 57.46	top5: 99.94	
[09/18 17:02:19 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/18 17:02:32 visual_prompt]: Epoch 58 / 100: avg data time: 2.26e-01, avg batch time: 0.6266, average train loss: 0.7646
[09/18 17:02:39 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1422, average loss: 0.4962
[09/18 17:02:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 75.50	top5: 100.00	
[09/18 17:03:02 visual_prompt]: 	Test 100/1152. loss: 0.574, 0.1959 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 17:03:21 visual_prompt]: 	Test 200/1152. loss: 0.721, 0.2050 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 17:03:41 visual_prompt]: 	Test 300/1152. loss: 1.181, 0.1830 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 17:04:00 visual_prompt]: 	Test 400/1152. loss: 0.650, 0.1960 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 17:04:20 visual_prompt]: 	Test 500/1152. loss: 0.645, 0.1986 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 17:04:39 visual_prompt]: 	Test 600/1152. loss: 0.871, 0.1955 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 17:04:59 visual_prompt]: 	Test 700/1152. loss: 0.675, 0.1829 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 17:05:18 visual_prompt]: 	Test 800/1152. loss: 0.762, 0.1926 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/18 17:05:38 visual_prompt]: 	Test 900/1152. loss: 1.183, 0.1938 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 17:05:57 visual_prompt]: 	Test 1000/1152. loss: 1.014, 0.1879 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 17:06:16 visual_prompt]: 	Test 1100/1152. loss: 0.654, 0.1866 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:06:30 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1937, average loss: 0.8336
[09/18 17:06:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.75	top5: 100.00	
[09/18 17:06:31 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/18 17:06:44 visual_prompt]: Epoch 59 / 100: avg data time: 2.30e-01, avg batch time: 0.6317, average train loss: 0.6198
[09/18 17:06:51 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1428, average loss: 0.5522
[09/18 17:06:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.50	top5: 100.00	
[09/18 17:07:14 visual_prompt]: 	Test 100/1152. loss: 0.828, 0.1825 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 17:07:33 visual_prompt]: 	Test 200/1152. loss: 0.984, 0.1958 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 17:07:53 visual_prompt]: 	Test 300/1152. loss: 1.084, 0.1835 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 17:08:12 visual_prompt]: 	Test 400/1152. loss: 0.821, 0.1867 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 17:08:31 visual_prompt]: 	Test 500/1152. loss: 0.657, 0.1829 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 17:08:51 visual_prompt]: 	Test 600/1152. loss: 0.988, 0.1935 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/18 17:09:10 visual_prompt]: 	Test 700/1152. loss: 0.758, 0.1918 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 17:09:30 visual_prompt]: 	Test 800/1152. loss: 0.910, 0.2029 s / batch. (data: 2.09e-02)max mem: 17.22454 GB 
[09/18 17:09:49 visual_prompt]: 	Test 900/1152. loss: 1.226, 0.1825 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 17:10:08 visual_prompt]: 	Test 1000/1152. loss: 0.980, 0.1860 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 17:10:28 visual_prompt]: 	Test 1100/1152. loss: 0.917, 0.1926 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/18 17:10:43 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1935, average loss: 0.9742
[09/18 17:10:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.98	top5: 99.94	
[09/18 17:10:43 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/18 17:10:56 visual_prompt]: Epoch 60 / 100: avg data time: 2.33e-01, avg batch time: 0.6338, average train loss: 0.6595
[09/18 17:11:03 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1421, average loss: 0.5016
[09/18 17:11:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/18 17:11:26 visual_prompt]: 	Test 100/1152. loss: 0.806, 0.1827 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:11:46 visual_prompt]: 	Test 200/1152. loss: 0.816, 0.1826 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:12:05 visual_prompt]: 	Test 300/1152. loss: 0.784, 0.1841 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 17:12:24 visual_prompt]: 	Test 400/1152. loss: 0.633, 0.1847 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/18 17:12:44 visual_prompt]: 	Test 500/1152. loss: 0.701, 0.2175 s / batch. (data: 3.22e-02)max mem: 17.22454 GB 
[09/18 17:13:03 visual_prompt]: 	Test 600/1152. loss: 0.889, 0.1829 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 17:13:23 visual_prompt]: 	Test 700/1152. loss: 0.781, 0.1825 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 17:13:42 visual_prompt]: 	Test 800/1152. loss: 0.598, 0.1973 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 17:14:02 visual_prompt]: 	Test 900/1152. loss: 0.850, 0.1996 s / batch. (data: 1.73e-02)max mem: 17.22454 GB 
[09/18 17:14:21 visual_prompt]: 	Test 1000/1152. loss: 0.827, 0.1948 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 17:14:40 visual_prompt]: 	Test 1100/1152. loss: 0.611, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 17:14:55 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1935, average loss: 0.7760
[09/18 17:14:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.65	top5: 100.00	
[09/18 17:14:55 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/18 17:15:08 visual_prompt]: Epoch 61 / 100: avg data time: 2.33e-01, avg batch time: 0.6338, average train loss: 0.6150
[09/18 17:15:15 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1444, average loss: 0.5981
[09/18 17:15:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/18 17:15:38 visual_prompt]: 	Test 100/1152. loss: 0.696, 0.1831 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:15:58 visual_prompt]: 	Test 200/1152. loss: 0.864, 0.1951 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 17:16:17 visual_prompt]: 	Test 300/1152. loss: 1.181, 0.1825 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 17:16:36 visual_prompt]: 	Test 400/1152. loss: 0.571, 0.1825 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 17:16:56 visual_prompt]: 	Test 500/1152. loss: 0.745, 0.2028 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 17:17:15 visual_prompt]: 	Test 600/1152. loss: 1.189, 0.1832 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 17:17:34 visual_prompt]: 	Test 700/1152. loss: 0.824, 0.1828 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:17:54 visual_prompt]: 	Test 800/1152. loss: 0.725, 0.1837 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 17:18:13 visual_prompt]: 	Test 900/1152. loss: 0.855, 0.1831 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:18:33 visual_prompt]: 	Test 1000/1152. loss: 0.868, 0.1828 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 17:18:52 visual_prompt]: 	Test 1100/1152. loss: 0.693, 0.1946 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 17:19:06 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1931, average loss: 0.8565
[09/18 17:19:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.66	top5: 100.00	
[09/18 17:19:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/18 17:19:19 visual_prompt]: Epoch 62 / 100: avg data time: 2.22e-01, avg batch time: 0.6263, average train loss: 0.5311
[09/18 17:19:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1421, average loss: 0.3618
[09/18 17:19:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.50	top5: 100.00	
[09/18 17:19:50 visual_prompt]: 	Test 100/1152. loss: 0.762, 0.1943 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/18 17:20:09 visual_prompt]: 	Test 200/1152. loss: 0.633, 0.1815 s / batch. (data: 8.30e-05)max mem: 17.22454 GB 
[09/18 17:20:28 visual_prompt]: 	Test 300/1152. loss: 0.833, 0.1959 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 17:20:47 visual_prompt]: 	Test 400/1152. loss: 0.569, 0.1825 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 17:21:07 visual_prompt]: 	Test 500/1152. loss: 0.665, 0.1829 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 17:21:27 visual_prompt]: 	Test 600/1152. loss: 0.695, 0.1834 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 17:21:46 visual_prompt]: 	Test 700/1152. loss: 0.665, 0.1956 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 17:22:05 visual_prompt]: 	Test 800/1152. loss: 0.586, 0.2025 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 17:22:25 visual_prompt]: 	Test 900/1152. loss: 0.988, 0.1830 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 17:22:44 visual_prompt]: 	Test 1000/1152. loss: 0.778, 0.1832 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 17:23:04 visual_prompt]: 	Test 1100/1152. loss: 0.509, 0.1821 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 17:23:18 visual_prompt]: Inference (test):avg data time: 7.67e-03, avg batch time: 0.1933, average loss: 0.7292
[09/18 17:23:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.82	top5: 100.00	
[09/18 17:23:18 visual_prompt]: Best epoch 62: best metric: 0.845
[09/18 17:23:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/18 17:23:31 visual_prompt]: Epoch 63 / 100: avg data time: 2.33e-01, avg batch time: 0.6334, average train loss: 0.5458
[09/18 17:23:39 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1476, average loss: 0.6084
[09/18 17:23:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.00	top5: 100.00	
[09/18 17:24:02 visual_prompt]: 	Test 100/1152. loss: 0.875, 0.1822 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:24:21 visual_prompt]: 	Test 200/1152. loss: 0.877, 0.1958 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 17:24:40 visual_prompt]: 	Test 300/1152. loss: 1.014, 0.1949 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 17:25:00 visual_prompt]: 	Test 400/1152. loss: 0.969, 0.2000 s / batch. (data: 9.06e-05)max mem: 17.22454 GB 
[09/18 17:25:19 visual_prompt]: 	Test 500/1152. loss: 0.918, 0.1829 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 17:25:39 visual_prompt]: 	Test 600/1152. loss: 0.985, 0.1947 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 17:25:58 visual_prompt]: 	Test 700/1152. loss: 0.921, 0.1917 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 17:26:17 visual_prompt]: 	Test 800/1152. loss: 0.799, 0.2172 s / batch. (data: 2.06e-02)max mem: 17.22454 GB 
[09/18 17:26:37 visual_prompt]: 	Test 900/1152. loss: 1.314, 0.1868 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 17:26:56 visual_prompt]: 	Test 1000/1152. loss: 0.925, 0.1854 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 17:27:16 visual_prompt]: 	Test 1100/1152. loss: 0.692, 0.1842 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/18 17:27:30 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1934, average loss: 0.9240
[09/18 17:27:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.39	top5: 99.99	
[09/18 17:27:30 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/18 17:27:43 visual_prompt]: Epoch 64 / 100: avg data time: 2.23e-01, avg batch time: 0.6246, average train loss: 0.5205
[09/18 17:27:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1421, average loss: 0.3666
[09/18 17:27:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 86.50	top5: 100.00	
[09/18 17:28:13 visual_prompt]: 	Test 100/1152. loss: 0.727, 0.1828 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 17:28:32 visual_prompt]: 	Test 200/1152. loss: 0.682, 0.1825 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 17:28:52 visual_prompt]: 	Test 300/1152. loss: 0.907, 0.1828 s / batch. (data: 8.89e-05)max mem: 17.22454 GB 
[09/18 17:29:11 visual_prompt]: 	Test 400/1152. loss: 0.482, 0.1834 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 17:29:31 visual_prompt]: 	Test 500/1152. loss: 0.608, 0.1950 s / batch. (data: 9.20e-05)max mem: 17.22454 GB 
[09/18 17:29:50 visual_prompt]: 	Test 600/1152. loss: 0.945, 0.1863 s / batch. (data: 3.70e-05)max mem: 17.22454 GB 
[09/18 17:30:09 visual_prompt]: 	Test 700/1152. loss: 0.763, 0.1988 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 17:30:29 visual_prompt]: 	Test 800/1152. loss: 0.667, 0.1935 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:30:48 visual_prompt]: 	Test 900/1152. loss: 1.000, 0.2046 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:31:08 visual_prompt]: 	Test 1000/1152. loss: 0.659, 0.1987 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:31:27 visual_prompt]: 	Test 1100/1152. loss: 0.653, 0.1949 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 17:31:42 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1935, average loss: 0.7244
[09/18 17:31:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.91	top5: 100.00	
[09/18 17:31:42 visual_prompt]: Best epoch 64: best metric: 0.865
[09/18 17:31:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/18 17:31:55 visual_prompt]: Epoch 65 / 100: avg data time: 2.17e-01, avg batch time: 0.6193, average train loss: 0.3672
[09/18 17:32:02 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1421, average loss: 0.4494
[09/18 17:32:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 83.00	top5: 100.00	
[09/18 17:32:25 visual_prompt]: 	Test 100/1152. loss: 0.890, 0.1852 s / batch. (data: 3.07e-03)max mem: 17.22454 GB 
[09/18 17:32:44 visual_prompt]: 	Test 200/1152. loss: 1.092, 0.1946 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 17:33:04 visual_prompt]: 	Test 300/1152. loss: 1.115, 0.2037 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:33:23 visual_prompt]: 	Test 400/1152. loss: 0.739, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 17:33:42 visual_prompt]: 	Test 500/1152. loss: 0.591, 0.1825 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 17:34:02 visual_prompt]: 	Test 600/1152. loss: 0.962, 0.1975 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 17:34:22 visual_prompt]: 	Test 700/1152. loss: 0.814, 0.1959 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 17:34:41 visual_prompt]: 	Test 800/1152. loss: 0.723, 0.1909 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 17:35:00 visual_prompt]: 	Test 900/1152. loss: 1.501, 0.2017 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 17:35:20 visual_prompt]: 	Test 1000/1152. loss: 1.078, 0.1827 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 17:35:39 visual_prompt]: 	Test 1100/1152. loss: 0.670, 0.1821 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 17:35:54 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1934, average loss: 0.9353
[09/18 17:35:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.37	top5: 100.00	
[09/18 17:35:54 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/18 17:36:07 visual_prompt]: Epoch 66 / 100: avg data time: 2.23e-01, avg batch time: 0.6254, average train loss: 0.5040
[09/18 17:36:14 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1422, average loss: 0.6662
[09/18 17:36:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.00	top5: 100.00	
[09/18 17:36:37 visual_prompt]: 	Test 100/1152. loss: 1.076, 0.2276 s / batch. (data: 4.57e-02)max mem: 17.22454 GB 
[09/18 17:36:56 visual_prompt]: 	Test 200/1152. loss: 0.927, 0.2024 s / batch. (data: 2.08e-02)max mem: 17.22454 GB 
[09/18 17:37:16 visual_prompt]: 	Test 300/1152. loss: 0.944, 0.1834 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 17:37:35 visual_prompt]: 	Test 400/1152. loss: 0.744, 0.1824 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 17:37:54 visual_prompt]: 	Test 500/1152. loss: 0.881, 0.1943 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/18 17:38:14 visual_prompt]: 	Test 600/1152. loss: 1.477, 0.1969 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 17:38:33 visual_prompt]: 	Test 700/1152. loss: 0.976, 0.2005 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/18 17:38:53 visual_prompt]: 	Test 800/1152. loss: 0.784, 0.2016 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 17:39:12 visual_prompt]: 	Test 900/1152. loss: 1.414, 0.2104 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 17:39:32 visual_prompt]: 	Test 1000/1152. loss: 0.913, 0.1859 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:39:51 visual_prompt]: 	Test 1100/1152. loss: 0.739, 0.2119 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:40:06 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1937, average loss: 0.9760
[09/18 17:40:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.04	top5: 99.99	
[09/18 17:40:06 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/18 17:40:19 visual_prompt]: Epoch 67 / 100: avg data time: 2.22e-01, avg batch time: 0.6213, average train loss: 0.4614
[09/18 17:40:26 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1423, average loss: 0.4759
[09/18 17:40:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.00	top5: 100.00	
[09/18 17:40:49 visual_prompt]: 	Test 100/1152. loss: 0.854, 0.2123 s / batch. (data: 3.13e-02)max mem: 17.22454 GB 
[09/18 17:41:08 visual_prompt]: 	Test 200/1152. loss: 0.820, 0.1963 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:41:27 visual_prompt]: 	Test 300/1152. loss: 1.051, 0.1960 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 17:41:46 visual_prompt]: 	Test 400/1152. loss: 0.701, 0.1961 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 17:42:06 visual_prompt]: 	Test 500/1152. loss: 0.719, 0.1930 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 17:42:25 visual_prompt]: 	Test 600/1152. loss: 0.970, 0.1824 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 17:42:45 visual_prompt]: 	Test 700/1152. loss: 1.022, 0.1830 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 17:43:04 visual_prompt]: 	Test 800/1152. loss: 0.707, 0.1830 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 17:43:23 visual_prompt]: 	Test 900/1152. loss: 1.387, 0.2314 s / batch. (data: 4.97e-02)max mem: 17.22454 GB 
[09/18 17:43:43 visual_prompt]: 	Test 1000/1152. loss: 0.838, 0.2081 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/18 17:44:02 visual_prompt]: 	Test 1100/1152. loss: 0.661, 0.1829 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 17:44:17 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1930, average loss: 0.8369
[09/18 17:44:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.00	top5: 100.00	
[09/18 17:44:17 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/18 17:44:30 visual_prompt]: Epoch 68 / 100: avg data time: 2.39e-01, avg batch time: 0.6388, average train loss: 0.4786
[09/18 17:44:37 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1445, average loss: 0.5337
[09/18 17:44:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.00	top5: 100.00	
[09/18 17:45:00 visual_prompt]: 	Test 100/1152. loss: 1.041, 0.1830 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 17:45:19 visual_prompt]: 	Test 200/1152. loss: 0.833, 0.1823 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 17:45:39 visual_prompt]: 	Test 300/1152. loss: 1.128, 0.1965 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 17:45:58 visual_prompt]: 	Test 400/1152. loss: 0.819, 0.1827 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:46:17 visual_prompt]: 	Test 500/1152. loss: 0.854, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 17:46:37 visual_prompt]: 	Test 600/1152. loss: 1.078, 0.2034 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 17:46:56 visual_prompt]: 	Test 700/1152. loss: 0.994, 0.1983 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 17:47:16 visual_prompt]: 	Test 800/1152. loss: 0.632, 0.1824 s / batch. (data: 8.56e-05)max mem: 17.22454 GB 
[09/18 17:47:35 visual_prompt]: 	Test 900/1152. loss: 1.143, 0.1955 s / batch. (data: 9.44e-03)max mem: 17.22454 GB 
[09/18 17:47:55 visual_prompt]: 	Test 1000/1152. loss: 0.775, 0.1953 s / batch. (data: 8.80e-05)max mem: 17.22454 GB 
[09/18 17:48:14 visual_prompt]: 	Test 1100/1152. loss: 0.854, 0.1879 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 17:48:29 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1932, average loss: 0.9363
[09/18 17:48:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.26	top5: 99.93	
[09/18 17:48:29 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/18 17:48:42 visual_prompt]: Epoch 69 / 100: avg data time: 2.34e-01, avg batch time: 0.6332, average train loss: 0.4427
[09/18 17:48:49 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1449, average loss: 0.4068
[09/18 17:48:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 83.00	top5: 100.00	
[09/18 17:49:12 visual_prompt]: 	Test 100/1152. loss: 0.766, 0.1930 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 17:49:32 visual_prompt]: 	Test 200/1152. loss: 0.716, 0.1822 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 17:49:51 visual_prompt]: 	Test 300/1152. loss: 1.014, 0.2076 s / batch. (data: 2.20e-02)max mem: 17.22454 GB 
[09/18 17:50:10 visual_prompt]: 	Test 400/1152. loss: 0.556, 0.1956 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 17:50:30 visual_prompt]: 	Test 500/1152. loss: 0.804, 0.1962 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 17:50:49 visual_prompt]: 	Test 600/1152. loss: 1.036, 0.1830 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 17:51:09 visual_prompt]: 	Test 700/1152. loss: 0.801, 0.2116 s / batch. (data: 2.93e-02)max mem: 17.22454 GB 
[09/18 17:51:28 visual_prompt]: 	Test 800/1152. loss: 0.817, 0.1833 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:51:48 visual_prompt]: 	Test 900/1152. loss: 1.089, 0.1955 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 17:52:07 visual_prompt]: 	Test 1000/1152. loss: 0.834, 0.1833 s / batch. (data: 9.89e-05)max mem: 17.22454 GB 
[09/18 17:52:26 visual_prompt]: 	Test 1100/1152. loss: 0.688, 0.1825 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 17:52:41 visual_prompt]: Inference (test):avg data time: 8.13e-03, avg batch time: 0.1934, average loss: 0.8788
[09/18 17:52:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.47	top5: 100.00	
[09/18 17:52:41 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/18 17:52:54 visual_prompt]: Epoch 70 / 100: avg data time: 2.21e-01, avg batch time: 0.6210, average train loss: 0.5332
[09/18 17:53:01 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1422, average loss: 0.4786
[09/18 17:53:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/18 17:53:24 visual_prompt]: 	Test 100/1152. loss: 0.896, 0.1938 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 17:53:43 visual_prompt]: 	Test 200/1152. loss: 0.637, 0.1980 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 17:54:02 visual_prompt]: 	Test 300/1152. loss: 0.850, 0.1895 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:54:21 visual_prompt]: 	Test 400/1152. loss: 0.547, 0.1834 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 17:54:41 visual_prompt]: 	Test 500/1152. loss: 0.700, 0.1821 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 17:55:00 visual_prompt]: 	Test 600/1152. loss: 1.052, 0.1828 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 17:55:20 visual_prompt]: 	Test 700/1152. loss: 0.804, 0.1833 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 17:55:39 visual_prompt]: 	Test 800/1152. loss: 0.689, 0.2036 s / batch. (data: 2.12e-02)max mem: 17.22454 GB 
[09/18 17:55:59 visual_prompt]: 	Test 900/1152. loss: 1.179, 0.1972 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 17:56:18 visual_prompt]: 	Test 1000/1152. loss: 0.836, 0.2139 s / batch. (data: 1.89e-02)max mem: 17.22454 GB 
[09/18 17:56:38 visual_prompt]: 	Test 1100/1152. loss: 0.630, 0.2096 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 17:56:52 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1932, average loss: 0.7898
[09/18 17:56:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.14	top5: 99.99	
[09/18 17:56:52 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/18 17:57:05 visual_prompt]: Epoch 71 / 100: avg data time: 2.30e-01, avg batch time: 0.6318, average train loss: 0.4381
[09/18 17:57:12 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1431, average loss: 0.4548
[09/18 17:57:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 85.00	top5: 100.00	
[09/18 17:57:35 visual_prompt]: 	Test 100/1152. loss: 0.909, 0.1821 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 17:57:55 visual_prompt]: 	Test 200/1152. loss: 0.513, 0.1968 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 17:58:14 visual_prompt]: 	Test 300/1152. loss: 0.845, 0.1862 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 17:58:33 visual_prompt]: 	Test 400/1152. loss: 0.647, 0.1825 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 17:58:53 visual_prompt]: 	Test 500/1152. loss: 0.753, 0.1978 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:59:12 visual_prompt]: 	Test 600/1152. loss: 0.898, 0.1967 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 17:59:32 visual_prompt]: 	Test 700/1152. loss: 0.923, 0.1983 s / batch. (data: 9.08e-05)max mem: 17.22454 GB 
[09/18 17:59:51 visual_prompt]: 	Test 800/1152. loss: 0.533, 0.2310 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 18:00:11 visual_prompt]: 	Test 900/1152. loss: 1.152, 0.1988 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 18:00:31 visual_prompt]: 	Test 1000/1152. loss: 0.862, 0.2169 s / batch. (data: 3.31e-02)max mem: 17.22454 GB 
[09/18 18:00:50 visual_prompt]: 	Test 1100/1152. loss: 0.765, 0.1898 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 18:01:04 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1939, average loss: 0.8666
[09/18 18:01:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.74	top5: 99.95	
[09/18 18:01:05 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/18 18:01:18 visual_prompt]: Epoch 72 / 100: avg data time: 2.33e-01, avg batch time: 0.6323, average train loss: 0.4253
[09/18 18:01:25 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1422, average loss: 0.3590
[09/18 18:01:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 86.50	top5: 100.00	
[09/18 18:01:48 visual_prompt]: 	Test 100/1152. loss: 0.834, 0.1948 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 18:02:07 visual_prompt]: 	Test 200/1152. loss: 0.756, 0.1825 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 18:02:26 visual_prompt]: 	Test 300/1152. loss: 0.955, 0.1968 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 18:02:46 visual_prompt]: 	Test 400/1152. loss: 0.493, 0.1957 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/18 18:03:05 visual_prompt]: 	Test 500/1152. loss: 0.531, 0.2069 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 18:03:25 visual_prompt]: 	Test 600/1152. loss: 0.888, 0.2262 s / batch. (data: 4.45e-02)max mem: 17.22454 GB 
[09/18 18:03:44 visual_prompt]: 	Test 700/1152. loss: 0.732, 0.1832 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:04:03 visual_prompt]: 	Test 800/1152. loss: 0.859, 0.1964 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 18:04:23 visual_prompt]: 	Test 900/1152. loss: 1.178, 0.1948 s / batch. (data: 9.20e-03)max mem: 17.22454 GB 
[09/18 18:04:42 visual_prompt]: 	Test 1000/1152. loss: 0.794, 0.1956 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 18:05:02 visual_prompt]: 	Test 1100/1152. loss: 0.920, 0.1986 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:05:16 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1936, average loss: 0.8147
[09/18 18:05:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.08	top5: 99.99	
[09/18 18:05:16 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/18 18:05:29 visual_prompt]: Epoch 73 / 100: avg data time: 2.22e-01, avg batch time: 0.6247, average train loss: 0.3970
[09/18 18:05:36 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1432, average loss: 0.2910
[09/18 18:05:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 87.50	top5: 100.00	
[09/18 18:05:59 visual_prompt]: 	Test 100/1152. loss: 0.975, 0.2082 s / batch. (data: 2.66e-02)max mem: 17.22454 GB 
[09/18 18:06:19 visual_prompt]: 	Test 200/1152. loss: 0.744, 0.2064 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/18 18:06:38 visual_prompt]: 	Test 300/1152. loss: 0.951, 0.1955 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 18:06:57 visual_prompt]: 	Test 400/1152. loss: 0.541, 0.1958 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 18:07:17 visual_prompt]: 	Test 500/1152. loss: 0.499, 0.1940 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 18:07:36 visual_prompt]: 	Test 600/1152. loss: 1.069, 0.2260 s / batch. (data: 3.74e-02)max mem: 17.22454 GB 
[09/18 18:07:56 visual_prompt]: 	Test 700/1152. loss: 0.935, 0.1974 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/18 18:08:15 visual_prompt]: 	Test 800/1152. loss: 0.674, 0.1890 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 18:08:35 visual_prompt]: 	Test 900/1152. loss: 1.113, 0.1823 s / batch. (data: 9.68e-05)max mem: 17.22454 GB 
[09/18 18:08:54 visual_prompt]: 	Test 1000/1152. loss: 0.751, 0.1829 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 18:09:13 visual_prompt]: 	Test 1100/1152. loss: 0.689, 0.2229 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/18 18:09:28 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1935, average loss: 0.8348
[09/18 18:09:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.25	top5: 99.99	
[09/18 18:09:28 visual_prompt]: Best epoch 73: best metric: 0.875
[09/18 18:09:28 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/18 18:09:41 visual_prompt]: Epoch 74 / 100: avg data time: 2.29e-01, avg batch time: 0.6280, average train loss: 0.2847
[09/18 18:09:48 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1431, average loss: 0.2948
[09/18 18:09:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 88.00	top5: 100.00	
[09/18 18:10:11 visual_prompt]: 	Test 100/1152. loss: 0.883, 0.1955 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 18:10:30 visual_prompt]: 	Test 200/1152. loss: 0.752, 0.2039 s / batch. (data: 2.23e-02)max mem: 17.22454 GB 
[09/18 18:10:49 visual_prompt]: 	Test 300/1152. loss: 1.048, 0.1829 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 18:11:08 visual_prompt]: 	Test 400/1152. loss: 0.652, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 18:11:28 visual_prompt]: 	Test 500/1152. loss: 0.676, 0.1949 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 18:11:47 visual_prompt]: 	Test 600/1152. loss: 1.007, 0.2090 s / batch. (data: 2.68e-02)max mem: 17.22454 GB 
[09/18 18:12:07 visual_prompt]: 	Test 700/1152. loss: 0.673, 0.1826 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:12:26 visual_prompt]: 	Test 800/1152. loss: 0.643, 0.1826 s / batch. (data: 8.56e-05)max mem: 17.22454 GB 
[09/18 18:12:46 visual_prompt]: 	Test 900/1152. loss: 1.292, 0.1826 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 18:13:05 visual_prompt]: 	Test 1000/1152. loss: 0.850, 0.2012 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 18:13:25 visual_prompt]: 	Test 1100/1152. loss: 0.616, 0.1960 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 18:13:39 visual_prompt]: Inference (test):avg data time: 8.17e-03, avg batch time: 0.1932, average loss: 0.8448
[09/18 18:13:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.32	top5: 99.98	
[09/18 18:13:39 visual_prompt]: Best epoch 74: best metric: 0.880
[09/18 18:13:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/18 18:13:52 visual_prompt]: Epoch 75 / 100: avg data time: 2.25e-01, avg batch time: 0.6274, average train loss: 0.2359
[09/18 18:13:59 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1436, average loss: 0.1464
[09/18 18:13:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 95.00	top5: 100.00	
[09/18 18:14:22 visual_prompt]: 	Test 100/1152. loss: 0.606, 0.1826 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 18:14:41 visual_prompt]: 	Test 200/1152. loss: 0.864, 0.2076 s / batch. (data: 2.60e-02)max mem: 17.22454 GB 
[09/18 18:15:01 visual_prompt]: 	Test 300/1152. loss: 0.991, 0.2073 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/18 18:15:20 visual_prompt]: 	Test 400/1152. loss: 0.587, 0.1838 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 18:15:39 visual_prompt]: 	Test 500/1152. loss: 0.602, 0.1934 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 18:15:59 visual_prompt]: 	Test 600/1152. loss: 0.884, 0.2139 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/18 18:16:18 visual_prompt]: 	Test 700/1152. loss: 0.706, 0.2211 s / batch. (data: 3.70e-02)max mem: 17.22454 GB 
[09/18 18:16:38 visual_prompt]: 	Test 800/1152. loss: 0.504, 0.1965 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 18:16:57 visual_prompt]: 	Test 900/1152. loss: 1.413, 0.2153 s / batch. (data: 2.14e-02)max mem: 17.22454 GB 
[09/18 18:17:16 visual_prompt]: 	Test 1000/1152. loss: 0.699, 0.1822 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 18:17:36 visual_prompt]: 	Test 1100/1152. loss: 0.416, 0.1822 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 18:17:50 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1932, average loss: 0.7880
[09/18 18:17:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 75.90	top5: 99.99	
[09/18 18:17:51 visual_prompt]: Best epoch 75: best metric: 0.950
[09/18 18:17:51 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/18 18:18:04 visual_prompt]: Epoch 76 / 100: avg data time: 2.28e-01, avg batch time: 0.6283, average train loss: 0.2395
[09/18 18:18:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1434, average loss: 0.5010
[09/18 18:18:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.50	top5: 100.00	
[09/18 18:18:34 visual_prompt]: 	Test 100/1152. loss: 1.143, 0.1870 s / batch. (data: 5.19e-03)max mem: 17.22454 GB 
[09/18 18:18:53 visual_prompt]: 	Test 200/1152. loss: 1.097, 0.1969 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 18:19:12 visual_prompt]: 	Test 300/1152. loss: 1.165, 0.1833 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:19:32 visual_prompt]: 	Test 400/1152. loss: 1.075, 0.1971 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 18:19:51 visual_prompt]: 	Test 500/1152. loss: 1.126, 0.1981 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 18:20:10 visual_prompt]: 	Test 600/1152. loss: 1.102, 0.1822 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 18:20:30 visual_prompt]: 	Test 700/1152. loss: 1.211, 0.1968 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 18:20:49 visual_prompt]: 	Test 800/1152. loss: 0.795, 0.1828 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 18:21:09 visual_prompt]: 	Test 900/1152. loss: 1.557, 0.1984 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 18:21:28 visual_prompt]: 	Test 1000/1152. loss: 0.997, 0.1833 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 18:21:48 visual_prompt]: 	Test 1100/1152. loss: 0.806, 0.2264 s / batch. (data: 4.44e-02)max mem: 17.22454 GB 
[09/18 18:22:02 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1936, average loss: 1.1831
[09/18 18:22:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.25	top5: 99.98	
[09/18 18:22:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/18 18:22:15 visual_prompt]: Epoch 77 / 100: avg data time: 2.30e-01, avg batch time: 0.6315, average train loss: 0.3541
[09/18 18:22:23 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1421, average loss: 0.3368
[09/18 18:22:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 87.50	top5: 100.00	
[09/18 18:22:45 visual_prompt]: 	Test 100/1152. loss: 1.078, 0.1960 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 18:23:05 visual_prompt]: 	Test 200/1152. loss: 0.920, 0.2001 s / batch. (data: 1.84e-02)max mem: 17.22454 GB 
[09/18 18:23:24 visual_prompt]: 	Test 300/1152. loss: 1.158, 0.1818 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 18:23:43 visual_prompt]: 	Test 400/1152. loss: 0.721, 0.1826 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 18:24:03 visual_prompt]: 	Test 500/1152. loss: 0.785, 0.2040 s / batch. (data: 2.17e-02)max mem: 17.22454 GB 
[09/18 18:24:22 visual_prompt]: 	Test 600/1152. loss: 1.125, 0.1968 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 18:24:42 visual_prompt]: 	Test 700/1152. loss: 1.087, 0.1830 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 18:25:01 visual_prompt]: 	Test 800/1152. loss: 0.718, 0.1976 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 18:25:21 visual_prompt]: 	Test 900/1152. loss: 1.318, 0.1831 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 18:25:40 visual_prompt]: 	Test 1000/1152. loss: 0.921, 0.1830 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 18:26:00 visual_prompt]: 	Test 1100/1152. loss: 0.636, 0.1971 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 18:26:14 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1935, average loss: 0.9317
[09/18 18:26:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.86	top5: 99.97	
[09/18 18:26:14 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/18 18:26:27 visual_prompt]: Epoch 78 / 100: avg data time: 2.31e-01, avg batch time: 0.6342, average train loss: 0.2525
[09/18 18:26:34 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1421, average loss: 0.1985
[09/18 18:26:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 91.50	top5: 100.00	
[09/18 18:26:58 visual_prompt]: 	Test 100/1152. loss: 1.111, 0.1959 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 18:27:17 visual_prompt]: 	Test 200/1152. loss: 0.892, 0.1958 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 18:27:36 visual_prompt]: 	Test 300/1152. loss: 1.151, 0.1833 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 18:27:55 visual_prompt]: 	Test 400/1152. loss: 0.658, 0.1868 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 18:28:15 visual_prompt]: 	Test 500/1152. loss: 0.680, 0.2195 s / batch. (data: 2.42e-02)max mem: 17.22454 GB 
[09/18 18:28:34 visual_prompt]: 	Test 600/1152. loss: 0.961, 0.2015 s / batch. (data: 1.69e-02)max mem: 17.22454 GB 
[09/18 18:28:53 visual_prompt]: 	Test 700/1152. loss: 0.890, 0.1969 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 18:29:13 visual_prompt]: 	Test 800/1152. loss: 0.517, 0.1832 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:29:32 visual_prompt]: 	Test 900/1152. loss: 1.339, 0.1848 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 18:29:52 visual_prompt]: 	Test 1000/1152. loss: 0.824, 0.1822 s / batch. (data: 4.65e-05)max mem: 17.22454 GB 
[09/18 18:30:11 visual_prompt]: 	Test 1100/1152. loss: 0.542, 0.1832 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:30:26 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1931, average loss: 0.8729
[09/18 18:30:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.63	top5: 99.98	
[09/18 18:30:26 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/18 18:30:39 visual_prompt]: Epoch 79 / 100: avg data time: 2.28e-01, avg batch time: 0.6340, average train loss: 0.2043
[09/18 18:30:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1422, average loss: 0.1677
[09/18 18:30:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 92.00	top5: 100.00	
[09/18 18:31:09 visual_prompt]: 	Test 100/1152. loss: 0.979, 0.1951 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 18:31:28 visual_prompt]: 	Test 200/1152. loss: 0.794, 0.1822 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 18:31:48 visual_prompt]: 	Test 300/1152. loss: 1.160, 0.1828 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 18:32:07 visual_prompt]: 	Test 400/1152. loss: 0.652, 0.1828 s / batch. (data: 9.47e-05)max mem: 17.22454 GB 
[09/18 18:32:27 visual_prompt]: 	Test 500/1152. loss: 0.635, 0.2026 s / batch. (data: 1.75e-02)max mem: 17.22454 GB 
[09/18 18:32:46 visual_prompt]: 	Test 600/1152. loss: 1.059, 0.2251 s / batch. (data: 4.27e-02)max mem: 17.22454 GB 
[09/18 18:33:06 visual_prompt]: 	Test 700/1152. loss: 0.816, 0.1831 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:33:25 visual_prompt]: 	Test 800/1152. loss: 0.758, 0.1984 s / batch. (data: 9.18e-05)max mem: 17.22454 GB 
[09/18 18:33:45 visual_prompt]: 	Test 900/1152. loss: 1.427, 0.1825 s / batch. (data: 8.89e-05)max mem: 17.22454 GB 
[09/18 18:34:04 visual_prompt]: 	Test 1000/1152. loss: 0.781, 0.1968 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:34:24 visual_prompt]: 	Test 1100/1152. loss: 0.701, 0.1985 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 18:34:38 visual_prompt]: Inference (test):avg data time: 8.61e-03, avg batch time: 0.1939, average loss: 0.8720
[09/18 18:34:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.85	top5: 99.98	
[09/18 18:34:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/18 18:34:52 visual_prompt]: Epoch 80 / 100: avg data time: 2.23e-01, avg batch time: 0.6234, average train loss: 0.2599
[09/18 18:34:59 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1423, average loss: 0.1622
[09/18 18:34:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 93.50	top5: 100.00	
[09/18 18:35:22 visual_prompt]: 	Test 100/1152. loss: 0.749, 0.1819 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 18:35:41 visual_prompt]: 	Test 200/1152. loss: 0.779, 0.2143 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 18:36:00 visual_prompt]: 	Test 300/1152. loss: 0.873, 0.1866 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:36:20 visual_prompt]: 	Test 400/1152. loss: 0.475, 0.1825 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 18:36:39 visual_prompt]: 	Test 500/1152. loss: 0.558, 0.2002 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 18:36:59 visual_prompt]: 	Test 600/1152. loss: 0.955, 0.1836 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:37:18 visual_prompt]: 	Test 700/1152. loss: 0.790, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 18:37:38 visual_prompt]: 	Test 800/1152. loss: 0.625, 0.2059 s / batch. (data: 2.33e-02)max mem: 17.22454 GB 
[09/18 18:37:57 visual_prompt]: 	Test 900/1152. loss: 1.319, 0.2158 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 18:38:16 visual_prompt]: 	Test 1000/1152. loss: 0.981, 0.1838 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 18:38:36 visual_prompt]: 	Test 1100/1152. loss: 0.633, 0.2031 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 18:38:50 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1938, average loss: 0.7873
[09/18 18:38:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.04	top5: 99.99	
[09/18 18:38:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/18 18:39:04 visual_prompt]: Epoch 81 / 100: avg data time: 2.27e-01, avg batch time: 0.6297, average train loss: 0.1515
[09/18 18:39:11 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1432, average loss: 0.1988
[09/18 18:39:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 90.00	top5: 100.00	
[09/18 18:39:34 visual_prompt]: 	Test 100/1152. loss: 1.056, 0.1965 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 18:39:53 visual_prompt]: 	Test 200/1152. loss: 0.852, 0.1949 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 18:40:12 visual_prompt]: 	Test 300/1152. loss: 0.986, 0.1980 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 18:40:31 visual_prompt]: 	Test 400/1152. loss: 0.689, 0.1826 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 18:40:50 visual_prompt]: 	Test 500/1152. loss: 0.572, 0.1835 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 18:41:10 visual_prompt]: 	Test 600/1152. loss: 0.966, 0.2015 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 18:41:30 visual_prompt]: 	Test 700/1152. loss: 0.861, 0.2046 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 18:41:49 visual_prompt]: 	Test 800/1152. loss: 0.556, 0.1933 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 18:42:08 visual_prompt]: 	Test 900/1152. loss: 1.259, 0.1955 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 18:42:28 visual_prompt]: 	Test 1000/1152. loss: 0.747, 0.1917 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 18:42:47 visual_prompt]: 	Test 1100/1152. loss: 0.539, 0.1828 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 18:43:02 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1932, average loss: 0.8509
[09/18 18:43:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.60	top5: 100.00	
[09/18 18:43:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/18 18:43:15 visual_prompt]: Epoch 82 / 100: avg data time: 2.32e-01, avg batch time: 0.6328, average train loss: 0.1184
[09/18 18:43:22 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1431, average loss: 0.1127
[09/18 18:43:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 96.00	top5: 100.00	
[09/18 18:43:45 visual_prompt]: 	Test 100/1152. loss: 0.888, 0.1830 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 18:44:04 visual_prompt]: 	Test 200/1152. loss: 0.725, 0.1967 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 18:44:24 visual_prompt]: 	Test 300/1152. loss: 0.900, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 18:44:43 visual_prompt]: 	Test 400/1152. loss: 0.565, 0.2043 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 18:45:03 visual_prompt]: 	Test 500/1152. loss: 0.652, 0.1822 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/18 18:45:22 visual_prompt]: 	Test 600/1152. loss: 1.067, 0.2071 s / batch. (data: 2.52e-02)max mem: 17.22454 GB 
[09/18 18:45:42 visual_prompt]: 	Test 700/1152. loss: 0.936, 0.2105 s / batch. (data: 2.54e-02)max mem: 17.22454 GB 
[09/18 18:46:01 visual_prompt]: 	Test 800/1152. loss: 0.560, 0.1833 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 18:46:21 visual_prompt]: 	Test 900/1152. loss: 1.480, 0.1968 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 18:46:40 visual_prompt]: 	Test 1000/1152. loss: 0.806, 0.1871 s / batch. (data: 5.08e-03)max mem: 17.22454 GB 
[09/18 18:47:00 visual_prompt]: 	Test 1100/1152. loss: 0.620, 0.1976 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 18:47:14 visual_prompt]: Inference (test):avg data time: 8.71e-03, avg batch time: 0.1943, average loss: 0.8256
[09/18 18:47:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.61	top5: 100.00	
[09/18 18:47:15 visual_prompt]: Best epoch 82: best metric: 0.960
[09/18 18:47:15 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/18 18:47:27 visual_prompt]: Epoch 83 / 100: avg data time: 2.15e-01, avg batch time: 0.6174, average train loss: 0.1229
[09/18 18:47:35 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1448, average loss: 0.0862
[09/18 18:47:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 96.50	top5: 100.00	
[09/18 18:47:58 visual_prompt]: 	Test 100/1152. loss: 0.887, 0.1823 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 18:48:17 visual_prompt]: 	Test 200/1152. loss: 0.765, 0.1822 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 18:48:36 visual_prompt]: 	Test 300/1152. loss: 0.996, 0.1817 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:48:55 visual_prompt]: 	Test 400/1152. loss: 0.832, 0.1833 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:49:15 visual_prompt]: 	Test 500/1152. loss: 0.621, 0.1830 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 18:49:34 visual_prompt]: 	Test 600/1152. loss: 1.069, 0.2309 s / batch. (data: 6.42e-03)max mem: 17.22454 GB 
[09/18 18:49:54 visual_prompt]: 	Test 700/1152. loss: 0.913, 0.1831 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 18:50:13 visual_prompt]: 	Test 800/1152. loss: 0.558, 0.1944 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 18:50:33 visual_prompt]: 	Test 900/1152. loss: 1.472, 0.1828 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 18:50:52 visual_prompt]: 	Test 1000/1152. loss: 0.952, 0.1969 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 18:51:11 visual_prompt]: 	Test 1100/1152. loss: 0.753, 0.1828 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 18:51:26 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1931, average loss: 0.9397
[09/18 18:51:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 75.75	top5: 99.99	
[09/18 18:51:26 visual_prompt]: Best epoch 83: best metric: 0.965
[09/18 18:51:26 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/18 18:51:39 visual_prompt]: Epoch 84 / 100: avg data time: 2.33e-01, avg batch time: 0.6328, average train loss: 0.0955
[09/18 18:51:46 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1419, average loss: 0.0645
[09/18 18:51:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 98.00	top5: 100.00	
[09/18 18:52:09 visual_prompt]: 	Test 100/1152. loss: 1.015, 0.1819 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 18:52:28 visual_prompt]: 	Test 200/1152. loss: 0.877, 0.1846 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:52:48 visual_prompt]: 	Test 300/1152. loss: 1.197, 0.1824 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 18:53:07 visual_prompt]: 	Test 400/1152. loss: 0.614, 0.1837 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 18:53:27 visual_prompt]: 	Test 500/1152. loss: 0.632, 0.1827 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:53:46 visual_prompt]: 	Test 600/1152. loss: 1.058, 0.1825 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:54:05 visual_prompt]: 	Test 700/1152. loss: 0.940, 0.1945 s / batch. (data: 9.51e-05)max mem: 17.22454 GB 
[09/18 18:54:25 visual_prompt]: 	Test 800/1152. loss: 0.500, 0.1826 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:54:44 visual_prompt]: 	Test 900/1152. loss: 1.370, 0.2019 s / batch. (data: 1.97e-02)max mem: 17.22454 GB 
[09/18 18:55:04 visual_prompt]: 	Test 1000/1152. loss: 0.940, 0.2243 s / batch. (data: 4.25e-02)max mem: 17.22454 GB 
[09/18 18:55:23 visual_prompt]: 	Test 1100/1152. loss: 0.620, 0.2099 s / batch. (data: 2.77e-02)max mem: 17.22454 GB 
[09/18 18:55:38 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1932, average loss: 0.8710
[09/18 18:55:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.26	top5: 99.99	
[09/18 18:55:38 visual_prompt]: Best epoch 84: best metric: 0.980
[09/18 18:55:38 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/18 18:55:51 visual_prompt]: Epoch 85 / 100: avg data time: 2.26e-01, avg batch time: 0.6259, average train loss: 0.0757
[09/18 18:55:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1432, average loss: 0.1587
[09/18 18:55:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.50	top5: 100.00	
[09/18 18:56:21 visual_prompt]: 	Test 100/1152. loss: 1.234, 0.2074 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/18 18:56:41 visual_prompt]: 	Test 200/1152. loss: 0.945, 0.1847 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 18:57:00 visual_prompt]: 	Test 300/1152. loss: 1.291, 0.2150 s / batch. (data: 2.63e-02)max mem: 17.22454 GB 
[09/18 18:57:19 visual_prompt]: 	Test 400/1152. loss: 0.991, 0.1963 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 18:57:38 visual_prompt]: 	Test 500/1152. loss: 0.646, 0.1955 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 18:57:58 visual_prompt]: 	Test 600/1152. loss: 1.318, 0.1829 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 18:58:17 visual_prompt]: 	Test 700/1152. loss: 1.356, 0.2060 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 18:58:37 visual_prompt]: 	Test 800/1152. loss: 0.696, 0.1960 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 18:58:56 visual_prompt]: 	Test 900/1152. loss: 1.832, 0.1921 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 18:59:16 visual_prompt]: 	Test 1000/1152. loss: 1.167, 0.2089 s / batch. (data: 1.82e-02)max mem: 17.22454 GB 
[09/18 18:59:35 visual_prompt]: 	Test 1100/1152. loss: 0.978, 0.1946 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 18:59:50 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1933, average loss: 1.1106
[09/18 18:59:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.07	top5: 99.98	
[09/18 18:59:50 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/18 19:00:03 visual_prompt]: Epoch 86 / 100: avg data time: 2.27e-01, avg batch time: 0.6281, average train loss: 0.0750
[09/18 19:00:10 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1435, average loss: 0.1183
[09/18 19:00:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 96.00	top5: 100.00	
[09/18 19:00:33 visual_prompt]: 	Test 100/1152. loss: 1.319, 0.1977 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 19:00:52 visual_prompt]: 	Test 200/1152. loss: 1.251, 0.1818 s / batch. (data: 8.51e-05)max mem: 17.22454 GB 
[09/18 19:01:12 visual_prompt]: 	Test 300/1152. loss: 1.633, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 19:01:31 visual_prompt]: 	Test 400/1152. loss: 0.901, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 19:01:50 visual_prompt]: 	Test 500/1152. loss: 0.777, 0.1987 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 19:02:10 visual_prompt]: 	Test 600/1152. loss: 1.392, 0.1882 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 19:02:29 visual_prompt]: 	Test 700/1152. loss: 1.147, 0.1838 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/18 19:02:49 visual_prompt]: 	Test 800/1152. loss: 0.840, 0.2281 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:03:08 visual_prompt]: 	Test 900/1152. loss: 2.134, 0.1960 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 19:03:28 visual_prompt]: 	Test 1000/1152. loss: 1.194, 0.2073 s / batch. (data: 2.54e-02)max mem: 17.22454 GB 
[09/18 19:03:48 visual_prompt]: 	Test 1100/1152. loss: 1.077, 0.1829 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 19:04:02 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1938, average loss: 1.1549
[09/18 19:04:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.92	top5: 99.97	
[09/18 19:04:02 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/18 19:04:15 visual_prompt]: Epoch 87 / 100: avg data time: 2.30e-01, avg batch time: 0.6316, average train loss: 0.0920
[09/18 19:04:22 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1422, average loss: 0.0431
[09/18 19:04:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 98.00	top5: 100.00	
[09/18 19:04:46 visual_prompt]: 	Test 100/1152. loss: 0.958, 0.2125 s / batch. (data: 2.00e-02)max mem: 17.22454 GB 
[09/18 19:05:05 visual_prompt]: 	Test 200/1152. loss: 0.792, 0.2044 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 19:05:24 visual_prompt]: 	Test 300/1152. loss: 1.109, 0.1974 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 19:05:43 visual_prompt]: 	Test 400/1152. loss: 0.813, 0.1967 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 19:06:03 visual_prompt]: 	Test 500/1152. loss: 0.624, 0.1819 s / batch. (data: 2.96e-05)max mem: 17.22454 GB 
[09/18 19:06:22 visual_prompt]: 	Test 600/1152. loss: 1.416, 0.1893 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 19:06:42 visual_prompt]: 	Test 700/1152. loss: 1.230, 0.1824 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 19:07:01 visual_prompt]: 	Test 800/1152. loss: 0.673, 0.1999 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 19:07:21 visual_prompt]: 	Test 900/1152. loss: 1.706, 0.1822 s / batch. (data: 3.89e-05)max mem: 17.22454 GB 
[09/18 19:07:40 visual_prompt]: 	Test 1000/1152. loss: 1.082, 0.1830 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 19:08:00 visual_prompt]: 	Test 1100/1152. loss: 0.793, 0.2110 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 19:08:14 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1934, average loss: 1.0138
[09/18 19:08:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.35	top5: 99.99	
[09/18 19:08:14 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/18 19:08:27 visual_prompt]: Epoch 88 / 100: avg data time: 2.30e-01, avg batch time: 0.6307, average train loss: 0.0849
[09/18 19:08:34 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1438, average loss: 0.1465
[09/18 19:08:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.50	top5: 100.00	
[09/18 19:08:57 visual_prompt]: 	Test 100/1152. loss: 1.133, 0.1820 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 19:09:16 visual_prompt]: 	Test 200/1152. loss: 1.037, 0.1966 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:09:36 visual_prompt]: 	Test 300/1152. loss: 1.365, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:09:55 visual_prompt]: 	Test 400/1152. loss: 0.730, 0.1830 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 19:10:15 visual_prompt]: 	Test 500/1152. loss: 0.896, 0.1962 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 19:10:34 visual_prompt]: 	Test 600/1152. loss: 1.314, 0.1848 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 19:10:53 visual_prompt]: 	Test 700/1152. loss: 1.340, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 19:11:13 visual_prompt]: 	Test 800/1152. loss: 0.898, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 19:11:33 visual_prompt]: 	Test 900/1152. loss: 2.018, 0.2109 s / batch. (data: 2.33e-02)max mem: 17.22454 GB 
[09/18 19:11:52 visual_prompt]: 	Test 1000/1152. loss: 1.190, 0.2086 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 19:12:12 visual_prompt]: 	Test 1100/1152. loss: 0.719, 0.1947 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 19:12:26 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1936, average loss: 1.1441
[09/18 19:12:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.67	top5: 99.99	
[09/18 19:12:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/18 19:12:39 visual_prompt]: Epoch 89 / 100: avg data time: 2.27e-01, avg batch time: 0.6285, average train loss: 0.0649
[09/18 19:12:46 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1422, average loss: 0.0571
[09/18 19:12:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 97.50	top5: 100.00	
[09/18 19:13:10 visual_prompt]: 	Test 100/1152. loss: 1.074, 0.1962 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 19:13:29 visual_prompt]: 	Test 200/1152. loss: 1.009, 0.1970 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 19:13:48 visual_prompt]: 	Test 300/1152. loss: 1.325, 0.2046 s / batch. (data: 2.26e-02)max mem: 17.22454 GB 
[09/18 19:14:07 visual_prompt]: 	Test 400/1152. loss: 0.824, 0.1950 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 19:14:27 visual_prompt]: 	Test 500/1152. loss: 0.739, 0.2003 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/18 19:14:46 visual_prompt]: 	Test 600/1152. loss: 1.530, 0.1829 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 19:15:06 visual_prompt]: 	Test 700/1152. loss: 1.199, 0.1961 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 19:15:25 visual_prompt]: 	Test 800/1152. loss: 0.795, 0.1995 s / batch. (data: 1.70e-02)max mem: 17.22454 GB 
[09/18 19:15:45 visual_prompt]: 	Test 900/1152. loss: 2.175, 0.1877 s / batch. (data: 8.87e-05)max mem: 17.22454 GB 
[09/18 19:16:04 visual_prompt]: 	Test 1000/1152. loss: 1.236, 0.2132 s / batch. (data: 2.55e-02)max mem: 17.22454 GB 
[09/18 19:16:24 visual_prompt]: 	Test 1100/1152. loss: 0.811, 0.2046 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 19:16:38 visual_prompt]: Inference (test):avg data time: 8.42e-03, avg batch time: 0.1937, average loss: 1.0965
[09/18 19:16:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 75.35	top5: 99.99	
[09/18 19:16:38 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/18 19:16:51 visual_prompt]: Epoch 90 / 100: avg data time: 2.23e-01, avg batch time: 0.6215, average train loss: 0.0817
[09/18 19:16:58 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1431, average loss: 0.0458
[09/18 19:16:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 98.00	top5: 100.00	
[09/18 19:17:21 visual_prompt]: 	Test 100/1152. loss: 1.077, 0.1820 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 19:17:40 visual_prompt]: 	Test 200/1152. loss: 0.748, 0.1901 s / batch. (data: 8.82e-05)max mem: 17.22454 GB 
[09/18 19:18:00 visual_prompt]: 	Test 300/1152. loss: 1.202, 0.1987 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 19:18:19 visual_prompt]: 	Test 400/1152. loss: 0.771, 0.1982 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 19:18:38 visual_prompt]: 	Test 500/1152. loss: 0.859, 0.2182 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 19:18:58 visual_prompt]: 	Test 600/1152. loss: 1.268, 0.2059 s / batch. (data: 2.36e-02)max mem: 17.22454 GB 
[09/18 19:19:17 visual_prompt]: 	Test 700/1152. loss: 1.145, 0.1831 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 19:19:37 visual_prompt]: 	Test 800/1152. loss: 0.687, 0.1853 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 19:19:56 visual_prompt]: 	Test 900/1152. loss: 1.601, 0.2048 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 19:20:16 visual_prompt]: 	Test 1000/1152. loss: 1.043, 0.1827 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 19:20:35 visual_prompt]: 	Test 1100/1152. loss: 0.672, 0.1983 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/18 19:20:49 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1932, average loss: 1.0147
[09/18 19:20:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.90	top5: 99.99	
[09/18 19:20:50 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/18 19:21:03 visual_prompt]: Epoch 91 / 100: avg data time: 2.34e-01, avg batch time: 0.6342, average train loss: 0.0546
[09/18 19:21:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1434, average loss: 0.0313
[09/18 19:21:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/18 19:21:33 visual_prompt]: 	Test 100/1152. loss: 1.171, 0.1819 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 19:21:52 visual_prompt]: 	Test 200/1152. loss: 0.945, 0.1957 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 19:22:12 visual_prompt]: 	Test 300/1152. loss: 1.114, 0.1961 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 19:22:31 visual_prompt]: 	Test 400/1152. loss: 1.018, 0.1822 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 19:22:50 visual_prompt]: 	Test 500/1152. loss: 0.638, 0.2076 s / batch. (data: 1.91e-02)max mem: 17.22454 GB 
[09/18 19:23:10 visual_prompt]: 	Test 600/1152. loss: 1.131, 0.1873 s / batch. (data: 5.25e-03)max mem: 17.22454 GB 
[09/18 19:23:29 visual_prompt]: 	Test 700/1152. loss: 1.078, 0.1956 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 19:23:49 visual_prompt]: 	Test 800/1152. loss: 0.603, 0.1828 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 19:24:08 visual_prompt]: 	Test 900/1152. loss: 1.822, 0.1823 s / batch. (data: 3.22e-05)max mem: 17.22454 GB 
[09/18 19:24:28 visual_prompt]: 	Test 1000/1152. loss: 1.105, 0.1829 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 19:24:47 visual_prompt]: 	Test 1100/1152. loss: 0.680, 0.1992 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 19:25:01 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1933, average loss: 1.0283
[09/18 19:25:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.89	top5: 100.00	
[09/18 19:25:02 visual_prompt]: Best epoch 91: best metric: 0.990
[09/18 19:25:02 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/18 19:25:15 visual_prompt]: Epoch 92 / 100: avg data time: 2.25e-01, avg batch time: 0.6266, average train loss: 0.0329
[09/18 19:25:22 visual_prompt]: Inference (val):avg data time: 1.77e-05, avg batch time: 0.1419, average loss: 0.0385
[09/18 19:25:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 98.50	top5: 100.00	
[09/18 19:25:45 visual_prompt]: 	Test 100/1152. loss: 1.244, 0.2055 s / batch. (data: 2.03e-02)max mem: 17.22454 GB 
[09/18 19:26:04 visual_prompt]: 	Test 200/1152. loss: 0.879, 0.2082 s / batch. (data: 2.64e-02)max mem: 17.22454 GB 
[09/18 19:26:24 visual_prompt]: 	Test 300/1152. loss: 1.338, 0.1954 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 19:26:43 visual_prompt]: 	Test 400/1152. loss: 0.803, 0.1955 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 19:27:02 visual_prompt]: 	Test 500/1152. loss: 0.498, 0.1852 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 19:27:22 visual_prompt]: 	Test 600/1152. loss: 1.310, 0.1904 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 19:27:41 visual_prompt]: 	Test 700/1152. loss: 1.126, 0.1979 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 19:28:01 visual_prompt]: 	Test 800/1152. loss: 0.612, 0.2365 s / batch. (data: 5.44e-02)max mem: 17.22454 GB 
[09/18 19:28:20 visual_prompt]: 	Test 900/1152. loss: 1.716, 0.1829 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 19:28:40 visual_prompt]: 	Test 1000/1152. loss: 1.208, 0.1988 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 19:28:59 visual_prompt]: 	Test 1100/1152. loss: 0.714, 0.1984 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 19:29:13 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1936, average loss: 1.0265
[09/18 19:29:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.27	top5: 99.99	
[09/18 19:29:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/18 19:29:27 visual_prompt]: Epoch 93 / 100: avg data time: 2.29e-01, avg batch time: 0.6295, average train loss: 0.0238
[09/18 19:29:34 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1542, average loss: 0.0293
[09/18 19:29:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/18 19:29:57 visual_prompt]: 	Test 100/1152. loss: 1.264, 0.2181 s / batch. (data: 3.65e-02)max mem: 17.22454 GB 
[09/18 19:30:16 visual_prompt]: 	Test 200/1152. loss: 0.965, 0.1970 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:30:35 visual_prompt]: 	Test 300/1152. loss: 1.337, 0.1838 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 19:30:54 visual_prompt]: 	Test 400/1152. loss: 0.922, 0.1824 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 19:31:14 visual_prompt]: 	Test 500/1152. loss: 0.505, 0.1824 s / batch. (data: 8.61e-05)max mem: 17.22454 GB 
[09/18 19:31:33 visual_prompt]: 	Test 600/1152. loss: 1.275, 0.1981 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 19:31:52 visual_prompt]: 	Test 700/1152. loss: 1.100, 0.1971 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 19:32:12 visual_prompt]: 	Test 800/1152. loss: 0.608, 0.2106 s / batch. (data: 2.86e-02)max mem: 17.22454 GB 
[09/18 19:32:31 visual_prompt]: 	Test 900/1152. loss: 1.866, 0.1974 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 19:32:51 visual_prompt]: 	Test 1000/1152. loss: 1.255, 0.1826 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 19:33:10 visual_prompt]: 	Test 1100/1152. loss: 0.675, 0.2000 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 19:33:25 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1929, average loss: 1.0535
[09/18 19:33:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.99	top5: 99.99	
[09/18 19:33:25 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/18 19:33:38 visual_prompt]: Epoch 94 / 100: avg data time: 2.28e-01, avg batch time: 0.6295, average train loss: 0.0227
[09/18 19:33:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1422, average loss: 0.0149
[09/18 19:33:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 100.00	top5: 100.00	
[09/18 19:34:08 visual_prompt]: 	Test 100/1152. loss: 1.134, 0.1918 s / batch. (data: 8.30e-05)max mem: 17.22454 GB 
[09/18 19:34:27 visual_prompt]: 	Test 200/1152. loss: 0.904, 0.1822 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 19:34:46 visual_prompt]: 	Test 300/1152. loss: 1.213, 0.2078 s / batch. (data: 2.61e-02)max mem: 17.22454 GB 
[09/18 19:35:06 visual_prompt]: 	Test 400/1152. loss: 0.892, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 19:35:25 visual_prompt]: 	Test 500/1152. loss: 0.480, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 19:35:45 visual_prompt]: 	Test 600/1152. loss: 1.366, 0.1957 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 19:36:04 visual_prompt]: 	Test 700/1152. loss: 1.188, 0.1834 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 19:36:24 visual_prompt]: 	Test 800/1152. loss: 0.619, 0.1822 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 19:36:43 visual_prompt]: 	Test 900/1152. loss: 1.757, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:37:03 visual_prompt]: 	Test 1000/1152. loss: 1.147, 0.1983 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 19:37:22 visual_prompt]: 	Test 1100/1152. loss: 0.706, 0.1900 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 19:37:36 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1935, average loss: 1.0149
[09/18 19:37:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.09	top5: 99.99	
[09/18 19:37:37 visual_prompt]: Best epoch 94: best metric: 1.000
[09/18 19:37:37 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/18 19:37:50 visual_prompt]: Epoch 95 / 100: avg data time: 2.37e-01, avg batch time: 0.6366, average train loss: 0.0190
[09/18 19:37:57 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1422, average loss: 0.0322
[09/18 19:37:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 98.50	top5: 100.00	
[09/18 19:38:20 visual_prompt]: 	Test 100/1152. loss: 1.337, 0.1824 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 19:38:39 visual_prompt]: 	Test 200/1152. loss: 0.975, 0.1815 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 19:38:59 visual_prompt]: 	Test 300/1152. loss: 1.374, 0.1961 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 19:39:18 visual_prompt]: 	Test 400/1152. loss: 0.969, 0.1826 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 19:39:38 visual_prompt]: 	Test 500/1152. loss: 0.540, 0.1826 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 19:39:57 visual_prompt]: 	Test 600/1152. loss: 1.290, 0.1826 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 19:40:17 visual_prompt]: 	Test 700/1152. loss: 1.229, 0.1832 s / batch. (data: 2.06e-04)max mem: 17.22454 GB 
[09/18 19:40:36 visual_prompt]: 	Test 800/1152. loss: 0.622, 0.1832 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 19:40:55 visual_prompt]: 	Test 900/1152. loss: 1.914, 0.1946 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 19:41:15 visual_prompt]: 	Test 1000/1152. loss: 1.231, 0.2100 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 19:41:34 visual_prompt]: 	Test 1100/1152. loss: 0.716, 0.1970 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 19:41:49 visual_prompt]: Inference (test):avg data time: 8.33e-03, avg batch time: 0.1936, average loss: 1.0870
[09/18 19:41:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.86	top5: 99.99	
[09/18 19:41:49 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/18 19:42:02 visual_prompt]: Epoch 96 / 100: avg data time: 2.27e-01, avg batch time: 0.6307, average train loss: 0.0206
[09/18 19:42:09 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1426, average loss: 0.0147
[09/18 19:42:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/18 19:42:32 visual_prompt]: 	Test 100/1152. loss: 1.198, 0.1966 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 19:42:51 visual_prompt]: 	Test 200/1152. loss: 0.921, 0.1974 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 19:43:11 visual_prompt]: 	Test 300/1152. loss: 1.251, 0.1955 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 19:43:30 visual_prompt]: 	Test 400/1152. loss: 0.874, 0.1935 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 19:43:49 visual_prompt]: 	Test 500/1152. loss: 0.480, 0.1835 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 19:44:09 visual_prompt]: 	Test 600/1152. loss: 1.361, 0.1821 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 19:44:28 visual_prompt]: 	Test 700/1152. loss: 1.246, 0.2034 s / batch. (data: 2.11e-02)max mem: 17.22454 GB 
[09/18 19:44:48 visual_prompt]: 	Test 800/1152. loss: 0.611, 0.1896 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 19:45:07 visual_prompt]: 	Test 900/1152. loss: 1.772, 0.1860 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 19:45:27 visual_prompt]: 	Test 1000/1152. loss: 1.197, 0.2040 s / batch. (data: 1.94e-02)max mem: 17.22454 GB 
[09/18 19:45:46 visual_prompt]: 	Test 1100/1152. loss: 0.704, 0.1953 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 19:46:00 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1933, average loss: 1.0397
[09/18 19:46:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.89	top5: 99.99	
[09/18 19:46:01 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/18 19:46:14 visual_prompt]: Epoch 97 / 100: avg data time: 2.24e-01, avg batch time: 0.6264, average train loss: 0.0169
[09/18 19:46:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1448, average loss: 0.0175
[09/18 19:46:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/18 19:46:43 visual_prompt]: 	Test 100/1152. loss: 1.234, 0.1818 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 19:47:03 visual_prompt]: 	Test 200/1152. loss: 0.929, 0.1958 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 19:47:22 visual_prompt]: 	Test 300/1152. loss: 1.287, 0.1947 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 19:47:41 visual_prompt]: 	Test 400/1152. loss: 0.916, 0.1825 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/18 19:48:01 visual_prompt]: 	Test 500/1152. loss: 0.488, 0.1978 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 19:48:20 visual_prompt]: 	Test 600/1152. loss: 1.362, 0.1981 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 19:48:39 visual_prompt]: 	Test 700/1152. loss: 1.247, 0.1826 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/18 19:48:59 visual_prompt]: 	Test 800/1152. loss: 0.620, 0.1957 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 19:49:18 visual_prompt]: 	Test 900/1152. loss: 1.791, 0.1952 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 19:49:38 visual_prompt]: 	Test 1000/1152. loss: 1.201, 0.2063 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 19:49:57 visual_prompt]: 	Test 1100/1152. loss: 0.712, 0.1831 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 19:50:12 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1931, average loss: 1.0489
[09/18 19:50:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.80	top5: 99.99	
[09/18 19:50:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/18 19:50:25 visual_prompt]: Epoch 98 / 100: avg data time: 2.34e-01, avg batch time: 0.6400, average train loss: 0.0201
[09/18 19:50:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1437, average loss: 0.0248
[09/18 19:50:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/18 19:50:56 visual_prompt]: 	Test 100/1152. loss: 1.291, 0.1945 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 19:51:15 visual_prompt]: 	Test 200/1152. loss: 0.934, 0.1819 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 19:51:34 visual_prompt]: 	Test 300/1152. loss: 1.328, 0.2304 s / batch. (data: 3.27e-02)max mem: 17.22454 GB 
[09/18 19:51:54 visual_prompt]: 	Test 400/1152. loss: 0.948, 0.1915 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 19:52:14 visual_prompt]: 	Test 500/1152. loss: 0.502, 0.1964 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 19:52:33 visual_prompt]: 	Test 600/1152. loss: 1.362, 0.1967 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 19:52:53 visual_prompt]: 	Test 700/1152. loss: 1.263, 0.2434 s / batch. (data: 3.71e-02)max mem: 17.22454 GB 
[09/18 19:53:12 visual_prompt]: 	Test 800/1152. loss: 0.625, 0.1864 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 19:53:32 visual_prompt]: 	Test 900/1152. loss: 1.824, 0.2154 s / batch. (data: 3.32e-02)max mem: 17.22454 GB 
[09/18 19:53:51 visual_prompt]: 	Test 1000/1152. loss: 1.208, 0.1829 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 19:54:11 visual_prompt]: 	Test 1100/1152. loss: 0.731, 0.1968 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 19:54:25 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1942, average loss: 1.0659
[09/18 19:54:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.52	top5: 99.99	
[09/18 19:54:26 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/18 19:54:39 visual_prompt]: Epoch 99 / 100: avg data time: 2.34e-01, avg batch time: 0.6355, average train loss: 0.0142
[09/18 19:54:46 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1431, average loss: 0.0255
[09/18 19:54:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/18 19:55:10 visual_prompt]: 	Test 100/1152. loss: 1.304, 0.1836 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 19:55:29 visual_prompt]: 	Test 200/1152. loss: 0.941, 0.2069 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 19:55:49 visual_prompt]: 	Test 300/1152. loss: 1.338, 0.1818 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 19:56:08 visual_prompt]: 	Test 400/1152. loss: 0.955, 0.1825 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 19:56:28 visual_prompt]: 	Test 500/1152. loss: 0.508, 0.2196 s / batch. (data: 3.79e-02)max mem: 17.22454 GB 
[09/18 19:56:47 visual_prompt]: 	Test 600/1152. loss: 1.358, 0.1961 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 19:57:07 visual_prompt]: 	Test 700/1152. loss: 1.257, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:57:26 visual_prompt]: 	Test 800/1152. loss: 0.629, 0.1983 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 19:57:46 visual_prompt]: 	Test 900/1152. loss: 1.841, 0.1828 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 19:58:06 visual_prompt]: 	Test 1000/1152. loss: 1.216, 0.1854 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 19:58:25 visual_prompt]: 	Test 1100/1152. loss: 0.731, 0.1837 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 19:58:40 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1946, average loss: 1.0709
[09/18 19:58:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.41	top5: 99.99	
[09/18 19:58:40 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/18 19:58:54 visual_prompt]: Epoch 100 / 100: avg data time: 2.26e-01, avg batch time: 0.6299, average train loss: 0.0131
[09/18 19:59:01 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1447, average loss: 0.0253
[09/18 19:59:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/18 19:59:24 visual_prompt]: 	Test 100/1152. loss: 1.306, 0.1821 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 19:59:43 visual_prompt]: 	Test 200/1152. loss: 0.943, 0.2074 s / batch. (data: 2.61e-02)max mem: 17.22454 GB 
[09/18 20:00:03 visual_prompt]: 	Test 300/1152. loss: 1.338, 0.1839 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:00:23 visual_prompt]: 	Test 400/1152. loss: 0.956, 0.1912 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 20:00:42 visual_prompt]: 	Test 500/1152. loss: 0.506, 0.1831 s / batch. (data: 4.46e-05)max mem: 17.22454 GB 
[09/18 20:01:02 visual_prompt]: 	Test 600/1152. loss: 1.359, 0.1910 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 20:01:21 visual_prompt]: 	Test 700/1152. loss: 1.256, 0.2239 s / batch. (data: 4.20e-02)max mem: 17.22454 GB 
[09/18 20:01:41 visual_prompt]: 	Test 800/1152. loss: 0.631, 0.1862 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 20:02:00 visual_prompt]: 	Test 900/1152. loss: 1.844, 0.1939 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 20:02:20 visual_prompt]: 	Test 1000/1152. loss: 1.217, 0.2110 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/18 20:02:40 visual_prompt]: 	Test 1100/1152. loss: 0.730, 0.2232 s / batch. (data: 4.10e-02)max mem: 17.22454 GB 
[09/18 20:02:54 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1946, average loss: 1.0715
[09/18 20:02:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.43	top5: 99.99	
[09/18 20:03:20 visual_prompt]: Rank of current process: 0. World size: 1
[09/18 20:03:20 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/18 20:03:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/18 20:03:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/18 20:03:20 visual_prompt]: Training with config:
[09/18 20:03:20 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/18 20:03:20 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-18 20:03:20.282717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-18 20:03:20.452492: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-18 20:03:21.331327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 20:03:21.331406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 20:03:21.331416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-18 20:03:23.330591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 20:03:23.330692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 20:03:23.330706: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/18 20:03:23 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-18 20:03:23.348731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 20:03:25 visual_prompt]: Number of images: 1000
[09/18 20:03:25 visual_prompt]: Number of classes: 16 / 16
[09/18 20:03:25 visual_prompt]: Loading validation data...
[09/18 20:03:25 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 20:03:25 visual_prompt]: Number of images: 200
[09/18 20:03:25 visual_prompt]: Number of classes: 16 / 16
[09/18 20:03:25 visual_prompt]: Loading test data...
[09/18 20:03:25 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 20:04:59 visual_prompt]: Number of images: 73728
[09/18 20:04:59 visual_prompt]: Number of classes: 16 / 16
[09/18 20:04:59 visual_prompt]: Constructing models...
[09/18 20:05:02 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/18 20:05:02 visual_prompt]: tuned percent:1.077
[09/18 20:05:04 visual_prompt]: Device used for model: 0
[09/18 20:05:04 visual_prompt]: Setting up Evalutator...
[09/18 20:05:04 visual_prompt]: Setting up Trainer...
[09/18 20:05:04 visual_prompt]: 	Setting up the optimizer...
[09/18 20:05:04 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/18 20:05:19 visual_prompt]: Epoch 1 / 100: avg data time: 2.54e-01, avg batch time: 0.7325, average train loss: 2.8887
[09/18 20:05:27 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1416, average loss: 2.9089
[09/18 20:05:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 29.00	
[09/18 20:05:50 visual_prompt]: 	Test 100/1152. loss: 2.897, 0.2035 s / batch. (data: 2.34e-02)max mem: 17.22454 GB 
[09/18 20:06:09 visual_prompt]: 	Test 200/1152. loss: 2.848, 0.1816 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:06:28 visual_prompt]: 	Test 300/1152. loss: 2.968, 0.2080 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 20:06:48 visual_prompt]: 	Test 400/1152. loss: 2.829, 0.2066 s / batch. (data: 2.20e-02)max mem: 17.22454 GB 
[09/18 20:07:08 visual_prompt]: 	Test 500/1152. loss: 2.753, 0.1968 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 20:07:27 visual_prompt]: 	Test 600/1152. loss: 2.889, 0.2058 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 20:07:47 visual_prompt]: 	Test 700/1152. loss: 2.853, 0.2043 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 20:08:06 visual_prompt]: 	Test 800/1152. loss: 2.917, 0.2139 s / batch. (data: 3.26e-02)max mem: 17.22454 GB 
[09/18 20:08:26 visual_prompt]: 	Test 900/1152. loss: 2.888, 0.1835 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 20:08:45 visual_prompt]: 	Test 1000/1152. loss: 2.794, 0.1904 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 20:09:05 visual_prompt]: 	Test 1100/1152. loss: 2.913, 0.2000 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 20:09:19 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1940, average loss: 2.8838
[09/18 20:09:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 31.25	
[09/18 20:09:19 visual_prompt]: Best epoch 1: best metric: 0.060
[09/18 20:09:19 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/18 20:09:33 visual_prompt]: Epoch 2 / 100: avg data time: 2.47e-01, avg batch time: 0.6471, average train loss: 3.1919
[09/18 20:09:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1418, average loss: 2.8779
[09/18 20:09:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 31.50	
[09/18 20:10:04 visual_prompt]: 	Test 100/1152. loss: 2.848, 0.1958 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 20:10:23 visual_prompt]: 	Test 200/1152. loss: 2.849, 0.1971 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 20:10:42 visual_prompt]: 	Test 300/1152. loss: 2.872, 0.1946 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 20:11:02 visual_prompt]: 	Test 400/1152. loss: 2.876, 0.1995 s / batch. (data: 1.78e-02)max mem: 17.22454 GB 
[09/18 20:11:22 visual_prompt]: 	Test 500/1152. loss: 2.874, 0.2096 s / batch. (data: 2.81e-05)max mem: 17.22454 GB 
[09/18 20:11:41 visual_prompt]: 	Test 600/1152. loss: 2.862, 0.1980 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 20:12:01 visual_prompt]: 	Test 700/1152. loss: 2.905, 0.1906 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 20:12:20 visual_prompt]: 	Test 800/1152. loss: 2.897, 0.1826 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 20:12:40 visual_prompt]: 	Test 900/1152. loss: 2.978, 0.1867 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 20:13:00 visual_prompt]: 	Test 1000/1152. loss: 2.892, 0.1969 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 20:13:19 visual_prompt]: 	Test 1100/1152. loss: 2.984, 0.1843 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 20:13:34 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1945, average loss: 2.9040
[09/18 20:13:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.17	top5: 31.25	
[09/18 20:13:34 visual_prompt]: Best epoch 2: best metric: 0.065
[09/18 20:13:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/18 20:13:47 visual_prompt]: Epoch 3 / 100: avg data time: 2.47e-01, avg batch time: 0.6460, average train loss: 2.9441
[09/18 20:13:55 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1448, average loss: 2.8994
[09/18 20:13:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 32.50	
[09/18 20:14:18 visual_prompt]: 	Test 100/1152. loss: 2.853, 0.1947 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 20:14:37 visual_prompt]: 	Test 200/1152. loss: 3.030, 0.1829 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 20:14:57 visual_prompt]: 	Test 300/1152. loss: 2.856, 0.1970 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 20:15:16 visual_prompt]: 	Test 400/1152. loss: 2.972, 0.2140 s / batch. (data: 2.09e-02)max mem: 17.22454 GB 
[09/18 20:15:36 visual_prompt]: 	Test 500/1152. loss: 2.878, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 20:15:55 visual_prompt]: 	Test 600/1152. loss: 2.935, 0.1906 s / batch. (data: 8.78e-03)max mem: 17.22454 GB 
[09/18 20:16:15 visual_prompt]: 	Test 700/1152. loss: 2.821, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 20:16:34 visual_prompt]: 	Test 800/1152. loss: 2.937, 0.1828 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 20:16:54 visual_prompt]: 	Test 900/1152. loss: 3.035, 0.1936 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 20:17:13 visual_prompt]: 	Test 1000/1152. loss: 2.991, 0.1821 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 20:17:33 visual_prompt]: 	Test 1100/1152. loss: 2.985, 0.2140 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/18 20:17:47 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1937, average loss: 2.9375
[09/18 20:17:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 31.15	
[09/18 20:17:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/18 20:18:01 visual_prompt]: Epoch 4 / 100: avg data time: 2.46e-01, avg batch time: 0.6481, average train loss: 3.1168
[09/18 20:18:08 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1440, average loss: 3.1860
[09/18 20:18:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 30.50	
[09/18 20:18:31 visual_prompt]: 	Test 100/1152. loss: 3.043, 0.1825 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 20:18:51 visual_prompt]: 	Test 200/1152. loss: 3.152, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 20:19:10 visual_prompt]: 	Test 300/1152. loss: 3.118, 0.1958 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 20:19:30 visual_prompt]: 	Test 400/1152. loss: 3.340, 0.1998 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 20:19:49 visual_prompt]: 	Test 500/1152. loss: 3.171, 0.2111 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 20:20:09 visual_prompt]: 	Test 600/1152. loss: 3.076, 0.2049 s / batch. (data: 2.30e-02)max mem: 17.22454 GB 
[09/18 20:20:28 visual_prompt]: 	Test 700/1152. loss: 3.345, 0.1951 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 20:20:48 visual_prompt]: 	Test 800/1152. loss: 3.179, 0.1947 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/18 20:21:07 visual_prompt]: 	Test 900/1152. loss: 2.966, 0.1839 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 20:21:27 visual_prompt]: 	Test 1000/1152. loss: 3.180, 0.1955 s / batch. (data: 7.27e-03)max mem: 17.22454 GB 
[09/18 20:21:46 visual_prompt]: 	Test 1100/1152. loss: 3.066, 0.2221 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 20:22:01 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1939, average loss: 3.1372
[09/18 20:22:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.24	top5: 31.31	
[09/18 20:22:01 visual_prompt]: Best epoch 4: best metric: 0.080
[09/18 20:22:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/18 20:22:14 visual_prompt]: Epoch 5 / 100: avg data time: 2.38e-01, avg batch time: 0.6399, average train loss: 3.2573
[09/18 20:22:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1453, average loss: 2.9934
[09/18 20:22:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 37.00	
[09/18 20:22:45 visual_prompt]: 	Test 100/1152. loss: 3.142, 0.2275 s / batch. (data: 2.44e-02)max mem: 17.22454 GB 
[09/18 20:23:04 visual_prompt]: 	Test 200/1152. loss: 3.024, 0.1900 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 20:23:24 visual_prompt]: 	Test 300/1152. loss: 3.031, 0.1972 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 20:23:43 visual_prompt]: 	Test 400/1152. loss: 2.870, 0.2139 s / batch. (data: 1.74e-02)max mem: 17.22454 GB 
[09/18 20:24:03 visual_prompt]: 	Test 500/1152. loss: 2.943, 0.1958 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 20:24:22 visual_prompt]: 	Test 600/1152. loss: 3.044, 0.1825 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 20:24:42 visual_prompt]: 	Test 700/1152. loss: 3.041, 0.1829 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 20:25:01 visual_prompt]: 	Test 800/1152. loss: 2.976, 0.2140 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 20:25:21 visual_prompt]: 	Test 900/1152. loss: 3.198, 0.1830 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 20:25:40 visual_prompt]: 	Test 1000/1152. loss: 3.064, 0.2148 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/18 20:26:00 visual_prompt]: 	Test 1100/1152. loss: 3.091, 0.1822 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 20:26:15 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1943, average loss: 3.0279
[09/18 20:26:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.13	top5: 31.16	
[09/18 20:26:15 visual_prompt]: Best epoch 5: best metric: 0.095
[09/18 20:26:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/18 20:26:28 visual_prompt]: Epoch 6 / 100: avg data time: 2.36e-01, avg batch time: 0.6397, average train loss: 3.1729
[09/18 20:26:36 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1421, average loss: 3.1291
[09/18 20:26:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 26.50	
[09/18 20:26:59 visual_prompt]: 	Test 100/1152. loss: 3.032, 0.1826 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 20:27:18 visual_prompt]: 	Test 200/1152. loss: 3.001, 0.1867 s / batch. (data: 9.85e-05)max mem: 17.22454 GB 
[09/18 20:27:38 visual_prompt]: 	Test 300/1152. loss: 2.998, 0.1995 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 20:27:57 visual_prompt]: 	Test 400/1152. loss: 3.069, 0.1940 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 20:28:17 visual_prompt]: 	Test 500/1152. loss: 2.963, 0.1945 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 20:28:36 visual_prompt]: 	Test 600/1152. loss: 3.023, 0.1828 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 20:28:56 visual_prompt]: 	Test 700/1152. loss: 3.212, 0.2006 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 20:29:15 visual_prompt]: 	Test 800/1152. loss: 3.168, 0.1935 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 20:29:35 visual_prompt]: 	Test 900/1152. loss: 3.115, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 20:29:55 visual_prompt]: 	Test 1000/1152. loss: 3.163, 0.2109 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 20:30:14 visual_prompt]: 	Test 1100/1152. loss: 3.272, 0.1867 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 20:30:29 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1944, average loss: 3.0874
[09/18 20:30:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.49	
[09/18 20:30:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/18 20:30:42 visual_prompt]: Epoch 7 / 100: avg data time: 2.36e-01, avg batch time: 0.6393, average train loss: 3.1121
[09/18 20:30:50 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1421, average loss: 3.0604
[09/18 20:30:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 30.00	
[09/18 20:31:13 visual_prompt]: 	Test 100/1152. loss: 3.137, 0.1924 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/18 20:31:32 visual_prompt]: 	Test 200/1152. loss: 2.911, 0.1823 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 20:31:52 visual_prompt]: 	Test 300/1152. loss: 3.106, 0.2159 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 20:32:11 visual_prompt]: 	Test 400/1152. loss: 3.105, 0.1829 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/18 20:32:31 visual_prompt]: 	Test 500/1152. loss: 3.006, 0.1992 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 20:32:50 visual_prompt]: 	Test 600/1152. loss: 3.047, 0.2085 s / batch. (data: 2.64e-02)max mem: 17.22454 GB 
[09/18 20:33:10 visual_prompt]: 	Test 700/1152. loss: 3.150, 0.1817 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 20:33:30 visual_prompt]: 	Test 800/1152. loss: 3.173, 0.1835 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 20:33:49 visual_prompt]: 	Test 900/1152. loss: 3.164, 0.1824 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 20:34:09 visual_prompt]: 	Test 1000/1152. loss: 3.231, 0.1828 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 20:34:28 visual_prompt]: 	Test 1100/1152. loss: 3.362, 0.1823 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 20:34:43 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1943, average loss: 3.1290
[09/18 20:34:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.39	
[09/18 20:34:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/18 20:34:56 visual_prompt]: Epoch 8 / 100: avg data time: 2.36e-01, avg batch time: 0.6367, average train loss: 3.1596
[09/18 20:35:04 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1421, average loss: 3.1556
[09/18 20:35:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.50	top5: 33.00	
[09/18 20:35:27 visual_prompt]: 	Test 100/1152. loss: 3.236, 0.1826 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 20:35:46 visual_prompt]: 	Test 200/1152. loss: 2.939, 0.1922 s / batch. (data: 9.88e-03)max mem: 17.22454 GB 
[09/18 20:36:06 visual_prompt]: 	Test 300/1152. loss: 3.305, 0.1971 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 20:36:25 visual_prompt]: 	Test 400/1152. loss: 3.027, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 20:36:45 visual_prompt]: 	Test 500/1152. loss: 2.932, 0.1830 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 20:37:04 visual_prompt]: 	Test 600/1152. loss: 3.154, 0.1846 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 20:37:24 visual_prompt]: 	Test 700/1152. loss: 3.229, 0.2036 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 20:37:43 visual_prompt]: 	Test 800/1152. loss: 3.228, 0.1863 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 20:38:03 visual_prompt]: 	Test 900/1152. loss: 3.105, 0.1900 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 20:38:22 visual_prompt]: 	Test 1000/1152. loss: 3.106, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 20:38:42 visual_prompt]: 	Test 1100/1152. loss: 3.118, 0.1908 s / batch. (data: 8.37e-03)max mem: 17.22454 GB 
[09/18 20:38:56 visual_prompt]: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1939, average loss: 3.1046
[09/18 20:38:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.28	top5: 31.75	
[09/18 20:38:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/18 20:39:10 visual_prompt]: Epoch 9 / 100: avg data time: 2.44e-01, avg batch time: 0.6443, average train loss: 3.2328
[09/18 20:39:17 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1428, average loss: 3.1027
[09/18 20:39:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.50	top5: 28.50	
[09/18 20:39:40 visual_prompt]: 	Test 100/1152. loss: 3.072, 0.1824 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 20:40:00 visual_prompt]: 	Test 200/1152. loss: 2.919, 0.1851 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:40:19 visual_prompt]: 	Test 300/1152. loss: 2.856, 0.1867 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 20:40:39 visual_prompt]: 	Test 400/1152. loss: 3.079, 0.1838 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 20:40:58 visual_prompt]: 	Test 500/1152. loss: 3.207, 0.1844 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 20:41:18 visual_prompt]: 	Test 600/1152. loss: 3.029, 0.2073 s / batch. (data: 4.82e-05)max mem: 17.22454 GB 
[09/18 20:41:37 visual_prompt]: 	Test 700/1152. loss: 3.003, 0.2087 s / batch. (data: 2.67e-02)max mem: 17.22454 GB 
[09/18 20:41:57 visual_prompt]: 	Test 800/1152. loss: 3.154, 0.1825 s / batch. (data: 9.68e-05)max mem: 17.22454 GB 
[09/18 20:42:16 visual_prompt]: 	Test 900/1152. loss: 2.935, 0.1834 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 20:42:36 visual_prompt]: 	Test 1000/1152. loss: 2.889, 0.2073 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 20:42:55 visual_prompt]: 	Test 1100/1152. loss: 3.204, 0.1888 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 20:43:10 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1940, average loss: 3.0411
[09/18 20:43:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.22	top5: 31.35	
[09/18 20:43:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/18 20:43:23 visual_prompt]: Epoch 10 / 100: avg data time: 2.33e-01, avg batch time: 0.6348, average train loss: 3.6435
[09/18 20:43:31 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1421, average loss: 4.4873
[09/18 20:43:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 39.50	
[09/18 20:43:54 visual_prompt]: 	Test 100/1152. loss: 4.780, 0.2038 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/18 20:44:14 visual_prompt]: 	Test 200/1152. loss: 4.322, 0.1825 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 20:44:33 visual_prompt]: 	Test 300/1152. loss: 4.102, 0.1959 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 20:44:53 visual_prompt]: 	Test 400/1152. loss: 5.615, 0.1838 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 20:45:12 visual_prompt]: 	Test 500/1152. loss: 5.831, 0.1947 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 20:45:32 visual_prompt]: 	Test 600/1152. loss: 4.535, 0.1987 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 20:45:52 visual_prompt]: 	Test 700/1152. loss: 5.466, 0.1824 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 20:46:11 visual_prompt]: 	Test 800/1152. loss: 4.640, 0.2050 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 20:46:31 visual_prompt]: 	Test 900/1152. loss: 5.012, 0.1824 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/18 20:46:50 visual_prompt]: 	Test 1000/1152. loss: 4.429, 0.2094 s / batch. (data: 2.09e-02)max mem: 17.22454 GB 
[09/18 20:47:10 visual_prompt]: 	Test 1100/1152. loss: 5.577, 0.2062 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 20:47:25 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1948, average loss: 4.8784
[09/18 20:47:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 30.96	
[09/18 20:47:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/18 20:47:39 visual_prompt]: Epoch 11 / 100: avg data time: 2.46e-01, avg batch time: 0.6491, average train loss: 4.5695
[09/18 20:47:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1422, average loss: 4.0175
[09/18 20:47:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 10.00	top5: 37.00	
[09/18 20:48:09 visual_prompt]: 	Test 100/1152. loss: 4.829, 0.1878 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 20:48:28 visual_prompt]: 	Test 200/1152. loss: 4.374, 0.2057 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 20:48:48 visual_prompt]: 	Test 300/1152. loss: 3.873, 0.2136 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 20:49:07 visual_prompt]: 	Test 400/1152. loss: 4.058, 0.1826 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 20:49:27 visual_prompt]: 	Test 500/1152. loss: 4.788, 0.1827 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 20:49:46 visual_prompt]: 	Test 600/1152. loss: 3.973, 0.1830 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 20:50:06 visual_prompt]: 	Test 700/1152. loss: 4.340, 0.1835 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 20:50:25 visual_prompt]: 	Test 800/1152. loss: 3.782, 0.1933 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 20:50:45 visual_prompt]: 	Test 900/1152. loss: 4.448, 0.1826 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 20:51:05 visual_prompt]: 	Test 1000/1152. loss: 4.582, 0.1969 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 20:51:24 visual_prompt]: 	Test 1100/1152. loss: 3.747, 0.1965 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 20:51:39 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1944, average loss: 4.1425
[09/18 20:51:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.14	top5: 30.94	
[09/18 20:51:39 visual_prompt]: Best epoch 11: best metric: 0.100
[09/18 20:51:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/18 20:51:52 visual_prompt]: Epoch 12 / 100: avg data time: 2.31e-01, avg batch time: 0.6342, average train loss: 3.6459
[09/18 20:52:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1423, average loss: 4.4477
[09/18 20:52:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 30.00	
[09/18 20:52:23 visual_prompt]: 	Test 100/1152. loss: 3.893, 0.1821 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 20:52:42 visual_prompt]: 	Test 200/1152. loss: 3.845, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 20:53:01 visual_prompt]: 	Test 300/1152. loss: 3.522, 0.1830 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 20:53:21 visual_prompt]: 	Test 400/1152. loss: 4.494, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 20:53:41 visual_prompt]: 	Test 500/1152. loss: 4.896, 0.1975 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 20:54:00 visual_prompt]: 	Test 600/1152. loss: 4.667, 0.1830 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 20:54:20 visual_prompt]: 	Test 700/1152. loss: 4.089, 0.1916 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 20:54:39 visual_prompt]: 	Test 800/1152. loss: 4.076, 0.1833 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 20:54:59 visual_prompt]: 	Test 900/1152. loss: 4.034, 0.1840 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 20:55:18 visual_prompt]: 	Test 1000/1152. loss: 3.877, 0.2154 s / batch. (data: 2.28e-02)max mem: 17.22454 GB 
[09/18 20:55:38 visual_prompt]: 	Test 1100/1152. loss: 4.075, 0.2186 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 20:55:53 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1942, average loss: 4.0917
[09/18 20:55:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.60	top5: 35.40	
[09/18 20:55:53 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/18 20:56:06 visual_prompt]: Epoch 13 / 100: avg data time: 2.44e-01, avg batch time: 0.6445, average train loss: 3.3916
[09/18 20:56:14 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1420, average loss: 2.6707
[09/18 20:56:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.00	top5: 55.00	
[09/18 20:56:37 visual_prompt]: 	Test 100/1152. loss: 2.269, 0.1825 s / batch. (data: 8.13e-05)max mem: 17.22454 GB 
[09/18 20:56:56 visual_prompt]: 	Test 200/1152. loss: 2.645, 0.1823 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 20:57:16 visual_prompt]: 	Test 300/1152. loss: 2.577, 0.2029 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 20:57:35 visual_prompt]: 	Test 400/1152. loss: 2.747, 0.1927 s / batch. (data: 4.86e-05)max mem: 17.22454 GB 
[09/18 20:57:55 visual_prompt]: 	Test 500/1152. loss: 2.778, 0.2008 s / batch. (data: 1.89e-02)max mem: 17.22454 GB 
[09/18 20:58:14 visual_prompt]: 	Test 600/1152. loss: 2.633, 0.1834 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 20:58:34 visual_prompt]: 	Test 700/1152. loss: 2.538, 0.2199 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 20:58:54 visual_prompt]: 	Test 800/1152. loss: 2.704, 0.2025 s / batch. (data: 2.00e-02)max mem: 17.22454 GB 
[09/18 20:59:13 visual_prompt]: 	Test 900/1152. loss: 2.568, 0.1997 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 20:59:33 visual_prompt]: 	Test 1000/1152. loss: 2.752, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 20:59:52 visual_prompt]: 	Test 1100/1152. loss: 2.740, 0.1876 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 21:00:07 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1945, average loss: 2.6504
[09/18 21:00:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.27	top5: 56.74	
[09/18 21:00:07 visual_prompt]: Best epoch 13: best metric: 0.120
[09/18 21:00:07 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/18 21:00:20 visual_prompt]: Epoch 14 / 100: avg data time: 2.29e-01, avg batch time: 0.6333, average train loss: 2.4638
[09/18 21:00:28 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1423, average loss: 2.4361
[09/18 21:00:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 13.50	top5: 62.50	
[09/18 21:00:51 visual_prompt]: 	Test 100/1152. loss: 2.465, 0.1827 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 21:01:11 visual_prompt]: 	Test 200/1152. loss: 2.152, 0.1818 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 21:01:30 visual_prompt]: 	Test 300/1152. loss: 2.470, 0.1828 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 21:01:50 visual_prompt]: 	Test 400/1152. loss: 2.498, 0.1836 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 21:02:09 visual_prompt]: 	Test 500/1152. loss: 2.502, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 21:02:29 visual_prompt]: 	Test 600/1152. loss: 2.377, 0.1931 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/18 21:02:48 visual_prompt]: 	Test 700/1152. loss: 2.437, 0.1918 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:03:08 visual_prompt]: 	Test 800/1152. loss: 2.387, 0.1981 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/18 21:03:27 visual_prompt]: 	Test 900/1152. loss: 2.466, 0.1947 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 21:03:47 visual_prompt]: 	Test 1000/1152. loss: 2.315, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 21:04:07 visual_prompt]: 	Test 1100/1152. loss: 2.538, 0.2105 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 21:04:21 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1945, average loss: 2.4153
[09/18 21:04:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.27	top5: 65.01	
[09/18 21:04:21 visual_prompt]: Best epoch 14: best metric: 0.135
[09/18 21:04:21 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/18 21:04:35 visual_prompt]: Epoch 15 / 100: avg data time: 2.40e-01, avg batch time: 0.6406, average train loss: 2.4770
[09/18 21:04:42 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1435, average loss: 2.6851
[09/18 21:04:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.50	top5: 65.50	
[09/18 21:05:06 visual_prompt]: 	Test 100/1152. loss: 2.459, 0.1818 s / batch. (data: 2.74e-05)max mem: 17.22454 GB 
[09/18 21:05:25 visual_prompt]: 	Test 200/1152. loss: 2.877, 0.1963 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 21:05:45 visual_prompt]: 	Test 300/1152. loss: 2.708, 0.2046 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 21:06:04 visual_prompt]: 	Test 400/1152. loss: 2.674, 0.1826 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 21:06:24 visual_prompt]: 	Test 500/1152. loss: 2.618, 0.1963 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 21:06:43 visual_prompt]: 	Test 600/1152. loss: 2.726, 0.1834 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 21:07:03 visual_prompt]: 	Test 700/1152. loss: 2.883, 0.1836 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/18 21:07:22 visual_prompt]: 	Test 800/1152. loss: 2.671, 0.2027 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 21:07:42 visual_prompt]: 	Test 900/1152. loss: 3.151, 0.2225 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/18 21:08:02 visual_prompt]: 	Test 1000/1152. loss: 3.176, 0.1838 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 21:08:21 visual_prompt]: 	Test 1100/1152. loss: 2.573, 0.2078 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 21:08:36 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1948, average loss: 2.7056
[09/18 21:08:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.67	top5: 64.93	
[09/18 21:08:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/18 21:08:50 visual_prompt]: Epoch 16 / 100: avg data time: 2.41e-01, avg batch time: 0.6467, average train loss: 2.6115
[09/18 21:08:57 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1421, average loss: 2.8060
[09/18 21:08:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 17.00	top5: 58.00	
[09/18 21:09:20 visual_prompt]: 	Test 100/1152. loss: 2.578, 0.1826 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 21:09:40 visual_prompt]: 	Test 200/1152. loss: 2.743, 0.2122 s / batch. (data: 3.08e-02)max mem: 17.22454 GB 
[09/18 21:09:59 visual_prompt]: 	Test 300/1152. loss: 3.008, 0.2104 s / batch. (data: 2.88e-02)max mem: 17.22454 GB 
[09/18 21:10:19 visual_prompt]: 	Test 400/1152. loss: 2.621, 0.2144 s / batch. (data: 3.23e-02)max mem: 17.22454 GB 
[09/18 21:10:38 visual_prompt]: 	Test 500/1152. loss: 2.321, 0.1824 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 21:10:58 visual_prompt]: 	Test 600/1152. loss: 2.721, 0.1967 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 21:11:18 visual_prompt]: 	Test 700/1152. loss: 2.415, 0.1987 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 21:11:37 visual_prompt]: 	Test 800/1152. loss: 2.896, 0.1989 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 21:11:56 visual_prompt]: 	Test 900/1152. loss: 2.795, 0.1919 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 21:12:16 visual_prompt]: 	Test 1000/1152. loss: 2.539, 0.1826 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 21:12:36 visual_prompt]: 	Test 1100/1152. loss: 2.839, 0.1828 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:12:50 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1945, average loss: 2.7428
[09/18 21:12:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 18.18	top5: 60.50	
[09/18 21:12:50 visual_prompt]: Best epoch 16: best metric: 0.170
[09/18 21:12:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/18 21:13:04 visual_prompt]: Epoch 17 / 100: avg data time: 2.40e-01, avg batch time: 0.6393, average train loss: 2.1554
[09/18 21:13:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1420, average loss: 2.3002
[09/18 21:13:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 15.50	top5: 74.00	
[09/18 21:13:34 visual_prompt]: 	Test 100/1152. loss: 2.179, 0.1819 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/18 21:13:53 visual_prompt]: 	Test 200/1152. loss: 2.325, 0.1954 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 21:14:13 visual_prompt]: 	Test 300/1152. loss: 2.429, 0.2184 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 21:14:32 visual_prompt]: 	Test 400/1152. loss: 2.372, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 21:14:52 visual_prompt]: 	Test 500/1152. loss: 2.381, 0.1959 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 21:15:11 visual_prompt]: 	Test 600/1152. loss: 2.507, 0.2100 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 21:15:31 visual_prompt]: 	Test 700/1152. loss: 2.449, 0.1942 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 21:15:51 visual_prompt]: 	Test 800/1152. loss: 2.206, 0.1943 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 21:16:10 visual_prompt]: 	Test 900/1152. loss: 2.538, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 21:16:30 visual_prompt]: 	Test 1000/1152. loss: 2.437, 0.1832 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 21:16:49 visual_prompt]: 	Test 1100/1152. loss: 2.252, 0.1956 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 21:17:04 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1943, average loss: 2.3353
[09/18 21:17:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.35	top5: 74.77	
[09/18 21:17:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/18 21:17:18 visual_prompt]: Epoch 18 / 100: avg data time: 2.36e-01, avg batch time: 0.6373, average train loss: 2.1241
[09/18 21:17:25 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1422, average loss: 1.8436
[09/18 21:17:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 28.50	top5: 90.00	
[09/18 21:17:48 visual_prompt]: 	Test 100/1152. loss: 1.888, 0.1953 s / batch. (data: 9.73e-05)max mem: 17.22454 GB 
[09/18 21:18:07 visual_prompt]: 	Test 200/1152. loss: 1.928, 0.1818 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 21:18:27 visual_prompt]: 	Test 300/1152. loss: 1.816, 0.2008 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 21:18:46 visual_prompt]: 	Test 400/1152. loss: 1.992, 0.1973 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/18 21:19:06 visual_prompt]: 	Test 500/1152. loss: 2.031, 0.1830 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:19:26 visual_prompt]: 	Test 600/1152. loss: 1.987, 0.2335 s / batch. (data: 2.05e-02)max mem: 17.22454 GB 
[09/18 21:19:45 visual_prompt]: 	Test 700/1152. loss: 2.029, 0.1987 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 21:20:05 visual_prompt]: 	Test 800/1152. loss: 1.935, 0.1914 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 21:20:25 visual_prompt]: 	Test 900/1152. loss: 2.054, 0.1879 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:20:44 visual_prompt]: 	Test 1000/1152. loss: 1.842, 0.1829 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:21:04 visual_prompt]: 	Test 1100/1152. loss: 2.078, 0.1831 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:21:18 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1947, average loss: 1.9366
[09/18 21:21:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 24.12	top5: 86.75	
[09/18 21:21:18 visual_prompt]: Best epoch 18: best metric: 0.285
[09/18 21:21:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/18 21:21:32 visual_prompt]: Epoch 19 / 100: avg data time: 2.30e-01, avg batch time: 0.6313, average train loss: 2.2625
[09/18 21:21:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1423, average loss: 2.5639
[09/18 21:21:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.50	top5: 70.50	
[09/18 21:22:02 visual_prompt]: 	Test 100/1152. loss: 2.728, 0.1928 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 21:22:21 visual_prompt]: 	Test 200/1152. loss: 2.276, 0.2041 s / batch. (data: 2.19e-02)max mem: 17.22454 GB 
[09/18 21:22:41 visual_prompt]: 	Test 300/1152. loss: 2.677, 0.1834 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 21:23:00 visual_prompt]: 	Test 400/1152. loss: 2.664, 0.1825 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 21:23:20 visual_prompt]: 	Test 500/1152. loss: 2.581, 0.1895 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 21:23:39 visual_prompt]: 	Test 600/1152. loss: 2.668, 0.1898 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 21:23:59 visual_prompt]: 	Test 700/1152. loss: 2.571, 0.1929 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 21:24:18 visual_prompt]: 	Test 800/1152. loss: 2.629, 0.2081 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 21:24:38 visual_prompt]: 	Test 900/1152. loss: 2.674, 0.1830 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 21:24:57 visual_prompt]: 	Test 1000/1152. loss: 2.579, 0.2038 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 21:25:17 visual_prompt]: 	Test 1100/1152. loss: 2.495, 0.2094 s / batch. (data: 2.76e-02)max mem: 17.22454 GB 
[09/18 21:25:31 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1939, average loss: 2.5710
[09/18 21:25:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 14.85	top5: 70.70	
[09/18 21:25:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/18 21:25:45 visual_prompt]: Epoch 20 / 100: avg data time: 2.32e-01, avg batch time: 0.6386, average train loss: 2.2265
[09/18 21:25:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1422, average loss: 1.9278
[09/18 21:25:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 35.00	top5: 94.00	
[09/18 21:26:15 visual_prompt]: 	Test 100/1152. loss: 2.066, 0.1954 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 21:26:35 visual_prompt]: 	Test 200/1152. loss: 2.170, 0.1824 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 21:26:54 visual_prompt]: 	Test 300/1152. loss: 2.028, 0.2006 s / batch. (data: 1.84e-02)max mem: 17.22454 GB 
[09/18 21:27:14 visual_prompt]: 	Test 400/1152. loss: 1.949, 0.2007 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/18 21:27:33 visual_prompt]: 	Test 500/1152. loss: 1.917, 0.1822 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/18 21:27:53 visual_prompt]: 	Test 600/1152. loss: 1.960, 0.1824 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:28:12 visual_prompt]: 	Test 700/1152. loss: 1.715, 0.2020 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 21:28:32 visual_prompt]: 	Test 800/1152. loss: 1.786, 0.1982 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 21:28:52 visual_prompt]: 	Test 900/1152. loss: 1.989, 0.1984 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 21:29:11 visual_prompt]: 	Test 1000/1152. loss: 2.018, 0.2079 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 21:29:31 visual_prompt]: 	Test 1100/1152. loss: 1.579, 0.1956 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 21:29:45 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1944, average loss: 1.9296
[09/18 21:29:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.07	top5: 92.31	
[09/18 21:29:45 visual_prompt]: Best epoch 20: best metric: 0.350
[09/18 21:29:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/18 21:29:59 visual_prompt]: Epoch 21 / 100: avg data time: 2.42e-01, avg batch time: 0.6436, average train loss: 1.8845
[09/18 21:30:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1421, average loss: 1.5134
[09/18 21:30:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.00	top5: 99.50	
[09/18 21:30:30 visual_prompt]: 	Test 100/1152. loss: 1.628, 0.1823 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 21:30:49 visual_prompt]: 	Test 200/1152. loss: 1.437, 0.1821 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 21:31:08 visual_prompt]: 	Test 300/1152. loss: 1.662, 0.1968 s / batch. (data: 9.78e-05)max mem: 17.22454 GB 
[09/18 21:31:28 visual_prompt]: 	Test 400/1152. loss: 1.445, 0.2299 s / batch. (data: 4.81e-02)max mem: 17.22454 GB 
[09/18 21:31:47 visual_prompt]: 	Test 500/1152. loss: 1.496, 0.1959 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 21:32:07 visual_prompt]: 	Test 600/1152. loss: 1.585, 0.1829 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 21:32:26 visual_prompt]: 	Test 700/1152. loss: 1.452, 0.2121 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 21:32:46 visual_prompt]: 	Test 800/1152. loss: 1.504, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 21:33:05 visual_prompt]: 	Test 900/1152. loss: 1.541, 0.1944 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 21:33:25 visual_prompt]: 	Test 1000/1152. loss: 1.488, 0.1929 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:33:45 visual_prompt]: 	Test 1100/1152. loss: 1.479, 0.1868 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 21:33:59 visual_prompt]: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1941, average loss: 1.5184
[09/18 21:33:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.54	top5: 98.48	
[09/18 21:33:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/18 21:34:12 visual_prompt]: Epoch 22 / 100: avg data time: 2.37e-01, avg batch time: 0.6402, average train loss: 2.0283
[09/18 21:34:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1423, average loss: 2.1175
[09/18 21:34:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 35.00	top5: 92.50	
[09/18 21:34:43 visual_prompt]: 	Test 100/1152. loss: 2.079, 0.1957 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 21:35:03 visual_prompt]: 	Test 200/1152. loss: 2.301, 0.1825 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 21:35:22 visual_prompt]: 	Test 300/1152. loss: 2.166, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 21:35:42 visual_prompt]: 	Test 400/1152. loss: 2.350, 0.1987 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 21:36:01 visual_prompt]: 	Test 500/1152. loss: 2.598, 0.2185 s / batch. (data: 1.78e-02)max mem: 17.22454 GB 
[09/18 21:36:21 visual_prompt]: 	Test 600/1152. loss: 2.522, 0.1821 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 21:36:40 visual_prompt]: 	Test 700/1152. loss: 2.522, 0.1904 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/18 21:37:00 visual_prompt]: 	Test 800/1152. loss: 2.280, 0.1834 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:37:19 visual_prompt]: 	Test 900/1152. loss: 2.493, 0.1826 s / batch. (data: 8.61e-05)max mem: 17.22454 GB 
[09/18 21:37:39 visual_prompt]: 	Test 1000/1152. loss: 2.421, 0.1850 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:37:58 visual_prompt]: 	Test 1100/1152. loss: 2.705, 0.1828 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:38:13 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1942, average loss: 2.3673
[09/18 21:38:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 29.21	top5: 89.92	
[09/18 21:38:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/18 21:38:26 visual_prompt]: Epoch 23 / 100: avg data time: 2.34e-01, avg batch time: 0.6375, average train loss: 1.8313
[09/18 21:38:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1421, average loss: 1.5989
[09/18 21:38:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 29.50	top5: 99.00	
[09/18 21:38:57 visual_prompt]: 	Test 100/1152. loss: 1.793, 0.1954 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 21:39:16 visual_prompt]: 	Test 200/1152. loss: 1.527, 0.2064 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 21:39:36 visual_prompt]: 	Test 300/1152. loss: 1.708, 0.2130 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 21:39:55 visual_prompt]: 	Test 400/1152. loss: 1.532, 0.1890 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 21:40:15 visual_prompt]: 	Test 500/1152. loss: 1.400, 0.1983 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 21:40:34 visual_prompt]: 	Test 600/1152. loss: 1.537, 0.1969 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 21:40:54 visual_prompt]: 	Test 700/1152. loss: 1.772, 0.1825 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/18 21:41:13 visual_prompt]: 	Test 800/1152. loss: 1.649, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 21:41:33 visual_prompt]: 	Test 900/1152. loss: 1.780, 0.1959 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 21:41:52 visual_prompt]: 	Test 1000/1152. loss: 1.751, 0.1982 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/18 21:42:12 visual_prompt]: 	Test 1100/1152. loss: 1.540, 0.1958 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 21:42:26 visual_prompt]: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1943, average loss: 1.6110
[09/18 21:42:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.86	top5: 99.53	
[09/18 21:42:27 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/18 21:42:40 visual_prompt]: Epoch 24 / 100: avg data time: 2.32e-01, avg batch time: 0.6360, average train loss: 1.6885
[09/18 21:42:48 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1431, average loss: 1.8992
[09/18 21:42:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 29.00	top5: 99.50	
[09/18 21:43:11 visual_prompt]: 	Test 100/1152. loss: 2.239, 0.1825 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 21:43:30 visual_prompt]: 	Test 200/1152. loss: 1.705, 0.2023 s / batch. (data: 2.02e-02)max mem: 17.22454 GB 
[09/18 21:43:50 visual_prompt]: 	Test 300/1152. loss: 1.935, 0.1917 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 21:44:09 visual_prompt]: 	Test 400/1152. loss: 1.931, 0.1975 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 21:44:29 visual_prompt]: 	Test 500/1152. loss: 1.885, 0.1828 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:44:48 visual_prompt]: 	Test 600/1152. loss: 1.859, 0.2120 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 21:45:08 visual_prompt]: 	Test 700/1152. loss: 2.067, 0.1912 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/18 21:45:27 visual_prompt]: 	Test 800/1152. loss: 1.995, 0.2074 s / batch. (data: 2.27e-02)max mem: 17.22454 GB 
[09/18 21:45:47 visual_prompt]: 	Test 900/1152. loss: 1.894, 0.2118 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 21:46:06 visual_prompt]: 	Test 1000/1152. loss: 1.698, 0.1952 s / batch. (data: 2.91e-05)max mem: 17.22454 GB 
[09/18 21:46:26 visual_prompt]: 	Test 1100/1152. loss: 1.987, 0.1828 s / batch. (data: 8.94e-05)max mem: 17.22454 GB 
[09/18 21:46:40 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1939, average loss: 1.9174
[09/18 21:46:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 29.31	top5: 99.47	
[09/18 21:46:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/18 21:46:54 visual_prompt]: Epoch 25 / 100: avg data time: 2.34e-01, avg batch time: 0.6379, average train loss: 1.7484
[09/18 21:47:01 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1421, average loss: 1.3566
[09/18 21:47:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.00	top5: 100.00	
[09/18 21:47:24 visual_prompt]: 	Test 100/1152. loss: 1.653, 0.1825 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 21:47:44 visual_prompt]: 	Test 200/1152. loss: 1.307, 0.2195 s / batch. (data: 3.17e-02)max mem: 17.22454 GB 
[09/18 21:48:03 visual_prompt]: 	Test 300/1152. loss: 1.661, 0.2017 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 21:48:23 visual_prompt]: 	Test 400/1152. loss: 1.320, 0.1826 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:48:42 visual_prompt]: 	Test 500/1152. loss: 1.543, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 21:49:02 visual_prompt]: 	Test 600/1152. loss: 1.522, 0.2274 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 21:49:21 visual_prompt]: 	Test 700/1152. loss: 1.358, 0.2077 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 21:49:41 visual_prompt]: 	Test 800/1152. loss: 1.462, 0.2063 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 21:50:00 visual_prompt]: 	Test 900/1152. loss: 1.410, 0.1916 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 21:50:20 visual_prompt]: 	Test 1000/1152. loss: 1.476, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 21:50:39 visual_prompt]: 	Test 1100/1152. loss: 1.447, 0.1967 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 21:50:53 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1937, average loss: 1.4804
[09/18 21:50:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 38.99	top5: 99.99	
[09/18 21:50:54 visual_prompt]: Best epoch 25: best metric: 0.450
[09/18 21:50:54 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/18 21:51:07 visual_prompt]: Epoch 26 / 100: avg data time: 2.40e-01, avg batch time: 0.6388, average train loss: 1.3442
[09/18 21:51:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1437, average loss: 1.7987
[09/18 21:51:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 37.00	top5: 98.00	
[09/18 21:51:37 visual_prompt]: 	Test 100/1152. loss: 1.900, 0.1824 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 21:51:57 visual_prompt]: 	Test 200/1152. loss: 1.714, 0.1828 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 21:52:16 visual_prompt]: 	Test 300/1152. loss: 1.697, 0.1820 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 21:52:35 visual_prompt]: 	Test 400/1152. loss: 1.943, 0.1835 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/18 21:52:55 visual_prompt]: 	Test 500/1152. loss: 2.044, 0.1825 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 21:53:14 visual_prompt]: 	Test 600/1152. loss: 1.989, 0.1821 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 21:53:34 visual_prompt]: 	Test 700/1152. loss: 2.032, 0.2186 s / batch. (data: 3.65e-02)max mem: 17.22454 GB 
[09/18 21:53:53 visual_prompt]: 	Test 800/1152. loss: 1.721, 0.1833 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 21:54:13 visual_prompt]: 	Test 900/1152. loss: 2.167, 0.1840 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 21:54:32 visual_prompt]: 	Test 1000/1152. loss: 2.004, 0.1826 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/18 21:54:52 visual_prompt]: 	Test 1100/1152. loss: 1.932, 0.2099 s / batch. (data: 2.72e-02)max mem: 17.22454 GB 
[09/18 21:55:06 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1936, average loss: 1.8680
[09/18 21:55:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 35.43	top5: 98.40	
[09/18 21:55:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/18 21:55:20 visual_prompt]: Epoch 27 / 100: avg data time: 2.36e-01, avg batch time: 0.6389, average train loss: 1.6072
[09/18 21:55:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1425, average loss: 1.1226
[09/18 21:55:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.50	top5: 100.00	
[09/18 21:55:50 visual_prompt]: 	Test 100/1152. loss: 1.106, 0.1864 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 21:56:10 visual_prompt]: 	Test 200/1152. loss: 1.128, 0.1827 s / batch. (data: 9.66e-05)max mem: 17.22454 GB 
[09/18 21:56:29 visual_prompt]: 	Test 300/1152. loss: 1.155, 0.1823 s / batch. (data: 2.69e-05)max mem: 17.22454 GB 
[09/18 21:56:49 visual_prompt]: 	Test 400/1152. loss: 1.242, 0.2375 s / batch. (data: 4.19e-02)max mem: 17.22454 GB 
[09/18 21:57:08 visual_prompt]: 	Test 500/1152. loss: 1.133, 0.1935 s / batch. (data: 9.94e-03)max mem: 17.22454 GB 
[09/18 21:57:28 visual_prompt]: 	Test 600/1152. loss: 1.153, 0.2066 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 21:57:47 visual_prompt]: 	Test 700/1152. loss: 1.148, 0.1822 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 21:58:07 visual_prompt]: 	Test 800/1152. loss: 1.225, 0.1996 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 21:58:27 visual_prompt]: 	Test 900/1152. loss: 1.244, 0.2082 s / batch. (data: 2.60e-02)max mem: 17.22454 GB 
[09/18 21:58:46 visual_prompt]: 	Test 1000/1152. loss: 1.250, 0.1825 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 21:59:05 visual_prompt]: 	Test 1100/1152. loss: 1.238, 0.2036 s / batch. (data: 2.19e-02)max mem: 17.22454 GB 
[09/18 21:59:20 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1940, average loss: 1.1750
[09/18 21:59:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 47.33	top5: 100.00	
[09/18 21:59:20 visual_prompt]: Best epoch 27: best metric: 0.525
[09/18 21:59:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/18 21:59:33 visual_prompt]: Epoch 28 / 100: avg data time: 2.36e-01, avg batch time: 0.6366, average train loss: 1.1864
[09/18 21:59:41 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1430, average loss: 1.3212
[09/18 21:59:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.00	top5: 100.00	
[09/18 22:00:04 visual_prompt]: 	Test 100/1152. loss: 1.573, 0.2020 s / batch. (data: 2.04e-02)max mem: 17.22454 GB 
[09/18 22:00:23 visual_prompt]: 	Test 200/1152. loss: 1.246, 0.1826 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 22:00:43 visual_prompt]: 	Test 300/1152. loss: 1.165, 0.1910 s / batch. (data: 9.36e-03)max mem: 17.22454 GB 
[09/18 22:01:02 visual_prompt]: 	Test 400/1152. loss: 1.295, 0.1963 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 22:01:22 visual_prompt]: 	Test 500/1152. loss: 1.868, 0.1825 s / batch. (data: 2.65e-05)max mem: 17.22454 GB 
[09/18 22:01:41 visual_prompt]: 	Test 600/1152. loss: 1.345, 0.1832 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 22:02:01 visual_prompt]: 	Test 700/1152. loss: 1.262, 0.1824 s / batch. (data: 8.99e-05)max mem: 17.22454 GB 
[09/18 22:02:20 visual_prompt]: 	Test 800/1152. loss: 1.225, 0.1932 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 22:02:40 visual_prompt]: 	Test 900/1152. loss: 1.411, 0.1961 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 22:02:59 visual_prompt]: 	Test 1000/1152. loss: 1.461, 0.2081 s / batch. (data: 2.55e-02)max mem: 17.22454 GB 
[09/18 22:03:19 visual_prompt]: 	Test 1100/1152. loss: 1.179, 0.1828 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/18 22:03:33 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1941, average loss: 1.3528
[09/18 22:03:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 46.58	top5: 99.96	
[09/18 22:03:34 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/18 22:03:47 visual_prompt]: Epoch 29 / 100: avg data time: 2.28e-01, avg batch time: 0.6310, average train loss: 1.3117
[09/18 22:03:55 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1420, average loss: 1.1143
[09/18 22:03:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 57.00	top5: 100.00	
[09/18 22:04:17 visual_prompt]: 	Test 100/1152. loss: 1.270, 0.1945 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 22:04:37 visual_prompt]: 	Test 200/1152. loss: 1.366, 0.1834 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 22:04:56 visual_prompt]: 	Test 300/1152. loss: 1.556, 0.1821 s / batch. (data: 3.96e-05)max mem: 17.22454 GB 
[09/18 22:05:16 visual_prompt]: 	Test 400/1152. loss: 1.310, 0.1873 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 22:05:35 visual_prompt]: 	Test 500/1152. loss: 1.154, 0.1854 s / batch. (data: 3.13e-03)max mem: 17.22454 GB 
[09/18 22:05:55 visual_prompt]: 	Test 600/1152. loss: 1.410, 0.1845 s / batch. (data: 2.13e-03)max mem: 17.22454 GB 
[09/18 22:06:14 visual_prompt]: 	Test 700/1152. loss: 1.139, 0.1947 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 22:06:34 visual_prompt]: 	Test 800/1152. loss: 1.308, 0.2009 s / batch. (data: 7.61e-03)max mem: 17.22454 GB 
[09/18 22:06:53 visual_prompt]: 	Test 900/1152. loss: 1.569, 0.1832 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 22:07:13 visual_prompt]: 	Test 1000/1152. loss: 1.607, 0.1836 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 22:07:32 visual_prompt]: 	Test 1100/1152. loss: 1.238, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 22:07:47 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1939, average loss: 1.3398
[09/18 22:07:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 46.70	top5: 100.00	
[09/18 22:07:47 visual_prompt]: Best epoch 29: best metric: 0.570
[09/18 22:07:47 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/18 22:08:00 visual_prompt]: Epoch 30 / 100: avg data time: 2.42e-01, avg batch time: 0.6414, average train loss: 1.2348
[09/18 22:08:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1439, average loss: 1.2749
[09/18 22:08:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.00	top5: 100.00	
[09/18 22:08:31 visual_prompt]: 	Test 100/1152. loss: 1.472, 0.1979 s / batch. (data: 1.63e-02)max mem: 17.22454 GB 
[09/18 22:08:50 visual_prompt]: 	Test 200/1152. loss: 1.194, 0.1956 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 22:09:10 visual_prompt]: 	Test 300/1152. loss: 1.486, 0.1825 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:09:29 visual_prompt]: 	Test 400/1152. loss: 1.195, 0.1826 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:09:49 visual_prompt]: 	Test 500/1152. loss: 1.070, 0.2065 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 22:10:08 visual_prompt]: 	Test 600/1152. loss: 1.414, 0.2103 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 22:10:28 visual_prompt]: 	Test 700/1152. loss: 1.209, 0.1943 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 22:10:47 visual_prompt]: 	Test 800/1152. loss: 1.380, 0.2270 s / batch. (data: 4.57e-02)max mem: 17.22454 GB 
[09/18 22:11:07 visual_prompt]: 	Test 900/1152. loss: 1.245, 0.1836 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 22:11:26 visual_prompt]: 	Test 1000/1152. loss: 1.368, 0.1957 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 22:11:46 visual_prompt]: 	Test 1100/1152. loss: 1.228, 0.1962 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 22:12:00 visual_prompt]: Inference (test):avg data time: 8.21e-03, avg batch time: 0.1942, average loss: 1.3348
[09/18 22:12:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 49.16	top5: 100.00	
[09/18 22:12:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/18 22:12:14 visual_prompt]: Epoch 31 / 100: avg data time: 2.35e-01, avg batch time: 0.6360, average train loss: 1.3630
[09/18 22:12:21 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1420, average loss: 2.0458
[09/18 22:12:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.00	top5: 91.00	
[09/18 22:12:44 visual_prompt]: 	Test 100/1152. loss: 2.072, 0.2005 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 22:13:04 visual_prompt]: 	Test 200/1152. loss: 2.186, 0.1964 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 22:13:23 visual_prompt]: 	Test 300/1152. loss: 2.573, 0.1826 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 22:13:43 visual_prompt]: 	Test 400/1152. loss: 1.876, 0.1870 s / batch. (data: 5.20e-03)max mem: 17.22454 GB 
[09/18 22:14:02 visual_prompt]: 	Test 500/1152. loss: 1.908, 0.1958 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 22:14:22 visual_prompt]: 	Test 600/1152. loss: 2.109, 0.2079 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/18 22:14:42 visual_prompt]: 	Test 700/1152. loss: 2.389, 0.2141 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 22:15:01 visual_prompt]: 	Test 800/1152. loss: 2.249, 0.1957 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 22:15:21 visual_prompt]: 	Test 900/1152. loss: 2.407, 0.1966 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 22:15:40 visual_prompt]: 	Test 1000/1152. loss: 2.744, 0.1826 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:16:00 visual_prompt]: 	Test 1100/1152. loss: 1.788, 0.1984 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 22:16:14 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1946, average loss: 2.1074
[09/18 22:16:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.78	top5: 91.06	
[09/18 22:16:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/18 22:16:28 visual_prompt]: Epoch 32 / 100: avg data time: 2.31e-01, avg batch time: 0.6330, average train loss: 1.3669
[09/18 22:16:35 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1420, average loss: 1.0684
[09/18 22:16:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 55.50	top5: 100.00	
[09/18 22:16:58 visual_prompt]: 	Test 100/1152. loss: 0.945, 0.1823 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 22:17:18 visual_prompt]: 	Test 200/1152. loss: 1.112, 0.1831 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 22:17:37 visual_prompt]: 	Test 300/1152. loss: 1.142, 0.1974 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 22:17:57 visual_prompt]: 	Test 400/1152. loss: 1.181, 0.1924 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/18 22:18:16 visual_prompt]: 	Test 500/1152. loss: 0.953, 0.1878 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 22:18:36 visual_prompt]: 	Test 600/1152. loss: 1.128, 0.1831 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 22:18:55 visual_prompt]: 	Test 700/1152. loss: 0.987, 0.1830 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 22:19:15 visual_prompt]: 	Test 800/1152. loss: 1.178, 0.1978 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/18 22:19:34 visual_prompt]: 	Test 900/1152. loss: 1.256, 0.2024 s / batch. (data: 1.81e-02)max mem: 17.22454 GB 
[09/18 22:19:54 visual_prompt]: 	Test 1000/1152. loss: 1.179, 0.1825 s / batch. (data: 3.70e-05)max mem: 17.22454 GB 
[09/18 22:20:13 visual_prompt]: 	Test 1100/1152. loss: 1.114, 0.1922 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:20:28 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1941, average loss: 1.1451
[09/18 22:20:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 49.19	top5: 100.00	
[09/18 22:20:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/18 22:20:41 visual_prompt]: Epoch 33 / 100: avg data time: 2.40e-01, avg batch time: 0.6423, average train loss: 1.4292
[09/18 22:20:49 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1423, average loss: 1.6187
[09/18 22:20:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 39.00	top5: 94.50	
[09/18 22:21:12 visual_prompt]: 	Test 100/1152. loss: 1.744, 0.2172 s / batch. (data: 3.53e-02)max mem: 17.22454 GB 
[09/18 22:21:31 visual_prompt]: 	Test 200/1152. loss: 1.605, 0.2103 s / batch. (data: 2.85e-02)max mem: 17.22454 GB 
[09/18 22:21:50 visual_prompt]: 	Test 300/1152. loss: 2.142, 0.1963 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 22:22:10 visual_prompt]: 	Test 400/1152. loss: 1.499, 0.1986 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 22:22:30 visual_prompt]: 	Test 500/1152. loss: 1.541, 0.1829 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 22:22:49 visual_prompt]: 	Test 600/1152. loss: 1.794, 0.1954 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 22:23:09 visual_prompt]: 	Test 700/1152. loss: 1.568, 0.1831 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 22:23:28 visual_prompt]: 	Test 800/1152. loss: 1.649, 0.1965 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 22:23:48 visual_prompt]: 	Test 900/1152. loss: 1.626, 0.1962 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 22:24:07 visual_prompt]: 	Test 1000/1152. loss: 1.827, 0.2019 s / batch. (data: 9.23e-03)max mem: 17.22454 GB 
[09/18 22:24:27 visual_prompt]: 	Test 1100/1152. loss: 1.496, 0.1823 s / batch. (data: 3.15e-05)max mem: 17.22454 GB 
[09/18 22:24:41 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1944, average loss: 1.6963
[09/18 22:24:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.74	top5: 93.67	
[09/18 22:24:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/18 22:24:55 visual_prompt]: Epoch 34 / 100: avg data time: 2.38e-01, avg batch time: 0.6398, average train loss: 1.4822
[09/18 22:25:02 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1429, average loss: 1.1126
[09/18 22:25:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.00	top5: 100.00	
[09/18 22:25:25 visual_prompt]: 	Test 100/1152. loss: 1.259, 0.2062 s / batch. (data: 2.45e-02)max mem: 17.22454 GB 
[09/18 22:25:45 visual_prompt]: 	Test 200/1152. loss: 1.277, 0.1876 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 22:26:04 visual_prompt]: 	Test 300/1152. loss: 1.230, 0.1902 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 22:26:24 visual_prompt]: 	Test 400/1152. loss: 1.197, 0.1958 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 22:26:43 visual_prompt]: 	Test 500/1152. loss: 1.300, 0.1833 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:27:03 visual_prompt]: 	Test 600/1152. loss: 1.468, 0.2066 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 22:27:22 visual_prompt]: 	Test 700/1152. loss: 1.256, 0.1838 s / batch. (data: 4.27e-05)max mem: 17.22454 GB 
[09/18 22:27:42 visual_prompt]: 	Test 800/1152. loss: 1.249, 0.1831 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 22:28:01 visual_prompt]: 	Test 900/1152. loss: 1.306, 0.1841 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 22:28:21 visual_prompt]: 	Test 1000/1152. loss: 1.220, 0.1850 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 22:28:40 visual_prompt]: 	Test 1100/1152. loss: 1.166, 0.1929 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/18 22:28:55 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1941, average loss: 1.2147
[09/18 22:28:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 47.32	top5: 99.99	
[09/18 22:28:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/18 22:29:08 visual_prompt]: Epoch 35 / 100: avg data time: 2.34e-01, avg batch time: 0.6416, average train loss: 1.2043
[09/18 22:29:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1421, average loss: 1.1339
[09/18 22:29:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.00	top5: 100.00	
[09/18 22:29:39 visual_prompt]: 	Test 100/1152. loss: 1.277, 0.2088 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 22:29:58 visual_prompt]: 	Test 200/1152. loss: 1.298, 0.2027 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 22:30:17 visual_prompt]: 	Test 300/1152. loss: 1.462, 0.1839 s / batch. (data: 9.78e-05)max mem: 17.22454 GB 
[09/18 22:30:37 visual_prompt]: 	Test 400/1152. loss: 1.109, 0.2086 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 22:30:56 visual_prompt]: 	Test 500/1152. loss: 1.010, 0.1830 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 22:31:16 visual_prompt]: 	Test 600/1152. loss: 1.479, 0.2077 s / batch. (data: 9.27e-03)max mem: 17.22454 GB 
[09/18 22:31:36 visual_prompt]: 	Test 700/1152. loss: 0.927, 0.2063 s / batch. (data: 2.43e-02)max mem: 17.22454 GB 
[09/18 22:31:55 visual_prompt]: 	Test 800/1152. loss: 1.192, 0.2207 s / batch. (data: 3.89e-02)max mem: 17.22454 GB 
[09/18 22:32:15 visual_prompt]: 	Test 900/1152. loss: 1.374, 0.1971 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 22:32:34 visual_prompt]: 	Test 1000/1152. loss: 1.240, 0.1830 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 22:32:53 visual_prompt]: 	Test 1100/1152. loss: 1.241, 0.1947 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 22:33:08 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1937, average loss: 1.2437
[09/18 22:33:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.45	top5: 99.97	
[09/18 22:33:08 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/18 22:33:22 visual_prompt]: Epoch 36 / 100: avg data time: 2.36e-01, avg batch time: 0.6413, average train loss: 1.0006
[09/18 22:33:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1426, average loss: 0.9697
[09/18 22:33:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.00	top5: 100.00	
[09/18 22:33:52 visual_prompt]: 	Test 100/1152. loss: 1.280, 0.1961 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 22:34:12 visual_prompt]: 	Test 200/1152. loss: 1.414, 0.2029 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 22:34:31 visual_prompt]: 	Test 300/1152. loss: 0.971, 0.1823 s / batch. (data: 4.65e-05)max mem: 17.22454 GB 
[09/18 22:34:51 visual_prompt]: 	Test 400/1152. loss: 1.009, 0.2021 s / batch. (data: 5.58e-04)max mem: 17.22454 GB 
[09/18 22:35:10 visual_prompt]: 	Test 500/1152. loss: 1.221, 0.1823 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 22:35:30 visual_prompt]: 	Test 600/1152. loss: 0.983, 0.1877 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 22:35:49 visual_prompt]: 	Test 700/1152. loss: 1.020, 0.1837 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 22:36:09 visual_prompt]: 	Test 800/1152. loss: 0.930, 0.2235 s / batch. (data: 2.67e-02)max mem: 17.22454 GB 
[09/18 22:36:28 visual_prompt]: 	Test 900/1152. loss: 1.116, 0.1949 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 22:36:48 visual_prompt]: 	Test 1000/1152. loss: 1.151, 0.2019 s / batch. (data: 9.09e-03)max mem: 17.22454 GB 
[09/18 22:37:07 visual_prompt]: 	Test 1100/1152. loss: 0.616, 0.1820 s / batch. (data: 4.79e-05)max mem: 17.22454 GB 
[09/18 22:37:22 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1942, average loss: 1.0300
[09/18 22:37:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.69	top5: 99.99	
[09/18 22:37:22 visual_prompt]: Best epoch 36: best metric: 0.670
[09/18 22:37:22 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/18 22:37:35 visual_prompt]: Epoch 37 / 100: avg data time: 2.32e-01, avg batch time: 0.6333, average train loss: 0.9611
[09/18 22:37:43 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1424, average loss: 1.2490
[09/18 22:37:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 48.50	top5: 100.00	
[09/18 22:38:06 visual_prompt]: 	Test 100/1152. loss: 1.632, 0.1921 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 22:38:25 visual_prompt]: 	Test 200/1152. loss: 1.526, 0.1847 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 22:38:45 visual_prompt]: 	Test 300/1152. loss: 1.808, 0.2081 s / batch. (data: 2.60e-02)max mem: 17.22454 GB 
[09/18 22:39:04 visual_prompt]: 	Test 400/1152. loss: 1.280, 0.1927 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 22:39:24 visual_prompt]: 	Test 500/1152. loss: 1.302, 0.1823 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 22:39:44 visual_prompt]: 	Test 600/1152. loss: 1.657, 0.1830 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 22:40:03 visual_prompt]: 	Test 700/1152. loss: 1.260, 0.1951 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 22:40:23 visual_prompt]: 	Test 800/1152. loss: 1.484, 0.2079 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 22:40:42 visual_prompt]: 	Test 900/1152. loss: 1.543, 0.1895 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 22:41:02 visual_prompt]: 	Test 1000/1152. loss: 1.489, 0.1957 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 22:41:21 visual_prompt]: 	Test 1100/1152. loss: 1.341, 0.1968 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 22:41:35 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1941, average loss: 1.4746
[09/18 22:41:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 43.91	top5: 99.72	
[09/18 22:41:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/18 22:41:49 visual_prompt]: Epoch 38 / 100: avg data time: 2.35e-01, avg batch time: 0.6416, average train loss: 1.1734
[09/18 22:41:56 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1423, average loss: 0.9725
[09/18 22:41:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.00	top5: 100.00	
[09/18 22:42:19 visual_prompt]: 	Test 100/1152. loss: 0.932, 0.1820 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 22:42:39 visual_prompt]: 	Test 200/1152. loss: 1.138, 0.1958 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 22:42:58 visual_prompt]: 	Test 300/1152. loss: 1.210, 0.2052 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 22:43:18 visual_prompt]: 	Test 400/1152. loss: 1.067, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 22:43:37 visual_prompt]: 	Test 500/1152. loss: 0.880, 0.1961 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 22:43:57 visual_prompt]: 	Test 600/1152. loss: 1.104, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 22:44:17 visual_prompt]: 	Test 700/1152. loss: 0.975, 0.1828 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 22:44:36 visual_prompt]: 	Test 800/1152. loss: 1.059, 0.2086 s / batch. (data: 2.64e-02)max mem: 17.22454 GB 
[09/18 22:44:56 visual_prompt]: 	Test 900/1152. loss: 0.908, 0.1929 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 22:45:15 visual_prompt]: 	Test 1000/1152. loss: 0.938, 0.2000 s / batch. (data: 1.78e-02)max mem: 17.22454 GB 
[09/18 22:45:35 visual_prompt]: 	Test 1100/1152. loss: 1.066, 0.1830 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 22:45:49 visual_prompt]: Inference (test):avg data time: 8.88e-03, avg batch time: 0.1947, average loss: 1.0557
[09/18 22:45:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.71	top5: 100.00	
[09/18 22:45:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/18 22:46:03 visual_prompt]: Epoch 39 / 100: avg data time: 2.37e-01, avg batch time: 0.6364, average train loss: 0.9978
[09/18 22:46:10 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1421, average loss: 1.2056
[09/18 22:46:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.00	top5: 100.00	
[09/18 22:46:33 visual_prompt]: 	Test 100/1152. loss: 1.513, 0.1928 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 22:46:53 visual_prompt]: 	Test 200/1152. loss: 1.278, 0.2205 s / batch. (data: 3.91e-02)max mem: 17.22454 GB 
[09/18 22:47:12 visual_prompt]: 	Test 300/1152. loss: 1.384, 0.2207 s / batch. (data: 8.14e-03)max mem: 17.22454 GB 
[09/18 22:47:31 visual_prompt]: 	Test 400/1152. loss: 1.094, 0.1894 s / batch. (data: 3.19e-05)max mem: 17.22454 GB 
[09/18 22:47:51 visual_prompt]: 	Test 500/1152. loss: 1.126, 0.1916 s / batch. (data: 9.08e-03)max mem: 17.22454 GB 
[09/18 22:48:10 visual_prompt]: 	Test 600/1152. loss: 1.491, 0.2054 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:48:30 visual_prompt]: 	Test 700/1152. loss: 1.279, 0.1958 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 22:48:49 visual_prompt]: 	Test 800/1152. loss: 1.270, 0.1827 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 22:49:09 visual_prompt]: 	Test 900/1152. loss: 1.799, 0.1967 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 22:49:28 visual_prompt]: 	Test 1000/1152. loss: 1.363, 0.2087 s / batch. (data: 2.23e-02)max mem: 17.22454 GB 
[09/18 22:49:48 visual_prompt]: 	Test 1100/1152. loss: 1.127, 0.1833 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 22:50:03 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1939, average loss: 1.2533
[09/18 22:50:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.64	top5: 99.99	
[09/18 22:50:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/18 22:50:16 visual_prompt]: Epoch 40 / 100: avg data time: 2.26e-01, avg batch time: 0.6295, average train loss: 0.9213
[09/18 22:50:23 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1422, average loss: 0.8219
[09/18 22:50:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.50	top5: 100.00	
[09/18 22:50:46 visual_prompt]: 	Test 100/1152. loss: 0.863, 0.1823 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 22:51:06 visual_prompt]: 	Test 200/1152. loss: 0.800, 0.1927 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 22:51:25 visual_prompt]: 	Test 300/1152. loss: 0.959, 0.1967 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 22:51:45 visual_prompt]: 	Test 400/1152. loss: 0.918, 0.1844 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 22:52:04 visual_prompt]: 	Test 500/1152. loss: 1.078, 0.1828 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 22:52:24 visual_prompt]: 	Test 600/1152. loss: 1.110, 0.1860 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 22:52:43 visual_prompt]: 	Test 700/1152. loss: 1.057, 0.1827 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 22:53:03 visual_prompt]: 	Test 800/1152. loss: 0.723, 0.2115 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 22:53:22 visual_prompt]: 	Test 900/1152. loss: 0.957, 0.1978 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/18 22:53:42 visual_prompt]: 	Test 1000/1152. loss: 1.034, 0.2126 s / batch. (data: 2.52e-02)max mem: 17.22454 GB 
[09/18 22:54:01 visual_prompt]: 	Test 1100/1152. loss: 0.788, 0.1967 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 22:54:16 visual_prompt]: Inference (test):avg data time: 8.39e-03, avg batch time: 0.1939, average loss: 0.9773
[09/18 22:54:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.49	top5: 99.93	
[09/18 22:54:16 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/18 22:54:29 visual_prompt]: Epoch 41 / 100: avg data time: 2.34e-01, avg batch time: 0.6388, average train loss: 1.0343
[09/18 22:54:37 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1422, average loss: 1.5212
[09/18 22:54:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 49.00	top5: 100.00	
[09/18 22:55:00 visual_prompt]: 	Test 100/1152. loss: 1.764, 0.1817 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 22:55:19 visual_prompt]: 	Test 200/1152. loss: 1.261, 0.1987 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 22:55:39 visual_prompt]: 	Test 300/1152. loss: 1.422, 0.2141 s / batch. (data: 4.72e-05)max mem: 17.22454 GB 
[09/18 22:55:58 visual_prompt]: 	Test 400/1152. loss: 1.652, 0.1985 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 22:56:18 visual_prompt]: 	Test 500/1152. loss: 1.366, 0.1913 s / batch. (data: 3.00e-05)max mem: 17.22454 GB 
[09/18 22:56:37 visual_prompt]: 	Test 600/1152. loss: 1.505, 0.1964 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 22:56:57 visual_prompt]: 	Test 700/1152. loss: 1.541, 0.1951 s / batch. (data: 8.49e-05)max mem: 17.22454 GB 
[09/18 22:57:16 visual_prompt]: 	Test 800/1152. loss: 1.616, 0.1833 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 22:57:36 visual_prompt]: 	Test 900/1152. loss: 1.368, 0.1867 s / batch. (data: 9.87e-05)max mem: 17.22454 GB 
[09/18 22:57:55 visual_prompt]: 	Test 1000/1152. loss: 1.483, 0.1827 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:58:15 visual_prompt]: 	Test 1100/1152. loss: 1.405, 0.1822 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:58:29 visual_prompt]: Inference (test):avg data time: 8.56e-03, avg batch time: 0.1946, average loss: 1.4745
[09/18 22:58:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 49.02	top5: 99.69	
[09/18 22:58:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/18 22:58:43 visual_prompt]: Epoch 42 / 100: avg data time: 2.31e-01, avg batch time: 0.6328, average train loss: 1.1284
[09/18 22:58:50 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1435, average loss: 1.6525
[09/18 22:58:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 34.00	top5: 99.50	
[09/18 22:59:13 visual_prompt]: 	Test 100/1152. loss: 1.663, 0.1948 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 22:59:33 visual_prompt]: 	Test 200/1152. loss: 1.976, 0.1851 s / batch. (data: 3.17e-03)max mem: 17.22454 GB 
[09/18 22:59:52 visual_prompt]: 	Test 300/1152. loss: 1.971, 0.1816 s / batch. (data: 4.20e-05)max mem: 17.22454 GB 
[09/18 23:00:12 visual_prompt]: 	Test 400/1152. loss: 1.665, 0.1961 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 23:00:31 visual_prompt]: 	Test 500/1152. loss: 1.776, 0.1828 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 23:00:51 visual_prompt]: 	Test 600/1152. loss: 1.636, 0.1828 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 23:01:11 visual_prompt]: 	Test 700/1152. loss: 1.749, 0.1963 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 23:01:30 visual_prompt]: 	Test 800/1152. loss: 1.757, 0.1832 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 23:01:50 visual_prompt]: 	Test 900/1152. loss: 1.749, 0.1970 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 23:02:09 visual_prompt]: 	Test 1000/1152. loss: 1.940, 0.1837 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 23:02:29 visual_prompt]: 	Test 1100/1152. loss: 1.321, 0.1824 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:02:43 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1943, average loss: 1.7225
[09/18 23:02:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.22	top5: 99.72	
[09/18 23:02:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/18 23:02:56 visual_prompt]: Epoch 43 / 100: avg data time: 2.27e-01, avg batch time: 0.6328, average train loss: 1.1512
[09/18 23:03:04 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1421, average loss: 0.9163
[09/18 23:03:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 55.50	top5: 100.00	
[09/18 23:03:27 visual_prompt]: 	Test 100/1152. loss: 1.138, 0.1856 s / batch. (data: 8.56e-05)max mem: 17.22454 GB 
[09/18 23:03:47 visual_prompt]: 	Test 200/1152. loss: 1.194, 0.1824 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 23:04:06 visual_prompt]: 	Test 300/1152. loss: 1.223, 0.1973 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 23:04:25 visual_prompt]: 	Test 400/1152. loss: 0.988, 0.2079 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 23:04:45 visual_prompt]: 	Test 500/1152. loss: 1.193, 0.1838 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/18 23:05:04 visual_prompt]: 	Test 600/1152. loss: 1.112, 0.1970 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/18 23:05:24 visual_prompt]: 	Test 700/1152. loss: 1.001, 0.2240 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 23:05:43 visual_prompt]: 	Test 800/1152. loss: 0.869, 0.1961 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 23:06:03 visual_prompt]: 	Test 900/1152. loss: 1.145, 0.2012 s / batch. (data: 4.01e-05)max mem: 17.22454 GB 
[09/18 23:06:22 visual_prompt]: 	Test 1000/1152. loss: 1.191, 0.1825 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:06:42 visual_prompt]: 	Test 1100/1152. loss: 1.169, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 23:06:56 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1941, average loss: 1.1561
[09/18 23:06:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.33	top5: 99.77	
[09/18 23:06:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/18 23:07:10 visual_prompt]: Epoch 44 / 100: avg data time: 2.42e-01, avg batch time: 0.6433, average train loss: 1.1100
[09/18 23:07:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1421, average loss: 0.8877
[09/18 23:07:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 56.50	top5: 100.00	
[09/18 23:07:40 visual_prompt]: 	Test 100/1152. loss: 1.202, 0.1889 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 23:08:00 visual_prompt]: 	Test 200/1152. loss: 1.038, 0.1824 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 23:08:19 visual_prompt]: 	Test 300/1152. loss: 0.885, 0.1964 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/18 23:08:39 visual_prompt]: 	Test 400/1152. loss: 0.898, 0.2244 s / batch. (data: 2.48e-02)max mem: 17.22454 GB 
[09/18 23:08:58 visual_prompt]: 	Test 500/1152. loss: 1.056, 0.2221 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/18 23:09:18 visual_prompt]: 	Test 600/1152. loss: 0.999, 0.1830 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 23:09:37 visual_prompt]: 	Test 700/1152. loss: 0.981, 0.2020 s / batch. (data: 1.96e-02)max mem: 17.22454 GB 
[09/18 23:09:57 visual_prompt]: 	Test 800/1152. loss: 0.747, 0.1830 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:10:16 visual_prompt]: 	Test 900/1152. loss: 0.887, 0.1826 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 23:10:36 visual_prompt]: 	Test 1000/1152. loss: 0.897, 0.2471 s / batch. (data: 3.70e-02)max mem: 17.22454 GB 
[09/18 23:10:56 visual_prompt]: 	Test 1100/1152. loss: 0.825, 0.1829 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 23:11:10 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1944, average loss: 0.9774
[09/18 23:11:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 54.76	top5: 100.00	
[09/18 23:11:10 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/18 23:11:24 visual_prompt]: Epoch 45 / 100: avg data time: 2.34e-01, avg batch time: 0.6356, average train loss: 0.9796
[09/18 23:11:31 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1422, average loss: 1.1139
[09/18 23:11:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.00	top5: 100.00	
[09/18 23:11:54 visual_prompt]: 	Test 100/1152. loss: 0.950, 0.1820 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 23:12:13 visual_prompt]: 	Test 200/1152. loss: 1.200, 0.1826 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 23:12:33 visual_prompt]: 	Test 300/1152. loss: 1.319, 0.1823 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 23:12:52 visual_prompt]: 	Test 400/1152. loss: 1.096, 0.1877 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 23:13:12 visual_prompt]: 	Test 500/1152. loss: 0.898, 0.2060 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 23:13:31 visual_prompt]: 	Test 600/1152. loss: 1.076, 0.1945 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 23:13:51 visual_prompt]: 	Test 700/1152. loss: 1.140, 0.1950 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 23:14:10 visual_prompt]: 	Test 800/1152. loss: 1.258, 0.2140 s / batch. (data: 1.70e-02)max mem: 17.22454 GB 
[09/18 23:14:30 visual_prompt]: 	Test 900/1152. loss: 1.351, 0.2207 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/18 23:14:49 visual_prompt]: 	Test 1000/1152. loss: 1.326, 0.2067 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 23:15:08 visual_prompt]: 	Test 1100/1152. loss: 1.153, 0.1929 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/18 23:15:23 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1937, average loss: 1.1982
[09/18 23:15:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 48.36	top5: 100.00	
[09/18 23:15:23 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/18 23:15:37 visual_prompt]: Epoch 46 / 100: avg data time: 2.34e-01, avg batch time: 0.6346, average train loss: 1.0252
[09/18 23:15:44 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1421, average loss: 0.9722
[09/18 23:15:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 60.50	top5: 100.00	
[09/18 23:16:07 visual_prompt]: 	Test 100/1152. loss: 1.017, 0.1946 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 23:16:27 visual_prompt]: 	Test 200/1152. loss: 0.935, 0.1977 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 23:16:46 visual_prompt]: 	Test 300/1152. loss: 1.035, 0.2026 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 23:17:06 visual_prompt]: 	Test 400/1152. loss: 0.986, 0.1959 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 23:17:25 visual_prompt]: 	Test 500/1152. loss: 1.307, 0.1842 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/18 23:17:45 visual_prompt]: 	Test 600/1152. loss: 1.373, 0.2078 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/18 23:18:04 visual_prompt]: 	Test 700/1152. loss: 1.173, 0.1905 s / batch. (data: 4.89e-05)max mem: 17.22454 GB 
[09/18 23:18:24 visual_prompt]: 	Test 800/1152. loss: 0.861, 0.1821 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 23:18:43 visual_prompt]: 	Test 900/1152. loss: 1.340, 0.2082 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/18 23:19:03 visual_prompt]: 	Test 1000/1152. loss: 1.323, 0.1824 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 23:19:22 visual_prompt]: 	Test 1100/1152. loss: 0.937, 0.1835 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 23:19:37 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1943, average loss: 1.1111
[09/18 23:19:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 55.13	top5: 99.96	
[09/18 23:19:37 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/18 23:19:51 visual_prompt]: Epoch 47 / 100: avg data time: 2.40e-01, avg batch time: 0.6416, average train loss: 0.8681
[09/18 23:19:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1422, average loss: 0.8498
[09/18 23:19:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.50	top5: 100.00	
[09/18 23:20:21 visual_prompt]: 	Test 100/1152. loss: 0.954, 0.1954 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 23:20:40 visual_prompt]: 	Test 200/1152. loss: 0.933, 0.2045 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 23:20:59 visual_prompt]: 	Test 300/1152. loss: 0.818, 0.1866 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 23:21:19 visual_prompt]: 	Test 400/1152. loss: 0.815, 0.1947 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 23:21:38 visual_prompt]: 	Test 500/1152. loss: 1.057, 0.1927 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 23:21:58 visual_prompt]: 	Test 600/1152. loss: 1.086, 0.1980 s / batch. (data: 1.62e-02)max mem: 17.22454 GB 
[09/18 23:22:18 visual_prompt]: 	Test 700/1152. loss: 0.878, 0.1829 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 23:22:37 visual_prompt]: 	Test 800/1152. loss: 0.705, 0.1961 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 23:22:57 visual_prompt]: 	Test 900/1152. loss: 0.977, 0.2125 s / batch. (data: 2.48e-02)max mem: 17.22454 GB 
[09/18 23:23:16 visual_prompt]: 	Test 1000/1152. loss: 0.916, 0.1830 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 23:23:36 visual_prompt]: 	Test 1100/1152. loss: 0.878, 0.1823 s / batch. (data: 8.25e-05)max mem: 17.22454 GB 
[09/18 23:23:50 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1940, average loss: 0.9483
[09/18 23:23:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 60.83	top5: 100.00	
[09/18 23:23:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/18 23:24:04 visual_prompt]: Epoch 48 / 100: avg data time: 2.43e-01, avg batch time: 0.6417, average train loss: 0.9286
[09/18 23:24:11 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1418, average loss: 0.8196
[09/18 23:24:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.50	top5: 100.00	
[09/18 23:24:34 visual_prompt]: 	Test 100/1152. loss: 0.874, 0.1821 s / batch. (data: 9.63e-05)max mem: 17.22454 GB 
[09/18 23:24:53 visual_prompt]: 	Test 200/1152. loss: 1.196, 0.1818 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 23:25:13 visual_prompt]: 	Test 300/1152. loss: 1.129, 0.1956 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 23:25:32 visual_prompt]: 	Test 400/1152. loss: 0.790, 0.1828 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 23:25:52 visual_prompt]: 	Test 500/1152. loss: 0.809, 0.1830 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 23:26:12 visual_prompt]: 	Test 600/1152. loss: 1.111, 0.1952 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 23:26:31 visual_prompt]: 	Test 700/1152. loss: 0.834, 0.1999 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 23:26:51 visual_prompt]: 	Test 800/1152. loss: 0.844, 0.1985 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 23:27:10 visual_prompt]: 	Test 900/1152. loss: 1.095, 0.1824 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 23:27:30 visual_prompt]: 	Test 1000/1152. loss: 0.842, 0.2134 s / batch. (data: 2.32e-02)max mem: 17.22454 GB 
[09/18 23:27:49 visual_prompt]: 	Test 1100/1152. loss: 0.987, 0.1829 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 23:28:04 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1944, average loss: 0.9980
[09/18 23:28:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 60.16	top5: 99.98	
[09/18 23:28:04 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/18 23:28:17 visual_prompt]: Epoch 49 / 100: avg data time: 2.38e-01, avg batch time: 0.6397, average train loss: 1.1352
[09/18 23:28:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1420, average loss: 0.9053
[09/18 23:28:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.50	top5: 100.00	
[09/18 23:28:48 visual_prompt]: 	Test 100/1152. loss: 0.955, 0.1818 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 23:29:08 visual_prompt]: 	Test 200/1152. loss: 1.254, 0.1929 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 23:29:27 visual_prompt]: 	Test 300/1152. loss: 0.964, 0.2517 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 23:29:47 visual_prompt]: 	Test 400/1152. loss: 1.121, 0.2082 s / batch. (data: 2.64e-02)max mem: 17.22454 GB 
[09/18 23:30:06 visual_prompt]: 	Test 500/1152. loss: 1.230, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 23:30:26 visual_prompt]: 	Test 600/1152. loss: 1.311, 0.2384 s / batch. (data: 4.70e-02)max mem: 17.22454 GB 
[09/18 23:30:45 visual_prompt]: 	Test 700/1152. loss: 0.898, 0.2009 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/18 23:31:05 visual_prompt]: 	Test 800/1152. loss: 0.904, 0.1880 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 23:31:24 visual_prompt]: 	Test 900/1152. loss: 1.314, 0.1933 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 23:31:44 visual_prompt]: 	Test 1000/1152. loss: 1.057, 0.1988 s / batch. (data: 1.62e-02)max mem: 17.22454 GB 
[09/18 23:32:03 visual_prompt]: 	Test 1100/1152. loss: 0.994, 0.1839 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 23:32:18 visual_prompt]: Inference (test):avg data time: 8.60e-03, avg batch time: 0.1944, average loss: 1.0669
[09/18 23:32:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.25	top5: 99.99	
[09/18 23:32:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/18 23:32:32 visual_prompt]: Epoch 50 / 100: avg data time: 2.40e-01, avg batch time: 0.6419, average train loss: 0.9015
[09/18 23:32:39 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1459, average loss: 0.5644
[09/18 23:32:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.50	top5: 100.00	
[09/18 23:33:02 visual_prompt]: 	Test 100/1152. loss: 0.958, 0.2057 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 23:33:22 visual_prompt]: 	Test 200/1152. loss: 0.840, 0.1969 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/18 23:33:41 visual_prompt]: 	Test 300/1152. loss: 0.932, 0.1932 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 23:34:00 visual_prompt]: 	Test 400/1152. loss: 0.702, 0.1819 s / batch. (data: 3.15e-05)max mem: 17.22454 GB 
[09/18 23:34:20 visual_prompt]: 	Test 500/1152. loss: 0.748, 0.1881 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 23:34:39 visual_prompt]: 	Test 600/1152. loss: 0.979, 0.2019 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:34:59 visual_prompt]: 	Test 700/1152. loss: 0.685, 0.1983 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 23:35:18 visual_prompt]: 	Test 800/1152. loss: 0.600, 0.1974 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 23:35:38 visual_prompt]: 	Test 900/1152. loss: 0.925, 0.1829 s / batch. (data: 9.99e-05)max mem: 17.22454 GB 
[09/18 23:35:57 visual_prompt]: 	Test 1000/1152. loss: 0.778, 0.1827 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 23:36:17 visual_prompt]: 	Test 1100/1152. loss: 0.486, 0.1948 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:36:31 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1937, average loss: 0.8013
[09/18 23:36:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.70	top5: 100.00	
[09/18 23:36:32 visual_prompt]: Best epoch 50: best metric: 0.765
[09/18 23:36:32 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/18 23:36:45 visual_prompt]: Epoch 51 / 100: avg data time: 2.38e-01, avg batch time: 0.6376, average train loss: 0.7739
[09/18 23:36:52 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1423, average loss: 1.0881
[09/18 23:36:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 64.50	top5: 99.50	
[09/18 23:37:15 visual_prompt]: 	Test 100/1152. loss: 1.340, 0.1823 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 23:37:35 visual_prompt]: 	Test 200/1152. loss: 0.743, 0.1827 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 23:37:54 visual_prompt]: 	Test 300/1152. loss: 1.000, 0.1974 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/18 23:38:14 visual_prompt]: 	Test 400/1152. loss: 1.179, 0.1833 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:38:33 visual_prompt]: 	Test 500/1152. loss: 1.302, 0.1825 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 23:38:53 visual_prompt]: 	Test 600/1152. loss: 1.184, 0.1980 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 23:39:12 visual_prompt]: 	Test 700/1152. loss: 1.249, 0.1821 s / batch. (data: 2.91e-05)max mem: 17.22454 GB 
[09/18 23:39:32 visual_prompt]: 	Test 800/1152. loss: 1.099, 0.1954 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 23:39:51 visual_prompt]: 	Test 900/1152. loss: 1.377, 0.2108 s / batch. (data: 2.48e-02)max mem: 17.22454 GB 
[09/18 23:40:10 visual_prompt]: 	Test 1000/1152. loss: 1.189, 0.1887 s / batch. (data: 4.00e-03)max mem: 17.22454 GB 
[09/18 23:40:30 visual_prompt]: 	Test 1100/1152. loss: 1.165, 0.2119 s / batch. (data: 2.98e-02)max mem: 17.22454 GB 
[09/18 23:40:45 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1937, average loss: 1.2071
[09/18 23:40:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 56.08	top5: 99.33	
[09/18 23:40:45 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/18 23:40:58 visual_prompt]: Epoch 52 / 100: avg data time: 2.45e-01, avg batch time: 0.6471, average train loss: 0.7942
[09/18 23:41:06 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1422, average loss: 0.6573
[09/18 23:41:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.50	top5: 100.00	
[09/18 23:41:29 visual_prompt]: 	Test 100/1152. loss: 0.955, 0.1819 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 23:41:48 visual_prompt]: 	Test 200/1152. loss: 0.883, 0.1958 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 23:42:08 visual_prompt]: 	Test 300/1152. loss: 0.816, 0.1989 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 23:42:27 visual_prompt]: 	Test 400/1152. loss: 0.778, 0.2071 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 23:42:47 visual_prompt]: 	Test 500/1152. loss: 0.725, 0.1826 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 23:43:06 visual_prompt]: 	Test 600/1152. loss: 0.875, 0.2107 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 23:43:26 visual_prompt]: 	Test 700/1152. loss: 0.760, 0.1831 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 23:43:45 visual_prompt]: 	Test 800/1152. loss: 0.811, 0.1834 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 23:44:05 visual_prompt]: 	Test 900/1152. loss: 0.976, 0.1825 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 23:44:25 visual_prompt]: 	Test 1000/1152. loss: 0.725, 0.1895 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/18 23:44:44 visual_prompt]: 	Test 1100/1152. loss: 0.789, 0.1959 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/18 23:44:58 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1941, average loss: 0.8454
[09/18 23:44:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.32	top5: 100.00	
[09/18 23:44:59 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/18 23:45:12 visual_prompt]: Epoch 53 / 100: avg data time: 2.41e-01, avg batch time: 0.6444, average train loss: 0.7383
[09/18 23:45:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1421, average loss: 0.7117
[09/18 23:45:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.00	top5: 100.00	
[09/18 23:45:43 visual_prompt]: 	Test 100/1152. loss: 0.960, 0.1818 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 23:46:02 visual_prompt]: 	Test 200/1152. loss: 1.052, 0.1822 s / batch. (data: 8.70e-05)max mem: 17.22454 GB 
[09/18 23:46:22 visual_prompt]: 	Test 300/1152. loss: 0.985, 0.1995 s / batch. (data: 1.71e-02)max mem: 17.22454 GB 
[09/18 23:46:41 visual_prompt]: 	Test 400/1152. loss: 0.788, 0.2184 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 23:47:01 visual_prompt]: 	Test 500/1152. loss: 0.720, 0.1956 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 23:47:20 visual_prompt]: 	Test 600/1152. loss: 1.075, 0.1905 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 23:47:40 visual_prompt]: 	Test 700/1152. loss: 0.817, 0.1833 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 23:47:59 visual_prompt]: 	Test 800/1152. loss: 0.800, 0.1997 s / batch. (data: 1.79e-02)max mem: 17.22454 GB 
[09/18 23:48:19 visual_prompt]: 	Test 900/1152. loss: 0.974, 0.1836 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 23:48:38 visual_prompt]: 	Test 1000/1152. loss: 0.953, 0.1924 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/18 23:48:58 visual_prompt]: 	Test 1100/1152. loss: 0.657, 0.1968 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 23:49:12 visual_prompt]: Inference (test):avg data time: 7.94e-03, avg batch time: 0.1940, average loss: 0.9036
[09/18 23:49:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 62.08	top5: 99.98	
[09/18 23:49:13 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/18 23:49:26 visual_prompt]: Epoch 54 / 100: avg data time: 2.32e-01, avg batch time: 0.6336, average train loss: 0.8320
[09/18 23:49:33 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1423, average loss: 0.5602
[09/18 23:49:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.00	top5: 100.00	
[09/18 23:49:56 visual_prompt]: 	Test 100/1152. loss: 0.582, 0.1823 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:50:15 visual_prompt]: 	Test 200/1152. loss: 0.676, 0.2075 s / batch. (data: 2.60e-02)max mem: 17.22454 GB 
[09/18 23:50:35 visual_prompt]: 	Test 300/1152. loss: 0.676, 0.1819 s / batch. (data: 2.79e-05)max mem: 17.22454 GB 
[09/18 23:50:54 visual_prompt]: 	Test 400/1152. loss: 0.852, 0.1827 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 23:51:14 visual_prompt]: 	Test 500/1152. loss: 0.756, 0.1942 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/18 23:51:34 visual_prompt]: 	Test 600/1152. loss: 0.866, 0.1907 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 23:51:53 visual_prompt]: 	Test 700/1152. loss: 0.646, 0.1957 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/18 23:52:13 visual_prompt]: 	Test 800/1152. loss: 0.773, 0.1935 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 23:52:32 visual_prompt]: 	Test 900/1152. loss: 1.024, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 23:52:52 visual_prompt]: 	Test 1000/1152. loss: 0.937, 0.1958 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/18 23:53:11 visual_prompt]: 	Test 1100/1152. loss: 0.666, 0.2235 s / batch. (data: 4.17e-02)max mem: 17.22454 GB 
[09/18 23:53:26 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1942, average loss: 0.8103
[09/18 23:53:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.71	top5: 99.98	
[09/18 23:53:26 visual_prompt]: Best epoch 54: best metric: 0.790
[09/18 23:53:26 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/18 23:53:40 visual_prompt]: Epoch 55 / 100: avg data time: 2.41e-01, avg batch time: 0.6436, average train loss: 0.6291
[09/18 23:53:47 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1424, average loss: 0.4567
[09/18 23:53:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 81.50	top5: 100.00	
[09/18 23:54:10 visual_prompt]: 	Test 100/1152. loss: 0.860, 0.1939 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 23:54:29 visual_prompt]: 	Test 200/1152. loss: 0.853, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 23:54:49 visual_prompt]: 	Test 300/1152. loss: 1.169, 0.1880 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 23:55:08 visual_prompt]: 	Test 400/1152. loss: 0.685, 0.1918 s / batch. (data: 9.54e-03)max mem: 17.22454 GB 
[09/18 23:55:28 visual_prompt]: 	Test 500/1152. loss: 0.536, 0.1963 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/18 23:55:47 visual_prompt]: 	Test 600/1152. loss: 1.138, 0.1944 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 23:56:07 visual_prompt]: 	Test 700/1152. loss: 0.754, 0.1827 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 23:56:26 visual_prompt]: 	Test 800/1152. loss: 0.662, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/18 23:56:46 visual_prompt]: 	Test 900/1152. loss: 0.967, 0.1828 s / batch. (data: 2.79e-05)max mem: 17.22454 GB 
[09/18 23:57:05 visual_prompt]: 	Test 1000/1152. loss: 0.830, 0.1956 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 23:57:25 visual_prompt]: 	Test 1100/1152. loss: 0.525, 0.2102 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 23:57:39 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1940, average loss: 0.8320
[09/18 23:57:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.21	top5: 99.97	
[09/18 23:57:39 visual_prompt]: Best epoch 55: best metric: 0.815
[09/18 23:57:39 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/18 23:57:53 visual_prompt]: Epoch 56 / 100: avg data time: 2.34e-01, avg batch time: 0.6354, average train loss: 0.6323
[09/18 23:58:00 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1423, average loss: 0.5631
[09/18 23:58:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.00	top5: 100.00	
[09/18 23:58:24 visual_prompt]: 	Test 100/1152. loss: 0.979, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 23:58:43 visual_prompt]: 	Test 200/1152. loss: 0.833, 0.2181 s / batch. (data: 3.61e-02)max mem: 17.22454 GB 
[09/18 23:59:02 visual_prompt]: 	Test 300/1152. loss: 1.006, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 23:59:22 visual_prompt]: 	Test 400/1152. loss: 0.756, 0.2236 s / batch. (data: 2.70e-02)max mem: 17.22454 GB 
[09/18 23:59:41 visual_prompt]: 	Test 500/1152. loss: 0.723, 0.1905 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 00:00:01 visual_prompt]: 	Test 600/1152. loss: 0.922, 0.1833 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 00:00:20 visual_prompt]: 	Test 700/1152. loss: 0.670, 0.1932 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 00:00:40 visual_prompt]: 	Test 800/1152. loss: 0.697, 0.1919 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/19 00:00:59 visual_prompt]: 	Test 900/1152. loss: 0.925, 0.1830 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 00:01:19 visual_prompt]: 	Test 1000/1152. loss: 0.740, 0.2006 s / batch. (data: 1.83e-02)max mem: 17.22454 GB 
[09/19 00:01:38 visual_prompt]: 	Test 1100/1152. loss: 0.542, 0.1827 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 00:01:53 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1941, average loss: 0.8392
[09/19 00:01:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.43	top5: 99.91	
[09/19 00:01:53 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/19 00:02:06 visual_prompt]: Epoch 57 / 100: avg data time: 2.36e-01, avg batch time: 0.6370, average train loss: 0.6507
[09/19 00:02:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1423, average loss: 0.4891
[09/19 00:02:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 80.50	top5: 100.00	
[09/19 00:02:37 visual_prompt]: 	Test 100/1152. loss: 0.730, 0.1821 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 00:02:56 visual_prompt]: 	Test 200/1152. loss: 0.618, 0.1955 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 00:03:15 visual_prompt]: 	Test 300/1152. loss: 0.703, 0.1823 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 00:03:35 visual_prompt]: 	Test 400/1152. loss: 0.622, 0.2022 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 00:03:54 visual_prompt]: 	Test 500/1152. loss: 0.470, 0.2083 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 00:04:14 visual_prompt]: 	Test 600/1152. loss: 0.709, 0.2052 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 00:04:33 visual_prompt]: 	Test 700/1152. loss: 0.637, 0.1962 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 00:04:53 visual_prompt]: 	Test 800/1152. loss: 0.599, 0.1831 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 00:05:12 visual_prompt]: 	Test 900/1152. loss: 0.886, 0.1981 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 00:05:32 visual_prompt]: 	Test 1000/1152. loss: 0.764, 0.1834 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 00:05:52 visual_prompt]: 	Test 1100/1152. loss: 0.527, 0.1946 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 00:06:06 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1939, average loss: 0.7023
[09/19 00:06:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 70.50	top5: 100.00	
[09/19 00:06:06 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/19 00:06:20 visual_prompt]: Epoch 58 / 100: avg data time: 2.42e-01, avg batch time: 0.6430, average train loss: 0.6039
[09/19 00:06:27 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1429, average loss: 0.5800
[09/19 00:06:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.00	top5: 100.00	
[09/19 00:06:51 visual_prompt]: 	Test 100/1152. loss: 1.030, 0.2049 s / batch. (data: 2.26e-02)max mem: 17.22454 GB 
[09/19 00:07:10 visual_prompt]: 	Test 200/1152. loss: 0.833, 0.2084 s / batch. (data: 2.67e-02)max mem: 17.22454 GB 
[09/19 00:07:29 visual_prompt]: 	Test 300/1152. loss: 0.732, 0.1921 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 00:07:49 visual_prompt]: 	Test 400/1152. loss: 0.721, 0.1934 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 00:08:08 visual_prompt]: 	Test 500/1152. loss: 0.703, 0.1844 s / batch. (data: 3.93e-05)max mem: 17.22454 GB 
[09/19 00:08:28 visual_prompt]: 	Test 600/1152. loss: 0.984, 0.1830 s / batch. (data: 5.01e-05)max mem: 17.22454 GB 
[09/19 00:08:47 visual_prompt]: 	Test 700/1152. loss: 0.839, 0.1821 s / batch. (data: 2.98e-05)max mem: 17.22454 GB 
[09/19 00:09:07 visual_prompt]: 	Test 800/1152. loss: 0.681, 0.1829 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 00:09:26 visual_prompt]: 	Test 900/1152. loss: 0.959, 0.1888 s / batch. (data: 6.16e-03)max mem: 17.22454 GB 
[09/19 00:09:46 visual_prompt]: 	Test 1000/1152. loss: 0.756, 0.1964 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 00:10:06 visual_prompt]: 	Test 1100/1152. loss: 0.557, 0.1826 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 00:10:20 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1942, average loss: 0.8454
[09/19 00:10:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.55	top5: 99.99	
[09/19 00:10:20 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/19 00:10:33 visual_prompt]: Epoch 59 / 100: avg data time: 2.39e-01, avg batch time: 0.6388, average train loss: 0.6387
[09/19 00:10:41 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1425, average loss: 0.5136
[09/19 00:10:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 80.00	top5: 99.50	
[09/19 00:11:04 visual_prompt]: 	Test 100/1152. loss: 0.713, 0.1968 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 00:11:23 visual_prompt]: 	Test 200/1152. loss: 0.658, 0.1852 s / batch. (data: 2.57e-03)max mem: 17.22454 GB 
[09/19 00:11:43 visual_prompt]: 	Test 300/1152. loss: 0.835, 0.1934 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 00:12:02 visual_prompt]: 	Test 400/1152. loss: 0.785, 0.1880 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 00:12:22 visual_prompt]: 	Test 500/1152. loss: 0.583, 0.1847 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 00:12:41 visual_prompt]: 	Test 600/1152. loss: 0.736, 0.1965 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 00:13:01 visual_prompt]: 	Test 700/1152. loss: 0.707, 0.1830 s / batch. (data: 9.61e-05)max mem: 17.22454 GB 
[09/19 00:13:20 visual_prompt]: 	Test 800/1152. loss: 0.834, 0.1924 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 00:13:40 visual_prompt]: 	Test 900/1152. loss: 0.986, 0.1828 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 00:13:59 visual_prompt]: 	Test 1000/1152. loss: 0.601, 0.1854 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 00:14:19 visual_prompt]: 	Test 1100/1152. loss: 0.620, 0.1831 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 00:14:33 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1937, average loss: 0.8103
[09/19 00:14:33 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.06	top5: 99.89	
[09/19 00:14:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/19 00:14:46 visual_prompt]: Epoch 60 / 100: avg data time: 2.41e-01, avg batch time: 0.6415, average train loss: 0.7045
[09/19 00:14:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1423, average loss: 0.4346
[09/19 00:14:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.00	top5: 100.00	
[09/19 00:15:17 visual_prompt]: 	Test 100/1152. loss: 0.745, 0.1942 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 00:15:36 visual_prompt]: 	Test 200/1152. loss: 0.555, 0.1828 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 00:15:55 visual_prompt]: 	Test 300/1152. loss: 0.748, 0.1927 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 00:16:15 visual_prompt]: 	Test 400/1152. loss: 0.664, 0.1951 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 00:16:34 visual_prompt]: 	Test 500/1152. loss: 0.638, 0.1830 s / batch. (data: 9.80e-05)max mem: 17.22454 GB 
[09/19 00:16:54 visual_prompt]: 	Test 600/1152. loss: 0.700, 0.1826 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 00:17:14 visual_prompt]: 	Test 700/1152. loss: 0.668, 0.1956 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 00:17:33 visual_prompt]: 	Test 800/1152. loss: 0.501, 0.2011 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 00:17:53 visual_prompt]: 	Test 900/1152. loss: 0.890, 0.1924 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 00:18:12 visual_prompt]: 	Test 1000/1152. loss: 0.617, 0.2089 s / batch. (data: 3.81e-05)max mem: 17.22454 GB 
[09/19 00:18:32 visual_prompt]: 	Test 1100/1152. loss: 0.516, 0.1950 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 00:18:46 visual_prompt]: Inference (test):avg data time: 7.77e-03, avg batch time: 0.1940, average loss: 0.7155
[09/19 00:18:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 70.22	top5: 99.99	
[09/19 00:18:46 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/19 00:18:59 visual_prompt]: Epoch 61 / 100: avg data time: 2.23e-01, avg batch time: 0.6289, average train loss: 0.5092
[09/19 00:19:07 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1421, average loss: 0.4327
[09/19 00:19:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.50	top5: 100.00	
[09/19 00:19:30 visual_prompt]: 	Test 100/1152. loss: 1.071, 0.2075 s / batch. (data: 2.61e-02)max mem: 17.22454 GB 
[09/19 00:19:49 visual_prompt]: 	Test 200/1152. loss: 0.863, 0.1942 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 00:20:09 visual_prompt]: 	Test 300/1152. loss: 0.948, 0.1939 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 00:20:28 visual_prompt]: 	Test 400/1152. loss: 0.564, 0.1847 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:20:48 visual_prompt]: 	Test 500/1152. loss: 0.648, 0.2175 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 00:21:07 visual_prompt]: 	Test 600/1152. loss: 0.881, 0.1873 s / batch. (data: 4.97e-03)max mem: 17.22454 GB 
[09/19 00:21:27 visual_prompt]: 	Test 700/1152. loss: 0.700, 0.2009 s / batch. (data: 1.91e-02)max mem: 17.22454 GB 
[09/19 00:21:46 visual_prompt]: 	Test 800/1152. loss: 0.606, 0.2094 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 00:22:06 visual_prompt]: 	Test 900/1152. loss: 0.820, 0.2077 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/19 00:22:26 visual_prompt]: 	Test 1000/1152. loss: 0.741, 0.1901 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 00:22:45 visual_prompt]: 	Test 1100/1152. loss: 0.407, 0.1948 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 00:23:00 visual_prompt]: Inference (test):avg data time: 8.10e-03, avg batch time: 0.1944, average loss: 0.7919
[09/19 00:23:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.14	top5: 100.00	
[09/19 00:23:00 visual_prompt]: Best epoch 61: best metric: 0.845
[09/19 00:23:00 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/19 00:23:13 visual_prompt]: Epoch 62 / 100: avg data time: 2.36e-01, avg batch time: 0.6377, average train loss: 0.5349
[09/19 00:23:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1421, average loss: 0.5869
[09/19 00:23:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.00	top5: 100.00	
[09/19 00:23:44 visual_prompt]: 	Test 100/1152. loss: 1.130, 0.1849 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 00:24:03 visual_prompt]: 	Test 200/1152. loss: 0.829, 0.1822 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 00:24:22 visual_prompt]: 	Test 300/1152. loss: 0.987, 0.2073 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/19 00:24:42 visual_prompt]: 	Test 400/1152. loss: 0.757, 0.1825 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 00:25:02 visual_prompt]: 	Test 500/1152. loss: 0.700, 0.1837 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 00:25:21 visual_prompt]: 	Test 600/1152. loss: 0.990, 0.1822 s / batch. (data: 3.15e-05)max mem: 17.22454 GB 
[09/19 00:25:41 visual_prompt]: 	Test 700/1152. loss: 0.778, 0.2063 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 00:26:00 visual_prompt]: 	Test 800/1152. loss: 0.814, 0.1826 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:26:20 visual_prompt]: 	Test 900/1152. loss: 0.928, 0.1872 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 00:26:39 visual_prompt]: 	Test 1000/1152. loss: 0.745, 0.1962 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 00:26:59 visual_prompt]: 	Test 1100/1152. loss: 0.612, 0.1958 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 00:27:13 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1942, average loss: 0.8819
[09/19 00:27:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.17	top5: 99.99	
[09/19 00:27:14 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/19 00:27:27 visual_prompt]: Epoch 63 / 100: avg data time: 2.33e-01, avg batch time: 0.6336, average train loss: 0.4902
[09/19 00:27:34 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1421, average loss: 0.3684
[09/19 00:27:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 88.00	top5: 100.00	
[09/19 00:27:57 visual_prompt]: 	Test 100/1152. loss: 0.639, 0.1998 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 00:28:17 visual_prompt]: 	Test 200/1152. loss: 0.655, 0.1826 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 00:28:36 visual_prompt]: 	Test 300/1152. loss: 0.745, 0.1825 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 00:28:56 visual_prompt]: 	Test 400/1152. loss: 0.637, 0.2124 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/19 00:29:15 visual_prompt]: 	Test 500/1152. loss: 0.525, 0.1822 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 00:29:35 visual_prompt]: 	Test 600/1152. loss: 0.858, 0.1949 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 00:29:54 visual_prompt]: 	Test 700/1152. loss: 0.580, 0.2078 s / batch. (data: 2.54e-02)max mem: 17.22454 GB 
[09/19 00:30:14 visual_prompt]: 	Test 800/1152. loss: 0.502, 0.1917 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 00:30:33 visual_prompt]: 	Test 900/1152. loss: 1.052, 0.1973 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 00:30:52 visual_prompt]: 	Test 1000/1152. loss: 0.642, 0.2026 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 00:31:12 visual_prompt]: 	Test 1100/1152. loss: 0.495, 0.1831 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:31:26 visual_prompt]: Inference (test):avg data time: 7.24e-03, avg batch time: 0.1937, average loss: 0.6727
[09/19 00:31:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 75.36	top5: 100.00	
[09/19 00:31:27 visual_prompt]: Best epoch 63: best metric: 0.880
[09/19 00:31:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/19 00:31:40 visual_prompt]: Epoch 64 / 100: avg data time: 2.38e-01, avg batch time: 0.6386, average train loss: 0.4594
[09/19 00:31:47 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1456, average loss: 0.6331
[09/19 00:31:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.50	top5: 100.00	
[09/19 00:32:10 visual_prompt]: 	Test 100/1152. loss: 1.001, 0.1960 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 00:32:29 visual_prompt]: 	Test 200/1152. loss: 1.049, 0.1822 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 00:32:49 visual_prompt]: 	Test 300/1152. loss: 1.131, 0.1827 s / batch. (data: 8.89e-05)max mem: 17.22454 GB 
[09/19 00:33:08 visual_prompt]: 	Test 400/1152. loss: 1.131, 0.2255 s / batch. (data: 4.35e-02)max mem: 17.22454 GB 
[09/19 00:33:28 visual_prompt]: 	Test 500/1152. loss: 0.673, 0.1856 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 00:33:47 visual_prompt]: 	Test 600/1152. loss: 1.140, 0.1953 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 00:34:07 visual_prompt]: 	Test 700/1152. loss: 0.813, 0.1995 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 00:34:27 visual_prompt]: 	Test 800/1152. loss: 1.098, 0.2039 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/19 00:34:46 visual_prompt]: 	Test 900/1152. loss: 1.456, 0.1978 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 00:35:06 visual_prompt]: 	Test 1000/1152. loss: 0.995, 0.1959 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 00:35:25 visual_prompt]: 	Test 1100/1152. loss: 0.867, 0.1830 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 00:35:40 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1941, average loss: 1.0285
[09/19 00:35:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.26	top5: 99.95	
[09/19 00:35:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/19 00:35:53 visual_prompt]: Epoch 65 / 100: avg data time: 2.32e-01, avg batch time: 0.6337, average train loss: 0.4559
[09/19 00:36:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1421, average loss: 0.3817
[09/19 00:36:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 85.50	top5: 100.00	
[09/19 00:36:24 visual_prompt]: 	Test 100/1152. loss: 0.847, 0.1820 s / batch. (data: 9.97e-05)max mem: 17.22454 GB 
[09/19 00:36:43 visual_prompt]: 	Test 200/1152. loss: 0.615, 0.1829 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 00:37:02 visual_prompt]: 	Test 300/1152. loss: 0.719, 0.1825 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 00:37:22 visual_prompt]: 	Test 400/1152. loss: 0.573, 0.1914 s / batch. (data: 3.10e-05)max mem: 17.22454 GB 
[09/19 00:37:41 visual_prompt]: 	Test 500/1152. loss: 0.731, 0.2071 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 00:38:01 visual_prompt]: 	Test 600/1152. loss: 0.904, 0.1841 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:38:20 visual_prompt]: 	Test 700/1152. loss: 0.669, 0.1831 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 00:38:40 visual_prompt]: 	Test 800/1152. loss: 0.417, 0.2115 s / batch. (data: 2.94e-02)max mem: 17.22454 GB 
[09/19 00:39:00 visual_prompt]: 	Test 900/1152. loss: 1.080, 0.1871 s / batch. (data: 4.63e-05)max mem: 17.22454 GB 
[09/19 00:39:19 visual_prompt]: 	Test 1000/1152. loss: 0.601, 0.1976 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 00:39:39 visual_prompt]: 	Test 1100/1152. loss: 0.458, 0.1962 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 00:39:53 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1940, average loss: 0.7521
[09/19 00:39:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.38	top5: 100.00	
[09/19 00:39:53 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/19 00:40:07 visual_prompt]: Epoch 66 / 100: avg data time: 2.38e-01, avg batch time: 0.6400, average train loss: 0.3687
[09/19 00:40:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1422, average loss: 0.5005
[09/19 00:40:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 82.50	top5: 100.00	
[09/19 00:40:37 visual_prompt]: 	Test 100/1152. loss: 1.190, 0.1947 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 00:40:56 visual_prompt]: 	Test 200/1152. loss: 0.853, 0.1940 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 00:41:16 visual_prompt]: 	Test 300/1152. loss: 0.985, 0.1959 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 00:41:35 visual_prompt]: 	Test 400/1152. loss: 0.638, 0.1822 s / batch. (data: 8.20e-05)max mem: 17.22454 GB 
[09/19 00:41:55 visual_prompt]: 	Test 500/1152. loss: 0.844, 0.2054 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 00:42:14 visual_prompt]: 	Test 600/1152. loss: 1.085, 0.1866 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:42:34 visual_prompt]: 	Test 700/1152. loss: 0.917, 0.1827 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 00:42:53 visual_prompt]: 	Test 800/1152. loss: 0.708, 0.1919 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:43:13 visual_prompt]: 	Test 900/1152. loss: 1.164, 0.1928 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 00:43:33 visual_prompt]: 	Test 1000/1152. loss: 0.873, 0.1835 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 00:43:52 visual_prompt]: 	Test 1100/1152. loss: 0.596, 0.1828 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:44:06 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1940, average loss: 0.9517
[09/19 00:44:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.63	top5: 99.98	
[09/19 00:44:07 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/19 00:44:20 visual_prompt]: Epoch 67 / 100: avg data time: 2.32e-01, avg batch time: 0.6340, average train loss: 0.6157
[09/19 00:44:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1420, average loss: 0.6007
[09/19 00:44:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.00	top5: 100.00	
[09/19 00:44:51 visual_prompt]: 	Test 100/1152. loss: 0.941, 0.1968 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 00:45:10 visual_prompt]: 	Test 200/1152. loss: 1.055, 0.1831 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 00:45:29 visual_prompt]: 	Test 300/1152. loss: 0.754, 0.1964 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 00:45:49 visual_prompt]: 	Test 400/1152. loss: 0.643, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 00:46:08 visual_prompt]: 	Test 500/1152. loss: 0.752, 0.1841 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 00:46:28 visual_prompt]: 	Test 600/1152. loss: 0.767, 0.1975 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 00:46:48 visual_prompt]: 	Test 700/1152. loss: 0.601, 0.1830 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 00:47:07 visual_prompt]: 	Test 800/1152. loss: 0.596, 0.1973 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 00:47:27 visual_prompt]: 	Test 900/1152. loss: 0.802, 0.1856 s / batch. (data: 4.15e-05)max mem: 17.22454 GB 
[09/19 00:47:46 visual_prompt]: 	Test 1000/1152. loss: 0.860, 0.2333 s / batch. (data: 4.88e-02)max mem: 17.22454 GB 
[09/19 00:48:06 visual_prompt]: 	Test 1100/1152. loss: 0.405, 0.1993 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 00:48:20 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1942, average loss: 0.8057
[09/19 00:48:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.67	top5: 100.00	
[09/19 00:48:21 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/19 00:48:34 visual_prompt]: Epoch 68 / 100: avg data time: 2.28e-01, avg batch time: 0.6320, average train loss: 0.5625
[09/19 00:48:41 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1421, average loss: 0.3852
[09/19 00:48:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.00	top5: 100.00	
[09/19 00:49:04 visual_prompt]: 	Test 100/1152. loss: 0.784, 0.1967 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 00:49:24 visual_prompt]: 	Test 200/1152. loss: 0.539, 0.1823 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 00:49:43 visual_prompt]: 	Test 300/1152. loss: 0.737, 0.1820 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 00:50:02 visual_prompt]: 	Test 400/1152. loss: 0.493, 0.1972 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 00:50:22 visual_prompt]: 	Test 500/1152. loss: 0.510, 0.2038 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 00:50:41 visual_prompt]: 	Test 600/1152. loss: 0.732, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 00:51:01 visual_prompt]: 	Test 700/1152. loss: 0.495, 0.1989 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 00:51:20 visual_prompt]: 	Test 800/1152. loss: 0.489, 0.1863 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 00:51:40 visual_prompt]: 	Test 900/1152. loss: 0.626, 0.1839 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 00:51:59 visual_prompt]: 	Test 1000/1152. loss: 0.506, 0.1956 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 00:52:19 visual_prompt]: 	Test 1100/1152. loss: 0.382, 0.1827 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 00:52:34 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1941, average loss: 0.6105
[09/19 00:52:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.48	top5: 100.00	
[09/19 00:52:34 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/19 00:52:47 visual_prompt]: Epoch 69 / 100: avg data time: 2.47e-01, avg batch time: 0.6500, average train loss: 0.4605
[09/19 00:52:55 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1422, average loss: 0.4097
[09/19 00:52:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 85.50	top5: 100.00	
[09/19 00:53:18 visual_prompt]: 	Test 100/1152. loss: 1.013, 0.1828 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 00:53:37 visual_prompt]: 	Test 200/1152. loss: 0.651, 0.1954 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 00:53:57 visual_prompt]: 	Test 300/1152. loss: 0.824, 0.1821 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/19 00:54:16 visual_prompt]: 	Test 400/1152. loss: 0.601, 0.2068 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 00:54:36 visual_prompt]: 	Test 500/1152. loss: 0.555, 0.2192 s / batch. (data: 3.73e-02)max mem: 17.22454 GB 
[09/19 00:54:55 visual_prompt]: 	Test 600/1152. loss: 0.698, 0.1830 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 00:55:15 visual_prompt]: 	Test 700/1152. loss: 0.716, 0.1901 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 00:55:34 visual_prompt]: 	Test 800/1152. loss: 0.725, 0.1874 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 00:55:54 visual_prompt]: 	Test 900/1152. loss: 0.915, 0.1828 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 00:56:13 visual_prompt]: 	Test 1000/1152. loss: 0.593, 0.1913 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 00:56:33 visual_prompt]: 	Test 1100/1152. loss: 0.578, 0.2075 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/19 00:56:47 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1941, average loss: 0.7557
[09/19 00:56:48 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.67	top5: 100.00	
[09/19 00:56:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/19 00:57:01 visual_prompt]: Epoch 70 / 100: avg data time: 2.40e-01, avg batch time: 0.6420, average train loss: 0.4654
[09/19 00:57:08 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1421, average loss: 0.4806
[09/19 00:57:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 82.00	top5: 100.00	
[09/19 00:57:32 visual_prompt]: 	Test 100/1152. loss: 1.083, 0.1953 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 00:57:51 visual_prompt]: 	Test 200/1152. loss: 1.342, 0.1943 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 00:58:10 visual_prompt]: 	Test 300/1152. loss: 1.184, 0.1820 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 00:58:30 visual_prompt]: 	Test 400/1152. loss: 0.788, 0.1819 s / batch. (data: 3.27e-05)max mem: 17.22454 GB 
[09/19 00:58:49 visual_prompt]: 	Test 500/1152. loss: 0.941, 0.1817 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 00:59:09 visual_prompt]: 	Test 600/1152. loss: 0.949, 0.2108 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 00:59:28 visual_prompt]: 	Test 700/1152. loss: 0.863, 0.2106 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 00:59:48 visual_prompt]: 	Test 800/1152. loss: 0.679, 0.1899 s / batch. (data: 3.12e-05)max mem: 17.22454 GB 
[09/19 01:00:07 visual_prompt]: 	Test 900/1152. loss: 1.315, 0.1826 s / batch. (data: 8.58e-05)max mem: 17.22454 GB 
[09/19 01:00:27 visual_prompt]: 	Test 1000/1152. loss: 1.135, 0.1829 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 01:00:47 visual_prompt]: 	Test 1100/1152. loss: 0.549, 0.1832 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 01:01:01 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1943, average loss: 0.9817
[09/19 01:01:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.21	top5: 99.98	
[09/19 01:01:01 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/19 01:01:15 visual_prompt]: Epoch 71 / 100: avg data time: 2.30e-01, avg batch time: 0.6310, average train loss: 0.3896
[09/19 01:01:22 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1421, average loss: 0.2958
[09/19 01:01:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 88.50	top5: 100.00	
[09/19 01:01:45 visual_prompt]: 	Test 100/1152. loss: 0.793, 0.2123 s / batch. (data: 2.51e-02)max mem: 17.22454 GB 
[09/19 01:02:04 visual_prompt]: 	Test 200/1152. loss: 0.698, 0.1826 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 01:02:24 visual_prompt]: 	Test 300/1152. loss: 0.750, 0.1984 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 01:02:43 visual_prompt]: 	Test 400/1152. loss: 0.448, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 01:03:03 visual_prompt]: 	Test 500/1152. loss: 0.602, 0.1833 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 01:03:22 visual_prompt]: 	Test 600/1152. loss: 0.809, 0.1829 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 01:03:42 visual_prompt]: 	Test 700/1152. loss: 0.553, 0.2098 s / batch. (data: 2.63e-02)max mem: 17.22454 GB 
[09/19 01:04:02 visual_prompt]: 	Test 800/1152. loss: 0.482, 0.2072 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 01:04:21 visual_prompt]: 	Test 900/1152. loss: 0.905, 0.1952 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 01:04:40 visual_prompt]: 	Test 1000/1152. loss: 0.595, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 01:05:00 visual_prompt]: 	Test 1100/1152. loss: 0.405, 0.1984 s / batch. (data: 3.98e-05)max mem: 17.22454 GB 
[09/19 01:05:15 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1939, average loss: 0.6607
[09/19 01:05:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.55	top5: 99.98	
[09/19 01:05:15 visual_prompt]: Best epoch 71: best metric: 0.885
[09/19 01:05:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/19 01:05:28 visual_prompt]: Epoch 72 / 100: avg data time: 2.40e-01, avg batch time: 0.6408, average train loss: 0.2690
[09/19 01:05:35 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1421, average loss: 0.1950
[09/19 01:05:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 01:05:59 visual_prompt]: 	Test 100/1152. loss: 0.830, 0.1822 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:06:18 visual_prompt]: 	Test 200/1152. loss: 0.608, 0.1834 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 01:06:37 visual_prompt]: 	Test 300/1152. loss: 0.904, 0.1872 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 01:06:57 visual_prompt]: 	Test 400/1152. loss: 0.513, 0.1827 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 01:07:16 visual_prompt]: 	Test 500/1152. loss: 0.456, 0.1822 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 01:07:36 visual_prompt]: 	Test 600/1152. loss: 0.734, 0.2023 s / batch. (data: 2.08e-02)max mem: 17.22454 GB 
[09/19 01:07:55 visual_prompt]: 	Test 700/1152. loss: 0.557, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 01:08:15 visual_prompt]: 	Test 800/1152. loss: 0.673, 0.1967 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 01:08:34 visual_prompt]: 	Test 900/1152. loss: 1.012, 0.1832 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:08:54 visual_prompt]: 	Test 1000/1152. loss: 0.520, 0.1830 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 01:09:13 visual_prompt]: 	Test 1100/1152. loss: 0.511, 0.1996 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 01:09:28 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1937, average loss: 0.6936
[09/19 01:09:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.75	top5: 100.00	
[09/19 01:09:28 visual_prompt]: Best epoch 72: best metric: 0.930
[09/19 01:09:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/19 01:09:42 visual_prompt]: Epoch 73 / 100: avg data time: 2.40e-01, avg batch time: 0.6432, average train loss: 0.2650
[09/19 01:09:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1434, average loss: 0.4366
[09/19 01:09:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.00	top5: 100.00	
[09/19 01:10:12 visual_prompt]: 	Test 100/1152. loss: 1.231, 0.1976 s / batch. (data: 8.44e-05)max mem: 17.22454 GB 
[09/19 01:10:32 visual_prompt]: 	Test 200/1152. loss: 0.675, 0.1826 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 01:10:51 visual_prompt]: 	Test 300/1152. loss: 1.047, 0.1963 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 01:11:10 visual_prompt]: 	Test 400/1152. loss: 0.844, 0.1868 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 01:11:30 visual_prompt]: 	Test 500/1152. loss: 0.430, 0.1837 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 01:11:50 visual_prompt]: 	Test 600/1152. loss: 0.774, 0.2040 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 01:12:09 visual_prompt]: 	Test 700/1152. loss: 1.108, 0.1826 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:12:29 visual_prompt]: 	Test 800/1152. loss: 0.878, 0.1971 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 01:12:48 visual_prompt]: 	Test 900/1152. loss: 1.162, 0.1831 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 01:13:08 visual_prompt]: 	Test 1000/1152. loss: 0.726, 0.1967 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 01:13:27 visual_prompt]: 	Test 1100/1152. loss: 0.636, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 01:13:42 visual_prompt]: Inference (test):avg data time: 8.36e-03, avg batch time: 0.1943, average loss: 0.9188
[09/19 01:13:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.51	top5: 99.98	
[09/19 01:13:42 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/19 01:13:56 visual_prompt]: Epoch 74 / 100: avg data time: 2.50e-01, avg batch time: 0.6496, average train loss: 0.3383
[09/19 01:14:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1433, average loss: 0.3349
[09/19 01:14:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 83.50	top5: 100.00	
[09/19 01:14:26 visual_prompt]: 	Test 100/1152. loss: 1.234, 0.1822 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 01:14:45 visual_prompt]: 	Test 200/1152. loss: 0.888, 0.1964 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 01:15:05 visual_prompt]: 	Test 300/1152. loss: 0.946, 0.1825 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 01:15:25 visual_prompt]: 	Test 400/1152. loss: 0.673, 0.1961 s / batch. (data: 3.77e-05)max mem: 17.22454 GB 
[09/19 01:15:44 visual_prompt]: 	Test 500/1152. loss: 0.369, 0.1827 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 01:16:04 visual_prompt]: 	Test 600/1152. loss: 0.790, 0.2292 s / batch. (data: 3.48e-05)max mem: 17.22454 GB 
[09/19 01:16:23 visual_prompt]: 	Test 700/1152. loss: 0.849, 0.1975 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 01:16:42 visual_prompt]: 	Test 800/1152. loss: 0.666, 0.1933 s / batch. (data: 4.79e-05)max mem: 17.22454 GB 
[09/19 01:17:02 visual_prompt]: 	Test 900/1152. loss: 1.281, 0.1878 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:17:22 visual_prompt]: 	Test 1000/1152. loss: 0.708, 0.1953 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 01:17:41 visual_prompt]: 	Test 1100/1152. loss: 0.571, 0.1826 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:17:56 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1942, average loss: 0.8222
[09/19 01:17:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.34	top5: 99.98	
[09/19 01:17:56 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/19 01:18:09 visual_prompt]: Epoch 75 / 100: avg data time: 2.39e-01, avg batch time: 0.6406, average train loss: 0.2691
[09/19 01:18:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1423, average loss: 0.1974
[09/19 01:18:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 91.50	top5: 100.00	
[09/19 01:18:40 visual_prompt]: 	Test 100/1152. loss: 1.099, 0.1828 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 01:19:00 visual_prompt]: 	Test 200/1152. loss: 1.033, 0.1828 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 01:19:19 visual_prompt]: 	Test 300/1152. loss: 1.008, 0.2195 s / batch. (data: 3.83e-02)max mem: 17.22454 GB 
[09/19 01:19:39 visual_prompt]: 	Test 400/1152. loss: 0.536, 0.1823 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 01:19:58 visual_prompt]: 	Test 500/1152. loss: 0.574, 0.2008 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 01:20:18 visual_prompt]: 	Test 600/1152. loss: 1.044, 0.1963 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 01:20:37 visual_prompt]: 	Test 700/1152. loss: 0.845, 0.2157 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 01:20:57 visual_prompt]: 	Test 800/1152. loss: 0.655, 0.2220 s / batch. (data: 4.03e-02)max mem: 17.22454 GB 
[09/19 01:21:16 visual_prompt]: 	Test 900/1152. loss: 1.078, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 01:21:36 visual_prompt]: 	Test 1000/1152. loss: 0.791, 0.1828 s / batch. (data: 8.75e-05)max mem: 17.22454 GB 
[09/19 01:21:55 visual_prompt]: 	Test 1100/1152. loss: 0.478, 0.2276 s / batch. (data: 4.53e-02)max mem: 17.22454 GB 
[09/19 01:22:09 visual_prompt]: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1940, average loss: 0.8008
[09/19 01:22:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.79	top5: 99.98	
[09/19 01:22:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/19 01:22:23 visual_prompt]: Epoch 76 / 100: avg data time: 2.35e-01, avg batch time: 0.6370, average train loss: 0.2602
[09/19 01:22:30 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1432, average loss: 0.1859
[09/19 01:22:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 01:22:53 visual_prompt]: 	Test 100/1152. loss: 0.871, 0.1828 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 01:23:13 visual_prompt]: 	Test 200/1152. loss: 0.577, 0.1854 s / batch. (data: 2.84e-05)max mem: 17.22454 GB 
[09/19 01:23:32 visual_prompt]: 	Test 300/1152. loss: 0.872, 0.2404 s / batch. (data: 2.84e-02)max mem: 17.22454 GB 
[09/19 01:23:52 visual_prompt]: 	Test 400/1152. loss: 0.458, 0.1878 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:24:11 visual_prompt]: 	Test 500/1152. loss: 0.450, 0.1909 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 01:24:31 visual_prompt]: 	Test 600/1152. loss: 0.795, 0.1954 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 01:24:50 visual_prompt]: 	Test 700/1152. loss: 0.665, 0.2039 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/19 01:25:10 visual_prompt]: 	Test 800/1152. loss: 0.507, 0.1962 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 01:25:29 visual_prompt]: 	Test 900/1152. loss: 0.794, 0.1968 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 01:25:49 visual_prompt]: 	Test 1000/1152. loss: 0.535, 0.1830 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 01:26:08 visual_prompt]: 	Test 1100/1152. loss: 0.391, 0.1886 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:26:23 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1939, average loss: 0.6520
[09/19 01:26:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.59	top5: 99.97	
[09/19 01:26:23 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/19 01:26:37 visual_prompt]: Epoch 77 / 100: avg data time: 2.45e-01, avg batch time: 0.6490, average train loss: 0.2179
[09/19 01:26:44 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1464, average loss: 0.3680
[09/19 01:26:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 86.50	top5: 100.00	
[09/19 01:27:08 visual_prompt]: 	Test 100/1152. loss: 1.091, 0.1826 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 01:27:27 visual_prompt]: 	Test 200/1152. loss: 0.888, 0.1991 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 01:27:46 visual_prompt]: 	Test 300/1152. loss: 1.253, 0.1948 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 01:28:06 visual_prompt]: 	Test 400/1152. loss: 0.666, 0.2056 s / batch. (data: 2.32e-02)max mem: 17.22454 GB 
[09/19 01:28:25 visual_prompt]: 	Test 500/1152. loss: 0.670, 0.1981 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 01:28:45 visual_prompt]: 	Test 600/1152. loss: 1.316, 0.2026 s / batch. (data: 1.00e-02)max mem: 17.22454 GB 
[09/19 01:29:05 visual_prompt]: 	Test 700/1152. loss: 0.614, 0.1939 s / batch. (data: 1.17e-02)max mem: 17.22454 GB 
[09/19 01:29:24 visual_prompt]: 	Test 800/1152. loss: 0.706, 0.2336 s / batch. (data: 3.70e-02)max mem: 17.22454 GB 
[09/19 01:29:44 visual_prompt]: 	Test 900/1152. loss: 0.880, 0.1950 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 01:30:03 visual_prompt]: 	Test 1000/1152. loss: 0.640, 0.1965 s / batch. (data: 1.20e-02)max mem: 17.22454 GB 
[09/19 01:30:23 visual_prompt]: 	Test 1100/1152. loss: 0.663, 0.1826 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 01:30:37 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1941, average loss: 0.9731
[09/19 01:30:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.74	top5: 99.91	
[09/19 01:30:37 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/19 01:30:51 visual_prompt]: Epoch 78 / 100: avg data time: 2.28e-01, avg batch time: 0.6322, average train loss: 0.2782
[09/19 01:30:58 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1421, average loss: 0.2712
[09/19 01:30:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 89.00	top5: 100.00	
[09/19 01:31:21 visual_prompt]: 	Test 100/1152. loss: 0.902, 0.1830 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 01:31:41 visual_prompt]: 	Test 200/1152. loss: 0.620, 0.1822 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 01:32:00 visual_prompt]: 	Test 300/1152. loss: 0.871, 0.2112 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 01:32:20 visual_prompt]: 	Test 400/1152. loss: 0.463, 0.2222 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 01:32:39 visual_prompt]: 	Test 500/1152. loss: 0.622, 0.1962 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 01:32:59 visual_prompt]: 	Test 600/1152. loss: 1.013, 0.1819 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 01:33:18 visual_prompt]: 	Test 700/1152. loss: 0.697, 0.1835 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 01:33:38 visual_prompt]: 	Test 800/1152. loss: 0.593, 0.1825 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 01:33:57 visual_prompt]: 	Test 900/1152. loss: 0.967, 0.1835 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:34:17 visual_prompt]: 	Test 1000/1152. loss: 0.596, 0.2154 s / batch. (data: 3.33e-02)max mem: 17.22454 GB 
[09/19 01:34:36 visual_prompt]: 	Test 1100/1152. loss: 0.466, 0.1834 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:34:51 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1939, average loss: 0.7991
[09/19 01:34:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.00	top5: 99.99	
[09/19 01:34:51 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/19 01:35:05 visual_prompt]: Epoch 79 / 100: avg data time: 2.50e-01, avg batch time: 0.6500, average train loss: 0.2434
[09/19 01:35:12 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1422, average loss: 0.1744
[09/19 01:35:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 92.50	top5: 100.00	
[09/19 01:35:35 visual_prompt]: 	Test 100/1152. loss: 0.741, 0.1961 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 01:35:55 visual_prompt]: 	Test 200/1152. loss: 0.697, 0.1974 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 01:36:14 visual_prompt]: 	Test 300/1152. loss: 1.101, 0.1949 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 01:36:34 visual_prompt]: 	Test 400/1152. loss: 0.613, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 01:36:53 visual_prompt]: 	Test 500/1152. loss: 0.477, 0.1826 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 01:37:13 visual_prompt]: 	Test 600/1152. loss: 0.839, 0.1946 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 01:37:33 visual_prompt]: 	Test 700/1152. loss: 0.700, 0.1971 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 01:37:52 visual_prompt]: 	Test 800/1152. loss: 0.822, 0.1824 s / batch. (data: 2.81e-05)max mem: 17.22454 GB 
[09/19 01:38:12 visual_prompt]: 	Test 900/1152. loss: 1.138, 0.1877 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 01:38:31 visual_prompt]: 	Test 1000/1152. loss: 0.729, 0.1962 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 01:38:51 visual_prompt]: 	Test 1100/1152. loss: 0.674, 0.1834 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 01:39:05 visual_prompt]: Inference (test):avg data time: 8.29e-03, avg batch time: 0.1944, average loss: 0.8312
[09/19 01:39:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.62	top5: 99.98	
[09/19 01:39:05 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/19 01:39:19 visual_prompt]: Epoch 80 / 100: avg data time: 2.46e-01, avg batch time: 0.6478, average train loss: 0.1681
[09/19 01:39:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1422, average loss: 0.1396
[09/19 01:39:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 95.00	top5: 100.00	
[09/19 01:39:49 visual_prompt]: 	Test 100/1152. loss: 1.048, 0.2075 s / batch. (data: 1.85e-02)max mem: 17.22454 GB 
[09/19 01:40:09 visual_prompt]: 	Test 200/1152. loss: 0.908, 0.1966 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 01:40:28 visual_prompt]: 	Test 300/1152. loss: 1.074, 0.2072 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 01:40:48 visual_prompt]: 	Test 400/1152. loss: 0.615, 0.1836 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 01:41:07 visual_prompt]: 	Test 500/1152. loss: 0.295, 0.1829 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 01:41:27 visual_prompt]: 	Test 600/1152. loss: 0.814, 0.1824 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 01:41:46 visual_prompt]: 	Test 700/1152. loss: 0.833, 0.1828 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 01:42:06 visual_prompt]: 	Test 800/1152. loss: 0.952, 0.1958 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 01:42:25 visual_prompt]: 	Test 900/1152. loss: 1.363, 0.1880 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:42:45 visual_prompt]: 	Test 1000/1152. loss: 0.720, 0.1928 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 01:43:04 visual_prompt]: 	Test 1100/1152. loss: 0.514, 0.1856 s / batch. (data: 4.72e-05)max mem: 17.22454 GB 
[09/19 01:43:18 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1939, average loss: 0.8684
[09/19 01:43:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.30	top5: 99.96	
[09/19 01:43:19 visual_prompt]: Best epoch 80: best metric: 0.950
[09/19 01:43:19 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/19 01:43:32 visual_prompt]: Epoch 81 / 100: avg data time: 2.29e-01, avg batch time: 0.6334, average train loss: 0.1106
[09/19 01:43:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1421, average loss: 0.1196
[09/19 01:43:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 96.50	top5: 100.00	
[09/19 01:44:02 visual_prompt]: 	Test 100/1152. loss: 0.888, 0.1958 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 01:44:22 visual_prompt]: 	Test 200/1152. loss: 0.691, 0.1835 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 01:44:41 visual_prompt]: 	Test 300/1152. loss: 0.952, 0.2109 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 01:45:01 visual_prompt]: 	Test 400/1152. loss: 0.571, 0.1821 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 01:45:20 visual_prompt]: 	Test 500/1152. loss: 0.351, 0.1826 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 01:45:39 visual_prompt]: 	Test 600/1152. loss: 0.802, 0.1898 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/19 01:45:59 visual_prompt]: 	Test 700/1152. loss: 0.759, 0.1989 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:46:19 visual_prompt]: 	Test 800/1152. loss: 0.592, 0.1970 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 01:46:38 visual_prompt]: 	Test 900/1152. loss: 1.403, 0.2091 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/19 01:46:58 visual_prompt]: 	Test 1000/1152. loss: 0.644, 0.1984 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/19 01:47:17 visual_prompt]: 	Test 1100/1152. loss: 0.525, 0.1982 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/19 01:47:32 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1941, average loss: 0.8078
[09/19 01:47:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.86	top5: 99.98	
[09/19 01:47:32 visual_prompt]: Best epoch 81: best metric: 0.965
[09/19 01:47:32 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/19 01:47:46 visual_prompt]: Epoch 82 / 100: avg data time: 2.40e-01, avg batch time: 0.6469, average train loss: 0.1062
[09/19 01:47:53 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1442, average loss: 0.1500
[09/19 01:47:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.00	top5: 100.00	
[09/19 01:48:16 visual_prompt]: 	Test 100/1152. loss: 1.075, 0.1931 s / batch. (data: 9.32e-05)max mem: 17.22454 GB 
[09/19 01:48:35 visual_prompt]: 	Test 200/1152. loss: 0.939, 0.2143 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/19 01:48:55 visual_prompt]: 	Test 300/1152. loss: 0.895, 0.1828 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 01:49:14 visual_prompt]: 	Test 400/1152. loss: 0.518, 0.2332 s / batch. (data: 4.15e-02)max mem: 17.22454 GB 
[09/19 01:49:34 visual_prompt]: 	Test 500/1152. loss: 0.400, 0.1824 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 01:49:53 visual_prompt]: 	Test 600/1152. loss: 0.747, 0.1967 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 01:50:13 visual_prompt]: 	Test 700/1152. loss: 0.800, 0.1867 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 01:50:32 visual_prompt]: 	Test 800/1152. loss: 0.533, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 01:50:52 visual_prompt]: 	Test 900/1152. loss: 1.405, 0.1826 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 01:51:11 visual_prompt]: 	Test 1000/1152. loss: 0.692, 0.2113 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 01:51:31 visual_prompt]: 	Test 1100/1152. loss: 0.527, 0.2200 s / batch. (data: 3.14e-02)max mem: 17.22454 GB 
[09/19 01:51:45 visual_prompt]: Inference (test):avg data time: 7.86e-03, avg batch time: 0.1940, average loss: 0.8487
[09/19 01:51:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.98	top5: 99.98	
[09/19 01:51:45 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/19 01:51:59 visual_prompt]: Epoch 83 / 100: avg data time: 2.32e-01, avg batch time: 0.6361, average train loss: 0.1265
[09/19 01:52:06 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1418, average loss: 0.0691
[09/19 01:52:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 97.50	top5: 100.00	
[09/19 01:52:30 visual_prompt]: 	Test 100/1152. loss: 0.989, 0.2087 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 01:52:49 visual_prompt]: 	Test 200/1152. loss: 0.882, 0.1821 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/19 01:53:08 visual_prompt]: 	Test 300/1152. loss: 1.069, 0.1835 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 01:53:28 visual_prompt]: 	Test 400/1152. loss: 0.534, 0.1953 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 01:53:47 visual_prompt]: 	Test 500/1152. loss: 0.545, 0.1949 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 01:54:07 visual_prompt]: 	Test 600/1152. loss: 0.694, 0.2052 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 01:54:26 visual_prompt]: 	Test 700/1152. loss: 0.795, 0.2038 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 01:54:46 visual_prompt]: 	Test 800/1152. loss: 0.966, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 01:55:06 visual_prompt]: 	Test 900/1152. loss: 1.252, 0.1846 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 01:55:25 visual_prompt]: 	Test 1000/1152. loss: 0.704, 0.1905 s / batch. (data: 3.39e-05)max mem: 17.22454 GB 
[09/19 01:55:45 visual_prompt]: 	Test 1100/1152. loss: 0.600, 0.2023 s / batch. (data: 2.03e-02)max mem: 17.22454 GB 
[09/19 01:55:59 visual_prompt]: Inference (test):avg data time: 7.80e-03, avg batch time: 0.1941, average loss: 0.8542
[09/19 01:55:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.83	top5: 99.98	
[09/19 01:55:59 visual_prompt]: Best epoch 83: best metric: 0.975
[09/19 01:55:59 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/19 01:56:12 visual_prompt]: Epoch 84 / 100: avg data time: 2.34e-01, avg batch time: 0.6377, average train loss: 0.1635
[09/19 01:56:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1421, average loss: 0.1214
[09/19 01:56:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.00	top5: 100.00	
[09/19 01:56:43 visual_prompt]: 	Test 100/1152. loss: 1.321, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 01:57:02 visual_prompt]: 	Test 200/1152. loss: 1.055, 0.1822 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:57:22 visual_prompt]: 	Test 300/1152. loss: 1.155, 0.2022 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 01:57:41 visual_prompt]: 	Test 400/1152. loss: 0.492, 0.1859 s / batch. (data: 5.08e-05)max mem: 17.22454 GB 
[09/19 01:58:01 visual_prompt]: 	Test 500/1152. loss: 0.629, 0.1826 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 01:58:20 visual_prompt]: 	Test 600/1152. loss: 0.841, 0.1829 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 01:58:40 visual_prompt]: 	Test 700/1152. loss: 0.746, 0.1861 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 01:58:59 visual_prompt]: 	Test 800/1152. loss: 0.493, 0.1830 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 01:59:19 visual_prompt]: 	Test 900/1152. loss: 1.197, 0.1957 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 01:59:39 visual_prompt]: 	Test 1000/1152. loss: 0.948, 0.2029 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 01:59:58 visual_prompt]: 	Test 1100/1152. loss: 0.388, 0.1906 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 02:00:12 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1943, average loss: 0.9167
[09/19 02:00:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.80	top5: 99.97	
[09/19 02:00:13 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/19 02:00:26 visual_prompt]: Epoch 85 / 100: avg data time: 2.39e-01, avg batch time: 0.6415, average train loss: 0.0852
[09/19 02:00:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1436, average loss: 0.0772
[09/19 02:00:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 97.00	top5: 100.00	
[09/19 02:00:57 visual_prompt]: 	Test 100/1152. loss: 1.266, 0.1976 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 02:01:16 visual_prompt]: 	Test 200/1152. loss: 1.168, 0.1823 s / batch. (data: 3.72e-05)max mem: 17.22454 GB 
[09/19 02:01:35 visual_prompt]: 	Test 300/1152. loss: 0.979, 0.2186 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/19 02:01:55 visual_prompt]: 	Test 400/1152. loss: 0.472, 0.2123 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 02:02:14 visual_prompt]: 	Test 500/1152. loss: 0.433, 0.1918 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 02:02:34 visual_prompt]: 	Test 600/1152. loss: 0.824, 0.1985 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 02:02:53 visual_prompt]: 	Test 700/1152. loss: 0.842, 0.1827 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 02:03:13 visual_prompt]: 	Test 800/1152. loss: 0.585, 0.2053 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 02:03:32 visual_prompt]: 	Test 900/1152. loss: 1.234, 0.1932 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 02:03:52 visual_prompt]: 	Test 1000/1152. loss: 0.790, 0.2108 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 02:04:11 visual_prompt]: 	Test 1100/1152. loss: 0.530, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 02:04:26 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1939, average loss: 0.8687
[09/19 02:04:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.41	top5: 99.98	
[09/19 02:04:26 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/19 02:04:39 visual_prompt]: Epoch 86 / 100: avg data time: 2.33e-01, avg batch time: 0.6379, average train loss: 0.0646
[09/19 02:04:47 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1421, average loss: 0.0364
[09/19 02:04:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/19 02:05:10 visual_prompt]: 	Test 100/1152. loss: 1.073, 0.2225 s / batch. (data: 2.06e-02)max mem: 17.22454 GB 
[09/19 02:05:29 visual_prompt]: 	Test 200/1152. loss: 0.994, 0.1825 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:05:49 visual_prompt]: 	Test 300/1152. loss: 0.982, 0.1845 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:06:08 visual_prompt]: 	Test 400/1152. loss: 0.453, 0.2329 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:06:28 visual_prompt]: 	Test 500/1152. loss: 0.398, 0.1824 s / batch. (data: 9.04e-05)max mem: 17.22454 GB 
[09/19 02:06:47 visual_prompt]: 	Test 600/1152. loss: 0.815, 0.2051 s / batch. (data: 2.32e-02)max mem: 17.22454 GB 
[09/19 02:07:07 visual_prompt]: 	Test 700/1152. loss: 0.852, 0.1957 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 02:07:26 visual_prompt]: 	Test 800/1152. loss: 0.735, 0.2002 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:07:46 visual_prompt]: 	Test 900/1152. loss: 1.471, 0.1961 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 02:08:06 visual_prompt]: 	Test 1000/1152. loss: 0.774, 0.2019 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 02:08:25 visual_prompt]: 	Test 1100/1152. loss: 0.484, 0.1828 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 02:08:40 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1947, average loss: 0.8662
[09/19 02:08:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.23	top5: 99.98	
[09/19 02:08:40 visual_prompt]: Best epoch 86: best metric: 0.990
[09/19 02:08:40 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/19 02:08:53 visual_prompt]: Epoch 87 / 100: avg data time: 2.37e-01, avg batch time: 0.6382, average train loss: 0.0662
[09/19 02:09:01 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1438, average loss: 0.0431
[09/19 02:09:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/19 02:09:24 visual_prompt]: 	Test 100/1152. loss: 1.147, 0.1873 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 02:09:43 visual_prompt]: 	Test 200/1152. loss: 0.992, 0.1820 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 02:10:03 visual_prompt]: 	Test 300/1152. loss: 1.049, 0.1957 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 02:10:22 visual_prompt]: 	Test 400/1152. loss: 0.402, 0.1828 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 02:10:42 visual_prompt]: 	Test 500/1152. loss: 0.315, 0.2031 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 02:11:01 visual_prompt]: 	Test 600/1152. loss: 0.882, 0.1974 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 02:11:21 visual_prompt]: 	Test 700/1152. loss: 0.893, 0.1965 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 02:11:40 visual_prompt]: 	Test 800/1152. loss: 0.599, 0.2189 s / batch. (data: 3.69e-02)max mem: 17.22454 GB 
[09/19 02:12:00 visual_prompt]: 	Test 900/1152. loss: 1.330, 0.1958 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 02:12:19 visual_prompt]: 	Test 1000/1152. loss: 0.749, 0.1830 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 02:12:39 visual_prompt]: 	Test 1100/1152. loss: 0.378, 0.1838 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 02:12:53 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1940, average loss: 0.8267
[09/19 02:12:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.01	top5: 99.98	
[09/19 02:12:53 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/19 02:13:07 visual_prompt]: Epoch 88 / 100: avg data time: 2.44e-01, avg batch time: 0.6450, average train loss: 0.0366
[09/19 02:13:15 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1435, average loss: 0.0663
[09/19 02:13:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 97.00	top5: 100.00	
[09/19 02:13:38 visual_prompt]: 	Test 100/1152. loss: 1.421, 0.1956 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 02:13:57 visual_prompt]: 	Test 200/1152. loss: 1.314, 0.1871 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 02:14:16 visual_prompt]: 	Test 300/1152. loss: 1.200, 0.1974 s / batch. (data: 8.13e-05)max mem: 17.22454 GB 
[09/19 02:14:36 visual_prompt]: 	Test 400/1152. loss: 0.546, 0.1831 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 02:14:56 visual_prompt]: 	Test 500/1152. loss: 0.450, 0.1828 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 02:15:15 visual_prompt]: 	Test 600/1152. loss: 0.992, 0.1823 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 02:15:35 visual_prompt]: 	Test 700/1152. loss: 1.010, 0.1959 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 02:15:54 visual_prompt]: 	Test 800/1152. loss: 0.718, 0.1942 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/19 02:16:14 visual_prompt]: 	Test 900/1152. loss: 1.543, 0.1955 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 02:16:34 visual_prompt]: 	Test 1000/1152. loss: 0.963, 0.1846 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:16:53 visual_prompt]: 	Test 1100/1152. loss: 0.636, 0.1832 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 02:17:08 visual_prompt]: Inference (test):avg data time: 8.24e-03, avg batch time: 0.1946, average loss: 1.0154
[09/19 02:17:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.10	top5: 99.97	
[09/19 02:17:08 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/19 02:17:21 visual_prompt]: Epoch 89 / 100: avg data time: 2.46e-01, avg batch time: 0.6484, average train loss: 0.0584
[09/19 02:17:29 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1440, average loss: 0.0290
[09/19 02:17:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/19 02:17:52 visual_prompt]: 	Test 100/1152. loss: 1.168, 0.1823 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 02:18:11 visual_prompt]: 	Test 200/1152. loss: 0.995, 0.1995 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 02:18:31 visual_prompt]: 	Test 300/1152. loss: 1.178, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 02:18:50 visual_prompt]: 	Test 400/1152. loss: 0.548, 0.2355 s / batch. (data: 5.40e-02)max mem: 17.22454 GB 
[09/19 02:19:10 visual_prompt]: 	Test 500/1152. loss: 0.515, 0.1834 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 02:19:29 visual_prompt]: 	Test 600/1152. loss: 1.010, 0.1828 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 02:19:49 visual_prompt]: 	Test 700/1152. loss: 0.745, 0.1832 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 02:20:09 visual_prompt]: 	Test 800/1152. loss: 0.836, 0.1981 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 02:20:28 visual_prompt]: 	Test 900/1152. loss: 1.417, 0.1982 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 02:20:48 visual_prompt]: 	Test 1000/1152. loss: 0.807, 0.1953 s / batch. (data: 4.84e-05)max mem: 17.22454 GB 
[09/19 02:21:07 visual_prompt]: 	Test 1100/1152. loss: 0.500, 0.1827 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 02:21:22 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1944, average loss: 0.9549
[09/19 02:21:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.15	top5: 99.98	
[09/19 02:21:22 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/19 02:21:35 visual_prompt]: Epoch 90 / 100: avg data time: 2.31e-01, avg batch time: 0.6323, average train loss: 0.0457
[09/19 02:21:42 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1423, average loss: 0.0175
[09/19 02:21:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 100.00	top5: 100.00	
[09/19 02:22:06 visual_prompt]: 	Test 100/1152. loss: 1.102, 0.1892 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:22:25 visual_prompt]: 	Test 200/1152. loss: 0.872, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 02:22:45 visual_prompt]: 	Test 300/1152. loss: 0.994, 0.1830 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 02:23:04 visual_prompt]: 	Test 400/1152. loss: 0.478, 0.2344 s / batch. (data: 4.57e-02)max mem: 17.22454 GB 
[09/19 02:23:24 visual_prompt]: 	Test 500/1152. loss: 0.501, 0.2066 s / batch. (data: 2.45e-02)max mem: 17.22454 GB 
[09/19 02:23:43 visual_prompt]: 	Test 600/1152. loss: 0.968, 0.2047 s / batch. (data: 2.29e-02)max mem: 17.22454 GB 
[09/19 02:24:03 visual_prompt]: 	Test 700/1152. loss: 0.737, 0.1975 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 02:24:22 visual_prompt]: 	Test 800/1152. loss: 0.668, 0.1824 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 02:24:42 visual_prompt]: 	Test 900/1152. loss: 1.334, 0.1829 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 02:25:01 visual_prompt]: 	Test 1000/1152. loss: 0.851, 0.1974 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 02:25:21 visual_prompt]: 	Test 1100/1152. loss: 0.533, 0.1973 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 02:25:35 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1944, average loss: 0.8655
[09/19 02:25:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.33	top5: 99.98	
[09/19 02:25:36 visual_prompt]: Best epoch 90: best metric: 1.000
[09/19 02:25:36 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/19 02:25:49 visual_prompt]: Epoch 91 / 100: avg data time: 2.44e-01, avg batch time: 0.6448, average train loss: 0.0396
[09/19 02:25:57 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1420, average loss: 0.0248
[09/19 02:25:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 02:26:20 visual_prompt]: 	Test 100/1152. loss: 1.169, 0.1958 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 02:26:39 visual_prompt]: 	Test 200/1152. loss: 0.900, 0.1824 s / batch. (data: 3.53e-05)max mem: 17.22454 GB 
[09/19 02:26:58 visual_prompt]: 	Test 300/1152. loss: 1.188, 0.1933 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 02:27:18 visual_prompt]: 	Test 400/1152. loss: 0.489, 0.1894 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 02:27:37 visual_prompt]: 	Test 500/1152. loss: 0.439, 0.1831 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 02:27:57 visual_prompt]: 	Test 600/1152. loss: 0.924, 0.1962 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 02:28:16 visual_prompt]: 	Test 700/1152. loss: 0.748, 0.2048 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 02:28:36 visual_prompt]: 	Test 800/1152. loss: 0.692, 0.1959 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 02:28:55 visual_prompt]: 	Test 900/1152. loss: 1.289, 0.2243 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/19 02:29:15 visual_prompt]: 	Test 1000/1152. loss: 0.799, 0.1829 s / batch. (data: 4.84e-05)max mem: 17.22454 GB 
[09/19 02:29:34 visual_prompt]: 	Test 1100/1152. loss: 0.459, 0.1825 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 02:29:49 visual_prompt]: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1939, average loss: 0.9073
[09/19 02:29:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.46	top5: 99.99	
[09/19 02:29:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/19 02:30:03 visual_prompt]: Epoch 92 / 100: avg data time: 2.38e-01, avg batch time: 0.6414, average train loss: 0.0239
[09/19 02:30:10 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1433, average loss: 0.0205
[09/19 02:30:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 100.00	top5: 100.00	
[09/19 02:30:33 visual_prompt]: 	Test 100/1152. loss: 1.264, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 02:30:53 visual_prompt]: 	Test 200/1152. loss: 0.990, 0.1830 s / batch. (data: 9.27e-05)max mem: 17.22454 GB 
[09/19 02:31:12 visual_prompt]: 	Test 300/1152. loss: 1.229, 0.1821 s / batch. (data: 3.55e-05)max mem: 17.22454 GB 
[09/19 02:31:32 visual_prompt]: 	Test 400/1152. loss: 0.435, 0.2042 s / batch. (data: 2.28e-02)max mem: 17.22454 GB 
[09/19 02:31:51 visual_prompt]: 	Test 500/1152. loss: 0.398, 0.1998 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 02:32:11 visual_prompt]: 	Test 600/1152. loss: 1.002, 0.2038 s / batch. (data: 5.69e-03)max mem: 17.22454 GB 
[09/19 02:32:30 visual_prompt]: 	Test 700/1152. loss: 0.931, 0.1902 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 02:32:49 visual_prompt]: 	Test 800/1152. loss: 0.576, 0.1958 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 02:33:09 visual_prompt]: 	Test 900/1152. loss: 1.412, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:33:29 visual_prompt]: 	Test 1000/1152. loss: 0.819, 0.1828 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:33:48 visual_prompt]: 	Test 1100/1152. loss: 0.438, 0.1950 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 02:34:03 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1938, average loss: 0.9101
[09/19 02:34:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.03	top5: 99.98	
[09/19 02:34:03 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/19 02:34:16 visual_prompt]: Epoch 93 / 100: avg data time: 2.39e-01, avg batch time: 0.6422, average train loss: 0.0238
[09/19 02:34:23 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1421, average loss: 0.0231
[09/19 02:34:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 02:34:47 visual_prompt]: 	Test 100/1152. loss: 1.131, 0.1924 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/19 02:35:06 visual_prompt]: 	Test 200/1152. loss: 0.874, 0.2146 s / batch. (data: 3.34e-02)max mem: 17.22454 GB 
[09/19 02:35:25 visual_prompt]: 	Test 300/1152. loss: 1.151, 0.2057 s / batch. (data: 2.12e-02)max mem: 17.22454 GB 
[09/19 02:35:45 visual_prompt]: 	Test 400/1152. loss: 0.479, 0.2022 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 02:36:05 visual_prompt]: 	Test 500/1152. loss: 0.371, 0.1860 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 02:36:24 visual_prompt]: 	Test 600/1152. loss: 0.948, 0.2072 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/19 02:36:44 visual_prompt]: 	Test 700/1152. loss: 0.883, 0.2011 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 02:37:03 visual_prompt]: 	Test 800/1152. loss: 0.630, 0.1822 s / batch. (data: 9.08e-05)max mem: 17.22454 GB 
[09/19 02:37:23 visual_prompt]: 	Test 900/1152. loss: 1.413, 0.2001 s / batch. (data: 1.80e-02)max mem: 17.22454 GB 
[09/19 02:37:42 visual_prompt]: 	Test 1000/1152. loss: 0.740, 0.1939 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 02:38:02 visual_prompt]: 	Test 1100/1152. loss: 0.431, 0.1923 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:38:16 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1943, average loss: 0.8938
[09/19 02:38:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.12	top5: 99.98	
[09/19 02:38:16 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/19 02:38:29 visual_prompt]: Epoch 94 / 100: avg data time: 2.36e-01, avg batch time: 0.6380, average train loss: 0.0185
[09/19 02:38:37 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1420, average loss: 0.0224
[09/19 02:38:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.00	top5: 100.00	
[09/19 02:39:00 visual_prompt]: 	Test 100/1152. loss: 1.347, 0.1918 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 02:39:20 visual_prompt]: 	Test 200/1152. loss: 1.069, 0.2125 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 02:39:39 visual_prompt]: 	Test 300/1152. loss: 1.234, 0.2273 s / batch. (data: 4.26e-02)max mem: 17.22454 GB 
[09/19 02:39:59 visual_prompt]: 	Test 400/1152. loss: 0.558, 0.1848 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 02:40:18 visual_prompt]: 	Test 500/1152. loss: 0.415, 0.2286 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 02:40:38 visual_prompt]: 	Test 600/1152. loss: 1.017, 0.1876 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 02:40:57 visual_prompt]: 	Test 700/1152. loss: 1.026, 0.2005 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 02:41:17 visual_prompt]: 	Test 800/1152. loss: 0.691, 0.1830 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:41:36 visual_prompt]: 	Test 900/1152. loss: 1.496, 0.1964 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 02:41:56 visual_prompt]: 	Test 1000/1152. loss: 0.839, 0.1825 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 02:42:15 visual_prompt]: 	Test 1100/1152. loss: 0.512, 0.1833 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 02:42:30 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1944, average loss: 1.0048
[09/19 02:42:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.67	top5: 99.98	
[09/19 02:42:30 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/19 02:42:44 visual_prompt]: Epoch 95 / 100: avg data time: 2.43e-01, avg batch time: 0.6448, average train loss: 0.0161
[09/19 02:42:51 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1419, average loss: 0.0136
[09/19 02:42:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 100.00	top5: 100.00	
[09/19 02:43:14 visual_prompt]: 	Test 100/1152. loss: 1.242, 0.1960 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 02:43:33 visual_prompt]: 	Test 200/1152. loss: 0.972, 0.1965 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 02:43:53 visual_prompt]: 	Test 300/1152. loss: 1.128, 0.1826 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 02:44:12 visual_prompt]: 	Test 400/1152. loss: 0.518, 0.1826 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 02:44:32 visual_prompt]: 	Test 500/1152. loss: 0.381, 0.2183 s / batch. (data: 3.47e-02)max mem: 17.22454 GB 
[09/19 02:44:51 visual_prompt]: 	Test 600/1152. loss: 0.992, 0.2061 s / batch. (data: 2.42e-02)max mem: 17.22454 GB 
[09/19 02:45:11 visual_prompt]: 	Test 700/1152. loss: 0.944, 0.1816 s / batch. (data: 2.84e-05)max mem: 17.22454 GB 
[09/19 02:45:30 visual_prompt]: 	Test 800/1152. loss: 0.695, 0.1868 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 02:45:50 visual_prompt]: 	Test 900/1152. loss: 1.430, 0.1888 s / batch. (data: 6.10e-03)max mem: 17.22454 GB 
[09/19 02:46:09 visual_prompt]: 	Test 1000/1152. loss: 0.805, 0.1934 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 02:46:29 visual_prompt]: 	Test 1100/1152. loss: 0.478, 0.1986 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 02:46:43 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1941, average loss: 0.9505
[09/19 02:46:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.69	top5: 99.99	
[09/19 02:46:44 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/19 02:46:57 visual_prompt]: Epoch 96 / 100: avg data time: 2.38e-01, avg batch time: 0.6407, average train loss: 0.0159
[09/19 02:47:05 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1423, average loss: 0.0143
[09/19 02:47:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 02:47:28 visual_prompt]: 	Test 100/1152. loss: 1.186, 0.1817 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:47:47 visual_prompt]: 	Test 200/1152. loss: 0.915, 0.1948 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 02:48:07 visual_prompt]: 	Test 300/1152. loss: 1.091, 0.1964 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 02:48:26 visual_prompt]: 	Test 400/1152. loss: 0.501, 0.1829 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:48:46 visual_prompt]: 	Test 500/1152. loss: 0.386, 0.2048 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/19 02:49:06 visual_prompt]: 	Test 600/1152. loss: 0.987, 0.1830 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 02:49:25 visual_prompt]: 	Test 700/1152. loss: 0.903, 0.1832 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 02:49:45 visual_prompt]: 	Test 800/1152. loss: 0.684, 0.2001 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 02:50:04 visual_prompt]: 	Test 900/1152. loss: 1.410, 0.2079 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 02:50:24 visual_prompt]: 	Test 1000/1152. loss: 0.769, 0.1834 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 02:50:43 visual_prompt]: 	Test 1100/1152. loss: 0.458, 0.1985 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 02:50:57 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1942, average loss: 0.9300
[09/19 02:50:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.06	top5: 99.98	
[09/19 02:50:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/19 02:51:11 visual_prompt]: Epoch 97 / 100: avg data time: 2.37e-01, avg batch time: 0.6371, average train loss: 0.0148
[09/19 02:51:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1422, average loss: 0.0134
[09/19 02:51:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 02:51:42 visual_prompt]: 	Test 100/1152. loss: 1.212, 0.1963 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 02:52:01 visual_prompt]: 	Test 200/1152. loss: 0.929, 0.1936 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 02:52:21 visual_prompt]: 	Test 300/1152. loss: 1.114, 0.1829 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 02:52:41 visual_prompt]: 	Test 400/1152. loss: 0.500, 0.2097 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 02:53:00 visual_prompt]: 	Test 500/1152. loss: 0.382, 0.1970 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 02:53:20 visual_prompt]: 	Test 600/1152. loss: 0.993, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 02:53:39 visual_prompt]: 	Test 700/1152. loss: 0.916, 0.1819 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 02:53:59 visual_prompt]: 	Test 800/1152. loss: 0.679, 0.1828 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 02:54:18 visual_prompt]: 	Test 900/1152. loss: 1.406, 0.1836 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:54:38 visual_prompt]: 	Test 1000/1152. loss: 0.776, 0.1831 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 02:54:57 visual_prompt]: 	Test 1100/1152. loss: 0.451, 0.1821 s / batch. (data: 9.99e-05)max mem: 17.22454 GB 
[09/19 02:55:12 visual_prompt]: Inference (test):avg data time: 8.30e-03, avg batch time: 0.1944, average loss: 0.9346
[09/19 02:55:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.05	top5: 99.99	
[09/19 02:55:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/19 02:55:25 visual_prompt]: Epoch 98 / 100: avg data time: 2.33e-01, avg batch time: 0.6362, average train loss: 0.0146
[09/19 02:55:33 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1423, average loss: 0.0130
[09/19 02:55:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 02:55:56 visual_prompt]: 	Test 100/1152. loss: 1.223, 0.1830 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 02:56:15 visual_prompt]: 	Test 200/1152. loss: 0.934, 0.1817 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 02:56:35 visual_prompt]: 	Test 300/1152. loss: 1.118, 0.1863 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 02:56:54 visual_prompt]: 	Test 400/1152. loss: 0.503, 0.1825 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 02:57:14 visual_prompt]: 	Test 500/1152. loss: 0.378, 0.1824 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 02:57:33 visual_prompt]: 	Test 600/1152. loss: 0.992, 0.1998 s / batch. (data: 1.78e-02)max mem: 17.22454 GB 
[09/19 02:57:53 visual_prompt]: 	Test 700/1152. loss: 0.925, 0.1850 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 02:58:12 visual_prompt]: 	Test 800/1152. loss: 0.676, 0.2011 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 02:58:32 visual_prompt]: 	Test 900/1152. loss: 1.412, 0.1828 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:58:51 visual_prompt]: 	Test 1000/1152. loss: 0.784, 0.1957 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 02:59:11 visual_prompt]: 	Test 1100/1152. loss: 0.452, 0.1974 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 02:59:25 visual_prompt]: Inference (test):avg data time: 7.73e-03, avg batch time: 0.1940, average loss: 0.9367
[09/19 02:59:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.02	top5: 99.99	
[09/19 02:59:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/19 02:59:39 visual_prompt]: Epoch 99 / 100: avg data time: 2.27e-01, avg batch time: 0.6318, average train loss: 0.0145
[09/19 02:59:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1429, average loss: 0.0132
[09/19 02:59:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 03:00:09 visual_prompt]: 	Test 100/1152. loss: 1.230, 0.1828 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 03:00:28 visual_prompt]: 	Test 200/1152. loss: 0.940, 0.1822 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 03:00:48 visual_prompt]: 	Test 300/1152. loss: 1.119, 0.2122 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 03:01:07 visual_prompt]: 	Test 400/1152. loss: 0.507, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:01:27 visual_prompt]: 	Test 500/1152. loss: 0.378, 0.2078 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 03:01:47 visual_prompt]: 	Test 600/1152. loss: 0.992, 0.1817 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 03:02:06 visual_prompt]: 	Test 700/1152. loss: 0.931, 0.1975 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 03:02:26 visual_prompt]: 	Test 800/1152. loss: 0.678, 0.2083 s / batch. (data: 8.99e-05)max mem: 17.22454 GB 
[09/19 03:02:45 visual_prompt]: 	Test 900/1152. loss: 1.419, 0.1958 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 03:03:05 visual_prompt]: 	Test 1000/1152. loss: 0.790, 0.1994 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 03:03:24 visual_prompt]: 	Test 1100/1152. loss: 0.453, 0.2005 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 03:03:39 visual_prompt]: Inference (test):avg data time: 7.90e-03, avg batch time: 0.1942, average loss: 0.9392
[09/19 03:03:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.98	top5: 99.99	
[09/19 03:03:39 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/19 03:03:53 visual_prompt]: Epoch 100 / 100: avg data time: 2.35e-01, avg batch time: 0.6369, average train loss: 0.0158
[09/19 03:04:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1423, average loss: 0.0131
[09/19 03:04:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 99.50	top5: 100.00	
[09/19 03:04:23 visual_prompt]: 	Test 100/1152. loss: 1.231, 0.1870 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:04:43 visual_prompt]: 	Test 200/1152. loss: 0.941, 0.2003 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 03:05:02 visual_prompt]: 	Test 300/1152. loss: 1.121, 0.1934 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 03:05:22 visual_prompt]: 	Test 400/1152. loss: 0.507, 0.1983 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 03:05:41 visual_prompt]: 	Test 500/1152. loss: 0.378, 0.1823 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 03:06:01 visual_prompt]: 	Test 600/1152. loss: 0.993, 0.1832 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 03:06:20 visual_prompt]: 	Test 700/1152. loss: 0.931, 0.1824 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 03:06:40 visual_prompt]: 	Test 800/1152. loss: 0.679, 0.1940 s / batch. (data: 1.19e-02)max mem: 17.22454 GB 
[09/19 03:06:59 visual_prompt]: 	Test 900/1152. loss: 1.420, 0.1921 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 03:07:18 visual_prompt]: 	Test 1000/1152. loss: 0.791, 0.1833 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 03:07:38 visual_prompt]: 	Test 1100/1152. loss: 0.453, 0.2142 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 03:07:52 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1937, average loss: 0.9398
[09/19 03:07:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 78.99	top5: 99.99	
[09/19 03:08:21 visual_prompt]: Rank of current process: 0. World size: 1
[09/19 03:08:21 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/19 03:08:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/19 03:08:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/19 03:08:21 visual_prompt]: Training with config:
[09/19 03:08:21 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/19 03:08:21 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-19 03:08:21.761041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-19 03:08:21.946536: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-19 03:08:27.086007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 03:08:27.086093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 03:08:27.086107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-19 03:08:36.362382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 03:08:36.362704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 03:08:36.362747: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/19 03:08:36 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-19 03:08:36.455369: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 03:08:38 visual_prompt]: Number of images: 1000
[09/19 03:08:38 visual_prompt]: Number of classes: 16 / 16
[09/19 03:08:38 visual_prompt]: Loading validation data...
[09/19 03:08:38 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 03:08:38 visual_prompt]: Number of images: 200
[09/19 03:08:38 visual_prompt]: Number of classes: 16 / 16
[09/19 03:08:38 visual_prompt]: Loading test data...
[09/19 03:08:38 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 03:10:10 visual_prompt]: Number of images: 73728
[09/19 03:10:10 visual_prompt]: Number of classes: 16 / 16
[09/19 03:10:10 visual_prompt]: Constructing models...
[09/19 03:10:13 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/19 03:10:13 visual_prompt]: tuned percent:1.077
[09/19 03:10:16 visual_prompt]: Device used for model: 0
[09/19 03:10:16 visual_prompt]: Setting up Evalutator...
[09/19 03:10:16 visual_prompt]: Setting up Trainer...
[09/19 03:10:16 visual_prompt]: 	Setting up the optimizer...
[09/19 03:10:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/19 03:10:31 visual_prompt]: Epoch 1 / 100: avg data time: 2.47e-01, avg batch time: 0.7368, average train loss: 3.0589
[09/19 03:10:38 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1423, average loss: 3.0507
[09/19 03:10:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.50	top5: 29.50	
[09/19 03:11:02 visual_prompt]: 	Test 100/1152. loss: 3.008, 0.1881 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 03:11:21 visual_prompt]: 	Test 200/1152. loss: 3.082, 0.1942 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 03:11:41 visual_prompt]: 	Test 300/1152. loss: 3.076, 0.2070 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 03:12:00 visual_prompt]: 	Test 400/1152. loss: 2.991, 0.2047 s / batch. (data: 2.30e-02)max mem: 17.22454 GB 
[09/19 03:12:20 visual_prompt]: 	Test 500/1152. loss: 2.975, 0.1946 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 03:12:39 visual_prompt]: 	Test 600/1152. loss: 3.141, 0.2193 s / batch. (data: 2.65e-02)max mem: 17.22454 GB 
[09/19 03:12:59 visual_prompt]: 	Test 700/1152. loss: 2.966, 0.1973 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 03:13:18 visual_prompt]: 	Test 800/1152. loss: 3.060, 0.2198 s / batch. (data: 3.81e-02)max mem: 17.22454 GB 
[09/19 03:13:38 visual_prompt]: 	Test 900/1152. loss: 3.270, 0.1917 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 03:13:57 visual_prompt]: 	Test 1000/1152. loss: 3.147, 0.2383 s / batch. (data: 4.56e-02)max mem: 17.22454 GB 
[09/19 03:14:17 visual_prompt]: 	Test 1100/1152. loss: 2.988, 0.1827 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 03:14:31 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1943, average loss: 3.0643
[09/19 03:14:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.31	top5: 31.32	
[09/19 03:14:31 visual_prompt]: Best epoch 1: best metric: 0.085
[09/19 03:14:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/19 03:14:45 visual_prompt]: Epoch 2 / 100: avg data time: 2.43e-01, avg batch time: 0.6429, average train loss: 3.5262
[09/19 03:14:53 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1432, average loss: 3.1553
[09/19 03:14:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 27.50	
[09/19 03:15:16 visual_prompt]: 	Test 100/1152. loss: 2.981, 0.1952 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 03:15:35 visual_prompt]: 	Test 200/1152. loss: 3.183, 0.1826 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 03:15:54 visual_prompt]: 	Test 300/1152. loss: 3.072, 0.1821 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 03:16:14 visual_prompt]: 	Test 400/1152. loss: 3.186, 0.1820 s / batch. (data: 9.27e-05)max mem: 17.22454 GB 
[09/19 03:16:34 visual_prompt]: 	Test 500/1152. loss: 3.287, 0.1999 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 03:16:53 visual_prompt]: 	Test 600/1152. loss: 3.209, 0.1970 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 03:17:13 visual_prompt]: 	Test 700/1152. loss: 3.250, 0.1954 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 03:17:32 visual_prompt]: 	Test 800/1152. loss: 3.117, 0.2059 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 03:17:52 visual_prompt]: 	Test 900/1152. loss: 3.236, 0.1967 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 03:18:11 visual_prompt]: 	Test 1000/1152. loss: 3.334, 0.2016 s / batch. (data: 1.96e-02)max mem: 17.22454 GB 
[09/19 03:18:31 visual_prompt]: 	Test 1100/1152. loss: 2.998, 0.1998 s / batch. (data: 1.76e-02)max mem: 17.22454 GB 
[09/19 03:18:45 visual_prompt]: Inference (test):avg data time: 7.45e-03, avg batch time: 0.1938, average loss: 3.1362
[09/19 03:18:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.33	
[09/19 03:18:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/19 03:18:59 visual_prompt]: Epoch 3 / 100: avg data time: 2.31e-01, avg batch time: 0.6341, average train loss: 3.0546
[09/19 03:19:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1440, average loss: 3.0830
[09/19 03:19:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 3.50	top5: 34.00	
[09/19 03:19:29 visual_prompt]: 	Test 100/1152. loss: 3.030, 0.1831 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 03:19:48 visual_prompt]: 	Test 200/1152. loss: 3.074, 0.1822 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 03:20:08 visual_prompt]: 	Test 300/1152. loss: 3.081, 0.1961 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 03:20:27 visual_prompt]: 	Test 400/1152. loss: 3.026, 0.1822 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 03:20:47 visual_prompt]: 	Test 500/1152. loss: 2.972, 0.2013 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 03:21:06 visual_prompt]: 	Test 600/1152. loss: 3.102, 0.1977 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 03:21:26 visual_prompt]: 	Test 700/1152. loss: 3.087, 0.1888 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 03:21:45 visual_prompt]: 	Test 800/1152. loss: 3.050, 0.2144 s / batch. (data: 2.17e-02)max mem: 17.22454 GB 
[09/19 03:22:05 visual_prompt]: 	Test 900/1152. loss: 3.073, 0.2182 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 03:22:24 visual_prompt]: 	Test 1000/1152. loss: 2.957, 0.2132 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 03:22:44 visual_prompt]: 	Test 1100/1152. loss: 3.216, 0.1827 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 03:22:58 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1936, average loss: 3.0820
[09/19 03:22:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.03	
[09/19 03:22:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/19 03:23:12 visual_prompt]: Epoch 4 / 100: avg data time: 2.43e-01, avg batch time: 0.6437, average train loss: 3.0534
[09/19 03:23:19 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1420, average loss: 3.0268
[09/19 03:23:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 31.00	
[09/19 03:23:42 visual_prompt]: 	Test 100/1152. loss: 3.165, 0.1814 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 03:24:01 visual_prompt]: 	Test 200/1152. loss: 2.969, 0.1967 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 03:24:21 visual_prompt]: 	Test 300/1152. loss: 3.038, 0.1822 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:24:40 visual_prompt]: 	Test 400/1152. loss: 2.803, 0.1950 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 03:25:00 visual_prompt]: 	Test 500/1152. loss: 2.944, 0.1822 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:25:19 visual_prompt]: 	Test 600/1152. loss: 2.967, 0.1827 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 03:25:38 visual_prompt]: 	Test 700/1152. loss: 2.878, 0.1831 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 03:25:58 visual_prompt]: 	Test 800/1152. loss: 2.954, 0.1942 s / batch. (data: 9.87e-05)max mem: 17.22454 GB 
[09/19 03:26:17 visual_prompt]: 	Test 900/1152. loss: 3.007, 0.1871 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 03:26:37 visual_prompt]: 	Test 1000/1152. loss: 2.982, 0.1855 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 03:26:57 visual_prompt]: 	Test 1100/1152. loss: 2.915, 0.2023 s / batch. (data: 2.02e-02)max mem: 17.22454 GB 
[09/19 03:27:11 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1934, average loss: 2.9727
[09/19 03:27:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.34	top5: 31.31	
[09/19 03:27:11 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/19 03:27:25 visual_prompt]: Epoch 5 / 100: avg data time: 2.37e-01, avg batch time: 0.6400, average train loss: 3.0801
[09/19 03:27:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1422, average loss: 2.9887
[09/19 03:27:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 32.00	
[09/19 03:27:56 visual_prompt]: 	Test 100/1152. loss: 2.969, 0.2119 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 03:28:15 visual_prompt]: 	Test 200/1152. loss: 3.212, 0.2109 s / batch. (data: 2.91e-02)max mem: 17.22454 GB 
[09/19 03:28:35 visual_prompt]: 	Test 300/1152. loss: 2.985, 0.2188 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 03:28:54 visual_prompt]: 	Test 400/1152. loss: 3.057, 0.1973 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 03:29:14 visual_prompt]: 	Test 500/1152. loss: 3.043, 0.1949 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 03:29:33 visual_prompt]: 	Test 600/1152. loss: 2.953, 0.1999 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 03:29:53 visual_prompt]: 	Test 700/1152. loss: 2.996, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:30:12 visual_prompt]: 	Test 800/1152. loss: 3.036, 0.1976 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 03:30:32 visual_prompt]: 	Test 900/1152. loss: 3.159, 0.2321 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/19 03:30:51 visual_prompt]: 	Test 1000/1152. loss: 3.121, 0.1935 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:31:11 visual_prompt]: 	Test 1100/1152. loss: 2.915, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 03:31:25 visual_prompt]: Inference (test):avg data time: 8.43e-03, avg batch time: 0.1941, average loss: 3.0202
[09/19 03:31:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.13	
[09/19 03:31:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/19 03:31:39 visual_prompt]: Epoch 6 / 100: avg data time: 2.46e-01, avg batch time: 0.6476, average train loss: 3.1316
[09/19 03:31:47 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1420, average loss: 3.1840
[09/19 03:31:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 31.00	
[09/19 03:32:10 visual_prompt]: 	Test 100/1152. loss: 3.080, 0.1968 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 03:32:29 visual_prompt]: 	Test 200/1152. loss: 3.002, 0.2155 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 03:32:48 visual_prompt]: 	Test 300/1152. loss: 3.225, 0.1817 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 03:33:08 visual_prompt]: 	Test 400/1152. loss: 3.365, 0.2187 s / batch. (data: 3.72e-02)max mem: 17.22454 GB 
[09/19 03:33:27 visual_prompt]: 	Test 500/1152. loss: 3.177, 0.1860 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 03:33:47 visual_prompt]: 	Test 600/1152. loss: 3.129, 0.2215 s / batch. (data: 3.55e-05)max mem: 17.22454 GB 
[09/19 03:34:06 visual_prompt]: 	Test 700/1152. loss: 3.314, 0.2091 s / batch. (data: 2.71e-02)max mem: 17.22454 GB 
[09/19 03:34:26 visual_prompt]: 	Test 800/1152. loss: 3.268, 0.1826 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 03:34:46 visual_prompt]: 	Test 900/1152. loss: 3.312, 0.2202 s / batch. (data: 3.85e-02)max mem: 17.22454 GB 
[09/19 03:35:05 visual_prompt]: 	Test 1000/1152. loss: 3.285, 0.1824 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 03:35:25 visual_prompt]: 	Test 1100/1152. loss: 3.209, 0.1828 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 03:35:39 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1940, average loss: 3.1900
[09/19 03:35:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.46	
[09/19 03:35:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/19 03:35:53 visual_prompt]: Epoch 7 / 100: avg data time: 2.45e-01, avg batch time: 0.6454, average train loss: 3.2045
[09/19 03:36:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1421, average loss: 3.5784
[09/19 03:36:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 31.00	
[09/19 03:36:24 visual_prompt]: 	Test 100/1152. loss: 3.614, 0.1825 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 03:36:44 visual_prompt]: 	Test 200/1152. loss: 3.211, 0.1962 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 03:37:03 visual_prompt]: 	Test 300/1152. loss: 3.655, 0.1932 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:37:22 visual_prompt]: 	Test 400/1152. loss: 3.647, 0.1828 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 03:37:42 visual_prompt]: 	Test 500/1152. loss: 3.437, 0.1875 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 03:38:01 visual_prompt]: 	Test 600/1152. loss: 3.502, 0.1833 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 03:38:21 visual_prompt]: 	Test 700/1152. loss: 3.702, 0.1941 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:38:40 visual_prompt]: 	Test 800/1152. loss: 3.675, 0.1823 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 03:39:00 visual_prompt]: 	Test 900/1152. loss: 3.460, 0.1838 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 03:39:19 visual_prompt]: 	Test 1000/1152. loss: 3.457, 0.1819 s / batch. (data: 3.50e-05)max mem: 17.22454 GB 
[09/19 03:39:39 visual_prompt]: 	Test 1100/1152. loss: 3.666, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 03:39:53 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1938, average loss: 3.5348
[09/19 03:39:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.32	
[09/19 03:39:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/19 03:40:07 visual_prompt]: Epoch 8 / 100: avg data time: 2.39e-01, avg batch time: 0.6420, average train loss: 3.2796
[09/19 03:40:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1424, average loss: 3.0103
[09/19 03:40:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 30.50	
[09/19 03:40:38 visual_prompt]: 	Test 100/1152. loss: 3.005, 0.2021 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 03:40:57 visual_prompt]: 	Test 200/1152. loss: 2.886, 0.2072 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/19 03:41:17 visual_prompt]: 	Test 300/1152. loss: 2.948, 0.1822 s / batch. (data: 9.85e-05)max mem: 17.22454 GB 
[09/19 03:41:36 visual_prompt]: 	Test 400/1152. loss: 3.140, 0.1884 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 03:41:56 visual_prompt]: 	Test 500/1152. loss: 3.123, 0.1823 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 03:42:15 visual_prompt]: 	Test 600/1152. loss: 2.927, 0.1898 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 03:42:35 visual_prompt]: 	Test 700/1152. loss: 3.062, 0.1960 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 03:42:54 visual_prompt]: 	Test 800/1152. loss: 2.908, 0.1859 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 03:43:13 visual_prompt]: 	Test 900/1152. loss: 2.858, 0.1966 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 03:43:33 visual_prompt]: 	Test 1000/1152. loss: 2.836, 0.1955 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 03:43:53 visual_prompt]: 	Test 1100/1152. loss: 3.047, 0.1836 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 03:44:07 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1941, average loss: 3.0043
[09/19 03:44:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.17	top5: 31.21	
[09/19 03:44:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/19 03:44:21 visual_prompt]: Epoch 9 / 100: avg data time: 2.43e-01, avg batch time: 0.6443, average train loss: 3.3611
[09/19 03:44:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1460, average loss: 3.1995
[09/19 03:44:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 38.50	
[09/19 03:44:52 visual_prompt]: 	Test 100/1152. loss: 3.446, 0.1822 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 03:45:11 visual_prompt]: 	Test 200/1152. loss: 3.023, 0.1971 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 03:45:31 visual_prompt]: 	Test 300/1152. loss: 3.084, 0.2145 s / batch. (data: 5.05e-05)max mem: 17.22454 GB 
[09/19 03:45:50 visual_prompt]: 	Test 400/1152. loss: 3.174, 0.1986 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:46:10 visual_prompt]: 	Test 500/1152. loss: 3.217, 0.2038 s / batch. (data: 2.16e-02)max mem: 17.22454 GB 
[09/19 03:46:29 visual_prompt]: 	Test 600/1152. loss: 3.022, 0.2037 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 03:46:49 visual_prompt]: 	Test 700/1152. loss: 3.232, 0.1830 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 03:47:08 visual_prompt]: 	Test 800/1152. loss: 3.287, 0.1904 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 03:47:28 visual_prompt]: 	Test 900/1152. loss: 3.213, 0.1962 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 03:47:47 visual_prompt]: 	Test 1000/1152. loss: 2.945, 0.1910 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 03:48:07 visual_prompt]: 	Test 1100/1152. loss: 3.436, 0.2205 s / batch. (data: 3.37e-02)max mem: 17.22454 GB 
[09/19 03:48:22 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1942, average loss: 3.1907
[09/19 03:48:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 34.79	
[09/19 03:48:22 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/19 03:48:35 visual_prompt]: Epoch 10 / 100: avg data time: 2.39e-01, avg batch time: 0.6405, average train loss: 3.3017
[09/19 03:48:43 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1429, average loss: 4.7942
[09/19 03:48:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 3.50	top5: 30.50	
[09/19 03:49:06 visual_prompt]: 	Test 100/1152. loss: 3.335, 0.1962 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 03:49:25 visual_prompt]: 	Test 200/1152. loss: 4.632, 0.1873 s / batch. (data: 8.30e-05)max mem: 17.22454 GB 
[09/19 03:49:45 visual_prompt]: 	Test 300/1152. loss: 3.919, 0.1953 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 03:50:04 visual_prompt]: 	Test 400/1152. loss: 5.063, 0.1827 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 03:50:24 visual_prompt]: 	Test 500/1152. loss: 4.863, 0.2137 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 03:50:43 visual_prompt]: 	Test 600/1152. loss: 4.426, 0.1821 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 03:51:02 visual_prompt]: 	Test 700/1152. loss: 4.030, 0.1917 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 03:51:22 visual_prompt]: 	Test 800/1152. loss: 4.902, 0.1830 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 03:51:41 visual_prompt]: 	Test 900/1152. loss: 5.224, 0.2160 s / batch. (data: 1.93e-02)max mem: 17.22454 GB 
[09/19 03:52:01 visual_prompt]: 	Test 1000/1152. loss: 5.134, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 03:52:20 visual_prompt]: 	Test 1100/1152. loss: 5.165, 0.1972 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 03:52:35 visual_prompt]: Inference (test):avg data time: 7.21e-03, avg batch time: 0.1933, average loss: 4.6705
[09/19 03:52:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.06	
[09/19 03:52:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/19 03:52:48 visual_prompt]: Epoch 11 / 100: avg data time: 2.40e-01, avg batch time: 0.6434, average train loss: 6.7915
[09/19 03:52:56 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1418, average loss: 3.8632
[09/19 03:52:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 35.00	
[09/19 03:53:19 visual_prompt]: 	Test 100/1152. loss: 3.737, 0.1819 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 03:53:39 visual_prompt]: 	Test 200/1152. loss: 4.045, 0.1821 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 03:53:58 visual_prompt]: 	Test 300/1152. loss: 3.893, 0.1820 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 03:54:18 visual_prompt]: 	Test 400/1152. loss: 3.916, 0.1831 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 03:54:37 visual_prompt]: 	Test 500/1152. loss: 3.584, 0.1960 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 03:54:57 visual_prompt]: 	Test 600/1152. loss: 3.526, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 03:55:16 visual_prompt]: 	Test 700/1152. loss: 3.584, 0.1976 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 03:55:36 visual_prompt]: 	Test 800/1152. loss: 4.223, 0.1931 s / batch. (data: 1.04e-02)max mem: 17.22454 GB 
[09/19 03:55:55 visual_prompt]: 	Test 900/1152. loss: 4.158, 0.1917 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 03:56:15 visual_prompt]: 	Test 1000/1152. loss: 3.939, 0.1984 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 03:56:34 visual_prompt]: 	Test 1100/1152. loss: 4.265, 0.1867 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 03:56:49 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1940, average loss: 3.9562
[09/19 03:56:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.24	top5: 31.33	
[09/19 03:56:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/19 03:57:02 visual_prompt]: Epoch 12 / 100: avg data time: 2.41e-01, avg batch time: 0.6433, average train loss: 17.5101
[09/19 03:57:10 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1422, average loss: 30.9175
[09/19 03:57:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 28.00	
[09/19 03:57:33 visual_prompt]: 	Test 100/1152. loss: 23.483, 0.2060 s / batch. (data: 2.47e-02)max mem: 17.22454 GB 
[09/19 03:57:52 visual_prompt]: 	Test 200/1152. loss: 29.193, 0.1976 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/19 03:58:12 visual_prompt]: 	Test 300/1152. loss: 27.790, 0.1858 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/19 03:58:31 visual_prompt]: 	Test 400/1152. loss: 28.944, 0.1959 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 03:58:50 visual_prompt]: 	Test 500/1152. loss: 27.377, 0.1944 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 03:59:10 visual_prompt]: 	Test 600/1152. loss: 28.148, 0.1969 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 03:59:30 visual_prompt]: 	Test 700/1152. loss: 28.245, 0.1826 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:59:49 visual_prompt]: 	Test 800/1152. loss: 31.004, 0.1819 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 04:00:09 visual_prompt]: 	Test 900/1152. loss: 33.997, 0.1956 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 04:00:28 visual_prompt]: 	Test 1000/1152. loss: 35.958, 0.1970 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 04:00:48 visual_prompt]: 	Test 1100/1152. loss: 32.067, 0.1888 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 04:01:02 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1942, average loss: 29.8318
[09/19 04:01:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.35	top5: 31.34	
[09/19 04:01:03 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/19 04:01:16 visual_prompt]: Epoch 13 / 100: avg data time: 2.42e-01, avg batch time: 0.6439, average train loss: 24.0698
[09/19 04:01:24 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1438, average loss: 15.4284
[09/19 04:01:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.50	top5: 33.00	
[09/19 04:01:47 visual_prompt]: 	Test 100/1152. loss: 16.161, 0.1819 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 04:02:06 visual_prompt]: 	Test 200/1152. loss: 15.678, 0.2006 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 04:02:26 visual_prompt]: 	Test 300/1152. loss: 16.237, 0.2126 s / batch. (data: 3.12e-02)max mem: 17.22454 GB 
[09/19 04:02:45 visual_prompt]: 	Test 400/1152. loss: 17.280, 0.1955 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 04:03:05 visual_prompt]: 	Test 500/1152. loss: 17.528, 0.1884 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 04:03:24 visual_prompt]: 	Test 600/1152. loss: 15.512, 0.1832 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 04:03:44 visual_prompt]: 	Test 700/1152. loss: 15.824, 0.1829 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 04:04:03 visual_prompt]: 	Test 800/1152. loss: 16.181, 0.2081 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/19 04:04:23 visual_prompt]: 	Test 900/1152. loss: 13.809, 0.1949 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 04:04:42 visual_prompt]: 	Test 1000/1152. loss: 13.057, 0.2201 s / batch. (data: 2.75e-02)max mem: 17.22454 GB 
[09/19 04:05:02 visual_prompt]: 	Test 1100/1152. loss: 16.937, 0.1840 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 04:05:16 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1941, average loss: 16.1676
[09/19 04:05:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.22	top5: 31.17	
[09/19 04:05:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/19 04:05:30 visual_prompt]: Epoch 14 / 100: avg data time: 2.46e-01, avg batch time: 0.6485, average train loss: 20.7297
[09/19 04:05:38 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1434, average loss: 25.2907
[09/19 04:05:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 35.00	
[09/19 04:06:01 visual_prompt]: 	Test 100/1152. loss: 22.887, 0.1969 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 04:06:20 visual_prompt]: 	Test 200/1152. loss: 25.183, 0.1829 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 04:06:39 visual_prompt]: 	Test 300/1152. loss: 26.111, 0.1864 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 04:06:59 visual_prompt]: 	Test 400/1152. loss: 26.717, 0.1877 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 04:07:19 visual_prompt]: 	Test 500/1152. loss: 28.500, 0.1950 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 04:07:38 visual_prompt]: 	Test 600/1152. loss: 26.531, 0.2010 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 04:07:57 visual_prompt]: 	Test 700/1152. loss: 29.386, 0.1829 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 04:08:17 visual_prompt]: 	Test 800/1152. loss: 26.365, 0.1826 s / batch. (data: 8.87e-05)max mem: 17.22454 GB 
[09/19 04:08:36 visual_prompt]: 	Test 900/1152. loss: 24.085, 0.1826 s / batch. (data: 2.93e-05)max mem: 17.22454 GB 
[09/19 04:08:56 visual_prompt]: 	Test 1000/1152. loss: 27.025, 0.1915 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 04:09:15 visual_prompt]: 	Test 1100/1152. loss: 28.169, 0.1982 s / batch. (data: 1.63e-02)max mem: 17.22454 GB 
[09/19 04:09:30 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1940, average loss: 26.3946
[09/19 04:09:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.17	
[09/19 04:09:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/19 04:09:44 visual_prompt]: Epoch 15 / 100: avg data time: 2.54e-01, avg batch time: 0.6542, average train loss: 24.2677
[09/19 04:09:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1465, average loss: 29.3514
[09/19 04:09:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 34.00	
[09/19 04:10:15 visual_prompt]: 	Test 100/1152. loss: 34.944, 0.1985 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 04:10:34 visual_prompt]: 	Test 200/1152. loss: 27.364, 0.1826 s / batch. (data: 8.03e-05)max mem: 17.22454 GB 
[09/19 04:10:53 visual_prompt]: 	Test 300/1152. loss: 28.569, 0.1993 s / batch. (data: 1.74e-02)max mem: 17.22454 GB 
[09/19 04:11:13 visual_prompt]: 	Test 400/1152. loss: 30.248, 0.1827 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 04:11:32 visual_prompt]: 	Test 500/1152. loss: 33.590, 0.1862 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 04:11:52 visual_prompt]: 	Test 600/1152. loss: 27.293, 0.1827 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 04:12:11 visual_prompt]: 	Test 700/1152. loss: 30.909, 0.2086 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 04:12:31 visual_prompt]: 	Test 800/1152. loss: 29.353, 0.1829 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 04:12:51 visual_prompt]: 	Test 900/1152. loss: 27.759, 0.2356 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 04:13:10 visual_prompt]: 	Test 1000/1152. loss: 29.514, 0.1833 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 04:13:29 visual_prompt]: 	Test 1100/1152. loss: 32.209, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 04:13:44 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1937, average loss: 30.3289
[09/19 04:13:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.18	
[09/19 04:13:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/19 04:13:58 visual_prompt]: Epoch 16 / 100: avg data time: 2.42e-01, avg batch time: 0.6433, average train loss: 24.8725
[09/19 04:14:05 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1422, average loss: 23.3488
[09/19 04:14:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 35.50	
[09/19 04:14:29 visual_prompt]: 	Test 100/1152. loss: 25.710, 0.1819 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 04:14:48 visual_prompt]: 	Test 200/1152. loss: 26.726, 0.1978 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 04:15:07 visual_prompt]: 	Test 300/1152. loss: 23.481, 0.2141 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 04:15:27 visual_prompt]: 	Test 400/1152. loss: 21.516, 0.2185 s / batch. (data: 3.66e-02)max mem: 17.22454 GB 
[09/19 04:15:47 visual_prompt]: 	Test 500/1152. loss: 24.022, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 04:16:06 visual_prompt]: 	Test 600/1152. loss: 24.878, 0.1824 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 04:16:26 visual_prompt]: 	Test 700/1152. loss: 21.266, 0.1957 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 04:16:45 visual_prompt]: 	Test 800/1152. loss: 25.769, 0.1828 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 04:17:05 visual_prompt]: 	Test 900/1152. loss: 25.966, 0.2183 s / batch. (data: 2.15e-02)max mem: 17.22454 GB 
[09/19 04:17:24 visual_prompt]: 	Test 1000/1152. loss: 21.890, 0.1827 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 04:17:44 visual_prompt]: 	Test 1100/1152. loss: 27.861, 0.1823 s / batch. (data: 9.61e-05)max mem: 17.22454 GB 
[09/19 04:17:58 visual_prompt]: Inference (test):avg data time: 8.63e-03, avg batch time: 0.1944, average loss: 24.4978
[09/19 04:17:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.19	
[09/19 04:17:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/19 04:18:12 visual_prompt]: Epoch 17 / 100: avg data time: 2.40e-01, avg batch time: 0.6421, average train loss: 16.5889
[09/19 04:18:20 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1420, average loss: 12.8267
[09/19 04:18:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 28.00	
[09/19 04:18:43 visual_prompt]: 	Test 100/1152. loss: 12.528, 0.1943 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 04:19:02 visual_prompt]: 	Test 200/1152. loss: 12.216, 0.1896 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 04:19:22 visual_prompt]: 	Test 300/1152. loss: 11.991, 0.1993 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 04:19:41 visual_prompt]: 	Test 400/1152. loss: 12.832, 0.1904 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 04:20:01 visual_prompt]: 	Test 500/1152. loss: 13.763, 0.1920 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/19 04:20:20 visual_prompt]: 	Test 600/1152. loss: 13.661, 0.1956 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 04:20:40 visual_prompt]: 	Test 700/1152. loss: 11.532, 0.1889 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 04:20:59 visual_prompt]: 	Test 800/1152. loss: 11.889, 0.1829 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 04:21:19 visual_prompt]: 	Test 900/1152. loss: 12.039, 0.1961 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 04:21:38 visual_prompt]: 	Test 1000/1152. loss: 11.129, 0.1822 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 04:21:58 visual_prompt]: 	Test 1100/1152. loss: 11.937, 0.1956 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 04:22:12 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1941, average loss: 12.4466
[09/19 04:22:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.17	top5: 31.27	
[09/19 04:22:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/19 04:22:26 visual_prompt]: Epoch 18 / 100: avg data time: 2.42e-01, avg batch time: 0.6434, average train loss: 18.4681
[09/19 04:22:34 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1420, average loss: 12.9063
[09/19 04:22:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 35.00	
[09/19 04:22:57 visual_prompt]: 	Test 100/1152. loss: 13.263, 0.1836 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 04:23:16 visual_prompt]: 	Test 200/1152. loss: 12.962, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 04:23:36 visual_prompt]: 	Test 300/1152. loss: 13.708, 0.2377 s / batch. (data: 5.61e-02)max mem: 17.22454 GB 
[09/19 04:23:55 visual_prompt]: 	Test 400/1152. loss: 12.021, 0.1895 s / batch. (data: 7.43e-03)max mem: 17.22454 GB 
[09/19 04:24:15 visual_prompt]: 	Test 500/1152. loss: 11.495, 0.2091 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 04:24:34 visual_prompt]: 	Test 600/1152. loss: 11.495, 0.1958 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 04:24:54 visual_prompt]: 	Test 700/1152. loss: 12.714, 0.1975 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 04:25:13 visual_prompt]: 	Test 800/1152. loss: 14.284, 0.1819 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 04:25:33 visual_prompt]: 	Test 900/1152. loss: 14.137, 0.1956 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 04:25:52 visual_prompt]: 	Test 1000/1152. loss: 14.359, 0.1821 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 04:26:12 visual_prompt]: 	Test 1100/1152. loss: 13.355, 0.1844 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 04:26:26 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1943, average loss: 12.9621
[09/19 04:26:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.17	top5: 31.28	
[09/19 04:26:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/19 04:26:40 visual_prompt]: Epoch 19 / 100: avg data time: 2.39e-01, avg batch time: 0.6389, average train loss: 11.2331
[09/19 04:26:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1427, average loss: 11.3928
[09/19 04:26:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 36.00	
[09/19 04:27:11 visual_prompt]: 	Test 100/1152. loss: 9.780, 0.1829 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 04:27:30 visual_prompt]: 	Test 200/1152. loss: 11.578, 0.1825 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 04:27:50 visual_prompt]: 	Test 300/1152. loss: 10.312, 0.2061 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 04:28:09 visual_prompt]: 	Test 400/1152. loss: 13.803, 0.1954 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 04:28:29 visual_prompt]: 	Test 500/1152. loss: 13.782, 0.1826 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 04:28:48 visual_prompt]: 	Test 600/1152. loss: 12.816, 0.2070 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 04:29:08 visual_prompt]: 	Test 700/1152. loss: 11.017, 0.2024 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 04:29:27 visual_prompt]: 	Test 800/1152. loss: 11.989, 0.1916 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 04:29:47 visual_prompt]: 	Test 900/1152. loss: 12.378, 0.2274 s / batch. (data: 4.56e-02)max mem: 17.22454 GB 
[09/19 04:30:06 visual_prompt]: 	Test 1000/1152. loss: 11.354, 0.1994 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 04:30:26 visual_prompt]: 	Test 1100/1152. loss: 12.771, 0.1831 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:30:40 visual_prompt]: Inference (test):avg data time: 7.71e-03, avg batch time: 0.1940, average loss: 11.9145
[09/19 04:30:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.20	
[09/19 04:30:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/19 04:30:54 visual_prompt]: Epoch 20 / 100: avg data time: 2.33e-01, avg batch time: 0.6357, average train loss: 10.2169
[09/19 04:31:01 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1427, average loss: 8.5606
[09/19 04:31:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 5.50	top5: 31.50	
[09/19 04:31:24 visual_prompt]: 	Test 100/1152. loss: 8.522, 0.1918 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 04:31:44 visual_prompt]: 	Test 200/1152. loss: 8.740, 0.1959 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 04:32:03 visual_prompt]: 	Test 300/1152. loss: 8.371, 0.1822 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 04:32:23 visual_prompt]: 	Test 400/1152. loss: 10.425, 0.2057 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 04:32:42 visual_prompt]: 	Test 500/1152. loss: 10.446, 0.1827 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 04:33:02 visual_prompt]: 	Test 600/1152. loss: 8.975, 0.1956 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 04:33:21 visual_prompt]: 	Test 700/1152. loss: 9.452, 0.1958 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 04:33:41 visual_prompt]: 	Test 800/1152. loss: 8.726, 0.2015 s / batch. (data: 1.89e-02)max mem: 17.22454 GB 
[09/19 04:34:01 visual_prompt]: 	Test 900/1152. loss: 8.738, 0.1828 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 04:34:20 visual_prompt]: 	Test 1000/1152. loss: 7.074, 0.2015 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 04:34:40 visual_prompt]: 	Test 1100/1152. loss: 9.100, 0.2083 s / batch. (data: 2.52e-02)max mem: 17.22454 GB 
[09/19 04:34:54 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1943, average loss: 8.9171
[09/19 04:34:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 31.29	
[09/19 04:34:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/19 04:35:08 visual_prompt]: Epoch 21 / 100: avg data time: 2.44e-01, avg batch time: 0.6472, average train loss: 7.1769
[09/19 04:35:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1430, average loss: 5.6382
[09/19 04:35:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 34.00	
[09/19 04:35:39 visual_prompt]: 	Test 100/1152. loss: 5.082, 0.1961 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 04:35:58 visual_prompt]: 	Test 200/1152. loss: 5.774, 0.1828 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 04:36:17 visual_prompt]: 	Test 300/1152. loss: 6.131, 0.1840 s / batch. (data: 3.48e-05)max mem: 17.22454 GB 
[09/19 04:36:37 visual_prompt]: 	Test 400/1152. loss: 6.100, 0.2119 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 04:36:56 visual_prompt]: 	Test 500/1152. loss: 4.434, 0.1820 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 04:37:16 visual_prompt]: 	Test 600/1152. loss: 5.411, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 04:37:35 visual_prompt]: 	Test 700/1152. loss: 6.030, 0.1969 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 04:37:55 visual_prompt]: 	Test 800/1152. loss: 6.053, 0.1896 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 04:38:14 visual_prompt]: 	Test 900/1152. loss: 7.190, 0.1833 s / batch. (data: 8.56e-05)max mem: 17.22454 GB 
[09/19 04:38:34 visual_prompt]: 	Test 1000/1152. loss: 6.683, 0.2118 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 04:38:53 visual_prompt]: 	Test 1100/1152. loss: 5.818, 0.1935 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 04:39:08 visual_prompt]: Inference (test):avg data time: 7.53e-03, avg batch time: 0.1934, average loss: 5.7273
[09/19 04:39:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 31.14	
[09/19 04:39:08 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/19 04:39:21 visual_prompt]: Epoch 22 / 100: avg data time: 2.54e-01, avg batch time: 0.6548, average train loss: 5.7177
[09/19 04:39:29 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1421, average loss: 3.4766
[09/19 04:39:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 34.00	
[09/19 04:39:52 visual_prompt]: 	Test 100/1152. loss: 3.333, 0.2075 s / batch. (data: 2.62e-02)max mem: 17.22454 GB 
[09/19 04:40:12 visual_prompt]: 	Test 200/1152. loss: 3.477, 0.2088 s / batch. (data: 2.61e-02)max mem: 17.22454 GB 
[09/19 04:40:31 visual_prompt]: 	Test 300/1152. loss: 3.546, 0.1964 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 04:40:51 visual_prompt]: 	Test 400/1152. loss: 3.473, 0.2079 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/19 04:41:10 visual_prompt]: 	Test 500/1152. loss: 2.912, 0.1988 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 04:41:30 visual_prompt]: 	Test 600/1152. loss: 3.132, 0.1978 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 04:41:49 visual_prompt]: 	Test 700/1152. loss: 3.476, 0.2226 s / batch. (data: 4.07e-02)max mem: 17.22454 GB 
[09/19 04:42:09 visual_prompt]: 	Test 800/1152. loss: 3.620, 0.1857 s / batch. (data: 3.76e-03)max mem: 17.22454 GB 
[09/19 04:42:28 visual_prompt]: 	Test 900/1152. loss: 3.792, 0.1835 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 04:42:48 visual_prompt]: 	Test 1000/1152. loss: 3.725, 0.1856 s / batch. (data: 9.89e-05)max mem: 17.22454 GB 
[09/19 04:43:07 visual_prompt]: 	Test 1100/1152. loss: 3.367, 0.1989 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 04:43:21 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1939, average loss: 3.4351
[09/19 04:43:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.35	top5: 31.37	
[09/19 04:43:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/19 04:43:35 visual_prompt]: Epoch 23 / 100: avg data time: 2.38e-01, avg batch time: 0.6402, average train loss: 3.7917
[09/19 04:43:43 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1421, average loss: 3.8777
[09/19 04:43:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 28.50	
[09/19 04:44:06 visual_prompt]: 	Test 100/1152. loss: 4.002, 0.2026 s / batch. (data: 2.12e-02)max mem: 17.22454 GB 
[09/19 04:44:25 visual_prompt]: 	Test 200/1152. loss: 3.960, 0.1869 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 04:44:45 visual_prompt]: 	Test 300/1152. loss: 3.799, 0.1917 s / batch. (data: 4.12e-05)max mem: 17.22454 GB 
[09/19 04:45:05 visual_prompt]: 	Test 400/1152. loss: 3.867, 0.1930 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/19 04:45:24 visual_prompt]: 	Test 500/1152. loss: 4.258, 0.1829 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 04:45:44 visual_prompt]: 	Test 600/1152. loss: 3.970, 0.1831 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:46:03 visual_prompt]: 	Test 700/1152. loss: 3.955, 0.1953 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 04:46:23 visual_prompt]: 	Test 800/1152. loss: 3.735, 0.1828 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 04:46:42 visual_prompt]: 	Test 900/1152. loss: 3.891, 0.1829 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 04:47:02 visual_prompt]: 	Test 1000/1152. loss: 3.965, 0.2112 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 04:47:21 visual_prompt]: 	Test 1100/1152. loss: 3.798, 0.1827 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 04:47:36 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1943, average loss: 3.8957
[09/19 04:47:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.04	
[09/19 04:47:36 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/19 04:47:50 visual_prompt]: Epoch 24 / 100: avg data time: 2.42e-01, avg batch time: 0.6451, average train loss: 3.5308
[09/19 04:47:57 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1418, average loss: 3.5582
[09/19 04:47:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 31.00	
[09/19 04:48:20 visual_prompt]: 	Test 100/1152. loss: 3.415, 0.1946 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 04:48:40 visual_prompt]: 	Test 200/1152. loss: 3.692, 0.2047 s / batch. (data: 9.32e-05)max mem: 17.22454 GB 
[09/19 04:48:59 visual_prompt]: 	Test 300/1152. loss: 3.551, 0.1918 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 04:49:19 visual_prompt]: 	Test 400/1152. loss: 3.772, 0.1876 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 04:49:38 visual_prompt]: 	Test 500/1152. loss: 3.356, 0.1958 s / batch. (data: 4.67e-05)max mem: 17.22454 GB 
[09/19 04:49:58 visual_prompt]: 	Test 600/1152. loss: 3.576, 0.1954 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 04:50:17 visual_prompt]: 	Test 700/1152. loss: 3.432, 0.2117 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 04:50:37 visual_prompt]: 	Test 800/1152. loss: 3.279, 0.1970 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 04:50:56 visual_prompt]: 	Test 900/1152. loss: 3.676, 0.1829 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 04:51:16 visual_prompt]: 	Test 1000/1152. loss: 3.482, 0.1827 s / batch. (data: 8.27e-05)max mem: 17.22454 GB 
[09/19 04:51:35 visual_prompt]: 	Test 1100/1152. loss: 3.432, 0.1961 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 04:51:50 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1941, average loss: 3.5679
[09/19 04:51:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.12	
[09/19 04:51:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/19 04:52:04 visual_prompt]: Epoch 25 / 100: avg data time: 2.38e-01, avg batch time: 0.6403, average train loss: 3.3751
[09/19 04:52:11 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1421, average loss: 3.2309
[09/19 04:52:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 31.50	
[09/19 04:52:34 visual_prompt]: 	Test 100/1152. loss: 2.976, 0.1914 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 04:52:53 visual_prompt]: 	Test 200/1152. loss: 3.151, 0.1948 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 04:53:13 visual_prompt]: 	Test 300/1152. loss: 3.205, 0.1836 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 04:53:33 visual_prompt]: 	Test 400/1152. loss: 3.293, 0.1982 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 04:53:52 visual_prompt]: 	Test 500/1152. loss: 3.042, 0.1827 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/19 04:54:12 visual_prompt]: 	Test 600/1152. loss: 3.364, 0.1958 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 04:54:31 visual_prompt]: 	Test 700/1152. loss: 3.232, 0.1931 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/19 04:54:51 visual_prompt]: 	Test 800/1152. loss: 3.318, 0.1822 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 04:55:10 visual_prompt]: 	Test 900/1152. loss: 3.413, 0.1905 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 04:55:30 visual_prompt]: 	Test 1000/1152. loss: 3.437, 0.1958 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 04:55:49 visual_prompt]: 	Test 1100/1152. loss: 3.253, 0.1956 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 04:56:04 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1943, average loss: 3.1941
[09/19 04:56:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.38	
[09/19 04:56:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/19 04:56:18 visual_prompt]: Epoch 26 / 100: avg data time: 2.41e-01, avg batch time: 0.6423, average train loss: 3.3224
[09/19 04:56:25 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1424, average loss: 3.6392
[09/19 04:56:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 3.50	top5: 28.00	
[09/19 04:56:48 visual_prompt]: 	Test 100/1152. loss: 3.633, 0.1902 s / batch. (data: 4.10e-05)max mem: 17.22454 GB 
[09/19 04:57:08 visual_prompt]: 	Test 200/1152. loss: 3.530, 0.1886 s / batch. (data: 6.63e-03)max mem: 17.22454 GB 
[09/19 04:57:27 visual_prompt]: 	Test 300/1152. loss: 3.728, 0.1896 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 04:57:47 visual_prompt]: 	Test 400/1152. loss: 3.507, 0.1858 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 04:58:06 visual_prompt]: 	Test 500/1152. loss: 3.769, 0.2204 s / batch. (data: 2.39e-02)max mem: 17.22454 GB 
[09/19 04:58:26 visual_prompt]: 	Test 600/1152. loss: 3.687, 0.1822 s / batch. (data: 9.51e-05)max mem: 17.22454 GB 
[09/19 04:58:45 visual_prompt]: 	Test 700/1152. loss: 3.580, 0.1830 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 04:59:05 visual_prompt]: 	Test 800/1152. loss: 3.550, 0.1826 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 04:59:25 visual_prompt]: 	Test 900/1152. loss: 3.326, 0.1975 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 04:59:44 visual_prompt]: 	Test 1000/1152. loss: 3.462, 0.1862 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 05:00:04 visual_prompt]: 	Test 1100/1152. loss: 3.420, 0.1823 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 05:00:18 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1948, average loss: 3.5550
[09/19 05:00:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.13	
[09/19 05:00:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/19 05:00:32 visual_prompt]: Epoch 27 / 100: avg data time: 2.37e-01, avg batch time: 0.6378, average train loss: 3.4731
[09/19 05:00:39 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1422, average loss: 3.2125
[09/19 05:00:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 35.50	
[09/19 05:01:02 visual_prompt]: 	Test 100/1152. loss: 3.397, 0.1997 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 05:01:22 visual_prompt]: 	Test 200/1152. loss: 3.219, 0.1959 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 05:01:41 visual_prompt]: 	Test 300/1152. loss: 3.109, 0.2214 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 05:02:01 visual_prompt]: 	Test 400/1152. loss: 3.353, 0.1820 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 05:02:20 visual_prompt]: 	Test 500/1152. loss: 3.627, 0.1819 s / batch. (data: 4.17e-05)max mem: 17.22454 GB 
[09/19 05:02:40 visual_prompt]: 	Test 600/1152. loss: 3.368, 0.1835 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 05:02:59 visual_prompt]: 	Test 700/1152. loss: 3.618, 0.2064 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 05:03:19 visual_prompt]: 	Test 800/1152. loss: 3.240, 0.1821 s / batch. (data: 3.10e-05)max mem: 17.22454 GB 
[09/19 05:03:39 visual_prompt]: 	Test 900/1152. loss: 3.497, 0.1959 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 05:03:58 visual_prompt]: 	Test 1000/1152. loss: 3.578, 0.1833 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:04:18 visual_prompt]: 	Test 1100/1152. loss: 3.475, 0.1828 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 05:04:32 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1941, average loss: 3.3564
[09/19 05:04:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.11	
[09/19 05:04:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/19 05:04:46 visual_prompt]: Epoch 28 / 100: avg data time: 2.45e-01, avg batch time: 0.6462, average train loss: 3.1616
[09/19 05:04:54 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1420, average loss: 3.4116
[09/19 05:04:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 28.50	
[09/19 05:05:17 visual_prompt]: 	Test 100/1152. loss: 3.356, 0.2159 s / batch. (data: 3.43e-02)max mem: 17.22454 GB 
[09/19 05:05:36 visual_prompt]: 	Test 200/1152. loss: 3.334, 0.2065 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 05:05:56 visual_prompt]: 	Test 300/1152. loss: 3.372, 0.2117 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 05:06:15 visual_prompt]: 	Test 400/1152. loss: 3.216, 0.1829 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 05:06:35 visual_prompt]: 	Test 500/1152. loss: 3.312, 0.1962 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 05:06:54 visual_prompt]: 	Test 600/1152. loss: 3.415, 0.1822 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 05:07:13 visual_prompt]: 	Test 700/1152. loss: 3.335, 0.1949 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 05:07:33 visual_prompt]: 	Test 800/1152. loss: 3.444, 0.2041 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 05:07:53 visual_prompt]: 	Test 900/1152. loss: 3.452, 0.2060 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 05:08:12 visual_prompt]: 	Test 1000/1152. loss: 3.408, 0.2082 s / batch. (data: 2.63e-02)max mem: 17.22454 GB 
[09/19 05:08:31 visual_prompt]: 	Test 1100/1152. loss: 3.447, 0.1973 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 05:08:46 visual_prompt]: Inference (test):avg data time: 7.33e-03, avg batch time: 0.1937, average loss: 3.3939
[09/19 05:08:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.50	
[09/19 05:08:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/19 05:09:00 visual_prompt]: Epoch 29 / 100: avg data time: 2.40e-01, avg batch time: 0.6428, average train loss: 3.1826
[09/19 05:09:07 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1420, average loss: 3.3231
[09/19 05:09:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 3.50	top5: 30.00	
[09/19 05:09:30 visual_prompt]: 	Test 100/1152. loss: 3.552, 0.1819 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 05:09:50 visual_prompt]: 	Test 200/1152. loss: 3.291, 0.2108 s / batch. (data: 1.69e-02)max mem: 17.22454 GB 
[09/19 05:10:09 visual_prompt]: 	Test 300/1152. loss: 3.295, 0.2237 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 05:10:29 visual_prompt]: 	Test 400/1152. loss: 3.285, 0.2104 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:10:48 visual_prompt]: 	Test 500/1152. loss: 3.359, 0.1917 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 05:11:08 visual_prompt]: 	Test 600/1152. loss: 3.336, 0.2053 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 05:11:28 visual_prompt]: 	Test 700/1152. loss: 3.280, 0.1990 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 05:11:47 visual_prompt]: 	Test 800/1152. loss: 3.325, 0.1978 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/19 05:12:07 visual_prompt]: 	Test 900/1152. loss: 3.201, 0.1952 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 05:12:26 visual_prompt]: 	Test 1000/1152. loss: 3.022, 0.1828 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 05:12:46 visual_prompt]: 	Test 1100/1152. loss: 3.325, 0.1904 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/19 05:13:00 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1945, average loss: 3.2873
[09/19 05:13:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.08	
[09/19 05:13:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/19 05:13:14 visual_prompt]: Epoch 30 / 100: avg data time: 2.47e-01, avg batch time: 0.6476, average train loss: 3.1491
[09/19 05:13:22 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1422, average loss: 3.2479
[09/19 05:13:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 29.00	
[09/19 05:13:45 visual_prompt]: 	Test 100/1152. loss: 3.246, 0.1963 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 05:14:04 visual_prompt]: 	Test 200/1152. loss: 3.124, 0.1958 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 05:14:24 visual_prompt]: 	Test 300/1152. loss: 3.206, 0.2423 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 05:14:44 visual_prompt]: 	Test 400/1152. loss: 3.043, 0.1954 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 05:15:03 visual_prompt]: 	Test 500/1152. loss: 3.176, 0.1967 s / batch. (data: 9.90e-03)max mem: 17.22454 GB 
[09/19 05:15:23 visual_prompt]: 	Test 600/1152. loss: 3.162, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 05:15:42 visual_prompt]: 	Test 700/1152. loss: 3.388, 0.1934 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 05:16:02 visual_prompt]: 	Test 800/1152. loss: 3.170, 0.2065 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 05:16:21 visual_prompt]: 	Test 900/1152. loss: 3.168, 0.1821 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 05:16:41 visual_prompt]: 	Test 1000/1152. loss: 3.462, 0.2122 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 05:17:00 visual_prompt]: 	Test 1100/1152. loss: 3.144, 0.1824 s / batch. (data: 3.98e-05)max mem: 17.22454 GB 
[09/19 05:17:15 visual_prompt]: Inference (test):avg data time: 8.19e-03, avg batch time: 0.1943, average loss: 3.1946
[09/19 05:17:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.34	top5: 31.50	
[09/19 05:17:15 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/19 05:17:28 visual_prompt]: Epoch 31 / 100: avg data time: 2.40e-01, avg batch time: 0.6387, average train loss: 3.0855
[09/19 05:17:36 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1420, average loss: 2.9692
[09/19 05:17:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 8.00	top5: 38.00	
[09/19 05:17:59 visual_prompt]: 	Test 100/1152. loss: 2.867, 0.2078 s / batch. (data: 2.63e-02)max mem: 17.22454 GB 
[09/19 05:18:18 visual_prompt]: 	Test 200/1152. loss: 3.114, 0.1984 s / batch. (data: 8.89e-05)max mem: 17.22454 GB 
[09/19 05:18:38 visual_prompt]: 	Test 300/1152. loss: 3.135, 0.1961 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 05:18:57 visual_prompt]: 	Test 400/1152. loss: 3.069, 0.2000 s / batch. (data: 1.62e-02)max mem: 17.22454 GB 
[09/19 05:19:17 visual_prompt]: 	Test 500/1152. loss: 2.966, 0.2157 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 05:19:36 visual_prompt]: 	Test 600/1152. loss: 3.158, 0.1839 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 05:19:56 visual_prompt]: 	Test 700/1152. loss: 2.951, 0.2157 s / batch. (data: 3.67e-05)max mem: 17.22454 GB 
[09/19 05:20:15 visual_prompt]: 	Test 800/1152. loss: 2.973, 0.1828 s / batch. (data: 1.98e-04)max mem: 17.22454 GB 
[09/19 05:20:35 visual_prompt]: 	Test 900/1152. loss: 3.139, 0.1826 s / batch. (data: 8.32e-05)max mem: 17.22454 GB 
[09/19 05:20:54 visual_prompt]: 	Test 1000/1152. loss: 3.085, 0.1906 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 05:21:14 visual_prompt]: 	Test 1100/1152. loss: 3.029, 0.1825 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 05:21:28 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1936, average loss: 3.0661
[09/19 05:21:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.16	top5: 31.13	
[09/19 05:21:29 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/19 05:21:42 visual_prompt]: Epoch 32 / 100: avg data time: 2.30e-01, avg batch time: 0.6335, average train loss: 3.0915
[09/19 05:21:49 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1420, average loss: 3.1077
[09/19 05:21:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 28.50	
[09/19 05:22:13 visual_prompt]: 	Test 100/1152. loss: 3.080, 0.1814 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 05:22:32 visual_prompt]: 	Test 200/1152. loss: 2.978, 0.1821 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 05:22:52 visual_prompt]: 	Test 300/1152. loss: 2.981, 0.2184 s / batch. (data: 3.38e-02)max mem: 17.22454 GB 
[09/19 05:23:11 visual_prompt]: 	Test 400/1152. loss: 2.966, 0.1816 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 05:23:31 visual_prompt]: 	Test 500/1152. loss: 3.184, 0.2085 s / batch. (data: 2.66e-02)max mem: 17.22454 GB 
[09/19 05:23:50 visual_prompt]: 	Test 600/1152. loss: 3.121, 0.2091 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 05:24:10 visual_prompt]: 	Test 700/1152. loss: 3.051, 0.2025 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 05:24:30 visual_prompt]: 	Test 800/1152. loss: 3.049, 0.2039 s / batch. (data: 3.08e-05)max mem: 17.22454 GB 
[09/19 05:24:49 visual_prompt]: 	Test 900/1152. loss: 3.021, 0.1826 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 05:25:08 visual_prompt]: 	Test 1000/1152. loss: 2.979, 0.1834 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 05:25:28 visual_prompt]: 	Test 1100/1152. loss: 2.954, 0.2001 s / batch. (data: 1.82e-02)max mem: 17.22454 GB 
[09/19 05:25:43 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1945, average loss: 3.0218
[09/19 05:25:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.32	top5: 31.01	
[09/19 05:25:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/19 05:25:56 visual_prompt]: Epoch 33 / 100: avg data time: 2.25e-01, avg batch time: 0.6307, average train loss: 3.1101
[09/19 05:26:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1434, average loss: 2.8990
[09/19 05:26:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 31.50	
[09/19 05:26:27 visual_prompt]: 	Test 100/1152. loss: 2.930, 0.1971 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 05:26:46 visual_prompt]: 	Test 200/1152. loss: 2.889, 0.1967 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 05:27:06 visual_prompt]: 	Test 300/1152. loss: 2.897, 0.1962 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 05:27:25 visual_prompt]: 	Test 400/1152. loss: 2.923, 0.1834 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/19 05:27:45 visual_prompt]: 	Test 500/1152. loss: 2.894, 0.1821 s / batch. (data: 8.85e-05)max mem: 17.22454 GB 
[09/19 05:28:04 visual_prompt]: 	Test 600/1152. loss: 2.950, 0.2123 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/19 05:28:24 visual_prompt]: 	Test 700/1152. loss: 2.946, 0.1998 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 05:28:43 visual_prompt]: 	Test 800/1152. loss: 2.877, 0.1822 s / batch. (data: 2.91e-05)max mem: 17.22454 GB 
[09/19 05:29:03 visual_prompt]: 	Test 900/1152. loss: 2.899, 0.1827 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 05:29:22 visual_prompt]: 	Test 1000/1152. loss: 2.872, 0.1832 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 05:29:42 visual_prompt]: 	Test 1100/1152. loss: 2.923, 0.1833 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/19 05:29:56 visual_prompt]: Inference (test):avg data time: 7.54e-03, avg batch time: 0.1937, average loss: 2.8910
[09/19 05:29:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.08	
[09/19 05:29:56 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/19 05:30:10 visual_prompt]: Epoch 34 / 100: avg data time: 2.39e-01, avg batch time: 0.6447, average train loss: 2.9046
[09/19 05:30:17 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1421, average loss: 2.8937
[09/19 05:30:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 10.50	top5: 45.00	
[09/19 05:30:40 visual_prompt]: 	Test 100/1152. loss: 2.641, 0.2000 s / batch. (data: 1.80e-02)max mem: 17.22454 GB 
[09/19 05:31:00 visual_prompt]: 	Test 200/1152. loss: 2.939, 0.2197 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 05:31:19 visual_prompt]: 	Test 300/1152. loss: 2.896, 0.1957 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 05:31:39 visual_prompt]: 	Test 400/1152. loss: 2.909, 0.2270 s / batch. (data: 4.52e-02)max mem: 17.22454 GB 
[09/19 05:31:58 visual_prompt]: 	Test 500/1152. loss: 2.732, 0.1830 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 05:32:18 visual_prompt]: 	Test 600/1152. loss: 2.771, 0.1880 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 05:32:37 visual_prompt]: 	Test 700/1152. loss: 2.827, 0.1916 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 05:32:57 visual_prompt]: 	Test 800/1152. loss: 2.888, 0.1826 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 05:33:16 visual_prompt]: 	Test 900/1152. loss: 2.835, 0.1828 s / batch. (data: 2.81e-05)max mem: 17.22454 GB 
[09/19 05:33:36 visual_prompt]: 	Test 1000/1152. loss: 3.081, 0.1977 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 05:33:55 visual_prompt]: 	Test 1100/1152. loss: 2.806, 0.1832 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:34:10 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1943, average loss: 2.8765
[09/19 05:34:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 12.80	top5: 42.47	
[09/19 05:34:10 visual_prompt]: Best epoch 34: best metric: 0.105
[09/19 05:34:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/19 05:34:24 visual_prompt]: Epoch 35 / 100: avg data time: 2.53e-01, avg batch time: 0.6542, average train loss: 2.7051
[09/19 05:34:31 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1420, average loss: 2.8265
[09/19 05:34:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 59.00	
[09/19 05:34:54 visual_prompt]: 	Test 100/1152. loss: 2.880, 0.1885 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 05:35:14 visual_prompt]: 	Test 200/1152. loss: 2.753, 0.1910 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 05:35:33 visual_prompt]: 	Test 300/1152. loss: 2.765, 0.1989 s / batch. (data: 5.21e-03)max mem: 17.22454 GB 
[09/19 05:35:53 visual_prompt]: 	Test 400/1152. loss: 2.615, 0.1989 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 05:36:12 visual_prompt]: 	Test 500/1152. loss: 2.497, 0.1973 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 05:36:32 visual_prompt]: 	Test 600/1152. loss: 2.695, 0.2004 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 05:36:51 visual_prompt]: 	Test 700/1152. loss: 2.657, 0.1829 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 05:37:11 visual_prompt]: 	Test 800/1152. loss: 2.858, 0.1933 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 05:37:30 visual_prompt]: 	Test 900/1152. loss: 2.603, 0.2018 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 05:37:50 visual_prompt]: 	Test 1000/1152. loss: 2.551, 0.1823 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 05:38:10 visual_prompt]: 	Test 1100/1152. loss: 2.757, 0.2237 s / batch. (data: 4.12e-02)max mem: 17.22454 GB 
[09/19 05:38:24 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1941, average loss: 2.7006
[09/19 05:38:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 10.46	top5: 58.92	
[09/19 05:38:24 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/19 05:38:38 visual_prompt]: Epoch 36 / 100: avg data time: 2.51e-01, avg batch time: 0.6515, average train loss: 2.4467
[09/19 05:38:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1454, average loss: 2.5164
[09/19 05:38:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 15.00	top5: 61.50	
[09/19 05:39:09 visual_prompt]: 	Test 100/1152. loss: 2.439, 0.2237 s / batch. (data: 3.01e-02)max mem: 17.22454 GB 
[09/19 05:39:28 visual_prompt]: 	Test 200/1152. loss: 2.625, 0.1823 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 05:39:47 visual_prompt]: 	Test 300/1152. loss: 2.751, 0.1822 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 05:40:07 visual_prompt]: 	Test 400/1152. loss: 2.494, 0.1955 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 05:40:27 visual_prompt]: 	Test 500/1152. loss: 2.622, 0.1933 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 05:40:46 visual_prompt]: 	Test 600/1152. loss: 2.709, 0.1921 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 05:41:06 visual_prompt]: 	Test 700/1152. loss: 2.447, 0.1843 s / batch. (data: 3.65e-05)max mem: 17.22454 GB 
[09/19 05:41:25 visual_prompt]: 	Test 800/1152. loss: 2.609, 0.1953 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 05:41:45 visual_prompt]: 	Test 900/1152. loss: 2.574, 0.1959 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 05:42:04 visual_prompt]: 	Test 1000/1152. loss: 2.562, 0.1963 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 05:42:24 visual_prompt]: 	Test 1100/1152. loss: 2.447, 0.1974 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 05:42:38 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1943, average loss: 2.5733
[09/19 05:42:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 11.98	top5: 59.12	
[09/19 05:42:38 visual_prompt]: Best epoch 36: best metric: 0.150
[09/19 05:42:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/19 05:42:52 visual_prompt]: Epoch 37 / 100: avg data time: 2.28e-01, avg batch time: 0.6309, average train loss: 2.5952
[09/19 05:42:59 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1420, average loss: 2.4820
[09/19 05:42:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 16.00	top5: 63.50	
[09/19 05:43:23 visual_prompt]: 	Test 100/1152. loss: 2.370, 0.1817 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 05:43:42 visual_prompt]: 	Test 200/1152. loss: 2.639, 0.1926 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 05:44:01 visual_prompt]: 	Test 300/1152. loss: 2.371, 0.1824 s / batch. (data: 8.99e-05)max mem: 17.22454 GB 
[09/19 05:44:21 visual_prompt]: 	Test 400/1152. loss: 2.464, 0.1822 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 05:44:40 visual_prompt]: 	Test 500/1152. loss: 2.417, 0.1944 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 05:45:00 visual_prompt]: 	Test 600/1152. loss: 2.384, 0.1980 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 05:45:19 visual_prompt]: 	Test 700/1152. loss: 2.248, 0.2126 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 05:45:39 visual_prompt]: 	Test 800/1152. loss: 2.542, 0.2085 s / batch. (data: 2.60e-02)max mem: 17.22454 GB 
[09/19 05:45:58 visual_prompt]: 	Test 900/1152. loss: 2.572, 0.1830 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 05:46:18 visual_prompt]: 	Test 1000/1152. loss: 2.474, 0.2071 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/19 05:46:37 visual_prompt]: 	Test 1100/1152. loss: 2.413, 0.2050 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 05:46:52 visual_prompt]: Inference (test):avg data time: 7.50e-03, avg batch time: 0.1936, average loss: 2.4569
[09/19 05:46:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 17.56	top5: 65.15	
[09/19 05:46:52 visual_prompt]: Best epoch 37: best metric: 0.160
[09/19 05:46:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/19 05:47:05 visual_prompt]: Epoch 38 / 100: avg data time: 2.40e-01, avg batch time: 0.6427, average train loss: 2.2179
[09/19 05:47:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1421, average loss: 1.9698
[09/19 05:47:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 27.50	top5: 83.50	
[09/19 05:47:36 visual_prompt]: 	Test 100/1152. loss: 1.898, 0.1971 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 05:47:55 visual_prompt]: 	Test 200/1152. loss: 2.119, 0.2090 s / batch. (data: 2.74e-02)max mem: 17.22454 GB 
[09/19 05:48:15 visual_prompt]: 	Test 300/1152. loss: 2.156, 0.1823 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 05:48:34 visual_prompt]: 	Test 400/1152. loss: 2.047, 0.2136 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 05:48:54 visual_prompt]: 	Test 500/1152. loss: 1.715, 0.1872 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 05:49:13 visual_prompt]: 	Test 600/1152. loss: 1.884, 0.2031 s / batch. (data: 2.12e-02)max mem: 17.22454 GB 
[09/19 05:49:33 visual_prompt]: 	Test 700/1152. loss: 1.909, 0.1894 s / batch. (data: 3.43e-05)max mem: 17.22454 GB 
[09/19 05:49:52 visual_prompt]: 	Test 800/1152. loss: 2.055, 0.1969 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 05:50:12 visual_prompt]: 	Test 900/1152. loss: 2.067, 0.1959 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 05:50:32 visual_prompt]: 	Test 1000/1152. loss: 2.038, 0.2105 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 05:50:51 visual_prompt]: 	Test 1100/1152. loss: 2.100, 0.1949 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 05:51:06 visual_prompt]: Inference (test):avg data time: 8.37e-03, avg batch time: 0.1944, average loss: 2.0158
[09/19 05:51:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 25.60	top5: 81.66	
[09/19 05:51:06 visual_prompt]: Best epoch 38: best metric: 0.275
[09/19 05:51:06 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/19 05:51:19 visual_prompt]: Epoch 39 / 100: avg data time: 2.40e-01, avg batch time: 0.6422, average train loss: 2.1956
[09/19 05:51:27 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1451, average loss: 2.0155
[09/19 05:51:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 23.50	top5: 77.50	
[09/19 05:51:50 visual_prompt]: 	Test 100/1152. loss: 2.163, 0.1833 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 05:52:09 visual_prompt]: 	Test 200/1152. loss: 2.152, 0.1826 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 05:52:29 visual_prompt]: 	Test 300/1152. loss: 2.219, 0.2314 s / batch. (data: 4.52e-02)max mem: 17.22454 GB 
[09/19 05:52:49 visual_prompt]: 	Test 400/1152. loss: 2.006, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 05:53:08 visual_prompt]: 	Test 500/1152. loss: 1.922, 0.2065 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 05:53:28 visual_prompt]: 	Test 600/1152. loss: 2.103, 0.1828 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 05:53:47 visual_prompt]: 	Test 700/1152. loss: 1.920, 0.2102 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 05:54:07 visual_prompt]: 	Test 800/1152. loss: 2.071, 0.1840 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 05:54:26 visual_prompt]: 	Test 900/1152. loss: 2.016, 0.2066 s / batch. (data: 1.96e-02)max mem: 17.22454 GB 
[09/19 05:54:46 visual_prompt]: 	Test 1000/1152. loss: 1.965, 0.1829 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 05:55:05 visual_prompt]: 	Test 1100/1152. loss: 2.132, 0.1956 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 05:55:20 visual_prompt]: Inference (test):avg data time: 8.41e-03, avg batch time: 0.1945, average loss: 2.0957
[09/19 05:55:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 20.37	top5: 75.93	
[09/19 05:55:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/19 05:55:34 visual_prompt]: Epoch 40 / 100: avg data time: 2.48e-01, avg batch time: 0.6505, average train loss: 1.9247
[09/19 05:55:41 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1420, average loss: 1.5740
[09/19 05:55:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 41.00	top5: 93.50	
[09/19 05:56:05 visual_prompt]: 	Test 100/1152. loss: 1.683, 0.1824 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 05:56:24 visual_prompt]: 	Test 200/1152. loss: 1.544, 0.1827 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 05:56:44 visual_prompt]: 	Test 300/1152. loss: 1.752, 0.2029 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 05:57:03 visual_prompt]: 	Test 400/1152. loss: 1.611, 0.1938 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 05:57:22 visual_prompt]: 	Test 500/1152. loss: 1.457, 0.1877 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 05:57:42 visual_prompt]: 	Test 600/1152. loss: 1.547, 0.1852 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 05:58:01 visual_prompt]: 	Test 700/1152. loss: 1.690, 0.2043 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 05:58:21 visual_prompt]: 	Test 800/1152. loss: 1.625, 0.1826 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 05:58:40 visual_prompt]: 	Test 900/1152. loss: 1.739, 0.1826 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/19 05:59:00 visual_prompt]: 	Test 1000/1152. loss: 1.630, 0.2101 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/19 05:59:19 visual_prompt]: 	Test 1100/1152. loss: 1.682, 0.1970 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 05:59:34 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1940, average loss: 1.6355
[09/19 05:59:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 33.81	top5: 95.52	
[09/19 05:59:34 visual_prompt]: Best epoch 40: best metric: 0.410
[09/19 05:59:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/19 05:59:48 visual_prompt]: Epoch 41 / 100: avg data time: 2.55e-01, avg batch time: 0.6547, average train loss: 1.8735
[09/19 05:59:56 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1430, average loss: 1.8400
[09/19 05:59:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 26.50	top5: 90.00	
[09/19 06:00:19 visual_prompt]: 	Test 100/1152. loss: 1.839, 0.1967 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 06:00:38 visual_prompt]: 	Test 200/1152. loss: 1.903, 0.2183 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 06:00:58 visual_prompt]: 	Test 300/1152. loss: 1.863, 0.2099 s / batch. (data: 2.80e-02)max mem: 17.22454 GB 
[09/19 06:01:17 visual_prompt]: 	Test 400/1152. loss: 1.851, 0.2078 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/19 06:01:37 visual_prompt]: 	Test 500/1152. loss: 2.016, 0.1941 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 06:01:56 visual_prompt]: 	Test 600/1152. loss: 2.130, 0.1945 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 06:02:16 visual_prompt]: 	Test 700/1152. loss: 1.787, 0.1822 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 06:02:35 visual_prompt]: 	Test 800/1152. loss: 1.815, 0.2017 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 06:02:55 visual_prompt]: 	Test 900/1152. loss: 1.903, 0.2178 s / batch. (data: 2.69e-02)max mem: 17.22454 GB 
[09/19 06:03:14 visual_prompt]: 	Test 1000/1152. loss: 1.588, 0.1827 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 06:03:34 visual_prompt]: 	Test 1100/1152. loss: 1.888, 0.1823 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 06:03:48 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1942, average loss: 1.8658
[09/19 06:03:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 27.75	top5: 88.85	
[09/19 06:03:49 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/19 06:04:03 visual_prompt]: Epoch 42 / 100: avg data time: 2.41e-01, avg batch time: 0.6457, average train loss: 1.7461
[09/19 06:04:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1422, average loss: 1.8573
[09/19 06:04:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 26.50	top5: 97.00	
[09/19 06:04:33 visual_prompt]: 	Test 100/1152. loss: 1.664, 0.1969 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:04:53 visual_prompt]: 	Test 200/1152. loss: 1.629, 0.1820 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 06:05:12 visual_prompt]: 	Test 300/1152. loss: 1.577, 0.1825 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 06:05:32 visual_prompt]: 	Test 400/1152. loss: 1.831, 0.2243 s / batch. (data: 2.78e-02)max mem: 17.22454 GB 
[09/19 06:05:51 visual_prompt]: 	Test 500/1152. loss: 1.824, 0.1929 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 06:06:11 visual_prompt]: 	Test 600/1152. loss: 1.758, 0.1830 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 06:06:30 visual_prompt]: 	Test 700/1152. loss: 1.727, 0.1820 s / batch. (data: 2.98e-05)max mem: 17.22454 GB 
[09/19 06:06:50 visual_prompt]: 	Test 800/1152. loss: 1.719, 0.2060 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 06:07:09 visual_prompt]: 	Test 900/1152. loss: 1.554, 0.2070 s / batch. (data: 2.50e-02)max mem: 17.22454 GB 
[09/19 06:07:29 visual_prompt]: 	Test 1000/1152. loss: 1.627, 0.1923 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 06:07:48 visual_prompt]: 	Test 1100/1152. loss: 1.824, 0.1829 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 06:08:02 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1940, average loss: 1.7618
[09/19 06:08:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 28.36	top5: 98.24	
[09/19 06:08:03 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/19 06:08:16 visual_prompt]: Epoch 43 / 100: avg data time: 2.49e-01, avg batch time: 0.6503, average train loss: 1.8389
[09/19 06:08:24 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1424, average loss: 1.7725
[09/19 06:08:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 27.00	top5: 90.50	
[09/19 06:08:47 visual_prompt]: 	Test 100/1152. loss: 1.808, 0.1967 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:09:06 visual_prompt]: 	Test 200/1152. loss: 1.820, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 06:09:26 visual_prompt]: 	Test 300/1152. loss: 1.873, 0.1963 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 06:09:45 visual_prompt]: 	Test 400/1152. loss: 1.793, 0.2013 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 06:10:05 visual_prompt]: 	Test 500/1152. loss: 1.612, 0.1998 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 06:10:25 visual_prompt]: 	Test 600/1152. loss: 1.720, 0.1961 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 06:10:44 visual_prompt]: 	Test 700/1152. loss: 1.811, 0.2054 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 06:11:04 visual_prompt]: 	Test 800/1152. loss: 1.870, 0.1875 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 06:11:23 visual_prompt]: 	Test 900/1152. loss: 2.108, 0.1910 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 06:11:43 visual_prompt]: 	Test 1000/1152. loss: 2.004, 0.2054 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 06:12:03 visual_prompt]: 	Test 1100/1152. loss: 1.870, 0.1934 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 06:12:17 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1948, average loss: 1.8526
[09/19 06:12:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 24.69	top5: 91.62	
[09/19 06:12:17 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/19 06:12:31 visual_prompt]: Epoch 44 / 100: avg data time: 2.37e-01, avg batch time: 0.6404, average train loss: 1.7067
[09/19 06:12:38 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1420, average loss: 1.5743
[09/19 06:12:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 34.50	top5: 92.00	
[09/19 06:13:01 visual_prompt]: 	Test 100/1152. loss: 1.893, 0.1819 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 06:13:21 visual_prompt]: 	Test 200/1152. loss: 1.579, 0.2032 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 06:13:40 visual_prompt]: 	Test 300/1152. loss: 1.697, 0.2037 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 06:14:00 visual_prompt]: 	Test 400/1152. loss: 1.532, 0.1993 s / batch. (data: 1.69e-02)max mem: 17.22454 GB 
[09/19 06:14:19 visual_prompt]: 	Test 500/1152. loss: 1.694, 0.1828 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 06:14:39 visual_prompt]: 	Test 600/1152. loss: 1.688, 0.1984 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 06:14:58 visual_prompt]: 	Test 700/1152. loss: 1.521, 0.2013 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 06:15:18 visual_prompt]: 	Test 800/1152. loss: 1.661, 0.1878 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 06:15:38 visual_prompt]: 	Test 900/1152. loss: 1.783, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:15:57 visual_prompt]: 	Test 1000/1152. loss: 1.738, 0.1953 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 06:16:16 visual_prompt]: 	Test 1100/1152. loss: 1.680, 0.1978 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:16:31 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1941, average loss: 1.6870
[09/19 06:16:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 32.11	top5: 93.51	
[09/19 06:16:31 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/19 06:16:44 visual_prompt]: Epoch 45 / 100: avg data time: 2.40e-01, avg batch time: 0.6408, average train loss: 1.6684
[09/19 06:16:52 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1421, average loss: 1.4979
[09/19 06:16:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 27.00	top5: 100.00	
[09/19 06:17:15 visual_prompt]: 	Test 100/1152. loss: 1.422, 0.1969 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 06:17:35 visual_prompt]: 	Test 200/1152. loss: 1.594, 0.1823 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 06:17:54 visual_prompt]: 	Test 300/1152. loss: 1.432, 0.1903 s / batch. (data: 4.15e-05)max mem: 17.22454 GB 
[09/19 06:18:14 visual_prompt]: 	Test 400/1152. loss: 1.551, 0.2093 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/19 06:18:33 visual_prompt]: 	Test 500/1152. loss: 1.625, 0.2179 s / batch. (data: 2.81e-02)max mem: 17.22454 GB 
[09/19 06:18:53 visual_prompt]: 	Test 600/1152. loss: 1.605, 0.1969 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 06:19:12 visual_prompt]: 	Test 700/1152. loss: 1.510, 0.2151 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 06:19:32 visual_prompt]: 	Test 800/1152. loss: 1.464, 0.1965 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 06:19:52 visual_prompt]: 	Test 900/1152. loss: 1.536, 0.1828 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 06:20:11 visual_prompt]: 	Test 1000/1152. loss: 1.394, 0.1978 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 06:20:31 visual_prompt]: 	Test 1100/1152. loss: 1.727, 0.1948 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 06:20:45 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1944, average loss: 1.5840
[09/19 06:20:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 27.44	top5: 99.82	
[09/19 06:20:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/19 06:20:59 visual_prompt]: Epoch 46 / 100: avg data time: 2.51e-01, avg batch time: 0.6506, average train loss: 1.6953
[09/19 06:21:06 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1422, average loss: 1.6667
[09/19 06:21:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 35.00	top5: 98.50	
[09/19 06:21:29 visual_prompt]: 	Test 100/1152. loss: 1.906, 0.1967 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 06:21:49 visual_prompt]: 	Test 200/1152. loss: 1.729, 0.1830 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:22:08 visual_prompt]: 	Test 300/1152. loss: 1.997, 0.1830 s / batch. (data: 9.80e-05)max mem: 17.22454 GB 
[09/19 06:22:28 visual_prompt]: 	Test 400/1152. loss: 1.702, 0.1825 s / batch. (data: 3.00e-05)max mem: 17.22454 GB 
[09/19 06:22:47 visual_prompt]: 	Test 500/1152. loss: 1.599, 0.1890 s / batch. (data: 2.98e-05)max mem: 17.22454 GB 
[09/19 06:23:07 visual_prompt]: 	Test 600/1152. loss: 1.580, 0.1968 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 06:23:26 visual_prompt]: 	Test 700/1152. loss: 1.945, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:23:46 visual_prompt]: 	Test 800/1152. loss: 1.787, 0.2009 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 06:24:05 visual_prompt]: 	Test 900/1152. loss: 1.931, 0.1962 s / batch. (data: 1.18e-02)max mem: 17.22454 GB 
[09/19 06:24:25 visual_prompt]: 	Test 1000/1152. loss: 2.115, 0.1967 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 06:24:44 visual_prompt]: 	Test 1100/1152. loss: 1.603, 0.1831 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 06:24:59 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1941, average loss: 1.7520
[09/19 06:24:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 34.10	top5: 98.11	
[09/19 06:24:59 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/19 06:25:13 visual_prompt]: Epoch 47 / 100: avg data time: 2.48e-01, avg batch time: 0.6501, average train loss: 1.6116
[09/19 06:25:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1438, average loss: 1.7464
[09/19 06:25:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 33.00	top5: 99.50	
[09/19 06:25:44 visual_prompt]: 	Test 100/1152. loss: 1.742, 0.1917 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 06:26:03 visual_prompt]: 	Test 200/1152. loss: 1.837, 0.1826 s / batch. (data: 4.27e-05)max mem: 17.22454 GB 
[09/19 06:26:22 visual_prompt]: 	Test 300/1152. loss: 1.724, 0.2025 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 06:26:42 visual_prompt]: 	Test 400/1152. loss: 1.933, 0.1971 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 06:27:02 visual_prompt]: 	Test 500/1152. loss: 1.837, 0.1952 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 06:27:21 visual_prompt]: 	Test 600/1152. loss: 1.756, 0.1833 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 06:27:41 visual_prompt]: 	Test 700/1152. loss: 1.698, 0.1972 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 06:28:00 visual_prompt]: 	Test 800/1152. loss: 1.772, 0.1821 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 06:28:20 visual_prompt]: 	Test 900/1152. loss: 1.666, 0.1826 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 06:28:39 visual_prompt]: 	Test 1000/1152. loss: 1.804, 0.2078 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/19 06:28:59 visual_prompt]: 	Test 1100/1152. loss: 1.761, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 06:29:13 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1943, average loss: 1.8135
[09/19 06:29:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 28.50	top5: 98.33	
[09/19 06:29:13 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/19 06:29:27 visual_prompt]: Epoch 48 / 100: avg data time: 2.44e-01, avg batch time: 0.6469, average train loss: 1.3983
[09/19 06:29:34 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1433, average loss: 1.5462
[09/19 06:29:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 33.50	top5: 99.50	
[09/19 06:29:58 visual_prompt]: 	Test 100/1152. loss: 1.550, 0.1829 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 06:30:17 visual_prompt]: 	Test 200/1152. loss: 1.694, 0.1836 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/19 06:30:36 visual_prompt]: 	Test 300/1152. loss: 1.449, 0.1826 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 06:30:56 visual_prompt]: 	Test 400/1152. loss: 1.391, 0.1829 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 06:31:15 visual_prompt]: 	Test 500/1152. loss: 1.595, 0.2030 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 06:31:35 visual_prompt]: 	Test 600/1152. loss: 1.523, 0.1830 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 06:31:55 visual_prompt]: 	Test 700/1152. loss: 1.422, 0.1974 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:32:14 visual_prompt]: 	Test 800/1152. loss: 1.552, 0.1830 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 06:32:34 visual_prompt]: 	Test 900/1152. loss: 1.492, 0.1829 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 06:32:53 visual_prompt]: 	Test 1000/1152. loss: 1.645, 0.1824 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 06:33:13 visual_prompt]: 	Test 1100/1152. loss: 1.420, 0.1918 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 06:33:27 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1944, average loss: 1.5452
[09/19 06:33:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 33.30	top5: 99.37	
[09/19 06:33:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/19 06:33:41 visual_prompt]: Epoch 49 / 100: avg data time: 2.35e-01, avg batch time: 0.6378, average train loss: 1.3238
[09/19 06:33:49 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1420, average loss: 1.0151
[09/19 06:33:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 56.50	top5: 100.00	
[09/19 06:34:12 visual_prompt]: 	Test 100/1152. loss: 1.144, 0.2121 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 06:34:31 visual_prompt]: 	Test 200/1152. loss: 1.025, 0.2115 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 06:34:51 visual_prompt]: 	Test 300/1152. loss: 1.126, 0.1958 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 06:35:10 visual_prompt]: 	Test 400/1152. loss: 1.012, 0.1957 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 06:35:30 visual_prompt]: 	Test 500/1152. loss: 1.062, 0.1993 s / batch. (data: 9.87e-05)max mem: 17.22454 GB 
[09/19 06:35:49 visual_prompt]: 	Test 600/1152. loss: 1.122, 0.1830 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 06:36:09 visual_prompt]: 	Test 700/1152. loss: 1.033, 0.1973 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:36:28 visual_prompt]: 	Test 800/1152. loss: 0.965, 0.1829 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 06:36:48 visual_prompt]: 	Test 900/1152. loss: 1.146, 0.1965 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 06:37:07 visual_prompt]: 	Test 1000/1152. loss: 1.186, 0.2029 s / batch. (data: 2.05e-02)max mem: 17.22454 GB 
[09/19 06:37:27 visual_prompt]: 	Test 1100/1152. loss: 0.945, 0.1824 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 06:37:41 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1940, average loss: 1.1017
[09/19 06:37:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.60	top5: 100.00	
[09/19 06:37:42 visual_prompt]: Best epoch 49: best metric: 0.565
[09/19 06:37:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/19 06:37:55 visual_prompt]: Epoch 50 / 100: avg data time: 2.34e-01, avg batch time: 0.6353, average train loss: 1.2050
[09/19 06:38:03 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1475, average loss: 1.6244
[09/19 06:38:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 35.00	top5: 99.50	
[09/19 06:38:26 visual_prompt]: 	Test 100/1152. loss: 1.764, 0.1824 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:38:45 visual_prompt]: 	Test 200/1152. loss: 1.827, 0.1825 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 06:39:05 visual_prompt]: 	Test 300/1152. loss: 1.722, 0.1878 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 06:39:24 visual_prompt]: 	Test 400/1152. loss: 1.671, 0.1823 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:39:44 visual_prompt]: 	Test 500/1152. loss: 1.711, 0.1913 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 06:40:03 visual_prompt]: 	Test 600/1152. loss: 1.509, 0.1949 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 06:40:23 visual_prompt]: 	Test 700/1152. loss: 1.498, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 06:40:43 visual_prompt]: 	Test 800/1152. loss: 1.747, 0.1982 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 06:41:02 visual_prompt]: 	Test 900/1152. loss: 1.812, 0.1829 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 06:41:21 visual_prompt]: 	Test 1000/1152. loss: 1.725, 0.2000 s / batch. (data: 1.74e-02)max mem: 17.22454 GB 
[09/19 06:41:41 visual_prompt]: 	Test 1100/1152. loss: 1.435, 0.1958 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 06:41:55 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1943, average loss: 1.6795
[09/19 06:41:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 37.53	top5: 99.83	
[09/19 06:41:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/19 06:42:09 visual_prompt]: Epoch 51 / 100: avg data time: 2.49e-01, avg batch time: 0.6498, average train loss: 1.2909
[09/19 06:42:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1421, average loss: 1.1806
[09/19 06:42:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.50	top5: 100.00	
[09/19 06:42:40 visual_prompt]: 	Test 100/1152. loss: 1.293, 0.1824 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/19 06:42:59 visual_prompt]: 	Test 200/1152. loss: 1.249, 0.1972 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:43:19 visual_prompt]: 	Test 300/1152. loss: 1.216, 0.1834 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 06:43:38 visual_prompt]: 	Test 400/1152. loss: 1.103, 0.2191 s / batch. (data: 9.91e-03)max mem: 17.22454 GB 
[09/19 06:43:58 visual_prompt]: 	Test 500/1152. loss: 1.102, 0.2015 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 06:44:18 visual_prompt]: 	Test 600/1152. loss: 1.198, 0.2021 s / batch. (data: 1.18e-02)max mem: 17.22454 GB 
[09/19 06:44:37 visual_prompt]: 	Test 700/1152. loss: 1.151, 0.2341 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 06:44:57 visual_prompt]: 	Test 800/1152. loss: 1.145, 0.1865 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 06:45:16 visual_prompt]: 	Test 900/1152. loss: 1.360, 0.1958 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 06:45:36 visual_prompt]: 	Test 1000/1152. loss: 1.258, 0.1960 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 06:45:55 visual_prompt]: 	Test 1100/1152. loss: 1.081, 0.2058 s / batch. (data: 1.78e-02)max mem: 17.22454 GB 
[09/19 06:46:10 visual_prompt]: Inference (test):avg data time: 8.45e-03, avg batch time: 0.1945, average loss: 1.2082
[09/19 06:46:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 43.79	top5: 99.99	
[09/19 06:46:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/19 06:46:23 visual_prompt]: Epoch 52 / 100: avg data time: 2.32e-01, avg batch time: 0.6361, average train loss: 1.2782
[09/19 06:46:31 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1450, average loss: 1.4698
[09/19 06:46:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 48.50	top5: 99.00	
[09/19 06:46:54 visual_prompt]: 	Test 100/1152. loss: 1.419, 0.1824 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 06:47:14 visual_prompt]: 	Test 200/1152. loss: 1.577, 0.1981 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/19 06:47:33 visual_prompt]: 	Test 300/1152. loss: 1.758, 0.1823 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 06:47:53 visual_prompt]: 	Test 400/1152. loss: 1.596, 0.1917 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 06:48:12 visual_prompt]: 	Test 500/1152. loss: 1.346, 0.2082 s / batch. (data: 1.73e-02)max mem: 17.22454 GB 
[09/19 06:48:31 visual_prompt]: 	Test 600/1152. loss: 1.588, 0.1833 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 06:48:51 visual_prompt]: 	Test 700/1152. loss: 1.773, 0.1826 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 06:49:10 visual_prompt]: 	Test 800/1152. loss: 1.605, 0.1827 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 06:49:30 visual_prompt]: 	Test 900/1152. loss: 1.875, 0.1961 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 06:49:49 visual_prompt]: 	Test 1000/1152. loss: 1.945, 0.2082 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/19 06:50:09 visual_prompt]: 	Test 1100/1152. loss: 1.668, 0.1972 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 06:50:23 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1939, average loss: 1.6365
[09/19 06:50:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.71	top5: 99.14	
[09/19 06:50:24 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/19 06:50:37 visual_prompt]: Epoch 53 / 100: avg data time: 2.52e-01, avg batch time: 0.6531, average train loss: 1.3179
[09/19 06:50:45 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1421, average loss: 1.0959
[09/19 06:50:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 51.00	top5: 100.00	
[09/19 06:51:08 visual_prompt]: 	Test 100/1152. loss: 1.284, 0.2159 s / batch. (data: 2.08e-02)max mem: 17.22454 GB 
[09/19 06:51:27 visual_prompt]: 	Test 200/1152. loss: 1.037, 0.1964 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 06:51:47 visual_prompt]: 	Test 300/1152. loss: 1.135, 0.1828 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 06:52:06 visual_prompt]: 	Test 400/1152. loss: 1.113, 0.1894 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/19 06:52:26 visual_prompt]: 	Test 500/1152. loss: 0.943, 0.1828 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 06:52:45 visual_prompt]: 	Test 600/1152. loss: 1.128, 0.2249 s / batch. (data: 2.80e-02)max mem: 17.22454 GB 
[09/19 06:53:05 visual_prompt]: 	Test 700/1152. loss: 1.268, 0.1962 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 06:53:25 visual_prompt]: 	Test 800/1152. loss: 1.173, 0.1952 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 06:53:44 visual_prompt]: 	Test 900/1152. loss: 1.192, 0.1953 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 06:54:04 visual_prompt]: 	Test 1000/1152. loss: 1.248, 0.1826 s / batch. (data: 9.61e-05)max mem: 17.22454 GB 
[09/19 06:54:23 visual_prompt]: 	Test 1100/1152. loss: 1.065, 0.1971 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 06:54:38 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1942, average loss: 1.1623
[09/19 06:54:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 47.78	top5: 99.95	
[09/19 06:54:38 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/19 06:54:52 visual_prompt]: Epoch 54 / 100: avg data time: 2.54e-01, avg batch time: 0.6546, average train loss: 1.0978
[09/19 06:54:59 visual_prompt]: Inference (val):avg data time: 4.77e-05, avg batch time: 0.1442, average loss: 1.2132
[09/19 06:54:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.50	top5: 100.00	
[09/19 06:55:23 visual_prompt]: 	Test 100/1152. loss: 1.296, 0.1820 s / batch. (data: 8.89e-05)max mem: 17.22454 GB 
[09/19 06:55:42 visual_prompt]: 	Test 200/1152. loss: 1.017, 0.2076 s / batch. (data: 2.62e-02)max mem: 17.22454 GB 
[09/19 06:56:01 visual_prompt]: 	Test 300/1152. loss: 1.058, 0.2212 s / batch. (data: 1.76e-02)max mem: 17.22454 GB 
[09/19 06:56:21 visual_prompt]: 	Test 400/1152. loss: 1.215, 0.2201 s / batch. (data: 3.79e-02)max mem: 17.22454 GB 
[09/19 06:56:41 visual_prompt]: 	Test 500/1152. loss: 1.235, 0.2028 s / batch. (data: 1.98e-02)max mem: 17.22454 GB 
[09/19 06:57:00 visual_prompt]: 	Test 600/1152. loss: 1.053, 0.1854 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 06:57:20 visual_prompt]: 	Test 700/1152. loss: 1.240, 0.1935 s / batch. (data: 8.93e-03)max mem: 17.22454 GB 
[09/19 06:57:39 visual_prompt]: 	Test 800/1152. loss: 1.208, 0.1902 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 06:57:59 visual_prompt]: 	Test 900/1152. loss: 1.050, 0.1832 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 06:58:18 visual_prompt]: 	Test 1000/1152. loss: 1.026, 0.1969 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 06:58:38 visual_prompt]: 	Test 1100/1152. loss: 1.201, 0.2265 s / batch. (data: 4.27e-02)max mem: 17.22454 GB 
[09/19 06:58:52 visual_prompt]: Inference (test):avg data time: 8.12e-03, avg batch time: 0.1941, average loss: 1.2136
[09/19 06:58:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.27	top5: 100.00	
[09/19 06:58:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/19 06:59:06 visual_prompt]: Epoch 55 / 100: avg data time: 2.49e-01, avg batch time: 0.6485, average train loss: 1.0941
[09/19 06:59:14 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1421, average loss: 1.3107
[09/19 06:59:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 45.00	top5: 100.00	
[09/19 06:59:37 visual_prompt]: 	Test 100/1152. loss: 1.263, 0.1823 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 06:59:56 visual_prompt]: 	Test 200/1152. loss: 1.254, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 07:00:15 visual_prompt]: 	Test 300/1152. loss: 1.326, 0.1873 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 07:00:35 visual_prompt]: 	Test 400/1152. loss: 1.484, 0.1822 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:00:55 visual_prompt]: 	Test 500/1152. loss: 1.238, 0.1822 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 07:01:14 visual_prompt]: 	Test 600/1152. loss: 1.368, 0.1823 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 07:01:34 visual_prompt]: 	Test 700/1152. loss: 1.321, 0.2111 s / batch. (data: 1.85e-02)max mem: 17.22454 GB 
[09/19 07:01:53 visual_prompt]: 	Test 800/1152. loss: 1.418, 0.1824 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 07:02:13 visual_prompt]: 	Test 900/1152. loss: 1.477, 0.1966 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 07:02:32 visual_prompt]: 	Test 1000/1152. loss: 1.484, 0.2110 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 07:02:52 visual_prompt]: 	Test 1100/1152. loss: 1.337, 0.1836 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 07:03:06 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1943, average loss: 1.4065
[09/19 07:03:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.37	top5: 99.91	
[09/19 07:03:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/19 07:03:20 visual_prompt]: Epoch 56 / 100: avg data time: 2.46e-01, avg batch time: 0.6474, average train loss: 1.0909
[09/19 07:03:28 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1430, average loss: 1.1719
[09/19 07:03:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 41.50	top5: 100.00	
[09/19 07:03:51 visual_prompt]: 	Test 100/1152. loss: 1.387, 0.2005 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/19 07:04:10 visual_prompt]: 	Test 200/1152. loss: 1.132, 0.1851 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 07:04:30 visual_prompt]: 	Test 300/1152. loss: 1.160, 0.1828 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 07:04:49 visual_prompt]: 	Test 400/1152. loss: 1.178, 0.2120 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 07:05:09 visual_prompt]: 	Test 500/1152. loss: 1.210, 0.2015 s / batch. (data: 1.94e-02)max mem: 17.22454 GB 
[09/19 07:05:29 visual_prompt]: 	Test 600/1152. loss: 1.272, 0.1951 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 07:05:48 visual_prompt]: 	Test 700/1152. loss: 1.421, 0.1965 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 07:06:08 visual_prompt]: 	Test 800/1152. loss: 1.142, 0.1931 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 07:06:27 visual_prompt]: 	Test 900/1152. loss: 1.351, 0.1933 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 07:06:47 visual_prompt]: 	Test 1000/1152. loss: 1.312, 0.2011 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/19 07:07:06 visual_prompt]: 	Test 1100/1152. loss: 1.156, 0.1952 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 07:07:21 visual_prompt]: Inference (test):avg data time: 8.22e-03, avg batch time: 0.1944, average loss: 1.2625
[09/19 07:07:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 40.54	top5: 100.00	
[09/19 07:07:21 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/19 07:07:35 visual_prompt]: Epoch 57 / 100: avg data time: 2.44e-01, avg batch time: 0.6466, average train loss: 1.0652
[09/19 07:07:42 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1421, average loss: 1.0448
[09/19 07:07:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.50	top5: 100.00	
[09/19 07:08:06 visual_prompt]: 	Test 100/1152. loss: 1.298, 0.1946 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 07:08:25 visual_prompt]: 	Test 200/1152. loss: 1.110, 0.1996 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 07:08:44 visual_prompt]: 	Test 300/1152. loss: 1.241, 0.1828 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 07:09:04 visual_prompt]: 	Test 400/1152. loss: 1.068, 0.1998 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 07:09:24 visual_prompt]: 	Test 500/1152. loss: 1.139, 0.1975 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 07:09:43 visual_prompt]: 	Test 600/1152. loss: 1.220, 0.2008 s / batch. (data: 1.87e-02)max mem: 17.22454 GB 
[09/19 07:10:03 visual_prompt]: 	Test 700/1152. loss: 1.038, 0.2009 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 07:10:22 visual_prompt]: 	Test 800/1152. loss: 0.941, 0.1829 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 07:10:42 visual_prompt]: 	Test 900/1152. loss: 1.202, 0.1977 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 07:11:01 visual_prompt]: 	Test 1000/1152. loss: 1.258, 0.2041 s / batch. (data: 2.18e-02)max mem: 17.22454 GB 
[09/19 07:11:21 visual_prompt]: 	Test 1100/1152. loss: 0.799, 0.1826 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 07:11:35 visual_prompt]: Inference (test):avg data time: 8.18e-03, avg batch time: 0.1941, average loss: 1.1411
[09/19 07:11:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 47.74	top5: 99.99	
[09/19 07:11:35 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/19 07:11:49 visual_prompt]: Epoch 58 / 100: avg data time: 2.46e-01, avg batch time: 0.6469, average train loss: 1.0179
[09/19 07:11:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1442, average loss: 0.8358
[09/19 07:11:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 58.00	top5: 100.00	
[09/19 07:12:20 visual_prompt]: 	Test 100/1152. loss: 0.933, 0.2184 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 07:12:39 visual_prompt]: 	Test 200/1152. loss: 0.829, 0.1958 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 07:12:58 visual_prompt]: 	Test 300/1152. loss: 0.887, 0.1888 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 07:13:18 visual_prompt]: 	Test 400/1152. loss: 0.815, 0.1873 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 07:13:37 visual_prompt]: 	Test 500/1152. loss: 0.916, 0.1950 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 07:13:57 visual_prompt]: 	Test 600/1152. loss: 0.774, 0.1822 s / batch. (data: 3.39e-05)max mem: 17.22454 GB 
[09/19 07:14:16 visual_prompt]: 	Test 700/1152. loss: 0.926, 0.1965 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 07:14:36 visual_prompt]: 	Test 800/1152. loss: 0.866, 0.2037 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 07:14:55 visual_prompt]: 	Test 900/1152. loss: 0.908, 0.1826 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 07:15:15 visual_prompt]: 	Test 1000/1152. loss: 0.861, 0.1955 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 07:15:34 visual_prompt]: 	Test 1100/1152. loss: 0.778, 0.2051 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 07:15:48 visual_prompt]: Inference (test):avg data time: 7.55e-03, avg batch time: 0.1940, average loss: 0.8652
[09/19 07:15:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.90	top5: 100.00	
[09/19 07:15:49 visual_prompt]: Best epoch 58: best metric: 0.580
[09/19 07:15:49 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/19 07:16:02 visual_prompt]: Epoch 59 / 100: avg data time: 2.36e-01, avg batch time: 0.6422, average train loss: 0.9303
[09/19 07:16:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1420, average loss: 1.3435
[09/19 07:16:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 57.50	top5: 100.00	
[09/19 07:16:33 visual_prompt]: 	Test 100/1152. loss: 1.490, 0.1950 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 07:16:53 visual_prompt]: 	Test 200/1152. loss: 0.925, 0.2008 s / batch. (data: 1.86e-02)max mem: 17.22454 GB 
[09/19 07:17:12 visual_prompt]: 	Test 300/1152. loss: 1.143, 0.1980 s / batch. (data: 2.77e-05)max mem: 17.22454 GB 
[09/19 07:17:32 visual_prompt]: 	Test 400/1152. loss: 1.476, 0.2087 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/19 07:17:51 visual_prompt]: 	Test 500/1152. loss: 1.566, 0.1823 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 07:18:11 visual_prompt]: 	Test 600/1152. loss: 1.310, 0.1827 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 07:18:30 visual_prompt]: 	Test 700/1152. loss: 1.423, 0.1830 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 07:18:50 visual_prompt]: 	Test 800/1152. loss: 1.158, 0.2391 s / batch. (data: 5.75e-02)max mem: 17.22454 GB 
[09/19 07:19:09 visual_prompt]: 	Test 900/1152. loss: 1.152, 0.1948 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 07:19:29 visual_prompt]: 	Test 1000/1152. loss: 1.177, 0.2068 s / batch. (data: 2.51e-02)max mem: 17.22454 GB 
[09/19 07:19:48 visual_prompt]: 	Test 1100/1152. loss: 1.114, 0.2077 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 07:20:03 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1943, average loss: 1.3439
[09/19 07:20:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 52.31	top5: 100.00	
[09/19 07:20:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/19 07:20:16 visual_prompt]: Epoch 60 / 100: avg data time: 2.45e-01, avg batch time: 0.6456, average train loss: 1.0739
[09/19 07:20:24 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1422, average loss: 0.8962
[09/19 07:20:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 62.50	top5: 100.00	
[09/19 07:20:48 visual_prompt]: 	Test 100/1152. loss: 1.031, 0.1966 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 07:21:07 visual_prompt]: 	Test 200/1152. loss: 0.803, 0.1932 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 07:21:26 visual_prompt]: 	Test 300/1152. loss: 0.869, 0.1825 s / batch. (data: 8.75e-05)max mem: 17.22454 GB 
[09/19 07:21:46 visual_prompt]: 	Test 400/1152. loss: 0.775, 0.1940 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 07:22:06 visual_prompt]: 	Test 500/1152. loss: 0.982, 0.2290 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 07:22:25 visual_prompt]: 	Test 600/1152. loss: 1.021, 0.2143 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 07:22:45 visual_prompt]: 	Test 700/1152. loss: 0.968, 0.2038 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 07:23:04 visual_prompt]: 	Test 800/1152. loss: 0.723, 0.2193 s / batch. (data: 3.79e-02)max mem: 17.22454 GB 
[09/19 07:23:24 visual_prompt]: 	Test 900/1152. loss: 0.983, 0.1971 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/19 07:23:43 visual_prompt]: 	Test 1000/1152. loss: 0.991, 0.1827 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 07:24:03 visual_prompt]: 	Test 1100/1152. loss: 0.677, 0.1821 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 07:24:17 visual_prompt]: Inference (test):avg data time: 8.07e-03, avg batch time: 0.1945, average loss: 0.9152
[09/19 07:24:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.80	top5: 100.00	
[09/19 07:24:17 visual_prompt]: Best epoch 60: best metric: 0.625
[09/19 07:24:17 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/19 07:24:31 visual_prompt]: Epoch 61 / 100: avg data time: 2.33e-01, avg batch time: 0.6358, average train loss: 0.9428
[09/19 07:24:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1422, average loss: 1.4091
[09/19 07:24:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 36.50	top5: 100.00	
[09/19 07:25:02 visual_prompt]: 	Test 100/1152. loss: 1.755, 0.1969 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 07:25:21 visual_prompt]: 	Test 200/1152. loss: 1.322, 0.1827 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 07:25:41 visual_prompt]: 	Test 300/1152. loss: 1.219, 0.2184 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/19 07:26:00 visual_prompt]: 	Test 400/1152. loss: 1.426, 0.1962 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 07:26:20 visual_prompt]: 	Test 500/1152. loss: 1.552, 0.1827 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 07:26:39 visual_prompt]: 	Test 600/1152. loss: 1.516, 0.2119 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 07:26:59 visual_prompt]: 	Test 700/1152. loss: 1.554, 0.2039 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 07:27:18 visual_prompt]: 	Test 800/1152. loss: 1.077, 0.1900 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 07:27:38 visual_prompt]: 	Test 900/1152. loss: 1.628, 0.2108 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:27:57 visual_prompt]: 	Test 1000/1152. loss: 1.540, 0.1883 s / batch. (data: 5.92e-03)max mem: 17.22454 GB 
[09/19 07:28:17 visual_prompt]: 	Test 1100/1152. loss: 1.137, 0.1833 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 07:28:31 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1941, average loss: 1.4398
[09/19 07:28:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 37.30	top5: 99.97	
[09/19 07:28:31 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/19 07:28:45 visual_prompt]: Epoch 62 / 100: avg data time: 2.47e-01, avg batch time: 0.6519, average train loss: 1.0943
[09/19 07:28:53 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1421, average loss: 1.2639
[09/19 07:28:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 39.50	top5: 100.00	
[09/19 07:29:16 visual_prompt]: 	Test 100/1152. loss: 1.459, 0.1822 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 07:29:35 visual_prompt]: 	Test 200/1152. loss: 1.332, 0.1843 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 07:29:55 visual_prompt]: 	Test 300/1152. loss: 1.446, 0.1825 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 07:30:14 visual_prompt]: 	Test 400/1152. loss: 1.328, 0.2093 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/19 07:30:34 visual_prompt]: 	Test 500/1152. loss: 1.186, 0.1984 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 07:30:53 visual_prompt]: 	Test 600/1152. loss: 1.393, 0.1879 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 07:31:12 visual_prompt]: 	Test 700/1152. loss: 1.245, 0.1830 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 07:31:32 visual_prompt]: 	Test 800/1152. loss: 1.392, 0.1827 s / batch. (data: 4.03e-05)max mem: 17.22454 GB 
[09/19 07:31:51 visual_prompt]: 	Test 900/1152. loss: 1.394, 0.2129 s / batch. (data: 3.06e-02)max mem: 17.22454 GB 
[09/19 07:32:11 visual_prompt]: 	Test 1000/1152. loss: 1.438, 0.1836 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 07:32:30 visual_prompt]: 	Test 1100/1152. loss: 1.185, 0.1827 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:32:45 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1935, average loss: 1.3296
[09/19 07:32:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 44.71	top5: 99.96	
[09/19 07:32:45 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/19 07:32:59 visual_prompt]: Epoch 63 / 100: avg data time: 2.38e-01, avg batch time: 0.6416, average train loss: 1.0478
[09/19 07:33:06 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1433, average loss: 1.1858
[09/19 07:33:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 50.00	top5: 100.00	
[09/19 07:33:29 visual_prompt]: 	Test 100/1152. loss: 1.390, 0.1829 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 07:33:49 visual_prompt]: 	Test 200/1152. loss: 1.474, 0.1960 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 07:34:08 visual_prompt]: 	Test 300/1152. loss: 1.345, 0.2079 s / batch. (data: 4.12e-05)max mem: 17.22454 GB 
[09/19 07:34:28 visual_prompt]: 	Test 400/1152. loss: 1.317, 0.1878 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 07:34:47 visual_prompt]: 	Test 500/1152. loss: 1.183, 0.1824 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 07:35:07 visual_prompt]: 	Test 600/1152. loss: 1.345, 0.1826 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 07:35:26 visual_prompt]: 	Test 700/1152. loss: 1.221, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 07:35:46 visual_prompt]: 	Test 800/1152. loss: 1.002, 0.1889 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 07:36:05 visual_prompt]: 	Test 900/1152. loss: 1.227, 0.1827 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 07:36:25 visual_prompt]: 	Test 1000/1152. loss: 1.403, 0.1967 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 07:36:44 visual_prompt]: 	Test 1100/1152. loss: 0.857, 0.2207 s / batch. (data: 2.32e-02)max mem: 17.22454 GB 
[09/19 07:36:59 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1941, average loss: 1.2630
[09/19 07:36:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 46.68	top5: 99.97	
[09/19 07:36:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/19 07:37:12 visual_prompt]: Epoch 64 / 100: avg data time: 2.39e-01, avg batch time: 0.6401, average train loss: 0.9036
[09/19 07:37:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1437, average loss: 1.0885
[09/19 07:37:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 55.00	top5: 100.00	
[09/19 07:37:43 visual_prompt]: 	Test 100/1152. loss: 1.124, 0.1959 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 07:38:03 visual_prompt]: 	Test 200/1152. loss: 1.373, 0.2177 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 07:38:22 visual_prompt]: 	Test 300/1152. loss: 1.212, 0.1833 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:38:41 visual_prompt]: 	Test 400/1152. loss: 1.112, 0.1879 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 07:39:01 visual_prompt]: 	Test 500/1152. loss: 0.954, 0.1828 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 07:39:21 visual_prompt]: 	Test 600/1152. loss: 1.096, 0.2107 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 07:39:40 visual_prompt]: 	Test 700/1152. loss: 1.031, 0.1823 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 07:40:00 visual_prompt]: 	Test 800/1152. loss: 1.087, 0.1991 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 07:40:19 visual_prompt]: 	Test 900/1152. loss: 0.948, 0.1827 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 07:40:39 visual_prompt]: 	Test 1000/1152. loss: 1.262, 0.2007 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 07:40:58 visual_prompt]: 	Test 1100/1152. loss: 0.964, 0.1824 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:41:12 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1940, average loss: 1.1504
[09/19 07:41:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 53.95	top5: 100.00	
[09/19 07:41:13 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/19 07:41:26 visual_prompt]: Epoch 65 / 100: avg data time: 2.52e-01, avg batch time: 0.6533, average train loss: 0.9261
[09/19 07:41:34 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1432, average loss: 0.8734
[09/19 07:41:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.00	top5: 100.00	
[09/19 07:41:57 visual_prompt]: 	Test 100/1152. loss: 0.853, 0.1976 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 07:42:17 visual_prompt]: 	Test 200/1152. loss: 0.986, 0.1948 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 07:42:36 visual_prompt]: 	Test 300/1152. loss: 1.104, 0.1854 s / batch. (data: 3.25e-03)max mem: 17.22454 GB 
[09/19 07:42:56 visual_prompt]: 	Test 400/1152. loss: 0.897, 0.2007 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 07:43:15 visual_prompt]: 	Test 500/1152. loss: 0.964, 0.1828 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 07:43:35 visual_prompt]: 	Test 600/1152. loss: 1.012, 0.2174 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 07:43:54 visual_prompt]: 	Test 700/1152. loss: 0.929, 0.2126 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/19 07:44:14 visual_prompt]: 	Test 800/1152. loss: 1.023, 0.1985 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 07:44:33 visual_prompt]: 	Test 900/1152. loss: 1.127, 0.1958 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 07:44:52 visual_prompt]: 	Test 1000/1152. loss: 1.049, 0.1837 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 07:45:12 visual_prompt]: 	Test 1100/1152. loss: 0.808, 0.1832 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 07:45:26 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1939, average loss: 0.9839
[09/19 07:45:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 54.50	top5: 100.00	
[09/19 07:45:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/19 07:45:40 visual_prompt]: Epoch 66 / 100: avg data time: 2.37e-01, avg batch time: 0.6400, average train loss: 0.8945
[09/19 07:45:48 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1422, average loss: 0.8741
[09/19 07:45:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 58.00	top5: 100.00	
[09/19 07:46:11 visual_prompt]: 	Test 100/1152. loss: 1.127, 0.1847 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 07:46:30 visual_prompt]: 	Test 200/1152. loss: 0.879, 0.1834 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 07:46:50 visual_prompt]: 	Test 300/1152. loss: 1.000, 0.1994 s / batch. (data: 3.36e-05)max mem: 17.22454 GB 
[09/19 07:47:10 visual_prompt]: 	Test 400/1152. loss: 1.280, 0.1829 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 07:47:29 visual_prompt]: 	Test 500/1152. loss: 1.052, 0.2324 s / batch. (data: 5.05e-02)max mem: 17.22454 GB 
[09/19 07:47:49 visual_prompt]: 	Test 600/1152. loss: 1.167, 0.1845 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 07:48:08 visual_prompt]: 	Test 700/1152. loss: 1.088, 0.1832 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 07:48:28 visual_prompt]: 	Test 800/1152. loss: 0.957, 0.1891 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 07:48:48 visual_prompt]: 	Test 900/1152. loss: 1.227, 0.1959 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 07:49:07 visual_prompt]: 	Test 1000/1152. loss: 1.177, 0.1968 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 07:49:27 visual_prompt]: 	Test 1100/1152. loss: 0.865, 0.1957 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 07:49:41 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1943, average loss: 1.0976
[09/19 07:49:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 53.10	top5: 100.00	
[09/19 07:49:41 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/19 07:49:55 visual_prompt]: Epoch 67 / 100: avg data time: 2.48e-01, avg batch time: 0.6501, average train loss: 0.9479
[09/19 07:50:03 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1424, average loss: 0.8664
[09/19 07:50:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.00	top5: 100.00	
[09/19 07:50:26 visual_prompt]: 	Test 100/1152. loss: 1.070, 0.1964 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 07:50:45 visual_prompt]: 	Test 200/1152. loss: 1.026, 0.2065 s / batch. (data: 2.45e-02)max mem: 17.22454 GB 
[09/19 07:51:05 visual_prompt]: 	Test 300/1152. loss: 1.112, 0.1868 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 07:51:24 visual_prompt]: 	Test 400/1152. loss: 0.990, 0.1977 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 07:51:44 visual_prompt]: 	Test 500/1152. loss: 0.890, 0.1955 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 07:52:03 visual_prompt]: 	Test 600/1152. loss: 0.898, 0.1998 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 07:52:23 visual_prompt]: 	Test 700/1152. loss: 1.006, 0.1830 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 07:52:43 visual_prompt]: 	Test 800/1152. loss: 0.903, 0.2021 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 07:53:02 visual_prompt]: 	Test 900/1152. loss: 1.020, 0.1854 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 07:53:21 visual_prompt]: 	Test 1000/1152. loss: 1.091, 0.1919 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 07:53:41 visual_prompt]: 	Test 1100/1152. loss: 0.763, 0.1960 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 07:53:55 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1942, average loss: 0.9956
[09/19 07:53:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 55.94	top5: 99.99	
[09/19 07:53:56 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/19 07:54:09 visual_prompt]: Epoch 68 / 100: avg data time: 2.35e-01, avg batch time: 0.6363, average train loss: 0.8764
[09/19 07:54:17 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1422, average loss: 1.0162
[09/19 07:54:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.00	top5: 100.00	
[09/19 07:54:40 visual_prompt]: 	Test 100/1152. loss: 0.863, 0.1949 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 07:54:59 visual_prompt]: 	Test 200/1152. loss: 1.005, 0.2080 s / batch. (data: 2.66e-02)max mem: 17.22454 GB 
[09/19 07:55:19 visual_prompt]: 	Test 300/1152. loss: 1.144, 0.2034 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 07:55:39 visual_prompt]: 	Test 400/1152. loss: 0.947, 0.2052 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 07:55:58 visual_prompt]: 	Test 500/1152. loss: 0.873, 0.1828 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 07:56:18 visual_prompt]: 	Test 600/1152. loss: 1.153, 0.1861 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 07:56:37 visual_prompt]: 	Test 700/1152. loss: 1.077, 0.1829 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 07:56:57 visual_prompt]: 	Test 800/1152. loss: 1.212, 0.1826 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 07:57:16 visual_prompt]: 	Test 900/1152. loss: 1.063, 0.1825 s / batch. (data: 8.73e-05)max mem: 17.22454 GB 
[09/19 07:57:36 visual_prompt]: 	Test 1000/1152. loss: 1.291, 0.1826 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 07:57:55 visual_prompt]: 	Test 1100/1152. loss: 1.032, 0.1826 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 07:58:10 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1944, average loss: 1.0753
[09/19 07:58:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 59.06	top5: 100.00	
[09/19 07:58:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/19 07:58:23 visual_prompt]: Epoch 69 / 100: avg data time: 2.32e-01, avg batch time: 0.6335, average train loss: 0.8574
[09/19 07:58:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1446, average loss: 0.6482
[09/19 07:58:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 71.00	top5: 100.00	
[09/19 07:58:54 visual_prompt]: 	Test 100/1152. loss: 0.772, 0.1951 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 07:59:14 visual_prompt]: 	Test 200/1152. loss: 0.847, 0.1829 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 07:59:33 visual_prompt]: 	Test 300/1152. loss: 0.889, 0.1942 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 07:59:53 visual_prompt]: 	Test 400/1152. loss: 0.787, 0.1998 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 08:00:12 visual_prompt]: 	Test 500/1152. loss: 0.829, 0.1827 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 08:00:32 visual_prompt]: 	Test 600/1152. loss: 0.916, 0.2022 s / batch. (data: 1.97e-02)max mem: 17.22454 GB 
[09/19 08:00:51 visual_prompt]: 	Test 700/1152. loss: 0.744, 0.1827 s / batch. (data: 1.78e-04)max mem: 17.22454 GB 
[09/19 08:01:11 visual_prompt]: 	Test 800/1152. loss: 0.707, 0.1841 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 08:01:30 visual_prompt]: 	Test 900/1152. loss: 0.808, 0.1986 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/19 08:01:50 visual_prompt]: 	Test 1000/1152. loss: 0.711, 0.1828 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 08:02:09 visual_prompt]: 	Test 1100/1152. loss: 0.680, 0.1955 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 08:02:24 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1943, average loss: 0.8417
[09/19 08:02:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 60.90	top5: 100.00	
[09/19 08:02:24 visual_prompt]: Best epoch 69: best metric: 0.710
[09/19 08:02:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/19 08:02:38 visual_prompt]: Epoch 70 / 100: avg data time: 2.45e-01, avg batch time: 0.6469, average train loss: 0.8103
[09/19 08:02:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1424, average loss: 0.7376
[09/19 08:02:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.50	top5: 100.00	
[09/19 08:03:09 visual_prompt]: 	Test 100/1152. loss: 1.027, 0.1828 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 08:03:28 visual_prompt]: 	Test 200/1152. loss: 0.804, 0.1965 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 08:03:48 visual_prompt]: 	Test 300/1152. loss: 0.813, 0.1832 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 08:04:07 visual_prompt]: 	Test 400/1152. loss: 0.760, 0.1828 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 08:04:27 visual_prompt]: 	Test 500/1152. loss: 0.862, 0.1830 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 08:04:46 visual_prompt]: 	Test 600/1152. loss: 0.890, 0.1926 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:05:06 visual_prompt]: 	Test 700/1152. loss: 0.995, 0.1826 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 08:05:25 visual_prompt]: 	Test 800/1152. loss: 0.665, 0.1833 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 08:05:45 visual_prompt]: 	Test 900/1152. loss: 0.861, 0.1970 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 08:06:04 visual_prompt]: 	Test 1000/1152. loss: 0.933, 0.1827 s / batch. (data: 4.27e-05)max mem: 17.22454 GB 
[09/19 08:06:24 visual_prompt]: 	Test 1100/1152. loss: 0.692, 0.2198 s / batch. (data: 3.80e-02)max mem: 17.22454 GB 
[09/19 08:06:38 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1943, average loss: 0.8581
[09/19 08:06:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 62.91	top5: 100.00	
[09/19 08:06:38 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/19 08:06:52 visual_prompt]: Epoch 71 / 100: avg data time: 2.43e-01, avg batch time: 0.6448, average train loss: 0.7379
[09/19 08:06:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1438, average loss: 0.6227
[09/19 08:06:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.00	top5: 100.00	
[09/19 08:07:23 visual_prompt]: 	Test 100/1152. loss: 0.799, 0.1963 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 08:07:42 visual_prompt]: 	Test 200/1152. loss: 0.614, 0.1961 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 08:08:01 visual_prompt]: 	Test 300/1152. loss: 0.776, 0.2185 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 08:08:21 visual_prompt]: 	Test 400/1152. loss: 0.638, 0.1828 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 08:08:40 visual_prompt]: 	Test 500/1152. loss: 0.844, 0.1835 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 08:09:00 visual_prompt]: 	Test 600/1152. loss: 0.846, 0.2306 s / batch. (data: 2.96e-02)max mem: 17.22454 GB 
[09/19 08:09:19 visual_prompt]: 	Test 700/1152. loss: 0.794, 0.2006 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 08:09:39 visual_prompt]: 	Test 800/1152. loss: 0.574, 0.1828 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 08:09:58 visual_prompt]: 	Test 900/1152. loss: 0.694, 0.1824 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 08:10:18 visual_prompt]: 	Test 1000/1152. loss: 0.672, 0.1971 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 08:10:37 visual_prompt]: 	Test 1100/1152. loss: 0.541, 0.2081 s / batch. (data: 2.58e-02)max mem: 17.22454 GB 
[09/19 08:10:52 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1938, average loss: 0.7410
[09/19 08:10:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.67	top5: 100.00	
[09/19 08:10:52 visual_prompt]: Best epoch 71: best metric: 0.770
[09/19 08:10:52 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/19 08:11:06 visual_prompt]: Epoch 72 / 100: avg data time: 2.42e-01, avg batch time: 0.6472, average train loss: 0.6886
[09/19 08:11:13 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1421, average loss: 0.6941
[09/19 08:11:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.50	top5: 100.00	
[09/19 08:11:37 visual_prompt]: 	Test 100/1152. loss: 0.903, 0.1972 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 08:11:56 visual_prompt]: 	Test 200/1152. loss: 0.896, 0.2072 s / batch. (data: 2.56e-02)max mem: 17.22454 GB 
[09/19 08:12:16 visual_prompt]: 	Test 300/1152. loss: 1.121, 0.1926 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 08:12:35 visual_prompt]: 	Test 400/1152. loss: 0.961, 0.1930 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 08:12:55 visual_prompt]: 	Test 500/1152. loss: 0.806, 0.1981 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 08:13:15 visual_prompt]: 	Test 600/1152. loss: 0.970, 0.1827 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 08:13:34 visual_prompt]: 	Test 700/1152. loss: 0.776, 0.1881 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 08:13:53 visual_prompt]: 	Test 800/1152. loss: 0.752, 0.1997 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 08:14:13 visual_prompt]: 	Test 900/1152. loss: 0.915, 0.2097 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 08:14:33 visual_prompt]: 	Test 1000/1152. loss: 0.913, 0.2006 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 08:14:52 visual_prompt]: 	Test 1100/1152. loss: 0.821, 0.1825 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 08:15:07 visual_prompt]: Inference (test):avg data time: 8.11e-03, avg batch time: 0.1943, average loss: 0.9664
[09/19 08:15:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 57.28	top5: 100.00	
[09/19 08:15:07 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/19 08:15:21 visual_prompt]: Epoch 73 / 100: avg data time: 2.45e-01, avg batch time: 0.6457, average train loss: 0.7369
[09/19 08:15:28 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1422, average loss: 0.6730
[09/19 08:15:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.00	top5: 100.00	
[09/19 08:15:51 visual_prompt]: 	Test 100/1152. loss: 0.734, 0.1961 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 08:16:11 visual_prompt]: 	Test 200/1152. loss: 0.744, 0.1951 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 08:16:30 visual_prompt]: 	Test 300/1152. loss: 1.110, 0.1829 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 08:16:50 visual_prompt]: 	Test 400/1152. loss: 0.937, 0.1978 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 08:17:09 visual_prompt]: 	Test 500/1152. loss: 0.896, 0.1830 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 08:17:29 visual_prompt]: 	Test 600/1152. loss: 0.956, 0.1824 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 08:17:48 visual_prompt]: 	Test 700/1152. loss: 1.035, 0.1832 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 08:18:08 visual_prompt]: 	Test 800/1152. loss: 0.824, 0.1934 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 08:18:27 visual_prompt]: 	Test 900/1152. loss: 0.872, 0.1995 s / batch. (data: 1.76e-02)max mem: 17.22454 GB 
[09/19 08:18:47 visual_prompt]: 	Test 1000/1152. loss: 0.881, 0.2067 s / batch. (data: 4.17e-05)max mem: 17.22454 GB 
[09/19 08:19:06 visual_prompt]: 	Test 1100/1152. loss: 0.823, 0.1897 s / batch. (data: 9.61e-05)max mem: 17.22454 GB 
[09/19 08:19:20 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1937, average loss: 0.9078
[09/19 08:19:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 58.50	top5: 100.00	
[09/19 08:19:20 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/19 08:19:34 visual_prompt]: Epoch 74 / 100: avg data time: 2.40e-01, avg batch time: 0.6397, average train loss: 0.7118
[09/19 08:19:42 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1423, average loss: 0.5372
[09/19 08:19:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 76.50	top5: 100.00	
[09/19 08:20:05 visual_prompt]: 	Test 100/1152. loss: 0.840, 0.1825 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:20:24 visual_prompt]: 	Test 200/1152. loss: 0.712, 0.1827 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:20:44 visual_prompt]: 	Test 300/1152. loss: 0.904, 0.2288 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 08:21:03 visual_prompt]: 	Test 400/1152. loss: 0.770, 0.1957 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 08:21:23 visual_prompt]: 	Test 500/1152. loss: 0.792, 0.2088 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/19 08:21:42 visual_prompt]: 	Test 600/1152. loss: 0.857, 0.1942 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 08:22:02 visual_prompt]: 	Test 700/1152. loss: 0.854, 0.1831 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 08:22:21 visual_prompt]: 	Test 800/1152. loss: 0.616, 0.1833 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 08:22:41 visual_prompt]: 	Test 900/1152. loss: 0.752, 0.1962 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 08:23:00 visual_prompt]: 	Test 1000/1152. loss: 0.795, 0.1827 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 08:23:20 visual_prompt]: 	Test 1100/1152. loss: 0.709, 0.1826 s / batch. (data: 8.70e-05)max mem: 17.22454 GB 
[09/19 08:23:34 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1940, average loss: 0.7948
[09/19 08:23:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 64.60	top5: 100.00	
[09/19 08:23:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/19 08:23:48 visual_prompt]: Epoch 75 / 100: avg data time: 2.46e-01, avg batch time: 0.6487, average train loss: 0.5752
[09/19 08:23:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1435, average loss: 0.4725
[09/19 08:23:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 79.50	top5: 100.00	
[09/19 08:24:19 visual_prompt]: 	Test 100/1152. loss: 0.640, 0.1963 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 08:24:38 visual_prompt]: 	Test 200/1152. loss: 0.748, 0.1826 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 08:24:58 visual_prompt]: 	Test 300/1152. loss: 0.749, 0.1950 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 08:25:18 visual_prompt]: 	Test 400/1152. loss: 0.701, 0.1881 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 08:25:37 visual_prompt]: 	Test 500/1152. loss: 0.736, 0.1864 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 08:25:56 visual_prompt]: 	Test 600/1152. loss: 0.838, 0.2061 s / batch. (data: 2.46e-02)max mem: 17.22454 GB 
[09/19 08:26:16 visual_prompt]: 	Test 700/1152. loss: 0.821, 0.1824 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 08:26:35 visual_prompt]: 	Test 800/1152. loss: 0.517, 0.1826 s / batch. (data: 9.23e-05)max mem: 17.22454 GB 
[09/19 08:26:55 visual_prompt]: 	Test 900/1152. loss: 0.806, 0.1827 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 08:27:14 visual_prompt]: 	Test 1000/1152. loss: 0.722, 0.2119 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 08:27:34 visual_prompt]: 	Test 1100/1152. loss: 0.504, 0.1936 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 08:27:48 visual_prompt]: Inference (test):avg data time: 8.06e-03, avg batch time: 0.1943, average loss: 0.7772
[09/19 08:27:48 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 69.22	top5: 100.00	
[09/19 08:27:48 visual_prompt]: Best epoch 75: best metric: 0.795
[09/19 08:27:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/19 08:28:02 visual_prompt]: Epoch 76 / 100: avg data time: 2.34e-01, avg batch time: 0.6366, average train loss: 0.6406
[09/19 08:28:09 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1422, average loss: 0.6096
[09/19 08:28:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.00	top5: 100.00	
[09/19 08:28:32 visual_prompt]: 	Test 100/1152. loss: 0.956, 0.1977 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 08:28:52 visual_prompt]: 	Test 200/1152. loss: 0.633, 0.1823 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/19 08:29:11 visual_prompt]: 	Test 300/1152. loss: 0.935, 0.1926 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 08:29:31 visual_prompt]: 	Test 400/1152. loss: 0.789, 0.2104 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 08:29:50 visual_prompt]: 	Test 500/1152. loss: 0.646, 0.1880 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 08:30:10 visual_prompt]: 	Test 600/1152. loss: 0.731, 0.1853 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 08:30:29 visual_prompt]: 	Test 700/1152. loss: 1.066, 0.1832 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 08:30:49 visual_prompt]: 	Test 800/1152. loss: 0.664, 0.1823 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 08:31:09 visual_prompt]: 	Test 900/1152. loss: 0.911, 0.2155 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 08:31:28 visual_prompt]: 	Test 1000/1152. loss: 0.909, 0.1997 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 08:31:48 visual_prompt]: 	Test 1100/1152. loss: 0.616, 0.2191 s / batch. (data: 3.44e-02)max mem: 17.22454 GB 
[09/19 08:32:02 visual_prompt]: Inference (test):avg data time: 8.52e-03, avg batch time: 0.1948, average loss: 0.8265
[09/19 08:32:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.70	top5: 100.00	
[09/19 08:32:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/19 08:32:16 visual_prompt]: Epoch 77 / 100: avg data time: 2.32e-01, avg batch time: 0.6344, average train loss: 0.5485
[09/19 08:32:24 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1424, average loss: 0.4841
[09/19 08:32:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 84.00	top5: 100.00	
[09/19 08:32:47 visual_prompt]: 	Test 100/1152. loss: 0.874, 0.1823 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 08:33:06 visual_prompt]: 	Test 200/1152. loss: 0.722, 0.1933 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/19 08:33:26 visual_prompt]: 	Test 300/1152. loss: 0.869, 0.1891 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:33:45 visual_prompt]: 	Test 400/1152. loss: 0.570, 0.1824 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 08:34:05 visual_prompt]: 	Test 500/1152. loss: 0.584, 0.2074 s / batch. (data: 2.55e-02)max mem: 17.22454 GB 
[09/19 08:34:24 visual_prompt]: 	Test 600/1152. loss: 0.707, 0.1829 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 08:34:44 visual_prompt]: 	Test 700/1152. loss: 0.733, 0.1905 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 08:35:04 visual_prompt]: 	Test 800/1152. loss: 0.617, 0.2051 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 08:35:23 visual_prompt]: 	Test 900/1152. loss: 0.649, 0.1836 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 08:35:43 visual_prompt]: 	Test 1000/1152. loss: 0.580, 0.1837 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 08:36:02 visual_prompt]: 	Test 1100/1152. loss: 0.705, 0.1832 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 08:36:17 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1944, average loss: 0.7649
[09/19 08:36:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 70.20	top5: 100.00	
[09/19 08:36:17 visual_prompt]: Best epoch 77: best metric: 0.840
[09/19 08:36:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/19 08:36:30 visual_prompt]: Epoch 78 / 100: avg data time: 2.42e-01, avg batch time: 0.6438, average train loss: 0.4880
[09/19 08:36:38 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1422, average loss: 0.4644
[09/19 08:36:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.00	top5: 100.00	
[09/19 08:37:01 visual_prompt]: 	Test 100/1152. loss: 0.987, 0.1958 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 08:37:20 visual_prompt]: 	Test 200/1152. loss: 0.767, 0.1831 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 08:37:40 visual_prompt]: 	Test 300/1152. loss: 1.004, 0.1955 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 08:37:59 visual_prompt]: 	Test 400/1152. loss: 0.775, 0.1829 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 08:38:19 visual_prompt]: 	Test 500/1152. loss: 0.794, 0.1828 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:38:39 visual_prompt]: 	Test 600/1152. loss: 0.994, 0.2077 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 08:38:58 visual_prompt]: 	Test 700/1152. loss: 0.926, 0.1823 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 08:39:18 visual_prompt]: 	Test 800/1152. loss: 0.549, 0.1962 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 08:39:37 visual_prompt]: 	Test 900/1152. loss: 0.928, 0.1896 s / batch. (data: 9.11e-05)max mem: 17.22454 GB 
[09/19 08:39:57 visual_prompt]: 	Test 1000/1152. loss: 0.837, 0.1826 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 08:40:17 visual_prompt]: 	Test 1100/1152. loss: 0.638, 0.2188 s / batch. (data: 3.33e-02)max mem: 17.22454 GB 
[09/19 08:40:31 visual_prompt]: Inference (test):avg data time: 8.34e-03, avg batch time: 0.1949, average loss: 0.8626
[09/19 08:40:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 65.99	top5: 100.00	
[09/19 08:40:31 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/19 08:40:45 visual_prompt]: Epoch 79 / 100: avg data time: 2.47e-01, avg batch time: 0.6482, average train loss: 0.6415
[09/19 08:40:53 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1420, average loss: 0.3963
[09/19 08:40:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 89.50	top5: 100.00	
[09/19 08:41:16 visual_prompt]: 	Test 100/1152. loss: 0.635, 0.1819 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 08:41:35 visual_prompt]: 	Test 200/1152. loss: 0.568, 0.1957 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:41:55 visual_prompt]: 	Test 300/1152. loss: 0.807, 0.1951 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 08:42:14 visual_prompt]: 	Test 400/1152. loss: 0.555, 0.2052 s / batch. (data: 1.66e-02)max mem: 17.22454 GB 
[09/19 08:42:34 visual_prompt]: 	Test 500/1152. loss: 0.721, 0.1965 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 08:42:53 visual_prompt]: 	Test 600/1152. loss: 0.736, 0.1842 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 08:43:13 visual_prompt]: 	Test 700/1152. loss: 0.587, 0.1829 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 08:43:32 visual_prompt]: 	Test 800/1152. loss: 0.536, 0.2086 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 08:43:52 visual_prompt]: 	Test 900/1152. loss: 0.684, 0.2031 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 08:44:11 visual_prompt]: 	Test 1000/1152. loss: 0.460, 0.1938 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 08:44:31 visual_prompt]: 	Test 1100/1152. loss: 0.435, 0.1825 s / batch. (data: 3.81e-05)max mem: 17.22454 GB 
[09/19 08:44:46 visual_prompt]: Inference (test):avg data time: 8.08e-03, avg batch time: 0.1942, average loss: 0.6604
[09/19 08:44:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.18	top5: 100.00	
[09/19 08:44:46 visual_prompt]: Best epoch 79: best metric: 0.895
[09/19 08:44:46 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/19 08:44:59 visual_prompt]: Epoch 80 / 100: avg data time: 2.43e-01, avg batch time: 0.6487, average train loss: 0.5132
[09/19 08:45:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1428, average loss: 0.5654
[09/19 08:45:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/19 08:45:30 visual_prompt]: 	Test 100/1152. loss: 0.909, 0.1957 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 08:45:50 visual_prompt]: 	Test 200/1152. loss: 0.837, 0.1966 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 08:46:09 visual_prompt]: 	Test 300/1152. loss: 1.046, 0.2064 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 08:46:29 visual_prompt]: 	Test 400/1152. loss: 0.670, 0.2171 s / batch. (data: 3.59e-02)max mem: 17.22454 GB 
[09/19 08:46:48 visual_prompt]: 	Test 500/1152. loss: 0.691, 0.2141 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 08:47:08 visual_prompt]: 	Test 600/1152. loss: 0.876, 0.1973 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 08:47:27 visual_prompt]: 	Test 700/1152. loss: 1.035, 0.1983 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 08:47:47 visual_prompt]: 	Test 800/1152. loss: 0.759, 0.1836 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 08:48:06 visual_prompt]: 	Test 900/1152. loss: 0.952, 0.1836 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 08:48:26 visual_prompt]: 	Test 1000/1152. loss: 0.903, 0.1822 s / batch. (data: 2.88e-05)max mem: 17.22454 GB 
[09/19 08:48:45 visual_prompt]: 	Test 1100/1152. loss: 0.751, 0.1828 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 08:48:59 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1940, average loss: 0.8600
[09/19 08:49:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 66.25	top5: 100.00	
[09/19 08:49:00 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/19 08:49:13 visual_prompt]: Epoch 81 / 100: avg data time: 2.45e-01, avg batch time: 0.6454, average train loss: 0.4619
[09/19 08:49:21 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1422, average loss: 0.5041
[09/19 08:49:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 77.50	top5: 100.00	
[09/19 08:49:44 visual_prompt]: 	Test 100/1152. loss: 0.903, 0.1822 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/19 08:50:03 visual_prompt]: 	Test 200/1152. loss: 0.750, 0.1940 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 08:50:23 visual_prompt]: 	Test 300/1152. loss: 0.864, 0.1824 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:50:42 visual_prompt]: 	Test 400/1152. loss: 0.690, 0.2118 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 08:51:02 visual_prompt]: 	Test 500/1152. loss: 0.824, 0.1971 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 08:51:21 visual_prompt]: 	Test 600/1152. loss: 1.001, 0.2261 s / batch. (data: 3.84e-02)max mem: 17.22454 GB 
[09/19 08:51:41 visual_prompt]: 	Test 700/1152. loss: 1.092, 0.1971 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 08:52:01 visual_prompt]: 	Test 800/1152. loss: 0.745, 0.1977 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 08:52:20 visual_prompt]: 	Test 900/1152. loss: 1.019, 0.1947 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 08:52:40 visual_prompt]: 	Test 1000/1152. loss: 0.668, 0.1830 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:52:59 visual_prompt]: 	Test 1100/1152. loss: 0.676, 0.2067 s / batch. (data: 2.44e-02)max mem: 17.22454 GB 
[09/19 08:53:14 visual_prompt]: Inference (test):avg data time: 8.60e-03, avg batch time: 0.1946, average loss: 0.8460
[09/19 08:53:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 67.66	top5: 100.00	
[09/19 08:53:14 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/19 08:53:28 visual_prompt]: Epoch 82 / 100: avg data time: 2.48e-01, avg batch time: 0.6559, average train loss: 0.4416
[09/19 08:53:35 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1422, average loss: 0.5650
[09/19 08:53:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.50	top5: 100.00	
[09/19 08:53:59 visual_prompt]: 	Test 100/1152. loss: 0.842, 0.2089 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/19 08:54:18 visual_prompt]: 	Test 200/1152. loss: 0.932, 0.1818 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 08:54:38 visual_prompt]: 	Test 300/1152. loss: 1.083, 0.1879 s / batch. (data: 8.82e-05)max mem: 17.22454 GB 
[09/19 08:54:57 visual_prompt]: 	Test 400/1152. loss: 0.764, 0.1954 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 08:55:17 visual_prompt]: 	Test 500/1152. loss: 0.853, 0.2039 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 08:55:37 visual_prompt]: 	Test 600/1152. loss: 0.978, 0.2334 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 08:55:56 visual_prompt]: 	Test 700/1152. loss: 1.186, 0.2269 s / batch. (data: 2.16e-02)max mem: 17.22454 GB 
[09/19 08:56:16 visual_prompt]: 	Test 800/1152. loss: 0.912, 0.1977 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 08:56:35 visual_prompt]: 	Test 900/1152. loss: 1.151, 0.2035 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 08:56:55 visual_prompt]: 	Test 1000/1152. loss: 1.077, 0.1829 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 08:57:14 visual_prompt]: 	Test 1100/1152. loss: 0.897, 0.1831 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 08:57:29 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1949, average loss: 0.9892
[09/19 08:57:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.30	top5: 100.00	
[09/19 08:57:29 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/19 08:57:43 visual_prompt]: Epoch 83 / 100: avg data time: 2.40e-01, avg batch time: 0.6426, average train loss: 0.3715
[09/19 08:57:50 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1456, average loss: 0.4019
[09/19 08:57:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 83.00	top5: 100.00	
[09/19 08:58:14 visual_prompt]: 	Test 100/1152. loss: 0.914, 0.1827 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:58:33 visual_prompt]: 	Test 200/1152. loss: 0.933, 0.1962 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 08:58:52 visual_prompt]: 	Test 300/1152. loss: 0.994, 0.1931 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 08:59:12 visual_prompt]: 	Test 400/1152. loss: 0.690, 0.1969 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 08:59:31 visual_prompt]: 	Test 500/1152. loss: 0.652, 0.1824 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:59:51 visual_prompt]: 	Test 600/1152. loss: 0.881, 0.1883 s / batch. (data: 6.37e-03)max mem: 17.22454 GB 
[09/19 09:00:11 visual_prompt]: 	Test 700/1152. loss: 0.973, 0.1831 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 09:00:30 visual_prompt]: 	Test 800/1152. loss: 0.548, 0.2236 s / batch. (data: 4.15e-02)max mem: 17.22454 GB 
[09/19 09:00:50 visual_prompt]: 	Test 900/1152. loss: 0.983, 0.1826 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 09:01:09 visual_prompt]: 	Test 1000/1152. loss: 0.788, 0.1828 s / batch. (data: 9.08e-05)max mem: 17.22454 GB 
[09/19 09:01:29 visual_prompt]: 	Test 1100/1152. loss: 0.558, 0.1901 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 09:01:43 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1942, average loss: 0.8614
[09/19 09:01:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 68.02	top5: 100.00	
[09/19 09:01:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/19 09:01:57 visual_prompt]: Epoch 84 / 100: avg data time: 2.46e-01, avg batch time: 0.6493, average train loss: 0.3417
[09/19 09:02:05 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1429, average loss: 0.6806
[09/19 09:02:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 70.00	top5: 100.00	
[09/19 09:02:28 visual_prompt]: 	Test 100/1152. loss: 1.444, 0.1825 s / batch. (data: 5.13e-05)max mem: 17.22454 GB 
[09/19 09:02:47 visual_prompt]: 	Test 200/1152. loss: 1.032, 0.1828 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 09:03:06 visual_prompt]: 	Test 300/1152. loss: 1.253, 0.1874 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 09:03:26 visual_prompt]: 	Test 400/1152. loss: 1.269, 0.1825 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:03:46 visual_prompt]: 	Test 500/1152. loss: 1.060, 0.2016 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 09:04:05 visual_prompt]: 	Test 600/1152. loss: 1.212, 0.1826 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 09:04:25 visual_prompt]: 	Test 700/1152. loss: 1.424, 0.1840 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 09:04:44 visual_prompt]: 	Test 800/1152. loss: 0.827, 0.1982 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 09:05:04 visual_prompt]: 	Test 900/1152. loss: 0.982, 0.1828 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 09:05:23 visual_prompt]: 	Test 1000/1152. loss: 1.179, 0.1931 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:05:43 visual_prompt]: 	Test 1100/1152. loss: 0.835, 0.1968 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 09:05:57 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1944, average loss: 1.2257
[09/19 09:05:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 61.50	top5: 100.00	
[09/19 09:05:58 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/19 09:06:11 visual_prompt]: Epoch 85 / 100: avg data time: 2.40e-01, avg batch time: 0.6417, average train loss: 0.3476
[09/19 09:06:19 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1420, average loss: 0.6299
[09/19 09:06:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 75.50	top5: 100.00	
[09/19 09:06:42 visual_prompt]: 	Test 100/1152. loss: 1.062, 0.1870 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/19 09:07:02 visual_prompt]: 	Test 200/1152. loss: 1.303, 0.1989 s / batch. (data: 1.68e-02)max mem: 17.22454 GB 
[09/19 09:07:21 visual_prompt]: 	Test 300/1152. loss: 1.293, 0.2073 s / batch. (data: 2.55e-02)max mem: 17.22454 GB 
[09/19 09:07:41 visual_prompt]: 	Test 400/1152. loss: 0.952, 0.1825 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 09:08:00 visual_prompt]: 	Test 500/1152. loss: 0.974, 0.1856 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 09:08:20 visual_prompt]: 	Test 600/1152. loss: 1.246, 0.1888 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 09:08:39 visual_prompt]: 	Test 700/1152. loss: 1.345, 0.1961 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 09:08:59 visual_prompt]: 	Test 800/1152. loss: 0.765, 0.1899 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 09:09:18 visual_prompt]: 	Test 900/1152. loss: 1.293, 0.1828 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 09:09:38 visual_prompt]: 	Test 1000/1152. loss: 1.474, 0.1831 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 09:09:58 visual_prompt]: 	Test 1100/1152. loss: 0.730, 0.1994 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 09:10:12 visual_prompt]: Inference (test):avg data time: 8.78e-03, avg batch time: 0.1946, average loss: 1.2023
[09/19 09:10:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 63.83	top5: 100.00	
[09/19 09:10:12 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/19 09:10:26 visual_prompt]: Epoch 86 / 100: avg data time: 2.43e-01, avg batch time: 0.6473, average train loss: 0.3520
[09/19 09:10:33 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1476, average loss: 0.3348
[09/19 09:10:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 86.50	top5: 100.00	
[09/19 09:10:57 visual_prompt]: 	Test 100/1152. loss: 0.943, 0.1819 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 09:11:16 visual_prompt]: 	Test 200/1152. loss: 0.673, 0.2074 s / batch. (data: 2.59e-02)max mem: 17.22454 GB 
[09/19 09:11:36 visual_prompt]: 	Test 300/1152. loss: 0.767, 0.2158 s / batch. (data: 1.94e-02)max mem: 17.22454 GB 
[09/19 09:11:55 visual_prompt]: 	Test 400/1152. loss: 0.691, 0.1989 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:12:15 visual_prompt]: 	Test 500/1152. loss: 0.898, 0.1822 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 09:12:34 visual_prompt]: 	Test 600/1152. loss: 1.045, 0.1862 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 09:12:54 visual_prompt]: 	Test 700/1152. loss: 0.999, 0.1933 s / batch. (data: 4.63e-05)max mem: 17.22454 GB 
[09/19 09:13:13 visual_prompt]: 	Test 800/1152. loss: 0.453, 0.2009 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 09:13:33 visual_prompt]: 	Test 900/1152. loss: 0.512, 0.1975 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 09:13:52 visual_prompt]: 	Test 1000/1152. loss: 0.658, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 09:14:12 visual_prompt]: 	Test 1100/1152. loss: 0.400, 0.1910 s / batch. (data: 9.18e-05)max mem: 17.22454 GB 
[09/19 09:14:26 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1944, average loss: 0.8066
[09/19 09:14:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.50	top5: 100.00	
[09/19 09:14:27 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/19 09:14:40 visual_prompt]: Epoch 87 / 100: avg data time: 2.43e-01, avg batch time: 0.6439, average train loss: 0.3004
[09/19 09:14:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1421, average loss: 0.3129
[09/19 09:14:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 89.50	top5: 100.00	
[09/19 09:15:11 visual_prompt]: 	Test 100/1152. loss: 1.009, 0.1966 s / batch. (data: 1.46e-02)max mem: 17.22454 GB 
[09/19 09:15:31 visual_prompt]: 	Test 200/1152. loss: 0.595, 0.1824 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 09:15:50 visual_prompt]: 	Test 300/1152. loss: 0.799, 0.1829 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 09:16:10 visual_prompt]: 	Test 400/1152. loss: 0.656, 0.2108 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 09:16:29 visual_prompt]: 	Test 500/1152. loss: 0.757, 0.1958 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 09:16:49 visual_prompt]: 	Test 600/1152. loss: 0.840, 0.2207 s / batch. (data: 2.16e-02)max mem: 17.22454 GB 
[09/19 09:17:08 visual_prompt]: 	Test 700/1152. loss: 0.950, 0.1824 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 09:17:28 visual_prompt]: 	Test 800/1152. loss: 0.500, 0.1977 s / batch. (data: 1.58e-02)max mem: 17.22454 GB 
[09/19 09:17:47 visual_prompt]: 	Test 900/1152. loss: 0.633, 0.1906 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 09:18:07 visual_prompt]: 	Test 1000/1152. loss: 0.707, 0.1838 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 09:18:26 visual_prompt]: 	Test 1100/1152. loss: 0.508, 0.1885 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 09:18:41 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1943, average loss: 0.8279
[09/19 09:18:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.03	top5: 100.00	
[09/19 09:18:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/19 09:18:54 visual_prompt]: Epoch 88 / 100: avg data time: 2.36e-01, avg batch time: 0.6376, average train loss: 0.2547
[09/19 09:19:02 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1421, average loss: 0.2955
[09/19 09:19:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 90.50	top5: 100.00	
[09/19 09:19:26 visual_prompt]: 	Test 100/1152. loss: 1.023, 0.1964 s / batch. (data: 9.01e-05)max mem: 17.22454 GB 
[09/19 09:19:45 visual_prompt]: 	Test 200/1152. loss: 0.829, 0.1947 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 09:20:04 visual_prompt]: 	Test 300/1152. loss: 1.113, 0.2045 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 09:20:24 visual_prompt]: 	Test 400/1152. loss: 0.871, 0.2100 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 09:20:44 visual_prompt]: 	Test 500/1152. loss: 0.843, 0.1826 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 09:21:03 visual_prompt]: 	Test 600/1152. loss: 0.943, 0.1829 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 09:21:23 visual_prompt]: 	Test 700/1152. loss: 1.111, 0.2010 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 09:21:42 visual_prompt]: 	Test 800/1152. loss: 0.600, 0.1952 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 09:22:02 visual_prompt]: 	Test 900/1152. loss: 1.010, 0.1903 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 09:22:21 visual_prompt]: 	Test 1000/1152. loss: 0.815, 0.1831 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 09:22:41 visual_prompt]: 	Test 1100/1152. loss: 0.594, 0.1835 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 09:22:55 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1941, average loss: 0.9346
[09/19 09:22:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 70.62	top5: 100.00	
[09/19 09:22:55 visual_prompt]: Best epoch 88: best metric: 0.905
[09/19 09:22:55 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/19 09:23:09 visual_prompt]: Epoch 89 / 100: avg data time: 2.40e-01, avg batch time: 0.6428, average train loss: 0.2072
[09/19 09:23:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1435, average loss: 0.3430
[09/19 09:23:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 87.00	top5: 100.00	
[09/19 09:23:39 visual_prompt]: 	Test 100/1152. loss: 0.906, 0.2050 s / batch. (data: 2.96e-05)max mem: 17.22454 GB 
[09/19 09:23:59 visual_prompt]: 	Test 200/1152. loss: 0.752, 0.1962 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 09:24:18 visual_prompt]: 	Test 300/1152. loss: 0.872, 0.1934 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:24:38 visual_prompt]: 	Test 400/1152. loss: 0.835, 0.2047 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:24:57 visual_prompt]: 	Test 500/1152. loss: 1.035, 0.2096 s / batch. (data: 2.71e-02)max mem: 17.22454 GB 
[09/19 09:25:17 visual_prompt]: 	Test 600/1152. loss: 0.970, 0.1928 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 09:25:37 visual_prompt]: 	Test 700/1152. loss: 1.128, 0.1955 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 09:25:56 visual_prompt]: 	Test 800/1152. loss: 0.475, 0.1962 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 09:26:16 visual_prompt]: 	Test 900/1152. loss: 0.776, 0.1956 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 09:26:35 visual_prompt]: 	Test 1000/1152. loss: 0.772, 0.1971 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:26:55 visual_prompt]: 	Test 1100/1152. loss: 0.448, 0.1830 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 09:27:09 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1943, average loss: 0.9303
[09/19 09:27:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.40	top5: 100.00	
[09/19 09:27:09 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/19 09:27:23 visual_prompt]: Epoch 90 / 100: avg data time: 2.40e-01, avg batch time: 0.6451, average train loss: 0.2279
[09/19 09:27:31 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1424, average loss: 0.3243
[09/19 09:27:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 86.50	top5: 100.00	
[09/19 09:27:54 visual_prompt]: 	Test 100/1152. loss: 1.198, 0.1955 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 09:28:13 visual_prompt]: 	Test 200/1152. loss: 1.017, 0.2004 s / batch. (data: 1.81e-02)max mem: 17.22454 GB 
[09/19 09:28:33 visual_prompt]: 	Test 300/1152. loss: 1.165, 0.1886 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 09:28:52 visual_prompt]: 	Test 400/1152. loss: 0.757, 0.1976 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 09:29:12 visual_prompt]: 	Test 500/1152. loss: 0.852, 0.1820 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 09:29:31 visual_prompt]: 	Test 600/1152. loss: 0.921, 0.1962 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 09:29:51 visual_prompt]: 	Test 700/1152. loss: 1.045, 0.1829 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 09:30:10 visual_prompt]: 	Test 800/1152. loss: 0.782, 0.1827 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 09:30:30 visual_prompt]: 	Test 900/1152. loss: 1.291, 0.1824 s / batch. (data: 3.27e-05)max mem: 17.22454 GB 
[09/19 09:30:49 visual_prompt]: 	Test 1000/1152. loss: 0.761, 0.2086 s / batch. (data: 2.69e-02)max mem: 17.22454 GB 
[09/19 09:31:09 visual_prompt]: 	Test 1100/1152. loss: 0.839, 0.1970 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 09:31:24 visual_prompt]: Inference (test):avg data time: 8.26e-03, avg batch time: 0.1944, average loss: 1.0262
[09/19 09:31:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 70.61	top5: 100.00	
[09/19 09:31:24 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/19 09:31:37 visual_prompt]: Epoch 91 / 100: avg data time: 2.38e-01, avg batch time: 0.6429, average train loss: 0.2023
[09/19 09:31:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1422, average loss: 0.2700
[09/19 09:31:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 90.50	top5: 100.00	
[09/19 09:32:08 visual_prompt]: 	Test 100/1152. loss: 0.925, 0.1957 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 09:32:28 visual_prompt]: 	Test 200/1152. loss: 0.778, 0.1929 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:32:47 visual_prompt]: 	Test 300/1152. loss: 0.996, 0.1827 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 09:33:07 visual_prompt]: 	Test 400/1152. loss: 0.864, 0.1980 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 09:33:26 visual_prompt]: 	Test 500/1152. loss: 0.966, 0.1983 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 09:33:46 visual_prompt]: 	Test 600/1152. loss: 0.883, 0.1974 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 09:34:05 visual_prompt]: 	Test 700/1152. loss: 0.984, 0.1952 s / batch. (data: 1.29e-02)max mem: 17.22454 GB 
[09/19 09:34:24 visual_prompt]: 	Test 800/1152. loss: 0.554, 0.1963 s / batch. (data: 3.10e-05)max mem: 17.22454 GB 
[09/19 09:34:44 visual_prompt]: 	Test 900/1152. loss: 1.133, 0.2000 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 09:35:03 visual_prompt]: 	Test 1000/1152. loss: 0.866, 0.1824 s / batch. (data: 3.36e-05)max mem: 17.22454 GB 
[09/19 09:35:23 visual_prompt]: 	Test 1100/1152. loss: 0.382, 0.1993 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 09:35:37 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1938, average loss: 0.8921
[09/19 09:35:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.15	top5: 100.00	
[09/19 09:35:38 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/19 09:35:51 visual_prompt]: Epoch 92 / 100: avg data time: 2.41e-01, avg batch time: 0.6425, average train loss: 0.1974
[09/19 09:35:59 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1450, average loss: 0.2237
[09/19 09:35:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 88.50	top5: 100.00	
[09/19 09:36:22 visual_prompt]: 	Test 100/1152. loss: 0.975, 0.1957 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 09:36:42 visual_prompt]: 	Test 200/1152. loss: 0.838, 0.1947 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 09:37:01 visual_prompt]: 	Test 300/1152. loss: 1.080, 0.1961 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 09:37:21 visual_prompt]: 	Test 400/1152. loss: 0.741, 0.2056 s / batch. (data: 2.39e-02)max mem: 17.22454 GB 
[09/19 09:37:40 visual_prompt]: 	Test 500/1152. loss: 0.957, 0.1834 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 09:38:00 visual_prompt]: 	Test 600/1152. loss: 1.052, 0.2097 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/19 09:38:20 visual_prompt]: 	Test 700/1152. loss: 0.906, 0.1959 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 09:38:39 visual_prompt]: 	Test 800/1152. loss: 0.598, 0.1924 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 09:38:59 visual_prompt]: 	Test 900/1152. loss: 1.142, 0.2058 s / batch. (data: 2.38e-02)max mem: 17.22454 GB 
[09/19 09:39:18 visual_prompt]: 	Test 1000/1152. loss: 0.710, 0.1828 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 09:39:38 visual_prompt]: 	Test 1100/1152. loss: 0.604, 0.2015 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 09:39:52 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1944, average loss: 0.9253
[09/19 09:39:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 72.42	top5: 100.00	
[09/19 09:39:52 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/19 09:40:06 visual_prompt]: Epoch 93 / 100: avg data time: 2.34e-01, avg batch time: 0.6373, average train loss: 0.1766
[09/19 09:40:13 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1419, average loss: 0.1924
[09/19 09:40:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 89.50	top5: 100.00	
[09/19 09:40:37 visual_prompt]: 	Test 100/1152. loss: 0.898, 0.1872 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 09:40:56 visual_prompt]: 	Test 200/1152. loss: 0.766, 0.1835 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 09:41:16 visual_prompt]: 	Test 300/1152. loss: 1.029, 0.2058 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 09:41:35 visual_prompt]: 	Test 400/1152. loss: 0.734, 0.1867 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:41:55 visual_prompt]: 	Test 500/1152. loss: 0.958, 0.1945 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 09:42:14 visual_prompt]: 	Test 600/1152. loss: 0.995, 0.1823 s / batch. (data: 9.58e-05)max mem: 17.22454 GB 
[09/19 09:42:34 visual_prompt]: 	Test 700/1152. loss: 0.907, 0.1862 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 09:42:53 visual_prompt]: 	Test 800/1152. loss: 0.587, 0.1982 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 09:43:13 visual_prompt]: 	Test 900/1152. loss: 1.125, 0.1953 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 09:43:32 visual_prompt]: 	Test 1000/1152. loss: 0.705, 0.1821 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 09:43:52 visual_prompt]: 	Test 1100/1152. loss: 0.397, 0.1844 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 09:44:07 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1945, average loss: 0.8895
[09/19 09:44:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.54	top5: 100.00	
[09/19 09:44:07 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/19 09:44:20 visual_prompt]: Epoch 94 / 100: avg data time: 2.47e-01, avg batch time: 0.6500, average train loss: 0.1433
[09/19 09:44:28 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1434, average loss: 0.1672
[09/19 09:44:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 93.50	top5: 100.00	
[09/19 09:44:51 visual_prompt]: 	Test 100/1152. loss: 1.086, 0.1977 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 09:45:10 visual_prompt]: 	Test 200/1152. loss: 0.791, 0.1840 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 09:45:30 visual_prompt]: 	Test 300/1152. loss: 1.087, 0.1844 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:45:49 visual_prompt]: 	Test 400/1152. loss: 0.796, 0.1943 s / batch. (data: 1.20e-02)max mem: 17.22454 GB 
[09/19 09:46:09 visual_prompt]: 	Test 500/1152. loss: 0.922, 0.1866 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 09:46:28 visual_prompt]: 	Test 600/1152. loss: 0.959, 0.1947 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 09:46:48 visual_prompt]: 	Test 700/1152. loss: 0.995, 0.1827 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 09:47:07 visual_prompt]: 	Test 800/1152. loss: 0.571, 0.1954 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 09:47:27 visual_prompt]: 	Test 900/1152. loss: 1.065, 0.2000 s / batch. (data: 3.39e-05)max mem: 17.22454 GB 
[09/19 09:47:46 visual_prompt]: 	Test 1000/1152. loss: 0.746, 0.1822 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 09:48:06 visual_prompt]: 	Test 1100/1152. loss: 0.379, 0.1959 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 09:48:21 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1939, average loss: 0.9079
[09/19 09:48:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.76	top5: 100.00	
[09/19 09:48:21 visual_prompt]: Best epoch 94: best metric: 0.935
[09/19 09:48:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/19 09:48:37 visual_prompt]: Epoch 95 / 100: avg data time: 2.93e-01, avg batch time: 0.7456, average train loss: 0.1392
[09/19 09:48:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1935, average loss: 0.1833
[09/19 09:48:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 09:49:08 visual_prompt]: 	Test 100/1152. loss: 1.085, 0.1818 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 09:49:27 visual_prompt]: 	Test 200/1152. loss: 0.767, 0.1968 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 09:49:47 visual_prompt]: 	Test 300/1152. loss: 1.125, 0.1974 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 09:50:06 visual_prompt]: 	Test 400/1152. loss: 0.770, 0.1865 s / batch. (data: 9.97e-05)max mem: 17.22454 GB 
[09/19 09:50:25 visual_prompt]: 	Test 500/1152. loss: 0.943, 0.1831 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 09:50:45 visual_prompt]: 	Test 600/1152. loss: 0.963, 0.1861 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 09:51:04 visual_prompt]: 	Test 700/1152. loss: 0.991, 0.1930 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 09:51:24 visual_prompt]: 	Test 800/1152. loss: 0.687, 0.2048 s / batch. (data: 2.30e-02)max mem: 17.22454 GB 
[09/19 09:51:43 visual_prompt]: 	Test 900/1152. loss: 1.144, 0.1971 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:52:03 visual_prompt]: 	Test 1000/1152. loss: 0.681, 0.1828 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 09:52:22 visual_prompt]: 	Test 1100/1152. loss: 0.502, 0.2157 s / batch. (data: 2.73e-02)max mem: 17.22454 GB 
[09/19 09:52:37 visual_prompt]: Inference (test):avg data time: 7.91e-03, avg batch time: 0.1939, average loss: 0.9215
[09/19 09:52:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.09	top5: 100.00	
[09/19 09:52:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/19 09:52:51 visual_prompt]: Epoch 96 / 100: avg data time: 2.52e-01, avg batch time: 0.6531, average train loss: 0.1222
[09/19 09:52:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1420, average loss: 0.1846
[09/19 09:52:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 09:53:22 visual_prompt]: 	Test 100/1152. loss: 1.115, 0.1950 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 09:53:41 visual_prompt]: 	Test 200/1152. loss: 0.828, 0.1826 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 09:54:01 visual_prompt]: 	Test 300/1152. loss: 1.118, 0.1828 s / batch. (data: 8.85e-05)max mem: 17.22454 GB 
[09/19 09:54:20 visual_prompt]: 	Test 400/1152. loss: 0.781, 0.2000 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:54:40 visual_prompt]: 	Test 500/1152. loss: 0.954, 0.2165 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 09:54:59 visual_prompt]: 	Test 600/1152. loss: 0.990, 0.1903 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 09:55:19 visual_prompt]: 	Test 700/1152. loss: 0.979, 0.1966 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 09:55:38 visual_prompt]: 	Test 800/1152. loss: 0.682, 0.1881 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 09:55:58 visual_prompt]: 	Test 900/1152. loss: 1.144, 0.1959 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 09:56:17 visual_prompt]: 	Test 1000/1152. loss: 0.721, 0.1975 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:56:37 visual_prompt]: 	Test 1100/1152. loss: 0.551, 0.1994 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 09:56:51 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1940, average loss: 0.9356
[09/19 09:56:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.85	top5: 100.00	
[09/19 09:56:52 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/19 09:57:05 visual_prompt]: Epoch 97 / 100: avg data time: 2.50e-01, avg batch time: 0.6505, average train loss: 0.1143
[09/19 09:57:13 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1420, average loss: 0.1803
[09/19 09:57:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 92.50	top5: 100.00	
[09/19 09:57:36 visual_prompt]: 	Test 100/1152. loss: 1.080, 0.1833 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 09:57:56 visual_prompt]: 	Test 200/1152. loss: 0.896, 0.1820 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 09:58:15 visual_prompt]: 	Test 300/1152. loss: 1.066, 0.1857 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:58:34 visual_prompt]: 	Test 400/1152. loss: 0.799, 0.2118 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 09:58:54 visual_prompt]: 	Test 500/1152. loss: 0.980, 0.1831 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 09:59:13 visual_prompt]: 	Test 600/1152. loss: 0.998, 0.1951 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 09:59:33 visual_prompt]: 	Test 700/1152. loss: 1.007, 0.2235 s / batch. (data: 2.69e-02)max mem: 17.22454 GB 
[09/19 09:59:52 visual_prompt]: 	Test 800/1152. loss: 0.665, 0.1948 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:00:12 visual_prompt]: 	Test 900/1152. loss: 1.179, 0.1979 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 10:00:32 visual_prompt]: 	Test 1000/1152. loss: 0.768, 0.1831 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 10:00:51 visual_prompt]: 	Test 1100/1152. loss: 0.520, 0.1826 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 10:01:06 visual_prompt]: Inference (test):avg data time: 8.32e-03, avg batch time: 0.1945, average loss: 0.9425
[09/19 10:01:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.40	top5: 100.00	
[09/19 10:01:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/19 10:01:20 visual_prompt]: Epoch 98 / 100: avg data time: 2.58e-01, avg batch time: 0.6591, average train loss: 0.1110
[09/19 10:01:27 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1421, average loss: 0.1549
[09/19 10:01:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.50	top5: 100.00	
[09/19 10:01:50 visual_prompt]: 	Test 100/1152. loss: 1.023, 0.1861 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 10:02:10 visual_prompt]: 	Test 200/1152. loss: 0.847, 0.2098 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 10:02:29 visual_prompt]: 	Test 300/1152. loss: 1.031, 0.1883 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 10:02:49 visual_prompt]: 	Test 400/1152. loss: 0.782, 0.1844 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:03:08 visual_prompt]: 	Test 500/1152. loss: 0.969, 0.1924 s / batch. (data: 9.63e-05)max mem: 17.22454 GB 
[09/19 10:03:27 visual_prompt]: 	Test 600/1152. loss: 0.977, 0.1947 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 10:03:47 visual_prompt]: 	Test 700/1152. loss: 0.956, 0.1838 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 10:04:06 visual_prompt]: 	Test 800/1152. loss: 0.684, 0.1962 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 10:04:26 visual_prompt]: 	Test 900/1152. loss: 1.178, 0.1829 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:04:45 visual_prompt]: 	Test 1000/1152. loss: 0.726, 0.1972 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 10:05:05 visual_prompt]: 	Test 1100/1152. loss: 0.517, 0.2001 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:05:19 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1938, average loss: 0.9173
[09/19 10:05:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 74.04	top5: 100.00	
[09/19 10:05:20 visual_prompt]: Best epoch 98: best metric: 0.945
[09/19 10:05:20 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/19 10:05:33 visual_prompt]: Epoch 99 / 100: avg data time: 2.48e-01, avg batch time: 0.6499, average train loss: 0.1100
[09/19 10:05:41 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1420, average loss: 0.1678
[09/19 10:05:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.50	top5: 100.00	
[09/19 10:06:05 visual_prompt]: 	Test 100/1152. loss: 1.044, 0.1962 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/19 10:06:24 visual_prompt]: 	Test 200/1152. loss: 0.866, 0.1826 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 10:06:43 visual_prompt]: 	Test 300/1152. loss: 1.056, 0.1820 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/19 10:07:03 visual_prompt]: 	Test 400/1152. loss: 0.803, 0.1826 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:07:22 visual_prompt]: 	Test 500/1152. loss: 0.968, 0.1955 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 10:07:42 visual_prompt]: 	Test 600/1152. loss: 0.996, 0.1826 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:08:01 visual_prompt]: 	Test 700/1152. loss: 0.993, 0.1867 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 10:08:22 visual_prompt]: 	Test 800/1152. loss: 0.697, 0.1828 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 10:08:44 visual_prompt]: 	Test 900/1152. loss: 1.197, 0.2080 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 10:09:04 visual_prompt]: 	Test 1000/1152. loss: 0.742, 0.2138 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:09:30 visual_prompt]: 	Test 1100/1152. loss: 0.549, 0.1965 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 10:09:45 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1999, average loss: 0.9374
[09/19 10:09:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.70	top5: 100.00	
[09/19 10:09:45 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/19 10:10:00 visual_prompt]: Epoch 100 / 100: avg data time: 2.68e-01, avg batch time: 0.7062, average train loss: 0.1044
[09/19 10:10:07 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1561, average loss: 0.1670
[09/19 10:10:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 94.50	top5: 100.00	
[09/19 10:10:30 visual_prompt]: 	Test 100/1152. loss: 1.043, 0.1960 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 10:10:50 visual_prompt]: 	Test 200/1152. loss: 0.861, 0.1967 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 10:11:09 visual_prompt]: 	Test 300/1152. loss: 1.053, 0.1946 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 10:11:29 visual_prompt]: 	Test 400/1152. loss: 0.803, 0.1828 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:11:48 visual_prompt]: 	Test 500/1152. loss: 0.969, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:12:07 visual_prompt]: 	Test 600/1152. loss: 0.999, 0.1836 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 10:12:27 visual_prompt]: 	Test 700/1152. loss: 0.996, 0.1864 s / batch. (data: 9.99e-05)max mem: 17.22454 GB 
[09/19 10:12:46 visual_prompt]: 	Test 800/1152. loss: 0.694, 0.1833 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 10:13:06 visual_prompt]: 	Test 900/1152. loss: 1.191, 0.1917 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 10:13:25 visual_prompt]: 	Test 1000/1152. loss: 0.739, 0.1958 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 10:13:45 visual_prompt]: 	Test 1100/1152. loss: 0.541, 0.1984 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/19 10:13:59 visual_prompt]: Inference (test):avg data time: 8.40e-03, avg batch time: 0.1942, average loss: 0.9359
[09/19 10:14:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 73.77	top5: 100.00	
[09/19 10:16:16 visual_prompt]: Rank of current process: 0. World size: 1
[09/19 10:16:19 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/19 10:16:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/19 10:16:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/19 10:16:19 visual_prompt]: Training with config:
[09/19 10:16:19 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/19 10:16:19 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-19 10:16:20.309580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-19 10:16:22.848356: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-19 10:16:44.577950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 10:16:44.579085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 10:16:44.579124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-19 10:17:19.690866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 10:17:19.691347: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 10:17:19.691395: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/19 10:17:19 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-19 10:17:19.933717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 10:17:24 visual_prompt]: Number of images: 1000
[09/19 10:17:24 visual_prompt]: Number of classes: 16 / 16
[09/19 10:17:24 visual_prompt]: Loading validation data...
[09/19 10:17:24 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 10:17:24 visual_prompt]: Number of images: 200
[09/19 10:17:24 visual_prompt]: Number of classes: 16 / 16
[09/19 10:17:24 visual_prompt]: Loading test data...
[09/19 10:17:24 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_x_position",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 10:18:56 visual_prompt]: Number of images: 73728
[09/19 10:18:56 visual_prompt]: Number of classes: 16 / 16
[09/19 10:18:56 visual_prompt]: Constructing models...
[09/19 10:19:06 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/19 10:19:06 visual_prompt]: tuned percent:1.077
[09/19 10:19:31 visual_prompt]: Device used for model: 0
[09/19 10:19:31 visual_prompt]: Setting up Evalutator...
[09/19 10:19:31 visual_prompt]: Setting up Trainer...
[09/19 10:19:31 visual_prompt]: 	Setting up the optimizer...
[09/19 10:19:31 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/19 10:19:48 visual_prompt]: Epoch 1 / 100: avg data time: 2.27e-01, avg batch time: 0.8940, average train loss: 2.9562
[09/19 10:19:54 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1416, average loss: 2.8999
[09/19 10:19:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 35.50	
[09/19 10:20:17 visual_prompt]: 	Test 100/1152. loss: 3.019, 0.1955 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/19 10:20:36 visual_prompt]: 	Test 200/1152. loss: 2.876, 0.1822 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 10:20:55 visual_prompt]: 	Test 300/1152. loss: 2.953, 0.1843 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:21:15 visual_prompt]: 	Test 400/1152. loss: 2.817, 0.2079 s / batch. (data: 1.84e-02)max mem: 17.22454 GB 
[09/19 10:21:34 visual_prompt]: 	Test 500/1152. loss: 2.875, 0.1980 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:21:54 visual_prompt]: 	Test 600/1152. loss: 2.950, 0.1843 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 10:22:14 visual_prompt]: 	Test 700/1152. loss: 2.945, 0.2094 s / batch. (data: 1.68e-02)max mem: 17.22454 GB 
[09/19 10:22:33 visual_prompt]: 	Test 800/1152. loss: 2.961, 0.1960 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:22:53 visual_prompt]: 	Test 900/1152. loss: 2.940, 0.2104 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 10:23:12 visual_prompt]: 	Test 1000/1152. loss: 2.870, 0.1843 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:23:32 visual_prompt]: 	Test 1100/1152. loss: 3.125, 0.1997 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 10:23:46 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1943, average loss: 2.9411
[09/19 10:23:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.27	top5: 31.21	
[09/19 10:23:46 visual_prompt]: Best epoch 1: best metric: 0.060
[09/19 10:23:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/19 10:23:59 visual_prompt]: Epoch 2 / 100: avg data time: 2.05e-01, avg batch time: 0.6058, average train loss: 3.1723
[09/19 10:24:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1426, average loss: 3.0093
[09/19 10:24:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 33.00	
[09/19 10:24:28 visual_prompt]: 	Test 100/1152. loss: 3.072, 0.1932 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:24:47 visual_prompt]: 	Test 200/1152. loss: 2.919, 0.1829 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 10:25:07 visual_prompt]: 	Test 300/1152. loss: 3.114, 0.1823 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 10:25:26 visual_prompt]: 	Test 400/1152. loss: 3.121, 0.1835 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:25:46 visual_prompt]: 	Test 500/1152. loss: 2.892, 0.2185 s / batch. (data: 3.62e-02)max mem: 17.22454 GB 
[09/19 10:26:05 visual_prompt]: 	Test 600/1152. loss: 3.015, 0.2195 s / batch. (data: 3.73e-02)max mem: 17.22454 GB 
[09/19 10:26:25 visual_prompt]: 	Test 700/1152. loss: 3.127, 0.1933 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 10:26:44 visual_prompt]: 	Test 800/1152. loss: 3.053, 0.2035 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 10:27:04 visual_prompt]: 	Test 900/1152. loss: 3.189, 0.1986 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 10:27:23 visual_prompt]: 	Test 1000/1152. loss: 2.998, 0.1952 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/19 10:27:43 visual_prompt]: 	Test 1100/1152. loss: 3.087, 0.1830 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:27:57 visual_prompt]: Inference (test):avg data time: 7.95e-03, avg batch time: 0.1942, average loss: 3.0286
[09/19 10:27:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.13	top5: 31.12	
[09/19 10:27:57 visual_prompt]: Best epoch 2: best metric: 0.095
[09/19 10:27:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/19 10:28:10 visual_prompt]: Epoch 3 / 100: avg data time: 2.05e-01, avg batch time: 0.6059, average train loss: 2.9460
[09/19 10:28:17 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1422, average loss: 3.0380
[09/19 10:28:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.00	top5: 26.00	
[09/19 10:28:39 visual_prompt]: 	Test 100/1152. loss: 3.104, 0.2070 s / batch. (data: 2.47e-02)max mem: 17.22454 GB 
[09/19 10:28:58 visual_prompt]: 	Test 200/1152. loss: 2.965, 0.1815 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:29:18 visual_prompt]: 	Test 300/1152. loss: 2.996, 0.1841 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 10:29:37 visual_prompt]: 	Test 400/1152. loss: 2.888, 0.1919 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:29:56 visual_prompt]: 	Test 500/1152. loss: 2.842, 0.1946 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 10:30:16 visual_prompt]: 	Test 600/1152. loss: 2.891, 0.1825 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 10:30:35 visual_prompt]: 	Test 700/1152. loss: 2.803, 0.1931 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 10:30:55 visual_prompt]: 	Test 800/1152. loss: 2.994, 0.1952 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 10:31:14 visual_prompt]: 	Test 900/1152. loss: 2.809, 0.1975 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:31:34 visual_prompt]: 	Test 1000/1152. loss: 2.835, 0.1899 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:31:54 visual_prompt]: 	Test 1100/1152. loss: 2.913, 0.1981 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 10:32:08 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1941, average loss: 2.9477
[09/19 10:32:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.34	top5: 31.26	
[09/19 10:32:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/19 10:32:22 visual_prompt]: Epoch 4 / 100: avg data time: 2.38e-01, avg batch time: 0.6777, average train loss: 3.0404
[09/19 10:32:29 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1817, average loss: 3.0678
[09/19 10:32:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 9.50	top5: 35.50	
[09/19 10:32:51 visual_prompt]: 	Test 100/1152. loss: 3.303, 0.1947 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 10:33:11 visual_prompt]: 	Test 200/1152. loss: 3.108, 0.2137 s / batch. (data: 3.20e-02)max mem: 17.22454 GB 
[09/19 10:33:30 visual_prompt]: 	Test 300/1152. loss: 3.121, 0.1814 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 10:33:50 visual_prompt]: 	Test 400/1152. loss: 2.982, 0.1826 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 10:34:09 visual_prompt]: 	Test 500/1152. loss: 3.373, 0.1930 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 10:34:28 visual_prompt]: 	Test 600/1152. loss: 3.335, 0.1932 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 10:34:48 visual_prompt]: 	Test 700/1152. loss: 3.158, 0.1929 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/19 10:35:07 visual_prompt]: 	Test 800/1152. loss: 3.057, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 10:35:27 visual_prompt]: 	Test 900/1152. loss: 3.263, 0.2082 s / batch. (data: 2.61e-02)max mem: 17.22454 GB 
[09/19 10:35:47 visual_prompt]: 	Test 1000/1152. loss: 3.058, 0.1831 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 10:36:06 visual_prompt]: 	Test 1100/1152. loss: 3.139, 0.1972 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 10:36:20 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1939, average loss: 3.1379
[09/19 10:36:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.13	top5: 31.09	
[09/19 10:36:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/19 10:36:33 visual_prompt]: Epoch 5 / 100: avg data time: 2.12e-01, avg batch time: 0.6118, average train loss: 3.2249
[09/19 10:36:39 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1422, average loss: 3.0126
[09/19 10:36:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 33.00	
[09/19 10:37:02 visual_prompt]: 	Test 100/1152. loss: 3.075, 0.2212 s / batch. (data: 4.01e-02)max mem: 17.22454 GB 
[09/19 10:37:21 visual_prompt]: 	Test 200/1152. loss: 3.140, 0.1912 s / batch. (data: 8.54e-05)max mem: 17.22454 GB 
[09/19 10:37:41 visual_prompt]: 	Test 300/1152. loss: 3.006, 0.1964 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 10:38:00 visual_prompt]: 	Test 400/1152. loss: 3.075, 0.1833 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 10:38:20 visual_prompt]: 	Test 500/1152. loss: 2.997, 0.1833 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:38:39 visual_prompt]: 	Test 600/1152. loss: 2.952, 0.2090 s / batch. (data: 1.57e-02)max mem: 17.22454 GB 
[09/19 10:38:59 visual_prompt]: 	Test 700/1152. loss: 2.935, 0.1963 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 10:39:18 visual_prompt]: 	Test 800/1152. loss: 3.092, 0.1922 s / batch. (data: 1.00e-02)max mem: 17.22454 GB 
[09/19 10:39:37 visual_prompt]: 	Test 900/1152. loss: 3.015, 0.1828 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:39:57 visual_prompt]: 	Test 1000/1152. loss: 3.081, 0.1960 s / batch. (data: 1.38e-02)max mem: 17.22454 GB 
[09/19 10:40:17 visual_prompt]: 	Test 1100/1152. loss: 3.152, 0.1879 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 10:40:31 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1939, average loss: 3.0615
[09/19 10:40:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.21	top5: 31.36	
[09/19 10:40:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/19 10:40:44 visual_prompt]: Epoch 6 / 100: avg data time: 2.20e-01, avg batch time: 0.6269, average train loss: 3.1016
[09/19 10:40:50 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1426, average loss: 3.0836
[09/19 10:40:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 7.00	top5: 38.50	
[09/19 10:41:13 visual_prompt]: 	Test 100/1152. loss: 3.062, 0.1826 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 10:41:32 visual_prompt]: 	Test 200/1152. loss: 3.288, 0.2051 s / batch. (data: 2.30e-02)max mem: 17.22454 GB 
[09/19 10:41:51 visual_prompt]: 	Test 300/1152. loss: 3.284, 0.1825 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:42:11 visual_prompt]: 	Test 400/1152. loss: 3.193, 0.1827 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:42:30 visual_prompt]: 	Test 500/1152. loss: 3.313, 0.1821 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:42:50 visual_prompt]: 	Test 600/1152. loss: 3.487, 0.1820 s / batch. (data: 4.34e-05)max mem: 17.22454 GB 
[09/19 10:43:09 visual_prompt]: 	Test 700/1152. loss: 3.080, 0.2062 s / batch. (data: 2.43e-02)max mem: 17.22454 GB 
[09/19 10:43:28 visual_prompt]: 	Test 800/1152. loss: 3.223, 0.1881 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 10:43:48 visual_prompt]: 	Test 900/1152. loss: 3.269, 0.1831 s / batch. (data: 9.06e-05)max mem: 17.22454 GB 
[09/19 10:44:07 visual_prompt]: 	Test 1000/1152. loss: 3.216, 0.1920 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:44:27 visual_prompt]: 	Test 1100/1152. loss: 3.181, 0.1825 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:44:41 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1934, average loss: 3.2095
[09/19 10:44:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.35	top5: 31.15	
[09/19 10:44:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/19 10:44:53 visual_prompt]: Epoch 7 / 100: avg data time: 1.94e-01, avg batch time: 0.5983, average train loss: 3.2028
[09/19 10:44:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1425, average loss: 3.0998
[09/19 10:44:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 32.00	
[09/19 10:45:22 visual_prompt]: 	Test 100/1152. loss: 2.929, 0.1944 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 10:45:41 visual_prompt]: 	Test 200/1152. loss: 2.955, 0.1999 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:46:01 visual_prompt]: 	Test 300/1152. loss: 2.947, 0.1825 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:46:20 visual_prompt]: 	Test 400/1152. loss: 3.026, 0.1965 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 10:46:39 visual_prompt]: 	Test 500/1152. loss: 3.034, 0.1979 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:46:59 visual_prompt]: 	Test 600/1152. loss: 3.100, 0.1825 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 10:47:18 visual_prompt]: 	Test 700/1152. loss: 2.938, 0.1828 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:47:37 visual_prompt]: 	Test 800/1152. loss: 3.073, 0.1824 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/19 10:47:57 visual_prompt]: 	Test 900/1152. loss: 2.952, 0.1829 s / batch. (data: 9.73e-05)max mem: 17.22454 GB 
[09/19 10:48:16 visual_prompt]: 	Test 1000/1152. loss: 2.831, 0.2039 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 10:48:36 visual_prompt]: 	Test 1100/1152. loss: 3.111, 0.1835 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 10:48:49 visual_prompt]: Inference (test):avg data time: 8.00e-03, avg batch time: 0.1932, average loss: 3.0175
[09/19 10:48:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.26	top5: 31.21	
[09/19 10:48:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/19 10:49:02 visual_prompt]: Epoch 8 / 100: avg data time: 1.99e-01, avg batch time: 0.6012, average train loss: 3.1232
[09/19 10:49:08 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1421, average loss: 3.1102
[09/19 10:49:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.50	top5: 30.00	
[09/19 10:49:31 visual_prompt]: 	Test 100/1152. loss: 3.064, 0.2073 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 10:49:50 visual_prompt]: 	Test 200/1152. loss: 3.065, 0.1952 s / batch. (data: 1.30e-02)max mem: 17.22454 GB 
[09/19 10:50:09 visual_prompt]: 	Test 300/1152. loss: 2.986, 0.1872 s / batch. (data: 2.96e-05)max mem: 17.22454 GB 
[09/19 10:50:29 visual_prompt]: 	Test 400/1152. loss: 3.137, 0.1825 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:50:48 visual_prompt]: 	Test 500/1152. loss: 3.163, 0.1995 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:51:07 visual_prompt]: 	Test 600/1152. loss: 3.059, 0.1832 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/19 10:51:27 visual_prompt]: 	Test 700/1152. loss: 2.947, 0.1834 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 10:51:46 visual_prompt]: 	Test 800/1152. loss: 3.014, 0.1832 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 10:52:06 visual_prompt]: 	Test 900/1152. loss: 2.929, 0.1821 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 10:52:25 visual_prompt]: 	Test 1000/1152. loss: 2.765, 0.1880 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:52:45 visual_prompt]: 	Test 1100/1152. loss: 3.005, 0.2000 s / batch. (data: 1.75e-02)max mem: 17.22454 GB 
[09/19 10:52:59 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1935, average loss: 3.0452
[09/19 10:52:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.17	top5: 31.07	
[09/19 10:52:59 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/19 10:53:11 visual_prompt]: Epoch 9 / 100: avg data time: 1.91e-01, avg batch time: 0.5928, average train loss: 3.1113
[09/19 10:53:17 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1435, average loss: 3.2305
[09/19 10:53:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.00	top5: 26.50	
[09/19 10:53:40 visual_prompt]: 	Test 100/1152. loss: 3.269, 0.1835 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 10:53:59 visual_prompt]: 	Test 200/1152. loss: 3.131, 0.1828 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 10:54:18 visual_prompt]: 	Test 300/1152. loss: 3.435, 0.1825 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 10:54:38 visual_prompt]: 	Test 400/1152. loss: 3.243, 0.1828 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 10:54:57 visual_prompt]: 	Test 500/1152. loss: 3.233, 0.1969 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 10:55:17 visual_prompt]: 	Test 600/1152. loss: 3.264, 0.1825 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:55:36 visual_prompt]: 	Test 700/1152. loss: 3.192, 0.1879 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:55:55 visual_prompt]: 	Test 800/1152. loss: 3.169, 0.1833 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:56:15 visual_prompt]: 	Test 900/1152. loss: 3.079, 0.1972 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 10:56:35 visual_prompt]: 	Test 1000/1152. loss: 3.130, 0.1954 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 10:56:54 visual_prompt]: 	Test 1100/1152. loss: 3.016, 0.1838 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 10:57:08 visual_prompt]: Inference (test):avg data time: 7.68e-03, avg batch time: 0.1936, average loss: 3.2024
[09/19 10:57:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 6.33	top5: 31.20	
[09/19 10:57:08 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/19 10:57:21 visual_prompt]: Epoch 10 / 100: avg data time: 2.09e-01, avg batch time: 0.6118, average train loss: 3.1227
[09/19 10:57:27 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1423, average loss: 3.2203
[09/19 10:57:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_x_position",num_classes=16): top1: 4.50	top5: 28.50	
[09/19 10:57:49 visual_prompt]: 	Test 100/1152. loss: 3.436, 0.1954 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/19 10:58:09 visual_prompt]: 	Test 200/1152. loss: 3.219, 0.1972 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:58:28 visual_prompt]: 	Test 300/1152. loss: 3.226, 0.1987 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 10:58:47 visual_prompt]: 	Test 400/1152. loss: 3.073, 0.1990 s / batch. (data: 1.73e-02)max mem: 17.22454 GB 
[09/19 10:59:07 visual_prompt]: 	Test 500/1152. loss: 3.102, 0.1941 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/19 10:59:26 visual_prompt]: 	Test 600/1152. loss: 3.034, 0.2280 s / batch. (data: 4.19e-02)max mem: 17.22454 GB 
[09/19 10:59:46 visual_prompt]: 	Test 700/1152. loss: 3.216, 0.1975 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 11:00:05 visual_prompt]: 	Test 800/1152. loss: 3.213, 0.1963 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 11:00:25 visual_prompt]: 	Test 900/1152. loss: 3.152, 0.1824 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:00:44 visual_prompt]: 	Test 1000/1152. loss: 3.188, 0.2056 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/19 11:01:04 visual_prompt]: 	Test 1100/1152. loss: 2.980, 0.2232 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
visual_prompt_tuning/experiments/vit_vtab.sh: line 9: 1499937 Killed                  python visual_prompt_tuning/train.py --config-file visual_prompt_tuning/configs/prompt/cub.yaml MODEL.TYPE "vit" DATA.BATCH_SIZE "64" MODEL.PROMPT.NUM_TOKENS "100" MODEL.PROMPT.DEEP "True" MODEL.PROMPT.DROPOUT "0.1" DATA.FEATURE "sup_vitb16_imagenet21k" DATA.NAME "vtab-${dataset}" DATA.NUMBER_CLASSES "${num_classes}" SOLVER.BASE_LR "5.0" SOLVER.WEIGHT_DECAY "0.0001" MODEL.MODEL_ROOT "${model_root}" DATA.DATAPATH "${data_path}" OUTPUT_DIR "${output_dir}/seed${seed}"
Traceback (most recent call last):
  File "visual_prompt_tuning/train.py", line 129, in <module>
    main(args)
  File "visual_prompt_tuning/train.py", line 121, in main
    cfg = setup(args)
  File "visual_prompt_tuning/train.py", line 57, in setup
    f"Already run {cfg.RUN_N_TIMES} times for {output_folder}, no need to run more")
ValueError: Already run 1 times for vtab-dsprites(predicted_attribute="label_x_position",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001, no need to run more
