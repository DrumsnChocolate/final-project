/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 22:38:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/27 22:38:10 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/27 22:38:10 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 22:38:10 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/27 22:38:10 visual_prompt]: Training with config:
[09/27 22:38:10 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/test/seed1188/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 1188, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/27 22:38:10 visual_prompt]: Loading training data...
2023-09-27 22:38:11.371791: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-27 22:38:11.430944: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-27 22:38:17.833031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/27 22:38:28 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800]+train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/27 22:38:29 visual_prompt]: Number of images: 1000
[09/27 22:38:29 visual_prompt]: Number of classes: 100 / 100
[09/27 22:38:29 visual_prompt]: Loading validation data...
[09/27 22:38:29 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/27 22:38:30 visual_prompt]: Number of images: 200
[09/27 22:38:30 visual_prompt]: Number of classes: 90 / 100
[09/27 22:38:30 visual_prompt]: Loading test data...
[09/27 22:38:30 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split test, from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/27 22:38:42 visual_prompt]: Number of images: 10000
[09/27 22:38:42 visual_prompt]: Number of classes: 100 / 100
[09/27 22:38:42 visual_prompt]: Constructing models...
[09/27 22:38:45 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/27 22:38:45 visual_prompt]: tuned percent:0.623
[09/27 22:38:48 visual_prompt]: Device used for model: 0
[09/27 22:38:48 visual_prompt]: Setting up Evaluator...
[09/27 22:38:48 visual_prompt]: Setting up Trainer...
[09/27 22:38:48 visual_prompt]: 	Setting up the optimizer...
[09/27 22:38:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/27 22:39:01 visual_prompt]: Epoch 1 / 100: avg data time: 1.91e-01, avg batch time: 0.7952, average train loss: 4.6501
[09/27 22:39:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1744, average loss: 4.6749
[09/27 22:39:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/27 22:39:26 visual_prompt]: 	Test 100/157. loss: 4.646, 0.2068 s / batch. (data: 2.91e-05)max mem: 7.80512 GB 
[09/27 22:39:39 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2060, average loss: 4.6504
[09/27 22:39:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 0.67	top5: 5.13	
[09/27 22:39:39 visual_prompt]: Best epoch 1: best metric: 0.005
[09/27 22:39:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/27 22:39:48 visual_prompt]: Epoch 2 / 100: avg data time: 8.06e-02, avg batch time: 0.5172, average train loss: 4.6318
[09/27 22:39:51 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1867, average loss: 4.5747
[09/27 22:39:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 8.50	
[09/27 22:40:13 visual_prompt]: 	Test 100/157. loss: 4.646, 0.2116 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 22:40:26 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2085, average loss: 4.6249
[09/27 22:40:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.24	top5: 5.09	
[09/27 22:40:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/27 22:40:35 visual_prompt]: Epoch 3 / 100: avg data time: 8.40e-02, avg batch time: 0.5195, average train loss: 4.5856
[09/27 22:40:38 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1867, average loss: 4.5569
[09/27 22:40:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 7.00	
[09/27 22:41:00 visual_prompt]: 	Test 100/157. loss: 4.522, 0.2076 s / batch. (data: 3.22e-05)max mem: 7.80512 GB 
[09/27 22:41:13 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2079, average loss: 4.6366
[09/27 22:41:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.34	top5: 5.69	
[09/27 22:41:13 visual_prompt]: Best epoch 3: best metric: 0.030
[09/27 22:41:13 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/27 22:41:22 visual_prompt]: Epoch 4 / 100: avg data time: 9.50e-02, avg batch time: 0.5295, average train loss: 4.5836
[09/27 22:41:25 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1871, average loss: 4.5095
[09/27 22:41:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.00	
[09/27 22:41:47 visual_prompt]: 	Test 100/157. loss: 4.579, 0.2072 s / batch. (data: 1.00e-04)max mem: 7.80512 GB 
[09/27 22:42:00 visual_prompt]: Inference (test):avg data time: 1.17e-04, avg batch time: 0.2066, average loss: 4.6140
[09/27 22:42:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.92	top5: 8.68	
[09/27 22:42:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/27 22:42:09 visual_prompt]: Epoch 5 / 100: avg data time: 8.82e-02, avg batch time: 0.5198, average train loss: 4.4909
[09/27 22:42:12 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1767, average loss: 4.2488
[09/27 22:42:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 24.50	
[09/27 22:42:34 visual_prompt]: 	Test 100/157. loss: 4.362, 0.2062 s / batch. (data: 2.81e-05)max mem: 7.80512 GB 
[09/27 22:42:47 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2056, average loss: 4.4801
[09/27 22:42:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 4.36	top5: 13.93	
[09/27 22:42:47 visual_prompt]: Best epoch 5: best metric: 0.085
[09/27 22:42:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/27 22:42:56 visual_prompt]: Epoch 6 / 100: avg data time: 9.63e-02, avg batch time: 0.5255, average train loss: 4.2205
[09/27 22:42:59 visual_prompt]: Inference (val):avg data time: 5.42e-05, avg batch time: 0.1786, average loss: 3.9907
[09/27 22:42:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 11.50	top5: 29.00	
[09/27 22:43:21 visual_prompt]: 	Test 100/157. loss: 4.117, 0.2057 s / batch. (data: 3.19e-05)max mem: 7.80512 GB 
[09/27 22:43:33 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2048, average loss: 4.2429
[09/27 22:43:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 5.36	top5: 18.03	
[09/27 22:43:33 visual_prompt]: Best epoch 6: best metric: 0.115
[09/27 22:43:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/27 22:43:43 visual_prompt]: Epoch 7 / 100: avg data time: 9.60e-02, avg batch time: 0.5248, average train loss: 4.0197
[09/27 22:43:45 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1732, average loss: 3.7719
[09/27 22:43:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.50	top5: 34.00	
[09/27 22:44:07 visual_prompt]: 	Test 100/157. loss: 3.926, 0.2044 s / batch. (data: 3.12e-05)max mem: 7.80512 GB 
[09/27 22:44:20 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2048, average loss: 3.9765
[09/27 22:44:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 8.73	top5: 27.37	
[09/27 22:44:20 visual_prompt]: Best epoch 7: best metric: 0.125
[09/27 22:44:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/27 22:44:29 visual_prompt]: Epoch 8 / 100: avg data time: 9.13e-02, avg batch time: 0.5186, average train loss: 3.2668
[09/27 22:44:32 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1816, average loss: 2.5726
[09/27 22:44:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 31.00	top5: 68.00	
[09/27 22:44:54 visual_prompt]: 	Test 100/157. loss: 2.707, 0.2053 s / batch. (data: 3.12e-05)max mem: 7.80512 GB 
[09/27 22:45:07 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2042, average loss: 2.9931
[09/27 22:45:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 22.81	top5: 56.07	
[09/27 22:45:07 visual_prompt]: Best epoch 8: best metric: 0.310
[09/27 22:45:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/27 22:45:16 visual_prompt]: Epoch 9 / 100: avg data time: 9.74e-02, avg batch time: 0.5269, average train loss: 2.1256
[09/27 22:45:19 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1764, average loss: 1.1618
[09/27 22:45:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/27 22:45:41 visual_prompt]: 	Test 100/157. loss: 1.967, 0.2055 s / batch. (data: 2.98e-05)max mem: 7.80512 GB 
[09/27 22:45:53 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2044, average loss: 1.9999
[09/27 22:45:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 47.40	top5: 80.10	
[09/27 22:45:53 visual_prompt]: Best epoch 9: best metric: 0.760
[09/27 22:45:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/27 22:46:03 visual_prompt]: Epoch 10 / 100: avg data time: 9.68e-02, avg batch time: 0.5244, average train loss: 1.0411
[09/27 22:46:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1766, average loss: 0.5242
[09/27 22:46:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 88.00	top5: 100.00	
[09/27 22:46:27 visual_prompt]: 	Test 100/157. loss: 1.371, 0.2037 s / batch. (data: 3.60e-05)max mem: 7.80512 GB 
[09/27 22:46:40 visual_prompt]: Inference (test):avg data time: 1.93e-04, avg batch time: 0.2044, average loss: 1.4530
[09/27 22:46:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 59.69	top5: 88.54	
[09/27 22:46:40 visual_prompt]: Best epoch 10: best metric: 0.880
[09/27 22:46:40 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/27 22:46:49 visual_prompt]: Epoch 11 / 100: avg data time: 9.19e-02, avg batch time: 0.5188, average train loss: 0.5020
[09/27 22:46:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1773, average loss: 0.2358
[09/27 22:46:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 96.00	top5: 100.00	
[09/27 22:47:14 visual_prompt]: 	Test 100/157. loss: 1.084, 0.2038 s / batch. (data: 3.17e-05)max mem: 7.80512 GB 
[09/27 22:47:26 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2041, average loss: 1.1748
[09/27 22:47:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 68.16	top5: 91.79	
[09/27 22:47:27 visual_prompt]: Best epoch 11: best metric: 0.960
[09/27 22:47:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/27 22:47:36 visual_prompt]: Epoch 12 / 100: avg data time: 9.23e-02, avg batch time: 0.5204, average train loss: 0.2241
[09/27 22:47:38 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1846, average loss: 0.1174
[09/27 22:47:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/27 22:48:00 visual_prompt]: 	Test 100/157. loss: 1.001, 0.2051 s / batch. (data: 3.00e-05)max mem: 7.80512 GB 
[09/27 22:48:13 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2040, average loss: 1.0799
[09/27 22:48:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.68	top5: 93.07	
[09/27 22:48:13 visual_prompt]: Best epoch 12: best metric: 0.995
[09/27 22:48:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/27 22:48:22 visual_prompt]: Epoch 13 / 100: avg data time: 9.46e-02, avg batch time: 0.5223, average train loss: 0.1156
[09/27 22:48:25 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1723, average loss: 0.0718
[09/27 22:48:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/27 22:48:47 visual_prompt]: 	Test 100/157. loss: 0.956, 0.2045 s / batch. (data: 2.65e-05)max mem: 7.80512 GB 
[09/27 22:48:59 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2043, average loss: 1.0026
[09/27 22:48:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.20	top5: 93.54	
[09/27 22:48:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/27 22:49:09 visual_prompt]: Epoch 14 / 100: avg data time: 9.53e-02, avg batch time: 0.5222, average train loss: 0.0758
[09/27 22:49:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1763, average loss: 0.0508
[09/27 22:49:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:49:33 visual_prompt]: 	Test 100/157. loss: 0.946, 0.2045 s / batch. (data: 5.10e-05)max mem: 7.80512 GB 
[09/27 22:49:46 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2041, average loss: 0.9749
[09/27 22:49:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.94	top5: 93.81	
[09/27 22:49:46 visual_prompt]: Best epoch 14: best metric: 1.000
[09/27 22:49:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/27 22:49:55 visual_prompt]: Epoch 15 / 100: avg data time: 9.27e-02, avg batch time: 0.5204, average train loss: 0.0616
[09/27 22:49:58 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1766, average loss: 0.0429
[09/27 22:49:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:50:20 visual_prompt]: 	Test 100/157. loss: 1.003, 0.2068 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 22:50:33 visual_prompt]: Inference (test):avg data time: 1.25e-04, avg batch time: 0.2043, average loss: 0.9867
[09/27 22:50:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.04	top5: 93.79	
[09/27 22:50:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/27 22:50:42 visual_prompt]: Epoch 16 / 100: avg data time: 9.09e-02, avg batch time: 0.5184, average train loss: 0.0544
[09/27 22:50:45 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1821, average loss: 0.0407
[09/27 22:50:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:51:07 visual_prompt]: 	Test 100/157. loss: 0.902, 0.2062 s / batch. (data: 3.62e-05)max mem: 7.80512 GB 
[09/27 22:51:19 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2041, average loss: 0.9862
[09/27 22:51:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.77	top5: 93.97	
[09/27 22:51:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/27 22:51:28 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e-02, avg batch time: 0.5250, average train loss: 0.0524
[09/27 22:51:31 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1765, average loss: 0.0388
[09/27 22:51:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:51:53 visual_prompt]: 	Test 100/157. loss: 0.966, 0.2056 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 22:52:06 visual_prompt]: Inference (test):avg data time: 1.00e-04, avg batch time: 0.2046, average loss: 0.9792
[09/27 22:52:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.36	top5: 94.12	
[09/27 22:52:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/27 22:52:15 visual_prompt]: Epoch 18 / 100: avg data time: 9.12e-02, avg batch time: 0.5192, average train loss: 0.0518
[09/27 22:52:18 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1816, average loss: 0.0389
[09/27 22:52:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:52:40 visual_prompt]: 	Test 100/157. loss: 1.002, 0.2044 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 22:52:52 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2042, average loss: 0.9880
[09/27 22:52:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.21	top5: 93.84	
[09/27 22:52:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/27 22:53:01 visual_prompt]: Epoch 19 / 100: avg data time: 8.34e-02, avg batch time: 0.5117, average train loss: 0.0537
[09/27 22:53:04 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1843, average loss: 0.0389
[09/27 22:53:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:53:26 visual_prompt]: 	Test 100/157. loss: 0.926, 0.2061 s / batch. (data: 3.08e-05)max mem: 7.80512 GB 
[09/27 22:53:39 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2044, average loss: 0.9836
[09/27 22:53:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.36	top5: 94.08	
[09/27 22:53:39 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/27 22:53:48 visual_prompt]: Epoch 20 / 100: avg data time: 9.94e-02, avg batch time: 0.5277, average train loss: 0.0572
[09/27 22:53:51 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1759, average loss: 0.0454
[09/27 22:53:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:54:13 visual_prompt]: 	Test 100/157. loss: 0.937, 0.2057 s / batch. (data: 3.22e-05)max mem: 7.80512 GB 
[09/27 22:54:26 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2043, average loss: 1.0148
[09/27 22:54:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.75	top5: 94.06	
[09/27 22:54:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/27 22:54:35 visual_prompt]: Epoch 21 / 100: avg data time: 1.01e-01, avg batch time: 0.5276, average train loss: 0.0665
[09/27 22:54:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1763, average loss: 0.0511
[09/27 22:54:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 22:55:00 visual_prompt]: 	Test 100/157. loss: 0.967, 0.2038 s / batch. (data: 3.05e-05)max mem: 7.80512 GB 
[09/27 22:55:12 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2044, average loss: 1.0663
[09/27 22:55:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.12	top5: 93.47	
[09/27 22:55:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/27 22:55:21 visual_prompt]: Epoch 22 / 100: avg data time: 9.45e-02, avg batch time: 0.5199, average train loss: 0.9472
[09/27 22:55:24 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1751, average loss: 4.7572
[09/27 22:55:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 8.00	
[09/27 22:55:46 visual_prompt]: 	Test 100/157. loss: 5.018, 0.2051 s / batch. (data: 2.98e-05)max mem: 7.80512 GB 
[09/27 22:55:59 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2037, average loss: 4.8935
[09/27 22:55:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.20	top5: 6.69	
[09/27 22:55:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/27 22:56:08 visual_prompt]: Epoch 23 / 100: avg data time: 8.95e-02, avg batch time: 0.5189, average train loss: 4.6640
[09/27 22:56:11 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1775, average loss: 4.5293
[09/27 22:56:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/27 22:56:33 visual_prompt]: 	Test 100/157. loss: 4.611, 0.2049 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 22:56:45 visual_prompt]: Inference (test):avg data time: 1.03e-04, avg batch time: 0.2039, average loss: 4.6599
[09/27 22:56:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.57	
[09/27 22:56:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/27 22:56:54 visual_prompt]: Epoch 24 / 100: avg data time: 9.72e-02, avg batch time: 0.5236, average train loss: 4.5911
[09/27 22:56:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1719, average loss: 4.5625
[09/27 22:56:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/27 22:57:19 visual_prompt]: 	Test 100/157. loss: 4.635, 0.2029 s / batch. (data: 3.15e-05)max mem: 7.80512 GB 
[09/27 22:57:32 visual_prompt]: Inference (test):avg data time: 2.17e-04, avg batch time: 0.2037, average loss: 4.6426
[09/27 22:57:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.35	top5: 5.61	
[09/27 22:57:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/27 22:57:41 visual_prompt]: Epoch 25 / 100: avg data time: 9.84e-02, avg batch time: 0.5240, average train loss: 4.6163
[09/27 22:57:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1807, average loss: 4.5268
[09/27 22:57:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.50	
[09/27 22:58:05 visual_prompt]: 	Test 100/157. loss: 4.590, 0.2035 s / batch. (data: 2.74e-05)max mem: 7.80512 GB 
[09/27 22:58:18 visual_prompt]: Inference (test):avg data time: 1.24e-04, avg batch time: 0.2042, average loss: 4.6346
[09/27 22:58:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.94	top5: 7.54	
[09/27 22:58:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/27 22:58:27 visual_prompt]: Epoch 26 / 100: avg data time: 1.01e-01, avg batch time: 0.5271, average train loss: 4.4438
[09/27 22:58:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1771, average loss: 4.0479
[09/27 22:58:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 29.50	
[09/27 22:58:52 visual_prompt]: 	Test 100/157. loss: 4.151, 0.2039 s / batch. (data: 2.69e-05)max mem: 7.80512 GB 
[09/27 22:59:04 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2040, average loss: 4.2750
[09/27 22:59:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 5.59	top5: 19.69	
[09/27 22:59:04 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/27 22:59:14 visual_prompt]: Epoch 27 / 100: avg data time: 9.04e-02, avg batch time: 0.5160, average train loss: 3.4663
[09/27 22:59:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1787, average loss: 2.4498
[09/27 22:59:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 81.50	
[09/27 22:59:38 visual_prompt]: 	Test 100/157. loss: 2.914, 0.2053 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 22:59:51 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2045, average loss: 3.0308
[09/27 22:59:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 29.27	top5: 60.88	
[09/27 22:59:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/27 23:00:00 visual_prompt]: Epoch 28 / 100: avg data time: 9.50e-02, avg batch time: 0.5206, average train loss: 1.6380
[09/27 23:00:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1838, average loss: 0.6850
[09/27 23:00:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 88.50	top5: 99.50	
[09/27 23:00:25 visual_prompt]: 	Test 100/157. loss: 1.557, 0.2049 s / batch. (data: 3.12e-05)max mem: 7.80512 GB 
[09/27 23:00:37 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2041, average loss: 1.5120
[09/27 23:00:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 62.28	top5: 89.07	
[09/27 23:00:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/27 23:00:47 visual_prompt]: Epoch 29 / 100: avg data time: 9.23e-02, avg batch time: 0.5201, average train loss: 0.5465
[09/27 23:00:49 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1739, average loss: 0.2052
[09/27 23:00:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.00	top5: 100.00	
[09/27 23:01:11 visual_prompt]: 	Test 100/157. loss: 1.064, 0.2057 s / batch. (data: 2.91e-05)max mem: 7.80512 GB 
[09/27 23:01:24 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2043, average loss: 1.0452
[09/27 23:01:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.80	top5: 93.98	
[09/27 23:01:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/27 23:01:33 visual_prompt]: Epoch 30 / 100: avg data time: 9.87e-02, avg batch time: 0.5256, average train loss: 0.2069
[09/27 23:01:36 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1765, average loss: 0.1397
[09/27 23:01:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.00	top5: 100.00	
[09/27 23:01:58 visual_prompt]: 	Test 100/157. loss: 0.910, 0.2057 s / batch. (data: 3.65e-05)max mem: 7.80512 GB 
[09/27 23:02:10 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2044, average loss: 0.9576
[09/27 23:02:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.52	top5: 94.45	
[09/27 23:02:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/27 23:02:19 visual_prompt]: Epoch 31 / 100: avg data time: 9.46e-02, avg batch time: 0.5211, average train loss: 0.1085
[09/27 23:02:22 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1841, average loss: 0.0735
[09/27 23:02:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:02:44 visual_prompt]: 	Test 100/157. loss: 0.810, 0.2053 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:02:57 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2046, average loss: 0.8912
[09/27 23:02:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.81	top5: 94.83	
[09/27 23:02:57 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/27 23:03:06 visual_prompt]: Epoch 32 / 100: avg data time: 9.08e-02, avg batch time: 0.5186, average train loss: 0.0728
[09/27 23:03:09 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1816, average loss: 0.0582
[09/27 23:03:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/27 23:03:31 visual_prompt]: 	Test 100/157. loss: 0.760, 0.2048 s / batch. (data: 3.19e-05)max mem: 7.80512 GB 
[09/27 23:03:43 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2043, average loss: 0.8609
[09/27 23:03:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.72	top5: 95.25	
[09/27 23:03:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/27 23:03:53 visual_prompt]: Epoch 33 / 100: avg data time: 9.09e-02, avg batch time: 0.5192, average train loss: 0.0612
[09/27 23:03:55 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1806, average loss: 0.0482
[09/27 23:03:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:04:17 visual_prompt]: 	Test 100/157. loss: 0.764, 0.2035 s / batch. (data: 3.19e-05)max mem: 7.80512 GB 
[09/27 23:04:30 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2044, average loss: 0.8529
[09/27 23:04:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.06	top5: 95.38	
[09/27 23:04:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/27 23:04:39 visual_prompt]: Epoch 34 / 100: avg data time: 9.06e-02, avg batch time: 0.5186, average train loss: 0.0620
[09/27 23:04:42 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1727, average loss: 0.0499
[09/27 23:04:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:05:04 visual_prompt]: 	Test 100/157. loss: 0.742, 0.2048 s / batch. (data: 3.00e-05)max mem: 7.80512 GB 
[09/27 23:05:16 visual_prompt]: Inference (test):avg data time: 1.40e-04, avg batch time: 0.2044, average loss: 0.8735
[09/27 23:05:16 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.92	top5: 95.44	
[09/27 23:05:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/27 23:05:25 visual_prompt]: Epoch 35 / 100: avg data time: 8.25e-02, avg batch time: 0.5103, average train loss: 0.0621
[09/27 23:05:28 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1758, average loss: 0.0524
[09/27 23:05:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:05:50 visual_prompt]: 	Test 100/157. loss: 0.816, 0.2060 s / batch. (data: 2.98e-05)max mem: 7.80512 GB 
[09/27 23:06:03 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2040, average loss: 0.8978
[09/27 23:06:03 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.02	top5: 95.24	
[09/27 23:06:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/27 23:06:12 visual_prompt]: Epoch 36 / 100: avg data time: 9.05e-02, avg batch time: 0.5164, average train loss: 0.0541
[09/27 23:06:15 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1746, average loss: 0.0429
[09/27 23:06:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:06:37 visual_prompt]: 	Test 100/157. loss: 0.784, 0.2034 s / batch. (data: 2.86e-05)max mem: 7.80512 GB 
[09/27 23:06:49 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2049, average loss: 0.8676
[09/27 23:06:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.39	top5: 95.52	
[09/27 23:06:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/27 23:06:58 visual_prompt]: Epoch 37 / 100: avg data time: 1.00e-01, avg batch time: 0.5277, average train loss: 0.0515
[09/27 23:07:01 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1841, average loss: 0.0419
[09/27 23:07:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:07:23 visual_prompt]: 	Test 100/157. loss: 0.765, 0.2038 s / batch. (data: 2.74e-05)max mem: 7.80512 GB 
[09/27 23:07:36 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2041, average loss: 0.8794
[09/27 23:07:36 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.07	top5: 95.55	
[09/27 23:07:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/27 23:07:45 visual_prompt]: Epoch 38 / 100: avg data time: 9.33e-02, avg batch time: 0.5220, average train loss: 0.0484
[09/27 23:07:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1804, average loss: 0.0407
[09/27 23:07:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:08:10 visual_prompt]: 	Test 100/157. loss: 0.838, 0.2040 s / batch. (data: 3.08e-05)max mem: 7.80512 GB 
[09/27 23:08:22 visual_prompt]: Inference (test):avg data time: 1.19e-04, avg batch time: 0.2043, average loss: 0.8851
[09/27 23:08:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.79	top5: 95.45	
[09/27 23:08:22 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/27 23:08:31 visual_prompt]: Epoch 39 / 100: avg data time: 9.64e-02, avg batch time: 0.5217, average train loss: 0.0491
[09/27 23:08:34 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1741, average loss: 0.0375
[09/27 23:08:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:08:56 visual_prompt]: 	Test 100/157. loss: 0.807, 0.2051 s / batch. (data: 3.15e-05)max mem: 7.80512 GB 
[09/27 23:09:09 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2041, average loss: 0.8690
[09/27 23:09:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.56	top5: 95.48	
[09/27 23:09:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/27 23:09:18 visual_prompt]: Epoch 40 / 100: avg data time: 8.57e-02, avg batch time: 0.5153, average train loss: 0.0460
[09/27 23:09:21 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.1846, average loss: 0.0386
[09/27 23:09:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:09:43 visual_prompt]: 	Test 100/157. loss: 0.870, 0.2045 s / batch. (data: 4.22e-05)max mem: 7.80512 GB 
[09/27 23:09:55 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2045, average loss: 0.9020
[09/27 23:09:55 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.29	top5: 95.21	
[09/27 23:09:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/27 23:10:04 visual_prompt]: Epoch 41 / 100: avg data time: 9.02e-02, avg batch time: 0.5188, average train loss: 0.0448
[09/27 23:10:07 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1737, average loss: 0.0366
[09/27 23:10:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:10:29 visual_prompt]: 	Test 100/157. loss: 0.844, 0.2041 s / batch. (data: 3.10e-05)max mem: 7.80512 GB 
[09/27 23:10:42 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2046, average loss: 0.9009
[09/27 23:10:42 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.86	top5: 95.14	
[09/27 23:10:42 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/27 23:10:51 visual_prompt]: Epoch 42 / 100: avg data time: 9.19e-02, avg batch time: 0.5211, average train loss: 0.0443
[09/27 23:10:54 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1761, average loss: 0.0377
[09/27 23:10:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:11:16 visual_prompt]: 	Test 100/157. loss: 0.882, 0.2043 s / batch. (data: 3.05e-05)max mem: 7.80512 GB 
[09/27 23:11:28 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2045, average loss: 0.9179
[09/27 23:11:28 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.26	top5: 95.07	
[09/27 23:11:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/27 23:11:37 visual_prompt]: Epoch 43 / 100: avg data time: 9.20e-02, avg batch time: 0.5189, average train loss: 0.0466
[09/27 23:11:40 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1745, average loss: 0.0366
[09/27 23:11:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:12:02 visual_prompt]: 	Test 100/157. loss: 0.792, 0.2051 s / batch. (data: 3.15e-05)max mem: 7.80512 GB 
[09/27 23:12:15 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2044, average loss: 0.9108
[09/27 23:12:15 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.57	top5: 95.32	
[09/27 23:12:15 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/27 23:12:24 visual_prompt]: Epoch 44 / 100: avg data time: 9.85e-02, avg batch time: 0.5263, average train loss: 0.0441
[09/27 23:12:27 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1768, average loss: 0.0346
[09/27 23:12:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:12:49 visual_prompt]: 	Test 100/157. loss: 0.893, 0.2036 s / batch. (data: 2.98e-05)max mem: 7.80512 GB 
[09/27 23:13:01 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2042, average loss: 0.9077
[09/27 23:13:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.34	
[09/27 23:13:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/27 23:13:11 visual_prompt]: Epoch 45 / 100: avg data time: 9.14e-02, avg batch time: 0.5202, average train loss: 0.0435
[09/27 23:13:13 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1817, average loss: 0.0333
[09/27 23:13:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:13:36 visual_prompt]: 	Test 100/157. loss: 0.870, 0.2051 s / batch. (data: 3.22e-05)max mem: 7.80512 GB 
[09/27 23:13:48 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2045, average loss: 0.9490
[09/27 23:13:48 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.54	top5: 95.23	
[09/27 23:13:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/27 23:13:57 visual_prompt]: Epoch 46 / 100: avg data time: 9.40e-02, avg batch time: 0.5214, average train loss: 0.1417
[09/27 23:14:00 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1843, average loss: 0.2522
[09/27 23:14:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.00	top5: 100.00	
[09/27 23:14:22 visual_prompt]: 	Test 100/157. loss: 1.157, 0.2044 s / batch. (data: 2.91e-05)max mem: 7.80512 GB 
[09/27 23:14:35 visual_prompt]: Inference (test):avg data time: 9.35e-05, avg batch time: 0.2043, average loss: 1.1330
[09/27 23:14:35 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.04	top5: 93.31	
[09/27 23:14:35 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/27 23:14:44 visual_prompt]: Epoch 47 / 100: avg data time: 8.61e-02, avg batch time: 0.5172, average train loss: 0.3326
[09/27 23:14:47 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1852, average loss: 3.0052
[09/27 23:14:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 27.50	top5: 60.50	
[09/27 23:15:09 visual_prompt]: 	Test 100/157. loss: 3.169, 0.2046 s / batch. (data: 2.77e-05)max mem: 7.80512 GB 
[09/27 23:15:21 visual_prompt]: Inference (test):avg data time: 1.54e-04, avg batch time: 0.2040, average loss: 3.4624
[09/27 23:15:21 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 20.45	top5: 47.63	
[09/27 23:15:21 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/27 23:15:30 visual_prompt]: Epoch 48 / 100: avg data time: 9.52e-02, avg batch time: 0.5215, average train loss: 2.0864
[09/27 23:15:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1826, average loss: 1.0583
[09/27 23:15:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 83.50	top5: 96.50	
[09/27 23:15:55 visual_prompt]: 	Test 100/157. loss: 1.854, 0.2046 s / batch. (data: 3.08e-05)max mem: 7.80512 GB 
[09/27 23:16:07 visual_prompt]: Inference (test):avg data time: 5.52e-05, avg batch time: 0.2042, average loss: 1.7939
[09/27 23:16:08 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 60.47	top5: 86.47	
[09/27 23:16:08 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/27 23:16:17 visual_prompt]: Epoch 49 / 100: avg data time: 9.23e-02, avg batch time: 0.5184, average train loss: 0.6138
[09/27 23:16:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1821, average loss: 0.2776
[09/27 23:16:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.00	top5: 100.00	
[09/27 23:16:41 visual_prompt]: 	Test 100/157. loss: 1.102, 0.2051 s / batch. (data: 3.34e-05)max mem: 7.80512 GB 
[09/27 23:16:54 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2041, average loss: 1.0537
[09/27 23:16:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.13	top5: 93.88	
[09/27 23:16:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/27 23:17:03 visual_prompt]: Epoch 50 / 100: avg data time: 9.77e-02, avg batch time: 0.5258, average train loss: 0.2285
[09/27 23:17:06 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1767, average loss: 0.1192
[09/27 23:17:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/27 23:17:28 visual_prompt]: 	Test 100/157. loss: 1.060, 0.2038 s / batch. (data: 3.22e-05)max mem: 7.80512 GB 
[09/27 23:17:40 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2044, average loss: 0.9483
[09/27 23:17:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.17	top5: 94.54	
[09/27 23:17:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/27 23:17:49 visual_prompt]: Epoch 51 / 100: avg data time: 9.18e-02, avg batch time: 0.5196, average train loss: 0.1198
[09/27 23:17:52 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1842, average loss: 0.0796
[09/27 23:17:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:18:14 visual_prompt]: 	Test 100/157. loss: 0.895, 0.2038 s / batch. (data: 3.05e-05)max mem: 7.80512 GB 
[09/27 23:18:27 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2045, average loss: 0.8896
[09/27 23:18:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.82	top5: 95.25	
[09/27 23:18:27 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/27 23:18:36 visual_prompt]: Epoch 52 / 100: avg data time: 9.94e-02, avg batch time: 0.5269, average train loss: 0.0754
[09/27 23:18:39 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1825, average loss: 0.0585
[09/27 23:18:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:19:01 visual_prompt]: 	Test 100/157. loss: 0.910, 0.2062 s / batch. (data: 3.24e-05)max mem: 7.80512 GB 
[09/27 23:19:14 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2042, average loss: 0.8807
[09/27 23:19:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.64	top5: 95.45	
[09/27 23:19:14 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/27 23:19:23 visual_prompt]: Epoch 53 / 100: avg data time: 1.01e-01, avg batch time: 0.5290, average train loss: 0.0599
[09/27 23:19:26 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1809, average loss: 0.0454
[09/27 23:19:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:19:48 visual_prompt]: 	Test 100/157. loss: 0.905, 0.2052 s / batch. (data: 2.86e-05)max mem: 7.80512 GB 
[09/27 23:20:00 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2042, average loss: 0.8602
[09/27 23:20:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.37	top5: 95.48	
[09/27 23:20:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/27 23:20:09 visual_prompt]: Epoch 54 / 100: avg data time: 9.07e-02, avg batch time: 0.5169, average train loss: 0.0499
[09/27 23:20:12 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1792, average loss: 0.0435
[09/27 23:20:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:20:34 visual_prompt]: 	Test 100/157. loss: 0.893, 0.2039 s / batch. (data: 3.46e-05)max mem: 7.80512 GB 
[09/27 23:20:47 visual_prompt]: Inference (test):avg data time: 5.62e-05, avg batch time: 0.2040, average loss: 0.8802
[09/27 23:20:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.68	top5: 95.29	
[09/27 23:20:47 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/27 23:20:56 visual_prompt]: Epoch 55 / 100: avg data time: 9.52e-02, avg batch time: 0.5244, average train loss: 0.0479
[09/27 23:20:59 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1729, average loss: 0.0384
[09/27 23:20:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:21:21 visual_prompt]: 	Test 100/157. loss: 0.889, 0.2045 s / batch. (data: 3.05e-05)max mem: 7.80512 GB 
[09/27 23:21:34 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2042, average loss: 0.8561
[09/27 23:21:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.45	top5: 95.60	
[09/27 23:21:34 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/27 23:21:43 visual_prompt]: Epoch 56 / 100: avg data time: 9.37e-02, avg batch time: 0.5212, average train loss: 0.0450
[09/27 23:21:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1845, average loss: 0.0395
[09/27 23:21:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:22:08 visual_prompt]: 	Test 100/157. loss: 0.888, 0.2052 s / batch. (data: 3.05e-05)max mem: 7.80512 GB 
[09/27 23:22:20 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2040, average loss: 0.8721
[09/27 23:22:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.16	top5: 95.37	
[09/27 23:22:20 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/27 23:22:29 visual_prompt]: Epoch 57 / 100: avg data time: 8.59e-02, avg batch time: 0.5149, average train loss: 0.0435
[09/27 23:22:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1755, average loss: 0.0378
[09/27 23:22:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:22:54 visual_prompt]: 	Test 100/157. loss: 0.882, 0.2052 s / batch. (data: 2.88e-05)max mem: 7.80512 GB 
[09/27 23:23:07 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2042, average loss: 0.8688
[09/27 23:23:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.14	top5: 95.50	
[09/27 23:23:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/27 23:23:16 visual_prompt]: Epoch 58 / 100: avg data time: 7.32e-02, avg batch time: 0.5018, average train loss: 0.0423
[09/27 23:23:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1759, average loss: 0.0367
[09/27 23:23:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:23:40 visual_prompt]: 	Test 100/157. loss: 0.893, 0.2051 s / batch. (data: 2.69e-05)max mem: 7.80512 GB 
[09/27 23:23:53 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2041, average loss: 0.8694
[09/27 23:23:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.30	top5: 95.52	
[09/27 23:23:53 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/27 23:24:02 visual_prompt]: Epoch 59 / 100: avg data time: 9.66e-02, avg batch time: 0.5236, average train loss: 0.0423
[09/27 23:24:05 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1769, average loss: 0.0354
[09/27 23:24:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:24:27 visual_prompt]: 	Test 100/157. loss: 0.885, 0.2042 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:24:39 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2041, average loss: 0.8805
[09/27 23:24:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.13	top5: 95.38	
[09/27 23:24:39 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/27 23:24:49 visual_prompt]: Epoch 60 / 100: avg data time: 9.30e-02, avg batch time: 0.5178, average train loss: 0.0414
[09/27 23:24:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1741, average loss: 0.0347
[09/27 23:24:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:25:13 visual_prompt]: 	Test 100/157. loss: 0.879, 0.2053 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:25:26 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2042, average loss: 0.8845
[09/27 23:25:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.22	top5: 95.34	
[09/27 23:25:26 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/27 23:25:35 visual_prompt]: Epoch 61 / 100: avg data time: 9.62e-02, avg batch time: 0.5220, average train loss: 0.0404
[09/27 23:25:38 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1803, average loss: 0.0348
[09/27 23:25:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:26:00 visual_prompt]: 	Test 100/157. loss: 0.864, 0.2048 s / batch. (data: 3.10e-05)max mem: 7.80512 GB 
[09/27 23:26:12 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2041, average loss: 0.8967
[09/27 23:26:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.56	top5: 95.14	
[09/27 23:26:12 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/27 23:26:22 visual_prompt]: Epoch 62 / 100: avg data time: 9.16e-02, avg batch time: 0.5192, average train loss: 0.0408
[09/27 23:26:24 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1779, average loss: 0.0342
[09/27 23:26:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:26:46 visual_prompt]: 	Test 100/157. loss: 0.852, 0.2043 s / batch. (data: 5.27e-05)max mem: 7.80512 GB 
[09/27 23:26:59 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2040, average loss: 0.8973
[09/27 23:26:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.84	top5: 95.50	
[09/27 23:26:59 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/27 23:27:08 visual_prompt]: Epoch 63 / 100: avg data time: 9.28e-02, avg batch time: 0.5214, average train loss: 0.0415
[09/27 23:27:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1777, average loss: 0.0341
[09/27 23:27:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:27:33 visual_prompt]: 	Test 100/157. loss: 0.894, 0.2058 s / batch. (data: 2.91e-05)max mem: 7.80512 GB 
[09/27 23:27:45 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2042, average loss: 0.9017
[09/27 23:27:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.72	top5: 95.33	
[09/27 23:27:45 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/27 23:27:54 visual_prompt]: Epoch 64 / 100: avg data time: 8.30e-02, avg batch time: 0.5113, average train loss: 0.0428
[09/27 23:27:57 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1780, average loss: 0.0353
[09/27 23:27:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:28:19 visual_prompt]: 	Test 100/157. loss: 0.867, 0.2058 s / batch. (data: 2.88e-05)max mem: 7.80512 GB 
[09/27 23:28:32 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2041, average loss: 0.8939
[09/27 23:28:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.16	top5: 95.36	
[09/27 23:28:32 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/27 23:28:41 visual_prompt]: Epoch 65 / 100: avg data time: 1.00e-01, avg batch time: 0.5295, average train loss: 0.0407
[09/27 23:28:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1788, average loss: 0.0344
[09/27 23:28:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:29:06 visual_prompt]: 	Test 100/157. loss: 0.863, 0.2069 s / batch. (data: 2.98e-05)max mem: 7.80512 GB 
[09/27 23:29:18 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2041, average loss: 0.9011
[09/27 23:29:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.64	top5: 95.29	
[09/27 23:29:18 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/27 23:29:27 visual_prompt]: Epoch 66 / 100: avg data time: 8.96e-02, avg batch time: 0.5186, average train loss: 0.0393
[09/27 23:29:30 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1800, average loss: 0.0334
[09/27 23:29:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:29:52 visual_prompt]: 	Test 100/157. loss: 0.903, 0.2049 s / batch. (data: 3.17e-05)max mem: 7.80512 GB 
[09/27 23:30:05 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2041, average loss: 0.9128
[09/27 23:30:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.82	top5: 95.28	
[09/27 23:30:05 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/27 23:30:14 visual_prompt]: Epoch 67 / 100: avg data time: 9.28e-02, avg batch time: 0.5219, average train loss: 0.0385
[09/27 23:30:17 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1847, average loss: 0.0321
[09/27 23:30:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:30:39 visual_prompt]: 	Test 100/157. loss: 0.840, 0.2062 s / batch. (data: 2.91e-05)max mem: 7.80512 GB 
[09/27 23:30:51 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2043, average loss: 0.9047
[09/27 23:30:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.76	top5: 95.38	
[09/27 23:30:51 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/27 23:31:00 visual_prompt]: Epoch 68 / 100: avg data time: 9.13e-02, avg batch time: 0.5176, average train loss: 0.0381
[09/27 23:31:03 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1727, average loss: 0.0319
[09/27 23:31:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:31:25 visual_prompt]: 	Test 100/157. loss: 0.824, 0.2043 s / batch. (data: 2.88e-05)max mem: 7.80512 GB 
[09/27 23:31:38 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2039, average loss: 0.9083
[09/27 23:31:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.94	top5: 95.42	
[09/27 23:31:38 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/27 23:31:47 visual_prompt]: Epoch 69 / 100: avg data time: 9.05e-02, avg batch time: 0.5192, average train loss: 0.0366
[09/27 23:31:50 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1777, average loss: 0.0301
[09/27 23:31:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:32:12 visual_prompt]: 	Test 100/157. loss: 0.855, 0.2056 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 23:32:24 visual_prompt]: Inference (test):avg data time: 6.46e-05, avg batch time: 0.2044, average loss: 0.9214
[09/27 23:32:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.46	top5: 95.22	
[09/27 23:32:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/27 23:32:33 visual_prompt]: Epoch 70 / 100: avg data time: 8.66e-02, avg batch time: 0.5121, average train loss: 0.0357
[09/27 23:32:36 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1734, average loss: 0.0301
[09/27 23:32:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:32:58 visual_prompt]: 	Test 100/157. loss: 0.847, 0.2049 s / batch. (data: 3.81e-05)max mem: 7.80512 GB 
[09/27 23:33:11 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2045, average loss: 0.9192
[09/27 23:33:11 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.42	top5: 95.14	
[09/27 23:33:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/27 23:33:20 visual_prompt]: Epoch 71 / 100: avg data time: 9.47e-02, avg batch time: 0.5230, average train loss: 0.0357
[09/27 23:33:23 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1776, average loss: 0.0297
[09/27 23:33:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:33:45 visual_prompt]: 	Test 100/157. loss: 0.844, 0.2045 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:33:57 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2041, average loss: 0.9233
[09/27 23:33:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.64	top5: 95.28	
[09/27 23:33:57 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/27 23:34:07 visual_prompt]: Epoch 72 / 100: avg data time: 9.10e-02, avg batch time: 0.5196, average train loss: 0.0353
[09/27 23:34:09 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1736, average loss: 0.0301
[09/27 23:34:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:34:32 visual_prompt]: 	Test 100/157. loss: 0.892, 0.2052 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:34:44 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2046, average loss: 0.9301
[09/27 23:34:44 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.23	top5: 95.18	
[09/27 23:34:44 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/27 23:34:53 visual_prompt]: Epoch 73 / 100: avg data time: 9.18e-02, avg batch time: 0.5213, average train loss: 0.0349
[09/27 23:34:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1763, average loss: 0.0288
[09/27 23:34:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:35:18 visual_prompt]: 	Test 100/157. loss: 0.841, 0.2050 s / batch. (data: 2.88e-05)max mem: 7.80512 GB 
[09/27 23:35:31 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2044, average loss: 0.9333
[09/27 23:35:31 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.32	top5: 95.02	
[09/27 23:35:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/27 23:35:40 visual_prompt]: Epoch 74 / 100: avg data time: 9.62e-02, avg batch time: 0.5241, average train loss: 0.0341
[09/27 23:35:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1743, average loss: 0.0282
[09/27 23:35:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:36:05 visual_prompt]: 	Test 100/157. loss: 0.845, 0.2052 s / batch. (data: 2.96e-05)max mem: 7.80512 GB 
[09/27 23:36:17 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2042, average loss: 0.9423
[09/27 23:36:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.93	
[09/27 23:36:17 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/27 23:36:26 visual_prompt]: Epoch 75 / 100: avg data time: 9.88e-02, avg batch time: 0.5284, average train loss: 0.0337
[09/27 23:36:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1734, average loss: 0.0278
[09/27 23:36:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:36:51 visual_prompt]: 	Test 100/157. loss: 0.876, 0.2043 s / batch. (data: 2.79e-05)max mem: 7.80512 GB 
[09/27 23:37:04 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2046, average loss: 0.9488
[09/27 23:37:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.88	top5: 95.06	
[09/27 23:37:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/27 23:37:13 visual_prompt]: Epoch 76 / 100: avg data time: 9.76e-02, avg batch time: 0.5259, average train loss: 0.0333
[09/27 23:37:16 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1834, average loss: 0.0273
[09/27 23:37:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:37:38 visual_prompt]: 	Test 100/157. loss: 0.852, 0.2049 s / batch. (data: 2.48e-05)max mem: 7.80512 GB 
[09/27 23:37:50 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2044, average loss: 0.9402
[09/27 23:37:50 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.25	top5: 95.03	
[09/27 23:37:50 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/27 23:38:00 visual_prompt]: Epoch 77 / 100: avg data time: 9.50e-02, avg batch time: 0.5224, average train loss: 0.0332
[09/27 23:38:02 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1852, average loss: 0.0276
[09/27 23:38:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:38:24 visual_prompt]: 	Test 100/157. loss: 0.875, 0.2060 s / batch. (data: 2.98e-05)max mem: 7.80512 GB 
[09/27 23:38:37 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2045, average loss: 0.9566
[09/27 23:38:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.79	top5: 94.94	
[09/27 23:38:37 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/27 23:38:46 visual_prompt]: Epoch 78 / 100: avg data time: 9.20e-02, avg batch time: 0.5203, average train loss: 0.0325
[09/27 23:38:49 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1785, average loss: 0.0274
[09/27 23:38:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:39:11 visual_prompt]: 	Test 100/157. loss: 0.880, 0.2043 s / batch. (data: 3.05e-05)max mem: 7.80512 GB 
[09/27 23:39:23 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2043, average loss: 0.9578
[09/27 23:39:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.53	top5: 94.78	
[09/27 23:39:24 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/27 23:39:33 visual_prompt]: Epoch 79 / 100: avg data time: 8.97e-02, avg batch time: 0.5162, average train loss: 0.0324
[09/27 23:39:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1728, average loss: 0.0271
[09/27 23:39:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:39:57 visual_prompt]: 	Test 100/157. loss: 0.879, 0.2041 s / batch. (data: 2.72e-05)max mem: 7.80512 GB 
[09/27 23:40:10 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2044, average loss: 0.9507
[09/27 23:40:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.72	top5: 94.91	
[09/27 23:40:10 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/27 23:40:19 visual_prompt]: Epoch 80 / 100: avg data time: 9.29e-02, avg batch time: 0.5196, average train loss: 0.0324
[09/27 23:40:22 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1848, average loss: 0.0272
[09/27 23:40:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:40:44 visual_prompt]: 	Test 100/157. loss: 0.863, 0.2038 s / batch. (data: 3.27e-05)max mem: 7.80512 GB 
[09/27 23:40:57 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2044, average loss: 0.9658
[09/27 23:40:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.92	
[09/27 23:40:57 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/27 23:41:06 visual_prompt]: Epoch 81 / 100: avg data time: 8.82e-02, avg batch time: 0.5163, average train loss: 0.0322
[09/27 23:41:09 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1755, average loss: 0.0272
[09/27 23:41:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:41:31 visual_prompt]: 	Test 100/157. loss: 0.873, 0.2058 s / batch. (data: 2.77e-05)max mem: 7.80512 GB 
[09/27 23:41:43 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2044, average loss: 0.9683
[09/27 23:41:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.34	top5: 94.77	
[09/27 23:41:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/27 23:41:52 visual_prompt]: Epoch 82 / 100: avg data time: 9.40e-02, avg batch time: 0.5203, average train loss: 0.0321
[09/27 23:41:55 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1749, average loss: 0.0270
[09/27 23:41:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:42:17 visual_prompt]: 	Test 100/157. loss: 0.866, 0.2043 s / batch. (data: 3.10e-05)max mem: 7.80512 GB 
[09/27 23:42:30 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2042, average loss: 0.9723
[09/27 23:42:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.34	top5: 94.96	
[09/27 23:42:30 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/27 23:42:39 visual_prompt]: Epoch 83 / 100: avg data time: 8.68e-02, avg batch time: 0.5144, average train loss: 0.0320
[09/27 23:42:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1830, average loss: 0.0271
[09/27 23:42:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:43:04 visual_prompt]: 	Test 100/157. loss: 0.888, 0.2030 s / batch. (data: 3.08e-05)max mem: 7.80512 GB 
[09/27 23:43:16 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2044, average loss: 0.9710
[09/27 23:43:16 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.42	top5: 94.81	
[09/27 23:43:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/27 23:43:25 visual_prompt]: Epoch 84 / 100: avg data time: 9.06e-02, avg batch time: 0.5191, average train loss: 0.0319
[09/27 23:43:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1764, average loss: 0.0271
[09/27 23:43:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:43:50 visual_prompt]: 	Test 100/157. loss: 0.878, 0.2046 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 23:44:03 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2041, average loss: 0.9713
[09/27 23:44:03 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.48	top5: 94.80	
[09/27 23:44:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/27 23:44:12 visual_prompt]: Epoch 85 / 100: avg data time: 8.48e-02, avg batch time: 0.5138, average train loss: 0.0315
[09/27 23:44:15 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1853, average loss: 0.0264
[09/27 23:44:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:44:37 visual_prompt]: 	Test 100/157. loss: 0.886, 0.2054 s / batch. (data: 2.91e-05)max mem: 7.80512 GB 
[09/27 23:44:49 visual_prompt]: Inference (test):avg data time: 1.00e-04, avg batch time: 0.2041, average loss: 0.9743
[09/27 23:44:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.47	top5: 94.75	
[09/27 23:44:49 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/27 23:44:59 visual_prompt]: Epoch 86 / 100: avg data time: 9.43e-02, avg batch time: 0.5247, average train loss: 0.0315
[09/27 23:45:01 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1802, average loss: 0.0265
[09/27 23:45:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:45:24 visual_prompt]: 	Test 100/157. loss: 0.906, 0.2031 s / batch. (data: 3.03e-05)max mem: 7.80512 GB 
[09/27 23:45:36 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2043, average loss: 0.9819
[09/27 23:45:36 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.04	top5: 94.67	
[09/27 23:45:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/27 23:45:45 visual_prompt]: Epoch 87 / 100: avg data time: 7.89e-02, avg batch time: 0.5085, average train loss: 0.0316
[09/27 23:45:48 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1758, average loss: 0.0264
[09/27 23:45:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:46:10 visual_prompt]: 	Test 100/157. loss: 0.906, 0.2043 s / batch. (data: 3.15e-05)max mem: 7.80512 GB 
[09/27 23:46:22 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2043, average loss: 0.9773
[09/27 23:46:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.24	top5: 94.70	
[09/27 23:46:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/27 23:46:31 visual_prompt]: Epoch 88 / 100: avg data time: 8.81e-02, avg batch time: 0.5159, average train loss: 0.0317
[09/27 23:46:34 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1753, average loss: 0.0264
[09/27 23:46:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:46:56 visual_prompt]: 	Test 100/157. loss: 0.903, 0.2049 s / batch. (data: 3.10e-05)max mem: 7.80512 GB 
[09/27 23:47:09 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2042, average loss: 0.9715
[09/27 23:47:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.29	top5: 94.74	
[09/27 23:47:09 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/27 23:47:18 visual_prompt]: Epoch 89 / 100: avg data time: 9.51e-02, avg batch time: 0.5216, average train loss: 0.0315
[09/27 23:47:21 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1759, average loss: 0.0264
[09/27 23:47:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:47:43 visual_prompt]: 	Test 100/157. loss: 0.902, 0.2047 s / batch. (data: 3.12e-05)max mem: 7.80512 GB 
[09/27 23:47:55 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2043, average loss: 0.9747
[09/27 23:47:55 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.21	top5: 94.85	
[09/27 23:47:55 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/27 23:48:05 visual_prompt]: Epoch 90 / 100: avg data time: 9.54e-02, avg batch time: 0.5253, average train loss: 0.0310
[09/27 23:48:07 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1755, average loss: 0.0265
[09/27 23:48:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:48:30 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2046 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:48:42 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2043, average loss: 0.9842
[09/27 23:48:42 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.96	top5: 94.67	
[09/27 23:48:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/27 23:48:51 visual_prompt]: Epoch 91 / 100: avg data time: 9.83e-02, avg batch time: 0.5238, average train loss: 0.0311
[09/27 23:48:54 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1802, average loss: 0.0263
[09/27 23:48:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:49:16 visual_prompt]: 	Test 100/157. loss: 0.916, 0.2050 s / batch. (data: 3.24e-05)max mem: 7.80512 GB 
[09/27 23:49:29 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2039, average loss: 0.9900
[09/27 23:49:29 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.91	top5: 94.62	
[09/27 23:49:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/27 23:49:38 visual_prompt]: Epoch 92 / 100: avg data time: 8.79e-02, avg batch time: 0.5143, average train loss: 0.0312
[09/27 23:49:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1746, average loss: 0.0262
[09/27 23:49:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:50:03 visual_prompt]: 	Test 100/157. loss: 0.914, 0.2051 s / batch. (data: 2.88e-05)max mem: 7.80512 GB 
[09/27 23:50:15 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2042, average loss: 0.9905
[09/27 23:50:15 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.92	top5: 94.71	
[09/27 23:50:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/27 23:50:24 visual_prompt]: Epoch 93 / 100: avg data time: 9.31e-02, avg batch time: 0.5214, average train loss: 0.0315
[09/27 23:50:27 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1848, average loss: 0.0262
[09/27 23:50:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:50:49 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2061 s / batch. (data: 3.15e-05)max mem: 7.80512 GB 
[09/27 23:51:02 visual_prompt]: Inference (test):avg data time: 1.52e-04, avg batch time: 0.2046, average loss: 0.9883
[09/27 23:51:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.99	top5: 94.65	
[09/27 23:51:02 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/27 23:51:11 visual_prompt]: Epoch 94 / 100: avg data time: 9.52e-02, avg batch time: 0.5231, average train loss: 0.0312
[09/27 23:51:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1787, average loss: 0.0262
[09/27 23:51:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:51:36 visual_prompt]: 	Test 100/157. loss: 0.920, 0.2050 s / batch. (data: 4.70e-05)max mem: 7.80512 GB 
[09/27 23:51:48 visual_prompt]: Inference (test):avg data time: 4.27e-05, avg batch time: 0.2043, average loss: 0.9886
[09/27 23:51:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.94	top5: 94.66	
[09/27 23:51:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/27 23:51:58 visual_prompt]: Epoch 95 / 100: avg data time: 9.24e-02, avg batch time: 0.5207, average train loss: 0.0309
[09/27 23:52:00 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1790, average loss: 0.0262
[09/27 23:52:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:52:23 visual_prompt]: 	Test 100/157. loss: 0.920, 0.2042 s / batch. (data: 3.08e-05)max mem: 7.80512 GB 
[09/27 23:52:35 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2043, average loss: 0.9881
[09/27 23:52:35 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.92	top5: 94.70	
[09/27 23:52:35 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/27 23:52:44 visual_prompt]: Epoch 96 / 100: avg data time: 9.52e-02, avg batch time: 0.5239, average train loss: 0.0309
[09/27 23:52:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1745, average loss: 0.0261
[09/27 23:52:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:53:09 visual_prompt]: 	Test 100/157. loss: 0.918, 0.2058 s / batch. (data: 3.31e-05)max mem: 7.80512 GB 
[09/27 23:53:22 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2043, average loss: 0.9887
[09/27 23:53:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.02	top5: 94.71	
[09/27 23:53:22 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/27 23:53:31 visual_prompt]: Epoch 97 / 100: avg data time: 9.41e-02, avg batch time: 0.5201, average train loss: 0.0313
[09/27 23:53:34 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1822, average loss: 0.0261
[09/27 23:53:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:53:56 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2057 s / batch. (data: 2.88e-05)max mem: 7.80512 GB 
[09/27 23:54:08 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2039, average loss: 0.9895
[09/27 23:54:08 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.99	top5: 94.69	
[09/27 23:54:08 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/27 23:54:17 visual_prompt]: Epoch 98 / 100: avg data time: 8.30e-02, avg batch time: 0.5123, average train loss: 0.0309
[09/27 23:54:20 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1791, average loss: 0.0261
[09/27 23:54:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:54:42 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2040 s / batch. (data: 2.93e-05)max mem: 7.80512 GB 
[09/27 23:54:55 visual_prompt]: Inference (test):avg data time: 8.51e-05, avg batch time: 0.2041, average loss: 0.9892
[09/27 23:54:55 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.95	top5: 94.70	
[09/27 23:54:55 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/27 23:55:04 visual_prompt]: Epoch 99 / 100: avg data time: 9.42e-02, avg batch time: 0.5223, average train loss: 0.0310
[09/27 23:55:07 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1739, average loss: 0.0261
[09/27 23:55:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:55:29 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2038 s / batch. (data: 2.86e-05)max mem: 7.80512 GB 
[09/27 23:55:41 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2043, average loss: 0.9894
[09/27 23:55:41 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.96	top5: 94.68	
[09/27 23:55:41 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/27 23:55:50 visual_prompt]: Epoch 100 / 100: avg data time: 8.57e-02, avg batch time: 0.5139, average train loss: 0.0307
[09/27 23:55:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1768, average loss: 0.0261
[09/27 23:55:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/27 23:56:15 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2062 s / batch. (data: 2.55e-05)max mem: 7.80512 GB 
[09/27 23:56:27 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2044, average loss: 0.9894
[09/27 23:56:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.96	top5: 94.68	
[09/27 23:56:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/27 23:56:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/27 23:56:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 23:56:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/27 23:56:27 visual_prompt]: Training with config:
[09/27 23:56:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/test/seed9286/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9286, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/27 23:56:27 visual_prompt]: Loading training data...
[09/27 23:56:27 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800]+train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/27 23:56:29 visual_prompt]: Number of images: 1000
[09/27 23:56:29 visual_prompt]: Number of classes: 100 / 100
[09/27 23:56:29 visual_prompt]: Loading validation data...
[09/27 23:56:29 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/27 23:56:29 visual_prompt]: Number of images: 200
[09/27 23:56:29 visual_prompt]: Number of classes: 90 / 100
[09/27 23:56:29 visual_prompt]: Loading test data...
[09/27 23:56:29 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split test, from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/27 23:56:41 visual_prompt]: Number of images: 10000
[09/27 23:56:41 visual_prompt]: Number of classes: 100 / 100
[09/27 23:56:41 visual_prompt]: Constructing models...
[09/27 23:56:43 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/27 23:56:43 visual_prompt]: tuned percent:0.623
[09/27 23:56:44 visual_prompt]: Device used for model: 0
[09/27 23:56:44 visual_prompt]: Setting up Evaluator...
[09/27 23:56:44 visual_prompt]: Setting up Trainer...
[09/27 23:56:44 visual_prompt]: 	Setting up the optimizer...
[09/27 23:56:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/27 23:56:53 visual_prompt]: Epoch 1 / 100: avg data time: 1.02e-01, avg batch time: 0.5252, average train loss: 4.6789
[09/27 23:56:56 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1724, average loss: 4.6620
[09/27 23:56:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/27 23:57:18 visual_prompt]: 	Test 100/157. loss: 4.588, 0.2030 s / batch. (data: 3.00e-05)max mem: 7.80597 GB 
[09/27 23:57:30 visual_prompt]: Inference (test):avg data time: 1.55e-04, avg batch time: 0.2031, average loss: 4.6561
[09/27 23:57:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 0.83	top5: 5.67	
[09/27 23:57:30 visual_prompt]: Best epoch 1: best metric: 0.005
[09/27 23:57:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/27 23:57:39 visual_prompt]: Epoch 2 / 100: avg data time: 9.90e-02, avg batch time: 0.5237, average train loss: 4.6284
[09/27 23:57:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1740, average loss: 4.5787
[09/27 23:57:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/27 23:58:05 visual_prompt]: 	Test 100/157. loss: 4.605, 0.2054 s / batch. (data: 3.05e-05)max mem: 7.80626 GB 
[09/27 23:58:17 visual_prompt]: Inference (test):avg data time: 1.26e-04, avg batch time: 0.2037, average loss: 4.6221
[09/27 23:58:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.05	top5: 5.91	
[09/27 23:58:17 visual_prompt]: Best epoch 2: best metric: 0.015
[09/27 23:58:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/27 23:58:26 visual_prompt]: Epoch 3 / 100: avg data time: 9.53e-02, avg batch time: 0.5228, average train loss: 4.5948
[09/27 23:58:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1761, average loss: 4.5584
[09/27 23:58:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/27 23:58:51 visual_prompt]: 	Test 100/157. loss: 4.602, 0.2039 s / batch. (data: 3.05e-05)max mem: 7.80626 GB 
[09/27 23:59:04 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2043, average loss: 4.6203
[09/27 23:59:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 0.86	top5: 5.59	
[09/27 23:59:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/27 23:59:13 visual_prompt]: Epoch 4 / 100: avg data time: 9.23e-02, avg batch time: 0.5199, average train loss: 4.5827
[09/27 23:59:16 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1727, average loss: 4.5338
[09/27 23:59:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 8.00	
[09/27 23:59:38 visual_prompt]: 	Test 100/157. loss: 4.615, 0.2060 s / batch. (data: 2.98e-05)max mem: 7.80626 GB 
[09/27 23:59:51 visual_prompt]: Inference (test):avg data time: 1.17e-04, avg batch time: 0.2042, average loss: 4.6335
[09/27 23:59:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.48	top5: 6.94	
[09/27 23:59:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/28 00:00:00 visual_prompt]: Epoch 5 / 100: avg data time: 8.92e-02, avg batch time: 0.5151, average train loss: 4.5647
[09/28 00:00:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 4.4989
[09/28 00:00:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 10.50	
[09/28 00:00:25 visual_prompt]: 	Test 100/157. loss: 4.575, 0.2036 s / batch. (data: 3.36e-05)max mem: 7.80626 GB 
[09/28 00:00:37 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2042, average loss: 4.6285
[09/28 00:00:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 2.20	top5: 6.71	
[09/28 00:00:37 visual_prompt]: Best epoch 5: best metric: 0.045
[09/28 00:00:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/28 00:00:47 visual_prompt]: Epoch 6 / 100: avg data time: 9.82e-02, avg batch time: 0.5264, average train loss: 4.4496
[09/28 00:00:50 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1857, average loss: 4.0452
[09/28 00:00:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 27.00	
[09/28 00:01:12 visual_prompt]: 	Test 100/157. loss: 4.241, 0.2047 s / batch. (data: 3.17e-05)max mem: 7.80626 GB 
[09/28 00:01:24 visual_prompt]: Inference (test):avg data time: 8.28e-05, avg batch time: 0.2040, average loss: 4.3438
[09/28 00:01:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 5.33	top5: 17.34	
[09/28 00:01:24 visual_prompt]: Best epoch 6: best metric: 0.100
[09/28 00:01:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/28 00:01:34 visual_prompt]: Epoch 7 / 100: avg data time: 1.02e-01, avg batch time: 0.5305, average train loss: 3.8330
[09/28 00:01:36 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1734, average loss: 2.8732
[09/28 00:01:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 29.50	top5: 62.00	
[09/28 00:01:59 visual_prompt]: 	Test 100/157. loss: 3.094, 0.2041 s / batch. (data: 3.17e-05)max mem: 7.80626 GB 
[09/28 00:02:11 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2041, average loss: 3.3865
[09/28 00:02:11 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 16.02	top5: 44.17	
[09/28 00:02:11 visual_prompt]: Best epoch 7: best metric: 0.295
[09/28 00:02:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/28 00:02:20 visual_prompt]: Epoch 8 / 100: avg data time: 8.80e-02, avg batch time: 0.5172, average train loss: 2.5950
[09/28 00:02:23 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1786, average loss: 1.7060
[09/28 00:02:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 85.00	
[09/28 00:02:45 visual_prompt]: 	Test 100/157. loss: 2.379, 0.2050 s / batch. (data: 3.00e-05)max mem: 7.80626 GB 
[09/28 00:02:58 visual_prompt]: Inference (test):avg data time: 1.57e-04, avg batch time: 0.2043, average loss: 2.4848
[09/28 00:02:58 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 37.30	top5: 70.32	
[09/28 00:02:58 visual_prompt]: Best epoch 8: best metric: 0.645
[09/28 00:02:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/28 00:03:07 visual_prompt]: Epoch 9 / 100: avg data time: 1.01e-01, avg batch time: 0.5290, average train loss: 1.3798
[09/28 00:03:10 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1731, average loss: 0.7154
[09/28 00:03:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 87.50	top5: 98.50	
[09/28 00:03:32 visual_prompt]: 	Test 100/157. loss: 1.571, 0.2049 s / batch. (data: 2.62e-05)max mem: 7.80626 GB 
[09/28 00:03:45 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2043, average loss: 1.6915
[09/28 00:03:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 55.88	top5: 85.15	
[09/28 00:03:45 visual_prompt]: Best epoch 9: best metric: 0.875
[09/28 00:03:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/28 00:03:54 visual_prompt]: Epoch 10 / 100: avg data time: 8.86e-02, avg batch time: 0.5148, average train loss: 0.6096
[09/28 00:03:57 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1823, average loss: 0.2674
[09/28 00:03:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:04:19 visual_prompt]: 	Test 100/157. loss: 1.186, 0.2040 s / batch. (data: 3.15e-05)max mem: 7.80626 GB 
[09/28 00:04:31 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2042, average loss: 1.3180
[09/28 00:04:31 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 65.76	top5: 91.44	
[09/28 00:04:31 visual_prompt]: Best epoch 10: best metric: 0.995
[09/28 00:04:31 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/28 00:04:41 visual_prompt]: Epoch 11 / 100: avg data time: 9.43e-02, avg batch time: 0.5233, average train loss: 0.2848
[09/28 00:04:44 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1856, average loss: 0.1399
[09/28 00:04:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:05:06 visual_prompt]: 	Test 100/157. loss: 0.916, 0.2040 s / batch. (data: 2.88e-05)max mem: 7.80626 GB 
[09/28 00:05:18 visual_prompt]: Inference (test):avg data time: 7.10e-05, avg batch time: 0.2040, average loss: 1.1423
[09/28 00:05:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.50	
[09/28 00:05:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/28 00:05:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e-01, avg batch time: 0.5312, average train loss: 0.1527
[09/28 00:05:30 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1858, average loss: 0.0884
[09/28 00:05:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:05:52 visual_prompt]: 	Test 100/157. loss: 1.000, 0.2048 s / batch. (data: 3.08e-05)max mem: 7.80626 GB 
[09/28 00:06:05 visual_prompt]: Inference (test):avg data time: 7.79e-05, avg batch time: 0.2042, average loss: 1.1132
[09/28 00:06:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.39	top5: 93.12	
[09/28 00:06:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/28 00:06:14 visual_prompt]: Epoch 13 / 100: avg data time: 9.63e-02, avg batch time: 0.5255, average train loss: 0.0968
[09/28 00:06:17 visual_prompt]: Inference (val):avg data time: 5.14e-05, avg batch time: 0.1813, average loss: 0.0675
[09/28 00:06:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:06:39 visual_prompt]: 	Test 100/157. loss: 0.899, 0.2045 s / batch. (data: 3.00e-05)max mem: 7.80626 GB 
[09/28 00:06:52 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2041, average loss: 1.0562
[09/28 00:06:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.23	top5: 93.77	
[09/28 00:06:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/28 00:07:01 visual_prompt]: Epoch 14 / 100: avg data time: 9.83e-02, avg batch time: 0.5248, average train loss: 0.0825
[09/28 00:07:04 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1796, average loss: 0.0563
[09/28 00:07:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:07:26 visual_prompt]: 	Test 100/157. loss: 0.900, 0.2040 s / batch. (data: 2.86e-05)max mem: 7.80626 GB 
[09/28 00:07:38 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2041, average loss: 1.0259
[09/28 00:07:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.58	top5: 94.25	
[09/28 00:07:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/28 00:07:48 visual_prompt]: Epoch 15 / 100: avg data time: 9.18e-02, avg batch time: 0.5179, average train loss: 0.0684
[09/28 00:07:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1845, average loss: 0.0466
[09/28 00:07:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:08:13 visual_prompt]: 	Test 100/157. loss: 0.898, 0.2045 s / batch. (data: 2.93e-05)max mem: 7.80626 GB 
[09/28 00:08:25 visual_prompt]: Inference (test):avg data time: 9.05e-05, avg batch time: 0.2043, average loss: 1.0209
[09/28 00:08:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.51	top5: 94.05	
[09/28 00:08:25 visual_prompt]: Best epoch 15: best metric: 1.000
[09/28 00:08:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/28 00:08:35 visual_prompt]: Epoch 16 / 100: avg data time: 1.01e-01, avg batch time: 0.5266, average train loss: 0.0649
[09/28 00:08:38 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1824, average loss: 0.0471
[09/28 00:08:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:09:00 visual_prompt]: 	Test 100/157. loss: 0.931, 0.2040 s / batch. (data: 3.34e-05)max mem: 7.80626 GB 
[09/28 00:09:12 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2039, average loss: 1.0376
[09/28 00:09:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.70	top5: 94.04	
[09/28 00:09:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/28 00:09:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e-01, avg batch time: 0.5306, average train loss: 0.0616
[09/28 00:09:25 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1829, average loss: 0.0452
[09/28 00:09:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:09:47 visual_prompt]: 	Test 100/157. loss: 0.922, 0.2039 s / batch. (data: 3.08e-05)max mem: 7.80626 GB 
[09/28 00:09:59 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2040, average loss: 1.0180
[09/28 00:09:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.28	top5: 94.42	
[09/28 00:09:59 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/28 00:10:09 visual_prompt]: Epoch 18 / 100: avg data time: 9.99e-02, avg batch time: 0.5265, average train loss: 0.0604
[09/28 00:10:11 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1763, average loss: 0.0441
[09/28 00:10:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:10:34 visual_prompt]: 	Test 100/157. loss: 0.894, 0.2035 s / batch. (data: 3.15e-05)max mem: 7.80626 GB 
[09/28 00:10:46 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2041, average loss: 1.0124
[09/28 00:10:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.63	top5: 94.47	
[09/28 00:10:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/28 00:10:55 visual_prompt]: Epoch 19 / 100: avg data time: 1.01e-01, avg batch time: 0.5266, average train loss: 0.0666
[09/28 00:10:58 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1838, average loss: 0.0558
[09/28 00:10:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:11:20 visual_prompt]: 	Test 100/157. loss: 0.936, 0.2058 s / batch. (data: 3.43e-05)max mem: 7.80626 GB 
[09/28 00:11:33 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2045, average loss: 1.0539
[09/28 00:11:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.48	top5: 94.31	
[09/28 00:11:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/28 00:11:42 visual_prompt]: Epoch 20 / 100: avg data time: 9.48e-02, avg batch time: 0.5221, average train loss: 0.0770
[09/28 00:11:45 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1757, average loss: 0.0509
[09/28 00:11:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:12:07 visual_prompt]: 	Test 100/157. loss: 0.849, 0.2045 s / batch. (data: 3.65e-05)max mem: 7.80626 GB 
[09/28 00:12:20 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2043, average loss: 1.0187
[09/28 00:12:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.73	top5: 94.35	
[09/28 00:12:20 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/28 00:12:29 visual_prompt]: Epoch 21 / 100: avg data time: 8.63e-02, avg batch time: 0.5127, average train loss: 0.0821
[09/28 00:12:32 visual_prompt]: Inference (val):avg data time: 5.57e-05, avg batch time: 0.1850, average loss: 0.0632
[09/28 00:12:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:12:54 visual_prompt]: 	Test 100/157. loss: 1.035, 0.2056 s / batch. (data: 3.19e-05)max mem: 7.80626 GB 
[09/28 00:13:06 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2043, average loss: 1.0371
[09/28 00:13:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.23	top5: 94.42	
[09/28 00:13:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/28 00:13:16 visual_prompt]: Epoch 22 / 100: avg data time: 9.55e-02, avg batch time: 0.5233, average train loss: 0.0820
[09/28 00:13:18 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1813, average loss: 0.0581
[09/28 00:13:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:13:41 visual_prompt]: 	Test 100/157. loss: 0.971, 0.2035 s / batch. (data: 3.53e-05)max mem: 7.80626 GB 
[09/28 00:13:53 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2040, average loss: 1.0097
[09/28 00:13:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.88	
[09/28 00:13:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/28 00:14:02 visual_prompt]: Epoch 23 / 100: avg data time: 9.59e-02, avg batch time: 0.5212, average train loss: 0.0756
[09/28 00:14:05 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1764, average loss: 0.0545
[09/28 00:14:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:14:27 visual_prompt]: 	Test 100/157. loss: 0.986, 0.2041 s / batch. (data: 2.98e-05)max mem: 7.80626 GB 
[09/28 00:14:40 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2043, average loss: 1.0176
[09/28 00:14:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.79	top5: 94.55	
[09/28 00:14:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/28 00:14:49 visual_prompt]: Epoch 24 / 100: avg data time: 1.02e-01, avg batch time: 0.5290, average train loss: 0.0864
[09/28 00:14:52 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1726, average loss: 0.0603
[09/28 00:14:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:15:14 visual_prompt]: 	Test 100/157. loss: 0.915, 0.2045 s / batch. (data: 3.70e-05)max mem: 7.80626 GB 
[09/28 00:15:27 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2050, average loss: 1.0031
[09/28 00:15:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.62	top5: 94.82	
[09/28 00:15:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/28 00:15:36 visual_prompt]: Epoch 25 / 100: avg data time: 9.47e-02, avg batch time: 0.5220, average train loss: 0.0955
[09/28 00:15:39 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1754, average loss: 0.1705
[09/28 00:15:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:16:01 visual_prompt]: 	Test 100/157. loss: 1.082, 0.2040 s / batch. (data: 3.89e-05)max mem: 7.80626 GB 
[09/28 00:16:14 visual_prompt]: Inference (test):avg data time: 1.50e-04, avg batch time: 0.2041, average loss: 1.1709
[09/28 00:16:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.19	top5: 92.91	
[09/28 00:16:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/28 00:16:23 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e-01, avg batch time: 0.5311, average train loss: 0.1404
[09/28 00:16:26 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1859, average loss: 0.0834
[09/28 00:16:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:16:48 visual_prompt]: 	Test 100/157. loss: 0.961, 0.2048 s / batch. (data: 3.27e-05)max mem: 7.80626 GB 
[09/28 00:17:01 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2042, average loss: 1.0469
[09/28 00:17:01 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.06	top5: 94.63	
[09/28 00:17:01 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/28 00:17:10 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e-01, avg batch time: 0.5304, average train loss: 0.1067
[09/28 00:17:13 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1787, average loss: 0.0859
[09/28 00:17:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:17:35 visual_prompt]: 	Test 100/157. loss: 1.110, 0.2042 s / batch. (data: 3.03e-05)max mem: 7.80626 GB 
[09/28 00:17:48 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2040, average loss: 1.0879
[09/28 00:17:48 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.61	top5: 93.80	
[09/28 00:17:48 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/28 00:17:57 visual_prompt]: Epoch 28 / 100: avg data time: 1.02e-01, avg batch time: 0.5280, average train loss: 0.0841
[09/28 00:18:00 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1735, average loss: 0.0601
[09/28 00:18:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:18:22 visual_prompt]: 	Test 100/157. loss: 0.962, 0.2052 s / batch. (data: 3.10e-05)max mem: 7.80626 GB 
[09/28 00:18:34 visual_prompt]: Inference (test):avg data time: 1.12e-04, avg batch time: 0.2042, average loss: 0.9889
[09/28 00:18:35 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.11	top5: 95.03	
[09/28 00:18:35 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/28 00:18:44 visual_prompt]: Epoch 29 / 100: avg data time: 8.67e-02, avg batch time: 0.5150, average train loss: 0.0896
[09/28 00:18:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1755, average loss: 0.0527
[09/28 00:18:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:19:09 visual_prompt]: 	Test 100/157. loss: 0.851, 0.2049 s / batch. (data: 5.44e-05)max mem: 7.80626 GB 
[09/28 00:19:21 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2042, average loss: 0.9432
[09/28 00:19:21 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.57	top5: 95.09	
[09/28 00:19:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/28 00:19:30 visual_prompt]: Epoch 30 / 100: avg data time: 9.27e-02, avg batch time: 0.5204, average train loss: 0.0617
[09/28 00:19:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1750, average loss: 0.0439
[09/28 00:19:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:19:55 visual_prompt]: 	Test 100/157. loss: 0.943, 0.2048 s / batch. (data: 3.22e-05)max mem: 7.80626 GB 
[09/28 00:20:08 visual_prompt]: Inference (test):avg data time: 2.16e-04, avg batch time: 0.2042, average loss: 0.9610
[09/28 00:20:08 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.50	top5: 95.15	
[09/28 00:20:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/28 00:20:17 visual_prompt]: Epoch 31 / 100: avg data time: 8.69e-02, avg batch time: 0.5141, average train loss: 0.0457
[09/28 00:20:20 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1756, average loss: 0.0320
[09/28 00:20:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:20:42 visual_prompt]: 	Test 100/157. loss: 0.820, 0.2042 s / batch. (data: 2.84e-05)max mem: 7.80626 GB 
[09/28 00:20:55 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2043, average loss: 0.8910
[09/28 00:20:55 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.14	top5: 95.60	
[09/28 00:20:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/28 00:21:04 visual_prompt]: Epoch 32 / 100: avg data time: 1.04e-01, avg batch time: 0.5304, average train loss: 0.0395
[09/28 00:21:07 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1770, average loss: 0.0299
[09/28 00:21:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:21:29 visual_prompt]: 	Test 100/157. loss: 0.832, 0.2038 s / batch. (data: 3.15e-05)max mem: 7.80626 GB 
[09/28 00:21:42 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2041, average loss: 0.8994
[09/28 00:21:42 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.04	top5: 95.63	
[09/28 00:21:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/28 00:21:51 visual_prompt]: Epoch 33 / 100: avg data time: 9.27e-02, avg batch time: 0.5196, average train loss: 0.0379
[09/28 00:21:54 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1794, average loss: 0.0329
[09/28 00:21:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:22:16 visual_prompt]: 	Test 100/157. loss: 0.839, 0.2044 s / batch. (data: 3.43e-05)max mem: 7.80626 GB 
[09/28 00:22:28 visual_prompt]: Inference (test):avg data time: 1.48e-04, avg batch time: 0.2043, average loss: 0.9122
[09/28 00:22:29 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.01	top5: 95.49	
[09/28 00:22:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/28 00:22:38 visual_prompt]: Epoch 34 / 100: avg data time: 9.94e-02, avg batch time: 0.5272, average train loss: 0.0385
[09/28 00:22:41 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1828, average loss: 0.0308
[09/28 00:22:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:23:03 visual_prompt]: 	Test 100/157. loss: 0.873, 0.2060 s / batch. (data: 3.00e-05)max mem: 7.80626 GB 
[09/28 00:23:15 visual_prompt]: Inference (test):avg data time: 1.03e-04, avg batch time: 0.2040, average loss: 0.9288
[09/28 00:23:16 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.81	top5: 95.13	
[09/28 00:23:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/28 00:23:25 visual_prompt]: Epoch 35 / 100: avg data time: 9.56e-02, avg batch time: 0.5235, average train loss: 0.0388
[09/28 00:23:28 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1769, average loss: 0.0288
[09/28 00:23:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:23:50 visual_prompt]: 	Test 100/157. loss: 0.884, 0.2037 s / batch. (data: 3.24e-05)max mem: 7.80626 GB 
[09/28 00:24:02 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2041, average loss: 0.9151
[09/28 00:24:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.13	top5: 95.50	
[09/28 00:24:02 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/28 00:24:11 visual_prompt]: Epoch 36 / 100: avg data time: 9.42e-02, avg batch time: 0.5199, average train loss: 0.0375
[09/28 00:24:14 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1860, average loss: 0.0293
[09/28 00:24:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:24:36 visual_prompt]: 	Test 100/157. loss: 0.852, 0.2066 s / batch. (data: 3.29e-05)max mem: 7.80626 GB 
[09/28 00:24:49 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2043, average loss: 0.9315
[09/28 00:24:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.71	top5: 95.23	
[09/28 00:24:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/28 00:24:58 visual_prompt]: Epoch 37 / 100: avg data time: 8.96e-02, avg batch time: 0.5162, average train loss: 0.0362
[09/28 00:25:01 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.1813, average loss: 0.0284
[09/28 00:25:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:25:23 visual_prompt]: 	Test 100/157. loss: 0.877, 0.2050 s / batch. (data: 2.50e-05)max mem: 7.80626 GB 
[09/28 00:25:35 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2042, average loss: 0.9459
[09/28 00:25:36 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.35	top5: 95.35	
[09/28 00:25:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/28 00:25:45 visual_prompt]: Epoch 38 / 100: avg data time: 9.87e-02, avg batch time: 0.5244, average train loss: 0.0348
[09/28 00:25:48 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1823, average loss: 0.0291
[09/28 00:25:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:26:10 visual_prompt]: 	Test 100/157. loss: 0.863, 0.2038 s / batch. (data: 3.03e-05)max mem: 7.80626 GB 
[09/28 00:26:22 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2043, average loss: 0.9645
[09/28 00:26:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.12	top5: 94.97	
[09/28 00:26:22 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/28 00:26:31 visual_prompt]: Epoch 39 / 100: avg data time: 8.46e-02, avg batch time: 0.5143, average train loss: 0.0374
[09/28 00:26:34 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1762, average loss: 0.0483
[09/28 00:26:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 00:26:57 visual_prompt]: 	Test 100/157. loss: 1.030, 0.2043 s / batch. (data: 3.15e-05)max mem: 7.80626 GB 
[09/28 00:27:09 visual_prompt]: Inference (test):avg data time: 8.91e-05, avg batch time: 0.2045, average loss: 1.0312
[09/28 00:27:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.13	top5: 94.64	
[09/28 00:27:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/28 00:27:18 visual_prompt]: Epoch 40 / 100: avg data time: 9.41e-02, avg batch time: 0.5217, average train loss: 0.2208
[09/28 00:27:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1748, average loss: 0.5963
[09/28 00:27:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 89.00	top5: 99.00	
[09/28 00:27:43 visual_prompt]: 	Test 100/157. loss: 1.533, 0.2048 s / batch. (data: 3.03e-05)max mem: 7.80626 GB 
[09/28 00:27:56 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2048, average loss: 1.6199
[09/28 00:27:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 63.14	top5: 89.42	
[09/28 00:27:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/28 00:28:05 visual_prompt]: Epoch 41 / 100: avg data time: 8.08e-02, avg batch time: 0.5114, average train loss: 0.5410
[09/28 00:28:08 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.1726, average loss: 0.3591
[09/28 00:28:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 96.00	top5: 99.50	
[09/28 00:28:30 visual_prompt]: 	Test 100/157. loss: 1.173, 0.2053 s / batch. (data: 2.84e-05)max mem: 7.80626 GB 
[09/28 00:28:43 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2046, average loss: 1.1572
[09/28 00:28:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.92	top5: 94.16	
[09/28 00:28:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/28 00:28:52 visual_prompt]: Epoch 42 / 100: avg data time: 9.84e-02, avg batch time: 0.5248, average train loss: 0.2406
[09/28 00:28:55 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1782, average loss: 0.0904
[09/28 00:28:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:29:17 visual_prompt]: 	Test 100/157. loss: 0.759, 0.2051 s / batch. (data: 2.91e-05)max mem: 7.80626 GB 
[09/28 00:29:30 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2043, average loss: 0.8954
[09/28 00:29:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.63	top5: 95.35	
[09/28 00:29:30 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/28 00:29:39 visual_prompt]: Epoch 43 / 100: avg data time: 9.84e-02, avg batch time: 0.5249, average train loss: 0.1104
[09/28 00:29:42 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1811, average loss: 0.0478
[09/28 00:29:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:30:04 visual_prompt]: 	Test 100/157. loss: 0.782, 0.2042 s / batch. (data: 2.98e-05)max mem: 7.80626 GB 
[09/28 00:30:16 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2046, average loss: 0.8593
[09/28 00:30:16 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.36	top5: 95.65	
[09/28 00:30:16 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/28 00:30:26 visual_prompt]: Epoch 44 / 100: avg data time: 1.02e-01, avg batch time: 0.5281, average train loss: 0.0568
[09/28 00:30:29 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1796, average loss: 0.0351
[09/28 00:30:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:30:51 visual_prompt]: 	Test 100/157. loss: 0.796, 0.2056 s / batch. (data: 3.17e-05)max mem: 7.80626 GB 
[09/28 00:31:03 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2043, average loss: 0.8033
[09/28 00:31:03 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.65	top5: 95.92	
[09/28 00:31:03 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/28 00:31:13 visual_prompt]: Epoch 45 / 100: avg data time: 9.39e-02, avg batch time: 0.5223, average train loss: 0.0404
[09/28 00:31:15 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1737, average loss: 0.0289
[09/28 00:31:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:31:38 visual_prompt]: 	Test 100/157. loss: 0.755, 0.2046 s / batch. (data: 2.60e-05)max mem: 7.80626 GB 
[09/28 00:31:50 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2042, average loss: 0.7995
[09/28 00:31:50 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.51	top5: 96.24	
[09/28 00:31:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/28 00:32:00 visual_prompt]: Epoch 46 / 100: avg data time: 1.00e-01, avg batch time: 0.5287, average train loss: 0.0351
[09/28 00:32:02 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1816, average loss: 0.0278
[09/28 00:32:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:32:24 visual_prompt]: 	Test 100/157. loss: 0.750, 0.2048 s / batch. (data: 3.22e-05)max mem: 7.80626 GB 
[09/28 00:32:37 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2044, average loss: 0.8035
[09/28 00:32:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.31	top5: 96.16	
[09/28 00:32:37 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/28 00:32:46 visual_prompt]: Epoch 47 / 100: avg data time: 8.63e-02, avg batch time: 0.5139, average train loss: 0.0341
[09/28 00:32:49 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1750, average loss: 0.0282
[09/28 00:32:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:33:11 visual_prompt]: 	Test 100/157. loss: 0.776, 0.2057 s / batch. (data: 3.19e-05)max mem: 7.80626 GB 
[09/28 00:33:24 visual_prompt]: Inference (test):avg data time: 2.48e-04, avg batch time: 0.2044, average loss: 0.8123
[09/28 00:33:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.22	top5: 96.18	
[09/28 00:33:24 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/28 00:33:33 visual_prompt]: Epoch 48 / 100: avg data time: 9.39e-02, avg batch time: 0.5224, average train loss: 0.0343
[09/28 00:33:36 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1759, average loss: 0.0281
[09/28 00:33:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:33:58 visual_prompt]: 	Test 100/157. loss: 0.768, 0.2051 s / batch. (data: 2.93e-05)max mem: 7.80626 GB 
[09/28 00:34:10 visual_prompt]: Inference (test):avg data time: 2.04e-04, avg batch time: 0.2045, average loss: 0.8271
[09/28 00:34:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.94	top5: 96.05	
[09/28 00:34:10 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/28 00:34:20 visual_prompt]: Epoch 49 / 100: avg data time: 9.93e-02, avg batch time: 0.5263, average train loss: 0.0349
[09/28 00:34:23 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1838, average loss: 0.0280
[09/28 00:34:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:34:45 visual_prompt]: 	Test 100/157. loss: 0.785, 0.2041 s / batch. (data: 3.05e-05)max mem: 7.80626 GB 
[09/28 00:34:57 visual_prompt]: Inference (test):avg data time: 1.61e-04, avg batch time: 0.2044, average loss: 0.8437
[09/28 00:34:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.58	top5: 96.01	
[09/28 00:34:57 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/28 00:35:07 visual_prompt]: Epoch 50 / 100: avg data time: 9.33e-02, avg batch time: 0.5205, average train loss: 0.0347
[09/28 00:35:10 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1835, average loss: 0.0285
[09/28 00:35:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:35:32 visual_prompt]: 	Test 100/157. loss: 0.771, 0.2044 s / batch. (data: 3.79e-05)max mem: 7.80626 GB 
[09/28 00:35:44 visual_prompt]: Inference (test):avg data time: 1.20e-04, avg batch time: 0.2044, average loss: 0.8420
[09/28 00:35:44 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.69	top5: 96.00	
[09/28 00:35:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/28 00:35:54 visual_prompt]: Epoch 51 / 100: avg data time: 9.65e-02, avg batch time: 0.5252, average train loss: 0.0346
[09/28 00:35:56 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1784, average loss: 0.0290
[09/28 00:35:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:36:19 visual_prompt]: 	Test 100/157. loss: 0.766, 0.2045 s / batch. (data: 3.46e-05)max mem: 7.80626 GB 
[09/28 00:36:31 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2043, average loss: 0.8544
[09/28 00:36:31 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.43	top5: 95.99	
[09/28 00:36:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/28 00:36:40 visual_prompt]: Epoch 52 / 100: avg data time: 9.68e-02, avg batch time: 0.5241, average train loss: 0.0354
[09/28 00:36:43 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1785, average loss: 0.0292
[09/28 00:36:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:37:06 visual_prompt]: 	Test 100/157. loss: 0.795, 0.2046 s / batch. (data: 3.10e-05)max mem: 7.80626 GB 
[09/28 00:37:18 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2041, average loss: 0.8753
[09/28 00:37:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.08	top5: 95.75	
[09/28 00:37:18 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/28 00:37:27 visual_prompt]: Epoch 53 / 100: avg data time: 9.42e-02, avg batch time: 0.5200, average train loss: 0.0349
[09/28 00:37:30 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1733, average loss: 0.0299
[09/28 00:37:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:37:52 visual_prompt]: 	Test 100/157. loss: 0.798, 0.2043 s / batch. (data: 3.19e-05)max mem: 7.80626 GB 
[09/28 00:38:05 visual_prompt]: Inference (test):avg data time: 1.35e-04, avg batch time: 0.2043, average loss: 0.8839
[09/28 00:38:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.07	top5: 95.95	
[09/28 00:38:05 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/28 00:38:14 visual_prompt]: Epoch 54 / 100: avg data time: 9.76e-02, avg batch time: 0.5253, average train loss: 0.0355
[09/28 00:38:17 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1761, average loss: 0.0310
[09/28 00:38:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:38:39 visual_prompt]: 	Test 100/157. loss: 0.784, 0.2052 s / batch. (data: 8.58e-05)max mem: 7.80626 GB 
[09/28 00:38:52 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2039, average loss: 0.8929
[09/28 00:38:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.78	top5: 95.82	
[09/28 00:38:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/28 00:39:01 visual_prompt]: Epoch 55 / 100: avg data time: 9.37e-02, avg batch time: 0.5244, average train loss: 0.0354
[09/28 00:39:04 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1732, average loss: 0.0290
[09/28 00:39:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:39:26 visual_prompt]: 	Test 100/157. loss: 0.777, 0.2044 s / batch. (data: 4.20e-05)max mem: 7.80626 GB 
[09/28 00:39:38 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2043, average loss: 0.8980
[09/28 00:39:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.71	top5: 95.75	
[09/28 00:39:39 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/28 00:39:48 visual_prompt]: Epoch 56 / 100: avg data time: 1.03e-01, avg batch time: 0.5295, average train loss: 0.0348
[09/28 00:39:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1837, average loss: 0.0281
[09/28 00:39:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:40:13 visual_prompt]: 	Test 100/157. loss: 0.816, 0.2054 s / batch. (data: 3.08e-05)max mem: 7.80626 GB 
[09/28 00:40:25 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2040, average loss: 0.9043
[09/28 00:40:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.61	top5: 95.85	
[09/28 00:40:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/28 00:40:35 visual_prompt]: Epoch 57 / 100: avg data time: 8.69e-02, avg batch time: 0.5119, average train loss: 0.0346
[09/28 00:40:37 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1732, average loss: 0.0317
[09/28 00:40:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:40:59 visual_prompt]: 	Test 100/157. loss: 0.765, 0.2041 s / batch. (data: 2.96e-05)max mem: 7.80626 GB 
[09/28 00:41:12 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2043, average loss: 0.9225
[09/28 00:41:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.80	top5: 95.52	
[09/28 00:41:12 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/28 00:41:21 visual_prompt]: Epoch 58 / 100: avg data time: 9.64e-02, avg batch time: 0.5235, average train loss: 0.0355
[09/28 00:41:24 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1794, average loss: 0.0291
[09/28 00:41:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:41:46 visual_prompt]: 	Test 100/157. loss: 0.825, 0.2054 s / batch. (data: 3.00e-05)max mem: 7.80626 GB 
[09/28 00:41:59 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2045, average loss: 0.9095
[09/28 00:41:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.54	top5: 95.70	
[09/28 00:41:59 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/28 00:42:08 visual_prompt]: Epoch 59 / 100: avg data time: 9.33e-02, avg batch time: 0.5215, average train loss: 0.0340
[09/28 00:42:11 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1849, average loss: 0.0290
[09/28 00:42:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:42:33 visual_prompt]: 	Test 100/157. loss: 0.855, 0.2055 s / batch. (data: 2.96e-05)max mem: 7.80626 GB 
[09/28 00:42:46 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2039, average loss: 0.9241
[09/28 00:42:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.26	top5: 95.53	
[09/28 00:42:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/28 00:42:55 visual_prompt]: Epoch 60 / 100: avg data time: 1.01e-01, avg batch time: 0.5280, average train loss: 0.0337
[09/28 00:42:58 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1858, average loss: 0.0282
[09/28 00:42:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:43:20 visual_prompt]: 	Test 100/157. loss: 0.834, 0.2061 s / batch. (data: 3.89e-05)max mem: 7.80626 GB 
[09/28 00:43:33 visual_prompt]: Inference (test):avg data time: 1.58e-04, avg batch time: 0.2043, average loss: 0.9252
[09/28 00:43:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.91	top5: 95.73	
[09/28 00:43:33 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/28 00:43:42 visual_prompt]: Epoch 61 / 100: avg data time: 8.33e-02, avg batch time: 0.5131, average train loss: 0.0325
[09/28 00:43:45 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1804, average loss: 0.0270
[09/28 00:43:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:44:07 visual_prompt]: 	Test 100/157. loss: 0.860, 0.2052 s / batch. (data: 2.96e-05)max mem: 7.80626 GB 
[09/28 00:44:19 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2043, average loss: 0.9384
[09/28 00:44:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.73	top5: 95.68	
[09/28 00:44:19 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/28 00:44:29 visual_prompt]: Epoch 62 / 100: avg data time: 9.55e-02, avg batch time: 0.5220, average train loss: 0.0318
[09/28 00:44:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1833, average loss: 0.0269
[09/28 00:44:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:44:54 visual_prompt]: 	Test 100/157. loss: 0.875, 0.2046 s / batch. (data: 2.81e-05)max mem: 7.80626 GB 
[09/28 00:45:06 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2041, average loss: 0.9489
[09/28 00:45:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.54	top5: 95.61	
[09/28 00:45:06 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/28 00:45:16 visual_prompt]: Epoch 63 / 100: avg data time: 9.98e-02, avg batch time: 0.5254, average train loss: 0.0337
[09/28 00:45:18 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1785, average loss: 0.0289
[09/28 00:45:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:45:40 visual_prompt]: 	Test 100/157. loss: 0.904, 0.2064 s / batch. (data: 3.05e-05)max mem: 7.80626 GB 
[09/28 00:45:53 visual_prompt]: Inference (test):avg data time: 5.83e-05, avg batch time: 0.2045, average loss: 0.9563
[09/28 00:45:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.29	top5: 95.55	
[09/28 00:45:53 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/28 00:46:02 visual_prompt]: Epoch 64 / 100: avg data time: 1.05e-01, avg batch time: 0.5341, average train loss: 0.0355
[09/28 00:46:05 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1845, average loss: 0.0325
[09/28 00:46:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:46:27 visual_prompt]: 	Test 100/157. loss: 0.880, 0.2060 s / batch. (data: 2.77e-05)max mem: 7.80626 GB 
[09/28 00:46:40 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2043, average loss: 0.9690
[09/28 00:46:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.54	top5: 95.17	
[09/28 00:46:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/28 00:46:49 visual_prompt]: Epoch 65 / 100: avg data time: 9.94e-02, avg batch time: 0.5254, average train loss: 0.0397
[09/28 00:46:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1761, average loss: 0.0337
[09/28 00:46:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:47:14 visual_prompt]: 	Test 100/157. loss: 0.859, 0.2057 s / batch. (data: 2.57e-05)max mem: 7.80626 GB 
[09/28 00:47:27 visual_prompt]: Inference (test):avg data time: 1.81e-04, avg batch time: 0.2041, average loss: 0.9445
[09/28 00:47:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.89	top5: 95.51	
[09/28 00:47:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/28 00:47:36 visual_prompt]: Epoch 66 / 100: avg data time: 9.55e-02, avg batch time: 0.5206, average train loss: 0.0373
[09/28 00:47:39 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1782, average loss: 0.0325
[09/28 00:47:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:48:01 visual_prompt]: 	Test 100/157. loss: 0.796, 0.2038 s / batch. (data: 3.19e-05)max mem: 7.80626 GB 
[09/28 00:48:14 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2040, average loss: 0.9571
[09/28 00:48:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.66	top5: 95.72	
[09/28 00:48:14 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/28 00:48:23 visual_prompt]: Epoch 67 / 100: avg data time: 9.25e-02, avg batch time: 0.5205, average train loss: 0.0351
[09/28 00:48:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1857, average loss: 0.0293
[09/28 00:48:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:48:48 visual_prompt]: 	Test 100/157. loss: 0.838, 0.2035 s / batch. (data: 3.08e-05)max mem: 7.80626 GB 
[09/28 00:49:01 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2040, average loss: 0.9394
[09/28 00:49:01 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.19	top5: 95.68	
[09/28 00:49:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/28 00:49:10 visual_prompt]: Epoch 68 / 100: avg data time: 9.47e-02, avg batch time: 0.5221, average train loss: 0.0356
[09/28 00:49:13 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1793, average loss: 0.0350
[09/28 00:49:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:49:35 visual_prompt]: 	Test 100/157. loss: 0.807, 0.2043 s / batch. (data: 3.50e-05)max mem: 7.80626 GB 
[09/28 00:49:47 visual_prompt]: Inference (test):avg data time: 1.62e-04, avg batch time: 0.2043, average loss: 0.9891
[09/28 00:49:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.77	top5: 95.14	
[09/28 00:49:47 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/28 00:49:57 visual_prompt]: Epoch 69 / 100: avg data time: 9.22e-02, avg batch time: 0.5203, average train loss: 0.0376
[09/28 00:50:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1840, average loss: 0.0306
[09/28 00:50:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:50:22 visual_prompt]: 	Test 100/157. loss: 0.872, 0.2043 s / batch. (data: 2.98e-05)max mem: 7.80626 GB 
[09/28 00:50:34 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2040, average loss: 0.9632
[09/28 00:50:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.85	top5: 95.57	
[09/28 00:50:34 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/28 00:50:44 visual_prompt]: Epoch 70 / 100: avg data time: 9.62e-02, avg batch time: 0.5240, average train loss: 0.0558
[09/28 00:50:47 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1855, average loss: 0.2580
[09/28 00:50:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 95.00	top5: 99.00	
[09/28 00:51:09 visual_prompt]: 	Test 100/157. loss: 0.969, 0.2050 s / batch. (data: 2.81e-05)max mem: 7.80626 GB 
[09/28 00:51:21 visual_prompt]: Inference (test):avg data time: 1.35e-04, avg batch time: 0.2046, average loss: 1.1916
[09/28 00:51:21 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.52	top5: 93.44	
[09/28 00:51:21 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/28 00:51:30 visual_prompt]: Epoch 71 / 100: avg data time: 8.22e-02, avg batch time: 0.5093, average train loss: 0.2598
[09/28 00:51:33 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1856, average loss: 0.2230
[09/28 00:51:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.50	top5: 100.00	
[09/28 00:51:55 visual_prompt]: 	Test 100/157. loss: 1.091, 0.2058 s / batch. (data: 3.41e-05)max mem: 7.80626 GB 
[09/28 00:52:08 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2043, average loss: 1.1504
[09/28 00:52:08 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.47	top5: 94.71	
[09/28 00:52:08 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/28 00:52:17 visual_prompt]: Epoch 72 / 100: avg data time: 9.57e-02, avg batch time: 0.5215, average train loss: 0.2196
[09/28 00:52:20 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1837, average loss: 0.1431
[09/28 00:52:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:52:42 visual_prompt]: 	Test 100/157. loss: 0.921, 0.2050 s / batch. (data: 3.12e-05)max mem: 7.80626 GB 
[09/28 00:52:54 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2044, average loss: 0.9913
[09/28 00:52:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.98	top5: 95.72	
[09/28 00:52:54 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/28 00:53:04 visual_prompt]: Epoch 73 / 100: avg data time: 9.67e-02, avg batch time: 0.5235, average train loss: 0.1268
[09/28 00:53:07 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1818, average loss: 0.0750
[09/28 00:53:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:53:29 visual_prompt]: 	Test 100/157. loss: 0.932, 0.2050 s / batch. (data: 2.67e-05)max mem: 7.80626 GB 
[09/28 00:53:41 visual_prompt]: Inference (test):avg data time: 1.50e-04, avg batch time: 0.2041, average loss: 0.9429
[09/28 00:53:41 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.44	top5: 95.73	
[09/28 00:53:41 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/28 00:53:51 visual_prompt]: Epoch 74 / 100: avg data time: 1.00e-01, avg batch time: 0.5262, average train loss: 0.0745
[09/28 00:53:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1828, average loss: 0.0479
[09/28 00:53:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:54:15 visual_prompt]: 	Test 100/157. loss: 0.836, 0.2050 s / batch. (data: 2.69e-05)max mem: 7.80626 GB 
[09/28 00:54:28 visual_prompt]: Inference (test):avg data time: 1.15e-04, avg batch time: 0.2043, average loss: 0.8887
[09/28 00:54:28 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.31	top5: 96.05	
[09/28 00:54:28 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/28 00:54:37 visual_prompt]: Epoch 75 / 100: avg data time: 8.91e-02, avg batch time: 0.5165, average train loss: 0.0500
[09/28 00:54:40 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1786, average loss: 0.0378
[09/28 00:54:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:55:02 visual_prompt]: 	Test 100/157. loss: 0.798, 0.2057 s / batch. (data: 2.88e-05)max mem: 7.80626 GB 
[09/28 00:55:15 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2043, average loss: 0.8604
[09/28 00:55:15 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.81	top5: 96.22	
[09/28 00:55:15 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/28 00:55:24 visual_prompt]: Epoch 76 / 100: avg data time: 9.06e-02, avg batch time: 0.5195, average train loss: 0.0412
[09/28 00:55:27 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1757, average loss: 0.0316
[09/28 00:55:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:55:49 visual_prompt]: 	Test 100/157. loss: 0.820, 0.2041 s / batch. (data: 3.12e-05)max mem: 7.80626 GB 
[09/28 00:56:01 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2043, average loss: 0.8530
[09/28 00:56:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.94	top5: 96.12	
[09/28 00:56:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/28 00:56:11 visual_prompt]: Epoch 77 / 100: avg data time: 8.69e-02, avg batch time: 0.5163, average train loss: 0.0350
[09/28 00:56:14 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1844, average loss: 0.0284
[09/28 00:56:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:56:36 visual_prompt]: 	Test 100/157. loss: 0.827, 0.2047 s / batch. (data: 3.29e-05)max mem: 7.80626 GB 
[09/28 00:56:48 visual_prompt]: Inference (test):avg data time: 5.21e-05, avg batch time: 0.2041, average loss: 0.8552
[09/28 00:56:48 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.04	top5: 96.08	
[09/28 00:56:48 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/28 00:56:57 visual_prompt]: Epoch 78 / 100: avg data time: 9.24e-02, avg batch time: 0.5178, average train loss: 0.0322
[09/28 00:57:00 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1850, average loss: 0.0273
[09/28 00:57:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:57:22 visual_prompt]: 	Test 100/157. loss: 0.820, 0.2043 s / batch. (data: 3.27e-05)max mem: 7.80626 GB 
[09/28 00:57:35 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2043, average loss: 0.8627
[09/28 00:57:35 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.98	top5: 95.90	
[09/28 00:57:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/28 00:57:44 visual_prompt]: Epoch 79 / 100: avg data time: 9.64e-02, avg batch time: 0.5236, average train loss: 0.0308
[09/28 00:57:47 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1825, average loss: 0.0268
[09/28 00:57:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:58:09 visual_prompt]: 	Test 100/157. loss: 0.831, 0.2037 s / batch. (data: 2.98e-05)max mem: 7.80626 GB 
[09/28 00:58:22 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2043, average loss: 0.8662
[09/28 00:58:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.74	top5: 95.95	
[09/28 00:58:22 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/28 00:58:31 visual_prompt]: Epoch 80 / 100: avg data time: 9.93e-02, avg batch time: 0.5278, average train loss: 0.0300
[09/28 00:58:34 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1763, average loss: 0.0260
[09/28 00:58:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:58:56 visual_prompt]: 	Test 100/157. loss: 0.824, 0.2043 s / batch. (data: 3.10e-05)max mem: 7.80626 GB 
[09/28 00:59:09 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2043, average loss: 0.8708
[09/28 00:59:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.53	top5: 95.93	
[09/28 00:59:09 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/28 00:59:18 visual_prompt]: Epoch 81 / 100: avg data time: 9.82e-02, avg batch time: 0.5253, average train loss: 0.0293
[09/28 00:59:21 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1730, average loss: 0.0257
[09/28 00:59:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 00:59:43 visual_prompt]: 	Test 100/157. loss: 0.817, 0.2031 s / batch. (data: 3.03e-05)max mem: 7.80626 GB 
[09/28 00:59:56 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2043, average loss: 0.8734
[09/28 00:59:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.93	
[09/28 00:59:56 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/28 01:00:05 visual_prompt]: Epoch 82 / 100: avg data time: 9.85e-02, avg batch time: 0.5265, average train loss: 0.0288
[09/28 01:00:08 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1837, average loss: 0.0253
[09/28 01:00:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:00:30 visual_prompt]: 	Test 100/157. loss: 0.814, 0.2058 s / batch. (data: 3.29e-05)max mem: 7.80626 GB 
[09/28 01:00:43 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2043, average loss: 0.8762
[09/28 01:00:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.40	top5: 95.95	
[09/28 01:00:43 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/28 01:00:52 visual_prompt]: Epoch 83 / 100: avg data time: 8.93e-02, avg batch time: 0.5153, average train loss: 0.0286
[09/28 01:00:55 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1744, average loss: 0.0251
[09/28 01:00:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:01:17 visual_prompt]: 	Test 100/157. loss: 0.811, 0.2050 s / batch. (data: 2.98e-05)max mem: 7.80626 GB 
[09/28 01:01:30 visual_prompt]: Inference (test):avg data time: 1.42e-04, avg batch time: 0.2042, average loss: 0.8800
[09/28 01:01:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.22	top5: 95.93	
[09/28 01:01:30 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/28 01:01:39 visual_prompt]: Epoch 84 / 100: avg data time: 1.00e-01, avg batch time: 0.5269, average train loss: 0.0285
[09/28 01:01:42 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1830, average loss: 0.0249
[09/28 01:01:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:02:04 visual_prompt]: 	Test 100/157. loss: 0.810, 0.2060 s / batch. (data: 2.79e-05)max mem: 7.80626 GB 
[09/28 01:02:17 visual_prompt]: Inference (test):avg data time: 2.27e-04, avg batch time: 0.2047, average loss: 0.8845
[09/28 01:02:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.10	top5: 95.96	
[09/28 01:02:17 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/28 01:02:26 visual_prompt]: Epoch 85 / 100: avg data time: 8.69e-02, avg batch time: 0.5151, average train loss: 0.0280
[09/28 01:02:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1770, average loss: 0.0247
[09/28 01:02:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:02:51 visual_prompt]: 	Test 100/157. loss: 0.818, 0.2042 s / batch. (data: 2.96e-05)max mem: 7.80626 GB 
[09/28 01:03:03 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2042, average loss: 0.8867
[09/28 01:03:03 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.21	top5: 95.93	
[09/28 01:03:03 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/28 01:03:12 visual_prompt]: Epoch 86 / 100: avg data time: 9.19e-02, avg batch time: 0.5181, average train loss: 0.0282
[09/28 01:03:15 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1805, average loss: 0.0246
[09/28 01:03:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:03:38 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2047 s / batch. (data: 3.12e-05)max mem: 7.80626 GB 
[09/28 01:03:50 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2045, average loss: 0.8884
[09/28 01:03:50 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.21	top5: 95.94	
[09/28 01:03:50 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/28 01:03:59 visual_prompt]: Epoch 87 / 100: avg data time: 8.93e-02, avg batch time: 0.5170, average train loss: 0.0279
[09/28 01:04:02 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1774, average loss: 0.0245
[09/28 01:04:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:04:24 visual_prompt]: 	Test 100/157. loss: 0.830, 0.2056 s / batch. (data: 3.24e-05)max mem: 7.80626 GB 
[09/28 01:04:37 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2045, average loss: 0.8893
[09/28 01:04:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.13	top5: 95.87	
[09/28 01:04:37 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/28 01:04:46 visual_prompt]: Epoch 88 / 100: avg data time: 1.02e-01, avg batch time: 0.5295, average train loss: 0.0279
[09/28 01:04:49 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1725, average loss: 0.0245
[09/28 01:04:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:05:11 visual_prompt]: 	Test 100/157. loss: 0.830, 0.2046 s / batch. (data: 3.31e-05)max mem: 7.80626 GB 
[09/28 01:05:24 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2040, average loss: 0.8923
[09/28 01:05:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.06	top5: 95.96	
[09/28 01:05:24 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/28 01:05:33 visual_prompt]: Epoch 89 / 100: avg data time: 9.03e-02, avg batch time: 0.5191, average train loss: 0.0277
[09/28 01:05:36 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1842, average loss: 0.0243
[09/28 01:05:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:05:58 visual_prompt]: 	Test 100/157. loss: 0.831, 0.2043 s / batch. (data: 2.81e-05)max mem: 7.80626 GB 
[09/28 01:06:10 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2046, average loss: 0.8941
[09/28 01:06:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.89	top5: 95.88	
[09/28 01:06:10 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/28 01:06:20 visual_prompt]: Epoch 90 / 100: avg data time: 9.49e-02, avg batch time: 0.5213, average train loss: 0.0277
[09/28 01:06:23 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1815, average loss: 0.0243
[09/28 01:06:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:06:45 visual_prompt]: 	Test 100/157. loss: 0.833, 0.2033 s / batch. (data: 3.19e-05)max mem: 7.80626 GB 
[09/28 01:06:57 visual_prompt]: Inference (test):avg data time: 1.20e-04, avg batch time: 0.2043, average loss: 0.8965
[09/28 01:06:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.91	top5: 95.90	
[09/28 01:06:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/28 01:07:06 visual_prompt]: Epoch 91 / 100: avg data time: 9.49e-02, avg batch time: 0.5206, average train loss: 0.0277
[09/28 01:07:09 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1836, average loss: 0.0243
[09/28 01:07:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:07:31 visual_prompt]: 	Test 100/157. loss: 0.830, 0.2042 s / batch. (data: 3.00e-05)max mem: 7.80626 GB 
[09/28 01:07:44 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2040, average loss: 0.8964
[09/28 01:07:44 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.94	top5: 95.85	
[09/28 01:07:44 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/28 01:07:53 visual_prompt]: Epoch 92 / 100: avg data time: 9.85e-02, avg batch time: 0.5274, average train loss: 0.0275
[09/28 01:07:56 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1728, average loss: 0.0242
[09/28 01:07:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:08:18 visual_prompt]: 	Test 100/157. loss: 0.832, 0.2034 s / batch. (data: 3.19e-05)max mem: 7.80626 GB 
[09/28 01:08:31 visual_prompt]: Inference (test):avg data time: 1.60e-04, avg batch time: 0.2043, average loss: 0.8982
[09/28 01:08:31 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.92	top5: 95.90	
[09/28 01:08:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/28 01:08:40 visual_prompt]: Epoch 93 / 100: avg data time: 9.61e-02, avg batch time: 0.5234, average train loss: 0.0278
[09/28 01:08:43 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1794, average loss: 0.0243
[09/28 01:08:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:09:05 visual_prompt]: 	Test 100/157. loss: 0.834, 0.2035 s / batch. (data: 3.55e-05)max mem: 7.80626 GB 
[09/28 01:09:18 visual_prompt]: Inference (test):avg data time: 7.73e-05, avg batch time: 0.2043, average loss: 0.8977
[09/28 01:09:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.94	top5: 95.89	
[09/28 01:09:18 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/28 01:09:27 visual_prompt]: Epoch 94 / 100: avg data time: 8.49e-02, avg batch time: 0.5139, average train loss: 0.0276
[09/28 01:09:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1840, average loss: 0.0243
[09/28 01:09:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:09:52 visual_prompt]: 	Test 100/157. loss: 0.834, 0.2044 s / batch. (data: 3.00e-05)max mem: 7.80626 GB 
[09/28 01:10:04 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2042, average loss: 0.8982
[09/28 01:10:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.93	top5: 95.88	
[09/28 01:10:05 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/28 01:10:14 visual_prompt]: Epoch 95 / 100: avg data time: 8.55e-02, avg batch time: 0.5159, average train loss: 0.0277
[09/28 01:10:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1831, average loss: 0.0243
[09/28 01:10:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:10:39 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2044 s / batch. (data: 3.17e-05)max mem: 7.80626 GB 
[09/28 01:10:51 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2042, average loss: 0.8995
[09/28 01:10:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.90	top5: 95.90	
[09/28 01:10:51 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/28 01:11:01 visual_prompt]: Epoch 96 / 100: avg data time: 9.97e-02, avg batch time: 0.5263, average train loss: 0.0274
[09/28 01:11:04 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1783, average loss: 0.0243
[09/28 01:11:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:11:26 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2051 s / batch. (data: 3.03e-05)max mem: 7.80626 GB 
[09/28 01:11:38 visual_prompt]: Inference (test):avg data time: 7.42e-05, avg batch time: 0.2043, average loss: 0.8994
[09/28 01:11:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.86	top5: 95.90	
[09/28 01:11:38 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/28 01:11:47 visual_prompt]: Epoch 97 / 100: avg data time: 9.00e-02, avg batch time: 0.5160, average train loss: 0.0275
[09/28 01:11:50 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1805, average loss: 0.0243
[09/28 01:11:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:12:13 visual_prompt]: 	Test 100/157. loss: 0.836, 0.2053 s / batch. (data: 3.27e-05)max mem: 7.80626 GB 
[09/28 01:12:25 visual_prompt]: Inference (test):avg data time: 1.79e-04, avg batch time: 0.2042, average loss: 0.8997
[09/28 01:12:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.85	top5: 95.91	
[09/28 01:12:25 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/28 01:12:34 visual_prompt]: Epoch 98 / 100: avg data time: 1.01e-01, avg batch time: 0.5264, average train loss: 0.0275
[09/28 01:12:37 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1829, average loss: 0.0243
[09/28 01:12:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:13:00 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2040 s / batch. (data: 3.72e-05)max mem: 7.80626 GB 
[09/28 01:13:12 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2043, average loss: 0.8999
[09/28 01:13:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.86	top5: 95.91	
[09/28 01:13:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/28 01:13:22 visual_prompt]: Epoch 99 / 100: avg data time: 1.05e-01, avg batch time: 0.5302, average train loss: 0.0275
[09/28 01:13:25 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1815, average loss: 0.0243
[09/28 01:13:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:13:46 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2035 s / batch. (data: 3.08e-05)max mem: 7.80626 GB 
[09/28 01:13:59 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2041, average loss: 0.8997
[09/28 01:13:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.86	top5: 95.91	
[09/28 01:13:59 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/28 01:14:08 visual_prompt]: Epoch 100 / 100: avg data time: 9.25e-02, avg batch time: 0.5219, average train loss: 0.0274
[09/28 01:14:11 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1755, average loss: 0.0243
[09/28 01:14:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:14:33 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2057 s / batch. (data: 2.91e-05)max mem: 7.80626 GB 
[09/28 01:14:46 visual_prompt]: Inference (test):avg data time: 1.34e-04, avg batch time: 0.2045, average loss: 0.8997
[09/28 01:14:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.86	top5: 95.90	
[09/28 01:14:46 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 01:14:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 01:14:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 01:14:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 01:14:46 visual_prompt]: Training with config:
[09/28 01:14:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/test/seed2132/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 2132, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 01:14:46 visual_prompt]: Loading training data...
[09/28 01:14:46 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800]+train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 01:14:47 visual_prompt]: Number of images: 1000
[09/28 01:14:47 visual_prompt]: Number of classes: 100 / 100
[09/28 01:14:47 visual_prompt]: Loading validation data...
[09/28 01:14:47 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 01:14:48 visual_prompt]: Number of images: 200
[09/28 01:14:48 visual_prompt]: Number of classes: 90 / 100
[09/28 01:14:48 visual_prompt]: Loading test data...
[09/28 01:14:48 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split test, from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 01:14:59 visual_prompt]: Number of images: 10000
[09/28 01:14:59 visual_prompt]: Number of classes: 100 / 100
[09/28 01:14:59 visual_prompt]: Constructing models...
[09/28 01:15:01 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/28 01:15:01 visual_prompt]: tuned percent:0.623
[09/28 01:15:02 visual_prompt]: Device used for model: 0
[09/28 01:15:02 visual_prompt]: Setting up Evaluator...
[09/28 01:15:02 visual_prompt]: Setting up Trainer...
[09/28 01:15:02 visual_prompt]: 	Setting up the optimizer...
[09/28 01:15:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 01:15:11 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e-01, avg batch time: 0.5325, average train loss: 4.6502
[09/28 01:15:14 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1789, average loss: 4.6471
[09/28 01:15:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.00	
[09/28 01:15:36 visual_prompt]: 	Test 100/157. loss: 4.725, 0.2055 s / batch. (data: 3.08e-05)max mem: 7.81312 GB 
[09/28 01:15:48 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2034, average loss: 4.6468
[09/28 01:15:48 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 0.94	top5: 5.05	
[09/28 01:15:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/28 01:15:58 visual_prompt]: Epoch 2 / 100: avg data time: 1.01e-01, avg batch time: 0.5288, average train loss: 4.6163
[09/28 01:16:01 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1722, average loss: 4.5610
[09/28 01:16:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/28 01:16:23 visual_prompt]: 	Test 100/157. loss: 4.641, 0.2057 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 01:16:35 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2042, average loss: 4.6212
[09/28 01:16:35 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.30	
[09/28 01:16:35 visual_prompt]: Best epoch 2: best metric: 0.005
[09/28 01:16:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/28 01:16:45 visual_prompt]: Epoch 3 / 100: avg data time: 9.49e-02, avg batch time: 0.5218, average train loss: 4.5722
[09/28 01:16:48 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1789, average loss: 4.5059
[09/28 01:16:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 10.50	
[09/28 01:17:10 visual_prompt]: 	Test 100/157. loss: 4.607, 0.2039 s / batch. (data: 2.74e-05)max mem: 7.81378 GB 
[09/28 01:17:22 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2040, average loss: 4.6081
[09/28 01:17:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.33	top5: 7.21	
[09/28 01:17:22 visual_prompt]: Best epoch 3: best metric: 0.015
[09/28 01:17:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/28 01:17:32 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e-01, avg batch time: 0.5317, average train loss: 4.5105
[09/28 01:17:35 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1855, average loss: 4.3360
[09/28 01:17:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 21.50	
[09/28 01:17:57 visual_prompt]: 	Test 100/157. loss: 4.484, 0.2037 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 01:18:09 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2039, average loss: 4.4765
[09/28 01:18:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 2.78	top5: 13.15	
[09/28 01:18:10 visual_prompt]: Best epoch 4: best metric: 0.065
[09/28 01:18:10 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/28 01:18:19 visual_prompt]: Epoch 5 / 100: avg data time: 9.64e-02, avg batch time: 0.5246, average train loss: 4.1316
[09/28 01:18:22 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1761, average loss: 3.5973
[09/28 01:18:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.00	top5: 39.00	
[09/28 01:18:44 visual_prompt]: 	Test 100/157. loss: 3.837, 0.2056 s / batch. (data: 3.36e-05)max mem: 7.81378 GB 
[09/28 01:18:56 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2040, average loss: 3.9130
[09/28 01:18:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 9.01	top5: 28.70	
[09/28 01:18:56 visual_prompt]: Best epoch 5: best metric: 0.120
[09/28 01:18:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/28 01:19:05 visual_prompt]: Epoch 6 / 100: avg data time: 8.76e-02, avg batch time: 0.5161, average train loss: 3.5203
[09/28 01:19:08 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1725, average loss: 2.9472
[09/28 01:19:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 29.00	top5: 62.00	
[09/28 01:19:31 visual_prompt]: 	Test 100/157. loss: 3.159, 0.2043 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 01:19:43 visual_prompt]: Inference (test):avg data time: 9.64e-05, avg batch time: 0.2044, average loss: 3.4790
[09/28 01:19:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 13.85	top5: 41.07	
[09/28 01:19:43 visual_prompt]: Best epoch 6: best metric: 0.290
[09/28 01:19:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/28 01:19:52 visual_prompt]: Epoch 7 / 100: avg data time: 8.52e-02, avg batch time: 0.5151, average train loss: 2.6844
[09/28 01:19:55 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1835, average loss: 2.0114
[09/28 01:19:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.00	top5: 82.00	
[09/28 01:20:17 visual_prompt]: 	Test 100/157. loss: 2.460, 0.2062 s / batch. (data: 3.34e-05)max mem: 7.81378 GB 
[09/28 01:20:30 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2040, average loss: 2.7855
[09/28 01:20:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 27.52	top5: 60.85	
[09/28 01:20:30 visual_prompt]: Best epoch 7: best metric: 0.450
[09/28 01:20:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/28 01:20:39 visual_prompt]: Epoch 8 / 100: avg data time: 8.69e-02, avg batch time: 0.5160, average train loss: 1.7805
[09/28 01:20:42 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1802, average loss: 1.0756
[09/28 01:20:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 95.00	
[09/28 01:21:04 visual_prompt]: 	Test 100/157. loss: 1.805, 0.2056 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 01:21:17 visual_prompt]: Inference (test):avg data time: 5.18e-05, avg batch time: 0.2044, average loss: 2.0381
[09/28 01:21:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 46.25	top5: 78.10	
[09/28 01:21:17 visual_prompt]: Best epoch 8: best metric: 0.750
[09/28 01:21:17 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/28 01:21:26 visual_prompt]: Epoch 9 / 100: avg data time: 9.31e-02, avg batch time: 0.5202, average train loss: 0.9370
[09/28 01:21:29 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1797, average loss: 0.4747
[09/28 01:21:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 95.00	top5: 100.00	
[09/28 01:21:51 visual_prompt]: 	Test 100/157. loss: 1.513, 0.2048 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 01:22:04 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2048, average loss: 1.5734
[09/28 01:22:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 57.19	top5: 86.48	
[09/28 01:22:04 visual_prompt]: Best epoch 9: best metric: 0.950
[09/28 01:22:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/28 01:22:13 visual_prompt]: Epoch 10 / 100: avg data time: 9.95e-02, avg batch time: 0.5252, average train loss: 0.4914
[09/28 01:22:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1823, average loss: 0.2844
[09/28 01:22:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.00	top5: 100.00	
[09/28 01:22:38 visual_prompt]: 	Test 100/157. loss: 1.132, 0.2060 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 01:22:50 visual_prompt]: Inference (test):avg data time: 1.60e-04, avg batch time: 0.2048, average loss: 1.3919
[09/28 01:22:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 63.33	top5: 88.65	
[09/28 01:22:51 visual_prompt]: Best epoch 10: best metric: 0.980
[09/28 01:22:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/28 01:23:00 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e-01, avg batch time: 0.5335, average train loss: 0.2432
[09/28 01:23:03 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1832, average loss: 0.1226
[09/28 01:23:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:23:25 visual_prompt]: 	Test 100/157. loss: 1.066, 0.2042 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 01:23:38 visual_prompt]: Inference (test):avg data time: 5.71e-05, avg batch time: 0.2046, average loss: 1.2332
[09/28 01:23:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 67.28	top5: 90.75	
[09/28 01:23:38 visual_prompt]: Best epoch 11: best metric: 0.995
[09/28 01:23:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/28 01:23:47 visual_prompt]: Epoch 12 / 100: avg data time: 9.82e-02, avg batch time: 0.5279, average train loss: 0.1475
[09/28 01:23:50 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1731, average loss: 0.0987
[09/28 01:23:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:24:12 visual_prompt]: 	Test 100/157. loss: 1.136, 0.2066 s / batch. (data: 3.43e-05)max mem: 7.81378 GB 
[09/28 01:24:25 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2045, average loss: 1.2238
[09/28 01:24:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 67.71	top5: 91.10	
[09/28 01:24:25 visual_prompt]: Best epoch 12: best metric: 1.000
[09/28 01:24:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/28 01:24:34 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e-01, avg batch time: 0.5343, average train loss: 0.1115
[09/28 01:24:37 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1829, average loss: 0.0578
[09/28 01:24:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:25:00 visual_prompt]: 	Test 100/157. loss: 0.991, 0.2049 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 01:25:12 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2043, average loss: 1.1336
[09/28 01:25:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.36	top5: 92.31	
[09/28 01:25:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/28 01:25:21 visual_prompt]: Epoch 14 / 100: avg data time: 9.40e-02, avg batch time: 0.5205, average train loss: 0.0797
[09/28 01:25:24 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1780, average loss: 0.0498
[09/28 01:25:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:25:47 visual_prompt]: 	Test 100/157. loss: 1.004, 0.2044 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 01:25:59 visual_prompt]: Inference (test):avg data time: 1.34e-04, avg batch time: 0.2044, average loss: 1.1029
[09/28 01:25:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.96	top5: 92.38	
[09/28 01:25:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/28 01:26:09 visual_prompt]: Epoch 15 / 100: avg data time: 1.03e-01, avg batch time: 0.5282, average train loss: 0.0631
[09/28 01:26:11 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1754, average loss: 0.0482
[09/28 01:26:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:26:33 visual_prompt]: 	Test 100/157. loss: 0.912, 0.2065 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 01:26:46 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2040, average loss: 1.0875
[09/28 01:26:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.63	top5: 92.79	
[09/28 01:26:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/28 01:26:55 visual_prompt]: Epoch 16 / 100: avg data time: 9.49e-02, avg batch time: 0.5217, average train loss: 0.0634
[09/28 01:26:58 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1856, average loss: 0.0427
[09/28 01:26:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:27:20 visual_prompt]: 	Test 100/157. loss: 0.911, 0.2057 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 01:27:33 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2040, average loss: 1.0650
[09/28 01:27:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.51	top5: 92.76	
[09/28 01:27:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/28 01:27:42 visual_prompt]: Epoch 17 / 100: avg data time: 8.80e-02, avg batch time: 0.5163, average train loss: 0.0608
[09/28 01:27:45 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1817, average loss: 0.0406
[09/28 01:27:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:28:07 visual_prompt]: 	Test 100/157. loss: 0.956, 0.2047 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 01:28:20 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2044, average loss: 1.0697
[09/28 01:28:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.89	top5: 93.12	
[09/28 01:28:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/28 01:28:29 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e-01, avg batch time: 0.5289, average train loss: 0.0562
[09/28 01:28:32 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1777, average loss: 0.0371
[09/28 01:28:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:28:54 visual_prompt]: 	Test 100/157. loss: 0.910, 0.2049 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 01:29:07 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2041, average loss: 1.0803
[09/28 01:29:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.96	top5: 93.05	
[09/28 01:29:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/28 01:29:16 visual_prompt]: Epoch 19 / 100: avg data time: 8.59e-02, avg batch time: 0.5147, average train loss: 0.0541
[09/28 01:29:18 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1762, average loss: 0.0374
[09/28 01:29:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:29:41 visual_prompt]: 	Test 100/157. loss: 1.027, 0.2050 s / batch. (data: 3.15e-05)max mem: 7.81378 GB 
[09/28 01:29:53 visual_prompt]: Inference (test):avg data time: 1.25e-04, avg batch time: 0.2043, average loss: 1.0829
[09/28 01:29:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.69	top5: 93.05	
[09/28 01:29:53 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/28 01:30:03 visual_prompt]: Epoch 20 / 100: avg data time: 9.97e-02, avg batch time: 0.5261, average train loss: 0.0655
[09/28 01:30:06 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1824, average loss: 0.0488
[09/28 01:30:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:30:28 visual_prompt]: 	Test 100/157. loss: 1.090, 0.2063 s / batch. (data: 3.15e-05)max mem: 7.81378 GB 
[09/28 01:30:40 visual_prompt]: Inference (test):avg data time: 2.77e-04, avg batch time: 0.2044, average loss: 1.1204
[09/28 01:30:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.68	top5: 92.85	
[09/28 01:30:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/28 01:30:50 visual_prompt]: Epoch 21 / 100: avg data time: 1.01e-01, avg batch time: 0.5295, average train loss: 0.0791
[09/28 01:30:53 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1855, average loss: 0.0540
[09/28 01:30:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:31:15 visual_prompt]: 	Test 100/157. loss: 0.946, 0.2056 s / batch. (data: 3.36e-05)max mem: 7.81378 GB 
[09/28 01:31:27 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2041, average loss: 1.0899
[09/28 01:31:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.33	top5: 93.40	
[09/28 01:31:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/28 01:31:37 visual_prompt]: Epoch 22 / 100: avg data time: 9.34e-02, avg batch time: 0.5218, average train loss: 0.1068
[09/28 01:31:40 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1842, average loss: 0.1478
[09/28 01:31:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.50	top5: 100.00	
[09/28 01:32:02 visual_prompt]: 	Test 100/157. loss: 1.298, 0.2042 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 01:32:14 visual_prompt]: Inference (test):avg data time: 1.20e-04, avg batch time: 0.2042, average loss: 1.2812
[09/28 01:32:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 68.59	top5: 91.37	
[09/28 01:32:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/28 01:32:24 visual_prompt]: Epoch 23 / 100: avg data time: 1.01e-01, avg batch time: 0.5289, average train loss: 0.1608
[09/28 01:32:27 visual_prompt]: Inference (val):avg data time: 5.47e-05, avg batch time: 0.1766, average loss: 0.1017
[09/28 01:32:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:32:49 visual_prompt]: 	Test 100/157. loss: 1.168, 0.2117 s / batch. (data: 8.46e-03)max mem: 7.81378 GB 
[09/28 01:33:02 visual_prompt]: Inference (test):avg data time: 2.34e-04, avg batch time: 0.2044, average loss: 1.1489
[09/28 01:33:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.88	top5: 93.30	
[09/28 01:33:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/28 01:33:11 visual_prompt]: Epoch 24 / 100: avg data time: 1.08e-01, avg batch time: 0.5350, average train loss: 0.1819
[09/28 01:33:14 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1730, average loss: 0.1467
[09/28 01:33:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:33:36 visual_prompt]: 	Test 100/157. loss: 1.180, 0.2059 s / batch. (data: 3.48e-05)max mem: 7.81378 GB 
[09/28 01:33:49 visual_prompt]: Inference (test):avg data time: 2.52e-04, avg batch time: 0.2044, average loss: 1.1949
[09/28 01:33:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.14	top5: 92.26	
[09/28 01:33:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/28 01:33:58 visual_prompt]: Epoch 25 / 100: avg data time: 9.94e-02, avg batch time: 0.5282, average train loss: 0.2158
[09/28 01:34:01 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1860, average loss: 0.1261
[09/28 01:34:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:34:23 visual_prompt]: 	Test 100/157. loss: 1.129, 0.2038 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 01:34:36 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2039, average loss: 1.1216
[09/28 01:34:36 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.09	top5: 92.82	
[09/28 01:34:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/28 01:34:45 visual_prompt]: Epoch 26 / 100: avg data time: 9.84e-02, avg batch time: 0.5264, average train loss: 0.1757
[09/28 01:34:48 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1765, average loss: 0.0765
[09/28 01:34:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:35:10 visual_prompt]: 	Test 100/157. loss: 0.875, 0.2046 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 01:35:23 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2041, average loss: 1.0230
[09/28 01:35:23 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.72	top5: 93.92	
[09/28 01:35:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/28 01:35:32 visual_prompt]: Epoch 27 / 100: avg data time: 9.96e-02, avg batch time: 0.5267, average train loss: 0.1027
[09/28 01:35:35 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1809, average loss: 0.0547
[09/28 01:35:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:35:57 visual_prompt]: 	Test 100/157. loss: 0.974, 0.2044 s / batch. (data: 3.43e-05)max mem: 7.81378 GB 
[09/28 01:36:09 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2044, average loss: 0.9640
[09/28 01:36:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.06	top5: 94.46	
[09/28 01:36:10 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/28 01:36:19 visual_prompt]: Epoch 28 / 100: avg data time: 9.70e-02, avg batch time: 0.5259, average train loss: 0.0671
[09/28 01:36:22 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1766, average loss: 0.0353
[09/28 01:36:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:36:44 visual_prompt]: 	Test 100/157. loss: 0.876, 0.2042 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 01:36:56 visual_prompt]: Inference (test):avg data time: 1.49e-04, avg batch time: 0.2046, average loss: 0.9411
[09/28 01:36:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.09	top5: 94.35	
[09/28 01:36:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/28 01:37:06 visual_prompt]: Epoch 29 / 100: avg data time: 9.43e-02, avg batch time: 0.5228, average train loss: 0.0463
[09/28 01:37:09 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1755, average loss: 0.0332
[09/28 01:37:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:37:31 visual_prompt]: 	Test 100/157. loss: 0.866, 0.2058 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 01:37:43 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2042, average loss: 0.9519
[09/28 01:37:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.03	top5: 94.59	
[09/28 01:37:43 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/28 01:37:53 visual_prompt]: Epoch 30 / 100: avg data time: 9.62e-02, avg batch time: 0.5234, average train loss: 0.0428
[09/28 01:37:55 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1802, average loss: 0.0300
[09/28 01:37:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:38:18 visual_prompt]: 	Test 100/157. loss: 0.867, 0.2060 s / batch. (data: 2.48e-05)max mem: 7.81378 GB 
[09/28 01:38:30 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2042, average loss: 0.9348
[09/28 01:38:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.62	top5: 94.65	
[09/28 01:38:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/28 01:38:40 visual_prompt]: Epoch 31 / 100: avg data time: 1.01e-01, avg batch time: 0.5293, average train loss: 0.0387
[09/28 01:38:42 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1755, average loss: 0.0282
[09/28 01:38:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:39:04 visual_prompt]: 	Test 100/157. loss: 0.840, 0.2046 s / batch. (data: 3.43e-05)max mem: 7.81378 GB 
[09/28 01:39:17 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2043, average loss: 0.9181
[09/28 01:39:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.88	top5: 95.13	
[09/28 01:39:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/28 01:39:26 visual_prompt]: Epoch 32 / 100: avg data time: 9.10e-02, avg batch time: 0.5209, average train loss: 0.0351
[09/28 01:39:29 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1800, average loss: 0.0270
[09/28 01:39:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:39:52 visual_prompt]: 	Test 100/157. loss: 0.832, 0.2061 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 01:40:04 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2043, average loss: 0.9221
[09/28 01:40:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.77	top5: 94.77	
[09/28 01:40:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/28 01:40:13 visual_prompt]: Epoch 33 / 100: avg data time: 9.30e-02, avg batch time: 0.5210, average train loss: 0.0349
[09/28 01:40:16 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1728, average loss: 0.0302
[09/28 01:40:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:40:38 visual_prompt]: 	Test 100/157. loss: 0.860, 0.2046 s / batch. (data: 3.15e-05)max mem: 7.81378 GB 
[09/28 01:40:51 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2045, average loss: 0.9522
[09/28 01:40:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.24	top5: 94.85	
[09/28 01:40:51 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/28 01:41:00 visual_prompt]: Epoch 34 / 100: avg data time: 9.74e-02, avg batch time: 0.5246, average train loss: 0.0358
[09/28 01:41:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1591, average loss: 0.0294
[09/28 01:41:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:41:25 visual_prompt]: 	Test 100/157. loss: 0.872, 0.2055 s / batch. (data: 5.20e-05)max mem: 7.81378 GB 
[09/28 01:41:38 visual_prompt]: Inference (test):avg data time: 6.85e-05, avg batch time: 0.2043, average loss: 0.9534
[09/28 01:41:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.08	top5: 94.98	
[09/28 01:41:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/28 01:41:47 visual_prompt]: Epoch 35 / 100: avg data time: 8.84e-02, avg batch time: 0.5176, average train loss: 0.0366
[09/28 01:41:50 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1734, average loss: 0.0391
[09/28 01:41:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:42:12 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2045 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 01:42:25 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2041, average loss: 0.9623
[09/28 01:42:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.27	top5: 94.70	
[09/28 01:42:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/28 01:42:34 visual_prompt]: Epoch 36 / 100: avg data time: 1.01e-01, avg batch time: 0.5285, average train loss: 0.0384
[09/28 01:42:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1778, average loss: 0.0297
[09/28 01:42:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:42:59 visual_prompt]: 	Test 100/157. loss: 0.779, 0.2050 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 01:43:11 visual_prompt]: Inference (test):avg data time: 1.30e-04, avg batch time: 0.2042, average loss: 0.9570
[09/28 01:43:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.18	top5: 94.56	
[09/28 01:43:12 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/28 01:43:21 visual_prompt]: Epoch 37 / 100: avg data time: 9.94e-02, avg batch time: 0.5261, average train loss: 0.0566
[09/28 01:43:24 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1851, average loss: 0.0414
[09/28 01:43:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:43:46 visual_prompt]: 	Test 100/157. loss: 0.930, 0.2033 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 01:43:58 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2041, average loss: 1.0182
[09/28 01:43:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.06	top5: 94.27	
[09/28 01:43:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/28 01:44:08 visual_prompt]: Epoch 38 / 100: avg data time: 1.03e-01, avg batch time: 0.5306, average train loss: 0.0865
[09/28 01:44:11 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1773, average loss: 0.0673
[09/28 01:44:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:44:33 visual_prompt]: 	Test 100/157. loss: 1.131, 0.2050 s / batch. (data: 4.67e-05)max mem: 7.81378 GB 
[09/28 01:44:45 visual_prompt]: Inference (test):avg data time: 1.22e-04, avg batch time: 0.2044, average loss: 1.1288
[09/28 01:44:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.75	top5: 93.67	
[09/28 01:44:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/28 01:44:55 visual_prompt]: Epoch 39 / 100: avg data time: 1.01e-01, avg batch time: 0.5292, average train loss: 0.1508
[09/28 01:44:58 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.1782, average loss: 0.1931
[09/28 01:44:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.00	top5: 100.00	
[09/28 01:45:20 visual_prompt]: 	Test 100/157. loss: 1.195, 0.2059 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 01:45:32 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2045, average loss: 1.2103
[09/28 01:45:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.32	top5: 92.97	
[09/28 01:45:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/28 01:45:42 visual_prompt]: Epoch 40 / 100: avg data time: 9.12e-02, avg batch time: 0.5197, average train loss: 0.4878
[09/28 01:45:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1855, average loss: 0.3617
[09/28 01:45:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.00	top5: 100.00	
[09/28 01:46:07 visual_prompt]: 	Test 100/157. loss: 1.238, 0.2042 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 01:46:19 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2042, average loss: 1.2865
[09/28 01:46:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.45	top5: 92.42	
[09/28 01:46:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/28 01:46:28 visual_prompt]: Epoch 41 / 100: avg data time: 8.30e-02, avg batch time: 0.5108, average train loss: 0.3685
[09/28 01:46:31 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1854, average loss: 0.1203
[09/28 01:46:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:46:53 visual_prompt]: 	Test 100/157. loss: 0.995, 0.2058 s / batch. (data: 3.29e-05)max mem: 7.81378 GB 
[09/28 01:47:06 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2043, average loss: 0.9917
[09/28 01:47:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.89	top5: 94.61	
[09/28 01:47:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/28 01:47:15 visual_prompt]: Epoch 42 / 100: avg data time: 9.69e-02, avg batch time: 0.5268, average train loss: 0.1415
[09/28 01:47:18 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1737, average loss: 0.0741
[09/28 01:47:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 01:47:40 visual_prompt]: 	Test 100/157. loss: 0.867, 0.2060 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 01:47:53 visual_prompt]: Inference (test):avg data time: 1.57e-04, avg batch time: 0.2046, average loss: 0.8945
[09/28 01:47:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.90	top5: 95.33	
[09/28 01:47:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/28 01:48:02 visual_prompt]: Epoch 43 / 100: avg data time: 9.43e-02, avg batch time: 0.5225, average train loss: 0.0721
[09/28 01:48:05 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1782, average loss: 0.0427
[09/28 01:48:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 01:48:27 visual_prompt]: 	Test 100/157. loss: 0.783, 0.2045 s / batch. (data: 5.65e-05)max mem: 7.81378 GB 
[09/28 01:48:40 visual_prompt]: Inference (test):avg data time: 9.65e-05, avg batch time: 0.2044, average loss: 0.8364
[09/28 01:48:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.23	top5: 95.70	
[09/28 01:48:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/28 01:48:49 visual_prompt]: Epoch 44 / 100: avg data time: 1.03e-01, avg batch time: 0.5310, average train loss: 0.0418
[09/28 01:48:52 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1802, average loss: 0.0282
[09/28 01:48:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:49:14 visual_prompt]: 	Test 100/157. loss: 0.780, 0.2056 s / batch. (data: 3.31e-05)max mem: 7.81378 GB 
[09/28 01:49:27 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2045, average loss: 0.8197
[09/28 01:49:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.83	top5: 95.88	
[09/28 01:49:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/28 01:49:36 visual_prompt]: Epoch 45 / 100: avg data time: 9.74e-02, avg batch time: 0.5242, average train loss: 0.0330
[09/28 01:49:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1803, average loss: 0.0256
[09/28 01:49:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:50:01 visual_prompt]: 	Test 100/157. loss: 0.775, 0.2048 s / batch. (data: 4.82e-05)max mem: 7.81378 GB 
[09/28 01:50:13 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2042, average loss: 0.8385
[09/28 01:50:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.14	top5: 95.61	
[09/28 01:50:14 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/28 01:50:23 visual_prompt]: Epoch 46 / 100: avg data time: 9.24e-02, avg batch time: 0.5258, average train loss: 0.0321
[09/28 01:50:26 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1771, average loss: 0.0254
[09/28 01:50:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:50:48 visual_prompt]: 	Test 100/157. loss: 0.753, 0.2045 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 01:51:01 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2041, average loss: 0.8353
[09/28 01:51:01 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.58	top5: 95.66	
[09/28 01:51:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/28 01:51:10 visual_prompt]: Epoch 47 / 100: avg data time: 9.46e-02, avg batch time: 0.5246, average train loss: 0.0311
[09/28 01:51:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1847, average loss: 0.0248
[09/28 01:51:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:51:35 visual_prompt]: 	Test 100/157. loss: 0.801, 0.2060 s / batch. (data: 2.96e-05)max mem: 7.81378 GB 
[09/28 01:51:48 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2042, average loss: 0.8471
[09/28 01:51:48 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.29	top5: 95.62	
[09/28 01:51:48 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/28 01:51:57 visual_prompt]: Epoch 48 / 100: avg data time: 9.08e-02, avg batch time: 0.5215, average train loss: 0.0315
[09/28 01:52:00 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1833, average loss: 0.0259
[09/28 01:52:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:52:22 visual_prompt]: 	Test 100/157. loss: 0.801, 0.2049 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 01:52:35 visual_prompt]: Inference (test):avg data time: 1.09e-04, avg batch time: 0.2044, average loss: 0.8644
[09/28 01:52:35 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.11	top5: 95.61	
[09/28 01:52:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/28 01:52:44 visual_prompt]: Epoch 49 / 100: avg data time: 9.54e-02, avg batch time: 0.5218, average train loss: 0.0323
[09/28 01:52:47 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1784, average loss: 0.0257
[09/28 01:52:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:53:09 visual_prompt]: 	Test 100/157. loss: 0.815, 0.2054 s / batch. (data: 3.62e-05)max mem: 7.81378 GB 
[09/28 01:53:22 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2042, average loss: 0.8708
[09/28 01:53:22 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.80	top5: 95.52	
[09/28 01:53:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/28 01:53:31 visual_prompt]: Epoch 50 / 100: avg data time: 1.07e-01, avg batch time: 0.5341, average train loss: 0.0323
[09/28 01:53:34 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1793, average loss: 0.0262
[09/28 01:53:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:53:56 visual_prompt]: 	Test 100/157. loss: 0.800, 0.2037 s / batch. (data: 2.96e-05)max mem: 7.81378 GB 
[09/28 01:54:09 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2044, average loss: 0.8715
[09/28 01:54:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.79	top5: 95.71	
[09/28 01:54:09 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/28 01:54:18 visual_prompt]: Epoch 51 / 100: avg data time: 9.89e-02, avg batch time: 0.5247, average train loss: 0.0335
[09/28 01:54:21 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1737, average loss: 0.0306
[09/28 01:54:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:54:43 visual_prompt]: 	Test 100/157. loss: 0.754, 0.2052 s / batch. (data: 2.57e-05)max mem: 7.81378 GB 
[09/28 01:54:56 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2042, average loss: 0.8943
[09/28 01:54:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.29	top5: 95.26	
[09/28 01:54:56 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/28 01:55:05 visual_prompt]: Epoch 52 / 100: avg data time: 9.47e-02, avg batch time: 0.5240, average train loss: 0.0370
[09/28 01:55:08 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1849, average loss: 0.0307
[09/28 01:55:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:55:30 visual_prompt]: 	Test 100/157. loss: 0.791, 0.2038 s / batch. (data: 5.25e-05)max mem: 7.81378 GB 
[09/28 01:55:42 visual_prompt]: Inference (test):avg data time: 5.94e-05, avg batch time: 0.2041, average loss: 0.8983
[09/28 01:55:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.30	top5: 95.35	
[09/28 01:55:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/28 01:55:52 visual_prompt]: Epoch 53 / 100: avg data time: 8.56e-02, avg batch time: 0.5136, average train loss: 0.0370
[09/28 01:55:55 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1758, average loss: 0.0280
[09/28 01:55:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:56:17 visual_prompt]: 	Test 100/157. loss: 0.806, 0.2035 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 01:56:29 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2042, average loss: 0.9007
[09/28 01:56:29 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.55	top5: 95.58	
[09/28 01:56:29 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/28 01:56:38 visual_prompt]: Epoch 54 / 100: avg data time: 8.79e-02, avg batch time: 0.5160, average train loss: 0.0348
[09/28 01:56:41 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1780, average loss: 0.0272
[09/28 01:56:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:57:04 visual_prompt]: 	Test 100/157. loss: 0.785, 0.2056 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 01:57:16 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2044, average loss: 0.9094
[09/28 01:57:16 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.16	top5: 95.40	
[09/28 01:57:16 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/28 01:57:25 visual_prompt]: Epoch 55 / 100: avg data time: 9.06e-02, avg batch time: 0.5182, average train loss: 0.0336
[09/28 01:57:28 visual_prompt]: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1732, average loss: 0.0257
[09/28 01:57:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:57:50 visual_prompt]: 	Test 100/157. loss: 0.823, 0.2051 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 01:58:03 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2040, average loss: 0.9019
[09/28 01:58:03 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.38	top5: 95.47	
[09/28 01:58:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/28 01:58:12 visual_prompt]: Epoch 56 / 100: avg data time: 9.30e-02, avg batch time: 0.5208, average train loss: 0.0328
[09/28 01:58:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1729, average loss: 0.0257
[09/28 01:58:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:58:37 visual_prompt]: 	Test 100/157. loss: 0.775, 0.2043 s / batch. (data: 3.08e-05)max mem: 7.81378 GB 
[09/28 01:58:50 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2043, average loss: 0.9253
[09/28 01:58:50 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.86	top5: 95.44	
[09/28 01:58:50 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/28 01:58:59 visual_prompt]: Epoch 57 / 100: avg data time: 9.94e-02, avg batch time: 0.5277, average train loss: 0.0320
[09/28 01:59:02 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1766, average loss: 0.0253
[09/28 01:59:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 01:59:24 visual_prompt]: 	Test 100/157. loss: 0.771, 0.2050 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 01:59:37 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2045, average loss: 0.9315
[09/28 01:59:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.57	top5: 95.25	
[09/28 01:59:37 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/28 01:59:46 visual_prompt]: Epoch 58 / 100: avg data time: 9.36e-02, avg batch time: 0.5230, average train loss: 0.0326
[09/28 01:59:49 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1728, average loss: 0.0257
[09/28 01:59:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:00:11 visual_prompt]: 	Test 100/157. loss: 0.760, 0.2052 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 02:00:24 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2042, average loss: 0.9118
[09/28 02:00:24 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.31	top5: 95.50	
[09/28 02:00:24 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/28 02:00:33 visual_prompt]: Epoch 59 / 100: avg data time: 1.00e-01, avg batch time: 0.5284, average train loss: 0.0321
[09/28 02:00:36 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1786, average loss: 0.0255
[09/28 02:00:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:00:58 visual_prompt]: 	Test 100/157. loss: 0.733, 0.2051 s / batch. (data: 3.70e-05)max mem: 7.81378 GB 
[09/28 02:01:10 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2043, average loss: 0.9398
[09/28 02:01:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.46	top5: 95.29	
[09/28 02:01:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/28 02:01:19 visual_prompt]: Epoch 60 / 100: avg data time: 8.89e-02, avg batch time: 0.5154, average train loss: 0.0319
[09/28 02:01:22 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1819, average loss: 0.0256
[09/28 02:01:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:01:45 visual_prompt]: 	Test 100/157. loss: 0.774, 0.2041 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 02:01:57 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2042, average loss: 0.9582
[09/28 02:01:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.11	top5: 95.06	
[09/28 02:01:57 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/28 02:02:06 visual_prompt]: Epoch 61 / 100: avg data time: 8.89e-02, avg batch time: 0.5162, average train loss: 0.0316
[09/28 02:02:09 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1801, average loss: 0.0254
[09/28 02:02:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:02:32 visual_prompt]: 	Test 100/157. loss: 0.783, 0.2051 s / batch. (data: 2.65e-05)max mem: 7.81378 GB 
[09/28 02:02:44 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2042, average loss: 0.9501
[09/28 02:02:44 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.08	top5: 95.25	
[09/28 02:02:44 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/28 02:02:54 visual_prompt]: Epoch 62 / 100: avg data time: 1.01e-01, avg batch time: 0.5288, average train loss: 0.0316
[09/28 02:02:57 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1822, average loss: 0.0262
[09/28 02:02:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:03:19 visual_prompt]: 	Test 100/157. loss: 0.827, 0.2054 s / batch. (data: 3.29e-05)max mem: 7.81378 GB 
[09/28 02:03:31 visual_prompt]: Inference (test):avg data time: 6.03e-05, avg batch time: 0.2044, average loss: 0.9765
[09/28 02:03:31 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.65	top5: 95.08	
[09/28 02:03:31 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/28 02:03:41 visual_prompt]: Epoch 63 / 100: avg data time: 1.00e-01, avg batch time: 0.5296, average train loss: 0.0315
[09/28 02:03:44 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1835, average loss: 0.0258
[09/28 02:03:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:04:06 visual_prompt]: 	Test 100/157. loss: 0.750, 0.2049 s / batch. (data: 5.32e-05)max mem: 7.81378 GB 
[09/28 02:04:18 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2045, average loss: 0.9817
[09/28 02:04:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.62	top5: 95.00	
[09/28 02:04:18 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/28 02:04:28 visual_prompt]: Epoch 64 / 100: avg data time: 1.06e-01, avg batch time: 0.5351, average train loss: 0.0315
[09/28 02:04:31 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1822, average loss: 0.0253
[09/28 02:04:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:04:53 visual_prompt]: 	Test 100/157. loss: 0.828, 0.2047 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 02:05:05 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2044, average loss: 0.9741
[09/28 02:05:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.86	top5: 95.11	
[09/28 02:05:06 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/28 02:05:15 visual_prompt]: Epoch 65 / 100: avg data time: 1.02e-01, avg batch time: 0.5292, average train loss: 0.0313
[09/28 02:05:18 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1821, average loss: 0.0251
[09/28 02:05:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:05:40 visual_prompt]: 	Test 100/157. loss: 0.778, 0.2042 s / batch. (data: 7.27e-05)max mem: 7.81378 GB 
[09/28 02:05:52 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2045, average loss: 0.9967
[09/28 02:05:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.43	top5: 94.77	
[09/28 02:05:52 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/28 02:06:02 visual_prompt]: Epoch 66 / 100: avg data time: 9.54e-02, avg batch time: 0.5236, average train loss: 0.0309
[09/28 02:06:04 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1738, average loss: 0.0259
[09/28 02:06:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:06:27 visual_prompt]: 	Test 100/157. loss: 0.874, 0.2052 s / batch. (data: 3.27e-05)max mem: 7.81378 GB 
[09/28 02:06:39 visual_prompt]: Inference (test):avg data time: 1.81e-04, avg batch time: 0.2048, average loss: 1.0392
[09/28 02:06:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.15	top5: 94.27	
[09/28 02:06:39 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/28 02:06:48 visual_prompt]: Epoch 67 / 100: avg data time: 9.12e-02, avg batch time: 0.5216, average train loss: 0.0306
[09/28 02:06:51 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1768, average loss: 0.0251
[09/28 02:06:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:07:13 visual_prompt]: 	Test 100/157. loss: 0.750, 0.2065 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 02:07:26 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2043, average loss: 1.0062
[09/28 02:07:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.96	top5: 94.77	
[09/28 02:07:26 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/28 02:07:35 visual_prompt]: Epoch 68 / 100: avg data time: 9.59e-02, avg batch time: 0.5221, average train loss: 0.0303
[09/28 02:07:38 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1832, average loss: 0.0253
[09/28 02:07:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:08:00 visual_prompt]: 	Test 100/157. loss: 0.856, 0.2042 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 02:08:13 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2043, average loss: 1.0134
[09/28 02:08:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.93	top5: 94.69	
[09/28 02:08:13 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/28 02:08:22 visual_prompt]: Epoch 69 / 100: avg data time: 9.35e-02, avg batch time: 0.5217, average train loss: 0.0300
[09/28 02:08:25 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1850, average loss: 0.0253
[09/28 02:08:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:08:47 visual_prompt]: 	Test 100/157. loss: 0.822, 0.2036 s / batch. (data: 3.08e-05)max mem: 7.81378 GB 
[09/28 02:09:00 visual_prompt]: Inference (test):avg data time: 2.47e-04, avg batch time: 0.2047, average loss: 1.0404
[09/28 02:09:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.47	top5: 94.45	
[09/28 02:09:00 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/28 02:09:09 visual_prompt]: Epoch 70 / 100: avg data time: 9.96e-02, avg batch time: 0.5277, average train loss: 0.0302
[09/28 02:09:12 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1740, average loss: 0.0247
[09/28 02:09:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:09:34 visual_prompt]: 	Test 100/157. loss: 0.829, 0.2051 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 02:09:47 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2044, average loss: 1.0254
[09/28 02:09:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.55	top5: 94.65	
[09/28 02:09:47 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/28 02:09:56 visual_prompt]: Epoch 71 / 100: avg data time: 8.99e-02, avg batch time: 0.5174, average train loss: 0.0302
[09/28 02:09:59 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1762, average loss: 0.0249
[09/28 02:09:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:10:21 visual_prompt]: 	Test 100/157. loss: 0.897, 0.2052 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 02:10:33 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2044, average loss: 1.0474
[09/28 02:10:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.10	top5: 94.45	
[09/28 02:10:33 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/28 02:10:42 visual_prompt]: Epoch 72 / 100: avg data time: 8.81e-02, avg batch time: 0.5144, average train loss: 0.0298
[09/28 02:10:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1728, average loss: 0.0252
[09/28 02:10:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:11:08 visual_prompt]: 	Test 100/157. loss: 0.886, 0.2058 s / batch. (data: 3.27e-05)max mem: 7.81378 GB 
[09/28 02:11:20 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2042, average loss: 1.0484
[09/28 02:11:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.28	top5: 94.47	
[09/28 02:11:20 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/28 02:11:29 visual_prompt]: Epoch 73 / 100: avg data time: 9.60e-02, avg batch time: 0.5236, average train loss: 0.0299
[09/28 02:11:32 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1796, average loss: 0.0249
[09/28 02:11:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:11:54 visual_prompt]: 	Test 100/157. loss: 0.874, 0.2045 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 02:12:07 visual_prompt]: Inference (test):avg data time: 4.59e-05, avg batch time: 0.2043, average loss: 1.0488
[09/28 02:12:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.68	top5: 94.24	
[09/28 02:12:07 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/28 02:12:16 visual_prompt]: Epoch 74 / 100: avg data time: 1.07e-01, avg batch time: 0.5354, average train loss: 0.0294
[09/28 02:12:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1812, average loss: 0.0249
[09/28 02:12:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:12:41 visual_prompt]: 	Test 100/157. loss: 0.931, 0.2041 s / batch. (data: 6.53e-05)max mem: 7.81378 GB 
[09/28 02:12:54 visual_prompt]: Inference (test):avg data time: 1.54e-04, avg batch time: 0.2043, average loss: 1.0655
[09/28 02:12:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.76	top5: 94.47	
[09/28 02:12:54 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/28 02:13:03 visual_prompt]: Epoch 75 / 100: avg data time: 1.03e-01, avg batch time: 0.5303, average train loss: 0.0296
[09/28 02:13:06 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1818, average loss: 0.0244
[09/28 02:13:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:13:28 visual_prompt]: 	Test 100/157. loss: 0.895, 0.2048 s / batch. (data: 5.34e-05)max mem: 7.81378 GB 
[09/28 02:13:41 visual_prompt]: Inference (test):avg data time: 1.60e-04, avg batch time: 0.2043, average loss: 1.0470
[09/28 02:13:41 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.42	top5: 94.29	
[09/28 02:13:41 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/28 02:13:50 visual_prompt]: Epoch 76 / 100: avg data time: 1.03e-01, avg batch time: 0.5309, average train loss: 0.0292
[09/28 02:13:53 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1779, average loss: 0.0246
[09/28 02:13:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:14:15 visual_prompt]: 	Test 100/157. loss: 0.923, 0.2054 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 02:14:28 visual_prompt]: Inference (test):avg data time: 1.18e-04, avg batch time: 0.2045, average loss: 1.0549
[09/28 02:14:28 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.17	top5: 94.43	
[09/28 02:14:28 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/28 02:14:37 visual_prompt]: Epoch 77 / 100: avg data time: 9.04e-02, avg batch time: 0.5205, average train loss: 0.0290
[09/28 02:14:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1737, average loss: 0.0246
[09/28 02:14:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:15:02 visual_prompt]: 	Test 100/157. loss: 0.935, 0.2062 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 02:15:15 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2044, average loss: 1.0764
[09/28 02:15:15 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.77	top5: 94.25	
[09/28 02:15:15 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/28 02:15:24 visual_prompt]: Epoch 78 / 100: avg data time: 9.69e-02, avg batch time: 0.5252, average train loss: 0.0292
[09/28 02:15:27 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1768, average loss: 0.0249
[09/28 02:15:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:15:49 visual_prompt]: 	Test 100/157. loss: 0.892, 0.2054 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 02:16:02 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2046, average loss: 1.0842
[09/28 02:16:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.62	top5: 94.14	
[09/28 02:16:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/28 02:16:11 visual_prompt]: Epoch 79 / 100: avg data time: 8.68e-02, avg batch time: 0.5160, average train loss: 0.0293
[09/28 02:16:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1732, average loss: 0.0247
[09/28 02:16:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:16:36 visual_prompt]: 	Test 100/157. loss: 0.890, 0.2057 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 02:16:49 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2044, average loss: 1.0664
[09/28 02:16:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.97	top5: 94.24	
[09/28 02:16:49 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/28 02:16:58 visual_prompt]: Epoch 80 / 100: avg data time: 9.46e-02, avg batch time: 0.5209, average train loss: 0.0290
[09/28 02:17:01 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1803, average loss: 0.0245
[09/28 02:17:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:17:23 visual_prompt]: 	Test 100/157. loss: 0.929, 0.2036 s / batch. (data: 4.41e-05)max mem: 7.81378 GB 
[09/28 02:17:35 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2044, average loss: 1.0813
[09/28 02:17:36 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.59	top5: 94.16	
[09/28 02:17:36 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/28 02:17:45 visual_prompt]: Epoch 81 / 100: avg data time: 1.02e-01, avg batch time: 0.5307, average train loss: 0.0288
[09/28 02:17:48 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1783, average loss: 0.0245
[09/28 02:17:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:18:10 visual_prompt]: 	Test 100/157. loss: 0.932, 0.2051 s / batch. (data: 3.34e-05)max mem: 7.81378 GB 
[09/28 02:18:23 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2046, average loss: 1.0990
[09/28 02:18:23 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.21	top5: 93.89	
[09/28 02:18:23 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/28 02:18:32 visual_prompt]: Epoch 82 / 100: avg data time: 9.39e-02, avg batch time: 0.5208, average train loss: 0.0287
[09/28 02:18:35 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1770, average loss: 0.0246
[09/28 02:18:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:18:57 visual_prompt]: 	Test 100/157. loss: 0.951, 0.2053 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 02:19:09 visual_prompt]: Inference (test):avg data time: 1.53e-04, avg batch time: 0.2047, average loss: 1.0812
[09/28 02:19:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.63	top5: 94.20	
[09/28 02:19:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/28 02:19:19 visual_prompt]: Epoch 83 / 100: avg data time: 9.92e-02, avg batch time: 0.5253, average train loss: 0.0285
[09/28 02:19:22 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1749, average loss: 0.0248
[09/28 02:19:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:19:44 visual_prompt]: 	Test 100/157. loss: 0.945, 0.2046 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 02:19:56 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2042, average loss: 1.0994
[09/28 02:19:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.54	top5: 93.95	
[09/28 02:19:56 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/28 02:20:06 visual_prompt]: Epoch 84 / 100: avg data time: 9.17e-02, avg batch time: 0.5202, average train loss: 0.0288
[09/28 02:20:09 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1787, average loss: 0.0242
[09/28 02:20:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:20:31 visual_prompt]: 	Test 100/157. loss: 0.964, 0.2042 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 02:20:43 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2042, average loss: 1.1028
[09/28 02:20:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.10	top5: 93.88	
[09/28 02:20:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/28 02:20:53 visual_prompt]: Epoch 85 / 100: avg data time: 9.65e-02, avg batch time: 0.5237, average train loss: 0.0285
[09/28 02:20:55 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1786, average loss: 0.0244
[09/28 02:20:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:21:18 visual_prompt]: 	Test 100/157. loss: 0.927, 0.2056 s / batch. (data: 3.15e-05)max mem: 7.81378 GB 
[09/28 02:21:30 visual_prompt]: Inference (test):avg data time: 1.23e-04, avg batch time: 0.2043, average loss: 1.0901
[09/28 02:21:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.47	top5: 94.13	
[09/28 02:21:30 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/28 02:21:39 visual_prompt]: Epoch 86 / 100: avg data time: 9.41e-02, avg batch time: 0.5216, average train loss: 0.0284
[09/28 02:21:42 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1835, average loss: 0.0240
[09/28 02:21:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:22:04 visual_prompt]: 	Test 100/157. loss: 0.938, 0.2051 s / batch. (data: 3.08e-05)max mem: 7.81378 GB 
[09/28 02:22:17 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2044, average loss: 1.0932
[09/28 02:22:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.26	top5: 94.06	
[09/28 02:22:17 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/28 02:22:26 visual_prompt]: Epoch 87 / 100: avg data time: 1.01e-01, avg batch time: 0.5291, average train loss: 0.0296
[09/28 02:22:29 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1823, average loss: 0.0250
[09/28 02:22:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:22:51 visual_prompt]: 	Test 100/157. loss: 0.964, 0.2038 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 02:23:04 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2042, average loss: 1.1087
[09/28 02:23:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.15	top5: 93.70	
[09/28 02:23:04 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/28 02:23:13 visual_prompt]: Epoch 88 / 100: avg data time: 8.96e-02, avg batch time: 0.5176, average train loss: 0.0292
[09/28 02:23:16 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1788, average loss: 0.0247
[09/28 02:23:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:23:38 visual_prompt]: 	Test 100/157. loss: 0.978, 0.2035 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 02:23:51 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2043, average loss: 1.0900
[09/28 02:23:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.88	top5: 93.96	
[09/28 02:23:51 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/28 02:24:00 visual_prompt]: Epoch 89 / 100: avg data time: 9.71e-02, avg batch time: 0.5257, average train loss: 0.0288
[09/28 02:24:03 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1854, average loss: 0.0244
[09/28 02:24:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:24:25 visual_prompt]: 	Test 100/157. loss: 0.959, 0.2058 s / batch. (data: 5.41e-05)max mem: 7.81378 GB 
[09/28 02:24:38 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2044, average loss: 1.0975
[09/28 02:24:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.43	top5: 93.95	
[09/28 02:24:38 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/28 02:24:47 visual_prompt]: Epoch 90 / 100: avg data time: 9.28e-02, avg batch time: 0.5194, average train loss: 0.0285
[09/28 02:24:50 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1777, average loss: 0.0245
[09/28 02:24:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:25:12 visual_prompt]: 	Test 100/157. loss: 0.967, 0.2052 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 02:25:24 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2042, average loss: 1.1128
[09/28 02:25:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.03	top5: 93.83	
[09/28 02:25:25 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/28 02:25:34 visual_prompt]: Epoch 91 / 100: avg data time: 9.06e-02, avg batch time: 0.5171, average train loss: 0.0285
[09/28 02:25:37 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1851, average loss: 0.0244
[09/28 02:25:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:25:59 visual_prompt]: 	Test 100/157. loss: 0.956, 0.2046 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 02:26:11 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2042, average loss: 1.1047
[09/28 02:26:11 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.24	top5: 93.81	
[09/28 02:26:11 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/28 02:26:21 visual_prompt]: Epoch 92 / 100: avg data time: 9.29e-02, avg batch time: 0.5197, average train loss: 0.0283
[09/28 02:26:24 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1823, average loss: 0.0241
[09/28 02:26:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:26:46 visual_prompt]: 	Test 100/157. loss: 0.932, 0.2045 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 02:26:58 visual_prompt]: Inference (test):avg data time: 2.78e-04, avg batch time: 0.2042, average loss: 1.0975
[09/28 02:26:58 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.36	top5: 93.83	
[09/28 02:26:58 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/28 02:27:08 visual_prompt]: Epoch 93 / 100: avg data time: 9.49e-02, avg batch time: 0.5213, average train loss: 0.0284
[09/28 02:27:10 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1761, average loss: 0.0242
[09/28 02:27:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:27:32 visual_prompt]: 	Test 100/157. loss: 0.951, 0.2069 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 02:27:45 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2046, average loss: 1.1031
[09/28 02:27:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.37	top5: 93.77	
[09/28 02:27:45 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/28 02:27:55 visual_prompt]: Epoch 94 / 100: avg data time: 1.03e-01, avg batch time: 0.5331, average train loss: 0.0282
[09/28 02:27:58 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1832, average loss: 0.0243
[09/28 02:27:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:28:20 visual_prompt]: 	Test 100/157. loss: 0.964, 0.2050 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 02:28:32 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2045, average loss: 1.1075
[09/28 02:28:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.17	top5: 93.76	
[09/28 02:28:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/28 02:28:41 visual_prompt]: Epoch 95 / 100: avg data time: 9.22e-02, avg batch time: 0.5204, average train loss: 0.0281
[09/28 02:28:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1770, average loss: 0.0243
[09/28 02:28:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:29:07 visual_prompt]: 	Test 100/157. loss: 0.962, 0.2053 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 02:29:19 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2048, average loss: 1.1122
[09/28 02:29:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.02	top5: 93.64	
[09/28 02:29:19 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/28 02:29:28 visual_prompt]: Epoch 96 / 100: avg data time: 9.46e-02, avg batch time: 0.5236, average train loss: 0.0281
[09/28 02:29:31 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1769, average loss: 0.0242
[09/28 02:29:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:29:53 visual_prompt]: 	Test 100/157. loss: 0.957, 0.2045 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 02:30:06 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2042, average loss: 1.1144
[09/28 02:30:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.03	top5: 93.66	
[09/28 02:30:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/28 02:30:15 visual_prompt]: Epoch 97 / 100: avg data time: 9.92e-02, avg batch time: 0.5256, average train loss: 0.0282
[09/28 02:30:18 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1844, average loss: 0.0242
[09/28 02:30:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:30:40 visual_prompt]: 	Test 100/157. loss: 0.957, 0.2043 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 02:30:53 visual_prompt]: Inference (test):avg data time: 5.49e-05, avg batch time: 0.2044, average loss: 1.1133
[09/28 02:30:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.05	top5: 93.61	
[09/28 02:30:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/28 02:31:02 visual_prompt]: Epoch 98 / 100: avg data time: 9.26e-02, avg batch time: 0.5208, average train loss: 0.0282
[09/28 02:31:05 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1776, average loss: 0.0242
[09/28 02:31:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:31:27 visual_prompt]: 	Test 100/157. loss: 0.960, 0.2042 s / batch. (data: 4.10e-05)max mem: 7.81378 GB 
[09/28 02:31:40 visual_prompt]: Inference (test):avg data time: 8.63e-05, avg batch time: 0.2045, average loss: 1.1123
[09/28 02:31:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.06	top5: 93.66	
[09/28 02:31:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/28 02:31:49 visual_prompt]: Epoch 99 / 100: avg data time: 9.52e-02, avg batch time: 0.5223, average train loss: 0.0281
[09/28 02:31:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1744, average loss: 0.0242
[09/28 02:31:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:32:14 visual_prompt]: 	Test 100/157. loss: 0.960, 0.2044 s / batch. (data: 5.29e-05)max mem: 7.81378 GB 
[09/28 02:32:26 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2044, average loss: 1.1123
[09/28 02:32:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.03	top5: 93.66	
[09/28 02:32:27 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/28 02:32:36 visual_prompt]: Epoch 100 / 100: avg data time: 1.01e-01, avg batch time: 0.5298, average train loss: 0.0283
[09/28 02:32:39 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1787, average loss: 0.0242
[09/28 02:32:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:33:01 visual_prompt]: 	Test 100/157. loss: 0.960, 0.2044 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 02:33:14 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2045, average loss: 1.1123
[09/28 02:33:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.66	
[09/28 02:33:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 02:33:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 02:33:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 02:33:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 02:33:14 visual_prompt]: Training with config:
[09/28 02:33:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/test/seed7190/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 7190, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 02:33:14 visual_prompt]: Loading training data...
[09/28 02:33:14 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800]+train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 02:33:15 visual_prompt]: Number of images: 1000
[09/28 02:33:15 visual_prompt]: Number of classes: 100 / 100
[09/28 02:33:15 visual_prompt]: Loading validation data...
[09/28 02:33:15 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 02:33:15 visual_prompt]: Number of images: 200
[09/28 02:33:15 visual_prompt]: Number of classes: 90 / 100
[09/28 02:33:15 visual_prompt]: Loading test data...
[09/28 02:33:15 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split test, from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 02:33:27 visual_prompt]: Number of images: 10000
[09/28 02:33:27 visual_prompt]: Number of classes: 100 / 100
[09/28 02:33:27 visual_prompt]: Constructing models...
[09/28 02:33:29 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/28 02:33:29 visual_prompt]: tuned percent:0.623
[09/28 02:33:30 visual_prompt]: Device used for model: 0
[09/28 02:33:30 visual_prompt]: Setting up Evaluator...
[09/28 02:33:30 visual_prompt]: Setting up Trainer...
[09/28 02:33:30 visual_prompt]: 	Setting up the optimizer...
[09/28 02:33:30 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 02:33:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e-01, avg batch time: 0.5298, average train loss: 4.6452
[09/28 02:33:42 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1847, average loss: 4.6636
[09/28 02:33:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/28 02:34:04 visual_prompt]: 	Test 100/157. loss: 4.621, 0.2024 s / batch. (data: 3.43e-05)max mem: 7.81378 GB 
[09/28 02:34:16 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2029, average loss: 4.6460
[09/28 02:34:16 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 0.93	top5: 5.26	
[09/28 02:34:16 visual_prompt]: Best epoch 1: best metric: 0.005
[09/28 02:34:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/28 02:34:26 visual_prompt]: Epoch 2 / 100: avg data time: 9.41e-02, avg batch time: 0.5200, average train loss: 4.6088
[09/28 02:34:28 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1801, average loss: 4.5566
[09/28 02:34:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/28 02:34:50 visual_prompt]: 	Test 100/157. loss: 4.624, 0.2050 s / batch. (data: 3.08e-05)max mem: 7.81378 GB 
[09/28 02:35:03 visual_prompt]: Inference (test):avg data time: 1.34e-04, avg batch time: 0.2040, average loss: 4.6149
[09/28 02:35:03 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.51	top5: 6.02	
[09/28 02:35:03 visual_prompt]: Best epoch 2: best metric: 0.010
[09/28 02:35:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/28 02:35:12 visual_prompt]: Epoch 3 / 100: avg data time: 9.77e-02, avg batch time: 0.5257, average train loss: 4.5600
[09/28 02:35:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1849, average loss: 4.4689
[09/28 02:35:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 15.00	
[09/28 02:35:37 visual_prompt]: 	Test 100/157. loss: 4.567, 0.2063 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 02:35:50 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2040, average loss: 4.5914
[09/28 02:35:50 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 2.42	top5: 11.03	
[09/28 02:35:50 visual_prompt]: Best epoch 3: best metric: 0.040
[09/28 02:35:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/28 02:35:59 visual_prompt]: Epoch 4 / 100: avg data time: 9.64e-02, avg batch time: 0.5240, average train loss: 4.3916
[09/28 02:36:02 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1847, average loss: 4.0653
[09/28 02:36:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 28.50	
[09/28 02:36:24 visual_prompt]: 	Test 100/157. loss: 4.410, 0.2039 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 02:36:37 visual_prompt]: Inference (test):avg data time: 1.56e-04, avg batch time: 0.2041, average loss: 4.2897
[09/28 02:36:37 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 5.32	top5: 20.27	
[09/28 02:36:37 visual_prompt]: Best epoch 4: best metric: 0.065
[09/28 02:36:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/28 02:36:46 visual_prompt]: Epoch 5 / 100: avg data time: 8.93e-02, avg batch time: 0.5155, average train loss: 4.0108
[09/28 02:36:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1808, average loss: 3.7462
[09/28 02:36:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.50	top5: 41.00	
[09/28 02:37:11 visual_prompt]: 	Test 100/157. loss: 3.829, 0.2043 s / batch. (data: 3.41e-05)max mem: 7.81378 GB 
[09/28 02:37:23 visual_prompt]: Inference (test):avg data time: 7.71e-05, avg batch time: 0.2043, average loss: 4.0950
[09/28 02:37:23 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 7.34	top5: 25.90	
[09/28 02:37:23 visual_prompt]: Best epoch 5: best metric: 0.135
[09/28 02:37:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/28 02:37:33 visual_prompt]: Epoch 6 / 100: avg data time: 9.54e-02, avg batch time: 0.5216, average train loss: 3.2191
[09/28 02:37:36 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1810, average loss: 2.6834
[09/28 02:37:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 31.50	top5: 67.00	
[09/28 02:37:58 visual_prompt]: 	Test 100/157. loss: 3.100, 0.2058 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 02:38:10 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2043, average loss: 3.2289
[09/28 02:38:10 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 19.82	top5: 49.89	
[09/28 02:38:10 visual_prompt]: Best epoch 6: best metric: 0.315
[09/28 02:38:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/28 02:38:20 visual_prompt]: Epoch 7 / 100: avg data time: 8.87e-02, avg batch time: 0.5183, average train loss: 2.2550
[09/28 02:38:23 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1761, average loss: 1.5164
[09/28 02:38:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 93.50	
[09/28 02:38:45 visual_prompt]: 	Test 100/157. loss: 2.412, 0.2054 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 02:38:57 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2043, average loss: 2.3495
[09/28 02:38:57 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 36.72	top5: 72.42	
[09/28 02:38:57 visual_prompt]: Best epoch 7: best metric: 0.580
[09/28 02:38:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/28 02:39:06 visual_prompt]: Epoch 8 / 100: avg data time: 9.64e-02, avg batch time: 0.5237, average train loss: 1.3705
[09/28 02:39:09 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1840, average loss: 0.7682
[09/28 02:39:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 84.50	top5: 98.50	
[09/28 02:39:32 visual_prompt]: 	Test 100/157. loss: 1.627, 0.2033 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 02:39:44 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2044, average loss: 1.7719
[09/28 02:39:44 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 53.00	top5: 84.17	
[09/28 02:39:44 visual_prompt]: Best epoch 8: best metric: 0.845
[09/28 02:39:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/28 02:39:53 visual_prompt]: Epoch 9 / 100: avg data time: 9.83e-02, avg batch time: 0.5269, average train loss: 0.7021
[09/28 02:39:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1799, average loss: 0.3663
[09/28 02:39:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 91.00	top5: 100.00	
[09/28 02:40:18 visual_prompt]: 	Test 100/157. loss: 1.404, 0.2046 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 02:40:31 visual_prompt]: Inference (test):avg data time: 1.60e-04, avg batch time: 0.2045, average loss: 1.4148
[09/28 02:40:31 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 61.46	top5: 88.97	
[09/28 02:40:31 visual_prompt]: Best epoch 9: best metric: 0.910
[09/28 02:40:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/28 02:40:40 visual_prompt]: Epoch 10 / 100: avg data time: 8.93e-02, avg batch time: 0.5185, average train loss: 0.3650
[09/28 02:40:43 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1816, average loss: 0.1794
[09/28 02:40:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.00	top5: 100.00	
[09/28 02:41:05 visual_prompt]: 	Test 100/157. loss: 1.216, 0.2038 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 02:41:18 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2041, average loss: 1.2516
[09/28 02:41:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 66.28	top5: 90.95	
[09/28 02:41:18 visual_prompt]: Best epoch 10: best metric: 0.980
[09/28 02:41:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/28 02:41:27 visual_prompt]: Epoch 11 / 100: avg data time: 9.36e-02, avg batch time: 0.5217, average train loss: 0.2083
[09/28 02:41:30 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1727, average loss: 0.0870
[09/28 02:41:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:41:52 visual_prompt]: 	Test 100/157. loss: 1.106, 0.2044 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 02:42:04 visual_prompt]: Inference (test):avg data time: 1.21e-04, avg batch time: 0.2047, average loss: 1.1306
[09/28 02:42:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.06	
[09/28 02:42:05 visual_prompt]: Best epoch 11: best metric: 1.000
[09/28 02:42:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/28 02:42:14 visual_prompt]: Epoch 12 / 100: avg data time: 1.00e-01, avg batch time: 0.5269, average train loss: 0.1306
[09/28 02:42:17 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1820, average loss: 0.0811
[09/28 02:42:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:42:39 visual_prompt]: 	Test 100/157. loss: 1.064, 0.2040 s / batch. (data: 2.67e-05)max mem: 7.81378 GB 
[09/28 02:42:51 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2045, average loss: 1.1271
[09/28 02:42:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.03	top5: 91.95	
[09/28 02:42:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/28 02:43:01 visual_prompt]: Epoch 13 / 100: avg data time: 9.52e-02, avg batch time: 0.5241, average train loss: 0.0964
[09/28 02:43:04 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1780, average loss: 0.0634
[09/28 02:43:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 02:43:26 visual_prompt]: 	Test 100/157. loss: 0.983, 0.2054 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 02:43:38 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2041, average loss: 1.0542
[09/28 02:43:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 71.97	top5: 92.92	
[09/28 02:43:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/28 02:43:48 visual_prompt]: Epoch 14 / 100: avg data time: 9.58e-02, avg batch time: 0.5240, average train loss: 0.0729
[09/28 02:43:51 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1804, average loss: 0.0538
[09/28 02:43:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 02:44:13 visual_prompt]: 	Test 100/157. loss: 1.058, 0.2043 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 02:44:25 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2043, average loss: 1.0454
[09/28 02:44:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.44	top5: 93.23	
[09/28 02:44:25 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/28 02:44:35 visual_prompt]: Epoch 15 / 100: avg data time: 1.04e-01, avg batch time: 0.5314, average train loss: 0.0690
[09/28 02:44:38 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1746, average loss: 0.0416
[09/28 02:44:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:45:00 visual_prompt]: 	Test 100/157. loss: 1.032, 0.2037 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 02:45:12 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2043, average loss: 1.0407
[09/28 02:45:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.74	top5: 93.17	
[09/28 02:45:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/28 02:45:22 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e-01, avg batch time: 0.5315, average train loss: 0.0607
[09/28 02:45:25 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1792, average loss: 0.0385
[09/28 02:45:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:45:47 visual_prompt]: 	Test 100/157. loss: 0.969, 0.2052 s / batch. (data: 3.31e-05)max mem: 7.81378 GB 
[09/28 02:45:59 visual_prompt]: Inference (test):avg data time: 1.05e-04, avg batch time: 0.2045, average loss: 1.0053
[09/28 02:45:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.59	top5: 93.66	
[09/28 02:45:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/28 02:46:09 visual_prompt]: Epoch 17 / 100: avg data time: 9.79e-02, avg batch time: 0.5238, average train loss: 0.0543
[09/28 02:46:12 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1794, average loss: 0.0367
[09/28 02:46:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:46:34 visual_prompt]: 	Test 100/157. loss: 1.018, 0.2051 s / batch. (data: 2.96e-05)max mem: 7.81378 GB 
[09/28 02:46:46 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2043, average loss: 1.0279
[09/28 02:46:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.76	top5: 93.57	
[09/28 02:46:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/28 02:46:56 visual_prompt]: Epoch 18 / 100: avg data time: 9.39e-02, avg batch time: 0.5228, average train loss: 0.0541
[09/28 02:46:59 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1820, average loss: 0.0386
[09/28 02:46:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:47:21 visual_prompt]: 	Test 100/157. loss: 0.963, 0.2057 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 02:47:33 visual_prompt]: Inference (test):avg data time: 9.07e-05, avg batch time: 0.2042, average loss: 1.0325
[09/28 02:47:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.29	top5: 93.72	
[09/28 02:47:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/28 02:47:43 visual_prompt]: Epoch 19 / 100: avg data time: 9.58e-02, avg batch time: 0.5231, average train loss: 0.0535
[09/28 02:47:46 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1814, average loss: 0.0385
[09/28 02:47:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:48:08 visual_prompt]: 	Test 100/157. loss: 1.035, 0.2034 s / batch. (data: 2.96e-05)max mem: 7.81378 GB 
[09/28 02:48:20 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2044, average loss: 1.0145
[09/28 02:48:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.80	top5: 93.82	
[09/28 02:48:20 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/28 02:48:30 visual_prompt]: Epoch 20 / 100: avg data time: 9.16e-02, avg batch time: 0.5215, average train loss: 0.0572
[09/28 02:48:32 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1726, average loss: 0.0385
[09/28 02:48:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:48:55 visual_prompt]: 	Test 100/157. loss: 1.088, 0.2038 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 02:49:07 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2043, average loss: 1.0311
[09/28 02:49:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.36	top5: 93.55	
[09/28 02:49:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/28 02:49:17 visual_prompt]: Epoch 21 / 100: avg data time: 9.85e-02, avg batch time: 0.5273, average train loss: 0.0695
[09/28 02:49:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1798, average loss: 0.0965
[09/28 02:49:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 02:49:42 visual_prompt]: 	Test 100/157. loss: 1.359, 0.2057 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 02:49:54 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2045, average loss: 1.2124
[09/28 02:49:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 69.13	top5: 91.72	
[09/28 02:49:54 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/28 02:50:04 visual_prompt]: Epoch 22 / 100: avg data time: 8.76e-02, avg batch time: 0.5175, average train loss: 0.2111
[09/28 02:50:07 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1836, average loss: 0.2683
[09/28 02:50:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.00	top5: 100.00	
[09/28 02:50:29 visual_prompt]: 	Test 100/157. loss: 1.388, 0.2061 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 02:50:41 visual_prompt]: Inference (test):avg data time: 1.47e-04, avg batch time: 0.2044, average loss: 1.3736
[09/28 02:50:41 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 66.28	top5: 90.23	
[09/28 02:50:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/28 02:50:51 visual_prompt]: Epoch 23 / 100: avg data time: 9.90e-02, avg batch time: 0.5258, average train loss: 1.4193
[09/28 02:50:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1843, average loss: 1.2584
[09/28 02:50:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.50	
[09/28 02:51:16 visual_prompt]: 	Test 100/157. loss: 1.876, 0.2053 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 02:51:28 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2043, average loss: 1.9201
[09/28 02:51:28 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 57.51	top5: 84.14	
[09/28 02:51:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/28 02:51:37 visual_prompt]: Epoch 24 / 100: avg data time: 9.74e-02, avg batch time: 0.5260, average train loss: 2.3434
[09/28 02:51:40 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1740, average loss: 0.7372
[09/28 02:51:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 89.50	top5: 98.00	
[09/28 02:52:03 visual_prompt]: 	Test 100/157. loss: 1.489, 0.2049 s / batch. (data: 3.15e-05)max mem: 7.81378 GB 
[09/28 02:52:15 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2043, average loss: 1.4911
[09/28 02:52:15 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 65.30	top5: 89.27	
[09/28 02:52:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/28 02:52:24 visual_prompt]: Epoch 25 / 100: avg data time: 8.48e-02, avg batch time: 0.5151, average train loss: 0.5189
[09/28 02:52:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1751, average loss: 0.2026
[09/28 02:52:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.50	top5: 100.00	
[09/28 02:52:49 visual_prompt]: 	Test 100/157. loss: 1.005, 0.2052 s / batch. (data: 3.08e-05)max mem: 7.81378 GB 
[09/28 02:53:02 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2044, average loss: 1.0211
[09/28 02:53:02 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.66	top5: 93.92	
[09/28 02:53:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/28 02:53:11 visual_prompt]: Epoch 26 / 100: avg data time: 9.08e-02, avg batch time: 0.5179, average train loss: 0.1939
[09/28 02:53:14 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1831, average loss: 0.0947
[09/28 02:53:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:53:36 visual_prompt]: 	Test 100/157. loss: 0.925, 0.2051 s / batch. (data: 3.65e-05)max mem: 7.81378 GB 
[09/28 02:53:49 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2043, average loss: 0.9047
[09/28 02:53:49 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.11	top5: 94.91	
[09/28 02:53:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/28 02:53:58 visual_prompt]: Epoch 27 / 100: avg data time: 9.78e-02, avg batch time: 0.5259, average train loss: 0.0965
[09/28 02:54:01 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1793, average loss: 0.0597
[09/28 02:54:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:54:23 visual_prompt]: 	Test 100/157. loss: 0.919, 0.2036 s / batch. (data: 3.08e-05)max mem: 7.81378 GB 
[09/28 02:54:35 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2043, average loss: 0.8704
[09/28 02:54:36 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.08	top5: 95.29	
[09/28 02:54:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/28 02:54:45 visual_prompt]: Epoch 28 / 100: avg data time: 9.28e-02, avg batch time: 0.5196, average train loss: 0.0681
[09/28 02:54:48 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1825, average loss: 0.0500
[09/28 02:54:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:55:10 visual_prompt]: 	Test 100/157. loss: 0.870, 0.2042 s / batch. (data: 2.38e-05)max mem: 7.81378 GB 
[09/28 02:55:22 visual_prompt]: Inference (test):avg data time: 5.03e-05, avg batch time: 0.2042, average loss: 0.8582
[09/28 02:55:23 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.49	top5: 95.68	
[09/28 02:55:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/28 02:55:32 visual_prompt]: Epoch 29 / 100: avg data time: 9.75e-02, avg batch time: 0.5256, average train loss: 0.0581
[09/28 02:55:35 visual_prompt]: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1825, average loss: 0.0438
[09/28 02:55:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:55:57 visual_prompt]: 	Test 100/157. loss: 0.883, 0.2055 s / batch. (data: 2.74e-05)max mem: 7.81378 GB 
[09/28 02:56:09 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2042, average loss: 0.8411
[09/28 02:56:09 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.08	top5: 95.94	
[09/28 02:56:09 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/28 02:56:19 visual_prompt]: Epoch 30 / 100: avg data time: 9.79e-02, avg batch time: 0.5241, average train loss: 0.0524
[09/28 02:56:22 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1725, average loss: 0.0412
[09/28 02:56:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:56:44 visual_prompt]: 	Test 100/157. loss: 0.940, 0.2047 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 02:56:56 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2044, average loss: 0.8479
[09/28 02:56:56 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.79	top5: 95.97	
[09/28 02:56:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/28 02:57:06 visual_prompt]: Epoch 31 / 100: avg data time: 9.64e-02, avg batch time: 0.5238, average train loss: 0.0545
[09/28 02:57:09 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1787, average loss: 0.0428
[09/28 02:57:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:57:31 visual_prompt]: 	Test 100/157. loss: 0.911, 0.2054 s / batch. (data: 3.43e-05)max mem: 7.81378 GB 
[09/28 02:57:43 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2042, average loss: 0.8645
[09/28 02:57:43 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.13	top5: 95.79	
[09/28 02:57:43 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/28 02:57:53 visual_prompt]: Epoch 32 / 100: avg data time: 8.83e-02, avg batch time: 0.5153, average train loss: 0.0528
[09/28 02:57:56 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1830, average loss: 0.0409
[09/28 02:57:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:58:18 visual_prompt]: 	Test 100/157. loss: 0.877, 0.2110 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 02:58:30 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2045, average loss: 0.8647
[09/28 02:58:30 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.69	top5: 95.83	
[09/28 02:58:30 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/28 02:58:40 visual_prompt]: Epoch 33 / 100: avg data time: 1.02e-01, avg batch time: 0.5292, average train loss: 0.0531
[09/28 02:58:42 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1810, average loss: 0.0393
[09/28 02:58:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:59:04 visual_prompt]: 	Test 100/157. loss: 0.930, 0.2062 s / batch. (data: 3.53e-05)max mem: 7.81378 GB 
[09/28 02:59:17 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2045, average loss: 0.8634
[09/28 02:59:17 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.78	top5: 96.09	
[09/28 02:59:17 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/28 02:59:26 visual_prompt]: Epoch 34 / 100: avg data time: 9.47e-02, avg batch time: 0.5226, average train loss: 0.0511
[09/28 02:59:29 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1855, average loss: 0.0376
[09/28 02:59:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 02:59:51 visual_prompt]: 	Test 100/157. loss: 0.908, 0.2044 s / batch. (data: 3.27e-05)max mem: 7.81378 GB 
[09/28 03:00:04 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2043, average loss: 0.8675
[09/28 03:00:04 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.49	top5: 95.81	
[09/28 03:00:04 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/28 03:00:13 visual_prompt]: Epoch 35 / 100: avg data time: 9.03e-02, avg batch time: 0.5192, average train loss: 0.0489
[09/28 03:00:16 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1839, average loss: 0.0377
[09/28 03:00:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:00:38 visual_prompt]: 	Test 100/157. loss: 0.936, 0.2035 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 03:00:51 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2042, average loss: 0.8724
[09/28 03:00:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.27	top5: 95.71	
[09/28 03:00:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/28 03:01:00 visual_prompt]: Epoch 36 / 100: avg data time: 9.61e-02, avg batch time: 0.5244, average train loss: 0.0489
[09/28 03:01:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1788, average loss: 0.0364
[09/28 03:01:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:01:25 visual_prompt]: 	Test 100/157. loss: 0.970, 0.2053 s / batch. (data: 3.36e-05)max mem: 7.81378 GB 
[09/28 03:01:38 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2041, average loss: 0.8823
[09/28 03:01:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.42	top5: 95.69	
[09/28 03:01:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/28 03:01:47 visual_prompt]: Epoch 37 / 100: avg data time: 9.44e-02, avg batch time: 0.5228, average train loss: 0.0472
[09/28 03:01:50 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1750, average loss: 0.0401
[09/28 03:01:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:02:12 visual_prompt]: 	Test 100/157. loss: 0.977, 0.2047 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 03:02:25 visual_prompt]: Inference (test):avg data time: 3.14e-04, avg batch time: 0.2047, average loss: 0.9072
[09/28 03:02:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.69	top5: 95.58	
[09/28 03:02:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/28 03:02:34 visual_prompt]: Epoch 38 / 100: avg data time: 8.99e-02, avg batch time: 0.5197, average train loss: 0.0630
[09/28 03:02:37 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1753, average loss: 0.0564
[09/28 03:02:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 03:02:59 visual_prompt]: 	Test 100/157. loss: 0.958, 0.2040 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 03:03:11 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2046, average loss: 0.9123
[09/28 03:03:11 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.88	top5: 95.49	
[09/28 03:03:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/28 03:03:21 visual_prompt]: Epoch 39 / 100: avg data time: 9.87e-02, avg batch time: 0.5278, average train loss: 0.0755
[09/28 03:03:23 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1755, average loss: 0.0577
[09/28 03:03:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:03:46 visual_prompt]: 	Test 100/157. loss: 1.024, 0.2042 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 03:03:58 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2042, average loss: 0.9400
[09/28 03:03:58 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.17	top5: 95.24	
[09/28 03:03:58 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/28 03:04:08 visual_prompt]: Epoch 40 / 100: avg data time: 9.64e-02, avg batch time: 0.5287, average train loss: 0.0872
[09/28 03:04:11 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1838, average loss: 0.1127
[09/28 03:04:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.50	top5: 100.00	
[09/28 03:04:33 visual_prompt]: 	Test 100/157. loss: 1.017, 0.2050 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 03:04:45 visual_prompt]: Inference (test):avg data time: 3.07e-04, avg batch time: 0.2045, average loss: 0.9906
[09/28 03:04:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.55	top5: 94.70	
[09/28 03:04:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/28 03:04:54 visual_prompt]: Epoch 41 / 100: avg data time: 9.45e-02, avg batch time: 0.5219, average train loss: 0.1911
[09/28 03:04:57 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1738, average loss: 0.1567
[09/28 03:04:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.50	top5: 100.00	
[09/28 03:05:19 visual_prompt]: 	Test 100/157. loss: 0.967, 0.2047 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 03:05:32 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2039, average loss: 1.0440
[09/28 03:05:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.53	top5: 94.39	
[09/28 03:05:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/28 03:05:41 visual_prompt]: Epoch 42 / 100: avg data time: 9.22e-02, avg batch time: 0.5200, average train loss: 0.1908
[09/28 03:05:44 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1754, average loss: 0.0944
[09/28 03:05:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:06:06 visual_prompt]: 	Test 100/157. loss: 0.922, 0.2053 s / batch. (data: 3.27e-05)max mem: 7.81378 GB 
[09/28 03:06:19 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2042, average loss: 0.9068
[09/28 03:06:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.67	top5: 95.59	
[09/28 03:06:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/28 03:06:28 visual_prompt]: Epoch 43 / 100: avg data time: 9.03e-02, avg batch time: 0.5181, average train loss: 0.1145
[09/28 03:06:31 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1826, average loss: 0.0751
[09/28 03:06:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 03:06:53 visual_prompt]: 	Test 100/157. loss: 1.040, 0.2042 s / batch. (data: 3.34e-05)max mem: 7.81378 GB 
[09/28 03:07:05 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2044, average loss: 0.8994
[09/28 03:07:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.25	top5: 95.53	
[09/28 03:07:06 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/28 03:07:15 visual_prompt]: Epoch 44 / 100: avg data time: 9.85e-02, avg batch time: 0.5271, average train loss: 0.0736
[09/28 03:07:18 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1770, average loss: 0.0488
[09/28 03:07:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:07:40 visual_prompt]: 	Test 100/157. loss: 0.976, 0.2057 s / batch. (data: 2.48e-05)max mem: 7.81378 GB 
[09/28 03:07:52 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2043, average loss: 0.8426
[09/28 03:07:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.71	top5: 95.87	
[09/28 03:07:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/28 03:08:02 visual_prompt]: Epoch 45 / 100: avg data time: 9.62e-02, avg batch time: 0.5219, average train loss: 0.0505
[09/28 03:08:05 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1751, average loss: 0.0312
[09/28 03:08:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:08:27 visual_prompt]: 	Test 100/157. loss: 0.927, 0.2039 s / batch. (data: 2.96e-05)max mem: 7.81378 GB 
[09/28 03:08:39 visual_prompt]: Inference (test):avg data time: 5.89e-05, avg batch time: 0.2043, average loss: 0.8236
[09/28 03:08:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.01	top5: 96.11	
[09/28 03:08:39 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/28 03:08:49 visual_prompt]: Epoch 46 / 100: avg data time: 9.67e-02, avg batch time: 0.5238, average train loss: 0.0376
[09/28 03:08:51 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1863, average loss: 0.0267
[09/28 03:08:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:09:14 visual_prompt]: 	Test 100/157. loss: 0.860, 0.2050 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 03:09:26 visual_prompt]: Inference (test):avg data time: 5.55e-05, avg batch time: 0.2047, average loss: 0.7967
[09/28 03:09:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.61	top5: 96.38	
[09/28 03:09:26 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/28 03:09:35 visual_prompt]: Epoch 47 / 100: avg data time: 9.20e-02, avg batch time: 0.5214, average train loss: 0.0337
[09/28 03:09:38 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1842, average loss: 0.0266
[09/28 03:09:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:10:00 visual_prompt]: 	Test 100/157. loss: 0.891, 0.2062 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 03:10:13 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2058, average loss: 0.8095
[09/28 03:10:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.33	top5: 96.39	
[09/28 03:10:13 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/28 03:10:22 visual_prompt]: Epoch 48 / 100: avg data time: 8.45e-02, avg batch time: 0.5174, average train loss: 0.0329
[09/28 03:10:25 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1791, average loss: 0.0263
[09/28 03:10:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:10:47 visual_prompt]: 	Test 100/157. loss: 0.867, 0.2086 s / batch. (data: 8.70e-05)max mem: 7.81378 GB 
[09/28 03:11:00 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2060, average loss: 0.8169
[09/28 03:11:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.35	top5: 96.33	
[09/28 03:11:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/28 03:11:09 visual_prompt]: Epoch 49 / 100: avg data time: 9.56e-02, avg batch time: 0.5259, average train loss: 0.0325
[09/28 03:11:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1794, average loss: 0.0270
[09/28 03:11:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:11:34 visual_prompt]: 	Test 100/157. loss: 0.875, 0.2067 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 03:11:47 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2057, average loss: 0.8169
[09/28 03:11:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.26	top5: 96.31	
[09/28 03:11:47 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/28 03:11:56 visual_prompt]: Epoch 50 / 100: avg data time: 8.89e-02, avg batch time: 0.5147, average train loss: 0.0333
[09/28 03:11:59 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1804, average loss: 0.0272
[09/28 03:11:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:12:21 visual_prompt]: 	Test 100/157. loss: 0.866, 0.2069 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 03:12:34 visual_prompt]: Inference (test):avg data time: 1.19e-04, avg batch time: 0.2057, average loss: 0.8276
[09/28 03:12:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.79	top5: 96.24	
[09/28 03:12:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/28 03:12:43 visual_prompt]: Epoch 51 / 100: avg data time: 8.79e-02, avg batch time: 0.5178, average train loss: 0.0340
[09/28 03:12:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1834, average loss: 0.0276
[09/28 03:12:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:13:08 visual_prompt]: 	Test 100/157. loss: 0.855, 0.2044 s / batch. (data: 2.60e-05)max mem: 7.81378 GB 
[09/28 03:13:21 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2051, average loss: 0.8489
[09/28 03:13:21 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.37	top5: 96.13	
[09/28 03:13:21 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/28 03:13:30 visual_prompt]: Epoch 52 / 100: avg data time: 9.41e-02, avg batch time: 0.5228, average train loss: 0.0340
[09/28 03:13:33 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1778, average loss: 0.0282
[09/28 03:13:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:13:55 visual_prompt]: 	Test 100/157. loss: 0.881, 0.2051 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 03:14:07 visual_prompt]: Inference (test):avg data time: 1.28e-04, avg batch time: 0.2044, average loss: 0.8538
[09/28 03:14:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.55	top5: 95.97	
[09/28 03:14:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/28 03:14:17 visual_prompt]: Epoch 53 / 100: avg data time: 8.94e-02, avg batch time: 0.5176, average train loss: 0.0340
[09/28 03:14:19 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1742, average loss: 0.0284
[09/28 03:14:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:14:41 visual_prompt]: 	Test 100/157. loss: 0.842, 0.2050 s / batch. (data: 2.43e-05)max mem: 7.81378 GB 
[09/28 03:14:54 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2041, average loss: 0.8751
[09/28 03:14:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.84	top5: 95.91	
[09/28 03:14:54 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/28 03:15:03 visual_prompt]: Epoch 54 / 100: avg data time: 9.60e-02, avg batch time: 0.5226, average train loss: 0.0334
[09/28 03:15:06 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1824, average loss: 0.0282
[09/28 03:15:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:15:28 visual_prompt]: 	Test 100/157. loss: 0.851, 0.2043 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 03:15:41 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2042, average loss: 0.8758
[09/28 03:15:41 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.08	top5: 95.79	
[09/28 03:15:41 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/28 03:15:50 visual_prompt]: Epoch 55 / 100: avg data time: 9.00e-02, avg batch time: 0.5162, average train loss: 0.0342
[09/28 03:15:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1824, average loss: 0.0286
[09/28 03:15:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:16:15 visual_prompt]: 	Test 100/157. loss: 0.849, 0.2047 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 03:16:27 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2044, average loss: 0.8853
[09/28 03:16:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.65	top5: 95.81	
[09/28 03:16:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/28 03:16:36 visual_prompt]: Epoch 56 / 100: avg data time: 9.61e-02, avg batch time: 0.5218, average train loss: 0.0334
[09/28 03:16:39 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1795, average loss: 0.0285
[09/28 03:16:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:17:01 visual_prompt]: 	Test 100/157. loss: 0.839, 0.2043 s / batch. (data: 2.46e-05)max mem: 7.81378 GB 
[09/28 03:17:14 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2043, average loss: 0.8961
[09/28 03:17:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.35	top5: 95.84	
[09/28 03:17:14 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/28 03:17:23 visual_prompt]: Epoch 57 / 100: avg data time: 9.23e-02, avg batch time: 0.5208, average train loss: 0.0338
[09/28 03:17:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1771, average loss: 0.0279
[09/28 03:17:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:17:48 visual_prompt]: 	Test 100/157. loss: 0.832, 0.2049 s / batch. (data: 2.53e-05)max mem: 7.81378 GB 
[09/28 03:18:00 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2039, average loss: 0.8845
[09/28 03:18:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.65	top5: 95.71	
[09/28 03:18:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/28 03:18:10 visual_prompt]: Epoch 58 / 100: avg data time: 8.72e-02, avg batch time: 0.5159, average train loss: 0.0344
[09/28 03:18:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1793, average loss: 0.0288
[09/28 03:18:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:18:35 visual_prompt]: 	Test 100/157. loss: 0.931, 0.2053 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 03:18:47 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2043, average loss: 0.9024
[09/28 03:18:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.35	top5: 95.60	
[09/28 03:18:47 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/28 03:18:56 visual_prompt]: Epoch 59 / 100: avg data time: 9.76e-02, avg batch time: 0.5254, average train loss: 0.0339
[09/28 03:18:59 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1734, average loss: 0.0270
[09/28 03:18:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:19:21 visual_prompt]: 	Test 100/157. loss: 0.807, 0.2049 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 03:19:34 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2041, average loss: 0.9012
[09/28 03:19:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.56	top5: 95.72	
[09/28 03:19:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/28 03:19:43 visual_prompt]: Epoch 60 / 100: avg data time: 9.09e-02, avg batch time: 0.5187, average train loss: 0.0329
[09/28 03:19:46 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1776, average loss: 0.0270
[09/28 03:19:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:20:08 visual_prompt]: 	Test 100/157. loss: 0.896, 0.2037 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 03:20:21 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2042, average loss: 0.9087
[09/28 03:20:21 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.30	top5: 95.58	
[09/28 03:20:21 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/28 03:20:30 visual_prompt]: Epoch 61 / 100: avg data time: 9.39e-02, avg batch time: 0.5205, average train loss: 0.0328
[09/28 03:20:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1755, average loss: 0.0268
[09/28 03:20:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:20:55 visual_prompt]: 	Test 100/157. loss: 0.802, 0.2047 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 03:21:07 visual_prompt]: Inference (test):avg data time: 1.36e-04, avg batch time: 0.2044, average loss: 0.9181
[09/28 03:21:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.99	top5: 95.58	
[09/28 03:21:07 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/28 03:21:16 visual_prompt]: Epoch 62 / 100: avg data time: 8.62e-02, avg batch time: 0.5128, average train loss: 0.0324
[09/28 03:21:19 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1768, average loss: 0.0272
[09/28 03:21:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:21:41 visual_prompt]: 	Test 100/157. loss: 0.893, 0.2043 s / batch. (data: 2.53e-05)max mem: 7.81378 GB 
[09/28 03:21:54 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2044, average loss: 0.9221
[09/28 03:21:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.78	top5: 95.51	
[09/28 03:21:54 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/28 03:22:03 visual_prompt]: Epoch 63 / 100: avg data time: 9.86e-02, avg batch time: 0.5270, average train loss: 0.0324
[09/28 03:22:06 visual_prompt]: Inference (val):avg data time: 4.96e-05, avg batch time: 0.1759, average loss: 0.0270
[09/28 03:22:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:22:28 visual_prompt]: 	Test 100/157. loss: 0.822, 0.2041 s / batch. (data: 2.62e-05)max mem: 7.81378 GB 
[09/28 03:22:40 visual_prompt]: Inference (test):avg data time: 6.06e-05, avg batch time: 0.2044, average loss: 0.9417
[09/28 03:22:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.57	top5: 95.35	
[09/28 03:22:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/28 03:22:50 visual_prompt]: Epoch 64 / 100: avg data time: 9.54e-02, avg batch time: 0.5236, average train loss: 0.0324
[09/28 03:22:52 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1852, average loss: 0.0267
[09/28 03:22:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:23:15 visual_prompt]: 	Test 100/157. loss: 0.803, 0.2057 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 03:23:27 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2044, average loss: 0.9556
[09/28 03:23:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.57	top5: 95.40	
[09/28 03:23:27 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/28 03:23:36 visual_prompt]: Epoch 65 / 100: avg data time: 9.18e-02, avg batch time: 0.5199, average train loss: 0.0318
[09/28 03:23:39 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1849, average loss: 0.0260
[09/28 03:23:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:24:01 visual_prompt]: 	Test 100/157. loss: 0.923, 0.2037 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 03:24:14 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2044, average loss: 0.9684
[09/28 03:24:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.29	top5: 95.19	
[09/28 03:24:14 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/28 03:24:23 visual_prompt]: Epoch 66 / 100: avg data time: 9.45e-02, avg batch time: 0.5204, average train loss: 0.0309
[09/28 03:24:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1742, average loss: 0.0249
[09/28 03:24:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:24:48 visual_prompt]: 	Test 100/157. loss: 0.823, 0.2043 s / batch. (data: 3.77e-05)max mem: 7.81378 GB 
[09/28 03:25:00 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2042, average loss: 0.9545
[09/28 03:25:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.55	top5: 95.31	
[09/28 03:25:00 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/28 03:25:10 visual_prompt]: Epoch 67 / 100: avg data time: 9.02e-02, avg batch time: 0.5171, average train loss: 0.0305
[09/28 03:25:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1848, average loss: 0.0258
[09/28 03:25:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:25:35 visual_prompt]: 	Test 100/157. loss: 0.875, 0.2054 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 03:25:47 visual_prompt]: Inference (test):avg data time: 2.92e-05, avg batch time: 0.2045, average loss: 0.9831
[09/28 03:25:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.15	top5: 95.07	
[09/28 03:25:47 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/28 03:25:56 visual_prompt]: Epoch 68 / 100: avg data time: 8.31e-02, avg batch time: 0.5088, average train loss: 0.0361
[09/28 03:25:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1763, average loss: 0.0301
[09/28 03:25:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:26:21 visual_prompt]: 	Test 100/157. loss: 0.865, 0.2046 s / batch. (data: 3.05e-05)max mem: 7.81378 GB 
[09/28 03:26:33 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2043, average loss: 0.9703
[09/28 03:26:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.39	top5: 95.40	
[09/28 03:26:34 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/28 03:26:43 visual_prompt]: Epoch 69 / 100: avg data time: 8.42e-02, avg batch time: 0.5122, average train loss: 0.0404
[09/28 03:26:45 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1822, average loss: 0.0588
[09/28 03:26:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 03:27:08 visual_prompt]: 	Test 100/157. loss: 1.107, 0.2048 s / batch. (data: 2.69e-05)max mem: 7.81378 GB 
[09/28 03:27:20 visual_prompt]: Inference (test):avg data time: 4.44e-05, avg batch time: 0.2043, average loss: 1.0065
[09/28 03:27:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.29	top5: 95.15	
[09/28 03:27:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/28 03:27:29 visual_prompt]: Epoch 70 / 100: avg data time: 8.35e-02, avg batch time: 0.5118, average train loss: 0.3145
[09/28 03:27:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1801, average loss: 1.5757
[09/28 03:27:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 89.50	
[09/28 03:27:54 visual_prompt]: 	Test 100/157. loss: 2.335, 0.2047 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 03:28:07 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2041, average loss: 2.2915
[09/28 03:28:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 54.86	top5: 77.94	
[09/28 03:28:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/28 03:28:16 visual_prompt]: Epoch 71 / 100: avg data time: 8.67e-02, avg batch time: 0.5140, average train loss: 0.6814
[09/28 03:28:19 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1747, average loss: 0.3542
[09/28 03:28:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.00	top5: 100.00	
[09/28 03:28:41 visual_prompt]: 	Test 100/157. loss: 1.166, 0.2037 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 03:28:53 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2046, average loss: 1.1140
[09/28 03:28:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.90	top5: 95.04	
[09/28 03:28:54 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/28 03:29:03 visual_prompt]: Epoch 72 / 100: avg data time: 8.28e-02, avg batch time: 0.5104, average train loss: 0.2970
[09/28 03:29:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1741, average loss: 0.1503
[09/28 03:29:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:29:27 visual_prompt]: 	Test 100/157. loss: 0.848, 0.2045 s / batch. (data: 2.57e-05)max mem: 7.81378 GB 
[09/28 03:29:40 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.2042, average loss: 0.8935
[09/28 03:29:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.16	
[09/28 03:29:40 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/28 03:29:49 visual_prompt]: Epoch 73 / 100: avg data time: 9.14e-02, avg batch time: 0.5208, average train loss: 0.1409
[09/28 03:29:52 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1815, average loss: 0.0896
[09/28 03:29:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:30:14 visual_prompt]: 	Test 100/157. loss: 0.721, 0.2044 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 03:30:27 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2043, average loss: 0.8338
[09/28 03:30:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.24	top5: 96.52	
[09/28 03:30:27 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/28 03:30:36 visual_prompt]: Epoch 74 / 100: avg data time: 9.65e-02, avg batch time: 0.5224, average train loss: 0.0839
[09/28 03:30:39 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1789, average loss: 0.0549
[09/28 03:30:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:31:01 visual_prompt]: 	Test 100/157. loss: 0.720, 0.2051 s / batch. (data: 2.74e-05)max mem: 7.81378 GB 
[09/28 03:31:13 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2043, average loss: 0.8041
[09/28 03:31:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.48	top5: 96.63	
[09/28 03:31:14 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/28 03:31:23 visual_prompt]: Epoch 75 / 100: avg data time: 9.04e-02, avg batch time: 0.5182, average train loss: 0.0591
[09/28 03:31:25 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1820, average loss: 0.0428
[09/28 03:31:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:31:48 visual_prompt]: 	Test 100/157. loss: 0.725, 0.2042 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 03:32:00 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2041, average loss: 0.7885
[09/28 03:32:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 80.30	top5: 96.42	
[09/28 03:32:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/28 03:32:09 visual_prompt]: Epoch 76 / 100: avg data time: 8.80e-02, avg batch time: 0.5134, average train loss: 0.0482
[09/28 03:32:12 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1738, average loss: 0.0374
[09/28 03:32:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:32:34 visual_prompt]: 	Test 100/157. loss: 0.712, 0.2066 s / batch. (data: 2.69e-05)max mem: 7.81378 GB 
[09/28 03:32:47 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2040, average loss: 0.7901
[09/28 03:32:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 80.05	top5: 96.57	
[09/28 03:32:47 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/28 03:32:56 visual_prompt]: Epoch 77 / 100: avg data time: 9.03e-02, avg batch time: 0.5173, average train loss: 0.0413
[09/28 03:32:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1740, average loss: 0.0345
[09/28 03:32:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:33:21 visual_prompt]: 	Test 100/157. loss: 0.676, 0.2051 s / batch. (data: 2.67e-05)max mem: 7.81378 GB 
[09/28 03:33:33 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2041, average loss: 0.7912
[09/28 03:33:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.74	top5: 96.45	
[09/28 03:33:33 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/28 03:33:42 visual_prompt]: Epoch 78 / 100: avg data time: 8.90e-02, avg batch time: 0.5164, average train loss: 0.0386
[09/28 03:33:45 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1769, average loss: 0.0322
[09/28 03:33:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:34:07 visual_prompt]: 	Test 100/157. loss: 0.665, 0.2052 s / batch. (data: 3.27e-05)max mem: 7.81378 GB 
[09/28 03:34:20 visual_prompt]: Inference (test):avg data time: 1.35e-04, avg batch time: 0.2043, average loss: 0.7941
[09/28 03:34:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.81	top5: 96.48	
[09/28 03:34:20 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/28 03:34:29 visual_prompt]: Epoch 79 / 100: avg data time: 8.19e-02, avg batch time: 0.5078, average train loss: 0.0364
[09/28 03:34:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1732, average loss: 0.0313
[09/28 03:34:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:34:53 visual_prompt]: 	Test 100/157. loss: 0.681, 0.2050 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 03:35:06 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2044, average loss: 0.7968
[09/28 03:35:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.67	top5: 96.48	
[09/28 03:35:06 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/28 03:35:15 visual_prompt]: Epoch 80 / 100: avg data time: 9.76e-02, avg batch time: 0.5261, average train loss: 0.0349
[09/28 03:35:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1795, average loss: 0.0298
[09/28 03:35:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:35:40 visual_prompt]: 	Test 100/157. loss: 0.666, 0.2048 s / batch. (data: 2.57e-05)max mem: 7.81378 GB 
[09/28 03:35:53 visual_prompt]: Inference (test):avg data time: 1.37e-04, avg batch time: 0.2047, average loss: 0.7991
[09/28 03:35:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.53	top5: 96.43	
[09/28 03:35:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/28 03:36:02 visual_prompt]: Epoch 81 / 100: avg data time: 8.56e-02, avg batch time: 0.5120, average train loss: 0.0342
[09/28 03:36:05 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1832, average loss: 0.0292
[09/28 03:36:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:36:27 visual_prompt]: 	Test 100/157. loss: 0.649, 0.2051 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 03:36:39 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2040, average loss: 0.8007
[09/28 03:36:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.53	top5: 96.34	
[09/28 03:36:39 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/28 03:36:48 visual_prompt]: Epoch 82 / 100: avg data time: 8.88e-02, avg batch time: 0.5161, average train loss: 0.0337
[09/28 03:36:51 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1740, average loss: 0.0287
[09/28 03:36:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:37:13 visual_prompt]: 	Test 100/157. loss: 0.657, 0.2048 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 03:37:26 visual_prompt]: Inference (test):avg data time: 5.62e-05, avg batch time: 0.2046, average loss: 0.8034
[09/28 03:37:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.49	top5: 96.34	
[09/28 03:37:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/28 03:37:35 visual_prompt]: Epoch 83 / 100: avg data time: 9.18e-02, avg batch time: 0.5191, average train loss: 0.0326
[09/28 03:37:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1832, average loss: 0.0282
[09/28 03:37:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:38:00 visual_prompt]: 	Test 100/157. loss: 0.671, 0.2032 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 03:38:12 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2042, average loss: 0.8046
[09/28 03:38:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.58	top5: 96.36	
[09/28 03:38:12 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/28 03:38:21 visual_prompt]: Epoch 84 / 100: avg data time: 7.76e-02, avg batch time: 0.5053, average train loss: 0.0321
[09/28 03:38:24 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1751, average loss: 0.0278
[09/28 03:38:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:38:46 visual_prompt]: 	Test 100/157. loss: 0.648, 0.2036 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 03:38:59 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2040, average loss: 0.8092
[09/28 03:38:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.53	top5: 96.36	
[09/28 03:38:59 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/28 03:39:08 visual_prompt]: Epoch 85 / 100: avg data time: 9.45e-02, avg batch time: 0.5220, average train loss: 0.0318
[09/28 03:39:11 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1778, average loss: 0.0276
[09/28 03:39:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:39:33 visual_prompt]: 	Test 100/157. loss: 0.647, 0.2041 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 03:39:45 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2044, average loss: 0.8084
[09/28 03:39:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.64	top5: 96.28	
[09/28 03:39:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/28 03:39:54 visual_prompt]: Epoch 86 / 100: avg data time: 8.92e-02, avg batch time: 0.5156, average train loss: 0.0315
[09/28 03:39:57 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1747, average loss: 0.0273
[09/28 03:39:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:40:19 visual_prompt]: 	Test 100/157. loss: 0.659, 0.2047 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 03:40:32 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2041, average loss: 0.8096
[09/28 03:40:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.64	top5: 96.27	
[09/28 03:40:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/28 03:40:41 visual_prompt]: Epoch 87 / 100: avg data time: 8.54e-02, avg batch time: 0.5134, average train loss: 0.0307
[09/28 03:40:44 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1821, average loss: 0.0271
[09/28 03:40:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:41:06 visual_prompt]: 	Test 100/157. loss: 0.654, 0.2055 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 03:41:18 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2044, average loss: 0.8141
[09/28 03:41:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.33	top5: 96.30	
[09/28 03:41:18 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/28 03:41:27 visual_prompt]: Epoch 88 / 100: avg data time: 8.13e-02, avg batch time: 0.5109, average train loss: 0.0311
[09/28 03:41:30 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1725, average loss: 0.0269
[09/28 03:41:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:41:52 visual_prompt]: 	Test 100/157. loss: 0.659, 0.2047 s / batch. (data: 2.60e-05)max mem: 7.81378 GB 
[09/28 03:42:05 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2043, average loss: 0.8133
[09/28 03:42:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.40	top5: 96.31	
[09/28 03:42:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/28 03:42:14 visual_prompt]: Epoch 89 / 100: avg data time: 8.52e-02, avg batch time: 0.5093, average train loss: 0.0308
[09/28 03:42:17 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1848, average loss: 0.0268
[09/28 03:42:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:42:39 visual_prompt]: 	Test 100/157. loss: 0.660, 0.2040 s / batch. (data: 2.48e-05)max mem: 7.81378 GB 
[09/28 03:42:51 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.2041, average loss: 0.8148
[09/28 03:42:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.43	top5: 96.27	
[09/28 03:42:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/28 03:43:00 visual_prompt]: Epoch 90 / 100: avg data time: 8.28e-02, avg batch time: 0.5112, average train loss: 0.0306
[09/28 03:43:03 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1832, average loss: 0.0267
[09/28 03:43:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:43:25 visual_prompt]: 	Test 100/157. loss: 0.669, 0.2065 s / batch. (data: 3.36e-05)max mem: 7.81378 GB 
[09/28 03:43:38 visual_prompt]: Inference (test):avg data time: 7.11e-05, avg batch time: 0.2044, average loss: 0.8158
[09/28 03:43:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.49	top5: 96.29	
[09/28 03:43:38 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/28 03:43:47 visual_prompt]: Epoch 91 / 100: avg data time: 9.18e-02, avg batch time: 0.5181, average train loss: 0.0308
[09/28 03:43:50 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1830, average loss: 0.0266
[09/28 03:43:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:44:12 visual_prompt]: 	Test 100/157. loss: 0.667, 0.2045 s / batch. (data: 2.67e-05)max mem: 7.81378 GB 
[09/28 03:44:25 visual_prompt]: Inference (test):avg data time: 1.62e-04, avg batch time: 0.2045, average loss: 0.8160
[09/28 03:44:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.41	top5: 96.28	
[09/28 03:44:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/28 03:44:34 visual_prompt]: Epoch 92 / 100: avg data time: 1.01e-01, avg batch time: 0.5282, average train loss: 0.0306
[09/28 03:44:37 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1777, average loss: 0.0266
[09/28 03:44:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:44:59 visual_prompt]: 	Test 100/157. loss: 0.667, 0.2042 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 03:45:11 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2044, average loss: 0.8162
[09/28 03:45:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.35	top5: 96.26	
[09/28 03:45:12 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/28 03:45:21 visual_prompt]: Epoch 93 / 100: avg data time: 9.24e-02, avg batch time: 0.5195, average train loss: 0.0303
[09/28 03:45:24 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.1818, average loss: 0.0265
[09/28 03:45:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:45:46 visual_prompt]: 	Test 100/157. loss: 0.669, 0.2044 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 03:45:58 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2040, average loss: 0.8159
[09/28 03:45:58 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.40	top5: 96.24	
[09/28 03:45:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/28 03:46:07 visual_prompt]: Epoch 94 / 100: avg data time: 8.99e-02, avg batch time: 0.5164, average train loss: 0.0304
[09/28 03:46:10 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1853, average loss: 0.0265
[09/28 03:46:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:46:32 visual_prompt]: 	Test 100/157. loss: 0.671, 0.2038 s / batch. (data: 2.69e-05)max mem: 7.81378 GB 
[09/28 03:46:45 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2041, average loss: 0.8164
[09/28 03:46:45 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.38	top5: 96.31	
[09/28 03:46:45 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/28 03:46:54 visual_prompt]: Epoch 95 / 100: avg data time: 8.98e-02, avg batch time: 0.5169, average train loss: 0.0303
[09/28 03:46:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1850, average loss: 0.0264
[09/28 03:46:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:47:19 visual_prompt]: 	Test 100/157. loss: 0.671, 0.2039 s / batch. (data: 3.43e-05)max mem: 7.81378 GB 
[09/28 03:47:32 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2043, average loss: 0.8173
[09/28 03:47:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.29	top5: 96.26	
[09/28 03:47:32 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/28 03:47:41 visual_prompt]: Epoch 96 / 100: avg data time: 9.25e-02, avg batch time: 0.5206, average train loss: 0.0304
[09/28 03:47:44 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1786, average loss: 0.0264
[09/28 03:47:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:48:06 visual_prompt]: 	Test 100/157. loss: 0.672, 0.2041 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 03:48:18 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2042, average loss: 0.8173
[09/28 03:48:18 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.34	top5: 96.25	
[09/28 03:48:18 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/28 03:48:27 visual_prompt]: Epoch 97 / 100: avg data time: 9.27e-02, avg batch time: 0.5222, average train loss: 0.0300
[09/28 03:48:30 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1797, average loss: 0.0264
[09/28 03:48:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:48:52 visual_prompt]: 	Test 100/157. loss: 0.673, 0.2039 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 03:49:05 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2042, average loss: 0.8178
[09/28 03:49:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.37	top5: 96.24	
[09/28 03:49:05 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/28 03:49:14 visual_prompt]: Epoch 98 / 100: avg data time: 9.76e-02, avg batch time: 0.5234, average train loss: 0.0299
[09/28 03:49:17 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1817, average loss: 0.0264
[09/28 03:49:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:49:39 visual_prompt]: 	Test 100/157. loss: 0.674, 0.2044 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 03:49:51 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2041, average loss: 0.8182
[09/28 03:49:51 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.36	top5: 96.24	
[09/28 03:49:51 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/28 03:50:00 visual_prompt]: Epoch 99 / 100: avg data time: 8.71e-02, avg batch time: 0.5133, average train loss: 0.0299
[09/28 03:50:03 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1834, average loss: 0.0264
[09/28 03:50:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:50:25 visual_prompt]: 	Test 100/157. loss: 0.674, 0.2062 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 03:50:38 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2045, average loss: 0.8182
[09/28 03:50:38 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.36	top5: 96.24	
[09/28 03:50:38 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/28 03:50:47 visual_prompt]: Epoch 100 / 100: avg data time: 7.94e-02, avg batch time: 0.5072, average train loss: 0.0299
[09/28 03:50:50 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1812, average loss: 0.0264
[09/28 03:50:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 03:51:12 visual_prompt]: 	Test 100/157. loss: 0.674, 0.2052 s / batch. (data: 2.57e-05)max mem: 7.81378 GB 
[09/28 03:51:25 visual_prompt]: Inference (test):avg data time: 1.25e-04, avg batch time: 0.2043, average loss: 0.8182
[09/28 03:51:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 79.36	top5: 96.24	
[09/28 03:51:25 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 03:51:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 03:51:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 03:51:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 03:51:25 visual_prompt]: Training with config:
[09/28 03:51:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/test/seed3157/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 3157, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 03:51:25 visual_prompt]: Loading training data...
[09/28 03:51:25 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800]+train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 03:51:26 visual_prompt]: Number of images: 1000
[09/28 03:51:26 visual_prompt]: Number of classes: 100 / 100
[09/28 03:51:26 visual_prompt]: Loading validation data...
[09/28 03:51:26 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 03:51:26 visual_prompt]: Number of images: 200
[09/28 03:51:26 visual_prompt]: Number of classes: 90 / 100
[09/28 03:51:26 visual_prompt]: Loading test data...
[09/28 03:51:26 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split test, from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/28 03:51:37 visual_prompt]: Number of images: 10000
[09/28 03:51:37 visual_prompt]: Number of classes: 100 / 100
[09/28 03:51:37 visual_prompt]: Constructing models...
[09/28 03:51:40 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/28 03:51:40 visual_prompt]: tuned percent:0.623
[09/28 03:51:40 visual_prompt]: Device used for model: 0
[09/28 03:51:40 visual_prompt]: Setting up Evaluator...
[09/28 03:51:40 visual_prompt]: Setting up Trainer...
[09/28 03:51:40 visual_prompt]: 	Setting up the optimizer...
[09/28 03:51:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 03:51:49 visual_prompt]: Epoch 1 / 100: avg data time: 9.25e-02, avg batch time: 0.5179, average train loss: 4.6548
[09/28 03:51:52 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1833, average loss: 4.6443
[09/28 03:51:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 7.00	
[09/28 03:52:14 visual_prompt]: 	Test 100/157. loss: 4.704, 0.2033 s / batch. (data: 3.39e-05)max mem: 7.81378 GB 
[09/28 03:52:27 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2030, average loss: 4.6624
[09/28 03:52:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.04	top5: 4.68	
[09/28 03:52:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/28 03:52:36 visual_prompt]: Epoch 2 / 100: avg data time: 9.10e-02, avg batch time: 0.5152, average train loss: 4.6047
[09/28 03:52:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1750, average loss: 4.5324
[09/28 03:52:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.00	
[09/28 03:53:01 visual_prompt]: 	Test 100/157. loss: 4.590, 0.2048 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 03:53:13 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2037, average loss: 4.6213
[09/28 03:53:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 1.37	top5: 7.18	
[09/28 03:53:13 visual_prompt]: Best epoch 2: best metric: 0.020
[09/28 03:53:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/28 03:53:22 visual_prompt]: Epoch 3 / 100: avg data time: 8.49e-02, avg batch time: 0.5108, average train loss: 4.5592
[09/28 03:53:25 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1801, average loss: 4.4188
[09/28 03:53:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 20.50	
[09/28 03:53:47 visual_prompt]: 	Test 100/157. loss: 4.494, 0.2050 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 03:54:00 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2038, average loss: 4.5457
[09/28 03:54:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 3.98	top5: 13.72	
[09/28 03:54:00 visual_prompt]: Best epoch 3: best metric: 0.065
[09/28 03:54:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/28 03:54:09 visual_prompt]: Epoch 4 / 100: avg data time: 8.83e-02, avg batch time: 0.5177, average train loss: 4.3298
[09/28 03:54:12 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1822, average loss: 3.9704
[09/28 03:54:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 31.00	
[09/28 03:54:34 visual_prompt]: 	Test 100/157. loss: 4.042, 0.2036 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 03:54:46 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2041, average loss: 4.2519
[09/28 03:54:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 5.11	top5: 20.10	
[09/28 03:54:46 visual_prompt]: Best epoch 4: best metric: 0.070
[09/28 03:54:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/28 03:54:55 visual_prompt]: Epoch 5 / 100: avg data time: 9.32e-02, avg batch time: 0.5209, average train loss: 3.9424
[09/28 03:54:58 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1770, average loss: 3.2960
[09/28 03:54:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 47.00	
[09/28 03:55:20 visual_prompt]: 	Test 100/157. loss: 3.678, 0.2055 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 03:55:33 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2041, average loss: 3.6406
[09/28 03:55:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 11.82	top5: 35.30	
[09/28 03:55:33 visual_prompt]: Best epoch 5: best metric: 0.205
[09/28 03:55:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/28 03:55:42 visual_prompt]: Epoch 6 / 100: avg data time: 9.17e-02, avg batch time: 0.5179, average train loss: 3.1318
[09/28 03:55:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1754, average loss: 2.2976
[09/28 03:55:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 38.00	top5: 78.50	
[09/28 03:56:07 visual_prompt]: 	Test 100/157. loss: 2.761, 0.2040 s / batch. (data: 2.55e-05)max mem: 7.81378 GB 
[09/28 03:56:19 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2042, average loss: 2.9344
[09/28 03:56:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 23.14	top5: 56.36	
[09/28 03:56:20 visual_prompt]: Best epoch 6: best metric: 0.380
[09/28 03:56:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/28 03:56:29 visual_prompt]: Epoch 7 / 100: avg data time: 9.55e-02, avg batch time: 0.5216, average train loss: 2.1292
[09/28 03:56:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1855, average loss: 1.2972
[09/28 03:56:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 94.00	
[09/28 03:56:54 visual_prompt]: 	Test 100/157. loss: 2.142, 0.2041 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 03:57:06 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2041, average loss: 2.2068
[09/28 03:57:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 41.52	top5: 75.47	
[09/28 03:57:06 visual_prompt]: Best epoch 7: best metric: 0.700
[09/28 03:57:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/28 03:57:15 visual_prompt]: Epoch 8 / 100: avg data time: 8.68e-02, avg batch time: 0.5152, average train loss: 1.2426
[09/28 03:57:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1800, average loss: 0.7759
[09/28 03:57:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 97.50	
[09/28 03:57:40 visual_prompt]: 	Test 100/157. loss: 1.675, 0.2040 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 03:57:53 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2047, average loss: 1.7210
[09/28 03:57:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 53.67	top5: 83.13	
[09/28 03:57:53 visual_prompt]: Best epoch 8: best metric: 0.815
[09/28 03:57:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/28 03:58:02 visual_prompt]: Epoch 9 / 100: avg data time: 8.78e-02, avg batch time: 0.5137, average train loss: 0.7041
[09/28 03:58:05 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1847, average loss: 0.3291
[09/28 03:58:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 94.50	top5: 100.00	
[09/28 03:58:27 visual_prompt]: 	Test 100/157. loss: 1.291, 0.2047 s / batch. (data: 2.60e-05)max mem: 7.81378 GB 
[09/28 03:58:39 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2045, average loss: 1.3914
[09/28 03:58:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 62.05	top5: 89.21	
[09/28 03:58:40 visual_prompt]: Best epoch 9: best metric: 0.945
[09/28 03:58:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/28 03:58:49 visual_prompt]: Epoch 10 / 100: avg data time: 8.53e-02, avg batch time: 0.5124, average train loss: 0.3364
[09/28 03:58:51 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1832, average loss: 0.1912
[09/28 03:58:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 97.50	top5: 100.00	
[09/28 03:59:14 visual_prompt]: 	Test 100/157. loss: 1.134, 0.2063 s / batch. (data: 2.43e-05)max mem: 7.81378 GB 
[09/28 03:59:26 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2043, average loss: 1.1980
[09/28 03:59:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 68.17	top5: 91.20	
[09/28 03:59:26 visual_prompt]: Best epoch 10: best metric: 0.975
[09/28 03:59:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/28 03:59:35 visual_prompt]: Epoch 11 / 100: avg data time: 8.59e-02, avg batch time: 0.5137, average train loss: 0.1893
[09/28 03:59:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1856, average loss: 0.1234
[09/28 03:59:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 04:00:00 visual_prompt]: 	Test 100/157. loss: 1.186, 0.2060 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 04:00:12 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2043, average loss: 1.1488
[09/28 04:00:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 69.15	top5: 91.77	
[09/28 04:00:13 visual_prompt]: Best epoch 11: best metric: 0.990
[09/28 04:00:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/28 04:00:22 visual_prompt]: Epoch 12 / 100: avg data time: 8.40e-02, avg batch time: 0.5117, average train loss: 0.1445
[09/28 04:00:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1787, average loss: 0.0942
[09/28 04:00:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 04:00:47 visual_prompt]: 	Test 100/157. loss: 1.133, 0.2050 s / batch. (data: 3.53e-05)max mem: 7.81378 GB 
[09/28 04:00:59 visual_prompt]: Inference (test):avg data time: 7.44e-05, avg batch time: 0.2044, average loss: 1.1389
[09/28 04:00:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 69.97	top5: 92.05	
[09/28 04:00:59 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/28 04:01:08 visual_prompt]: Epoch 13 / 100: avg data time: 8.46e-02, avg batch time: 0.5116, average train loss: 0.0976
[09/28 04:01:11 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1727, average loss: 0.0639
[09/28 04:01:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 04:01:33 visual_prompt]: 	Test 100/157. loss: 1.113, 0.2051 s / batch. (data: 2.31e-05)max mem: 7.81378 GB 
[09/28 04:01:46 visual_prompt]: Inference (test):avg data time: 5.43e-05, avg batch time: 0.2043, average loss: 1.1130
[09/28 04:01:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 70.44	top5: 92.17	
[09/28 04:01:46 visual_prompt]: Best epoch 13: best metric: 0.995
[09/28 04:01:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/28 04:01:55 visual_prompt]: Epoch 14 / 100: avg data time: 9.20e-02, avg batch time: 0.5182, average train loss: 0.0719
[09/28 04:01:58 visual_prompt]: Inference (val):avg data time: 4.46e-05, avg batch time: 0.1851, average loss: 0.0454
[09/28 04:01:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:02:20 visual_prompt]: 	Test 100/157. loss: 1.083, 0.2053 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 04:02:32 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2045, average loss: 1.0692
[09/28 04:02:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.37	top5: 92.52	
[09/28 04:02:32 visual_prompt]: Best epoch 14: best metric: 1.000
[09/28 04:02:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/28 04:02:42 visual_prompt]: Epoch 15 / 100: avg data time: 9.50e-02, avg batch time: 0.5232, average train loss: 0.0579
[09/28 04:02:45 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1837, average loss: 0.0372
[09/28 04:02:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:03:07 visual_prompt]: 	Test 100/157. loss: 1.005, 0.2046 s / batch. (data: 8.61e-05)max mem: 7.81378 GB 
[09/28 04:03:19 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2042, average loss: 1.0352
[09/28 04:03:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.58	top5: 93.07	
[09/28 04:03:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/28 04:03:28 visual_prompt]: Epoch 16 / 100: avg data time: 8.81e-02, avg batch time: 0.5141, average train loss: 0.0492
[09/28 04:03:31 visual_prompt]: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1830, average loss: 0.0356
[09/28 04:03:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:03:53 visual_prompt]: 	Test 100/157. loss: 1.029, 0.2039 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 04:04:06 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2047, average loss: 1.0412
[09/28 04:04:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.85	top5: 92.95	
[09/28 04:04:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/28 04:04:15 visual_prompt]: Epoch 17 / 100: avg data time: 9.46e-02, avg batch time: 0.5209, average train loss: 0.0483
[09/28 04:04:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1788, average loss: 0.0355
[09/28 04:04:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:04:40 visual_prompt]: 	Test 100/157. loss: 1.127, 0.2054 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 04:04:53 visual_prompt]: Inference (test):avg data time: 1.14e-04, avg batch time: 0.2049, average loss: 1.0613
[09/28 04:04:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.02	
[09/28 04:04:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/28 04:05:02 visual_prompt]: Epoch 18 / 100: avg data time: 7.76e-02, avg batch time: 0.5052, average train loss: 0.0497
[09/28 04:05:05 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1806, average loss: 0.0370
[09/28 04:05:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:05:27 visual_prompt]: 	Test 100/157. loss: 1.002, 0.2041 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 04:05:39 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2042, average loss: 1.0494
[09/28 04:05:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.84	top5: 93.13	
[09/28 04:05:39 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/28 04:05:49 visual_prompt]: Epoch 19 / 100: avg data time: 9.98e-02, avg batch time: 0.5260, average train loss: 0.0583
[09/28 04:05:52 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1859, average loss: 0.0452
[09/28 04:05:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:06:14 visual_prompt]: 	Test 100/157. loss: 1.050, 0.2057 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 04:06:26 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2041, average loss: 1.1103
[09/28 04:06:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.27	top5: 92.89	
[09/28 04:06:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/28 04:06:35 visual_prompt]: Epoch 20 / 100: avg data time: 8.43e-02, avg batch time: 0.5159, average train loss: 0.1072
[09/28 04:06:38 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1836, average loss: 0.1323
[09/28 04:06:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 04:07:00 visual_prompt]: 	Test 100/157. loss: 1.036, 0.2036 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 04:07:13 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2040, average loss: 1.2373
[09/28 04:07:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 69.45	top5: 91.25	
[09/28 04:07:13 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/28 04:07:22 visual_prompt]: Epoch 21 / 100: avg data time: 8.10e-02, avg batch time: 0.5088, average train loss: 0.3528
[09/28 04:07:25 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1823, average loss: 1.0487
[09/28 04:07:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 96.50	
[09/28 04:07:47 visual_prompt]: 	Test 100/157. loss: 1.952, 0.2053 s / batch. (data: 3.58e-05)max mem: 7.81378 GB 
[09/28 04:08:00 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2045, average loss: 1.9548
[09/28 04:08:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 54.34	top5: 79.86	
[09/28 04:08:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/28 04:08:09 visual_prompt]: Epoch 22 / 100: avg data time: 9.56e-02, avg batch time: 0.5245, average train loss: 0.3763
[09/28 04:08:12 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1727, average loss: 0.1767
[09/28 04:08:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.00	top5: 100.00	
[09/28 04:08:34 visual_prompt]: 	Test 100/157. loss: 1.052, 0.2043 s / batch. (data: 2.46e-05)max mem: 7.81378 GB 
[09/28 04:08:47 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2045, average loss: 1.0644
[09/28 04:08:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.52	top5: 93.33	
[09/28 04:08:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/28 04:08:56 visual_prompt]: Epoch 23 / 100: avg data time: 8.77e-02, avg batch time: 0.5148, average train loss: 0.1729
[09/28 04:08:59 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1742, average loss: 0.1218
[09/28 04:08:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 98.50	top5: 100.00	
[09/28 04:09:21 visual_prompt]: 	Test 100/157. loss: 1.022, 0.2055 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 04:09:33 visual_prompt]: Inference (test):avg data time: 8.51e-05, avg batch time: 0.2042, average loss: 0.9761
[09/28 04:09:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.98	top5: 94.17	
[09/28 04:09:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/28 04:09:42 visual_prompt]: Epoch 24 / 100: avg data time: 9.31e-02, avg batch time: 0.5203, average train loss: 0.0945
[09/28 04:09:45 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1762, average loss: 0.0496
[09/28 04:09:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 04:10:07 visual_prompt]: 	Test 100/157. loss: 0.794, 0.2041 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 04:10:20 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2043, average loss: 0.9045
[09/28 04:10:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.62	top5: 94.66	
[09/28 04:10:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/28 04:10:29 visual_prompt]: Epoch 25 / 100: avg data time: 8.78e-02, avg batch time: 0.5142, average train loss: 0.0528
[09/28 04:10:32 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1842, average loss: 0.0370
[09/28 04:10:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:10:54 visual_prompt]: 	Test 100/157. loss: 0.784, 0.2037 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 04:11:06 visual_prompt]: Inference (test):avg data time: 1.26e-04, avg batch time: 0.2042, average loss: 0.8965
[09/28 04:11:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.95	top5: 94.93	
[09/28 04:11:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/28 04:11:15 visual_prompt]: Epoch 26 / 100: avg data time: 8.27e-02, avg batch time: 0.5109, average train loss: 0.0415
[09/28 04:11:18 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1755, average loss: 0.0351
[09/28 04:11:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:11:40 visual_prompt]: 	Test 100/157. loss: 0.815, 0.2055 s / batch. (data: 4.91e-05)max mem: 7.81378 GB 
[09/28 04:11:53 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2042, average loss: 0.8699
[09/28 04:11:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.58	top5: 95.29	
[09/28 04:11:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/28 04:12:02 visual_prompt]: Epoch 27 / 100: avg data time: 9.88e-02, avg batch time: 0.5271, average train loss: 0.0379
[09/28 04:12:05 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1761, average loss: 0.0292
[09/28 04:12:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:12:27 visual_prompt]: 	Test 100/157. loss: 0.805, 0.2053 s / batch. (data: 2.67e-05)max mem: 7.81378 GB 
[09/28 04:12:40 visual_prompt]: Inference (test):avg data time: 2.94e-05, avg batch time: 0.2045, average loss: 0.9000
[09/28 04:12:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.33	top5: 94.99	
[09/28 04:12:40 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/28 04:12:49 visual_prompt]: Epoch 28 / 100: avg data time: 8.86e-02, avg batch time: 0.5154, average train loss: 0.0379
[09/28 04:12:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1848, average loss: 0.0302
[09/28 04:12:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:13:14 visual_prompt]: 	Test 100/157. loss: 0.788, 0.2044 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 04:13:27 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2043, average loss: 0.8843
[09/28 04:13:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.42	top5: 95.03	
[09/28 04:13:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/28 04:13:36 visual_prompt]: Epoch 29 / 100: avg data time: 8.94e-02, avg batch time: 0.5178, average train loss: 0.0383
[09/28 04:13:39 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1840, average loss: 0.0301
[09/28 04:13:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:14:01 visual_prompt]: 	Test 100/157. loss: 0.794, 0.2048 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 04:14:13 visual_prompt]: Inference (test):avg data time: 2.93e-05, avg batch time: 0.2041, average loss: 0.9008
[09/28 04:14:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.23	top5: 94.99	
[09/28 04:14:13 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/28 04:14:22 visual_prompt]: Epoch 30 / 100: avg data time: 8.75e-02, avg batch time: 0.5144, average train loss: 0.0391
[09/28 04:14:25 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1847, average loss: 0.0306
[09/28 04:14:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:14:47 visual_prompt]: 	Test 100/157. loss: 0.793, 0.2055 s / batch. (data: 3.10e-05)max mem: 7.81378 GB 
[09/28 04:15:00 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2046, average loss: 0.9062
[09/28 04:15:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.88	top5: 95.13	
[09/28 04:15:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/28 04:15:09 visual_prompt]: Epoch 31 / 100: avg data time: 8.39e-02, avg batch time: 0.5116, average train loss: 0.0393
[09/28 04:15:12 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1795, average loss: 0.0297
[09/28 04:15:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:15:34 visual_prompt]: 	Test 100/157. loss: 0.852, 0.2048 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 04:15:47 visual_prompt]: Inference (test):avg data time: 1.67e-04, avg batch time: 0.2044, average loss: 0.9167
[09/28 04:15:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.05	top5: 94.99	
[09/28 04:15:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/28 04:15:56 visual_prompt]: Epoch 32 / 100: avg data time: 8.70e-02, avg batch time: 0.5146, average train loss: 0.0408
[09/28 04:15:59 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1792, average loss: 0.0300
[09/28 04:15:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:16:21 visual_prompt]: 	Test 100/157. loss: 0.843, 0.2044 s / batch. (data: 2.96e-05)max mem: 7.81378 GB 
[09/28 04:16:33 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2044, average loss: 0.9199
[09/28 04:16:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.15	top5: 95.00	
[09/28 04:16:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/28 04:16:43 visual_prompt]: Epoch 33 / 100: avg data time: 9.41e-02, avg batch time: 0.5230, average train loss: 0.0400
[09/28 04:16:45 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1739, average loss: 0.0302
[09/28 04:16:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:17:07 visual_prompt]: 	Test 100/157. loss: 0.880, 0.2050 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 04:17:20 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2047, average loss: 0.9350
[09/28 04:17:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.03	top5: 94.91	
[09/28 04:17:20 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/28 04:17:29 visual_prompt]: Epoch 34 / 100: avg data time: 9.67e-02, avg batch time: 0.5255, average train loss: 0.0408
[09/28 04:17:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1771, average loss: 0.0470
[09/28 04:17:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 04:17:54 visual_prompt]: 	Test 100/157. loss: 0.903, 0.2057 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 04:18:07 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2045, average loss: 1.0054
[09/28 04:18:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.22	top5: 94.22	
[09/28 04:18:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/28 04:18:16 visual_prompt]: Epoch 35 / 100: avg data time: 9.00e-02, avg batch time: 0.5180, average train loss: 0.0674
[09/28 04:18:19 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1726, average loss: 0.1107
[09/28 04:18:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 04:18:41 visual_prompt]: 	Test 100/157. loss: 1.026, 0.2047 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 04:18:54 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2041, average loss: 1.1356
[09/28 04:18:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 72.55	top5: 93.08	
[09/28 04:18:54 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/28 04:19:03 visual_prompt]: Epoch 36 / 100: avg data time: 9.68e-02, avg batch time: 0.5255, average train loss: 0.8458
[09/28 04:19:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1842, average loss: 1.8366
[09/28 04:19:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 95.00	
[09/28 04:19:28 visual_prompt]: 	Test 100/157. loss: 2.265, 0.2062 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 04:19:40 visual_prompt]: Inference (test):avg data time: 2.94e-05, avg batch time: 0.2042, average loss: 2.3836
[09/28 04:19:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 54.09	top5: 82.54	
[09/28 04:19:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/28 04:19:50 visual_prompt]: Epoch 37 / 100: avg data time: 8.91e-02, avg batch time: 0.5184, average train loss: 1.2064
[09/28 04:19:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1740, average loss: 0.7464
[09/28 04:19:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 85.00	top5: 96.50	
[09/28 04:20:15 visual_prompt]: 	Test 100/157. loss: 1.353, 0.2043 s / batch. (data: 3.15e-05)max mem: 7.81378 GB 
[09/28 04:20:27 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2045, average loss: 1.5002
[09/28 04:20:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 64.19	top5: 87.94	
[09/28 04:20:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/28 04:20:37 visual_prompt]: Epoch 38 / 100: avg data time: 9.64e-02, avg batch time: 0.5227, average train loss: 0.4071
[09/28 04:20:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1763, average loss: 0.2329
[09/28 04:20:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 95.50	top5: 100.00	
[09/28 04:21:01 visual_prompt]: 	Test 100/157. loss: 1.036, 0.2046 s / batch. (data: 2.67e-05)max mem: 7.81378 GB 
[09/28 04:21:14 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2041, average loss: 1.0658
[09/28 04:21:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.31	top5: 92.80	
[09/28 04:21:14 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/28 04:21:23 visual_prompt]: Epoch 39 / 100: avg data time: 8.99e-02, avg batch time: 0.5185, average train loss: 0.1534
[09/28 04:21:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1761, average loss: 0.0692
[09/28 04:21:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:21:48 visual_prompt]: 	Test 100/157. loss: 0.872, 0.2053 s / batch. (data: 3.36e-05)max mem: 7.81378 GB 
[09/28 04:22:01 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2044, average loss: 0.8198
[09/28 04:22:01 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.58	top5: 95.47	
[09/28 04:22:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/28 04:22:10 visual_prompt]: Epoch 40 / 100: avg data time: 8.20e-02, avg batch time: 0.5088, average train loss: 0.0708
[09/28 04:22:13 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1752, average loss: 0.0508
[09/28 04:22:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:22:35 visual_prompt]: 	Test 100/157. loss: 0.913, 0.2044 s / batch. (data: 3.34e-05)max mem: 7.81378 GB 
[09/28 04:22:47 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2044, average loss: 0.8172
[09/28 04:22:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.43	top5: 95.55	
[09/28 04:22:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/28 04:22:57 visual_prompt]: Epoch 41 / 100: avg data time: 9.81e-02, avg batch time: 0.5252, average train loss: 0.0541
[09/28 04:22:59 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1746, average loss: 0.0410
[09/28 04:22:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:23:21 visual_prompt]: 	Test 100/157. loss: 0.826, 0.2055 s / batch. (data: 3.19e-05)max mem: 7.81378 GB 
[09/28 04:23:34 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2043, average loss: 0.8151
[09/28 04:23:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.56	top5: 95.64	
[09/28 04:23:34 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/28 04:23:43 visual_prompt]: Epoch 42 / 100: avg data time: 8.85e-02, avg batch time: 0.5163, average train loss: 0.0453
[09/28 04:23:46 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1767, average loss: 0.0387
[09/28 04:23:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:24:08 visual_prompt]: 	Test 100/157. loss: 0.789, 0.2053 s / batch. (data: 2.53e-05)max mem: 7.81378 GB 
[09/28 04:24:20 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2045, average loss: 0.8209
[09/28 04:24:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.34	top5: 95.75	
[09/28 04:24:20 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/28 04:24:29 visual_prompt]: Epoch 43 / 100: avg data time: 8.32e-02, avg batch time: 0.5121, average train loss: 0.0426
[09/28 04:24:32 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1778, average loss: 0.0353
[09/28 04:24:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:24:54 visual_prompt]: 	Test 100/157. loss: 0.806, 0.2036 s / batch. (data: 2.65e-05)max mem: 7.81378 GB 
[09/28 04:25:07 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2045, average loss: 0.8211
[09/28 04:25:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.57	top5: 95.79	
[09/28 04:25:07 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/28 04:25:16 visual_prompt]: Epoch 44 / 100: avg data time: 8.49e-02, avg batch time: 0.5153, average train loss: 0.0411
[09/28 04:25:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1797, average loss: 0.0343
[09/28 04:25:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:25:41 visual_prompt]: 	Test 100/157. loss: 0.788, 0.2041 s / batch. (data: 5.39e-05)max mem: 7.81378 GB 
[09/28 04:25:54 visual_prompt]: Inference (test):avg data time: 1.34e-04, avg batch time: 0.2044, average loss: 0.8259
[09/28 04:25:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.57	top5: 95.89	
[09/28 04:25:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/28 04:26:03 visual_prompt]: Epoch 45 / 100: avg data time: 9.19e-02, avg batch time: 0.5199, average train loss: 0.0401
[09/28 04:26:06 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1848, average loss: 0.0342
[09/28 04:26:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:26:28 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2057 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 04:26:40 visual_prompt]: Inference (test):avg data time: 1.27e-04, avg batch time: 0.2045, average loss: 0.8358
[09/28 04:26:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.56	top5: 95.72	
[09/28 04:26:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/28 04:26:49 visual_prompt]: Epoch 46 / 100: avg data time: 8.54e-02, avg batch time: 0.5122, average train loss: 0.0399
[09/28 04:26:52 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1766, average loss: 0.0325
[09/28 04:26:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:27:14 visual_prompt]: 	Test 100/157. loss: 0.813, 0.2047 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 04:27:27 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2043, average loss: 0.8458
[09/28 04:27:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.31	top5: 95.77	
[09/28 04:27:27 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/28 04:27:36 visual_prompt]: Epoch 47 / 100: avg data time: 9.22e-02, avg batch time: 0.5162, average train loss: 0.0396
[09/28 04:27:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1847, average loss: 0.0317
[09/28 04:27:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:28:01 visual_prompt]: 	Test 100/157. loss: 0.803, 0.2042 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 04:28:14 visual_prompt]: Inference (test):avg data time: 2.14e-04, avg batch time: 0.2046, average loss: 0.8374
[09/28 04:28:14 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.38	top5: 95.80	
[09/28 04:28:14 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/28 04:28:23 visual_prompt]: Epoch 48 / 100: avg data time: 8.79e-02, avg batch time: 0.5171, average train loss: 0.0391
[09/28 04:28:26 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1753, average loss: 0.0318
[09/28 04:28:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:28:48 visual_prompt]: 	Test 100/157. loss: 0.805, 0.2055 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 04:29:00 visual_prompt]: Inference (test):avg data time: 7.71e-05, avg batch time: 0.2045, average loss: 0.8591
[09/28 04:29:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.77	top5: 95.61	
[09/28 04:29:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/28 04:29:10 visual_prompt]: Epoch 49 / 100: avg data time: 9.25e-02, avg batch time: 0.5210, average train loss: 0.0395
[09/28 04:29:12 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1783, average loss: 0.0330
[09/28 04:29:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:29:34 visual_prompt]: 	Test 100/157. loss: 0.808, 0.2052 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 04:29:47 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2043, average loss: 0.8696
[09/28 04:29:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.92	top5: 95.54	
[09/28 04:29:47 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/28 04:29:56 visual_prompt]: Epoch 50 / 100: avg data time: 8.61e-02, avg batch time: 0.5127, average train loss: 0.0392
[09/28 04:29:59 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1821, average loss: 0.0309
[09/28 04:29:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:30:21 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2050 s / batch. (data: 2.41e-05)max mem: 7.81378 GB 
[09/28 04:30:34 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2044, average loss: 0.8630
[09/28 04:30:34 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 78.14	top5: 95.71	
[09/28 04:30:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/28 04:30:43 visual_prompt]: Epoch 51 / 100: avg data time: 8.72e-02, avg batch time: 0.5148, average train loss: 0.0401
[09/28 04:30:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1779, average loss: 0.0329
[09/28 04:30:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:31:08 visual_prompt]: 	Test 100/157. loss: 0.818, 0.2048 s / batch. (data: 2.62e-05)max mem: 7.81378 GB 
[09/28 04:31:20 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2043, average loss: 0.8765
[09/28 04:31:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.75	top5: 95.57	
[09/28 04:31:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/28 04:31:30 visual_prompt]: Epoch 52 / 100: avg data time: 9.23e-02, avg batch time: 0.5203, average train loss: 0.0405
[09/28 04:31:32 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1737, average loss: 0.0346
[09/28 04:31:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:31:54 visual_prompt]: 	Test 100/157. loss: 0.843, 0.2063 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 04:32:07 visual_prompt]: Inference (test):avg data time: 5.90e-05, avg batch time: 0.2043, average loss: 0.9033
[09/28 04:32:07 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.30	top5: 95.38	
[09/28 04:32:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/28 04:32:16 visual_prompt]: Epoch 53 / 100: avg data time: 1.01e-01, avg batch time: 0.5269, average train loss: 0.0438
[09/28 04:32:19 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1849, average loss: 0.0422
[09/28 04:32:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 04:32:41 visual_prompt]: 	Test 100/157. loss: 0.834, 0.2043 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 04:32:54 visual_prompt]: Inference (test):avg data time: 1.27e-04, avg batch time: 0.2044, average loss: 0.9119
[09/28 04:32:54 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.28	top5: 95.24	
[09/28 04:32:54 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/28 04:33:03 visual_prompt]: Epoch 54 / 100: avg data time: 9.29e-02, avg batch time: 0.5201, average train loss: 0.0433
[09/28 04:33:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1828, average loss: 0.0340
[09/28 04:33:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:33:28 visual_prompt]: 	Test 100/157. loss: 0.745, 0.2052 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 04:33:40 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2044, average loss: 0.8899
[09/28 04:33:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.71	top5: 95.54	
[09/28 04:33:40 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/28 04:33:49 visual_prompt]: Epoch 55 / 100: avg data time: 8.52e-02, avg batch time: 0.5132, average train loss: 0.0424
[09/28 04:33:52 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1772, average loss: 0.0461
[09/28 04:33:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.00	top5: 100.00	
[09/28 04:34:14 visual_prompt]: 	Test 100/157. loss: 0.794, 0.2058 s / batch. (data: 3.31e-05)max mem: 7.81378 GB 
[09/28 04:34:27 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2043, average loss: 0.9183
[09/28 04:34:27 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.01	top5: 95.61	
[09/28 04:34:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/28 04:34:36 visual_prompt]: Epoch 56 / 100: avg data time: 9.47e-02, avg batch time: 0.5202, average train loss: 0.0439
[09/28 04:34:39 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1750, average loss: 0.0357
[09/28 04:34:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:35:01 visual_prompt]: 	Test 100/157. loss: 0.798, 0.2065 s / batch. (data: 2.93e-05)max mem: 7.81378 GB 
[09/28 04:35:13 visual_prompt]: Inference (test):avg data time: 4.14e-05, avg batch time: 0.2044, average loss: 0.9223
[09/28 04:35:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.82	top5: 95.11	
[09/28 04:35:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/28 04:35:23 visual_prompt]: Epoch 57 / 100: avg data time: 9.50e-02, avg batch time: 0.5211, average train loss: 0.0419
[09/28 04:35:26 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1844, average loss: 0.0302
[09/28 04:35:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:35:48 visual_prompt]: 	Test 100/157. loss: 0.784, 0.2049 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 04:36:00 visual_prompt]: Inference (test):avg data time: 1.22e-04, avg batch time: 0.2044, average loss: 0.8988
[09/28 04:36:00 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.57	top5: 95.36	
[09/28 04:36:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/28 04:36:09 visual_prompt]: Epoch 58 / 100: avg data time: 7.83e-02, avg batch time: 0.5072, average train loss: 0.0367
[09/28 04:36:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1783, average loss: 0.0291
[09/28 04:36:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:36:34 visual_prompt]: 	Test 100/157. loss: 0.807, 0.2065 s / batch. (data: 2.69e-05)max mem: 7.81378 GB 
[09/28 04:36:46 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2044, average loss: 0.9254
[09/28 04:36:47 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.89	top5: 95.32	
[09/28 04:36:47 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/28 04:36:56 visual_prompt]: Epoch 59 / 100: avg data time: 9.44e-02, avg batch time: 0.5203, average train loss: 0.0354
[09/28 04:36:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1779, average loss: 0.0276
[09/28 04:36:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:37:20 visual_prompt]: 	Test 100/157. loss: 0.812, 0.2047 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 04:37:33 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2045, average loss: 0.9076
[09/28 04:37:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 77.15	top5: 95.32	
[09/28 04:37:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/28 04:37:42 visual_prompt]: Epoch 60 / 100: avg data time: 9.16e-02, avg batch time: 0.5176, average train loss: 0.0331
[09/28 04:37:45 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1822, average loss: 0.0391
[09/28 04:37:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 99.50	top5: 100.00	
[09/28 04:38:07 visual_prompt]: 	Test 100/157. loss: 0.787, 0.2061 s / batch. (data: 4.86e-05)max mem: 7.81378 GB 
[09/28 04:38:20 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2044, average loss: 0.9478
[09/28 04:38:20 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.19	top5: 95.02	
[09/28 04:38:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/28 04:38:29 visual_prompt]: Epoch 61 / 100: avg data time: 8.96e-02, avg batch time: 0.5164, average train loss: 0.0318
[09/28 04:38:32 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1774, average loss: 0.0265
[09/28 04:38:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:38:54 visual_prompt]: 	Test 100/157. loss: 0.812, 0.2043 s / batch. (data: 2.86e-05)max mem: 7.81378 GB 
[09/28 04:39:06 visual_prompt]: Inference (test):avg data time: 2.94e-05, avg batch time: 0.2042, average loss: 0.9501
[09/28 04:39:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.39	top5: 94.86	
[09/28 04:39:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/28 04:39:16 visual_prompt]: Epoch 62 / 100: avg data time: 9.02e-02, avg batch time: 0.5178, average train loss: 0.0315
[09/28 04:39:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1782, average loss: 0.0268
[09/28 04:39:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:39:40 visual_prompt]: 	Test 100/157. loss: 0.833, 0.2039 s / batch. (data: 3.22e-05)max mem: 7.81378 GB 
[09/28 04:39:53 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2042, average loss: 0.9582
[09/28 04:39:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.08	top5: 95.07	
[09/28 04:39:53 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/28 04:40:02 visual_prompt]: Epoch 63 / 100: avg data time: 8.25e-02, avg batch time: 0.5124, average train loss: 0.0313
[09/28 04:40:05 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1817, average loss: 0.0265
[09/28 04:40:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:40:27 visual_prompt]: 	Test 100/157. loss: 0.835, 0.2060 s / batch. (data: 2.74e-05)max mem: 7.81378 GB 
[09/28 04:40:39 visual_prompt]: Inference (test):avg data time: 2.95e-04, avg batch time: 0.2044, average loss: 0.9822
[09/28 04:40:40 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.61	top5: 94.83	
[09/28 04:40:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/28 04:40:49 visual_prompt]: Epoch 64 / 100: avg data time: 9.44e-02, avg batch time: 0.5208, average train loss: 0.0313
[09/28 04:40:52 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1819, average loss: 0.0264
[09/28 04:40:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:41:14 visual_prompt]: 	Test 100/157. loss: 0.857, 0.2046 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 04:41:26 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2042, average loss: 0.9591
[09/28 04:41:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.22	top5: 95.04	
[09/28 04:41:26 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/28 04:41:35 visual_prompt]: Epoch 65 / 100: avg data time: 8.03e-02, avg batch time: 0.5081, average train loss: 0.0309
[09/28 04:41:38 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1826, average loss: 0.0263
[09/28 04:41:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:42:00 visual_prompt]: 	Test 100/157. loss: 0.848, 0.2036 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 04:42:13 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2042, average loss: 1.0040
[09/28 04:42:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 75.42	top5: 94.41	
[09/28 04:42:13 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/28 04:42:22 visual_prompt]: Epoch 66 / 100: avg data time: 7.85e-02, avg batch time: 0.5066, average train loss: 0.0311
[09/28 04:42:25 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1841, average loss: 0.0262
[09/28 04:42:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:42:47 visual_prompt]: 	Test 100/157. loss: 0.885, 0.2033 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 04:42:59 visual_prompt]: Inference (test):avg data time: 7.64e-05, avg batch time: 0.2044, average loss: 0.9679
[09/28 04:42:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 76.15	top5: 95.06	
[09/28 04:42:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/28 04:43:08 visual_prompt]: Epoch 67 / 100: avg data time: 9.40e-02, avg batch time: 0.5195, average train loss: 0.0312
[09/28 04:43:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1729, average loss: 0.0262
[09/28 04:43:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:43:33 visual_prompt]: 	Test 100/157. loss: 0.913, 0.2051 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 04:43:46 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2040, average loss: 1.0143
[09/28 04:43:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.91	top5: 94.72	
[09/28 04:43:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/28 04:43:55 visual_prompt]: Epoch 68 / 100: avg data time: 9.74e-02, avg batch time: 0.5262, average train loss: 0.0309
[09/28 04:43:58 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1732, average loss: 0.0265
[09/28 04:43:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:44:20 visual_prompt]: 	Test 100/157. loss: 0.887, 0.2034 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 04:44:32 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2042, average loss: 1.0118
[09/28 04:44:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.84	top5: 94.60	
[09/28 04:44:32 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/28 04:44:41 visual_prompt]: Epoch 69 / 100: avg data time: 8.16e-02, avg batch time: 0.5099, average train loss: 0.0309
[09/28 04:44:44 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1786, average loss: 0.0260
[09/28 04:44:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:45:06 visual_prompt]: 	Test 100/157. loss: 0.956, 0.2059 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 04:45:19 visual_prompt]: Inference (test):avg data time: 1.67e-04, avg batch time: 0.2045, average loss: 1.0149
[09/28 04:45:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.77	top5: 94.52	
[09/28 04:45:19 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/28 04:45:28 visual_prompt]: Epoch 70 / 100: avg data time: 7.91e-02, avg batch time: 0.5089, average train loss: 0.0310
[09/28 04:45:31 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1813, average loss: 0.0258
[09/28 04:45:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:45:53 visual_prompt]: 	Test 100/157. loss: 0.960, 0.2060 s / batch. (data: 2.46e-05)max mem: 7.81378 GB 
[09/28 04:46:05 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2045, average loss: 1.0243
[09/28 04:46:05 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.94	top5: 94.67	
[09/28 04:46:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/28 04:46:15 visual_prompt]: Epoch 71 / 100: avg data time: 9.10e-02, avg batch time: 0.5181, average train loss: 0.0306
[09/28 04:46:17 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1746, average loss: 0.0269
[09/28 04:46:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:46:39 visual_prompt]: 	Test 100/157. loss: 0.940, 0.2050 s / batch. (data: 2.31e-05)max mem: 7.81378 GB 
[09/28 04:46:52 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2041, average loss: 1.0496
[09/28 04:46:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.26	top5: 94.23	
[09/28 04:46:52 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/28 04:47:01 visual_prompt]: Epoch 72 / 100: avg data time: 8.34e-02, avg batch time: 0.5098, average train loss: 0.0308
[09/28 04:47:04 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1757, average loss: 0.0260
[09/28 04:47:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:47:26 visual_prompt]: 	Test 100/157. loss: 0.957, 0.2059 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 04:47:38 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2043, average loss: 1.0252
[09/28 04:47:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.80	top5: 94.54	
[09/28 04:47:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/28 04:47:48 visual_prompt]: Epoch 73 / 100: avg data time: 9.67e-02, avg batch time: 0.5243, average train loss: 0.0306
[09/28 04:47:51 visual_prompt]: Inference (val):avg data time: 5.00e-05, avg batch time: 0.1858, average loss: 0.0254
[09/28 04:47:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:48:13 visual_prompt]: 	Test 100/157. loss: 0.964, 0.2038 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 04:48:25 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2044, average loss: 1.0351
[09/28 04:48:25 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.66	top5: 94.36	
[09/28 04:48:25 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/28 04:48:35 visual_prompt]: Epoch 74 / 100: avg data time: 9.36e-02, avg batch time: 0.5206, average train loss: 0.0302
[09/28 04:48:38 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1780, average loss: 0.0255
[09/28 04:48:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:49:00 visual_prompt]: 	Test 100/157. loss: 0.967, 0.2050 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 04:49:12 visual_prompt]: Inference (test):avg data time: 6.34e-05, avg batch time: 0.2042, average loss: 1.0228
[09/28 04:49:12 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.86	top5: 94.45	
[09/28 04:49:12 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/28 04:49:21 visual_prompt]: Epoch 75 / 100: avg data time: 8.79e-02, avg batch time: 0.5153, average train loss: 0.0301
[09/28 04:49:24 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1861, average loss: 0.0252
[09/28 04:49:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:49:46 visual_prompt]: 	Test 100/157. loss: 0.969, 0.2062 s / batch. (data: 3.24e-05)max mem: 7.81378 GB 
[09/28 04:49:59 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2046, average loss: 1.0536
[09/28 04:49:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.42	top5: 94.36	
[09/28 04:49:59 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/28 04:50:08 visual_prompt]: Epoch 76 / 100: avg data time: 8.92e-02, avg batch time: 0.5163, average train loss: 0.0300
[09/28 04:50:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1807, average loss: 0.0260
[09/28 04:50:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:50:33 visual_prompt]: 	Test 100/157. loss: 1.006, 0.2045 s / batch. (data: 2.46e-05)max mem: 7.81378 GB 
[09/28 04:50:46 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.2047, average loss: 1.0574
[09/28 04:50:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.04	top5: 94.13	
[09/28 04:50:46 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/28 04:50:55 visual_prompt]: Epoch 77 / 100: avg data time: 8.59e-02, avg batch time: 0.5153, average train loss: 0.0301
[09/28 04:50:58 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1818, average loss: 0.0253
[09/28 04:50:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:51:20 visual_prompt]: 	Test 100/157. loss: 1.000, 0.2054 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 04:51:33 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2044, average loss: 1.0532
[09/28 04:51:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.37	top5: 94.00	
[09/28 04:51:33 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/28 04:51:42 visual_prompt]: Epoch 78 / 100: avg data time: 9.70e-02, avg batch time: 0.5243, average train loss: 0.0301
[09/28 04:51:45 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1762, average loss: 0.0257
[09/28 04:51:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:52:07 visual_prompt]: 	Test 100/157. loss: 0.994, 0.2050 s / batch. (data: 2.53e-05)max mem: 7.81378 GB 
[09/28 04:52:19 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2046, average loss: 1.0618
[09/28 04:52:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 74.19	top5: 94.07	
[09/28 04:52:19 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/28 04:52:28 visual_prompt]: Epoch 79 / 100: avg data time: 9.00e-02, avg batch time: 0.5167, average train loss: 0.0297
[09/28 04:52:31 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1865, average loss: 0.0253
[09/28 04:52:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:52:53 visual_prompt]: 	Test 100/157. loss: 1.041, 0.2052 s / batch. (data: 4.05e-05)max mem: 7.81378 GB 
[09/28 04:53:06 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2045, average loss: 1.0716
[09/28 04:53:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.93	top5: 94.00	
[09/28 04:53:06 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/28 04:53:15 visual_prompt]: Epoch 80 / 100: avg data time: 9.87e-02, avg batch time: 0.5269, average train loss: 0.0294
[09/28 04:53:18 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1803, average loss: 0.0252
[09/28 04:53:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:53:40 visual_prompt]: 	Test 100/157. loss: 1.062, 0.2052 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 04:53:53 visual_prompt]: Inference (test):avg data time: 5.68e-05, avg batch time: 0.2046, average loss: 1.0875
[09/28 04:53:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.72	top5: 93.83	
[09/28 04:53:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/28 04:54:02 visual_prompt]: Epoch 81 / 100: avg data time: 9.20e-02, avg batch time: 0.5181, average train loss: 0.0295
[09/28 04:54:05 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1738, average loss: 0.0251
[09/28 04:54:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:54:27 visual_prompt]: 	Test 100/157. loss: 1.046, 0.2057 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 04:54:39 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2045, average loss: 1.0767
[09/28 04:54:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.88	top5: 93.98	
[09/28 04:54:39 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/28 04:54:49 visual_prompt]: Epoch 82 / 100: avg data time: 8.81e-02, avg batch time: 0.5149, average train loss: 0.0291
[09/28 04:54:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1742, average loss: 0.0252
[09/28 04:54:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:55:13 visual_prompt]: 	Test 100/157. loss: 0.999, 0.2058 s / batch. (data: 3.12e-05)max mem: 7.81378 GB 
[09/28 04:55:26 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2042, average loss: 1.0798
[09/28 04:55:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.67	top5: 93.99	
[09/28 04:55:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/28 04:55:35 visual_prompt]: Epoch 83 / 100: avg data time: 8.78e-02, avg batch time: 0.5144, average train loss: 0.0290
[09/28 04:55:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1720, average loss: 0.0251
[09/28 04:55:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:56:00 visual_prompt]: 	Test 100/157. loss: 1.036, 0.2056 s / batch. (data: 2.57e-05)max mem: 7.81378 GB 
[09/28 04:56:12 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2046, average loss: 1.0948
[09/28 04:56:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.44	top5: 93.81	
[09/28 04:56:13 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/28 04:56:22 visual_prompt]: Epoch 84 / 100: avg data time: 8.23e-02, avg batch time: 0.5115, average train loss: 0.0290
[09/28 04:56:24 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1738, average loss: 0.0249
[09/28 04:56:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:56:46 visual_prompt]: 	Test 100/157. loss: 1.081, 0.2051 s / batch. (data: 3.67e-05)max mem: 7.81378 GB 
[09/28 04:56:59 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2041, average loss: 1.0889
[09/28 04:56:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.68	top5: 93.86	
[09/28 04:56:59 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/28 04:57:08 visual_prompt]: Epoch 85 / 100: avg data time: 8.14e-02, avg batch time: 0.5112, average train loss: 0.0289
[09/28 04:57:11 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1800, average loss: 0.0248
[09/28 04:57:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:57:33 visual_prompt]: 	Test 100/157. loss: 1.082, 0.2049 s / batch. (data: 2.84e-05)max mem: 7.81378 GB 
[09/28 04:57:45 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2043, average loss: 1.0978
[09/28 04:57:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.29	top5: 93.72	
[09/28 04:57:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/28 04:57:55 visual_prompt]: Epoch 86 / 100: avg data time: 9.39e-02, avg batch time: 0.5229, average train loss: 0.0290
[09/28 04:57:58 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1790, average loss: 0.0246
[09/28 04:57:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:58:20 visual_prompt]: 	Test 100/157. loss: 1.067, 0.2053 s / batch. (data: 3.00e-05)max mem: 7.81378 GB 
[09/28 04:58:32 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2043, average loss: 1.0811
[09/28 04:58:32 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.71	top5: 93.97	
[09/28 04:58:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/28 04:58:42 visual_prompt]: Epoch 87 / 100: avg data time: 9.48e-02, avg batch time: 0.5227, average train loss: 0.0289
[09/28 04:58:45 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1779, average loss: 0.0248
[09/28 04:58:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:59:07 visual_prompt]: 	Test 100/157. loss: 1.071, 0.2048 s / batch. (data: 2.88e-05)max mem: 7.81378 GB 
[09/28 04:59:19 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2040, average loss: 1.0949
[09/28 04:59:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.39	top5: 93.79	
[09/28 04:59:19 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/28 04:59:28 visual_prompt]: Epoch 88 / 100: avg data time: 8.95e-02, avg batch time: 0.5160, average train loss: 0.0287
[09/28 04:59:31 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1756, average loss: 0.0249
[09/28 04:59:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 04:59:53 visual_prompt]: 	Test 100/157. loss: 1.101, 0.2051 s / batch. (data: 2.77e-05)max mem: 7.81378 GB 
[09/28 05:00:06 visual_prompt]: Inference (test):avg data time: 1.72e-04, avg batch time: 0.2045, average loss: 1.1017
[09/28 05:00:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.20	top5: 93.81	
[09/28 05:00:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/28 05:00:15 visual_prompt]: Epoch 89 / 100: avg data time: 8.96e-02, avg batch time: 0.5170, average train loss: 0.0287
[09/28 05:00:18 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1758, average loss: 0.0249
[09/28 05:00:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:00:40 visual_prompt]: 	Test 100/157. loss: 1.105, 0.2039 s / batch. (data: 2.98e-05)max mem: 7.81378 GB 
[09/28 05:00:52 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2043, average loss: 1.0984
[09/28 05:00:52 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.33	top5: 93.81	
[09/28 05:00:52 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/28 05:01:02 visual_prompt]: Epoch 90 / 100: avg data time: 8.96e-02, avg batch time: 0.5181, average train loss: 0.0285
[09/28 05:01:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1820, average loss: 0.0247
[09/28 05:01:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:01:27 visual_prompt]: 	Test 100/157. loss: 1.112, 0.2052 s / batch. (data: 2.65e-05)max mem: 7.81378 GB 
[09/28 05:01:39 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2046, average loss: 1.1074
[09/28 05:01:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.12	top5: 93.67	
[09/28 05:01:39 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/28 05:01:48 visual_prompt]: Epoch 91 / 100: avg data time: 8.81e-02, avg batch time: 0.5181, average train loss: 0.0285
[09/28 05:01:51 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1849, average loss: 0.0249
[09/28 05:01:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:02:13 visual_prompt]: 	Test 100/157. loss: 1.127, 0.2052 s / batch. (data: 3.53e-05)max mem: 7.81378 GB 
[09/28 05:02:26 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2046, average loss: 1.1064
[09/28 05:02:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.07	top5: 93.70	
[09/28 05:02:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/28 05:02:35 visual_prompt]: Epoch 92 / 100: avg data time: 8.74e-02, avg batch time: 0.5143, average train loss: 0.0287
[09/28 05:02:38 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1739, average loss: 0.0246
[09/28 05:02:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:03:00 visual_prompt]: 	Test 100/157. loss: 1.122, 0.2047 s / batch. (data: 2.81e-05)max mem: 7.81378 GB 
[09/28 05:03:12 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2042, average loss: 1.1002
[09/28 05:03:13 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.22	top5: 93.76	
[09/28 05:03:13 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/28 05:03:22 visual_prompt]: Epoch 93 / 100: avg data time: 8.60e-02, avg batch time: 0.5163, average train loss: 0.0285
[09/28 05:03:24 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1733, average loss: 0.0246
[09/28 05:03:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:03:47 visual_prompt]: 	Test 100/157. loss: 1.116, 0.2056 s / batch. (data: 3.03e-05)max mem: 7.81378 GB 
[09/28 05:03:59 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2044, average loss: 1.1041
[09/28 05:03:59 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.23	top5: 93.73	
[09/28 05:03:59 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/28 05:04:08 visual_prompt]: Epoch 94 / 100: avg data time: 9.06e-02, avg batch time: 0.5178, average train loss: 0.0285
[09/28 05:04:11 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1825, average loss: 0.0246
[09/28 05:04:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:04:33 visual_prompt]: 	Test 100/157. loss: 1.118, 0.2060 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 05:04:46 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2044, average loss: 1.1052
[09/28 05:04:46 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.31	top5: 93.73	
[09/28 05:04:46 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/28 05:04:55 visual_prompt]: Epoch 95 / 100: avg data time: 9.38e-02, avg batch time: 0.5210, average train loss: 0.0285
[09/28 05:04:58 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1739, average loss: 0.0247
[09/28 05:04:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:05:20 visual_prompt]: 	Test 100/157. loss: 1.118, 0.2051 s / batch. (data: 2.79e-05)max mem: 7.81378 GB 
[09/28 05:05:32 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2041, average loss: 1.1074
[09/28 05:05:33 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.15	top5: 93.67	
[09/28 05:05:33 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/28 05:05:42 visual_prompt]: Epoch 96 / 100: avg data time: 9.27e-02, avg batch time: 0.5213, average train loss: 0.0285
[09/28 05:05:45 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1783, average loss: 0.0248
[09/28 05:05:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:06:07 visual_prompt]: 	Test 100/157. loss: 1.119, 0.2045 s / batch. (data: 3.17e-05)max mem: 7.81378 GB 
[09/28 05:06:19 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2044, average loss: 1.1088
[09/28 05:06:19 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.14	top5: 93.69	
[09/28 05:06:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/28 05:06:28 visual_prompt]: Epoch 97 / 100: avg data time: 9.01e-02, avg batch time: 0.5188, average train loss: 0.0284
[09/28 05:06:31 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1810, average loss: 0.0247
[09/28 05:06:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:06:53 visual_prompt]: 	Test 100/157. loss: 1.119, 0.2057 s / batch. (data: 2.74e-05)max mem: 7.81378 GB 
[09/28 05:07:06 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2044, average loss: 1.1082
[09/28 05:07:06 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.04	top5: 93.73	
[09/28 05:07:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/28 05:07:15 visual_prompt]: Epoch 98 / 100: avg data time: 8.85e-02, avg batch time: 0.5169, average train loss: 0.0283
[09/28 05:07:18 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1839, average loss: 0.0247
[09/28 05:07:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:07:40 visual_prompt]: 	Test 100/157. loss: 1.117, 0.2046 s / batch. (data: 2.91e-05)max mem: 7.81378 GB 
[09/28 05:07:53 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2042, average loss: 1.1088
[09/28 05:07:53 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.05	top5: 93.73	
[09/28 05:07:53 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/28 05:08:02 visual_prompt]: Epoch 99 / 100: avg data time: 8.19e-02, avg batch time: 0.5100, average train loss: 0.0284
[09/28 05:08:05 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1730, average loss: 0.0247
[09/28 05:08:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:08:27 visual_prompt]: 	Test 100/157. loss: 1.118, 0.2042 s / batch. (data: 2.72e-05)max mem: 7.81378 GB 
[09/28 05:08:39 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2045, average loss: 1.1090
[09/28 05:08:39 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.05	top5: 93.71	
[09/28 05:08:39 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/28 05:08:48 visual_prompt]: Epoch 100 / 100: avg data time: 9.07e-02, avg batch time: 0.5164, average train loss: 0.0286
[09/28 05:08:51 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1863, average loss: 0.0247
[09/28 05:08:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 100.00	top5: 100.00	
[09/28 05:09:13 visual_prompt]: 	Test 100/157. loss: 1.118, 0.2062 s / batch. (data: 7.70e-05)max mem: 7.81378 GB 
[09/28 05:09:26 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2043, average loss: 1.1090
[09/28 05:09:26 visual_prompt]: Classification results with test_vtab-cifar(num_classes=100): top1: 73.05	top5: 93.70	
