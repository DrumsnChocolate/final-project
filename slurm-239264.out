/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/08 18:18:26 visual_prompt]: Rank of current process: 0. World size: 1
[10/08 18:18:29 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/08 18:18:29 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/08 18:18:29 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/08 18:18:29 visual_prompt]: Training with config:
[10/08 18:18:29 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/08 18:18:29 visual_prompt]: Loading training data...
[10/08 18:18:29 visual_prompt]: Constructing mammo-cbis dataset train...
[10/08 18:18:29 visual_prompt]: Loading validation data...
[10/08 18:18:29 visual_prompt]: Constructing mammo-cbis dataset val...
[10/08 18:18:29 visual_prompt]: Constructing models...
[10/08 18:18:34 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/08 18:18:34 visual_prompt]: tuned percent:0.536
[10/08 18:18:34 visual_prompt]: Device used for model: 0
[10/08 18:18:34 visual_prompt]: Setting up Evaluator...
[10/08 18:18:34 visual_prompt]: Setting up Trainer...
[10/08 18:18:34 visual_prompt]: 	Setting up the optimizer...
[10/08 18:18:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/08 18:25:15 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.4482, average train loss: 1.4524
[10/08 18:26:00 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2168, average loss: 1.4398
[10/08 18:26:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/08 18:26:00 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[10/08 18:32:16 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 10.7363, average train loss: 5.2629
[10/08 18:32:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2421, average loss: 1.0702
[10/08 18:32:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.69	
[10/08 18:32:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[10/08 18:39:15 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 10.7480, average train loss: 0.8149
[10/08 18:39:58 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.2322, average loss: 0.7242
[10/08 18:39:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.81	
[10/08 18:39:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[10/08 18:46:18 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e+01, avg batch time: 10.8713, average train loss: 1.3102
[10/08 18:47:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.2138, average loss: 1.8029
[10/08 18:47:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.80	
[10/08 18:47:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[10/08 18:53:18 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e+01, avg batch time: 10.7722, average train loss: 1.1591
[10/08 18:54:02 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.2318, average loss: 1.2950
[10/08 18:54:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.11	
[10/08 18:54:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[10/08 19:00:23 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e+01, avg batch time: 10.8973, average train loss: 2.4734
[10/08 19:01:07 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2094, average loss: 1.2398
[10/08 19:01:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.23	
[10/08 19:01:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[10/08 19:07:27 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 10.8532, average train loss: 4.2808
[10/08 19:08:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2284, average loss: 2.3885
[10/08 19:08:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.24	
[10/08 19:08:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[10/08 19:14:26 visual_prompt]: Epoch 8 / 100: avg data time: 1.03e+01, avg batch time: 10.7554, average train loss: 4.3807
[10/08 19:15:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.2101, average loss: 1.5825
[10/08 19:15:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.04	
[10/08 19:15:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[10/08 19:21:27 visual_prompt]: Epoch 9 / 100: avg data time: 1.03e+01, avg batch time: 10.8077, average train loss: 7.6512
[10/08 19:22:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.2276, average loss: 9.8387
[10/08 19:22:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.74	
[10/08 19:22:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[10/08 19:28:28 visual_prompt]: Epoch 10 / 100: avg data time: 1.03e+01, avg batch time: 10.7776, average train loss: 7.2738
[10/08 19:29:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.2360, average loss: 1.3416
[10/08 19:29:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.25	
[10/08 19:29:11 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[10/08 19:35:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e+01, avg batch time: 10.7903, average train loss: 9.7746
[10/08 19:36:11 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2249, average loss: 17.5989
[10/08 19:36:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.21	
[10/08 19:36:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[10/08 19:42:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.03e+01, avg batch time: 10.7406, average train loss: 9.3399
[10/08 19:43:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.2313, average loss: 9.8239
[10/08 19:43:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.73	
[10/08 19:43:11 visual_prompt]: Best epoch 12: best metric: -9.824
[10/08 19:43:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[10/08 19:49:27 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e+01, avg batch time: 10.7432, average train loss: 10.8688
[10/08 19:50:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.2369, average loss: 4.2955
[10/08 19:50:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.90	
[10/08 19:50:10 visual_prompt]: Best epoch 13: best metric: -4.295
[10/08 19:50:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[10/08 19:56:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e+01, avg batch time: 10.7386, average train loss: 7.0850
[10/08 19:57:08 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2148, average loss: 19.3817
[10/08 19:57:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.55	
[10/08 19:57:08 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[10/08 20:03:26 visual_prompt]: Epoch 15 / 100: avg data time: 1.03e+01, avg batch time: 10.7751, average train loss: 10.8186
[10/08 20:04:08 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.2100, average loss: 5.8920
[10/08 20:04:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.74	
[10/08 20:04:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[10/08 20:10:24 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.7293, average train loss: 6.8589
[10/08 20:11:07 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2079, average loss: 4.3114
[10/08 20:11:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.27	
[10/08 20:11:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[10/08 20:17:23 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e+01, avg batch time: 10.7414, average train loss: 9.5130
[10/08 20:18:05 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2090, average loss: 3.0557
[10/08 20:18:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.54	
[10/08 20:18:05 visual_prompt]: Best epoch 17: best metric: -3.056
[10/08 20:18:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[10/08 20:24:22 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e+01, avg batch time: 10.7548, average train loss: 8.3001
[10/08 20:25:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2146, average loss: 44.5825
[10/08 20:25:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.54	
[10/08 20:25:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[10/08 20:31:21 visual_prompt]: Epoch 19 / 100: avg data time: 1.03e+01, avg batch time: 10.7436, average train loss: 16.6955
[10/08 20:32:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2256, average loss: 13.6642
[10/08 20:32:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[10/08 20:32:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[10/08 20:38:20 visual_prompt]: Epoch 20 / 100: avg data time: 1.03e+01, avg batch time: 10.7447, average train loss: 10.6575
[10/08 20:39:03 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2271, average loss: 3.3306
[10/08 20:39:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.07	
[10/08 20:39:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[10/08 20:45:19 visual_prompt]: Epoch 21 / 100: avg data time: 1.03e+01, avg batch time: 10.7430, average train loss: 7.8375
[10/08 20:46:01 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2065, average loss: 6.6877
[10/08 20:46:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.66	
[10/08 20:46:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[10/08 20:52:17 visual_prompt]: Epoch 22 / 100: avg data time: 1.03e+01, avg batch time: 10.7423, average train loss: 8.1682
[10/08 20:53:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2270, average loss: 1.6552
[10/08 20:53:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.31	
[10/08 20:53:00 visual_prompt]: Best epoch 22: best metric: -1.655
[10/08 20:53:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[10/08 20:59:16 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 10.7328, average train loss: 5.1815
[10/08 20:59:59 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.2371, average loss: 5.5957
[10/08 20:59:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.44	
[10/08 20:59:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[10/08 21:06:15 visual_prompt]: Epoch 24 / 100: avg data time: 1.03e+01, avg batch time: 10.7486, average train loss: 6.6181
[10/08 21:06:58 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2091, average loss: 1.9396
[10/08 21:06:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.86	
[10/08 21:06:58 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[10/08 21:13:14 visual_prompt]: Epoch 25 / 100: avg data time: 1.03e+01, avg batch time: 10.7478, average train loss: 7.1925
[10/08 21:13:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2207, average loss: 12.6802
[10/08 21:13:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.52	
[10/08 21:13:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[10/08 21:20:13 visual_prompt]: Epoch 26 / 100: avg data time: 1.03e+01, avg batch time: 10.7433, average train loss: 12.0797
[10/08 21:20:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2406, average loss: 23.4375
[10/08 21:20:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.00	
[10/08 21:20:56 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[10/08 21:27:13 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e+01, avg batch time: 10.7558, average train loss: 8.7149
[10/08 21:27:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2064, average loss: 4.6368
[10/08 21:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.50	
[10/08 21:27:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[10/08 21:34:11 visual_prompt]: Epoch 28 / 100: avg data time: 1.03e+01, avg batch time: 10.7180, average train loss: 11.5669
[10/08 21:34:54 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2241, average loss: 2.5181
[10/08 21:34:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.59	
[10/08 21:34:54 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[10/08 21:41:11 visual_prompt]: Epoch 29 / 100: avg data time: 1.03e+01, avg batch time: 10.7702, average train loss: 8.6941
[10/08 21:41:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2128, average loss: 6.5074
[10/08 21:41:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.94	
[10/08 21:41:54 visual_prompt]: Stopping early.
[10/08 21:41:54 visual_prompt]: Rank of current process: 0. World size: 1
[10/08 21:41:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/08 21:41:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/08 21:41:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/08 21:41:54 visual_prompt]: Training with config:
[10/08 21:41:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/08 21:41:54 visual_prompt]: Loading training data...
[10/08 21:41:54 visual_prompt]: Constructing mammo-cbis dataset train...
[10/08 21:41:54 visual_prompt]: Loading validation data...
[10/08 21:41:54 visual_prompt]: Constructing mammo-cbis dataset val...
[10/08 21:41:54 visual_prompt]: Constructing models...
[10/08 21:41:56 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/08 21:41:56 visual_prompt]: tuned percent:0.536
[10/08 21:41:56 visual_prompt]: Device used for model: 0
[10/08 21:41:56 visual_prompt]: Setting up Evaluator...
[10/08 21:41:56 visual_prompt]: Setting up Trainer...
[10/08 21:41:56 visual_prompt]: 	Setting up the optimizer...
[10/08 21:41:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/08 21:48:13 visual_prompt]: Epoch 1 / 100: avg data time: 1.03e+01, avg batch time: 10.7583, average train loss: 1.4524
[10/08 21:48:56 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.2332, average loss: 1.4398
[10/08 21:48:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/08 21:48:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[10/08 21:55:12 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 10.7477, average train loss: 5.3815
[10/08 21:55:56 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.2365, average loss: 1.5738
[10/08 21:55:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.66	
[10/08 21:55:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[10/08 22:02:12 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 10.7565, average train loss: 0.9784
[10/08 22:02:55 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.2086, average loss: 0.6952
[10/08 22:02:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.87	
[10/08 22:02:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[10/08 22:09:12 visual_prompt]: Epoch 4 / 100: avg data time: 1.03e+01, avg batch time: 10.7748, average train loss: 1.6524
[10/08 22:09:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.2195, average loss: 2.8253
[10/08 22:09:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.79	
[10/08 22:09:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[10/08 22:16:11 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e+01, avg batch time: 10.7403, average train loss: 3.6954
[10/08 22:16:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.2244, average loss: 5.7733
[10/08 22:16:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[10/08 22:16:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[10/08 22:23:11 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e+01, avg batch time: 10.7671, average train loss: 6.7541
[10/08 22:23:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2320, average loss: 4.0858
[10/08 22:23:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.07	
[10/08 22:23:54 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[10/08 22:30:12 visual_prompt]: Epoch 7 / 100: avg data time: 1.03e+01, avg batch time: 10.7757, average train loss: 2.7927
[10/08 22:30:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.2372, average loss: 4.9259
[10/08 22:30:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.08	
[10/08 22:30:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[10/08 22:37:11 visual_prompt]: Epoch 8 / 100: avg data time: 1.03e+01, avg batch time: 10.7510, average train loss: 3.6375
[10/08 22:37:54 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.2166, average loss: 0.9013
[10/08 22:37:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.84	
[10/08 22:37:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[10/08 22:44:11 visual_prompt]: Epoch 9 / 100: avg data time: 1.03e+01, avg batch time: 10.7819, average train loss: 5.0259
[10/08 22:44:54 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2306, average loss: 1.4257
[10/08 22:44:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.76	
[10/08 22:44:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[10/08 22:51:11 visual_prompt]: Epoch 10 / 100: avg data time: 1.03e+01, avg batch time: 10.7462, average train loss: 6.3828
[10/08 22:51:54 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.2358, average loss: 12.1854
[10/08 22:51:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.55	
[10/08 22:51:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[10/08 22:58:10 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e+01, avg batch time: 10.7530, average train loss: 5.0710
[10/08 22:58:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.2347, average loss: 4.0378
[10/08 22:58:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.61	
[10/08 22:58:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[10/08 23:05:09 visual_prompt]: Epoch 12 / 100: avg data time: 1.03e+01, avg batch time: 10.7377, average train loss: 3.8371
[10/08 23:05:52 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.2200, average loss: 5.5004
[10/08 23:05:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.49	
[10/08 23:05:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[10/08 23:12:09 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e+01, avg batch time: 10.7626, average train loss: 5.8047
[10/08 23:12:52 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.2334, average loss: 3.2413
[10/08 23:12:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.78	
[10/08 23:12:52 visual_prompt]: Best epoch 13: best metric: -3.241
[10/08 23:12:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[10/08 23:19:11 visual_prompt]: Epoch 14 / 100: avg data time: 1.04e+01, avg batch time: 10.8285, average train loss: 5.0316
[10/08 23:19:54 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2341, average loss: 2.4875
[10/08 23:19:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.89	
[10/08 23:19:54 visual_prompt]: Best epoch 14: best metric: -2.488
[10/08 23:19:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[10/08 23:26:17 visual_prompt]: Epoch 15 / 100: avg data time: 1.04e+01, avg batch time: 10.9172, average train loss: 4.8197
[10/08 23:27:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.2225, average loss: 2.8245
[10/08 23:27:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.28	
[10/08 23:27:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[10/08 23:33:17 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.7704, average train loss: 2.4972
[10/08 23:34:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2352, average loss: 10.3626
[10/08 23:34:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.32	
[10/08 23:34:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[10/08 23:40:17 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e+01, avg batch time: 10.7595, average train loss: 4.1236
[10/08 23:41:00 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2108, average loss: 1.4639
[10/08 23:41:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.95	
[10/08 23:41:00 visual_prompt]: Best epoch 17: best metric: -1.464
[10/08 23:41:00 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[10/08 23:47:18 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e+01, avg batch time: 10.7971, average train loss: 2.4507
[10/08 23:48:01 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2270, average loss: 1.2570
[10/08 23:48:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.88	
[10/08 23:48:01 visual_prompt]: Best epoch 18: best metric: -1.257
[10/08 23:48:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[10/08 23:54:33 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.1997, average train loss: 1.4804
[10/08 23:55:23 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2379, average loss: 1.2821
[10/08 23:55:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.84	
[10/08 23:55:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[10/09 00:02:30 visual_prompt]: Epoch 20 / 100: avg data time: 1.17e+01, avg batch time: 12.1742, average train loss: 0.9138
[10/09 00:03:14 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2400, average loss: 0.6851
[10/09 00:03:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.13	
[10/09 00:03:14 visual_prompt]: Best epoch 20: best metric: -0.685
[10/09 00:03:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[10/09 00:09:37 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.9488, average train loss: 1.6099
[10/09 00:10:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2274, average loss: 0.8051
[10/09 00:10:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.26	
[10/09 00:10:21 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[10/09 00:16:45 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9518, average train loss: 1.1901
[10/09 00:17:29 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.2332, average loss: 1.2438
[10/09 00:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.79	
[10/09 00:17:29 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[10/09 00:23:54 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 11.0066, average train loss: 1.7925
[10/09 00:24:40 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2377, average loss: 1.0707
[10/09 00:24:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.00	
[10/09 00:24:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[10/09 00:31:23 visual_prompt]: Epoch 24 / 100: avg data time: 1.11e+01, avg batch time: 11.5175, average train loss: 1.0617
[10/09 00:32:09 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2092, average loss: 1.4535
[10/09 00:32:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[10/09 00:32:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[10/09 00:38:46 visual_prompt]: Epoch 25 / 100: avg data time: 1.09e+01, avg batch time: 11.3565, average train loss: 1.7549
[10/09 00:39:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2323, average loss: 0.6911
[10/09 00:39:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.85	
[10/09 00:39:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[10/09 00:46:04 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.2133, average train loss: 1.5574
[10/09 00:46:50 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2119, average loss: 3.5944
[10/09 00:46:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.46	
[10/09 00:46:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[10/09 00:53:29 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.4014, average train loss: 8.4710
[10/09 00:54:15 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2412, average loss: 11.3124
[10/09 00:54:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.27	
[10/09 00:54:15 visual_prompt]: Stopping early.
[10/09 00:54:15 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 00:54:15 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 00:54:15 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 00:54:15 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 00:54:15 visual_prompt]: Training with config:
[10/09 00:54:15 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 00:54:15 visual_prompt]: Loading training data...
[10/09 00:54:15 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 00:54:15 visual_prompt]: Loading validation data...
[10/09 00:54:15 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 00:54:15 visual_prompt]: Constructing models...
[10/09 00:54:21 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 00:54:21 visual_prompt]: tuned percent:0.536
[10/09 00:54:21 visual_prompt]: Device used for model: 0
[10/09 00:54:21 visual_prompt]: Setting up Evaluator...
[10/09 00:54:21 visual_prompt]: Setting up Trainer...
[10/09 00:54:21 visual_prompt]: 	Setting up the optimizer...
[10/09 00:54:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 01:00:53 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.1921, average train loss: 1.4524
[10/09 01:01:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2081, average loss: 1.4398
[10/09 01:01:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 01:01:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[10/09 01:08:05 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0840, average train loss: 5.3814
[10/09 01:08:49 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2342, average loss: 1.5768
[10/09 01:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.13	
[10/09 01:08:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[10/09 01:15:15 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0076, average train loss: 0.9821
[10/09 01:15:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2377, average loss: 0.6970
[10/09 01:15:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[10/09 01:15:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[10/09 01:22:24 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0027, average train loss: 1.6481
[10/09 01:23:08 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2232, average loss: 2.5962
[10/09 01:23:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.30	
[10/09 01:23:08 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[10/09 01:29:33 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9871, average train loss: 3.1472
[10/09 01:30:16 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.2347, average loss: 1.8162
[10/09 01:30:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.49	
[10/09 01:30:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[10/09 01:36:42 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.0076, average train loss: 1.0607
[10/09 01:37:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2151, average loss: 1.0098
[10/09 01:37:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.81	
[10/09 01:37:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[10/09 01:43:51 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0071, average train loss: 1.4302
[10/09 01:44:35 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2310, average loss: 4.2510
[10/09 01:44:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.23	
[10/09 01:44:35 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[10/09 01:51:00 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9867, average train loss: 2.3865
[10/09 01:51:44 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2286, average loss: 8.1600
[10/09 01:51:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.15	
[10/09 01:51:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[10/09 01:58:10 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0266, average train loss: 3.7088
[10/09 01:58:54 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2102, average loss: 1.2451
[10/09 01:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.44	
[10/09 01:58:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[10/09 02:05:18 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9891, average train loss: 7.1342
[10/09 02:06:03 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2046, average loss: 8.5806
[10/09 02:06:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.04	
[10/09 02:06:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[10/09 02:12:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9904, average train loss: 8.5156
[10/09 02:13:12 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.2202, average loss: 8.7487
[10/09 02:13:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.28	
[10/09 02:13:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[10/09 02:19:37 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9941, average train loss: 6.6639
[10/09 02:20:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2266, average loss: 9.2732
[10/09 02:20:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.75	
[10/09 02:20:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[10/09 02:26:47 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0357, average train loss: 5.6000
[10/09 02:27:32 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2363, average loss: 4.7814
[10/09 02:27:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.89	
[10/09 02:27:32 visual_prompt]: Best epoch 13: best metric: -4.781
[10/09 02:27:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[10/09 02:33:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9815, average train loss: 5.2247
[10/09 02:34:40 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2313, average loss: 0.7641
[10/09 02:34:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.88	
[10/09 02:34:40 visual_prompt]: Best epoch 14: best metric: -0.764
[10/09 02:34:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[10/09 02:41:05 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0087, average train loss: 3.2208
[10/09 02:41:49 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2078, average loss: 0.8046
[10/09 02:41:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.83	
[10/09 02:41:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[10/09 02:48:14 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9813, average train loss: 2.0302
[10/09 02:48:58 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2086, average loss: 7.2570
[10/09 02:48:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.37	
[10/09 02:48:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[10/09 02:55:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9813, average train loss: 4.2447
[10/09 02:56:06 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2301, average loss: 5.9109
[10/09 02:56:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.15	
[10/09 02:56:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[10/09 03:02:31 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9966, average train loss: 3.1655
[10/09 03:03:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2062, average loss: 2.9510
[10/09 03:03:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.78	
[10/09 03:03:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[10/09 03:09:40 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9763, average train loss: 2.7710
[10/09 03:10:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2328, average loss: 5.1054
[10/09 03:10:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.29	
[10/09 03:10:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[10/09 03:16:49 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0022, average train loss: 2.7820
[10/09 03:17:33 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2138, average loss: 1.7507
[10/09 03:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.81	
[10/09 03:17:33 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[10/09 03:23:58 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.9781, average train loss: 1.5171
[10/09 03:24:42 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2064, average loss: 3.0478
[10/09 03:24:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.21	
[10/09 03:24:42 visual_prompt]: Stopping early.
[10/09 03:24:42 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 03:24:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 03:24:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 03:24:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 03:24:42 visual_prompt]: Training with config:
[10/09 03:24:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 03:24:42 visual_prompt]: Loading training data...
[10/09 03:24:42 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 03:24:42 visual_prompt]: Loading validation data...
[10/09 03:24:42 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 03:24:42 visual_prompt]: Constructing models...
[10/09 03:24:44 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 03:24:44 visual_prompt]: tuned percent:0.536
[10/09 03:24:44 visual_prompt]: Device used for model: 0
[10/09 03:24:44 visual_prompt]: Setting up Evaluator...
[10/09 03:24:44 visual_prompt]: Setting up Trainer...
[10/09 03:24:44 visual_prompt]: 	Setting up the optimizer...
[10/09 03:24:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 03:31:12 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0643, average train loss: 1.4524
[10/09 03:31:56 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.2350, average loss: 1.4398
[10/09 03:31:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 03:31:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[10/09 03:38:21 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9992, average train loss: 2.7910
[10/09 03:39:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2339, average loss: 0.8564
[10/09 03:39:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.29	
[10/09 03:39:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[10/09 03:45:30 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0012, average train loss: 0.7267
[10/09 03:46:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2042, average loss: 0.8156
[10/09 03:46:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.07	
[10/09 03:46:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[10/09 03:52:39 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0079, average train loss: 0.7883
[10/09 03:53:23 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2209, average loss: 0.9478
[10/09 03:53:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.65	
[10/09 03:53:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[10/09 03:59:48 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9838, average train loss: 0.8971
[10/09 04:00:33 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2234, average loss: 2.0849
[10/09 04:00:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.06	
[10/09 04:00:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[10/09 04:06:58 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0166, average train loss: 1.9069
[10/09 04:07:42 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2164, average loss: 2.2808
[10/09 04:07:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.17	
[10/09 04:07:42 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[10/09 04:14:08 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0184, average train loss: 2.0612
[10/09 04:14:52 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.2418, average loss: 4.6853
[10/09 04:14:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.85	
[10/09 04:14:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[10/09 04:21:18 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0128, average train loss: 1.5950
[10/09 04:22:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2404, average loss: 0.7025
[10/09 04:22:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.29	
[10/09 04:22:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[10/09 04:28:30 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0735, average train loss: 4.3745
[10/09 04:29:14 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2356, average loss: 0.8105
[10/09 04:29:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.99	
[10/09 04:29:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[10/09 04:35:40 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0376, average train loss: 2.4704
[10/09 04:36:25 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2064, average loss: 0.6953
[10/09 04:36:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.31	
[10/09 04:36:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[10/09 04:42:49 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9901, average train loss: 4.8592
[10/09 04:43:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2142, average loss: 2.8737
[10/09 04:43:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.25	
[10/09 04:43:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[10/09 04:49:58 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9989, average train loss: 3.5208
[10/09 04:50:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2269, average loss: 1.5596
[10/09 04:50:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.37	
[10/09 04:50:42 visual_prompt]: Best epoch 12: best metric: -1.560
[10/09 04:50:42 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[10/09 04:57:07 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0021, average train loss: 3.1491
[10/09 04:57:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2257, average loss: 5.2552
[10/09 04:57:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.03	
[10/09 04:57:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[10/09 05:04:16 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9903, average train loss: 4.3469
[10/09 05:05:01 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2332, average loss: 3.2167
[10/09 05:05:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.20	
[10/09 05:05:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[10/09 05:11:26 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0027, average train loss: 5.0121
[10/09 05:12:10 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2183, average loss: 0.6973
[10/09 05:12:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.71	
[10/09 05:12:10 visual_prompt]: Best epoch 15: best metric: -0.697
[10/09 05:12:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[10/09 05:18:34 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9768, average train loss: 2.9627
[10/09 05:19:19 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2353, average loss: 2.0444
[10/09 05:19:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.79	
[10/09 05:19:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[10/09 05:25:43 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9801, average train loss: 3.4393
[10/09 05:26:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2075, average loss: 1.8689
[10/09 05:26:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.34	
[10/09 05:26:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[10/09 05:32:51 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9778, average train loss: 2.7188
[10/09 05:33:35 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2335, average loss: 3.8292
[10/09 05:33:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.34	
[10/09 05:33:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[10/09 05:39:59 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9782, average train loss: 3.7585
[10/09 05:40:43 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2152, average loss: 11.1667
[10/09 05:40:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.78	
[10/09 05:40:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[10/09 05:47:08 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0016, average train loss: 3.4320
[10/09 05:47:52 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2260, average loss: 1.9436
[10/09 05:47:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.02	
[10/09 05:47:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[10/09 05:54:17 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.9904, average train loss: 6.2811
[10/09 05:55:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2222, average loss: 37.6642
[10/09 05:55:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.32	
[10/09 05:55:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[10/09 06:01:26 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9955, average train loss: 8.7958
[10/09 06:02:10 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2290, average loss: 39.1947
[10/09 06:02:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.42	
[10/09 06:02:10 visual_prompt]: Stopping early.
[10/09 06:02:10 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 06:02:10 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 06:02:10 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 06:02:10 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 06:02:10 visual_prompt]: Training with config:
[10/09 06:02:10 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 06:02:10 visual_prompt]: Loading training data...
[10/09 06:02:10 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 06:02:10 visual_prompt]: Loading validation data...
[10/09 06:02:10 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 06:02:10 visual_prompt]: Constructing models...
[10/09 06:02:13 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 06:02:13 visual_prompt]: tuned percent:0.536
[10/09 06:02:13 visual_prompt]: Device used for model: 0
[10/09 06:02:13 visual_prompt]: Setting up Evaluator...
[10/09 06:02:13 visual_prompt]: Setting up Trainer...
[10/09 06:02:13 visual_prompt]: 	Setting up the optimizer...
[10/09 06:02:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 06:08:38 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 11.0011, average train loss: 1.4524
[10/09 06:09:22 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.2042, average loss: 1.4398
[10/09 06:09:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 06:09:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[10/09 06:15:46 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9795, average train loss: 2.9209
[10/09 06:16:30 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2284, average loss: 0.7868
[10/09 06:16:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.13	
[10/09 06:16:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[10/09 06:22:54 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9708, average train loss: 0.7453
[10/09 06:23:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.2213, average loss: 0.7205
[10/09 06:23:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.25	
[10/09 06:23:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[10/09 06:30:04 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0145, average train loss: 0.9062
[10/09 06:30:48 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.2040, average loss: 0.8551
[10/09 06:30:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[10/09 06:30:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[10/09 06:37:12 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9782, average train loss: 0.9603
[10/09 06:37:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2471, average loss: 0.6894
[10/09 06:37:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[10/09 06:37:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[10/09 06:44:21 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.0047, average train loss: 0.9230
[10/09 06:45:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2375, average loss: 0.7966
[10/09 06:45:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[10/09 06:45:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[10/09 06:51:31 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0109, average train loss: 0.9044
[10/09 06:52:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.2318, average loss: 4.4514
[10/09 06:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.13	
[10/09 06:52:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[10/09 06:58:40 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9917, average train loss: 2.5075
[10/09 06:59:24 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2039, average loss: 1.4273
[10/09 06:59:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.30	
[10/09 06:59:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[10/09 07:05:49 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0133, average train loss: 1.4412
[10/09 07:06:33 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.2119, average loss: 0.7607
[10/09 07:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.52	
[10/09 07:06:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[10/09 07:12:58 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9885, average train loss: 0.8806
[10/09 07:13:42 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.2032, average loss: 0.9542
[10/09 07:13:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.93	
[10/09 07:13:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[10/09 07:20:07 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0107, average train loss: 1.0808
[10/09 07:20:51 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2180, average loss: 2.1305
[10/09 07:20:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.07	
[10/09 07:20:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[10/09 07:27:16 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9853, average train loss: 1.7266
[10/09 07:28:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2266, average loss: 0.8499
[10/09 07:28:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.37	
[10/09 07:28:00 visual_prompt]: Best epoch 12: best metric: -0.850
[10/09 07:28:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[10/09 07:34:25 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 10.9980, average train loss: 3.6576
[10/09 07:35:09 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.2085, average loss: 5.3247
[10/09 07:35:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[10/09 07:35:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[10/09 07:41:35 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0263, average train loss: 2.9879
[10/09 07:42:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2452, average loss: 3.0028
[10/09 07:42:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.49	
[10/09 07:42:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[10/09 07:48:46 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0728, average train loss: 1.8226
[10/09 07:49:31 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2325, average loss: 1.3612
[10/09 07:49:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.89	
[10/09 07:49:31 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[10/09 07:55:56 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9984, average train loss: 0.9978
[10/09 07:56:40 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.2346, average loss: 0.7160
[10/09 07:56:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.11	
[10/09 07:56:40 visual_prompt]: Best epoch 16: best metric: -0.716
[10/09 07:56:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[10/09 08:03:04 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9695, average train loss: 0.9038
[10/09 08:03:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2314, average loss: 0.9345
[10/09 08:03:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.49	
[10/09 08:03:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[10/09 08:10:13 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0070, average train loss: 0.8852
[10/09 08:10:57 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2330, average loss: 0.7042
[10/09 08:10:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.06	
[10/09 08:10:57 visual_prompt]: Best epoch 18: best metric: -0.704
[10/09 08:10:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[10/09 08:17:21 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9734, average train loss: 0.7425
[10/09 08:18:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.2342, average loss: 0.6960
[10/09 08:18:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.40	
[10/09 08:18:06 visual_prompt]: Best epoch 19: best metric: -0.696
[10/09 08:18:06 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[10/09 08:24:30 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.9899, average train loss: 0.9444
[10/09 08:25:14 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2123, average loss: 0.6941
[10/09 08:25:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 41.81	
[10/09 08:25:14 visual_prompt]: Best epoch 20: best metric: -0.694
[10/09 08:25:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[10/09 08:31:39 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.9928, average train loss: 0.9625
[10/09 08:32:23 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.2250, average loss: 0.7400
[10/09 08:32:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.84	
[10/09 08:32:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[10/09 08:38:48 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 11.0052, average train loss: 0.8576
[10/09 08:39:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2329, average loss: 0.8279
[10/09 08:39:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.79	
[10/09 08:39:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[10/09 08:45:57 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.9798, average train loss: 0.7677
[10/09 08:46:41 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2145, average loss: 0.7040
[10/09 08:46:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.89	
[10/09 08:46:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[10/09 08:53:06 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.9986, average train loss: 0.7634
[10/09 08:53:50 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.2090, average loss: 0.9280
[10/09 08:53:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.55	
[10/09 08:53:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[10/09 09:00:16 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 11.0157, average train loss: 1.0684
[10/09 09:01:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.2093, average loss: 1.0637
[10/09 09:01:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.50	
[10/09 09:01:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[10/09 09:07:26 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 11.0313, average train loss: 0.9604
[10/09 09:08:11 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.2199, average loss: 0.8331
[10/09 09:08:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.97	
[10/09 09:08:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[10/09 09:14:36 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.9922, average train loss: 0.7840
[10/09 09:15:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2273, average loss: 1.0496
[10/09 09:15:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.45	
[10/09 09:15:20 visual_prompt]: Stopping early.
[10/09 09:15:20 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 09:15:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 09:15:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 09:15:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 09:15:20 visual_prompt]: Training with config:
[10/09 09:15:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 09:15:20 visual_prompt]: Loading training data...
[10/09 09:15:20 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 09:15:20 visual_prompt]: Loading validation data...
[10/09 09:15:20 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 09:15:20 visual_prompt]: Constructing models...
[10/09 09:15:23 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 09:15:23 visual_prompt]: tuned percent:0.536
[10/09 09:15:23 visual_prompt]: Device used for model: 0
[10/09 09:15:23 visual_prompt]: Setting up Evaluator...
[10/09 09:15:23 visual_prompt]: Setting up Trainer...
[10/09 09:15:23 visual_prompt]: 	Setting up the optimizer...
[10/09 09:15:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 09:21:48 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0170, average train loss: 1.4524
[10/09 09:22:32 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2093, average loss: 1.4398
[10/09 09:22:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 09:22:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[10/09 09:28:58 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0098, average train loss: 2.9315
[10/09 09:29:42 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2388, average loss: 0.8063
[10/09 09:29:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.86	
[10/09 09:29:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[10/09 09:36:07 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0019, average train loss: 0.7745
[10/09 09:36:51 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2280, average loss: 0.7258
[10/09 09:36:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.74	
[10/09 09:36:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[10/09 09:43:17 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0151, average train loss: 0.9617
[10/09 09:44:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2244, average loss: 1.0854
[10/09 09:44:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.63	
[10/09 09:44:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[10/09 09:50:25 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9770, average train loss: 1.0329
[10/09 09:51:09 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2287, average loss: 0.6888
[10/09 09:51:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.25	
[10/09 09:51:09 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[10/09 09:57:35 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0277, average train loss: 1.2146
[10/09 09:58:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2054, average loss: 1.8423
[10/09 09:58:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.47	
[10/09 09:58:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[10/09 10:04:45 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0239, average train loss: 0.9712
[10/09 10:05:29 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2305, average loss: 2.9264
[10/09 10:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.86	
[10/09 10:05:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[10/09 10:11:54 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9989, average train loss: 1.0442
[10/09 10:12:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2307, average loss: 1.1879
[10/09 10:12:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[10/09 10:12:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[10/09 10:19:05 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0340, average train loss: 1.1327
[10/09 10:19:49 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.2109, average loss: 1.1015
[10/09 10:19:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.65	
[10/09 10:19:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[10/09 10:26:14 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9942, average train loss: 0.9362
[10/09 10:26:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2235, average loss: 0.9852
[10/09 10:26:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.47	
[10/09 10:26:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[10/09 10:33:25 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0408, average train loss: 5.5582
[10/09 10:34:09 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2360, average loss: 1.0544
[10/09 10:34:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.09	
[10/09 10:34:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[10/09 10:40:33 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9860, average train loss: 4.4907
[10/09 10:41:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2278, average loss: 8.5748
[10/09 10:41:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.42	
[10/09 10:41:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[10/09 10:47:43 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0014, average train loss: 5.7505
[10/09 10:48:27 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2336, average loss: 7.0121
[10/09 10:48:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.45	
[10/09 10:48:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[10/09 10:54:51 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9838, average train loss: 2.6302
[10/09 10:55:35 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.2095, average loss: 6.0106
[10/09 10:55:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.66	
[10/09 10:55:35 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[10/09 11:02:00 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 10.9999, average train loss: 5.2227
[10/09 11:02:44 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.2074, average loss: 6.0662
[10/09 11:02:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.10	
[10/09 11:02:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[10/09 11:09:09 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9908, average train loss: 5.5613
[10/09 11:09:53 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2324, average loss: 3.5478
[10/09 11:09:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.55	
[10/09 11:09:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[10/09 11:16:17 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9742, average train loss: 2.1524
[10/09 11:17:02 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2274, average loss: 1.0804
[10/09 11:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.38	
[10/09 11:17:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[10/09 11:23:26 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9889, average train loss: 1.7046
[10/09 11:24:10 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.2256, average loss: 2.7085
[10/09 11:24:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.09	
[10/09 11:24:10 visual_prompt]: Stopping early.
[10/09 11:24:10 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 11:24:10 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 11:24:10 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 11:24:10 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 11:24:10 visual_prompt]: Training with config:
[10/09 11:24:10 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 11:24:10 visual_prompt]: Loading training data...
[10/09 11:24:10 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 11:24:10 visual_prompt]: Loading validation data...
[10/09 11:24:10 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 11:24:10 visual_prompt]: Constructing models...
[10/09 11:24:13 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 11:24:13 visual_prompt]: tuned percent:0.536
[10/09 11:24:13 visual_prompt]: Device used for model: 0
[10/09 11:24:13 visual_prompt]: Setting up Evaluator...
[10/09 11:24:13 visual_prompt]: Setting up Trainer...
[10/09 11:24:13 visual_prompt]: 	Setting up the optimizer...
[10/09 11:24:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 11:30:38 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.9949, average train loss: 1.4524
[10/09 11:31:22 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2439, average loss: 1.4398
[10/09 11:31:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 11:31:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[10/09 11:37:47 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9992, average train loss: 2.9226
[10/09 11:38:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2128, average loss: 0.8024
[10/09 11:38:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[10/09 11:38:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[10/09 11:44:55 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9803, average train loss: 0.7728
[10/09 11:45:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2028, average loss: 0.7403
[10/09 11:45:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.20	
[10/09 11:45:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[10/09 11:52:05 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0199, average train loss: 0.9787
[10/09 11:52:49 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2198, average loss: 1.1164
[10/09 11:52:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.15	
[10/09 11:52:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[10/09 11:59:14 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0099, average train loss: 1.0421
[10/09 11:59:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2106, average loss: 0.6882
[10/09 11:59:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 53.62	
[10/09 11:59:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[10/09 12:06:24 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0234, average train loss: 1.2330
[10/09 12:07:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2253, average loss: 1.9306
[10/09 12:07:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.30	
[10/09 12:07:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[10/09 12:13:34 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0262, average train loss: 1.4394
[10/09 12:14:18 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2214, average loss: 3.3526
[10/09 12:14:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.79	
[10/09 12:14:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[10/09 12:20:46 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0673, average train loss: 6.3489
[10/09 12:21:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2415, average loss: 6.7749
[10/09 12:21:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.79	
[10/09 12:21:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[10/09 12:27:59 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.1097, average train loss: 4.3378
[10/09 12:28:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2313, average loss: 1.0097
[10/09 12:28:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/09 12:28:43 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[10/09 12:35:08 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9946, average train loss: 2.8130
[10/09 12:35:52 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.2076, average loss: 2.0374
[10/09 12:35:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.23	
[10/09 12:35:52 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[10/09 12:42:18 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0174, average train loss: 1.1103
[10/09 12:43:02 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2107, average loss: 0.7972
[10/09 12:43:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.98	
[10/09 12:43:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[10/09 12:49:26 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9721, average train loss: 1.1579
[10/09 12:50:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.2130, average loss: 1.8316
[10/09 12:50:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.51	
[10/09 12:50:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[10/09 12:56:35 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0098, average train loss: 2.0592
[10/09 12:57:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2222, average loss: 0.9849
[10/09 12:57:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[10/09 12:57:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[10/09 13:03:44 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9973, average train loss: 4.1812
[10/09 13:04:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2061, average loss: 2.9536
[10/09 13:04:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.12	
[10/09 13:04:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[10/09 13:10:54 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0281, average train loss: 1.9033
[10/09 13:11:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2337, average loss: 0.8704
[10/09 13:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.94	
[10/09 13:11:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[10/09 13:18:04 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9891, average train loss: 1.0906
[10/09 13:18:48 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2232, average loss: 0.6952
[10/09 13:18:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 53.60	
[10/09 13:18:48 visual_prompt]: Best epoch 16: best metric: -0.695
[10/09 13:18:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[10/09 13:25:13 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9872, average train loss: 1.7984
[10/09 13:25:57 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2227, average loss: 3.8245
[10/09 13:25:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.94	
[10/09 13:25:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[10/09 13:32:23 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0277, average train loss: 1.8354
[10/09 13:33:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.2043, average loss: 0.7318
[10/09 13:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.47	
[10/09 13:33:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[10/09 13:39:33 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0387, average train loss: 0.9756
[10/09 13:40:17 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2323, average loss: 0.9258
[10/09 13:40:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.50	
[10/09 13:40:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[10/09 13:46:43 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0180, average train loss: 0.8228
[10/09 13:47:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2329, average loss: 0.6931
[10/09 13:47:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 55.69	
[10/09 13:47:27 visual_prompt]: Best epoch 20: best metric: -0.693
[10/09 13:47:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[10/09 13:53:54 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.0589, average train loss: 0.9599
[10/09 13:54:38 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2338, average loss: 1.1930
[10/09 13:54:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.23	
[10/09 13:54:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[10/09 14:01:03 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9925, average train loss: 1.6989
[10/09 14:01:47 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2060, average loss: 2.6999
[10/09 14:01:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.64	
[10/09 14:01:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[10/09 14:08:11 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.9731, average train loss: 1.8976
[10/09 14:08:55 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2214, average loss: 1.3412
[10/09 14:08:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.05	
[10/09 14:08:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[10/09 14:15:21 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.0149, average train loss: 1.2425
[10/09 14:16:05 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2323, average loss: 0.6964
[10/09 14:16:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 54.99	
[10/09 14:16:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[10/09 14:22:30 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 11.0029, average train loss: 1.1527
[10/09 14:23:14 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.2261, average loss: 0.6887
[10/09 14:23:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 54.67	
[10/09 14:23:14 visual_prompt]: Best epoch 25: best metric: -0.689
[10/09 14:23:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[10/09 14:29:39 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 11.0070, average train loss: 1.3922
[10/09 14:30:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2268, average loss: 1.4567
[10/09 14:30:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.82	
[10/09 14:30:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[10/09 14:36:50 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 11.0271, average train loss: 1.0028
[10/09 14:37:34 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.2070, average loss: 2.0520
[10/09 14:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.93	
[10/09 14:37:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[10/09 14:43:59 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 11.0001, average train loss: 1.0936
[10/09 14:44:42 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2060, average loss: 0.8831
[10/09 14:44:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.48	
[10/09 14:44:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[10/09 14:51:09 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0319, average train loss: 0.9387
[10/09 14:51:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2083, average loss: 1.1188
[10/09 14:51:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.49	
[10/09 14:51:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[10/09 14:58:18 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.9884, average train loss: 0.8804
[10/09 14:59:02 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.2366, average loss: 0.6954
[10/09 14:59:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 53.83	
[10/09 14:59:02 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[10/09 15:05:28 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0358, average train loss: 0.8907
[10/09 15:06:13 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.2095, average loss: 0.7748
[10/09 15:06:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.88	
[10/09 15:06:13 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[10/09 15:12:40 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0625, average train loss: 0.7614
[10/09 15:13:24 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2204, average loss: 1.0852
[10/09 15:13:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.38	
[10/09 15:13:24 visual_prompt]: Stopping early.
[10/09 15:13:24 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 15:13:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 15:13:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 15:13:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 15:13:24 visual_prompt]: Training with config:
[10/09 15:13:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 15:13:24 visual_prompt]: Loading training data...
[10/09 15:13:24 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 15:13:24 visual_prompt]: Loading validation data...
[10/09 15:13:24 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 15:13:25 visual_prompt]: Constructing models...
[10/09 15:13:27 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 15:13:27 visual_prompt]: tuned percent:0.536
[10/09 15:13:27 visual_prompt]: Device used for model: 0
[10/09 15:13:27 visual_prompt]: Setting up Evaluator...
[10/09 15:13:27 visual_prompt]: Setting up Trainer...
[10/09 15:13:27 visual_prompt]: 	Setting up the optimizer...
[10/09 15:13:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 15:19:55 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0658, average train loss: 1.4524
[10/09 15:20:39 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2044, average loss: 1.4398
[10/09 15:20:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 15:20:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/09 15:27:06 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0623, average train loss: 2.1598
[10/09 15:27:50 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2066, average loss: 0.6889
[10/09 15:27:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[10/09 15:27:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/09 15:34:16 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0384, average train loss: 0.7474
[10/09 15:35:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2292, average loss: 0.6939
[10/09 15:35:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.06	
[10/09 15:35:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/09 15:41:27 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0334, average train loss: 0.7220
[10/09 15:42:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2208, average loss: 0.7512
[10/09 15:42:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.39	
[10/09 15:42:11 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/09 15:48:36 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0039, average train loss: 0.7244
[10/09 15:49:20 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2081, average loss: 0.6883
[10/09 15:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.38	
[10/09 15:49:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/09 15:55:46 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0333, average train loss: 0.7614
[10/09 15:56:30 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2122, average loss: 0.7276
[10/09 15:56:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.18	
[10/09 15:56:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/09 16:02:56 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0256, average train loss: 0.7323
[10/09 16:03:40 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2138, average loss: 0.6952
[10/09 16:03:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.73	
[10/09 16:03:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/09 16:10:05 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9892, average train loss: 1.0086
[10/09 16:10:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2146, average loss: 0.7882
[10/09 16:10:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.32	
[10/09 16:10:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/09 16:17:15 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0391, average train loss: 0.8479
[10/09 16:18:00 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2213, average loss: 0.6905
[10/09 16:18:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.92	
[10/09 16:18:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/09 16:24:26 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0427, average train loss: 0.7635
[10/09 16:25:10 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2065, average loss: 0.8138
[10/09 16:25:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.35	
[10/09 16:25:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/09 16:31:37 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0385, average train loss: 1.0477
[10/09 16:32:21 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2031, average loss: 0.7195
[10/09 16:32:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.73	
[10/09 16:32:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/09 16:38:47 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0398, average train loss: 1.5001
[10/09 16:39:31 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2382, average loss: 0.7713
[10/09 16:39:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.49	
[10/09 16:39:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/09 16:45:59 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0687, average train loss: 1.3180
[10/09 16:46:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.2114, average loss: 0.7229
[10/09 16:46:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 52.08	
[10/09 16:46:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/09 16:53:09 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0368, average train loss: 1.3617
[10/09 16:53:54 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2426, average loss: 1.6576
[10/09 16:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.16	
[10/09 16:53:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/09 17:00:23 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0998, average train loss: 1.3427
[10/09 17:01:07 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2360, average loss: 2.5046
[10/09 17:01:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.23	
[10/09 17:01:07 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/09 17:07:33 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0297, average train loss: 1.0472
[10/09 17:08:17 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2053, average loss: 0.6904
[10/09 17:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.01	
[10/09 17:08:17 visual_prompt]: Best epoch 16: best metric: -0.690
[10/09 17:08:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/09 17:14:41 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9892, average train loss: 0.8080
[10/09 17:15:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2226, average loss: 1.0377
[10/09 17:15:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.56	
[10/09 17:15:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/09 17:21:51 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9995, average train loss: 0.8415
[10/09 17:22:35 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2139, average loss: 1.8042
[10/09 17:22:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.31	
[10/09 17:22:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/09 17:29:00 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 11.0069, average train loss: 1.3815
[10/09 17:29:44 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2348, average loss: 0.8303
[10/09 17:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.54	
[10/09 17:29:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/09 17:36:09 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0006, average train loss: 0.9441
[10/09 17:36:53 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2063, average loss: 1.0968
[10/09 17:36:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.36	
[10/09 17:36:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/09 17:43:19 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 11.0189, average train loss: 0.9009
[10/09 17:44:03 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2093, average loss: 1.9737
[10/09 17:44:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 41.14	
[10/09 17:44:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/09 17:50:28 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 11.0096, average train loss: 0.8102
[10/09 17:51:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2047, average loss: 0.6930
[10/09 17:51:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.15	
[10/09 17:51:12 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/09 17:57:37 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.9946, average train loss: 0.9468
[10/09 17:58:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2331, average loss: 2.3245
[10/09 17:58:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.81	
[10/09 17:58:21 visual_prompt]: Stopping early.
[10/09 17:58:21 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 17:58:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:58:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 17:58:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 17:58:21 visual_prompt]: Training with config:
[10/09 17:58:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 17:58:21 visual_prompt]: Loading training data...
[10/09 17:58:21 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 17:58:21 visual_prompt]: Loading validation data...
[10/09 17:58:21 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 17:58:21 visual_prompt]: Constructing models...
[10/09 17:58:24 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 17:58:24 visual_prompt]: tuned percent:0.536
[10/09 17:58:24 visual_prompt]: Device used for model: 0
[10/09 17:58:24 visual_prompt]: Setting up Evaluator...
[10/09 17:58:24 visual_prompt]: Setting up Trainer...
[10/09 17:58:24 visual_prompt]: 	Setting up the optimizer...
[10/09 17:58:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 18:04:50 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0194, average train loss: 1.4524
[10/09 18:05:34 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2282, average loss: 1.4398
[10/09 18:05:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 18:05:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/09 18:11:58 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9875, average train loss: 2.1973
[10/09 18:12:42 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2061, average loss: 0.7140
[10/09 18:12:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.32	
[10/09 18:12:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/09 18:19:07 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9933, average train loss: 0.7518
[10/09 18:19:51 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.2312, average loss: 0.7114
[10/09 18:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.60	
[10/09 18:19:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/09 18:26:18 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0286, average train loss: 0.7214
[10/09 18:27:02 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2149, average loss: 0.6967
[10/09 18:27:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.52	
[10/09 18:27:02 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/09 18:33:27 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9975, average train loss: 0.7947
[10/09 18:34:11 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.2128, average loss: 0.7154
[10/09 18:34:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.01	
[10/09 18:34:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/09 18:40:37 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0371, average train loss: 0.7853
[10/09 18:41:21 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.2278, average loss: 0.6862
[10/09 18:41:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.97	
[10/09 18:41:21 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/09 18:47:46 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0037, average train loss: 0.7209
[10/09 18:48:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2096, average loss: 1.3089
[10/09 18:48:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.14	
[10/09 18:48:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/09 18:54:54 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9796, average train loss: 0.9084
[10/09 18:55:38 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2367, average loss: 0.8131
[10/09 18:55:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.18	
[10/09 18:55:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/09 19:02:04 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0129, average train loss: 0.7658
[10/09 19:02:48 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2342, average loss: 0.7319
[10/09 19:02:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.43	
[10/09 19:02:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/09 19:09:14 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0416, average train loss: 0.7372
[10/09 19:09:58 visual_prompt]: Inference (val):avg data time: 4.38e-05, avg batch time: 0.2054, average loss: 0.7550
[10/09 19:09:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.74	
[10/09 19:09:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/09 19:16:23 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 11.0014, average train loss: 0.7575
[10/09 19:17:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2391, average loss: 0.8340
[10/09 19:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.83	
[10/09 19:17:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/09 19:23:34 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0151, average train loss: 0.7374
[10/09 19:24:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2147, average loss: 0.6918
[10/09 19:24:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 53.50	
[10/09 19:24:18 visual_prompt]: Best epoch 12: best metric: -0.692
[10/09 19:24:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/09 19:30:43 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0162, average train loss: 0.7568
[10/09 19:31:28 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2286, average loss: 0.6891
[10/09 19:31:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.31	
[10/09 19:31:28 visual_prompt]: Best epoch 13: best metric: -0.689
[10/09 19:31:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/09 19:37:53 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9986, average train loss: 0.7801
[10/09 19:38:37 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2207, average loss: 0.6911
[10/09 19:38:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.50	
[10/09 19:38:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/09 19:45:04 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0699, average train loss: 0.7609
[10/09 19:45:49 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2238, average loss: 0.7826
[10/09 19:45:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.71	
[10/09 19:45:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/09 19:52:14 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9989, average train loss: 0.7153
[10/09 19:52:58 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2304, average loss: 0.9400
[10/09 19:52:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[10/09 19:52:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/09 19:59:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9878, average train loss: 0.7830
[10/09 20:00:07 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2066, average loss: 1.0688
[10/09 20:00:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.34	
[10/09 20:00:07 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/09 20:06:32 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9966, average train loss: 0.7982
[10/09 20:07:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2382, average loss: 1.2217
[10/09 20:07:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.84	
[10/09 20:07:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/09 20:13:42 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 11.0086, average train loss: 0.7812
[10/09 20:14:26 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.2314, average loss: 0.7473
[10/09 20:14:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.72	
[10/09 20:14:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/09 20:20:52 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0291, average train loss: 0.7504
[10/09 20:21:36 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2281, average loss: 0.9516
[10/09 20:21:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.63	
[10/09 20:21:36 visual_prompt]: Stopping early.
[10/09 20:21:37 visual_prompt]: Rank of current process: 0. World size: 1
[10/09 20:21:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 20:21:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/09 20:21:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/09 20:21:37 visual_prompt]: Training with config:
[10/09 20:21:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/09 20:21:37 visual_prompt]: Loading training data...
[10/09 20:21:37 visual_prompt]: Constructing mammo-cbis dataset train...
[10/09 20:21:37 visual_prompt]: Loading validation data...
[10/09 20:21:37 visual_prompt]: Constructing mammo-cbis dataset val...
[10/09 20:21:37 visual_prompt]: Constructing models...
[10/09 20:21:39 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/09 20:21:39 visual_prompt]: tuned percent:0.536
[10/09 20:21:39 visual_prompt]: Device used for model: 0
[10/09 20:21:39 visual_prompt]: Setting up Evaluator...
[10/09 20:21:39 visual_prompt]: Setting up Trainer...
[10/09 20:21:39 visual_prompt]: 	Setting up the optimizer...
[10/09 20:21:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/09 20:28:07 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0601, average train loss: 1.4524
[10/09 20:28:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2286, average loss: 1.4398
[10/09 20:28:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/09 20:28:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/09 20:35:15 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9864, average train loss: 2.2007
[10/09 20:35:59 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.2305, average loss: 0.7123
[10/09 20:35:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.42	
[10/09 20:35:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/09 20:42:26 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0477, average train loss: 0.7535
[10/09 20:43:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.2102, average loss: 0.7097
[10/09 20:43:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.20	
[10/09 20:43:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/09 20:49:36 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0220, average train loss: 0.7250
[10/09 20:50:20 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2288, average loss: 0.6970
[10/09 20:50:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.49	
[10/09 20:50:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/09 20:56:44 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9806, average train loss: 0.8003
[10/09 20:57:29 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.2043, average loss: 0.7142
[10/09 20:57:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.98	
[10/09 20:57:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/09 21:03:55 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0283, average train loss: 0.7942
[10/09 21:04:39 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2159, average loss: 0.6846
[10/09 21:04:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 54.31	
[10/09 21:04:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/09 21:11:04 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0060, average train loss: 0.7254
[10/09 21:11:48 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2090, average loss: 1.4195
[10/09 21:11:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.58	
[10/09 21:11:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/09 21:18:14 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0276, average train loss: 0.8907
[10/09 21:18:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.2111, average loss: 0.6883
[10/09 21:18:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.27	
[10/09 21:18:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/09 21:25:26 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0810, average train loss: 0.8893
[10/09 21:26:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2224, average loss: 0.6967
[10/09 21:26:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 54.69	
[10/09 21:26:11 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/09 21:32:37 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0359, average train loss: 0.7843
[10/09 21:33:21 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.2091, average loss: 0.7607
[10/09 21:33:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.68	
[10/09 21:33:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/09 21:39:49 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0830, average train loss: 0.7785
[10/09 21:40:33 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2274, average loss: 0.7919
[10/09 21:40:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.18	
[10/09 21:40:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/09 21:47:00 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0430, average train loss: 0.7590
[10/09 21:47:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2051, average loss: 1.1350
[10/09 21:47:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.06	
[10/09 21:47:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/09 21:54:12 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0708, average train loss: 0.9471
[10/09 21:54:56 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2176, average loss: 0.8101
[10/09 21:54:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.01	
[10/09 21:54:56 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/09 22:01:21 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9988, average train loss: 0.8744
[10/09 22:02:05 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2093, average loss: 0.7454
[10/09 22:02:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.76	
[10/09 22:02:05 visual_prompt]: Best epoch 14: best metric: -0.745
[10/09 22:02:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/09 22:08:31 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0281, average train loss: 0.8263
[10/09 22:09:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2107, average loss: 0.9097
[10/09 22:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.42	
[10/09 22:09:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/09 22:15:40 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 11.0031, average train loss: 0.8615
[10/09 22:16:24 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.2275, average loss: 0.9162
[10/09 22:16:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[10/09 22:16:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/09 22:22:49 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9983, average train loss: 0.8565
[10/09 22:23:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2288, average loss: 1.4157
[10/09 22:23:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[10/09 22:23:33 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/09 22:30:00 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0276, average train loss: 0.9132
[10/09 22:30:43 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2301, average loss: 0.7481
[10/09 22:30:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 56.44	
[10/09 22:30:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/09 22:37:10 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0375, average train loss: 0.7840
[10/09 22:37:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2247, average loss: 0.7082
[10/09 22:37:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.02	
[10/09 22:37:54 visual_prompt]: Best epoch 19: best metric: -0.708
[10/09 22:37:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/09 22:44:22 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0852, average train loss: 0.7110
[10/09 22:45:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.2100, average loss: 0.6757
[10/09 22:45:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 57.72	
[10/09 22:45:06 visual_prompt]: Best epoch 20: best metric: -0.676
[10/09 22:45:06 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/09 22:51:33 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.0462, average train loss: 0.7560
[10/09 22:52:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2342, average loss: 0.6746
[10/09 22:52:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 60.24	
[10/09 22:52:17 visual_prompt]: Best epoch 21: best metric: -0.675
[10/09 22:52:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/09 22:58:45 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 11.0821, average train loss: 1.0114
[10/09 22:59:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2168, average loss: 0.9710
[10/09 22:59:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.38	
[10/09 22:59:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/09 23:05:57 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 11.0494, average train loss: 0.7608
[10/09 23:06:42 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.2082, average loss: 0.8966
[10/09 23:06:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.03	
[10/09 23:06:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/09 23:13:07 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 11.0030, average train loss: 0.8891
[10/09 23:13:51 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2152, average loss: 0.6840
[10/09 23:13:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 57.91	
[10/09 23:13:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/09 23:20:16 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.9964, average train loss: 0.7507
[10/09 23:21:00 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2137, average loss: 0.6973
[10/09 23:21:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 59.10	
[10/09 23:21:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/09 23:27:25 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.9926, average train loss: 0.7766
[10/09 23:28:09 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2269, average loss: 0.7234
[10/09 23:28:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 59.68	
[10/09 23:28:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/09 23:34:34 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 11.0143, average train loss: 0.7682
[10/09 23:35:18 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2355, average loss: 0.6764
[10/09 23:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.18	
[10/09 23:35:18 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/09 23:41:43 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 11.0018, average train loss: 0.7573
[10/09 23:42:28 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2349, average loss: 0.6698
[10/09 23:42:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.00	
[10/09 23:42:28 visual_prompt]: Best epoch 28: best metric: -0.670
[10/09 23:42:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[10/09 23:48:55 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0542, average train loss: 0.7112
[10/09 23:49:39 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.2131, average loss: 0.6805
[10/09 23:49:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 58.29	
[10/09 23:49:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[10/09 23:56:05 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 11.0248, average train loss: 0.7047
[10/09 23:56:49 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2387, average loss: 0.6845
[10/09 23:56:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 59.98	
[10/09 23:56:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[10/10 00:03:16 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0465, average train loss: 0.6985
[10/10 00:04:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2056, average loss: 0.6738
[10/10 00:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 60.40	
[10/10 00:04:00 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[10/10 00:10:27 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0603, average train loss: 0.7253
[10/10 00:11:12 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2251, average loss: 0.7012
[10/10 00:11:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 59.34	
[10/10 00:11:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[10/10 00:17:39 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 11.0568, average train loss: 0.7157
[10/10 00:18:23 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2048, average loss: 0.7066
[10/10 00:18:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 61.77	
[10/10 00:18:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[10/10 00:24:48 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.9919, average train loss: 0.6897
[10/10 00:25:32 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2104, average loss: 0.6713
[10/10 00:25:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.06	
[10/10 00:25:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[10/10 00:31:57 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 10.9988, average train loss: 0.7019
[10/10 00:32:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.2346, average loss: 0.6768
[10/10 00:32:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 60.51	
[10/10 00:32:41 visual_prompt]: Stopping early.
[10/10 00:32:41 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 00:32:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 00:32:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 00:32:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 00:32:41 visual_prompt]: Training with config:
[10/10 00:32:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 00:32:41 visual_prompt]: Loading training data...
[10/10 00:32:41 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 00:32:42 visual_prompt]: Loading validation data...
[10/10 00:32:42 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 00:32:42 visual_prompt]: Constructing models...
[10/10 00:32:44 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 00:32:44 visual_prompt]: tuned percent:0.536
[10/10 00:32:44 visual_prompt]: Device used for model: 0
[10/10 00:32:44 visual_prompt]: Setting up Evaluator...
[10/10 00:32:44 visual_prompt]: Setting up Trainer...
[10/10 00:32:44 visual_prompt]: 	Setting up the optimizer...
[10/10 00:32:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 00:39:11 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0317, average train loss: 1.4524
[10/10 00:39:55 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.2348, average loss: 1.4398
[10/10 00:39:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 00:39:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/10 00:46:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9872, average train loss: 2.2011
[10/10 00:47:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.2350, average loss: 0.7123
[10/10 00:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.42	
[10/10 00:47:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/10 00:53:28 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9946, average train loss: 0.7540
[10/10 00:54:12 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2150, average loss: 0.7088
[10/10 00:54:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.13	
[10/10 00:54:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/10 01:00:38 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0064, average train loss: 0.7255
[10/10 01:01:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2283, average loss: 0.6968
[10/10 01:01:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.36	
[10/10 01:01:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/10 01:07:46 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9836, average train loss: 0.8016
[10/10 01:08:30 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2349, average loss: 0.7127
[10/10 01:08:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 53.99	
[10/10 01:08:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/10 01:14:55 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.9931, average train loss: 0.7962
[10/10 01:15:39 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2123, average loss: 0.6842
[10/10 01:15:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 54.63	
[10/10 01:15:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/10 01:22:04 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0119, average train loss: 0.7267
[10/10 01:22:49 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2271, average loss: 1.4462
[10/10 01:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.66	
[10/10 01:22:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/10 01:29:13 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9872, average train loss: 0.8960
[10/10 01:29:57 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2190, average loss: 0.6835
[10/10 01:29:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 54.64	
[10/10 01:29:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/10 01:36:22 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 11.0054, average train loss: 0.9015
[10/10 01:37:07 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2332, average loss: 0.7384
[10/10 01:37:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.82	
[10/10 01:37:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/10 01:43:32 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0209, average train loss: 0.7942
[10/10 01:44:16 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2083, average loss: 0.7660
[10/10 01:44:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.49	
[10/10 01:44:16 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/10 01:50:41 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9941, average train loss: 0.8070
[10/10 01:51:25 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2199, average loss: 0.9245
[10/10 01:51:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.39	
[10/10 01:51:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/10 01:57:50 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9966, average train loss: 0.7524
[10/10 01:58:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2080, average loss: 1.1132
[10/10 01:58:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.83	
[10/10 01:58:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/10 02:04:59 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0029, average train loss: 0.9779
[10/10 02:05:43 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.2035, average loss: 0.7691
[10/10 02:05:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.18	
[10/10 02:05:43 visual_prompt]: Best epoch 13: best metric: -0.769
[10/10 02:05:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/10 02:12:07 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9782, average train loss: 0.8868
[10/10 02:12:52 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2286, average loss: 0.9605
[10/10 02:12:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.03	
[10/10 02:12:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/10 02:19:19 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0614, average train loss: 0.8667
[10/10 02:20:03 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.2140, average loss: 0.9614
[10/10 02:20:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.86	
[10/10 02:20:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/10 02:26:30 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0515, average train loss: 0.8916
[10/10 02:27:14 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.2341, average loss: 0.9141
[10/10 02:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.46	
[10/10 02:27:14 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/10 02:33:41 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0464, average train loss: 0.8479
[10/10 02:34:25 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2154, average loss: 1.4861
[10/10 02:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.66	
[10/10 02:34:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/10 02:40:50 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9945, average train loss: 0.9900
[10/10 02:41:34 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.2327, average loss: 1.3624
[10/10 02:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.14	
[10/10 02:41:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/10 02:48:00 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0164, average train loss: 0.8447
[10/10 02:48:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2109, average loss: 0.6829
[10/10 02:48:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 57.96	
[10/10 02:48:44 visual_prompt]: Best epoch 19: best metric: -0.683
[10/10 02:48:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/10 02:55:09 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.9976, average train loss: 0.7057
[10/10 02:55:53 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2131, average loss: 0.6808
[10/10 02:55:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.76	
[10/10 02:55:53 visual_prompt]: Best epoch 20: best metric: -0.681
[10/10 02:55:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/10 03:02:19 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.0198, average train loss: 0.7656
[10/10 03:03:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2315, average loss: 0.6719
[10/10 03:03:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.12	
[10/10 03:03:03 visual_prompt]: Best epoch 21: best metric: -0.672
[10/10 03:03:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/10 03:09:27 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9680, average train loss: 1.0473
[10/10 03:10:11 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2368, average loss: 1.0192
[10/10 03:10:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[10/10 03:10:11 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/10 03:16:37 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9999, average train loss: 0.7877
[10/10 03:17:21 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2087, average loss: 0.9443
[10/10 03:17:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.94	
[10/10 03:17:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/10 03:23:45 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.9925, average train loss: 0.9094
[10/10 03:24:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2353, average loss: 0.7986
[10/10 03:24:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 58.74	
[10/10 03:24:29 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/10 03:30:54 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.9860, average train loss: 0.7771
[10/10 03:31:39 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.2292, average loss: 0.8023
[10/10 03:31:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.78	
[10/10 03:31:39 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/10 03:38:03 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.9719, average train loss: 0.8336
[10/10 03:38:47 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.2274, average loss: 0.7577
[10/10 03:38:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.26	
[10/10 03:38:47 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/10 03:45:12 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 11.0104, average train loss: 0.8092
[10/10 03:45:56 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2113, average loss: 0.6782
[10/10 03:45:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 60.55	
[10/10 03:45:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/10 03:52:21 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.9926, average train loss: 0.7530
[10/10 03:53:05 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2273, average loss: 0.8142
[10/10 03:53:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 60.85	
[10/10 03:53:05 visual_prompt]: Stopping early.
[10/10 03:53:05 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 03:53:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 03:53:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 03:53:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 03:53:05 visual_prompt]: Training with config:
[10/10 03:53:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 03:53:05 visual_prompt]: Loading training data...
[10/10 03:53:05 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 03:53:05 visual_prompt]: Loading validation data...
[10/10 03:53:05 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 03:53:05 visual_prompt]: Constructing models...
[10/10 03:53:07 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 03:53:07 visual_prompt]: tuned percent:0.536
[10/10 03:53:07 visual_prompt]: Device used for model: 0
[10/10 03:53:07 visual_prompt]: Setting up Evaluator...
[10/10 03:53:07 visual_prompt]: Setting up Trainer...
[10/10 03:53:07 visual_prompt]: 	Setting up the optimizer...
[10/10 03:53:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 03:59:33 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0143, average train loss: 1.4524
[10/10 04:00:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2164, average loss: 1.4398
[10/10 04:00:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 04:00:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[10/10 04:06:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9981, average train loss: 1.5935
[10/10 04:07:26 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2037, average loss: 0.6908
[10/10 04:07:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 56.82	
[10/10 04:07:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[10/10 04:13:51 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9895, average train loss: 0.7040
[10/10 04:14:34 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2227, average loss: 0.7009
[10/10 04:14:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.48	
[10/10 04:14:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[10/10 04:21:02 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0689, average train loss: 0.6976
[10/10 04:21:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2383, average loss: 0.7137
[10/10 04:21:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.96	
[10/10 04:21:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[10/10 04:28:11 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9913, average train loss: 0.7247
[10/10 04:28:55 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2370, average loss: 0.7347
[10/10 04:28:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.50	
[10/10 04:28:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[10/10 04:35:20 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.0001, average train loss: 0.7312
[10/10 04:36:04 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2036, average loss: 0.6887
[10/10 04:36:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.41	
[10/10 04:36:04 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[10/10 04:42:30 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0106, average train loss: 0.7332
[10/10 04:43:14 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2294, average loss: 0.7206
[10/10 04:43:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.11	
[10/10 04:43:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[10/10 04:49:38 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9733, average train loss: 0.7260
[10/10 04:50:22 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.2218, average loss: 0.6884
[10/10 04:50:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.21	
[10/10 04:50:22 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[10/10 04:56:48 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0221, average train loss: 0.7017
[10/10 04:57:32 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.2400, average loss: 0.7324
[10/10 04:57:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.77	
[10/10 04:57:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[10/10 05:03:57 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 11.0003, average train loss: 0.6963
[10/10 05:04:41 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2134, average loss: 0.7322
[10/10 05:04:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.52	
[10/10 05:04:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[10/10 05:11:07 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0131, average train loss: 0.7098
[10/10 05:11:51 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2287, average loss: 0.6899
[10/10 05:11:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.82	
[10/10 05:11:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[10/10 05:18:15 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9925, average train loss: 0.7090
[10/10 05:18:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2164, average loss: 0.7415
[10/10 05:18:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.22	
[10/10 05:18:59 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[10/10 05:25:26 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0326, average train loss: 0.7470
[10/10 05:26:10 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2048, average loss: 0.7514
[10/10 05:26:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.47	
[10/10 05:26:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[10/10 05:32:34 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9763, average train loss: 0.7728
[10/10 05:33:18 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2248, average loss: 0.7426
[10/10 05:33:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.25	
[10/10 05:33:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[10/10 05:39:43 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0037, average train loss: 0.7194
[10/10 05:40:28 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2098, average loss: 0.6928
[10/10 05:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.52	
[10/10 05:40:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[10/10 05:46:52 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9819, average train loss: 0.7812
[10/10 05:47:36 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2309, average loss: 0.8333
[10/10 05:47:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.79	
[10/10 05:47:36 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[10/10 05:54:01 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9910, average train loss: 0.7639
[10/10 05:54:45 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2330, average loss: 0.8045
[10/10 05:54:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.12	
[10/10 05:54:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[10/10 06:01:12 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0544, average train loss: 0.7378
[10/10 06:01:56 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2034, average loss: 0.7344
[10/10 06:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.91	
[10/10 06:01:56 visual_prompt]: Stopping early.
[10/10 06:01:56 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 06:01:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 06:01:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 06:01:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 06:01:56 visual_prompt]: Training with config:
[10/10 06:01:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 06:01:56 visual_prompt]: Loading training data...
[10/10 06:01:56 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 06:01:56 visual_prompt]: Loading validation data...
[10/10 06:01:56 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 06:01:56 visual_prompt]: Constructing models...
[10/10 06:01:58 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 06:01:58 visual_prompt]: tuned percent:0.536
[10/10 06:01:58 visual_prompt]: Device used for model: 0
[10/10 06:01:58 visual_prompt]: Setting up Evaluator...
[10/10 06:01:58 visual_prompt]: Setting up Trainer...
[10/10 06:01:58 visual_prompt]: 	Setting up the optimizer...
[10/10 06:01:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 06:08:26 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0602, average train loss: 1.4524
[10/10 06:09:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2100, average loss: 1.4398
[10/10 06:09:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 06:09:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[10/10 06:15:37 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0564, average train loss: 1.6114
[10/10 06:16:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2295, average loss: 0.6864
[10/10 06:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 56.50	
[10/10 06:16:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[10/10 06:22:47 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0432, average train loss: 0.7124
[10/10 06:23:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2307, average loss: 0.6997
[10/10 06:23:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.31	
[10/10 06:23:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[10/10 06:29:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0667, average train loss: 0.7065
[10/10 06:30:43 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.2240, average loss: 0.6984
[10/10 06:30:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.65	
[10/10 06:30:43 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[10/10 06:37:09 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0101, average train loss: 0.7319
[10/10 06:37:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2163, average loss: 0.7842
[10/10 06:37:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[10/10 06:37:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[10/10 06:44:18 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.0049, average train loss: 0.7371
[10/10 06:45:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2089, average loss: 0.7172
[10/10 06:45:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.90	
[10/10 06:45:02 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[10/10 06:51:28 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0139, average train loss: 0.7682
[10/10 06:52:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.2129, average loss: 0.7099
[10/10 06:52:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.62	
[10/10 06:52:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[10/10 06:58:36 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9880, average train loss: 0.7369
[10/10 06:59:20 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2404, average loss: 0.6937
[10/10 06:59:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 57.23	
[10/10 06:59:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[10/10 07:05:46 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0164, average train loss: 0.7297
[10/10 07:06:30 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2296, average loss: 0.7844
[10/10 07:06:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.29	
[10/10 07:06:30 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[10/10 07:12:56 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0108, average train loss: 0.6937
[10/10 07:13:40 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2344, average loss: 0.8210
[10/10 07:13:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.55	
[10/10 07:13:40 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[10/10 07:20:07 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0683, average train loss: 0.7758
[10/10 07:20:52 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2338, average loss: 0.6887
[10/10 07:20:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.09	
[10/10 07:20:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[10/10 07:27:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0464, average train loss: 0.7095
[10/10 07:28:02 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2284, average loss: 0.6974
[10/10 07:28:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.89	
[10/10 07:28:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[10/10 07:34:30 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0686, average train loss: 0.7260
[10/10 07:35:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2422, average loss: 0.7263
[10/10 07:35:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.48	
[10/10 07:35:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[10/10 07:41:40 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0303, average train loss: 0.7942
[10/10 07:42:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2284, average loss: 0.8427
[10/10 07:42:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.03	
[10/10 07:42:25 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[10/10 07:48:53 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0838, average train loss: 0.7560
[10/10 07:49:37 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2382, average loss: 0.7258
[10/10 07:49:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[10/10 07:49:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[10/10 07:56:04 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0539, average train loss: 0.7080
[10/10 07:56:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2078, average loss: 0.8290
[10/10 07:56:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[10/10 07:56:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[10/10 08:03:15 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0319, average train loss: 0.8117
[10/10 08:03:59 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2349, average loss: 0.7053
[10/10 08:03:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.90	
[10/10 08:03:59 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[10/10 08:10:25 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0178, average train loss: 0.7766
[10/10 08:11:09 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2046, average loss: 1.0281
[10/10 08:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.92	
[10/10 08:11:09 visual_prompt]: Stopping early.
[10/10 08:11:09 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 08:11:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 08:11:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 08:11:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 08:11:09 visual_prompt]: Training with config:
[10/10 08:11:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 08:11:09 visual_prompt]: Loading training data...
[10/10 08:11:09 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 08:11:09 visual_prompt]: Loading validation data...
[10/10 08:11:09 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 08:11:09 visual_prompt]: Constructing models...
[10/10 08:11:12 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 08:11:12 visual_prompt]: tuned percent:0.536
[10/10 08:11:12 visual_prompt]: Device used for model: 0
[10/10 08:11:12 visual_prompt]: Setting up Evaluator...
[10/10 08:11:12 visual_prompt]: Setting up Trainer...
[10/10 08:11:12 visual_prompt]: 	Setting up the optimizer...
[10/10 08:11:12 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 08:17:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0712, average train loss: 1.4524
[10/10 08:18:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2082, average loss: 1.4398
[10/10 08:18:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 08:18:23 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[10/10 08:24:51 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0636, average train loss: 1.6133
[10/10 08:25:35 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2092, average loss: 0.6859
[10/10 08:25:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.56	
[10/10 08:25:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[10/10 08:32:01 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0330, average train loss: 0.7139
[10/10 08:32:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2322, average loss: 0.7001
[10/10 08:32:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.23	
[10/10 08:32:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[10/10 08:39:11 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0219, average train loss: 0.7073
[10/10 08:39:55 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2095, average loss: 0.6976
[10/10 08:39:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.69	
[10/10 08:39:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[10/10 08:46:19 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9719, average train loss: 0.7330
[10/10 08:47:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.2172, average loss: 0.7866
[10/10 08:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.83	
[10/10 08:47:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[10/10 08:53:29 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0342, average train loss: 0.7366
[10/10 08:54:13 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.2265, average loss: 0.7095
[10/10 08:54:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.33	
[10/10 08:54:13 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[10/10 09:00:39 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0141, average train loss: 0.7764
[10/10 09:01:23 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2290, average loss: 0.7136
[10/10 09:01:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.90	
[10/10 09:01:23 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[10/10 09:07:47 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9754, average train loss: 0.7574
[10/10 09:08:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2351, average loss: 0.6815
[10/10 09:08:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.34	
[10/10 09:08:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[10/10 09:14:57 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0141, average train loss: 0.7357
[10/10 09:15:41 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.2306, average loss: 0.7735
[10/10 09:15:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.24	
[10/10 09:15:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[10/10 09:22:07 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0052, average train loss: 0.6989
[10/10 09:22:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2315, average loss: 0.7190
[10/10 09:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 61.05	
[10/10 09:22:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[10/10 09:29:18 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0584, average train loss: 0.7479
[10/10 09:30:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2039, average loss: 0.7081
[10/10 09:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 58.44	
[10/10 09:30:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[10/10 09:36:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0182, average train loss: 0.7298
[10/10 09:37:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2393, average loss: 0.6801
[10/10 09:37:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 60.61	
[10/10 09:37:12 visual_prompt]: Best epoch 12: best metric: -0.680
[10/10 09:37:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[10/10 09:43:37 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0087, average train loss: 0.7109
[10/10 09:44:21 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.2037, average loss: 0.6714
[10/10 09:44:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.79	
[10/10 09:44:21 visual_prompt]: Best epoch 13: best metric: -0.671
[10/10 09:44:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[10/10 09:50:46 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9925, average train loss: 0.7508
[10/10 09:51:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2107, average loss: 0.6728
[10/10 09:51:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.21	
[10/10 09:51:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[10/10 09:57:56 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0268, average train loss: 0.8090
[10/10 09:58:40 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2355, average loss: 0.7088
[10/10 09:58:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.67	
[10/10 09:58:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[10/10 10:05:05 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9793, average train loss: 0.7238
[10/10 10:05:49 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2142, average loss: 0.8596
[10/10 10:05:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.50	
[10/10 10:05:49 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[10/10 10:12:14 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9890, average train loss: 0.7793
[10/10 10:12:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2382, average loss: 0.7347
[10/10 10:12:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.15	
[10/10 10:12:58 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[10/10 10:19:23 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0135, average train loss: 0.7320
[10/10 10:20:07 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2159, average loss: 1.0891
[10/10 10:20:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.01	
[10/10 10:20:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[10/10 10:26:32 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9794, average train loss: 0.7289
[10/10 10:27:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.2046, average loss: 0.8887
[10/10 10:27:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.43	
[10/10 10:27:16 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[10/10 10:33:41 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0024, average train loss: 0.7081
[10/10 10:34:25 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2353, average loss: 0.8832
[10/10 10:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.65	
[10/10 10:34:25 visual_prompt]: Stopping early.
[10/10 10:34:25 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 10:34:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 10:34:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 10:34:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 10:34:25 visual_prompt]: Training with config:
[10/10 10:34:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 10:34:25 visual_prompt]: Loading training data...
[10/10 10:34:25 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 10:34:25 visual_prompt]: Loading validation data...
[10/10 10:34:25 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 10:34:25 visual_prompt]: Constructing models...
[10/10 10:34:27 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 10:34:27 visual_prompt]: tuned percent:0.536
[10/10 10:34:28 visual_prompt]: Device used for model: 0
[10/10 10:34:28 visual_prompt]: Setting up Evaluator...
[10/10 10:34:28 visual_prompt]: Setting up Trainer...
[10/10 10:34:28 visual_prompt]: 	Setting up the optimizer...
[10/10 10:34:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 10:40:53 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0130, average train loss: 1.4524
[10/10 10:41:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.2187, average loss: 1.4398
[10/10 10:41:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 10:41:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[10/10 10:48:03 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0100, average train loss: 1.6135
[10/10 10:48:47 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2079, average loss: 0.6859
[10/10 10:48:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 56.54	
[10/10 10:48:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[10/10 10:55:12 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0114, average train loss: 0.7140
[10/10 10:55:56 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2187, average loss: 0.7000
[10/10 10:55:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.20	
[10/10 10:55:56 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[10/10 11:02:22 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0151, average train loss: 0.7075
[10/10 11:03:06 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2149, average loss: 0.6981
[10/10 11:03:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.75	
[10/10 11:03:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[10/10 11:09:30 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9749, average train loss: 0.7334
[10/10 11:10:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2091, average loss: 0.7879
[10/10 11:10:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.87	
[10/10 11:10:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[10/10 11:16:40 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0311, average train loss: 0.7369
[10/10 11:17:24 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2055, average loss: 0.7099
[10/10 11:17:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[10/10 11:17:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[10/10 11:23:50 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0212, average train loss: 0.7767
[10/10 11:24:34 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.2334, average loss: 0.7134
[10/10 11:24:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.15	
[10/10 11:24:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[10/10 11:31:00 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9991, average train loss: 0.7577
[10/10 11:31:43 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.2086, average loss: 0.6827
[10/10 11:31:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 57.34	
[10/10 11:31:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[10/10 11:38:10 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0341, average train loss: 0.7330
[10/10 11:38:54 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2251, average loss: 0.7543
[10/10 11:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.31	
[10/10 11:38:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[10/10 11:45:19 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9964, average train loss: 0.6985
[10/10 11:46:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2125, average loss: 0.7183
[10/10 11:46:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 59.30	
[10/10 11:46:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[10/10 11:52:29 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0141, average train loss: 0.7491
[10/10 11:53:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2276, average loss: 0.7155
[10/10 11:53:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 59.07	
[10/10 11:53:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[10/10 11:59:38 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9927, average train loss: 0.7315
[10/10 12:00:22 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2071, average loss: 0.6744
[10/10 12:00:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.35	
[10/10 12:00:22 visual_prompt]: Best epoch 12: best metric: -0.674
[10/10 12:00:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[10/10 12:06:48 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0329, average train loss: 0.7108
[10/10 12:07:33 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2318, average loss: 0.6707
[10/10 12:07:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.00	
[10/10 12:07:33 visual_prompt]: Best epoch 13: best metric: -0.671
[10/10 12:07:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[10/10 12:13:58 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 11.0057, average train loss: 0.7519
[10/10 12:14:42 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2379, average loss: 0.6687
[10/10 12:14:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.73	
[10/10 12:14:42 visual_prompt]: Best epoch 14: best metric: -0.669
[10/10 12:14:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[10/10 12:21:08 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0317, average train loss: 0.8010
[10/10 12:21:52 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2289, average loss: 0.6728
[10/10 12:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.87	
[10/10 12:21:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[10/10 12:28:18 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 11.0077, average train loss: 0.7190
[10/10 12:29:01 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2350, average loss: 0.8673
[10/10 12:29:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.54	
[10/10 12:29:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[10/10 12:35:26 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9829, average train loss: 0.7840
[10/10 12:36:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2036, average loss: 0.7470
[10/10 12:36:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 61.05	
[10/10 12:36:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[10/10 12:42:35 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9964, average train loss: 0.7324
[10/10 12:43:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2434, average loss: 1.1100
[10/10 12:43:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.62	
[10/10 12:43:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[10/10 12:49:43 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9648, average train loss: 0.7257
[10/10 12:50:26 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.2268, average loss: 0.8462
[10/10 12:50:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.34	
[10/10 12:50:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[10/10 12:56:52 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0181, average train loss: 0.7139
[10/10 12:57:36 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2298, average loss: 0.8798
[10/10 12:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.38	
[10/10 12:57:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[10/10 13:04:02 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 11.0155, average train loss: 0.7031
[10/10 13:04:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2214, average loss: 0.6708
[10/10 13:04:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.67	
[10/10 13:04:46 visual_prompt]: Stopping early.
[10/10 13:04:46 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 13:04:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 13:04:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 13:04:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 13:04:46 visual_prompt]: Training with config:
[10/10 13:04:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 13:04:46 visual_prompt]: Loading training data...
[10/10 13:04:46 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 13:04:46 visual_prompt]: Loading validation data...
[10/10 13:04:46 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 13:04:46 visual_prompt]: Constructing models...
[10/10 13:04:48 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 13:04:48 visual_prompt]: tuned percent:0.536
[10/10 13:04:49 visual_prompt]: Device used for model: 0
[10/10 13:04:49 visual_prompt]: Setting up Evaluator...
[10/10 13:04:49 visual_prompt]: Setting up Trainer...
[10/10 13:04:49 visual_prompt]: 	Setting up the optimizer...
[10/10 13:04:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 13:11:14 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 11.0005, average train loss: 1.4524
[10/10 13:11:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2229, average loss: 1.4398
[10/10 13:11:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 13:11:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[10/10 13:18:23 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9980, average train loss: 1.2245
[10/10 13:19:07 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2240, average loss: 0.6912
[10/10 13:19:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 57.92	
[10/10 13:19:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[10/10 13:25:32 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9966, average train loss: 0.7059
[10/10 13:26:16 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.2299, average loss: 0.6929
[10/10 13:26:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.66	
[10/10 13:26:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[10/10 13:32:42 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0299, average train loss: 0.7063
[10/10 13:33:26 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2098, average loss: 0.6975
[10/10 13:33:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.98	
[10/10 13:33:26 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[10/10 13:39:51 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9814, average train loss: 0.7224
[10/10 13:40:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2305, average loss: 0.6870
[10/10 13:40:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[10/10 13:40:35 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[10/10 13:47:00 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0175, average train loss: 0.7198
[10/10 13:47:44 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2287, average loss: 0.7158
[10/10 13:47:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.51	
[10/10 13:47:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[10/10 13:54:10 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0253, average train loss: 0.7076
[10/10 13:54:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2233, average loss: 0.6917
[10/10 13:54:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 57.07	
[10/10 13:54:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[10/10 14:01:21 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0318, average train loss: 0.7099
[10/10 14:02:05 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2317, average loss: 0.6879
[10/10 14:02:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.74	
[10/10 14:02:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[10/10 14:08:34 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.1032, average train loss: 0.7042
[10/10 14:09:18 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2245, average loss: 0.7117
[10/10 14:09:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.18	
[10/10 14:09:18 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[10/10 14:15:45 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0566, average train loss: 0.7214
[10/10 14:16:30 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.2175, average loss: 0.7000
[10/10 14:16:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.02	
[10/10 14:16:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[10/10 14:22:57 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0550, average train loss: 0.7001
[10/10 14:23:41 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2073, average loss: 0.6892
[10/10 14:23:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.45	
[10/10 14:23:41 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/10 14:30:06 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9952, average train loss: 0.7005
[10/10 14:30:50 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2118, average loss: 0.6982
[10/10 14:30:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.22	
[10/10 14:30:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/10 14:37:16 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0259, average train loss: 0.7254
[10/10 14:38:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2337, average loss: 0.6889
[10/10 14:38:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.48	
[10/10 14:38:01 visual_prompt]: Best epoch 13: best metric: -0.689
[10/10 14:38:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/10 14:44:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 11.0050, average train loss: 0.7185
[10/10 14:45:10 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2085, average loss: 0.6931
[10/10 14:45:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 46.26	
[10/10 14:45:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/10 14:51:35 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0098, average train loss: 0.7104
[10/10 14:52:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2307, average loss: 0.7034
[10/10 14:52:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.91	
[10/10 14:52:20 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[10/10 14:58:45 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9970, average train loss: 0.7108
[10/10 14:59:29 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2292, average loss: 0.7655
[10/10 14:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.69	
[10/10 14:59:29 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[10/10 15:05:53 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9845, average train loss: 0.7081
[10/10 15:06:37 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2364, average loss: 0.7015
[10/10 15:06:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 43.15	
[10/10 15:06:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[10/10 15:13:03 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0165, average train loss: 0.7250
[10/10 15:13:47 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2057, average loss: 0.7961
[10/10 15:13:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.20	
[10/10 15:13:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[10/10 15:20:12 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 11.0002, average train loss: 0.7081
[10/10 15:20:56 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2215, average loss: 0.7295
[10/10 15:20:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.67	
[10/10 15:20:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[10/10 15:27:22 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0177, average train loss: 0.7067
[10/10 15:28:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2264, average loss: 0.8454
[10/10 15:28:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.48	
[10/10 15:28:06 visual_prompt]: Stopping early.
[10/10 15:28:06 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 15:28:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 15:28:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 15:28:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 15:28:06 visual_prompt]: Training with config:
[10/10 15:28:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 15:28:06 visual_prompt]: Loading training data...
[10/10 15:28:06 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 15:28:06 visual_prompt]: Loading validation data...
[10/10 15:28:06 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 15:28:06 visual_prompt]: Constructing models...
[10/10 15:28:09 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 15:28:09 visual_prompt]: tuned percent:0.536
[10/10 15:28:09 visual_prompt]: Device used for model: 0
[10/10 15:28:09 visual_prompt]: Setting up Evaluator...
[10/10 15:28:09 visual_prompt]: Setting up Trainer...
[10/10 15:28:09 visual_prompt]: 	Setting up the optimizer...
[10/10 15:28:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 15:34:34 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.9950, average train loss: 1.4524
[10/10 15:35:18 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2266, average loss: 1.4398
[10/10 15:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 15:35:18 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[10/10 15:41:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9798, average train loss: 1.2307
[10/10 15:42:27 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.2032, average loss: 0.6908
[10/10 15:42:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.75	
[10/10 15:42:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[10/10 15:48:52 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0205, average train loss: 0.7111
[10/10 15:49:36 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2312, average loss: 0.6938
[10/10 15:49:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[10/10 15:49:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[10/10 15:56:02 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0086, average train loss: 0.7108
[10/10 15:56:46 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2273, average loss: 0.6850
[10/10 15:56:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.10	
[10/10 15:56:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[10/10 16:03:11 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0097, average train loss: 0.7346
[10/10 16:03:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2449, average loss: 0.7729
[10/10 16:03:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.07	
[10/10 16:03:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[10/10 16:10:21 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0118, average train loss: 0.7440
[10/10 16:11:05 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2365, average loss: 0.7404
[10/10 16:11:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.99	
[10/10 16:11:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[10/10 16:17:32 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0375, average train loss: 0.7244
[10/10 16:18:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2387, average loss: 0.6815
[10/10 16:18:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 57.55	
[10/10 16:18:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[10/10 16:24:43 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0574, average train loss: 0.7284
[10/10 16:25:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2041, average loss: 0.6809
[10/10 16:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 58.51	
[10/10 16:25:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[10/10 16:31:55 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0958, average train loss: 0.7008
[10/10 16:32:39 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2291, average loss: 0.7192
[10/10 16:32:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.30	
[10/10 16:32:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[10/10 16:39:04 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9959, average train loss: 0.6904
[10/10 16:39:48 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2088, average loss: 0.7195
[10/10 16:39:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 59.43	
[10/10 16:39:48 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[10/10 16:46:14 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0135, average train loss: 0.7078
[10/10 16:46:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2061, average loss: 0.6786
[10/10 16:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.46	
[10/10 16:46:59 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/10 16:53:25 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0464, average train loss: 0.7014
[10/10 16:54:09 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2070, average loss: 0.7167
[10/10 16:54:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 58.96	
[10/10 16:54:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/10 17:00:37 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0685, average train loss: 0.7446
[10/10 17:01:21 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2108, average loss: 0.6783
[10/10 17:01:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.63	
[10/10 17:01:21 visual_prompt]: Best epoch 13: best metric: -0.678
[10/10 17:01:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/10 17:07:46 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 11.0073, average train loss: 0.7083
[10/10 17:08:31 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2352, average loss: 0.7098
[10/10 17:08:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.54	
[10/10 17:08:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/10 17:14:57 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0293, average train loss: 0.7302
[10/10 17:15:41 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2152, average loss: 0.7025
[10/10 17:15:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.57	
[10/10 17:15:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[10/10 17:22:08 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0586, average train loss: 0.7488
[10/10 17:22:52 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.2104, average loss: 0.6816
[10/10 17:22:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 58.82	
[10/10 17:22:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[10/10 17:29:18 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0160, average train loss: 0.7019
[10/10 17:30:02 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2423, average loss: 0.6818
[10/10 17:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.35	
[10/10 17:30:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[10/10 17:36:27 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0165, average train loss: 0.7236
[10/10 17:37:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2276, average loss: 0.8477
[10/10 17:37:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.90	
[10/10 17:37:11 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[10/10 17:43:36 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9743, average train loss: 0.7020
[10/10 17:44:20 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2313, average loss: 0.7549
[10/10 17:44:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.69	
[10/10 17:44:20 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[10/10 17:50:47 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0613, average train loss: 0.6951
[10/10 17:51:31 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2474, average loss: 0.9078
[10/10 17:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.37	
[10/10 17:51:31 visual_prompt]: Stopping early.
[10/10 17:51:32 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 17:51:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 17:51:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 17:51:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 17:51:32 visual_prompt]: Training with config:
[10/10 17:51:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 17:51:32 visual_prompt]: Loading training data...
[10/10 17:51:32 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 17:51:32 visual_prompt]: Loading validation data...
[10/10 17:51:32 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 17:51:32 visual_prompt]: Constructing models...
[10/10 17:51:34 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 17:51:34 visual_prompt]: tuned percent:0.536
[10/10 17:51:34 visual_prompt]: Device used for model: 0
[10/10 17:51:34 visual_prompt]: Setting up Evaluator...
[10/10 17:51:34 visual_prompt]: Setting up Trainer...
[10/10 17:51:34 visual_prompt]: 	Setting up the optimizer...
[10/10 17:51:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 17:58:02 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0606, average train loss: 1.4524
[10/10 17:58:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2320, average loss: 1.4398
[10/10 17:58:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 17:58:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[10/10 18:05:11 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0018, average train loss: 1.2313
[10/10 18:05:55 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.2288, average loss: 0.6907
[10/10 18:05:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 57.75	
[10/10 18:05:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[10/10 18:12:21 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0257, average train loss: 0.7117
[10/10 18:13:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2374, average loss: 0.6941
[10/10 18:13:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.39	
[10/10 18:13:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[10/10 18:19:32 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0540, average train loss: 0.7115
[10/10 18:20:17 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.2405, average loss: 0.6850
[10/10 18:20:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[10/10 18:20:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[10/10 18:26:44 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0764, average train loss: 0.7364
[10/10 18:27:29 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2250, average loss: 0.7796
[10/10 18:27:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.24	
[10/10 18:27:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[10/10 18:33:54 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.0070, average train loss: 0.7459
[10/10 18:34:38 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2328, average loss: 0.7444
[10/10 18:34:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[10/10 18:34:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[10/10 18:41:04 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0388, average train loss: 0.7310
[10/10 18:41:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2039, average loss: 0.6825
[10/10 18:41:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 57.99	
[10/10 18:41:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[10/10 18:48:14 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0273, average train loss: 0.7334
[10/10 18:48:59 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.2352, average loss: 0.6784
[10/10 18:48:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 58.76	
[10/10 18:48:59 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[10/10 18:55:28 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.1105, average train loss: 0.7005
[10/10 18:56:12 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2408, average loss: 0.7350
[10/10 18:56:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.98	
[10/10 18:56:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[10/10 19:02:37 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9912, average train loss: 0.6937
[10/10 19:03:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.2062, average loss: 0.6865
[10/10 19:03:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 59.91	
[10/10 19:03:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[10/10 19:09:46 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0041, average train loss: 0.7132
[10/10 19:10:30 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2034, average loss: 0.6874
[10/10 19:10:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 58.67	
[10/10 19:10:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/10 19:16:55 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9873, average train loss: 0.7007
[10/10 19:17:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2118, average loss: 0.7662
[10/10 19:17:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.56	
[10/10 19:17:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/10 19:24:05 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0138, average train loss: 0.7789
[10/10 19:24:48 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2249, average loss: 0.6938
[10/10 19:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.61	
[10/10 19:24:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/10 19:31:14 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 11.0068, average train loss: 0.7289
[10/10 19:31:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.2340, average loss: 0.7103
[10/10 19:31:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.72	
[10/10 19:31:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/10 19:38:24 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0292, average train loss: 0.7427
[10/10 19:39:08 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2232, average loss: 0.7351
[10/10 19:39:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[10/10 19:39:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[10/10 19:45:35 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0376, average train loss: 0.7523
[10/10 19:46:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2071, average loss: 0.6867
[10/10 19:46:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 58.43	
[10/10 19:46:19 visual_prompt]: Best epoch 16: best metric: -0.687
[10/10 19:46:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[10/10 19:52:46 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0509, average train loss: 0.7192
[10/10 19:53:30 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2047, average loss: 0.6918
[10/10 19:53:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 59.77	
[10/10 19:53:30 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[10/10 19:59:58 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0857, average train loss: 0.7246
[10/10 20:00:43 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2284, average loss: 0.6926
[10/10 20:00:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 60.48	
[10/10 20:00:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[10/10 20:07:09 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0356, average train loss: 0.7154
[10/10 20:07:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2247, average loss: 0.6855
[10/10 20:07:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 60.30	
[10/10 20:07:53 visual_prompt]: Best epoch 19: best metric: -0.685
[10/10 20:07:53 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[10/10 20:14:19 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0226, average train loss: 0.6891
[10/10 20:15:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2267, average loss: 0.9683
[10/10 20:15:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.04	
[10/10 20:15:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[10/10 20:21:29 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 11.0009, average train loss: 0.6897
[10/10 20:22:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2368, average loss: 0.6893
[10/10 20:22:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.42	
[10/10 20:22:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[10/10 20:28:38 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9964, average train loss: 0.6764
[10/10 20:29:22 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2261, average loss: 0.6703
[10/10 20:29:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.43	
[10/10 20:29:22 visual_prompt]: Best epoch 22: best metric: -0.670
[10/10 20:29:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[10/10 20:35:47 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 11.0000, average train loss: 0.6911
[10/10 20:36:31 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2146, average loss: 0.6786
[10/10 20:36:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 63.98	
[10/10 20:36:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[10/10 20:42:57 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 11.0140, average train loss: 0.7064
[10/10 20:43:41 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2234, average loss: 0.6640
[10/10 20:43:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.47	
[10/10 20:43:41 visual_prompt]: Best epoch 24: best metric: -0.664
[10/10 20:43:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[10/10 20:50:06 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 11.0107, average train loss: 0.6780
[10/10 20:50:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2288, average loss: 0.6809
[10/10 20:50:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.16	
[10/10 20:50:51 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[10/10 20:57:16 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 11.0004, average train loss: 0.6854
[10/10 20:58:00 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.2249, average loss: 0.6564
[10/10 20:58:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.32	
[10/10 20:58:00 visual_prompt]: Best epoch 26: best metric: -0.656
[10/10 20:58:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[10/10 21:04:26 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 11.0257, average train loss: 0.6772
[10/10 21:05:11 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2057, average loss: 0.6516
[10/10 21:05:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.77	
[10/10 21:05:11 visual_prompt]: Best epoch 27: best metric: -0.652
[10/10 21:05:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[10/10 21:11:37 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 11.0337, average train loss: 0.7029
[10/10 21:12:21 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2415, average loss: 0.7288
[10/10 21:12:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.70	
[10/10 21:12:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[10/10 21:18:48 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0584, average train loss: 0.6677
[10/10 21:19:33 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2301, average loss: 0.6546
[10/10 21:19:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.91	
[10/10 21:19:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[10/10 21:26:00 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 11.0659, average train loss: 0.6557
[10/10 21:26:44 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2249, average loss: 0.6623
[10/10 21:26:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 64.49	
[10/10 21:26:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[10/10 21:33:12 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0728, average train loss: 0.6484
[10/10 21:33:56 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.2097, average loss: 0.6794
[10/10 21:33:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.67	
[10/10 21:33:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[10/10 21:40:23 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0487, average train loss: 0.6721
[10/10 21:41:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2237, average loss: 0.7245
[10/10 21:41:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 63.43	
[10/10 21:41:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[10/10 21:47:34 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 11.0371, average train loss: 0.6524
[10/10 21:48:18 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2110, average loss: 0.6564
[10/10 21:48:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.81	
[10/10 21:48:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[10/10 21:54:43 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 11.0022, average train loss: 0.6438
[10/10 21:55:27 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2200, average loss: 0.6593
[10/10 21:55:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 63.32	
[10/10 21:55:27 visual_prompt]: Stopping early.
[10/10 21:55:27 visual_prompt]: Rank of current process: 0. World size: 1
[10/10 21:55:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 21:55:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/10 21:55:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/10 21:55:27 visual_prompt]: Training with config:
[10/10 21:55:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/10 21:55:27 visual_prompt]: Loading training data...
[10/10 21:55:27 visual_prompt]: Constructing mammo-cbis dataset train...
[10/10 21:55:27 visual_prompt]: Loading validation data...
[10/10 21:55:27 visual_prompt]: Constructing mammo-cbis dataset val...
[10/10 21:55:27 visual_prompt]: Constructing models...
[10/10 21:55:30 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/10 21:55:30 visual_prompt]: tuned percent:0.536
[10/10 21:55:30 visual_prompt]: Device used for model: 0
[10/10 21:55:30 visual_prompt]: Setting up Evaluator...
[10/10 21:55:30 visual_prompt]: Setting up Trainer...
[10/10 21:55:30 visual_prompt]: 	Setting up the optimizer...
[10/10 21:55:30 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/10 22:01:55 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 11.0008, average train loss: 1.4524
[10/10 22:02:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2304, average loss: 1.4398
[10/10 22:02:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/10 22:02:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[10/10 22:09:05 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0216, average train loss: 1.2314
[10/10 22:09:50 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2186, average loss: 0.6907
[10/10 22:09:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 57.74	
[10/10 22:09:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[10/10 22:16:16 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0221, average train loss: 0.7118
[10/10 22:17:00 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2193, average loss: 0.6941
[10/10 22:17:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.37	
[10/10 22:17:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[10/10 22:23:25 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0045, average train loss: 0.7115
[10/10 22:24:09 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2256, average loss: 0.6850
[10/10 22:24:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.18	
[10/10 22:24:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[10/10 22:30:33 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9760, average train loss: 0.7366
[10/10 22:31:17 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2329, average loss: 0.7805
[10/10 22:31:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.29	
[10/10 22:31:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[10/10 22:37:42 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.9936, average train loss: 0.7478
[10/10 22:38:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2410, average loss: 0.7478
[10/10 22:38:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.10	
[10/10 22:38:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[10/10 22:44:52 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0046, average train loss: 0.7304
[10/10 22:45:35 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2109, average loss: 0.6819
[10/10 22:45:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 57.75	
[10/10 22:45:35 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[10/10 22:52:00 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9858, average train loss: 0.7351
[10/10 22:52:44 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2238, average loss: 0.6783
[10/10 22:52:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 58.53	
[10/10 22:52:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[10/10 22:59:11 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0492, average train loss: 0.7013
[10/10 22:59:55 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2048, average loss: 0.7323
[10/10 22:59:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.70	
[10/10 22:59:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[10/10 23:06:20 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9967, average train loss: 0.6939
[10/10 23:07:04 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2270, average loss: 0.6911
[10/10 23:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 59.97	
[10/10 23:07:04 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[10/10 23:13:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0249, average train loss: 0.7142
[10/10 23:14:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.2373, average loss: 0.6815
[10/10 23:14:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.61	
[10/10 23:14:14 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[10/10 23:20:39 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9948, average train loss: 0.7036
[10/10 23:21:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2109, average loss: 0.7622
[10/10 23:21:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.41	
[10/10 23:21:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[10/10 23:27:49 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0295, average train loss: 0.7787
[10/10 23:28:33 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2035, average loss: 0.7031
[10/10 23:28:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.42	
[10/10 23:28:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[10/10 23:34:58 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9803, average train loss: 0.7290
[10/10 23:35:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2392, average loss: 0.7127
[10/10 23:35:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.49	
[10/10 23:35:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[10/10 23:42:07 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0139, average train loss: 0.7415
[10/10 23:42:52 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.2357, average loss: 0.7583
[10/10 23:42:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.66	
[10/10 23:42:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[10/10 23:49:17 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 11.0029, average train loss: 0.7494
[10/10 23:50:01 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2126, average loss: 0.7080
[10/10 23:50:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.54	
[10/10 23:50:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[10/10 23:56:25 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9924, average train loss: 0.7328
[10/10 23:57:09 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2432, average loss: 0.6910
[10/10 23:57:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 59.62	
[10/10 23:57:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[10/11 00:03:35 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0188, average train loss: 0.7307
[10/11 00:04:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2280, average loss: 0.6927
[10/11 00:04:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 59.95	
[10/11 00:04:19 visual_prompt]: Stopping early.
[10/11 00:04:19 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 00:04:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 00:04:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 00:04:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 00:04:19 visual_prompt]: Training with config:
[10/11 00:04:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 00:04:19 visual_prompt]: Loading training data...
[10/11 00:04:19 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 00:04:19 visual_prompt]: Loading validation data...
[10/11 00:04:19 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 00:04:19 visual_prompt]: Constructing models...
[10/11 00:04:22 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 00:04:22 visual_prompt]: tuned percent:0.536
[10/11 00:04:22 visual_prompt]: Device used for model: 0
[10/11 00:04:22 visual_prompt]: Setting up Evaluator...
[10/11 00:04:22 visual_prompt]: Setting up Trainer...
[10/11 00:04:22 visual_prompt]: 	Setting up the optimizer...
[10/11 00:04:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 00:10:47 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.9886, average train loss: 1.4524
[10/11 00:11:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2319, average loss: 1.4398
[10/11 00:11:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 00:11:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/11 00:17:55 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9813, average train loss: 1.0402
[10/11 00:18:39 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2145, average loss: 0.6869
[10/11 00:18:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 53.93	
[10/11 00:18:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/11 00:25:04 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0086, average train loss: 0.7034
[10/11 00:25:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2144, average loss: 0.6845
[10/11 00:25:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.64	
[10/11 00:25:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/11 00:32:15 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0509, average train loss: 0.6930
[10/11 00:33:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2236, average loss: 0.6842
[10/11 00:33:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.06	
[10/11 00:33:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/11 00:39:26 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0362, average train loss: 0.7134
[10/11 00:40:10 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2058, average loss: 0.6942
[10/11 00:40:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.31	
[10/11 00:40:10 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/11 00:46:38 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0695, average train loss: 0.7134
[10/11 00:47:22 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.2173, average loss: 0.6898
[10/11 00:47:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 56.33	
[10/11 00:47:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/11 00:53:50 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0640, average train loss: 0.6999
[10/11 00:54:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2066, average loss: 0.6883
[10/11 00:54:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 57.32	
[10/11 00:54:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/11 01:00:59 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0010, average train loss: 0.7016
[10/11 01:01:43 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2448, average loss: 0.6852
[10/11 01:01:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.68	
[10/11 01:01:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/11 01:08:09 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0305, average train loss: 0.6944
[10/11 01:08:53 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2379, average loss: 0.6945
[10/11 01:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.01	
[10/11 01:08:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/11 01:15:18 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9862, average train loss: 0.7000
[10/11 01:16:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2323, average loss: 0.6920
[10/11 01:16:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.63	
[10/11 01:16:02 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/11 01:22:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0230, average train loss: 0.6934
[10/11 01:23:12 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2320, average loss: 0.6869
[10/11 01:23:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 56.42	
[10/11 01:23:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/11 01:29:39 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0391, average train loss: 0.6907
[10/11 01:30:23 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2051, average loss: 0.6871
[10/11 01:30:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.99	
[10/11 01:30:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/11 01:36:50 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0560, average train loss: 0.7132
[10/11 01:37:34 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2126, average loss: 0.7102
[10/11 01:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.01	
[10/11 01:37:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/11 01:43:58 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9683, average train loss: 0.7041
[10/11 01:44:42 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2034, average loss: 0.7118
[10/11 01:44:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.13	
[10/11 01:44:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/11 01:51:07 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0008, average train loss: 0.7116
[10/11 01:51:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2121, average loss: 0.6959
[10/11 01:51:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.39	
[10/11 01:51:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/11 01:58:18 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0239, average train loss: 0.6995
[10/11 01:59:04 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.2409, average loss: 0.6916
[10/11 01:59:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.25	
[10/11 01:59:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/11 02:05:46 visual_prompt]: Epoch 17 / 100: avg data time: 1.10e+01, avg batch time: 11.5021, average train loss: 0.6944
[10/11 02:06:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2378, average loss: 0.6876
[10/11 02:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.06	
[10/11 02:06:33 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/11 02:13:10 visual_prompt]: Epoch 18 / 100: avg data time: 1.09e+01, avg batch time: 11.3463, average train loss: 0.6926
[10/11 02:13:55 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.2301, average loss: 0.6957
[10/11 02:13:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.57	
[10/11 02:13:55 visual_prompt]: Stopping early.
[10/11 02:13:55 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 02:13:55 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 02:13:55 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 02:13:55 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 02:13:55 visual_prompt]: Training with config:
[10/11 02:13:55 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 02:13:55 visual_prompt]: Loading training data...
[10/11 02:13:55 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 02:13:55 visual_prompt]: Loading validation data...
[10/11 02:13:55 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 02:13:55 visual_prompt]: Constructing models...
[10/11 02:13:58 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 02:13:58 visual_prompt]: tuned percent:0.536
[10/11 02:13:58 visual_prompt]: Device used for model: 0
[10/11 02:13:58 visual_prompt]: Setting up Evaluator...
[10/11 02:13:58 visual_prompt]: Setting up Trainer...
[10/11 02:13:58 visual_prompt]: 	Setting up the optimizer...
[10/11 02:13:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 02:20:30 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.1953, average train loss: 1.4524
[10/11 02:21:14 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2076, average loss: 1.4398
[10/11 02:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 02:21:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/11 02:27:47 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.2329, average train loss: 1.0421
[10/11 02:28:33 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2320, average loss: 0.6867
[10/11 02:28:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 54.02	
[10/11 02:28:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/11 02:35:07 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.2780, average train loss: 0.7049
[10/11 02:35:53 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2317, average loss: 0.6841
[10/11 02:35:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[10/11 02:35:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/11 02:42:24 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.1758, average train loss: 0.6945
[10/11 02:43:08 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.2077, average loss: 0.6831
[10/11 02:43:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 57.30	
[10/11 02:43:08 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/11 02:49:33 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9839, average train loss: 0.7186
[10/11 02:50:17 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2305, average loss: 0.6953
[10/11 02:50:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.55	
[10/11 02:50:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/11 02:56:42 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.0112, average train loss: 0.7204
[10/11 02:57:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.2034, average loss: 0.7150
[10/11 02:57:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.66	
[10/11 02:57:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/11 03:03:53 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0213, average train loss: 0.7115
[10/11 03:04:37 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2328, average loss: 0.6862
[10/11 03:04:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.69	
[10/11 03:04:37 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/11 03:11:02 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9878, average train loss: 0.6993
[10/11 03:11:46 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2222, average loss: 0.6776
[10/11 03:11:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.82	
[10/11 03:11:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/11 03:18:12 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0294, average train loss: 0.7003
[10/11 03:18:56 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2331, average loss: 0.7233
[10/11 03:18:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.41	
[10/11 03:18:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/11 03:25:21 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9915, average train loss: 0.7227
[10/11 03:26:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2277, average loss: 0.7009
[10/11 03:26:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.96	
[10/11 03:26:05 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/11 03:32:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9946, average train loss: 0.6933
[10/11 03:33:14 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2398, average loss: 0.6798
[10/11 03:33:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 57.20	
[10/11 03:33:14 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/11 03:39:39 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9893, average train loss: 0.6992
[10/11 03:40:23 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2339, average loss: 0.6753
[10/11 03:40:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 59.02	
[10/11 03:40:23 visual_prompt]: Best epoch 12: best metric: -0.675
[10/11 03:40:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/11 03:46:48 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0155, average train loss: 0.7072
[10/11 03:47:32 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2166, average loss: 0.6908
[10/11 03:47:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 58.83	
[10/11 03:47:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/11 03:53:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9738, average train loss: 0.7172
[10/11 03:54:40 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.2056, average loss: 0.8846
[10/11 03:54:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.95	
[10/11 03:54:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/11 04:01:05 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0067, average train loss: 0.7119
[10/11 04:01:50 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2053, average loss: 0.6838
[10/11 04:01:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 58.39	
[10/11 04:01:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/11 04:08:14 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9742, average train loss: 0.6949
[10/11 04:08:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2408, average loss: 0.7674
[10/11 04:08:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.43	
[10/11 04:08:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/11 04:15:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9717, average train loss: 0.6972
[10/11 04:16:06 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2318, average loss: 0.6747
[10/11 04:16:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 58.97	
[10/11 04:16:06 visual_prompt]: Best epoch 17: best metric: -0.675
[10/11 04:16:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/11 04:22:31 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9871, average train loss: 0.7024
[10/11 04:23:15 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2112, average loss: 0.7054
[10/11 04:23:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 58.89	
[10/11 04:23:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/11 04:29:41 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0198, average train loss: 0.7003
[10/11 04:30:24 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2238, average loss: 0.7348
[10/11 04:30:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.69	
[10/11 04:30:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/11 04:36:50 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0052, average train loss: 0.6915
[10/11 04:37:34 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2356, average loss: 0.7458
[10/11 04:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.55	
[10/11 04:37:34 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/11 04:43:59 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.9957, average train loss: 0.6999
[10/11 04:44:43 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.2133, average loss: 0.6725
[10/11 04:44:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.28	
[10/11 04:44:43 visual_prompt]: Best epoch 21: best metric: -0.673
[10/11 04:44:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/11 04:51:07 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9897, average train loss: 0.6747
[10/11 04:51:51 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2309, average loss: 0.7199
[10/11 04:51:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 62.42	
[10/11 04:51:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/11 04:58:15 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.9715, average train loss: 0.6842
[10/11 04:59:00 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2285, average loss: 0.6674
[10/11 04:59:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 61.74	
[10/11 04:59:00 visual_prompt]: Best epoch 23: best metric: -0.667
[10/11 04:59:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/11 05:05:25 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.0108, average train loss: 0.6848
[10/11 05:06:10 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2277, average loss: 0.7522
[10/11 05:06:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 61.23	
[10/11 05:06:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/11 05:12:35 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 11.0068, average train loss: 0.6796
[10/11 05:13:19 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2283, average loss: 0.6668
[10/11 05:13:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 61.97	
[10/11 05:13:19 visual_prompt]: Best epoch 25: best metric: -0.667
[10/11 05:13:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/11 05:19:45 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 11.0134, average train loss: 0.6682
[10/11 05:20:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2238, average loss: 0.6625
[10/11 05:20:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 63.38	
[10/11 05:20:29 visual_prompt]: Best epoch 26: best metric: -0.662
[10/11 05:20:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/11 05:26:54 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.9969, average train loss: 0.6731
[10/11 05:27:38 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2305, average loss: 0.6578
[10/11 05:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 64.08	
[10/11 05:27:38 visual_prompt]: Best epoch 27: best metric: -0.658
[10/11 05:27:38 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/11 05:34:02 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.9634, average train loss: 0.6723
[10/11 05:34:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2289, average loss: 0.7109
[10/11 05:34:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.41	
[10/11 05:34:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/11 05:41:12 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0449, average train loss: 0.6686
[10/11 05:41:56 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.2139, average loss: 0.6849
[10/11 05:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 63.11	
[10/11 05:41:56 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[10/11 05:48:21 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.9953, average train loss: 0.6536
[10/11 05:49:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2398, average loss: 0.6630
[10/11 05:49:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 62.55	
[10/11 05:49:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[10/11 05:55:31 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0146, average train loss: 0.6562
[10/11 05:56:14 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2044, average loss: 0.6724
[10/11 05:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 63.99	
[10/11 05:56:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[10/11 06:02:40 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0162, average train loss: 0.6881
[10/11 06:03:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2084, average loss: 0.7572
[10/11 06:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 63.75	
[10/11 06:03:24 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[10/11 06:09:49 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 11.0066, average train loss: 0.6742
[10/11 06:10:34 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2183, average loss: 0.6580
[10/11 06:10:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 64.51	
[10/11 06:10:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[10/11 06:16:59 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.9950, average train loss: 0.6521
[10/11 06:17:43 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2285, average loss: 0.7294
[10/11 06:17:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 63.02	
[10/11 06:17:43 visual_prompt]: Stopping early.
[10/11 06:17:43 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 06:17:43 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 06:17:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 06:17:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 06:17:43 visual_prompt]: Training with config:
[10/11 06:17:43 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 06:17:43 visual_prompt]: Loading training data...
[10/11 06:17:43 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 06:17:43 visual_prompt]: Loading validation data...
[10/11 06:17:43 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 06:17:43 visual_prompt]: Constructing models...
[10/11 06:17:45 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 06:17:45 visual_prompt]: tuned percent:0.536
[10/11 06:17:46 visual_prompt]: Device used for model: 0
[10/11 06:17:46 visual_prompt]: Setting up Evaluator...
[10/11 06:17:46 visual_prompt]: Setting up Trainer...
[10/11 06:17:46 visual_prompt]: 	Setting up the optimizer...
[10/11 06:17:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 06:24:11 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.9989, average train loss: 1.4524
[10/11 06:24:55 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2388, average loss: 1.4398
[10/11 06:24:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 06:24:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/11 06:31:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9872, average train loss: 1.0422
[10/11 06:32:03 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2402, average loss: 0.6867
[10/11 06:32:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 54.00	
[10/11 06:32:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/11 06:38:28 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9916, average train loss: 0.7050
[10/11 06:39:12 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2351, average loss: 0.6841
[10/11 06:39:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.50	
[10/11 06:39:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/11 06:45:39 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0351, average train loss: 0.6947
[10/11 06:46:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.2365, average loss: 0.6830
[10/11 06:46:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 57.24	
[10/11 06:46:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/11 06:52:47 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9882, average train loss: 0.7188
[10/11 06:53:31 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2213, average loss: 0.6967
[10/11 06:53:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.54	
[10/11 06:53:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/11 06:59:58 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0336, average train loss: 0.7229
[10/11 07:00:42 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.2231, average loss: 0.7147
[10/11 07:00:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.85	
[10/11 07:00:42 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/11 07:07:07 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 11.0085, average train loss: 0.7114
[10/11 07:07:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2216, average loss: 0.6862
[10/11 07:07:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.93	
[10/11 07:07:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/11 07:14:16 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.9976, average train loss: 0.7007
[10/11 07:15:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2077, average loss: 0.6777
[10/11 07:15:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.21	
[10/11 07:15:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/11 07:21:27 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0302, average train loss: 0.6963
[10/11 07:22:11 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.2092, average loss: 0.7385
[10/11 07:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.79	
[10/11 07:22:11 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/11 07:28:36 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 11.0041, average train loss: 0.7211
[10/11 07:29:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2124, average loss: 0.6818
[10/11 07:29:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 58.37	
[10/11 07:29:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/11 07:35:45 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9841, average train loss: 0.6943
[10/11 07:36:29 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.2128, average loss: 0.6837
[10/11 07:36:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 57.31	
[10/11 07:36:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/11 07:42:54 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 11.0030, average train loss: 0.7032
[10/11 07:43:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2097, average loss: 0.6755
[10/11 07:43:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.97	
[10/11 07:43:38 visual_prompt]: Best epoch 12: best metric: -0.676
[10/11 07:43:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/11 07:50:03 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0110, average train loss: 0.7124
[10/11 07:50:47 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2037, average loss: 0.6926
[10/11 07:50:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 58.83	
[10/11 07:50:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/11 07:57:13 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 11.0184, average train loss: 0.7161
[10/11 07:57:58 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2393, average loss: 0.8834
[10/11 07:57:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.96	
[10/11 07:57:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/11 08:04:26 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0983, average train loss: 0.7192
[10/11 08:05:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2038, average loss: 0.6862
[10/11 08:05:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.43	
[10/11 08:05:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/11 08:11:38 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0727, average train loss: 0.6944
[10/11 08:12:23 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2302, average loss: 0.7695
[10/11 08:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[10/11 08:12:23 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/11 08:18:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0634, average train loss: 0.7013
[10/11 08:19:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2345, average loss: 0.6740
[10/11 08:19:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 59.02	
[10/11 08:19:34 visual_prompt]: Best epoch 17: best metric: -0.674
[10/11 08:19:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/11 08:26:01 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0588, average train loss: 0.7151
[10/11 08:26:46 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2278, average loss: 0.6969
[10/11 08:26:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.49	
[10/11 08:26:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/11 08:33:13 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0532, average train loss: 0.7020
[10/11 08:33:57 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2089, average loss: 0.7260
[10/11 08:33:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 59.70	
[10/11 08:33:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/11 08:40:25 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0661, average train loss: 0.6901
[10/11 08:41:09 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2322, average loss: 0.7749
[10/11 08:41:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.81	
[10/11 08:41:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/11 08:47:34 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 11.0064, average train loss: 0.6942
[10/11 08:48:18 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.2059, average loss: 0.6700
[10/11 08:48:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 60.47	
[10/11 08:48:18 visual_prompt]: Best epoch 21: best metric: -0.670
[10/11 08:48:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/11 08:54:43 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9839, average train loss: 0.6813
[10/11 08:55:27 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.2310, average loss: 0.7328
[10/11 08:55:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 61.47	
[10/11 08:55:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/11 09:02:09 visual_prompt]: Epoch 23 / 100: avg data time: 1.10e+01, avg batch time: 11.4984, average train loss: 0.6923
[10/11 09:02:56 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.2418, average loss: 0.6685
[10/11 09:02:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 61.19	
[10/11 09:02:56 visual_prompt]: Best epoch 23: best metric: -0.668
[10/11 09:02:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/11 09:09:34 visual_prompt]: Epoch 24 / 100: avg data time: 1.09e+01, avg batch time: 11.3734, average train loss: 0.6866
[10/11 09:10:18 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2091, average loss: 0.7530
[10/11 09:10:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 61.68	
[10/11 09:10:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/11 09:16:51 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.2194, average train loss: 0.6915
[10/11 09:17:36 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.2318, average loss: 0.6684
[10/11 09:17:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.36	
[10/11 09:17:36 visual_prompt]: Best epoch 25: best metric: -0.668
[10/11 09:17:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/11 09:24:11 visual_prompt]: Epoch 26 / 100: avg data time: 1.08e+01, avg batch time: 11.2697, average train loss: 0.6704
[10/11 09:24:56 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.2253, average loss: 0.6631
[10/11 09:24:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 62.62	
[10/11 09:24:56 visual_prompt]: Best epoch 26: best metric: -0.663
[10/11 09:24:56 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/11 09:31:35 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.3881, average train loss: 0.6719
[10/11 09:32:20 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2243, average loss: 0.6621
[10/11 09:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.07	
[10/11 09:32:20 visual_prompt]: Best epoch 27: best metric: -0.662
[10/11 09:32:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/11 09:38:59 visual_prompt]: Epoch 28 / 100: avg data time: 1.09e+01, avg batch time: 11.3949, average train loss: 0.6770
[10/11 09:39:44 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.2152, average loss: 0.7086
[10/11 09:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.15	
[10/11 09:39:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/11 09:46:20 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.3120, average train loss: 0.6719
[10/11 09:47:06 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.2371, average loss: 0.7028
[10/11 09:47:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.85	
[10/11 09:47:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[10/11 09:53:38 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.2080, average train loss: 0.6624
[10/11 09:54:23 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.2319, average loss: 0.6623
[10/11 09:54:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 63.28	
[10/11 09:54:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[10/11 10:00:50 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0662, average train loss: 0.6616
[10/11 10:01:35 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2337, average loss: 0.6828
[10/11 10:01:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.14	
[10/11 10:01:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[10/11 10:08:02 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0649, average train loss: 0.7076
[10/11 10:08:46 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2289, average loss: 0.7784
[10/11 10:08:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 63.46	
[10/11 10:08:46 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[10/11 10:15:14 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 11.0702, average train loss: 0.6871
[10/11 10:15:58 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2373, average loss: 0.6608
[10/11 10:15:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 62.93	
[10/11 10:15:58 visual_prompt]: Best epoch 33: best metric: -0.661
[10/11 10:15:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[10/11 10:22:25 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 11.0441, average train loss: 0.6620
[10/11 10:23:09 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2213, average loss: 0.7465
[10/11 10:23:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 62.84	
[10/11 10:23:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[10/11 10:29:36 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 11.0684, average train loss: 0.6684
[10/11 10:30:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2143, average loss: 0.6707
[10/11 10:30:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.24	
[10/11 10:30:21 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[10/11 10:36:48 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 11.0544, average train loss: 0.6673
[10/11 10:37:32 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2088, average loss: 0.6923
[10/11 10:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 63.88	
[10/11 10:37:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[10/11 10:44:00 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 11.0782, average train loss: 0.6729
[10/11 10:44:44 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.2298, average loss: 0.6904
[10/11 10:44:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.12	
[10/11 10:44:44 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[10/11 10:51:12 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 11.0746, average train loss: 0.6565
[10/11 10:51:56 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2228, average loss: 0.6639
[10/11 10:51:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 63.41	
[10/11 10:51:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[10/11 10:58:24 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 11.0714, average train loss: 0.6527
[10/11 10:59:08 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2078, average loss: 0.6950
[10/11 10:59:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 64.70	
[10/11 10:59:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[10/11 11:05:35 visual_prompt]: Epoch 40 / 100: avg data time: 1.06e+01, avg batch time: 11.0315, average train loss: 0.6536
[10/11 11:06:19 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2262, average loss: 0.6618
[10/11 11:06:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.01	
[10/11 11:06:19 visual_prompt]: Stopping early.
[10/11 11:06:19 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 11:06:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 11:06:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 11:06:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 11:06:19 visual_prompt]: Training with config:
[10/11 11:06:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 11:06:19 visual_prompt]: Loading training data...
[10/11 11:06:19 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 11:06:19 visual_prompt]: Loading validation data...
[10/11 11:06:19 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 11:06:19 visual_prompt]: Constructing models...
[10/11 11:06:22 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 11:06:22 visual_prompt]: tuned percent:0.536
[10/11 11:06:22 visual_prompt]: Device used for model: 0
[10/11 11:06:22 visual_prompt]: Setting up Evaluator...
[10/11 11:06:22 visual_prompt]: Setting up Trainer...
[10/11 11:06:22 visual_prompt]: 	Setting up the optimizer...
[10/11 11:06:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 11:12:48 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0265, average train loss: 1.4524
[10/11 11:13:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2081, average loss: 1.4398
[10/11 11:13:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 11:13:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/11 11:19:57 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9879, average train loss: 1.0423
[10/11 11:20:41 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2076, average loss: 0.6867
[10/11 11:20:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 54.00	
[10/11 11:20:41 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/11 11:27:06 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9948, average train loss: 0.7050
[10/11 11:27:50 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2270, average loss: 0.6840
[10/11 11:27:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.50	
[10/11 11:27:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/11 11:34:16 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0253, average train loss: 0.6947
[10/11 11:35:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2061, average loss: 0.6830
[10/11 11:35:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 57.23	
[10/11 11:35:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/11 11:41:24 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9758, average train loss: 0.7188
[10/11 11:42:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2298, average loss: 0.6970
[10/11 11:42:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.44	
[10/11 11:42:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/11 11:48:33 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0166, average train loss: 0.7230
[10/11 11:49:17 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.2293, average loss: 0.7149
[10/11 11:49:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.80	
[10/11 11:49:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/11 11:55:44 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0315, average train loss: 0.7114
[10/11 11:56:28 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2172, average loss: 0.6862
[10/11 11:56:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 57.11	
[10/11 11:56:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/11 12:02:53 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0206, average train loss: 0.7011
[10/11 12:03:38 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2422, average loss: 0.6782
[10/11 12:03:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 59.16	
[10/11 12:03:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/11 12:10:04 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0398, average train loss: 0.6954
[10/11 12:10:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2290, average loss: 0.7446
[10/11 12:10:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.54	
[10/11 12:10:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/11 12:17:14 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 11.0045, average train loss: 0.7189
[10/11 12:17:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2390, average loss: 0.6795
[10/11 12:17:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 58.15	
[10/11 12:17:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/11 12:24:23 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9889, average train loss: 0.6937
[10/11 12:25:06 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2154, average loss: 0.6812
[10/11 12:25:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 57.00	
[10/11 12:25:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/11 12:31:33 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0354, average train loss: 0.7007
[10/11 12:32:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2035, average loss: 0.6752
[10/11 12:32:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 59.03	
[10/11 12:32:17 visual_prompt]: Best epoch 12: best metric: -0.675
[10/11 12:32:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/11 12:38:45 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0683, average train loss: 0.7130
[10/11 12:39:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2277, average loss: 0.6958
[10/11 12:39:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 58.78	
[10/11 12:39:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/11 12:45:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0465, average train loss: 0.7175
[10/11 12:46:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2210, average loss: 0.8913
[10/11 12:46:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.93	
[10/11 12:46:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/11 12:53:05 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0097, average train loss: 0.7217
[10/11 12:53:49 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2179, average loss: 0.6886
[10/11 12:53:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 58.54	
[10/11 12:53:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/11 13:00:14 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9939, average train loss: 0.6940
[10/11 13:00:58 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.2434, average loss: 0.7655
[10/11 13:00:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.69	
[10/11 13:00:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/11 13:07:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9730, average train loss: 0.7005
[10/11 13:08:07 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2240, average loss: 0.6739
[10/11 13:08:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.11	
[10/11 13:08:07 visual_prompt]: Best epoch 17: best metric: -0.674
[10/11 13:08:07 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/11 13:14:32 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.9919, average train loss: 0.7157
[10/11 13:15:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.2033, average loss: 0.6972
[10/11 13:15:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.34	
[10/11 13:15:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/11 13:21:40 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9835, average train loss: 0.7033
[10/11 13:22:25 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2442, average loss: 0.7287
[10/11 13:22:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.41	
[10/11 13:22:25 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/11 13:28:57 visual_prompt]: Epoch 20 / 100: avg data time: 1.07e+01, avg batch time: 11.2006, average train loss: 0.6917
[10/11 13:29:41 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2051, average loss: 0.7704
[10/11 13:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.41	
[10/11 13:29:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/11 13:36:08 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.0349, average train loss: 0.6952
[10/11 13:36:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2285, average loss: 0.6703
[10/11 13:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 60.35	
[10/11 13:36:52 visual_prompt]: Best epoch 21: best metric: -0.670
[10/11 13:36:52 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/11 13:43:19 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 11.0618, average train loss: 0.6822
[10/11 13:44:03 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2322, average loss: 0.7386
[10/11 13:44:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 61.17	
[10/11 13:44:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/11 13:50:30 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 11.0416, average train loss: 0.6934
[10/11 13:51:14 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2303, average loss: 0.6695
[10/11 13:51:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.92	
[10/11 13:51:14 visual_prompt]: Best epoch 23: best metric: -0.670
[10/11 13:51:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/11 13:57:49 visual_prompt]: Epoch 24 / 100: avg data time: 1.08e+01, avg batch time: 11.2746, average train loss: 0.6874
[10/11 13:58:34 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.2333, average loss: 0.7539
[10/11 13:58:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 61.51	
[10/11 13:58:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/11 14:05:00 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 11.0378, average train loss: 0.6924
[10/11 14:05:45 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2065, average loss: 0.6693
[10/11 14:05:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 61.12	
[10/11 14:05:45 visual_prompt]: Best epoch 25: best metric: -0.669
[10/11 14:05:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/11 14:12:10 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.9946, average train loss: 0.6715
[10/11 14:12:54 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.2311, average loss: 0.6650
[10/11 14:12:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 62.43	
[10/11 14:12:54 visual_prompt]: Best epoch 26: best metric: -0.665
[10/11 14:12:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/11 14:19:20 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 11.0258, average train loss: 0.6778
[10/11 14:20:04 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2227, average loss: 0.6627
[10/11 14:20:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 62.86	
[10/11 14:20:04 visual_prompt]: Best epoch 27: best metric: -0.663
[10/11 14:20:04 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/11 14:26:28 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.9859, average train loss: 0.6753
[10/11 14:27:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2278, average loss: 0.7107
[10/11 14:27:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.98	
[10/11 14:27:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/11 14:33:38 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0339, average train loss: 0.6738
[10/11 14:34:23 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2335, average loss: 0.7063
[10/11 14:34:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 62.69	
[10/11 14:34:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[10/11 14:40:50 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 11.0707, average train loss: 0.6629
[10/11 14:41:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.2286, average loss: 0.6651
[10/11 14:41:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.11	
[10/11 14:41:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[10/11 14:48:02 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0600, average train loss: 0.6634
[10/11 14:48:46 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.2079, average loss: 0.6820
[10/11 14:48:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 63.32	
[10/11 14:48:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[10/11 14:55:11 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 11.0068, average train loss: 0.7105
[10/11 14:55:55 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2121, average loss: 0.7849
[10/11 14:55:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 62.69	
[10/11 14:55:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[10/11 15:02:21 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 11.0067, average train loss: 0.6888
[10/11 15:03:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2302, average loss: 0.6616
[10/11 15:03:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 63.07	
[10/11 15:03:05 visual_prompt]: Best epoch 33: best metric: -0.662
[10/11 15:03:05 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[10/11 15:09:31 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 11.0117, average train loss: 0.6604
[10/11 15:10:14 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2278, average loss: 0.7214
[10/11 15:10:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 63.27	
[10/11 15:10:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[10/11 15:16:38 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.9653, average train loss: 0.6677
[10/11 15:17:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2223, average loss: 0.6671
[10/11 15:17:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 62.49	
[10/11 15:17:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[10/11 15:23:48 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 11.0030, average train loss: 0.6677
[10/11 15:24:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2154, average loss: 0.6923
[10/11 15:24:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.65	
[10/11 15:24:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[10/11 15:30:57 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 11.0042, average train loss: 0.6737
[10/11 15:31:41 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2046, average loss: 0.6890
[10/11 15:31:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 64.27	
[10/11 15:31:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[10/11 15:38:09 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 11.0741, average train loss: 0.6602
[10/11 15:38:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2357, average loss: 0.6610
[10/11 15:38:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.99	
[10/11 15:38:53 visual_prompt]: Best epoch 38: best metric: -0.661
[10/11 15:38:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[10/11 15:45:19 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 11.0281, average train loss: 0.6546
[10/11 15:46:03 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2401, average loss: 0.6901
[10/11 15:46:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.41	
[10/11 15:46:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[10/11 15:52:29 visual_prompt]: Epoch 40 / 100: avg data time: 1.06e+01, avg batch time: 11.0268, average train loss: 0.6551
[10/11 15:53:14 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.2274, average loss: 0.6642
[10/11 15:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.76	
[10/11 15:53:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[10/11 15:59:39 visual_prompt]: Epoch 41 / 100: avg data time: 1.06e+01, avg batch time: 11.0048, average train loss: 0.6678
[10/11 16:00:23 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2034, average loss: 0.6942
[10/11 16:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.92	
[10/11 16:00:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[10/11 16:06:48 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.9992, average train loss: 0.6486
[10/11 16:07:32 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2296, average loss: 0.6897
[10/11 16:07:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 63.27	
[10/11 16:07:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[10/11 16:13:59 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 11.0315, average train loss: 0.6623
[10/11 16:14:43 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2288, average loss: 0.6597
[10/11 16:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 63.50	
[10/11 16:14:43 visual_prompt]: Best epoch 43: best metric: -0.660
[10/11 16:14:43 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[10/11 16:21:08 visual_prompt]: Epoch 44 / 100: avg data time: 1.05e+01, avg batch time: 10.9893, average train loss: 0.6604
[10/11 16:21:52 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2064, average loss: 0.6867
[10/11 16:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.62	
[10/11 16:21:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[10/11 16:28:21 visual_prompt]: Epoch 45 / 100: avg data time: 1.07e+01, avg batch time: 11.1340, average train loss: 0.6654
[10/11 16:29:06 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2223, average loss: 0.6796
[10/11 16:29:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.67	
[10/11 16:29:06 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[10/11 16:35:33 visual_prompt]: Epoch 46 / 100: avg data time: 1.06e+01, avg batch time: 11.0510, average train loss: 0.6566
[10/11 16:36:17 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.2291, average loss: 0.6662
[10/11 16:36:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 64.26	
[10/11 16:36:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[10/11 16:42:41 visual_prompt]: Epoch 47 / 100: avg data time: 1.05e+01, avg batch time: 10.9907, average train loss: 0.6394
[10/11 16:43:26 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2178, average loss: 0.6975
[10/11 16:43:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.56	
[10/11 16:43:26 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[10/11 16:49:51 visual_prompt]: Epoch 48 / 100: avg data time: 1.05e+01, avg batch time: 10.9978, average train loss: 0.6560
[10/11 16:50:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2286, average loss: 0.6764
[10/11 16:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.55	
[10/11 16:50:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[10/11 16:56:59 visual_prompt]: Epoch 49 / 100: avg data time: 1.05e+01, avg batch time: 10.9794, average train loss: 0.6345
[10/11 16:57:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2347, average loss: 0.7079
[10/11 16:57:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.35	
[10/11 16:57:43 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[10/11 17:04:08 visual_prompt]: Epoch 50 / 100: avg data time: 1.05e+01, avg batch time: 10.9951, average train loss: 0.6457
[10/11 17:04:52 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2274, average loss: 0.6567
[10/11 17:04:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 64.41	
[10/11 17:04:52 visual_prompt]: Best epoch 50: best metric: -0.657
[10/11 17:04:52 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[10/11 17:11:17 visual_prompt]: Epoch 51 / 100: avg data time: 1.05e+01, avg batch time: 10.9883, average train loss: 0.6774
[10/11 17:12:01 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.2130, average loss: 0.6508
[10/11 17:12:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 64.28	
[10/11 17:12:01 visual_prompt]: Best epoch 51: best metric: -0.651
[10/11 17:12:01 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[10/11 17:18:27 visual_prompt]: Epoch 52 / 100: avg data time: 1.06e+01, avg batch time: 11.0396, average train loss: 0.6433
[10/11 17:19:11 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2162, average loss: 0.6630
[10/11 17:19:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.10	
[10/11 17:19:11 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[10/11 17:25:35 visual_prompt]: Epoch 53 / 100: avg data time: 1.05e+01, avg batch time: 10.9750, average train loss: 0.6375
[10/11 17:26:19 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2401, average loss: 0.6614
[10/11 17:26:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 64.22	
[10/11 17:26:19 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[10/11 17:32:44 visual_prompt]: Epoch 54 / 100: avg data time: 1.05e+01, avg batch time: 10.9826, average train loss: 0.6429
[10/11 17:33:28 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2120, average loss: 0.6533
[10/11 17:33:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.06	
[10/11 17:33:28 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[10/11 17:39:51 visual_prompt]: Epoch 55 / 100: avg data time: 1.05e+01, avg batch time: 10.9549, average train loss: 0.6299
[10/11 17:40:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2358, average loss: 0.7018
[10/11 17:40:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 64.86	
[10/11 17:40:35 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[10/11 17:47:00 visual_prompt]: Epoch 56 / 100: avg data time: 1.05e+01, avg batch time: 10.9801, average train loss: 0.6443
[10/11 17:47:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2246, average loss: 0.6693
[10/11 17:47:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.52	
[10/11 17:47:44 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[10/11 17:54:11 visual_prompt]: Epoch 57 / 100: avg data time: 1.06e+01, avg batch time: 11.0499, average train loss: 0.6387
[10/11 17:54:55 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.2130, average loss: 0.6584
[10/11 17:54:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 64.31	
[10/11 17:54:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[10/11 18:01:21 visual_prompt]: Epoch 58 / 100: avg data time: 1.06e+01, avg batch time: 11.0175, average train loss: 0.6481
[10/11 18:02:05 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.2037, average loss: 0.6652
[10/11 18:02:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 63.54	
[10/11 18:02:05 visual_prompt]: Stopping early.
[10/11 18:02:05 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 18:02:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 18:02:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 18:02:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 18:02:05 visual_prompt]: Training with config:
[10/11 18:02:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 18:02:05 visual_prompt]: Loading training data...
[10/11 18:02:05 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 18:02:05 visual_prompt]: Loading validation data...
[10/11 18:02:05 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 18:02:05 visual_prompt]: Constructing models...
[10/11 18:02:08 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 18:02:08 visual_prompt]: tuned percent:0.536
[10/11 18:02:08 visual_prompt]: Device used for model: 0
[10/11 18:02:08 visual_prompt]: Setting up Evaluator...
[10/11 18:02:08 visual_prompt]: Setting up Trainer...
[10/11 18:02:08 visual_prompt]: 	Setting up the optimizer...
[10/11 18:02:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 18:08:33 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0140, average train loss: 1.4524
[10/11 18:09:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2068, average loss: 1.4398
[10/11 18:09:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 18:09:18 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[10/11 18:15:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.9779, average train loss: 0.8952
[10/11 18:16:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2107, average loss: 0.6908
[10/11 18:16:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.51	
[10/11 18:16:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[10/11 18:22:51 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0206, average train loss: 0.7043
[10/11 18:23:36 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2324, average loss: 0.6853
[10/11 18:23:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[10/11 18:23:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[10/11 18:30:01 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0057, average train loss: 0.6956
[10/11 18:30:45 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2351, average loss: 0.6831
[10/11 18:30:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.12	
[10/11 18:30:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[10/11 18:37:09 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9706, average train loss: 0.7158
[10/11 18:37:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2458, average loss: 0.6903
[10/11 18:37:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.97	
[10/11 18:37:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[10/11 18:44:18 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.9958, average train loss: 0.7210
[10/11 18:45:02 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.2134, average loss: 0.6934
[10/11 18:45:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 56.56	
[10/11 18:45:02 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[10/11 18:51:28 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0209, average train loss: 0.7061
[10/11 18:52:13 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2394, average loss: 0.6866
[10/11 18:52:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 57.59	
[10/11 18:52:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[10/11 18:58:38 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0197, average train loss: 0.6984
[10/11 18:59:22 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2348, average loss: 0.6797
[10/11 18:59:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.91	
[10/11 18:59:22 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[10/11 19:05:48 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.0193, average train loss: 0.6994
[10/11 19:06:32 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.2382, average loss: 0.6826
[10/11 19:06:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 58.48	
[10/11 19:06:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[10/11 19:12:57 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9868, average train loss: 0.7045
[10/11 19:13:41 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2397, average loss: 0.6847
[10/11 19:13:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.99	
[10/11 19:13:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[10/11 19:20:06 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0026, average train loss: 0.6887
[10/11 19:20:50 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.2060, average loss: 0.6779
[10/11 19:20:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.04	
[10/11 19:20:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[10/11 19:27:16 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0225, average train loss: 0.6955
[10/11 19:28:00 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2056, average loss: 0.6828
[10/11 19:28:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.27	
[10/11 19:28:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[10/11 19:34:26 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 11.0147, average train loss: 0.7052
[10/11 19:35:10 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2122, average loss: 0.6846
[10/11 19:35:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.35	
[10/11 19:35:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[10/11 19:41:35 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9884, average train loss: 0.6970
[10/11 19:42:19 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2065, average loss: 0.7767
[10/11 19:42:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.24	
[10/11 19:42:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[10/11 19:48:45 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0354, average train loss: 0.7058
[10/11 19:49:29 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2098, average loss: 0.6881
[10/11 19:49:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[10/11 19:49:29 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[10/11 19:55:54 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.9947, average train loss: 0.6920
[10/11 19:56:38 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2353, average loss: 0.8126
[10/11 19:56:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.95	
[10/11 19:56:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[10/11 20:03:02 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.9714, average train loss: 0.7048
[10/11 20:03:46 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.2305, average loss: 0.7060
[10/11 20:03:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.60	
[10/11 20:03:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[10/11 20:10:12 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 11.0177, average train loss: 0.7002
[10/11 20:10:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2065, average loss: 0.6985
[10/11 20:10:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.57	
[10/11 20:10:56 visual_prompt]: Stopping early.
[10/11 20:10:56 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 20:10:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 20:10:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 20:10:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 20:10:56 visual_prompt]: Training with config:
[10/11 20:10:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 20:10:56 visual_prompt]: Loading training data...
[10/11 20:10:56 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 20:10:56 visual_prompt]: Loading validation data...
[10/11 20:10:56 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 20:10:56 visual_prompt]: Constructing models...
[10/11 20:10:59 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 20:10:59 visual_prompt]: tuned percent:0.536
[10/11 20:10:59 visual_prompt]: Device used for model: 0
[10/11 20:10:59 visual_prompt]: Setting up Evaluator...
[10/11 20:10:59 visual_prompt]: Setting up Trainer...
[10/11 20:10:59 visual_prompt]: 	Setting up the optimizer...
[10/11 20:10:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 20:17:27 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0716, average train loss: 1.4524
[10/11 20:18:11 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2063, average loss: 1.4398
[10/11 20:18:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 20:18:11 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[10/11 20:24:40 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.1135, average train loss: 0.8955
[10/11 20:25:24 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2374, average loss: 0.6909
[10/11 20:25:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.44	
[10/11 20:25:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[10/11 20:31:50 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0386, average train loss: 0.7050
[10/11 20:32:34 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2378, average loss: 0.6849
[10/11 20:32:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.18	
[10/11 20:32:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[10/11 20:39:01 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 11.0302, average train loss: 0.6967
[10/11 20:39:45 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2297, average loss: 0.6827
[10/11 20:39:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 56.20	
[10/11 20:39:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[10/11 20:46:10 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9994, average train loss: 0.7178
[10/11 20:46:54 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.2078, average loss: 0.6904
[10/11 20:46:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.01	
[10/11 20:46:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[10/11 20:53:21 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0565, average train loss: 0.7238
[10/11 20:54:05 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.2291, average loss: 0.6925
[10/11 20:54:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 56.82	
[10/11 20:54:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[10/11 21:00:35 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.1136, average train loss: 0.7038
[10/11 21:01:19 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.2358, average loss: 0.6871
[10/11 21:01:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 58.47	
[10/11 21:01:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[10/11 21:07:47 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0791, average train loss: 0.7048
[10/11 21:08:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2304, average loss: 0.6784
[10/11 21:08:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 58.93	
[10/11 21:08:31 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[10/11 21:15:00 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.1120, average train loss: 0.7010
[10/11 21:15:45 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2155, average loss: 0.6824
[10/11 21:15:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.30	
[10/11 21:15:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[10/11 21:22:12 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0638, average train loss: 0.7110
[10/11 21:22:56 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2063, average loss: 0.6967
[10/11 21:22:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.57	
[10/11 21:22:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[10/11 21:29:23 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0568, average train loss: 0.6873
[10/11 21:30:08 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.2291, average loss: 0.6756
[10/11 21:30:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.23	
[10/11 21:30:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[10/11 21:36:34 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0379, average train loss: 0.6948
[10/11 21:37:18 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.2249, average loss: 0.6718
[10/11 21:37:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 60.41	
[10/11 21:37:18 visual_prompt]: Best epoch 12: best metric: -0.672
[10/11 21:37:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[10/11 21:43:45 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0569, average train loss: 0.7007
[10/11 21:44:29 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2200, average loss: 0.6826
[10/11 21:44:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.12	
[10/11 21:44:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[10/11 21:50:57 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0732, average train loss: 0.7045
[10/11 21:51:41 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.2139, average loss: 0.8296
[10/11 21:51:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.20	
[10/11 21:51:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[10/11 21:58:09 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0704, average train loss: 0.7073
[10/11 21:58:53 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.2250, average loss: 0.6750
[10/11 21:58:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 60.10	
[10/11 21:58:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[10/11 22:05:21 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0831, average train loss: 0.6902
[10/11 22:06:05 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.2220, average loss: 0.7417
[10/11 22:06:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.06	
[10/11 22:06:05 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[10/11 22:12:36 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.1501, average train loss: 0.6933
[10/11 22:13:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2326, average loss: 0.6888
[10/11 22:13:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.96	
[10/11 22:13:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[10/11 22:19:47 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0503, average train loss: 0.7091
[10/11 22:20:31 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.2091, average loss: 0.7357
[10/11 22:20:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.06	
[10/11 22:20:31 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[10/11 22:26:58 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0416, average train loss: 0.6907
[10/11 22:27:42 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.2255, average loss: 0.7020
[10/11 22:27:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 60.92	
[10/11 22:27:42 visual_prompt]: Stopping early.
[10/11 22:27:42 visual_prompt]: Rank of current process: 0. World size: 1
[10/11 22:27:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 22:27:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/11 22:27:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/11 22:27:42 visual_prompt]: Training with config:
[10/11 22:27:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/11 22:27:42 visual_prompt]: Loading training data...
[10/11 22:27:42 visual_prompt]: Constructing mammo-cbis dataset train...
[10/11 22:27:42 visual_prompt]: Loading validation data...
[10/11 22:27:42 visual_prompt]: Constructing mammo-cbis dataset val...
[10/11 22:27:43 visual_prompt]: Constructing models...
[10/11 22:27:45 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/11 22:27:45 visual_prompt]: tuned percent:0.536
[10/11 22:27:45 visual_prompt]: Device used for model: 0
[10/11 22:27:45 visual_prompt]: Setting up Evaluator...
[10/11 22:27:45 visual_prompt]: Setting up Trainer...
[10/11 22:27:45 visual_prompt]: 	Setting up the optimizer...
[10/11 22:27:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/11 22:34:12 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0573, average train loss: 1.4524
[10/11 22:34:57 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.2298, average loss: 1.4398
[10/11 22:34:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/11 22:34:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[10/11 22:41:24 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0639, average train loss: 0.8956
[10/11 22:42:08 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.2087, average loss: 0.6909
[10/11 22:42:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.44	
[10/11 22:42:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[10/11 22:48:35 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0423, average train loss: 0.7050
[10/11 22:49:20 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2216, average loss: 0.6849
[10/11 22:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.19	
[10/11 22:49:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[10/11 22:55:50 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.1402, average train loss: 0.6968
[10/11 22:56:34 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.2314, average loss: 0.6826
[10/11 22:56:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 56.19	
[10/11 22:56:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[10/11 23:03:03 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.1033, average train loss: 0.7181
[10/11 23:03:47 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.2288, average loss: 0.6903
[10/11 23:03:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.02	
[10/11 23:03:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[10/11 23:10:17 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.1234, average train loss: 0.7241
[10/11 23:11:01 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2422, average loss: 0.6935
[10/11 23:11:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 56.88	
[10/11 23:11:01 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[10/11 23:17:32 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.1663, average train loss: 0.7040
[10/11 23:18:16 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.2101, average loss: 0.6878
[10/11 23:18:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.46	
[10/11 23:18:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[10/11 23:24:44 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0927, average train loss: 0.7056
[10/11 23:25:29 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.2311, average loss: 0.6777
[10/11 23:25:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.10	
[10/11 23:25:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[10/11 23:32:00 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.1661, average train loss: 0.7014
[10/11 23:32:44 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.2137, average loss: 0.6821
[10/11 23:32:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.35	
[10/11 23:32:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[10/11 23:39:14 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.1272, average train loss: 0.7125
[10/11 23:39:59 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.2331, average loss: 0.6968
[10/11 23:39:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.66	
[10/11 23:39:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[10/11 23:46:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.1621, average train loss: 0.6883
[10/11 23:47:14 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.2260, average loss: 0.6756
[10/11 23:47:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.30	
[10/11 23:47:14 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[10/11 23:53:44 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.1284, average train loss: 0.6964
[10/11 23:54:29 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.2276, average loss: 0.6714
[10/11 23:54:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 60.70	
[10/11 23:54:29 visual_prompt]: Best epoch 12: best metric: -0.671
[10/11 23:54:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[10/12 00:00:58 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.1179, average train loss: 0.7044
[10/12 00:01:43 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.2440, average loss: 0.6812
[10/12 00:01:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.22	
[10/12 00:01:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[10/12 00:08:10 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0773, average train loss: 0.7079
[10/12 00:08:55 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.2316, average loss: 0.8508
[10/12 00:08:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.36	
[10/12 00:08:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[10/12 00:15:25 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.1208, average train loss: 0.7115
[10/12 00:16:09 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2094, average loss: 0.6723
[10/12 00:16:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 60.28	
[10/12 00:16:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[10/12 00:22:37 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0841, average train loss: 0.6937
[10/12 00:23:21 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.2292, average loss: 0.7475
[10/12 00:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.14	
[10/12 00:23:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[10/12 00:29:48 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0573, average train loss: 0.6957
[10/12 00:30:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2332, average loss: 0.6935
[10/12 00:30:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.70	
[10/12 00:30:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[10/12 00:37:03 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.1755, average train loss: 0.7113
[10/12 00:37:48 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.2319, average loss: 0.7307
[10/12 00:37:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.70	
[10/12 00:37:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[10/12 00:44:16 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.1009, average train loss: 0.6909
[10/12 00:45:01 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.2294, average loss: 0.6981
[10/12 00:45:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.53	
[10/12 00:45:01 visual_prompt]: Stopping early.
[10/12 00:45:01 visual_prompt]: Rank of current process: 0. World size: 1
[10/12 00:45:01 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/12 00:45:01 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/12 00:45:01 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/12 00:45:01 visual_prompt]: Training with config:
[10/12 00:45:01 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/12 00:45:01 visual_prompt]: Loading training data...
[10/12 00:45:01 visual_prompt]: Constructing mammo-cbis dataset train...
[10/12 00:45:01 visual_prompt]: Loading validation data...
[10/12 00:45:01 visual_prompt]: Constructing mammo-cbis dataset val...
[10/12 00:45:01 visual_prompt]: Constructing models...
[10/12 00:45:03 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/12 00:45:03 visual_prompt]: tuned percent:0.536
[10/12 00:45:04 visual_prompt]: Device used for model: 0
[10/12 00:45:04 visual_prompt]: Setting up Evaluator...
[10/12 00:45:04 visual_prompt]: Setting up Trainer...
[10/12 00:45:04 visual_prompt]: 	Setting up the optimizer...
[10/12 00:45:04 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/12 00:51:32 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0821, average train loss: 1.4524
[10/12 00:52:16 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2159, average loss: 1.4398
[10/12 00:52:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.06	
[10/12 00:52:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[10/12 00:58:46 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.1475, average train loss: 0.8956
[10/12 00:59:30 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2057, average loss: 0.6909
[10/12 00:59:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.44	
[10/12 00:59:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[10/12 01:06:03 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.2223, average train loss: 0.7051
[10/12 01:06:48 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.2133, average loss: 0.6849
[10/12 01:06:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.20	
[10/12 01:06:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[10/12 01:13:18 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.1458, average train loss: 0.6968
[10/12 01:14:02 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.2253, average loss: 0.6826
[10/12 01:14:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 56.20	
[10/12 01:14:02 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[10/12 01:20:30 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0782, average train loss: 0.7181
[10/12 01:21:14 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2380, average loss: 0.6903
[10/12 01:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.03	
[10/12 01:21:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[10/12 01:27:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0946, average train loss: 0.7241
[10/12 01:28:27 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.2041, average loss: 0.6936
[10/12 01:28:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 56.89	
[10/12 01:28:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[10/12 01:34:56 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0992, average train loss: 0.7040
[10/12 01:35:40 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.2159, average loss: 0.6878
[10/12 01:35:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.42	
[10/12 01:35:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[10/12 01:42:08 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0566, average train loss: 0.7056
[10/12 01:42:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2043, average loss: 0.6776
[10/12 01:42:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.13	
[10/12 01:42:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[10/12 01:49:23 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.1741, average train loss: 0.7015
[10/12 01:50:07 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.2039, average loss: 0.6821
[10/12 01:50:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.36	
[10/12 01:50:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[10/12 01:56:37 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.1414, average train loss: 0.7127
[10/12 01:57:23 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.2258, average loss: 0.6969
[10/12 01:57:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.68	
[10/12 01:57:23 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[10/12 02:03:53 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.1329, average train loss: 0.6884
[10/12 02:04:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2147, average loss: 0.6756
[10/12 02:04:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.26	
[10/12 02:04:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[10/12 02:11:06 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.1111, average train loss: 0.6964
[10/12 02:11:51 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2437, average loss: 0.6715
[10/12 02:11:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.68	
[10/12 02:11:51 visual_prompt]: Best epoch 12: best metric: -0.672
[10/12 02:11:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[10/12 02:18:26 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.2998, average train loss: 0.7045
[10/12 02:19:11 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2338, average loss: 0.6804
[10/12 02:19:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.12	
[10/12 02:19:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[10/12 02:25:47 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.3153, average train loss: 0.7079
[10/12 02:26:35 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.2082, average loss: 0.8504
[10/12 02:26:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.28	
[10/12 02:26:35 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[10/12 02:33:03 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0944, average train loss: 0.7117
[10/12 02:33:48 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2293, average loss: 0.6726
[10/12 02:33:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 60.22	
[10/12 02:33:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[10/12 02:40:18 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.1458, average train loss: 0.6940
[10/12 02:41:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2310, average loss: 0.7476
[10/12 02:41:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.98	
[10/12 02:41:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[10/12 02:47:33 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.1423, average train loss: 0.6955
[10/12 02:48:17 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.2049, average loss: 0.6935
[10/12 02:48:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.51	
[10/12 02:48:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[10/12 02:54:44 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0662, average train loss: 0.7114
[10/12 02:55:28 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2333, average loss: 0.7308
[10/12 02:55:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.60	
[10/12 02:55:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[10/12 03:01:55 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0521, average train loss: 0.6916
[10/12 03:02:40 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2069, average loss: 0.6981
[10/12 03:02:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.23	
[10/12 03:02:40 visual_prompt]: Stopping early.
[10/12 03:02:41 visual_prompt]: Rank of current process: 0. World size: 1
[10/12 03:02:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/12 03:02:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/12 03:02:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/12 03:02:41 visual_prompt]: Training with config:
[10/12 03:02:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/test/seed9805/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/12 03:02:42 visual_prompt]: Loading training data...
[10/12 03:02:42 visual_prompt]: Constructing mammo-cbis dataset train...
[10/12 03:02:42 visual_prompt]: Loading validation data...
[10/12 03:02:42 visual_prompt]: Constructing mammo-cbis dataset val...
[10/12 03:02:42 visual_prompt]: Loading test data...
[10/12 03:02:42 visual_prompt]: Constructing mammo-cbis dataset test...
[10/12 03:02:42 visual_prompt]: Constructing models...
[10/12 03:02:44 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/12 03:02:44 visual_prompt]: tuned percent:0.536
[10/12 03:02:44 visual_prompt]: Device used for model: 0
[10/12 03:02:44 visual_prompt]: Setting up Evaluator...
[10/12 03:02:44 visual_prompt]: Setting up Trainer...
[10/12 03:02:44 visual_prompt]: 	Setting up the optimizer...
[10/12 03:02:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/12 03:09:15 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.1453, average train loss: 0.9170
[10/12 03:09:59 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2169, average loss: 0.8622
[10/12 03:09:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 43.50	rocauc: 45.47	
[10/12 03:12:09 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2385, average loss: 0.8712
[10/12 03:12:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.86	rocauc: 48.56	
[10/12 03:12:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/12 03:18:40 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.1500, average train loss: 1.4532
[10/12 03:19:24 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.2311, average loss: 0.6997
[10/12 03:19:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.26	
[10/12 03:21:20 visual_prompt]: Inference (test):avg data time: 4.00e-05, avg batch time: 0.2253, average loss: 0.6783
[10/12 03:21:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 51.11	
[10/12 03:21:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/12 03:27:49 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.1078, average train loss: 0.7054
[10/12 03:28:33 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2216, average loss: 0.6913
[10/12 03:28:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 49.64	
[10/12 03:30:27 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2297, average loss: 0.6873
[10/12 03:30:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.05	rocauc: 53.09	
[10/12 03:30:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/12 03:36:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.1238, average train loss: 0.7095
[10/12 03:37:41 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.2351, average loss: 0.7012
[10/12 03:37:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 51.68	
[10/12 03:39:36 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2297, average loss: 0.7054
[10/12 03:39:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.78	rocauc: 55.33	
[10/12 03:39:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/12 03:46:06 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.1294, average train loss: 0.7069
[10/12 03:46:50 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.2317, average loss: 0.7053
[10/12 03:46:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 54.37	
[10/12 03:48:45 visual_prompt]: Inference (test):avg data time: 3.79e-05, avg batch time: 0.2329, average loss: 0.7120
[10/12 03:48:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 57.32	
[10/12 03:48:45 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/12 03:55:15 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.1402, average train loss: 0.7103
[10/12 03:56:00 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2375, average loss: 0.6870
[10/12 03:56:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[10/12 03:57:55 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2385, average loss: 0.6700
[10/12 03:57:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.58	
[10/12 03:57:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/12 04:04:27 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.1766, average train loss: 0.7189
[10/12 04:05:11 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.2060, average loss: 0.7252
[10/12 04:05:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.36	
[10/12 04:07:07 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2297, average loss: 0.7397
[10/12 04:07:07 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 60.89	
[10/12 04:07:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/12 04:13:37 visual_prompt]: Epoch 8 / 100: avg data time: 1.07e+01, avg batch time: 11.1358, average train loss: 0.7143
[10/12 04:14:22 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.2319, average loss: 0.6957
[10/12 04:14:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 60.81	
[10/12 04:16:17 visual_prompt]: Inference (test):avg data time: 3.88e-05, avg batch time: 0.2307, average loss: 0.7016
[10/12 04:16:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.43	rocauc: 63.07	
[10/12 04:16:17 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/12 04:22:46 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.1128, average train loss: 0.7224
[10/12 04:23:31 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.2320, average loss: 0.7082
[10/12 04:23:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[10/12 04:25:26 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2258, average loss: 0.6788
[10/12 04:25:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.04	
[10/12 04:25:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/12 04:31:54 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0993, average train loss: 0.7166
[10/12 04:32:38 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.2074, average loss: 0.7208
[10/12 04:32:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.20	
[10/12 04:34:34 visual_prompt]: Inference (test):avg data time: 3.91e-05, avg batch time: 0.2381, average loss: 0.7372
[10/12 04:34:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 62.33	
[10/12 04:34:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/12 04:41:04 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.1598, average train loss: 0.7190
[10/12 04:41:49 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.2303, average loss: 0.6843
[10/12 04:41:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.93	
[10/12 04:43:44 visual_prompt]: Inference (test):avg data time: 4.11e-05, avg batch time: 0.2300, average loss: 0.6850
[10/12 04:43:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.29	rocauc: 63.49	
[10/12 04:43:44 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/12 04:50:15 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.1506, average train loss: 0.7098
[10/12 04:50:59 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.2337, average loss: 0.6984
[10/12 04:50:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.83	
[10/12 04:52:54 visual_prompt]: Inference (test):avg data time: 4.12e-05, avg batch time: 0.2324, average loss: 0.6686
[10/12 04:52:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 62.96	
[10/12 04:52:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/12 04:59:24 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.1499, average train loss: 0.7204
[10/12 05:00:09 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.2078, average loss: 0.6815
[10/12 05:00:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.33	
[10/12 05:02:04 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2284, average loss: 0.6793
[10/12 05:02:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 63.10	
[10/12 05:02:04 visual_prompt]: Best epoch 13: best metric: -0.682
[10/12 05:02:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/12 05:08:35 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.1612, average train loss: 0.7235
[10/12 05:09:20 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.2289, average loss: 0.6837
[10/12 05:09:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.33	
[10/12 05:11:16 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.2328, average loss: 0.6857
[10/12 05:11:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.83	rocauc: 63.08	
[10/12 05:11:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/12 05:17:47 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.1679, average train loss: 0.6951
[10/12 05:18:32 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2333, average loss: 0.6807
[10/12 05:18:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.79	
[10/12 05:20:28 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2339, average loss: 0.6784
[10/12 05:20:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.91	rocauc: 62.45	
[10/12 05:20:28 visual_prompt]: Best epoch 15: best metric: -0.681
[10/12 05:20:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/12 05:27:04 visual_prompt]: Epoch 16 / 100: avg data time: 1.09e+01, avg batch time: 11.3022, average train loss: 0.6914
[10/12 05:27:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2066, average loss: 0.6742
[10/12 05:27:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.60	
[10/12 05:29:43 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2313, average loss: 0.6546
[10/12 05:29:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.84	rocauc: 62.73	
[10/12 05:29:43 visual_prompt]: Best epoch 16: best metric: -0.674
[10/12 05:29:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/12 05:36:11 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0888, average train loss: 0.6754
[10/12 05:36:56 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.2046, average loss: 0.7175
[10/12 05:36:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 60.21	
[10/12 05:38:54 visual_prompt]: Inference (test):avg data time: 4.12e-05, avg batch time: 0.2180, average loss: 0.7328
[10/12 05:38:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.84	rocauc: 62.67	
[10/12 05:38:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/12 05:45:25 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.1854, average train loss: 0.6962
[10/12 05:46:09 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2283, average loss: 0.6891
[10/12 05:46:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.47	
[10/12 05:48:04 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2292, average loss: 0.6616
[10/12 05:48:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 62.14	
[10/12 05:48:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/12 05:54:34 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.1243, average train loss: 0.6925
[10/12 05:55:18 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2091, average loss: 0.6978
[10/12 05:55:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 61.05	
[10/12 05:57:13 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2301, average loss: 0.7105
[10/12 05:57:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 52.56	rocauc: 62.63	
[10/12 05:57:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/12 06:03:41 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0920, average train loss: 0.6946
[10/12 06:04:26 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.2161, average loss: 0.7211
[10/12 06:04:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.62	
[10/12 06:06:21 visual_prompt]: Inference (test):avg data time: 4.04e-05, avg batch time: 0.2318, average loss: 0.6808
[10/12 06:06:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.91	rocauc: 63.30	
[10/12 06:06:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/12 06:12:52 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.1673, average train loss: 0.6800
[10/12 06:13:36 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.2310, average loss: 0.6734
[10/12 06:13:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 60.14	
[10/12 06:15:32 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2333, average loss: 0.6562
[10/12 06:15:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.24	rocauc: 62.22	
[10/12 06:15:32 visual_prompt]: Best epoch 21: best metric: -0.673
[10/12 06:15:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/12 06:22:06 visual_prompt]: Epoch 22 / 100: avg data time: 1.08e+01, avg batch time: 11.2513, average train loss: 0.6812
[10/12 06:22:50 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.2084, average loss: 0.6687
[10/12 06:22:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 61.09	
[10/12 06:24:48 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2342, average loss: 0.6537
[10/12 06:24:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 62.98	
[10/12 06:24:48 visual_prompt]: Best epoch 22: best metric: -0.669
[10/12 06:24:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/12 06:31:19 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.1602, average train loss: 0.6750
[10/12 06:32:04 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.2109, average loss: 0.6972
[10/12 06:32:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 60.95	
[10/12 06:34:01 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2293, average loss: 0.7107
[10/12 06:34:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 54.57	rocauc: 63.01	
[10/12 06:34:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/12 06:40:35 visual_prompt]: Epoch 24 / 100: avg data time: 1.08e+01, avg batch time: 11.2559, average train loss: 0.6921
[10/12 06:41:21 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2261, average loss: 0.6704
[10/12 06:41:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.53	
[10/12 06:43:15 visual_prompt]: Inference (test):avg data time: 4.36e-05, avg batch time: 0.2249, average loss: 0.6658
[10/12 06:43:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 63.54	
[10/12 06:43:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/12 06:49:44 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 11.1028, average train loss: 0.6815
[10/12 06:50:28 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.2062, average loss: 0.6858
[10/12 06:50:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 60.95	
[10/12 06:52:26 visual_prompt]: Inference (test):avg data time: 3.77e-05, avg batch time: 0.2286, average loss: 0.6900
[10/12 06:52:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.45	rocauc: 63.53	
[10/12 06:52:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/12 06:58:59 visual_prompt]: Epoch 26 / 100: avg data time: 1.08e+01, avg batch time: 11.2295, average train loss: 0.6748
[10/12 06:59:43 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2039, average loss: 0.6683
[10/12 06:59:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.25	
[10/12 07:01:40 visual_prompt]: Inference (test):avg data time: 3.87e-05, avg batch time: 0.2377, average loss: 0.6639
[10/12 07:01:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 63.35	
[10/12 07:01:40 visual_prompt]: Best epoch 26: best metric: -0.668
[10/12 07:01:40 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/12 07:08:12 visual_prompt]: Epoch 27 / 100: avg data time: 1.07e+01, avg batch time: 11.1974, average train loss: 0.6636
[10/12 07:08:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2282, average loss: 0.6693
[10/12 07:08:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.90	
[10/12 07:10:52 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2251, average loss: 0.6603
[10/12 07:10:52 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.02	rocauc: 63.20	
[10/12 07:10:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/12 07:17:20 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 11.0920, average train loss: 0.6706
[10/12 07:18:05 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.2174, average loss: 0.6893
[10/12 07:18:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 61.46	
[10/12 07:20:00 visual_prompt]: Inference (test):avg data time: 3.81e-05, avg batch time: 0.2242, average loss: 0.7056
[10/12 07:20:00 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.63	rocauc: 61.65	
[10/12 07:20:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/12 07:26:29 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.1126, average train loss: 0.6646
[10/12 07:27:14 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.2356, average loss: 0.6715
[10/12 07:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 62.12	
[10/12 07:29:08 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2167, average loss: 0.6724
[10/12 07:29:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.84	rocauc: 62.78	
[10/12 07:29:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[10/12 07:35:39 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.1444, average train loss: 0.6878
[10/12 07:36:23 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2363, average loss: 0.6767
[10/12 07:36:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 62.60	
[10/12 07:38:20 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2358, average loss: 0.6829
[10/12 07:38:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 64.11	
[10/12 07:38:20 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[10/12 07:44:52 visual_prompt]: Epoch 31 / 100: avg data time: 1.08e+01, avg batch time: 11.2085, average train loss: 0.6826
[10/12 07:45:39 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2319, average loss: 0.6995
[10/12 07:45:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 62.59	
[10/12 07:47:34 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2257, average loss: 0.6630
[10/12 07:47:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.71	rocauc: 63.39	
[10/12 07:47:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[10/12 07:54:08 visual_prompt]: Epoch 32 / 100: avg data time: 1.08e+01, avg batch time: 11.2435, average train loss: 0.6751
[10/12 07:54:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2270, average loss: 0.6654
[10/12 07:54:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.84	
[10/12 07:56:51 visual_prompt]: Inference (test):avg data time: 4.04e-05, avg batch time: 0.2269, average loss: 0.6617
[10/12 07:56:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 64.04	
[10/12 07:56:51 visual_prompt]: Best epoch 32: best metric: -0.665
[10/12 07:56:51 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[10/12 08:03:24 visual_prompt]: Epoch 33 / 100: avg data time: 1.08e+01, avg batch time: 11.2517, average train loss: 0.6623
[10/12 08:04:09 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.2169, average loss: 0.6647
[10/12 08:04:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 62.40	
[10/12 08:06:05 visual_prompt]: Inference (test):avg data time: 4.02e-05, avg batch time: 0.2307, average loss: 0.6501
[10/12 08:06:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.02	rocauc: 63.58	
[10/12 08:06:05 visual_prompt]: Best epoch 33: best metric: -0.665
[10/12 08:06:05 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[10/12 08:12:37 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.2073, average train loss: 0.6615
[10/12 08:13:22 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2275, average loss: 0.6664
[10/12 08:13:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 61.77	
[10/12 08:15:21 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2286, average loss: 0.6577
[10/12 08:15:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 63.50	
[10/12 08:15:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[10/12 08:21:58 visual_prompt]: Epoch 35 / 100: avg data time: 1.09e+01, avg batch time: 11.3353, average train loss: 0.6816
[10/12 08:22:43 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.2044, average loss: 0.6751
[10/12 08:22:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.90	
[10/12 08:24:40 visual_prompt]: Inference (test):avg data time: 3.89e-05, avg batch time: 0.2336, average loss: 0.6788
[10/12 08:24:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 63.30	
[10/12 08:24:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[10/12 08:31:16 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e+01, avg batch time: 11.3305, average train loss: 0.6676
[10/12 08:32:01 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.2074, average loss: 0.6719
[10/12 08:32:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 62.74	
[10/12 08:33:56 visual_prompt]: Inference (test):avg data time: 4.19e-05, avg batch time: 0.2193, average loss: 0.6464
[10/12 08:33:56 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.26	rocauc: 64.44	
[10/12 08:33:56 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[10/12 08:40:27 visual_prompt]: Epoch 37 / 100: avg data time: 1.07e+01, avg batch time: 11.1581, average train loss: 0.6826
[10/12 08:41:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2099, average loss: 0.7102
[10/12 08:41:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 63.08	
[10/12 08:43:07 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2353, average loss: 0.6656
[10/12 08:43:07 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 64.59	
[10/12 08:43:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[10/12 08:49:36 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 11.1234, average train loss: 0.6769
[10/12 08:50:20 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2064, average loss: 0.6660
[10/12 08:50:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.70	
[10/12 08:52:15 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2282, average loss: 0.6553
[10/12 08:52:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 64.74	
[10/12 08:52:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[10/12 08:58:44 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 11.0966, average train loss: 0.6617
[10/12 08:59:28 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.2234, average loss: 0.7120
[10/12 08:59:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 63.09	
[10/12 09:01:24 visual_prompt]: Inference (test):avg data time: 4.21e-05, avg batch time: 0.2223, average loss: 0.7283
[10/12 09:01:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.28	rocauc: 64.46	
[10/12 09:01:24 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[10/12 09:07:59 visual_prompt]: Epoch 40 / 100: avg data time: 1.08e+01, avg batch time: 11.2973, average train loss: 0.6589
[10/12 09:08:44 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.2288, average loss: 0.6762
[10/12 09:08:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 63.94	
[10/12 09:10:40 visual_prompt]: Inference (test):avg data time: 3.91e-05, avg batch time: 0.2345, average loss: 0.6737
[10/12 09:10:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 65.46	
[10/12 09:10:40 visual_prompt]: Stopping early.
[10/12 09:10:41 visual_prompt]: Rank of current process: 0. World size: 1
[10/12 09:10:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/12 09:10:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/12 09:10:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/12 09:10:41 visual_prompt]: Training with config:
[10/12 09:10:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/test/seed875/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 875, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/12 09:10:41 visual_prompt]: Loading training data...
[10/12 09:10:41 visual_prompt]: Constructing mammo-cbis dataset train...
[10/12 09:10:41 visual_prompt]: Loading validation data...
[10/12 09:10:41 visual_prompt]: Constructing mammo-cbis dataset val...
[10/12 09:10:41 visual_prompt]: Loading test data...
[10/12 09:10:41 visual_prompt]: Constructing mammo-cbis dataset test...
[10/12 09:10:41 visual_prompt]: Constructing models...
[10/12 09:10:43 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/12 09:10:43 visual_prompt]: tuned percent:0.536
[10/12 09:10:43 visual_prompt]: Device used for model: 0
[10/12 09:10:43 visual_prompt]: Setting up Evaluator...
[10/12 09:10:43 visual_prompt]: Setting up Trainer...
[10/12 09:10:43 visual_prompt]: 	Setting up the optimizer...
[10/12 09:10:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/12 09:17:15 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.1712, average train loss: 0.8583
[10/12 09:17:59 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.2384, average loss: 0.7941
[10/12 09:17:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.02	
[10/12 09:19:54 visual_prompt]: Inference (test):avg data time: 3.81e-05, avg batch time: 0.2306, average loss: 0.7629
[10/12 09:19:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.91	rocauc: 50.83	
[10/12 09:19:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/12 09:26:27 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.2150, average train loss: 0.8758
[10/12 09:27:11 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2280, average loss: 0.6855
[10/12 09:27:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 54.48	
[10/12 09:29:07 visual_prompt]: Inference (test):avg data time: 4.34e-05, avg batch time: 0.2369, average loss: 0.6789
[10/12 09:29:07 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 56.16	
[10/12 09:29:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/12 09:35:38 visual_prompt]: Epoch 3 / 100: avg data time: 1.07e+01, avg batch time: 11.1665, average train loss: 0.7085
[10/12 09:36:23 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.2282, average loss: 0.6874
[10/12 09:36:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 56.87	
[10/12 09:38:18 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2245, average loss: 0.6909
[10/12 09:38:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 50.70	rocauc: 55.25	
[10/12 09:38:18 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/12 09:44:50 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.1950, average train loss: 0.7072
[10/12 09:45:35 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.2251, average loss: 0.7309
[10/12 09:45:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.94	
[10/12 09:47:31 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2285, average loss: 0.6968
[10/12 09:47:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 57.60	
[10/12 09:47:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/12 09:54:02 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.1842, average train loss: 0.7128
[10/12 09:54:47 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.2147, average loss: 0.6798
[10/12 09:54:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 58.24	
[10/12 09:56:52 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2327, average loss: 0.6783
[10/12 09:56:52 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.74	rocauc: 57.74	
[10/12 09:56:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/12 10:03:37 visual_prompt]: Epoch 6 / 100: avg data time: 1.11e+01, avg batch time: 11.5635, average train loss: 0.7040
[10/12 10:04:31 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.2358, average loss: 0.8105
[10/12 10:04:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.57	
[10/12 10:06:27 visual_prompt]: Inference (test):avg data time: 3.95e-05, avg batch time: 0.2278, average loss: 0.8464
[10/12 10:06:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 58.15	
[10/12 10:06:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/12 10:12:58 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.1593, average train loss: 0.6976
[10/12 10:13:53 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2242, average loss: 0.6746
[10/12 10:13:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 58.73	
[10/12 10:15:49 visual_prompt]: Inference (test):avg data time: 4.22e-05, avg batch time: 0.2159, average loss: 0.6658
[10/12 10:15:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.84	rocauc: 59.27	
[10/12 10:15:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/12 10:22:28 visual_prompt]: Epoch 8 / 100: avg data time: 1.09e+01, avg batch time: 11.3946, average train loss: 0.7104
[10/12 10:23:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.2247, average loss: 0.6886
[10/12 10:23:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.33	
[10/12 10:25:08 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2332, average loss: 0.6662
[10/12 10:25:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 59.29	
[10/12 10:25:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/12 10:31:50 visual_prompt]: Epoch 9 / 100: avg data time: 1.10e+01, avg batch time: 11.4876, average train loss: 0.6940
[10/12 10:32:36 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2100, average loss: 0.6750
[10/12 10:32:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.97	
[10/12 10:34:32 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2324, average loss: 0.6605
[10/12 10:34:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 60.62	
[10/12 10:34:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/12 10:41:08 visual_prompt]: Epoch 10 / 100: avg data time: 1.09e+01, avg batch time: 11.3240, average train loss: 0.6928
[10/12 10:41:53 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.2306, average loss: 0.6942
[10/12 10:41:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 59.11	
[10/12 10:43:50 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.2312, average loss: 0.6683
[10/12 10:43:50 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 59.89	
[10/12 10:43:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/12 10:50:33 visual_prompt]: Epoch 11 / 100: avg data time: 1.10e+01, avg batch time: 11.4972, average train loss: 0.7026
[10/12 10:51:17 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.2304, average loss: 0.6856
[10/12 10:51:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.11	
[10/12 10:53:16 visual_prompt]: Inference (test):avg data time: 3.94e-05, avg batch time: 0.2325, average loss: 0.6917
[10/12 10:53:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.12	rocauc: 59.83	
[10/12 10:53:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/12 10:59:45 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.1042, average train loss: 0.7111
[10/12 11:00:29 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2062, average loss: 0.7384
[10/12 11:00:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 59.09	
[10/12 11:02:25 visual_prompt]: Inference (test):avg data time: 4.18e-05, avg batch time: 0.2160, average loss: 0.7620
[10/12 11:02:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 43.57	rocauc: 60.30	
[10/12 11:02:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/12 11:08:54 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0987, average train loss: 0.7040
[10/12 11:09:38 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.2362, average loss: 0.6788
[10/12 11:09:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 60.03	
[10/12 11:11:33 visual_prompt]: Inference (test):avg data time: 4.29e-05, avg batch time: 0.2318, average loss: 0.6815
[10/12 11:11:33 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 61.02	
[10/12 11:11:33 visual_prompt]: Best epoch 13: best metric: -0.679
[10/12 11:11:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/12 11:18:01 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0676, average train loss: 0.6852
[10/12 11:18:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2069, average loss: 0.7052
[10/12 11:18:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 61.63	
[10/12 11:20:40 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2302, average loss: 0.7248
[10/12 11:20:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.61	rocauc: 62.07	
[10/12 11:20:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/12 11:27:07 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 11.0698, average train loss: 0.7263
[10/12 11:27:52 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.2364, average loss: 0.7663
[10/12 11:27:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.71	
[10/12 11:29:47 visual_prompt]: Inference (test):avg data time: 3.95e-05, avg batch time: 0.2271, average loss: 0.8020
[10/12 11:29:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 42.64	rocauc: 61.16	
[10/12 11:29:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/12 11:36:15 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0928, average train loss: 0.7286
[10/12 11:37:00 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.2290, average loss: 0.6955
[10/12 11:37:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 61.71	
[10/12 11:38:55 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2249, average loss: 0.7124
[10/12 11:38:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.80	rocauc: 62.27	
[10/12 11:38:55 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/12 11:45:23 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0930, average train loss: 0.6869
[10/12 11:46:08 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.2362, average loss: 0.6677
[10/12 11:46:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.70	
[10/12 11:48:04 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2265, average loss: 0.6576
[10/12 11:48:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 62.06	
[10/12 11:48:04 visual_prompt]: Best epoch 17: best metric: -0.668
[10/12 11:48:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/12 11:54:35 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.1700, average train loss: 0.6960
[10/12 11:55:20 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.2231, average loss: 0.7057
[10/12 11:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 60.26	
[10/12 11:57:16 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2260, average loss: 0.7212
[10/12 11:57:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 52.71	rocauc: 61.51	
[10/12 11:57:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/12 12:03:47 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.1669, average train loss: 0.6961
[10/12 12:04:31 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.2170, average loss: 0.6880
[10/12 12:04:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 60.54	
[10/12 12:06:27 visual_prompt]: Inference (test):avg data time: 4.02e-05, avg batch time: 0.2371, average loss: 0.6937
[10/12 12:06:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.83	rocauc: 62.25	
[10/12 12:06:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/12 12:12:59 visual_prompt]: Epoch 20 / 100: avg data time: 1.07e+01, avg batch time: 11.1832, average train loss: 0.6693
[10/12 12:13:44 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.2321, average loss: 0.6781
[10/12 12:13:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.57	
[10/12 12:15:40 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2300, average loss: 0.6835
[10/12 12:15:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 62.46	
[10/12 12:15:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/12 12:22:08 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.0901, average train loss: 0.6679
[10/12 12:22:53 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.2443, average loss: 0.6624
[10/12 12:22:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.35	
[10/12 12:24:47 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2253, average loss: 0.6563
[10/12 12:24:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 62.53	
[10/12 12:24:47 visual_prompt]: Best epoch 21: best metric: -0.662
[10/12 12:24:47 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/12 12:31:15 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 11.0725, average train loss: 0.6776
[10/12 12:32:00 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.2083, average loss: 0.6704
[10/12 12:32:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.15	
[10/12 12:33:55 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2285, average loss: 0.6539
[10/12 12:33:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.16	rocauc: 62.56	
[10/12 12:33:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/12 12:40:23 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 11.0880, average train loss: 0.6740
[10/12 12:41:07 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2279, average loss: 0.7165
[10/12 12:41:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 60.15	
[10/12 12:43:03 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2234, average loss: 0.7305
[10/12 12:43:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.47	rocauc: 62.25	
[10/12 12:43:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/12 12:49:32 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.1039, average train loss: 0.6974
[10/12 12:50:16 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.2251, average loss: 0.6772
[10/12 12:50:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 62.34	
[10/12 12:52:11 visual_prompt]: Inference (test):avg data time: 4.11e-05, avg batch time: 0.2295, average loss: 0.6852
[10/12 12:52:11 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.60	rocauc: 62.87	
[10/12 12:52:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/12 12:58:39 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 11.0707, average train loss: 0.6886
[10/12 12:59:23 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.2170, average loss: 0.6671
[10/12 12:59:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 61.06	
[10/12 13:01:18 visual_prompt]: Inference (test):avg data time: 3.87e-05, avg batch time: 0.2298, average loss: 0.6532
[10/12 13:01:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.24	rocauc: 62.58	
[10/12 13:01:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/12 13:07:44 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 11.0422, average train loss: 0.6841
[10/12 13:08:29 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.2159, average loss: 0.6761
[10/12 13:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.56	
[10/12 13:10:23 visual_prompt]: Inference (test):avg data time: 4.06e-05, avg batch time: 0.2313, average loss: 0.6515
[10/12 13:10:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 63.51	
[10/12 13:10:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/12 13:16:50 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 11.0365, average train loss: 0.6692
[10/12 13:17:34 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.2262, average loss: 0.6565
[10/12 13:17:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 64.54	
[10/12 13:19:28 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2263, average loss: 0.6667
[10/12 13:19:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.78	rocauc: 62.41	
[10/12 13:19:28 visual_prompt]: Best epoch 27: best metric: -0.656
[10/12 13:19:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/12 13:25:57 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 11.0960, average train loss: 0.6742
[10/12 13:26:41 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.2359, average loss: 0.6644
[10/12 13:26:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.18	
[10/12 13:28:36 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2265, average loss: 0.6528
[10/12 13:28:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 62.16	
[10/12 13:28:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/12 13:35:04 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0892, average train loss: 0.6799
[10/12 13:35:48 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.2258, average loss: 0.6611
[10/12 13:35:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.42	
[10/12 13:37:43 visual_prompt]: Inference (test):avg data time: 4.06e-05, avg batch time: 0.2226, average loss: 0.6493
[10/12 13:37:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 62.79	
[10/12 13:37:43 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[10/12 13:44:09 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 11.0337, average train loss: 0.6724
[10/12 13:44:53 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.2158, average loss: 0.6521
[10/12 13:44:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.97	
[10/12 13:46:47 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2313, average loss: 0.6510
[10/12 13:46:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.95	rocauc: 62.32	
[10/12 13:46:47 visual_prompt]: Best epoch 30: best metric: -0.652
[10/12 13:46:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[10/12 13:53:12 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.9900, average train loss: 0.6695
[10/12 13:53:56 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.2185, average loss: 0.6707
[10/12 13:53:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.21	
[10/12 13:55:51 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2296, average loss: 0.6734
[10/12 13:55:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.09	rocauc: 62.84	
[10/12 13:55:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[10/12 14:02:19 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0762, average train loss: 0.6898
[10/12 14:03:03 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.2164, average loss: 0.6575
[10/12 14:03:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 63.96	
[10/12 14:04:58 visual_prompt]: Inference (test):avg data time: 4.04e-05, avg batch time: 0.2257, average loss: 0.6711
[10/12 14:04:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.78	rocauc: 62.30	
[10/12 14:04:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[10/12 14:11:28 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.1172, average train loss: 0.6832
[10/12 14:12:12 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.2248, average loss: 0.6950
[10/12 14:12:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.17	
[10/12 14:14:07 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2245, average loss: 0.6615
[10/12 14:14:07 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 62.71	
[10/12 14:14:07 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[10/12 14:20:36 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 11.1125, average train loss: 0.6704
[10/12 14:21:20 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.2160, average loss: 0.6648
[10/12 14:21:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.47	
[10/12 14:23:17 visual_prompt]: Inference (test):avg data time: 4.24e-05, avg batch time: 0.2286, average loss: 0.6521
[10/12 14:23:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 63.50	
[10/12 14:23:17 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[10/12 14:29:45 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 11.0860, average train loss: 0.6581
[10/12 14:30:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2322, average loss: 0.7972
[10/12 14:30:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.31	
[10/12 14:32:28 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2365, average loss: 0.7371
[10/12 14:32:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.71	rocauc: 61.67	
[10/12 14:32:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[10/12 14:38:56 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 11.0723, average train loss: 0.6786
[10/12 14:39:40 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2288, average loss: 0.6686
[10/12 14:39:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 64.43	
[10/12 14:41:35 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2249, average loss: 0.6704
[10/12 14:41:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 62.17	
[10/12 14:41:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[10/12 14:48:03 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 11.0743, average train loss: 0.6547
[10/12 14:48:47 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.2037, average loss: 0.6613
[10/12 14:48:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.63	
[10/12 14:50:42 visual_prompt]: Inference (test):avg data time: 4.10e-05, avg batch time: 0.2354, average loss: 0.6585
[10/12 14:50:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.26	rocauc: 62.06	
[10/12 14:50:42 visual_prompt]: Stopping early.
[10/12 14:50:42 visual_prompt]: Rank of current process: 0. World size: 1
[10/12 14:50:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/12 14:50:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/12 14:50:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/12 14:50:42 visual_prompt]: Training with config:
[10/12 14:50:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/test/seed4536/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 4536, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/12 14:50:42 visual_prompt]: Loading training data...
[10/12 14:50:42 visual_prompt]: Constructing mammo-cbis dataset train...
[10/12 14:50:42 visual_prompt]: Loading validation data...
[10/12 14:50:42 visual_prompt]: Constructing mammo-cbis dataset val...
[10/12 14:50:42 visual_prompt]: Loading test data...
[10/12 14:50:42 visual_prompt]: Constructing mammo-cbis dataset test...
[10/12 14:50:42 visual_prompt]: Constructing models...
[10/12 14:50:45 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/12 14:50:45 visual_prompt]: tuned percent:0.536
[10/12 14:50:45 visual_prompt]: Device used for model: 0
[10/12 14:50:45 visual_prompt]: Setting up Evaluator...
[10/12 14:50:45 visual_prompt]: Setting up Trainer...
[10/12 14:50:45 visual_prompt]: 	Setting up the optimizer...
[10/12 14:50:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/12 14:57:12 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 11.0523, average train loss: 1.4610
[10/12 14:57:56 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.2155, average loss: 1.4375
[10/12 14:57:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.72	
[10/12 14:59:50 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.2355, average loss: 1.3184
[10/12 14:59:50 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 48.24	
[10/12 14:59:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/12 15:06:19 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.1072, average train loss: 1.3891
[10/12 15:07:04 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.2388, average loss: 0.6955
[10/12 15:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 49.74	
[10/12 15:08:58 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2255, average loss: 0.6966
[10/12 15:08:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 47.91	rocauc: 49.02	
[10/12 15:08:58 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/12 15:15:25 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0585, average train loss: 0.7294
[10/12 15:16:09 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2346, average loss: 0.6885
[10/12 15:16:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.47	
[10/12 15:18:04 visual_prompt]: Inference (test):avg data time: 4.24e-05, avg batch time: 0.2345, average loss: 0.6793
[10/12 15:18:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 50.58	
[10/12 15:18:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/12 15:24:34 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.1454, average train loss: 0.7081
[10/12 15:25:19 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.2127, average loss: 0.7012
[10/12 15:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 53.58	
[10/12 15:27:14 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2338, average loss: 0.7085
[10/12 15:27:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 54.13	
[10/12 15:27:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/12 15:33:41 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0644, average train loss: 0.7029
[10/12 15:34:25 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2145, average loss: 0.6852
[10/12 15:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 54.37	
[10/12 15:36:19 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2284, average loss: 0.6803
[10/12 15:36:19 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 54.62	
[10/12 15:36:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/12 15:42:51 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.1900, average train loss: 0.7260
[10/12 15:43:35 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.2251, average loss: 0.7655
[10/12 15:43:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.58	
[10/12 15:45:29 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.2330, average loss: 0.7214
[10/12 15:45:29 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 54.44	
[10/12 15:45:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/12 15:51:56 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0471, average train loss: 0.7126
[10/12 15:52:40 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.2140, average loss: 0.6840
[10/12 15:52:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[10/12 15:54:35 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2298, average loss: 0.6801
[10/12 15:54:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.71	rocauc: 58.50	
[10/12 15:54:35 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/12 16:01:03 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0814, average train loss: 0.6986
[10/12 16:01:47 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.2324, average loss: 0.6813
[10/12 16:01:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 56.41	
[10/12 16:03:43 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2215, average loss: 0.6758
[10/12 16:03:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 59.26	
[10/12 16:03:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/12 16:10:12 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.1125, average train loss: 0.7246
[10/12 16:10:56 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.2085, average loss: 0.6931
[10/12 16:10:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.51	
[10/12 16:12:51 visual_prompt]: Inference (test):avg data time: 3.85e-05, avg batch time: 0.2258, average loss: 0.6710
[10/12 16:12:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 57.96	
[10/12 16:12:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/12 16:19:19 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 11.0912, average train loss: 0.7103
[10/12 16:20:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2347, average loss: 0.6996
[10/12 16:20:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.44	
[10/12 16:21:59 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2313, average loss: 0.6729
[10/12 16:21:59 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 58.62	
[10/12 16:21:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/12 16:28:32 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.2277, average train loss: 0.6862
[10/12 16:29:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.2347, average loss: 0.7987
[10/12 16:29:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.25	
[10/12 16:31:10 visual_prompt]: Inference (test):avg data time: 3.79e-05, avg batch time: 0.2287, average loss: 0.8340
[10/12 16:31:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.09	rocauc: 60.64	
[10/12 16:31:10 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/12 16:37:37 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0488, average train loss: 0.7030
[10/12 16:38:21 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2147, average loss: 0.6800
[10/12 16:38:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 57.31	
[10/12 16:40:17 visual_prompt]: Inference (test):avg data time: 3.96e-05, avg batch time: 0.2281, average loss: 0.6746
[10/12 16:40:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.00	rocauc: 59.54	
[10/12 16:40:17 visual_prompt]: Best epoch 12: best metric: -0.680
[10/12 16:40:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/12 16:46:47 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.1334, average train loss: 0.6854
[10/12 16:47:31 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.2358, average loss: 0.6740
[10/12 16:47:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.35	
[10/12 16:49:26 visual_prompt]: Inference (test):avg data time: 3.99e-05, avg batch time: 0.2233, average loss: 0.6624
[10/12 16:49:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 60.63	
[10/12 16:49:26 visual_prompt]: Best epoch 13: best metric: -0.674
[10/12 16:49:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/12 16:55:54 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0945, average train loss: 0.7018
[10/12 16:56:40 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.2255, average loss: 0.6815
[10/12 16:56:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 59.58	
[10/12 16:59:05 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2305, average loss: 0.6607
[10/12 16:59:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 61.58	
[10/12 16:59:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/12 17:06:40 visual_prompt]: Epoch 15 / 100: avg data time: 1.25e+01, avg batch time: 12.9936, average train loss: 0.7000
[10/12 17:07:33 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2294, average loss: 0.6827
[10/12 17:07:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 59.34	
[10/12 17:09:32 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2313, average loss: 0.6606
[10/12 17:09:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 61.16	
[10/12 17:09:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/12 17:16:02 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.1581, average train loss: 0.6877
[10/12 17:16:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.2219, average loss: 0.6730
[10/12 17:16:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 59.76	
[10/12 17:19:18 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2240, average loss: 0.6606
[10/12 17:19:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 61.27	
[10/12 17:19:18 visual_prompt]: Best epoch 16: best metric: -0.673
[10/12 17:19:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/12 17:26:56 visual_prompt]: Epoch 17 / 100: avg data time: 1.26e+01, avg batch time: 13.0768, average train loss: 0.6920
[10/12 17:27:50 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2200, average loss: 0.6778
[10/12 17:27:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 59.98	
[10/12 17:30:08 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2235, average loss: 0.6781
[10/12 17:30:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 62.43	
[10/12 17:30:08 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/12 17:36:48 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e+01, avg batch time: 11.4295, average train loss: 0.6985
[10/12 17:37:32 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2072, average loss: 0.7224
[10/12 17:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 59.69	
[10/12 17:39:27 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2298, average loss: 0.7409
[10/12 17:39:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.27	rocauc: 62.06	
[10/12 17:39:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/12 17:45:54 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0369, average train loss: 0.7027
[10/12 17:46:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2128, average loss: 0.6918
[10/12 17:46:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 59.96	
[10/12 17:48:37 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2344, average loss: 0.6633
[10/12 17:48:37 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.00	rocauc: 61.99	
[10/12 17:48:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/12 17:55:13 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e+01, avg batch time: 11.3283, average train loss: 0.7053
[10/12 17:55:59 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.2354, average loss: 0.6984
[10/12 17:55:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 60.53	
[10/12 17:57:56 visual_prompt]: Inference (test):avg data time: 3.87e-05, avg batch time: 0.2331, average loss: 0.7095
[10/12 17:57:56 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.63	rocauc: 62.47	
[10/12 17:57:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/12 18:05:19 visual_prompt]: Epoch 21 / 100: avg data time: 1.22e+01, avg batch time: 12.6391, average train loss: 0.6743
[10/12 18:06:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2152, average loss: 0.6795
[10/12 18:06:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.15	
[10/12 18:08:46 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2260, average loss: 0.6755
[10/12 18:08:46 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.78	rocauc: 62.92	
[10/12 18:08:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/12 18:16:14 visual_prompt]: Epoch 22 / 100: avg data time: 1.24e+01, avg batch time: 12.8100, average train loss: 0.6874
[10/12 18:17:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.2274, average loss: 0.7046
[10/12 18:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.66	
[10/12 18:19:13 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2313, average loss: 0.6671
[10/12 18:19:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.16	rocauc: 63.72	
[10/12 18:19:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/12 18:25:47 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e+01, avg batch time: 11.2527, average train loss: 0.7071
[10/12 18:26:31 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.2074, average loss: 0.7740
[10/12 18:26:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.03	
[10/12 18:28:24 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2335, average loss: 0.7244
[10/12 18:28:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 61.92	
[10/12 18:28:24 visual_prompt]: Stopping early.
[10/12 18:28:25 visual_prompt]: Rank of current process: 0. World size: 1
[10/12 18:28:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/12 18:28:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/12 18:28:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/12 18:28:25 visual_prompt]: Training with config:
[10/12 18:28:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/test/seed3172/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 3172, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/12 18:28:25 visual_prompt]: Loading training data...
[10/12 18:28:25 visual_prompt]: Constructing mammo-cbis dataset train...
[10/12 18:28:25 visual_prompt]: Loading validation data...
[10/12 18:28:25 visual_prompt]: Constructing mammo-cbis dataset val...
[10/12 18:28:25 visual_prompt]: Loading test data...
[10/12 18:28:25 visual_prompt]: Constructing mammo-cbis dataset test...
[10/12 18:28:25 visual_prompt]: Constructing models...
[10/12 18:28:38 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/12 18:28:38 visual_prompt]: tuned percent:0.536
[10/12 18:28:38 visual_prompt]: Device used for model: 0
[10/12 18:28:38 visual_prompt]: Setting up Evaluator...
[10/12 18:28:38 visual_prompt]: Setting up Trainer...
[10/12 18:28:38 visual_prompt]: 	Setting up the optimizer...
[10/12 18:28:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/12 18:35:52 visual_prompt]: Epoch 1 / 100: avg data time: 1.19e+01, avg batch time: 12.3954, average train loss: 1.3235
[10/12 18:36:46 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2288, average loss: 1.3228
[10/12 18:36:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.74	
[10/12 18:39:14 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2210, average loss: 1.4091
[10/12 18:39:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 51.94	
[10/12 18:39:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/12 18:46:01 visual_prompt]: Epoch 2 / 100: avg data time: 1.12e+01, avg batch time: 11.6307, average train loss: 1.2801
[10/12 18:46:53 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2189, average loss: 0.7169
[10/12 18:46:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 50.23	
[10/12 18:49:45 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2229, average loss: 0.7257
[10/12 18:49:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 52.01	
[10/12 18:49:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/12 18:57:35 visual_prompt]: Epoch 3 / 100: avg data time: 1.30e+01, avg batch time: 13.4085, average train loss: 0.7094
[10/12 18:58:22 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2093, average loss: 0.6926
[10/12 18:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.71	
[10/12 19:00:32 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2342, average loss: 0.6737
[10/12 19:00:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 54.83	
[10/12 19:00:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/12 19:07:45 visual_prompt]: Epoch 4 / 100: avg data time: 1.19e+01, avg batch time: 12.3664, average train loss: 0.6987
[10/12 19:08:29 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2119, average loss: 0.6985
[10/12 19:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.17	
[10/12 19:10:23 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2305, average loss: 0.6749
[10/12 19:10:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 55.90	
[10/12 19:10:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/12 19:16:48 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.9974, average train loss: 0.6954
[10/12 19:17:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.2108, average loss: 0.7002
[10/12 19:17:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 56.51	
[10/12 19:19:25 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2248, average loss: 0.7063
[10/12 19:19:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.43	rocauc: 59.21	
[10/12 19:19:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/12 19:25:58 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.2133, average train loss: 0.7205
[10/12 19:26:44 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.2105, average loss: 0.8379
[10/12 19:26:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.02	
[10/12 19:28:43 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2273, average loss: 0.8732
[10/12 19:28:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 58.98	
[10/12 19:28:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/12 19:35:25 visual_prompt]: Epoch 7 / 100: avg data time: 1.10e+01, avg batch time: 11.4872, average train loss: 0.7590
[10/12 19:36:11 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.2260, average loss: 0.6842
[10/12 19:36:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 56.17	
[10/12 19:38:10 visual_prompt]: Inference (test):avg data time: 4.08e-05, avg batch time: 0.2257, average loss: 0.6677
[10/12 19:38:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.53	rocauc: 59.56	
[10/12 19:38:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/12 19:44:44 visual_prompt]: Epoch 8 / 100: avg data time: 1.08e+01, avg batch time: 11.2671, average train loss: 0.7668
[10/12 19:45:30 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2322, average loss: 0.8269
[10/12 19:45:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.12	
[10/12 19:47:27 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2243, average loss: 0.7670
[10/12 19:47:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.16	
[10/12 19:47:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/12 19:54:06 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.3872, average train loss: 0.7327
[10/12 19:54:52 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.2267, average loss: 0.7728
[10/12 19:54:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.14	
[10/12 19:56:48 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2339, average loss: 0.7226
[10/12 19:56:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.95	
[10/12 19:56:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/12 20:03:20 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.1994, average train loss: 0.7033
[10/12 20:04:06 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2233, average loss: 0.7452
[10/12 20:04:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.90	
[10/12 20:06:01 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2247, average loss: 0.7005
[10/12 20:06:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.18	
[10/12 20:06:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/12 20:12:29 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.0904, average train loss: 0.7076
[10/12 20:13:13 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.2126, average loss: 0.6834
[10/12 20:13:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 57.69	
[10/12 20:15:08 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2197, average loss: 0.6616
[10/12 20:15:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.84	rocauc: 60.46	
[10/12 20:15:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/12 20:21:32 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.9729, average train loss: 0.7412
[10/12 20:22:16 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2248, average loss: 0.6802
[10/12 20:22:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 56.99	
[10/12 20:24:10 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2239, average loss: 0.6698
[10/12 20:24:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 59.77	
[10/12 20:24:10 visual_prompt]: Best epoch 12: best metric: -0.680
[10/12 20:24:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/12 20:30:36 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0319, average train loss: 0.6981
[10/12 20:31:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.2353, average loss: 0.7015
[10/12 20:31:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 57.95	
[10/12 20:33:15 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2247, average loss: 0.7097
[10/12 20:33:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.01	rocauc: 59.99	
[10/12 20:33:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/12 20:39:40 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.9924, average train loss: 0.7184
[10/12 20:40:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.2062, average loss: 0.6783
[10/12 20:40:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.92	
[10/12 20:42:18 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2264, average loss: 0.6604
[10/12 20:42:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 60.81	
[10/12 20:42:18 visual_prompt]: Best epoch 14: best metric: -0.678
[10/12 20:42:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/12 20:48:44 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0143, average train loss: 0.6800
[10/12 20:49:27 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.2103, average loss: 0.7090
[10/12 20:49:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 58.49	
[10/12 20:51:21 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2264, average loss: 0.7200
[10/12 20:51:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.92	rocauc: 60.51	
[10/12 20:51:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/12 20:57:47 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0350, average train loss: 0.7142
[10/12 20:58:31 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.2150, average loss: 0.7398
[10/12 20:58:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.98	
[10/12 21:00:25 visual_prompt]: Inference (test):avg data time: 4.12e-05, avg batch time: 0.2212, average loss: 0.6938
[10/12 21:00:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 61.68	
[10/12 21:00:25 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/12 21:06:51 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0259, average train loss: 0.6804
[10/12 21:07:36 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.2199, average loss: 0.6946
[10/12 21:07:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 59.32	
[10/12 21:09:30 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2273, average loss: 0.7010
[10/12 21:09:30 visual_prompt]: Classification results with test_mammo-cbis: top1: 54.26	rocauc: 60.97	
[10/12 21:09:30 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/12 21:15:57 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0284, average train loss: 0.7033
[10/12 21:16:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.2299, average loss: 0.6770
[10/12 21:16:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 60.27	
[10/12 21:18:35 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2300, average loss: 0.6574
[10/12 21:18:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 62.39	
[10/12 21:18:35 visual_prompt]: Best epoch 18: best metric: -0.677
[10/12 21:18:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/12 21:25:00 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9987, average train loss: 0.7293
[10/12 21:25:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2288, average loss: 0.6781
[10/12 21:25:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 59.30	
[10/12 21:27:38 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2263, average loss: 0.6567
[10/12 21:27:38 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 61.95	
[10/12 21:27:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/12 21:34:02 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.9792, average train loss: 0.6913
[10/12 21:34:47 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.2409, average loss: 0.8191
[10/12 21:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 59.48	
[10/12 21:36:41 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2267, average loss: 0.8582
[10/12 21:36:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.71	rocauc: 61.79	
[10/12 21:36:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/12 21:43:06 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 11.0119, average train loss: 0.6818
[10/12 21:43:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.2336, average loss: 0.6693
[10/12 21:43:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 60.75	
[10/12 21:45:44 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2279, average loss: 0.6606
[10/12 21:45:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 62.55	
[10/12 21:45:44 visual_prompt]: Best epoch 21: best metric: -0.669
[10/12 21:45:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/12 21:52:09 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9966, average train loss: 0.6664
[10/12 21:52:53 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2233, average loss: 0.6662
[10/12 21:52:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 61.22	
[10/12 21:54:47 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2312, average loss: 0.6589
[10/12 21:54:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.26	rocauc: 63.03	
[10/12 21:54:47 visual_prompt]: Best epoch 22: best metric: -0.666
[10/12 21:54:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/12 22:01:12 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9994, average train loss: 0.7017
[10/12 22:01:56 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2321, average loss: 0.6675
[10/12 22:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 61.07	
[10/12 22:03:50 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2439, average loss: 0.6564
[10/12 22:03:50 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 62.50	
[10/12 22:03:50 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/12 22:10:16 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.0425, average train loss: 0.6883
[10/12 22:11:01 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.2189, average loss: 0.6742
[10/12 22:11:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.21	
[10/12 22:12:55 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2330, average loss: 0.6534
[10/12 22:12:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 62.66	
[10/12 22:12:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/12 22:19:19 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.9807, average train loss: 0.6791
[10/12 22:20:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.2368, average loss: 0.6722
[10/12 22:20:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.49	
[10/12 22:21:57 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2279, average loss: 0.6499
[10/12 22:21:57 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.86	rocauc: 63.00	
[10/12 22:21:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/12 22:28:22 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.9991, average train loss: 0.6733
[10/12 22:29:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.2118, average loss: 0.6855
[10/12 22:29:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 60.79	
[10/12 22:31:00 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2258, average loss: 0.6845
[10/12 22:31:00 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.53	rocauc: 62.38	
[10/12 22:31:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/12 22:37:24 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.9915, average train loss: 0.6669
[10/12 22:38:09 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2097, average loss: 0.6763
[10/12 22:38:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 60.71	
[10/12 22:40:02 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2371, average loss: 0.6806
[10/12 22:40:02 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 61.95	
[10/12 22:40:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/12 22:46:27 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.9954, average train loss: 0.6701
[10/12 22:47:11 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2361, average loss: 0.6793
[10/12 22:47:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.78	
[10/12 22:49:05 visual_prompt]: Inference (test):avg data time: 3.69e-05, avg batch time: 0.2288, average loss: 0.6522
[10/12 22:49:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.10	rocauc: 62.84	
[10/12 22:49:05 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/12 22:55:30 visual_prompt]: Epoch 29 / 100: avg data time: 1.05e+01, avg batch time: 10.9917, average train loss: 0.6627
[10/12 22:56:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.2038, average loss: 0.6677
[10/12 22:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 63.01	
[10/12 22:58:09 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2329, average loss: 0.6728
[10/12 22:58:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.45	rocauc: 63.80	
[10/12 22:58:09 visual_prompt]: Stopping early.
[10/12 22:58:09 visual_prompt]: Rank of current process: 0. World size: 1
[10/12 22:58:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/12 22:58:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/12 22:58:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/12 22:58:09 visual_prompt]: Training with config:
[10/12 22:58:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/test/seed8393/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8393, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/12 22:58:09 visual_prompt]: Loading training data...
[10/12 22:58:09 visual_prompt]: Constructing mammo-cbis dataset train...
[10/12 22:58:09 visual_prompt]: Loading validation data...
[10/12 22:58:09 visual_prompt]: Constructing mammo-cbis dataset val...
[10/12 22:58:09 visual_prompt]: Loading test data...
[10/12 22:58:09 visual_prompt]: Constructing mammo-cbis dataset test...
[10/12 22:58:09 visual_prompt]: Constructing models...
[10/12 22:58:18 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/12 22:58:18 visual_prompt]: tuned percent:0.536
[10/12 22:58:18 visual_prompt]: Device used for model: 0
[10/12 22:58:18 visual_prompt]: Setting up Evaluator...
[10/12 22:58:18 visual_prompt]: Setting up Trainer...
[10/12 22:58:18 visual_prompt]: 	Setting up the optimizer...
[10/12 22:58:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/12 23:04:44 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 11.0072, average train loss: 1.2095
[10/12 23:05:27 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.2117, average loss: 1.0454
[10/12 23:05:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.82	
[10/12 23:07:21 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2280, average loss: 0.9737
[10/12 23:07:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 50.55	
[10/12 23:07:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[10/12 23:13:46 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 11.0060, average train loss: 1.3083
[10/12 23:14:30 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2420, average loss: 0.7425
[10/12 23:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.61	
[10/12 23:16:23 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2371, average loss: 0.7646
[10/12 23:16:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 48.76	
[10/12 23:16:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[10/12 23:22:48 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.9988, average train loss: 0.7054
[10/12 23:23:33 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2236, average loss: 0.6862
[10/12 23:23:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.52	
[10/12 23:25:27 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2260, average loss: 0.6813
[10/12 23:25:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 50.22	
[10/12 23:25:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[10/12 23:31:53 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0374, average train loss: 0.7013
[10/12 23:32:37 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2314, average loss: 0.7019
[10/12 23:32:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 56.02	
[10/12 23:34:31 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2246, average loss: 0.7109
[10/12 23:34:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.55	rocauc: 53.52	
[10/12 23:34:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[10/12 23:40:57 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.0299, average train loss: 0.6901
[10/12 23:41:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2207, average loss: 0.6867
[10/12 23:41:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.03	
[10/12 23:43:36 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2338, average loss: 0.6720
[10/12 23:43:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 55.84	
[10/12 23:43:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[10/12 23:50:03 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.0491, average train loss: 0.7039
[10/12 23:50:47 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2441, average loss: 0.6822
[10/12 23:50:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.17	
[10/12 23:52:41 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2270, average loss: 0.6701
[10/12 23:52:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 57.49	
[10/12 23:52:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[10/12 23:59:09 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0643, average train loss: 0.6929
[10/12 23:59:53 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.2038, average loss: 0.6978
[10/12 23:59:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.50	
[10/13 00:01:47 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2242, average loss: 0.6742
[10/13 00:01:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 58.87	
[10/13 00:01:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[10/13 00:08:14 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0464, average train loss: 0.7163
[10/13 00:08:58 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2346, average loss: 0.6954
[10/13 00:08:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 59.45	
[10/13 00:10:52 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2267, average loss: 0.7052
[10/13 00:10:52 visual_prompt]: Classification results with test_mammo-cbis: top1: 47.75	rocauc: 58.57	
[10/13 00:10:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[10/13 00:17:17 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 10.9944, average train loss: 0.7087
[10/13 00:18:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.2084, average loss: 0.6769
[10/13 00:18:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 59.57	
[10/13 00:19:55 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2323, average loss: 0.6740
[10/13 00:19:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.60	rocauc: 58.92	
[10/13 00:19:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[10/13 00:26:20 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9918, average train loss: 0.7105
[10/13 00:27:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2315, average loss: 0.7187
[10/13 00:27:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 57.91	
[10/13 00:28:58 visual_prompt]: Inference (test):avg data time: 1.49e-03, avg batch time: 0.2286, average loss: 0.7365
[10/13 00:28:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 43.57	rocauc: 58.64	
[10/13 00:28:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[10/13 00:35:23 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 11.0159, average train loss: 0.7239
[10/13 00:36:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.2267, average loss: 0.7820
[10/13 00:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.26	
[10/13 00:38:01 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2358, average loss: 0.8147
[10/13 00:38:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 59.82	
[10/13 00:38:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[10/13 00:44:27 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.0357, average train loss: 0.7325
[10/13 00:45:11 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2304, average loss: 0.6845
[10/13 00:45:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 59.04	
[10/13 00:47:04 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2323, average loss: 0.6871
[10/13 00:47:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.59	rocauc: 59.88	
[10/13 00:47:04 visual_prompt]: Best epoch 12: best metric: -0.685
[10/13 00:47:04 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[10/13 00:53:30 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.0190, average train loss: 0.6992
[10/13 00:54:15 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.2351, average loss: 0.6791
[10/13 00:54:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 58.92	
[10/13 00:56:08 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2316, average loss: 0.6625
[10/13 00:56:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.09	rocauc: 59.97	
[10/13 00:56:08 visual_prompt]: Best epoch 13: best metric: -0.679
[10/13 00:56:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[10/13 01:02:34 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.0282, average train loss: 0.6837
[10/13 01:03:19 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2352, average loss: 0.6767
[10/13 01:03:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 59.38	
[10/13 01:05:13 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2312, average loss: 0.6737
[10/13 01:05:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.23	
[10/13 01:05:13 visual_prompt]: Best epoch 14: best metric: -0.677
[10/13 01:05:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[10/13 01:11:39 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.0143, average train loss: 0.6862
[10/13 01:12:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.2384, average loss: 0.6756
[10/13 01:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 59.71	
[10/13 01:14:17 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.2373, average loss: 0.6739
[10/13 01:14:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 60.75	
[10/13 01:14:17 visual_prompt]: Best epoch 15: best metric: -0.676
[10/13 01:14:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[10/13 01:20:44 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.0578, average train loss: 0.6960
[10/13 01:21:29 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.2321, average loss: 0.7032
[10/13 01:21:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.45	
[10/13 01:23:23 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2220, average loss: 0.7141
[10/13 01:23:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.18	rocauc: 60.56	
[10/13 01:23:23 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[10/13 01:29:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 11.0566, average train loss: 0.6849
[10/13 01:30:34 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.2064, average loss: 0.6927
[10/13 01:30:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 61.20	
[10/13 01:32:28 visual_prompt]: Inference (test):avg data time: 3.79e-05, avg batch time: 0.2295, average loss: 0.6670
[10/13 01:32:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 61.51	
[10/13 01:32:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[10/13 01:38:56 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.0769, average train loss: 0.7261
[10/13 01:39:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.2285, average loss: 0.6715
[10/13 01:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 61.80	
[10/13 01:41:39 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2248, average loss: 0.6737
[10/13 01:41:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 61.13	
[10/13 01:41:39 visual_prompt]: Best epoch 18: best metric: -0.671
[10/13 01:41:39 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[10/13 01:48:07 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 11.0785, average train loss: 0.7329
[10/13 01:48:51 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2417, average loss: 0.7172
[10/13 01:48:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 60.36	
[10/13 01:50:46 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2336, average loss: 0.7357
[10/13 01:50:46 visual_prompt]: Classification results with test_mammo-cbis: top1: 46.20	rocauc: 61.30	
[10/13 01:50:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[10/13 01:57:11 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 11.0136, average train loss: 0.7037
[10/13 01:57:55 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.2331, average loss: 0.6685
[10/13 01:57:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.50	
[10/13 01:59:49 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2311, average loss: 0.6661
[10/13 01:59:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 61.70	
[10/13 01:59:49 visual_prompt]: Best epoch 20: best metric: -0.668
[10/13 01:59:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[10/13 02:06:15 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.0373, average train loss: 0.6857
[10/13 02:06:59 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.2071, average loss: 0.6719
[10/13 02:06:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.04	
[10/13 02:08:53 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2307, average loss: 0.6568
[10/13 02:08:53 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.24	rocauc: 61.94	
[10/13 02:08:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[10/13 02:15:17 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.9787, average train loss: 0.6839
[10/13 02:16:01 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.2091, average loss: 0.6668
[10/13 02:16:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.18	
[10/13 02:17:55 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2319, average loss: 0.6642
[10/13 02:17:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.78	rocauc: 61.43	
[10/13 02:17:55 visual_prompt]: Best epoch 22: best metric: -0.667
[10/13 02:17:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[10/13 02:24:20 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 11.0078, average train loss: 0.6756
[10/13 02:25:04 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.2418, average loss: 0.6811
[10/13 02:25:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 62.55	
[10/13 02:26:59 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2379, average loss: 0.6618
[10/13 02:26:59 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 61.39	
[10/13 02:26:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[10/13 02:33:25 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.0091, average train loss: 0.6787
[10/13 02:34:09 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.2358, average loss: 0.6651
[10/13 02:34:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 62.61	
[10/13 02:36:03 visual_prompt]: Inference (test):avg data time: 3.94e-05, avg batch time: 0.2348, average loss: 0.6606
[10/13 02:36:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 61.41	
[10/13 02:36:03 visual_prompt]: Best epoch 24: best metric: -0.665
[10/13 02:36:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[10/13 02:42:28 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.9989, average train loss: 0.6686
[10/13 02:43:12 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.2259, average loss: 0.6694
[10/13 02:43:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 62.43	
[10/13 02:45:05 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2336, average loss: 0.6764
[10/13 02:45:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.16	rocauc: 61.62	
[10/13 02:45:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[10/13 02:51:30 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 11.0022, average train loss: 0.6650
[10/13 02:52:15 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.2348, average loss: 0.7099
[10/13 02:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.78	
[10/13 02:54:09 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2262, average loss: 0.6804
[10/13 02:54:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.16	rocauc: 62.27	
[10/13 02:54:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[10/13 03:00:34 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.9998, average train loss: 0.6817
[10/13 03:01:18 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.2263, average loss: 0.7238
[10/13 03:01:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 61.92	
[10/13 03:03:12 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2269, average loss: 0.7508
[10/13 03:03:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.84	rocauc: 62.10	
[10/13 03:03:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[10/13 03:09:37 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 11.0059, average train loss: 0.6811
[10/13 03:10:21 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.2139, average loss: 0.6768
[10/13 03:10:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 62.69	
[10/13 03:12:15 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2271, average loss: 0.6566
[10/13 03:12:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.24	rocauc: 62.55	
[10/13 03:12:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[10/13 03:18:41 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 11.0318, average train loss: 0.6662
[10/13 03:19:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.2323, average loss: 0.6642
[10/13 03:19:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 63.42	
[10/13 03:21:19 visual_prompt]: Inference (test):avg data time: 3.85e-05, avg batch time: 0.2331, average loss: 0.6510
[10/13 03:21:19 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.02	rocauc: 62.91	
[10/13 03:21:19 visual_prompt]: Best epoch 29: best metric: -0.664
[10/13 03:21:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[10/13 03:27:46 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 11.0354, average train loss: 0.6622
[10/13 03:28:30 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.2303, average loss: 0.6828
[10/13 03:28:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 62.86	
[10/13 03:30:23 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2282, average loss: 0.6970
[10/13 03:30:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.60	rocauc: 62.65	
[10/13 03:30:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[10/13 03:36:50 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0339, average train loss: 0.6608
[10/13 03:37:34 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.2347, average loss: 0.7325
[10/13 03:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.05	
[10/13 03:39:28 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2338, average loss: 0.6905
[10/13 03:39:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.09	rocauc: 62.23	
[10/13 03:39:28 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[10/13 03:45:52 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.9883, average train loss: 0.6614
[10/13 03:46:36 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.2412, average loss: 0.6772
[10/13 03:46:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 62.05	
[10/13 03:48:31 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2417, average loss: 0.6513
[10/13 03:48:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.95	rocauc: 62.71	
[10/13 03:48:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[10/13 03:54:56 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 11.0158, average train loss: 0.6739
[10/13 03:55:40 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.2364, average loss: 0.6835
[10/13 03:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.15	
[10/13 03:57:34 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2318, average loss: 0.6528
[10/13 03:57:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 63.00	
[10/13 03:57:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[10/13 04:04:00 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 11.0246, average train loss: 0.6612
[10/13 04:04:44 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.2304, average loss: 0.6838
[10/13 04:04:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.05	
[10/13 04:06:38 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2280, average loss: 0.6547
[10/13 04:06:38 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 63.10	
[10/13 04:06:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[10/13 04:13:02 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.9950, average train loss: 0.6644
[10/13 04:13:47 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.2110, average loss: 0.6670
[10/13 04:13:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 63.04	
[10/13 04:15:41 visual_prompt]: Inference (test):avg data time: 3.75e-05, avg batch time: 0.2287, average loss: 0.6565
[10/13 04:15:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 63.19	
[10/13 04:15:41 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[10/13 04:22:07 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 11.0261, average train loss: 0.6657
[10/13 04:22:51 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.2262, average loss: 0.7471
[10/13 04:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 64.02	
[10/13 04:24:45 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2283, average loss: 0.7807
[10/13 04:24:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.43	rocauc: 63.87	
[10/13 04:24:45 visual_prompt]: Stopping early.
/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
