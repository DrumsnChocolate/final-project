[09/18 13:01:47 visual_prompt]: Rank of current process: 0. World size: 1
[09/18 13:01:47 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/18 13:01:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/18 13:01:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/18 13:01:47 visual_prompt]: Training with config:
[09/18 13:01:47 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/18 13:01:47 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-18 13:01:47.799447: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-18 13:01:47.967705: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-18 13:01:48.949713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:48.949791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:48.949800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-18 13:01:51.255544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:51.255659: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 13:01:51.255677: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/18 13:01:51 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-18 13:01:51.277544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 13:01:54 visual_prompt]: Number of images: 1000
[09/18 13:01:54 visual_prompt]: Number of classes: 16 / 16
[09/18 13:01:54 visual_prompt]: Loading validation data...
[09/18 13:01:54 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 13:01:54 visual_prompt]: Number of images: 200
[09/18 13:01:54 visual_prompt]: Number of classes: 16 / 16
[09/18 13:01:54 visual_prompt]: Loading test data...
[09/18 13:01:54 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 13:03:29 visual_prompt]: Number of images: 73728
[09/18 13:03:29 visual_prompt]: Number of classes: 16 / 16
[09/18 13:03:30 visual_prompt]: Constructing models...
[09/18 13:03:33 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/18 13:03:33 visual_prompt]: tuned percent:1.077
[09/18 13:03:36 visual_prompt]: Device used for model: 0
[09/18 13:03:36 visual_prompt]: Setting up Evalutator...
[09/18 13:03:36 visual_prompt]: Setting up Trainer...
[09/18 13:03:36 visual_prompt]: 	Setting up the optimizer...
[09/18 13:03:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/18 13:03:48 visual_prompt]: Epoch 1 / 100: avg data time: 2.52e-01, avg batch time: 0.5757, average train loss: 2.8889
[09/18 13:03:55 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0862, average loss: 2.8956
[09/18 13:03:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 32.00	
[09/18 13:04:15 visual_prompt]: 	Test 100/1152. loss: 2.806, 0.1119 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 13:04:31 visual_prompt]: 	Test 200/1152. loss: 2.912, 0.0981 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 13:04:46 visual_prompt]: 	Test 300/1152. loss: 2.851, 0.1334 s / batch. (data: 3.27e-02)max mem: 17.22454 GB 
[09/18 13:05:02 visual_prompt]: 	Test 400/1152. loss: 2.901, 0.1300 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 13:05:18 visual_prompt]: 	Test 500/1152. loss: 2.858, 0.1291 s / batch. (data: 3.25e-02)max mem: 17.22454 GB 
[09/18 13:05:34 visual_prompt]: 	Test 600/1152. loss: 2.784, 0.0972 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 13:05:50 visual_prompt]: 	Test 700/1152. loss: 2.933, 0.1051 s / batch. (data: 2.88e-05)max mem: 17.22454 GB 
[09/18 13:06:06 visual_prompt]: 	Test 800/1152. loss: 2.865, 0.0971 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:06:22 visual_prompt]: 	Test 900/1152. loss: 2.775, 0.1003 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 13:06:39 visual_prompt]: 	Test 1000/1152. loss: 2.753, 0.1039 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 13:06:55 visual_prompt]: 	Test 1100/1152. loss: 2.864, 0.1083 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/18 13:07:07 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1092, average loss: 2.8895
[09/18 13:07:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 34.55	
[09/18 13:07:07 visual_prompt]: Best epoch 1: best metric: 0.040
[09/18 13:07:07 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/18 13:07:18 visual_prompt]: Epoch 2 / 100: avg data time: 2.31e-01, avg batch time: 0.4588, average train loss: 3.1919
[09/18 13:07:25 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.0873, average loss: 2.8996
[09/18 13:07:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 30.50	
[09/18 13:07:44 visual_prompt]: 	Test 100/1152. loss: 2.935, 0.1798 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 13:08:00 visual_prompt]: 	Test 200/1152. loss: 2.884, 0.1205 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 13:08:15 visual_prompt]: 	Test 300/1152. loss: 2.778, 0.1161 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 13:08:31 visual_prompt]: 	Test 400/1152. loss: 2.889, 0.1047 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 13:08:46 visual_prompt]: 	Test 500/1152. loss: 2.879, 0.1198 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 13:09:01 visual_prompt]: 	Test 600/1152. loss: 2.906, 0.1038 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 13:09:18 visual_prompt]: 	Test 700/1152. loss: 2.952, 0.1184 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 13:09:34 visual_prompt]: 	Test 800/1152. loss: 2.943, 0.0999 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 13:09:51 visual_prompt]: 	Test 900/1152. loss: 3.100, 0.0946 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 13:10:07 visual_prompt]: 	Test 1000/1152. loss: 3.136, 0.1123 s / batch. (data: 6.58e-05)max mem: 17.22454 GB 
[09/18 13:10:23 visual_prompt]: 	Test 1100/1152. loss: 2.903, 0.1034 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 13:10:35 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1087, average loss: 2.9008
[09/18 13:10:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 32.47	
[09/18 13:10:35 visual_prompt]: Best epoch 2: best metric: 0.050
[09/18 13:10:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/18 13:10:45 visual_prompt]: Epoch 3 / 100: avg data time: 2.29e-01, avg batch time: 0.4549, average train loss: 2.9969
[09/18 13:10:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.0938, average loss: 2.9346
[09/18 13:10:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 42.50	
[09/18 13:11:12 visual_prompt]: 	Test 100/1152. loss: 3.052, 0.1022 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 13:11:28 visual_prompt]: 	Test 200/1152. loss: 3.090, 0.1020 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/18 13:11:43 visual_prompt]: 	Test 300/1152. loss: 2.975, 0.1317 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/18 13:11:59 visual_prompt]: 	Test 400/1152. loss: 3.035, 0.1486 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 13:12:14 visual_prompt]: 	Test 500/1152. loss: 3.012, 0.1135 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 13:12:29 visual_prompt]: 	Test 600/1152. loss: 2.982, 0.1093 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 13:12:46 visual_prompt]: 	Test 700/1152. loss: 2.821, 0.1277 s / batch. (data: 5.44e-03)max mem: 17.22454 GB 
[09/18 13:13:02 visual_prompt]: 	Test 800/1152. loss: 2.996, 0.1013 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 13:13:18 visual_prompt]: 	Test 900/1152. loss: 2.899, 0.1067 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 13:13:35 visual_prompt]: 	Test 1000/1152. loss: 2.832, 0.1121 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:13:51 visual_prompt]: 	Test 1100/1152. loss: 3.067, 0.1186 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/18 13:14:03 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1086, average loss: 2.9933
[09/18 13:14:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 35.19	
[09/18 13:14:03 visual_prompt]: Best epoch 3: best metric: 0.075
[09/18 13:14:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/18 13:14:14 visual_prompt]: Epoch 4 / 100: avg data time: 2.28e-01, avg batch time: 0.4573, average train loss: 2.9789
[09/18 13:14:20 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.0897, average loss: 2.9454
[09/18 13:14:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 25.50	
[09/18 13:14:40 visual_prompt]: 	Test 100/1152. loss: 2.934, 0.0984 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:14:56 visual_prompt]: 	Test 200/1152. loss: 3.016, 0.1047 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 13:15:11 visual_prompt]: 	Test 300/1152. loss: 3.014, 0.1174 s / batch. (data: 2.32e-03)max mem: 17.22454 GB 
[09/18 13:15:27 visual_prompt]: 	Test 400/1152. loss: 3.034, 0.1108 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 13:15:42 visual_prompt]: 	Test 500/1152. loss: 3.009, 0.1045 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/18 13:15:58 visual_prompt]: 	Test 600/1152. loss: 3.007, 0.0993 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 13:16:15 visual_prompt]: 	Test 700/1152. loss: 2.967, 0.0995 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:16:31 visual_prompt]: 	Test 800/1152. loss: 3.067, 0.1157 s / batch. (data: 7.09e-03)max mem: 17.22454 GB 
[09/18 13:16:47 visual_prompt]: 	Test 900/1152. loss: 2.874, 0.1238 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 13:17:04 visual_prompt]: 	Test 1000/1152. loss: 2.957, 0.1042 s / batch. (data: 8.79e-03)max mem: 17.22454 GB 
[09/18 13:17:20 visual_prompt]: 	Test 1100/1152. loss: 2.836, 0.0977 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:17:32 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1089, average loss: 2.9688
[09/18 13:17:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 24.99	
[09/18 13:17:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/18 13:17:42 visual_prompt]: Epoch 5 / 100: avg data time: 2.33e-01, avg batch time: 0.4592, average train loss: 3.0426
[09/18 13:17:49 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.0862, average loss: 2.9321
[09/18 13:17:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 29.50	
[09/18 13:18:09 visual_prompt]: 	Test 100/1152. loss: 2.921, 0.0979 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/18 13:18:24 visual_prompt]: 	Test 200/1152. loss: 2.966, 0.0981 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 13:18:40 visual_prompt]: 	Test 300/1152. loss: 2.979, 0.0996 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 13:18:55 visual_prompt]: 	Test 400/1152. loss: 2.954, 0.1162 s / batch. (data: 7.43e-03)max mem: 17.22454 GB 
[09/18 13:19:10 visual_prompt]: 	Test 500/1152. loss: 3.010, 0.1232 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 13:19:26 visual_prompt]: 	Test 600/1152. loss: 3.073, 0.1109 s / batch. (data: 5.05e-05)max mem: 17.22454 GB 
[09/18 13:19:42 visual_prompt]: 	Test 700/1152. loss: 2.918, 0.1040 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 13:19:58 visual_prompt]: 	Test 800/1152. loss: 2.918, 0.1124 s / batch. (data: 7.66e-03)max mem: 17.22454 GB 
[09/18 13:20:15 visual_prompt]: 	Test 900/1152. loss: 2.970, 0.1398 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 13:20:32 visual_prompt]: 	Test 1000/1152. loss: 2.900, 0.0998 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 13:20:48 visual_prompt]: 	Test 1100/1152. loss: 2.997, 0.1149 s / batch. (data: 1.83e-02)max mem: 17.22454 GB 
[09/18 13:21:00 visual_prompt]: Inference (test):avg data time: 1.83e-03, avg batch time: 0.1082, average loss: 2.9753
[09/18 13:21:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.34	
[09/18 13:21:00 visual_prompt]: Best epoch 5: best metric: 0.090
[09/18 13:21:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/18 13:21:11 visual_prompt]: Epoch 6 / 100: avg data time: 2.29e-01, avg batch time: 0.4579, average train loss: 3.1328
[09/18 13:21:18 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.0862, average loss: 3.0167
[09/18 13:21:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 41.50	
[09/18 13:21:37 visual_prompt]: 	Test 100/1152. loss: 3.305, 0.1043 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 13:21:53 visual_prompt]: 	Test 200/1152. loss: 3.145, 0.1296 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 13:22:08 visual_prompt]: 	Test 300/1152. loss: 3.082, 0.0983 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:22:24 visual_prompt]: 	Test 400/1152. loss: 3.354, 0.0970 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 13:22:39 visual_prompt]: 	Test 500/1152. loss: 3.175, 0.0999 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 13:22:54 visual_prompt]: 	Test 600/1152. loss: 3.088, 0.1431 s / batch. (data: 2.37e-04)max mem: 17.22454 GB 
[09/18 13:23:11 visual_prompt]: 	Test 700/1152. loss: 3.119, 0.1046 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/18 13:23:27 visual_prompt]: 	Test 800/1152. loss: 3.273, 0.1317 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 13:23:44 visual_prompt]: 	Test 900/1152. loss: 3.114, 0.1232 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 13:24:00 visual_prompt]: 	Test 1000/1152. loss: 3.292, 0.0987 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 13:24:16 visual_prompt]: 	Test 1100/1152. loss: 3.068, 0.0974 s / batch. (data: 9.99e-05)max mem: 17.22454 GB 
[09/18 13:24:28 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1088, average loss: 3.1322
[09/18 13:24:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 35.06	
[09/18 13:24:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/18 13:24:39 visual_prompt]: Epoch 7 / 100: avg data time: 2.31e-01, avg batch time: 0.4588, average train loss: 3.1976
[09/18 13:24:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.0953, average loss: 3.0974
[09/18 13:24:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.00	top5: 29.50	
[09/18 13:25:05 visual_prompt]: 	Test 100/1152. loss: 2.888, 0.1319 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:25:21 visual_prompt]: 	Test 200/1152. loss: 2.991, 0.1126 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:25:36 visual_prompt]: 	Test 300/1152. loss: 3.038, 0.1082 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 13:25:52 visual_prompt]: 	Test 400/1152. loss: 2.998, 0.1370 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 13:26:07 visual_prompt]: 	Test 500/1152. loss: 3.020, 0.0973 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/18 13:26:22 visual_prompt]: 	Test 600/1152. loss: 2.917, 0.1026 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 13:26:39 visual_prompt]: 	Test 700/1152. loss: 3.133, 0.1214 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 13:26:55 visual_prompt]: 	Test 800/1152. loss: 3.032, 0.0975 s / batch. (data: 3.17e-05)max mem: 17.22454 GB 
[09/18 13:27:12 visual_prompt]: 	Test 900/1152. loss: 3.041, 0.1181 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 13:27:28 visual_prompt]: 	Test 1000/1152. loss: 3.181, 0.1092 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 13:27:44 visual_prompt]: 	Test 1100/1152. loss: 2.981, 0.1054 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:27:57 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1094, average loss: 3.0653
[09/18 13:27:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.87	top5: 29.80	
[09/18 13:27:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/18 13:28:07 visual_prompt]: Epoch 8 / 100: avg data time: 2.33e-01, avg batch time: 0.4576, average train loss: 3.2059
[09/18 13:28:14 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.0863, average loss: 3.3357
[09/18 13:28:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 35.00	
[09/18 13:28:33 visual_prompt]: 	Test 100/1152. loss: 3.406, 0.1284 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:28:49 visual_prompt]: 	Test 200/1152. loss: 3.480, 0.0968 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:29:04 visual_prompt]: 	Test 300/1152. loss: 3.579, 0.1459 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:29:19 visual_prompt]: 	Test 400/1152. loss: 3.548, 0.1081 s / batch. (data: 6.46e-05)max mem: 17.22454 GB 
[09/18 13:29:35 visual_prompt]: 	Test 500/1152. loss: 3.521, 0.1093 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/18 13:29:50 visual_prompt]: 	Test 600/1152. loss: 3.321, 0.1155 s / batch. (data: 3.70e-05)max mem: 17.22454 GB 
[09/18 13:30:07 visual_prompt]: 	Test 700/1152. loss: 3.490, 0.1116 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 13:30:23 visual_prompt]: 	Test 800/1152. loss: 3.572, 0.1118 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 13:30:39 visual_prompt]: 	Test 900/1152. loss: 3.120, 0.1173 s / batch. (data: 2.13e-02)max mem: 17.22454 GB 
[09/18 13:30:56 visual_prompt]: 	Test 1000/1152. loss: 3.631, 0.0970 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 13:31:12 visual_prompt]: 	Test 1100/1152. loss: 3.400, 0.0949 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/18 13:31:24 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1097, average loss: 3.4950
[09/18 13:31:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 32.46	
[09/18 13:31:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/18 13:31:35 visual_prompt]: Epoch 9 / 100: avg data time: 2.28e-01, avg batch time: 0.4520, average train loss: 3.3482
[09/18 13:31:42 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.0910, average loss: 3.0731
[09/18 13:31:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 34.50	
[09/18 13:32:01 visual_prompt]: 	Test 100/1152. loss: 2.908, 0.1220 s / batch. (data: 2.15e-02)max mem: 17.22454 GB 
[09/18 13:32:17 visual_prompt]: 	Test 200/1152. loss: 3.310, 0.0951 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/18 13:32:32 visual_prompt]: 	Test 300/1152. loss: 2.936, 0.1260 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 13:32:48 visual_prompt]: 	Test 400/1152. loss: 3.007, 0.0975 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 13:33:03 visual_prompt]: 	Test 500/1152. loss: 2.949, 0.1378 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 13:33:19 visual_prompt]: 	Test 600/1152. loss: 3.099, 0.1333 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 13:33:35 visual_prompt]: 	Test 700/1152. loss: 3.061, 0.1173 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 13:33:51 visual_prompt]: 	Test 800/1152. loss: 3.087, 0.1038 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 13:34:08 visual_prompt]: 	Test 900/1152. loss: 3.127, 0.1129 s / batch. (data: 8.15e-03)max mem: 17.22454 GB 
[09/18 13:34:24 visual_prompt]: 	Test 1000/1152. loss: 3.205, 0.1412 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:34:41 visual_prompt]: 	Test 1100/1152. loss: 3.066, 0.1249 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 13:34:53 visual_prompt]: Inference (test):avg data time: 1.59e-03, avg batch time: 0.1086, average loss: 3.0722
[09/18 13:34:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 35.10	
[09/18 13:34:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/18 13:35:04 visual_prompt]: Epoch 10 / 100: avg data time: 2.50e-01, avg batch time: 0.4725, average train loss: 3.3683
[09/18 13:35:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.0942, average loss: 3.3889
[09/18 13:35:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 33.50	
[09/18 13:35:30 visual_prompt]: 	Test 100/1152. loss: 3.023, 0.0990 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 13:35:46 visual_prompt]: 	Test 200/1152. loss: 3.464, 0.1079 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 13:36:01 visual_prompt]: 	Test 300/1152. loss: 3.144, 0.1060 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 13:36:17 visual_prompt]: 	Test 400/1152. loss: 3.229, 0.1076 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 13:36:32 visual_prompt]: 	Test 500/1152. loss: 3.061, 0.0949 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 13:36:47 visual_prompt]: 	Test 600/1152. loss: 3.167, 0.1108 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 13:37:04 visual_prompt]: 	Test 700/1152. loss: 3.543, 0.1191 s / batch. (data: 6.55e-03)max mem: 17.22454 GB 
[09/18 13:37:20 visual_prompt]: 	Test 800/1152. loss: 3.252, 0.0984 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:37:37 visual_prompt]: 	Test 900/1152. loss: 3.543, 0.1067 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 13:37:53 visual_prompt]: 	Test 1000/1152. loss: 3.759, 0.1159 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 13:38:09 visual_prompt]: 	Test 1100/1152. loss: 3.407, 0.1365 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:38:21 visual_prompt]: Inference (test):avg data time: 1.50e-03, avg batch time: 0.1082, average loss: 3.3400
[09/18 13:38:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.52	
[09/18 13:38:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/18 13:38:32 visual_prompt]: Epoch 11 / 100: avg data time: 2.30e-01, avg batch time: 0.4542, average train loss: 3.5898
[09/18 13:38:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.0903, average loss: 3.5249
[09/18 13:38:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 34.50	
[09/18 13:38:58 visual_prompt]: 	Test 100/1152. loss: 3.364, 0.1094 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 13:39:14 visual_prompt]: 	Test 200/1152. loss: 3.497, 0.0959 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 13:39:30 visual_prompt]: 	Test 300/1152. loss: 3.442, 0.1001 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 13:39:45 visual_prompt]: 	Test 400/1152. loss: 3.548, 0.0991 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 13:40:01 visual_prompt]: 	Test 500/1152. loss: 3.598, 0.0995 s / batch. (data: 3.17e-05)max mem: 17.22454 GB 
[09/18 13:40:17 visual_prompt]: 	Test 600/1152. loss: 3.877, 0.1120 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 13:40:33 visual_prompt]: 	Test 700/1152. loss: 3.944, 0.1302 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 13:40:50 visual_prompt]: 	Test 800/1152. loss: 3.480, 0.1146 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 13:41:06 visual_prompt]: 	Test 900/1152. loss: 3.613, 0.1041 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 13:41:23 visual_prompt]: 	Test 1000/1152. loss: 3.347, 0.1143 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 13:41:39 visual_prompt]: 	Test 1100/1152. loss: 3.697, 0.1097 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 13:41:51 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1091, average loss: 3.6030
[09/18 13:41:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 30.17	
[09/18 13:41:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/18 13:42:02 visual_prompt]: Epoch 12 / 100: avg data time: 2.23e-01, avg batch time: 0.4527, average train loss: 4.7198
[09/18 13:42:08 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.0877, average loss: 6.8607
[09/18 13:42:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 30.00	
[09/18 13:42:28 visual_prompt]: 	Test 100/1152. loss: 6.177, 0.1102 s / batch. (data: 9.65e-03)max mem: 17.22454 GB 
[09/18 13:42:44 visual_prompt]: 	Test 200/1152. loss: 5.927, 0.1301 s / batch. (data: 7.12e-03)max mem: 17.22454 GB 
[09/18 13:42:59 visual_prompt]: 	Test 300/1152. loss: 5.686, 0.0997 s / batch. (data: 9.08e-05)max mem: 17.22454 GB 
[09/18 13:43:15 visual_prompt]: 	Test 400/1152. loss: 5.911, 0.1170 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:43:30 visual_prompt]: 	Test 500/1152. loss: 5.916, 0.1195 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 13:43:46 visual_prompt]: 	Test 600/1152. loss: 5.675, 0.0974 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 13:44:02 visual_prompt]: 	Test 700/1152. loss: 6.484, 0.0959 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 13:44:19 visual_prompt]: 	Test 800/1152. loss: 6.007, 0.1113 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 13:44:36 visual_prompt]: 	Test 900/1152. loss: 7.625, 0.1193 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/18 13:44:52 visual_prompt]: 	Test 1000/1152. loss: 7.591, 0.0979 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 13:45:08 visual_prompt]: 	Test 1100/1152. loss: 6.363, 0.0963 s / batch. (data: 1.91e-03)max mem: 17.22454 GB 
[09/18 13:45:20 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1084, average loss: 6.3179
[09/18 13:45:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.94	
[09/18 13:45:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/18 13:45:31 visual_prompt]: Epoch 13 / 100: avg data time: 2.34e-01, avg batch time: 0.4588, average train loss: 8.5116
[09/18 13:45:38 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.0908, average loss: 9.9685
[09/18 13:45:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 28.00	
[09/18 13:45:58 visual_prompt]: 	Test 100/1152. loss: 7.193, 0.1103 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 13:46:13 visual_prompt]: 	Test 200/1152. loss: 7.561, 0.1079 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 13:46:29 visual_prompt]: 	Test 300/1152. loss: 8.296, 0.1079 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 13:46:44 visual_prompt]: 	Test 400/1152. loss: 8.840, 0.0987 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 13:46:59 visual_prompt]: 	Test 500/1152. loss: 8.997, 0.1213 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 13:47:15 visual_prompt]: 	Test 600/1152. loss: 8.250, 0.1231 s / batch. (data: 4.24e-05)max mem: 17.22454 GB 
[09/18 13:47:32 visual_prompt]: 	Test 700/1152. loss: 11.378, 0.1406 s / batch. (data: 2.29e-02)max mem: 17.22454 GB 
[09/18 13:47:48 visual_prompt]: 	Test 800/1152. loss: 9.379, 0.1200 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/18 13:48:04 visual_prompt]: 	Test 900/1152. loss: 8.895, 0.1008 s / batch. (data: 2.98e-05)max mem: 17.22454 GB 
[09/18 13:48:21 visual_prompt]: 	Test 1000/1152. loss: 8.624, 0.1111 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/18 13:48:37 visual_prompt]: 	Test 1100/1152. loss: 8.912, 0.1202 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 13:48:49 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1090, average loss: 9.3542
[09/18 13:48:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 27.69	
[09/18 13:48:50 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/18 13:49:00 visual_prompt]: Epoch 14 / 100: avg data time: 2.30e-01, avg batch time: 0.4639, average train loss: 10.1461
[09/18 13:49:07 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.0880, average loss: 18.0749
[09/18 13:49:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 28.50	
[09/18 13:49:27 visual_prompt]: 	Test 100/1152. loss: 15.769, 0.0972 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 13:49:42 visual_prompt]: 	Test 200/1152. loss: 17.098, 0.1105 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 13:49:58 visual_prompt]: 	Test 300/1152. loss: 16.053, 0.1154 s / batch. (data: 3.08e-05)max mem: 17.22454 GB 
[09/18 13:50:13 visual_prompt]: 	Test 400/1152. loss: 14.839, 0.1357 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 13:50:28 visual_prompt]: 	Test 500/1152. loss: 16.597, 0.0979 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 13:50:44 visual_prompt]: 	Test 600/1152. loss: 14.560, 0.0972 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 13:51:00 visual_prompt]: 	Test 700/1152. loss: 16.526, 0.1007 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/18 13:51:16 visual_prompt]: 	Test 800/1152. loss: 17.511, 0.1078 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/18 13:51:33 visual_prompt]: 	Test 900/1152. loss: 15.292, 0.1155 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 13:51:49 visual_prompt]: 	Test 1000/1152. loss: 16.504, 0.1080 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 13:52:06 visual_prompt]: 	Test 1100/1152. loss: 19.953, 0.1110 s / batch. (data: 1.44e-02)max mem: 17.22454 GB 
[09/18 13:52:18 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1086, average loss: 17.2162
[09/18 13:52:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 30.12	
[09/18 13:52:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/18 13:52:29 visual_prompt]: Epoch 15 / 100: avg data time: 2.33e-01, avg batch time: 0.4623, average train loss: 17.3541
[09/18 13:52:36 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.0893, average loss: 18.0552
[09/18 13:52:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 35.00	
[09/18 13:52:55 visual_prompt]: 	Test 100/1152. loss: 22.860, 0.1211 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/18 13:53:11 visual_prompt]: 	Test 200/1152. loss: 17.704, 0.1001 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 13:53:27 visual_prompt]: 	Test 300/1152. loss: 18.085, 0.1014 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/18 13:53:42 visual_prompt]: 	Test 400/1152. loss: 19.491, 0.1168 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 13:53:57 visual_prompt]: 	Test 500/1152. loss: 19.245, 0.1117 s / batch. (data: 9.20e-05)max mem: 17.22454 GB 
[09/18 13:54:13 visual_prompt]: 	Test 600/1152. loss: 18.197, 0.0948 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/18 13:54:29 visual_prompt]: 	Test 700/1152. loss: 17.648, 0.1425 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 13:54:45 visual_prompt]: 	Test 800/1152. loss: 20.658, 0.1038 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 13:55:02 visual_prompt]: 	Test 900/1152. loss: 21.116, 0.0980 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 13:55:18 visual_prompt]: 	Test 1000/1152. loss: 22.577, 0.0999 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 13:55:35 visual_prompt]: 	Test 1100/1152. loss: 20.834, 0.1173 s / batch. (data: 2.07e-02)max mem: 17.22454 GB 
[09/18 13:55:47 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1086, average loss: 18.8020
[09/18 13:55:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 35.08	
[09/18 13:55:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/18 13:55:57 visual_prompt]: Epoch 16 / 100: avg data time: 2.34e-01, avg batch time: 0.4644, average train loss: 13.6380
[09/18 13:56:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0941, average loss: 9.6621
[09/18 13:56:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 29.50	
[09/18 13:56:24 visual_prompt]: 	Test 100/1152. loss: 10.801, 0.1114 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/18 13:56:40 visual_prompt]: 	Test 200/1152. loss: 8.194, 0.0980 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 13:56:55 visual_prompt]: 	Test 300/1152. loss: 7.598, 0.0981 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 13:57:10 visual_prompt]: 	Test 400/1152. loss: 8.591, 0.1201 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 13:57:26 visual_prompt]: 	Test 500/1152. loss: 8.733, 0.0953 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 13:57:41 visual_prompt]: 	Test 600/1152. loss: 8.457, 0.1004 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/18 13:57:58 visual_prompt]: 	Test 700/1152. loss: 8.113, 0.1482 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/18 13:58:14 visual_prompt]: 	Test 800/1152. loss: 8.269, 0.0980 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 13:58:30 visual_prompt]: 	Test 900/1152. loss: 11.103, 0.0984 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 13:58:47 visual_prompt]: 	Test 1000/1152. loss: 9.070, 0.1247 s / batch. (data: 7.12e-03)max mem: 17.22454 GB 
[09/18 13:59:04 visual_prompt]: 	Test 1100/1152. loss: 10.091, 0.0999 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 13:59:16 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1082, average loss: 8.9726
[09/18 13:59:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 34.94	
[09/18 13:59:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/18 13:59:27 visual_prompt]: Epoch 17 / 100: avg data time: 2.31e-01, avg batch time: 0.4594, average train loss: 9.3515
[09/18 13:59:34 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.0941, average loss: 6.0761
[09/18 13:59:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 35.00	
[09/18 13:59:54 visual_prompt]: 	Test 100/1152. loss: 6.851, 0.1202 s / batch. (data: 7.69e-03)max mem: 17.22454 GB 
[09/18 14:00:09 visual_prompt]: 	Test 200/1152. loss: 5.786, 0.1056 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/18 14:00:25 visual_prompt]: 	Test 300/1152. loss: 5.747, 0.0951 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 14:00:40 visual_prompt]: 	Test 400/1152. loss: 5.772, 0.0972 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 14:00:56 visual_prompt]: 	Test 500/1152. loss: 5.787, 0.1086 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 14:01:11 visual_prompt]: 	Test 600/1152. loss: 5.675, 0.0975 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 14:01:27 visual_prompt]: 	Test 700/1152. loss: 5.365, 0.0957 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 14:01:43 visual_prompt]: 	Test 800/1152. loss: 5.987, 0.1070 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 14:02:00 visual_prompt]: 	Test 900/1152. loss: 6.417, 0.0987 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 14:02:17 visual_prompt]: 	Test 1000/1152. loss: 5.958, 0.1039 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/18 14:02:33 visual_prompt]: 	Test 1100/1152. loss: 7.344, 0.1231 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/18 14:02:45 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1084, average loss: 5.9718
[09/18 14:02:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 35.08	
[09/18 14:02:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/18 14:02:55 visual_prompt]: Epoch 18 / 100: avg data time: 2.39e-01, avg batch time: 0.4646, average train loss: 5.1336
[09/18 14:03:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0949, average loss: 4.0831
[09/18 14:03:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 30.00	
[09/18 14:03:22 visual_prompt]: 	Test 100/1152. loss: 3.782, 0.0947 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/18 14:03:38 visual_prompt]: 	Test 200/1152. loss: 4.260, 0.0947 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/18 14:03:53 visual_prompt]: 	Test 300/1152. loss: 3.819, 0.1026 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/18 14:04:08 visual_prompt]: 	Test 400/1152. loss: 4.281, 0.1082 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 14:04:24 visual_prompt]: 	Test 500/1152. loss: 4.123, 0.1050 s / batch. (data: 8.79e-03)max mem: 17.22454 GB 
[09/18 14:04:40 visual_prompt]: 	Test 600/1152. loss: 4.107, 0.1227 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/18 14:04:56 visual_prompt]: 	Test 700/1152. loss: 4.357, 0.1079 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:05:13 visual_prompt]: 	Test 800/1152. loss: 3.957, 0.0983 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 14:05:30 visual_prompt]: 	Test 900/1152. loss: 4.398, 0.1054 s / batch. (data: 9.32e-05)max mem: 17.22454 GB 
[09/18 14:05:46 visual_prompt]: 	Test 1000/1152. loss: 4.557, 0.0965 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/18 14:06:02 visual_prompt]: 	Test 1100/1152. loss: 3.754, 0.1140 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 14:06:14 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1084, average loss: 4.1690
[09/18 14:06:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 27.37	
[09/18 14:06:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/18 14:06:25 visual_prompt]: Epoch 19 / 100: avg data time: 2.32e-01, avg batch time: 0.4571, average train loss: 3.8544
[09/18 14:06:32 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.0922, average loss: 3.4070
[09/18 14:06:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 37.50	
[09/18 14:06:51 visual_prompt]: 	Test 100/1152. loss: 3.795, 0.1061 s / batch. (data: 9.47e-05)max mem: 17.22454 GB 
[09/18 14:07:07 visual_prompt]: 	Test 200/1152. loss: 3.218, 0.0953 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/18 14:07:22 visual_prompt]: 	Test 300/1152. loss: 3.905, 0.1142 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/18 14:07:38 visual_prompt]: 	Test 400/1152. loss: 3.899, 0.0944 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/18 14:07:53 visual_prompt]: 	Test 500/1152. loss: 3.599, 0.1297 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/18 14:08:09 visual_prompt]: 	Test 600/1152. loss: 3.596, 0.0947 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/18 14:08:25 visual_prompt]: 	Test 700/1152. loss: 3.649, 0.0950 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 14:08:41 visual_prompt]: 	Test 800/1152. loss: 3.814, 0.0983 s / batch. (data: 7.18e-05)max mem: 17.22454 GB 
[09/18 14:08:57 visual_prompt]: 	Test 900/1152. loss: 3.654, 0.0949 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 14:09:14 visual_prompt]: 	Test 1000/1152. loss: 3.705, 0.0966 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 14:09:29 visual_prompt]: 	Test 1100/1152. loss: 3.489, 0.1224 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 14:09:42 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1088, average loss: 3.5888
[09/18 14:09:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.48	
[09/18 14:09:42 visual_prompt]: Best epoch 19: best metric: 0.105
[09/18 14:09:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/18 14:09:53 visual_prompt]: Epoch 20 / 100: avg data time: 2.24e-01, avg batch time: 0.4506, average train loss: 3.4044
[09/18 14:10:00 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0864, average loss: 3.4055
[09/18 14:10:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 33.50	
[09/18 14:10:19 visual_prompt]: 	Test 100/1152. loss: 3.388, 0.1078 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 14:10:35 visual_prompt]: 	Test 200/1152. loss: 3.486, 0.1098 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 14:10:50 visual_prompt]: 	Test 300/1152. loss: 3.332, 0.1077 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 14:11:05 visual_prompt]: 	Test 400/1152. loss: 3.349, 0.0987 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 14:11:21 visual_prompt]: 	Test 500/1152. loss: 3.322, 0.0968 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 14:11:37 visual_prompt]: 	Test 600/1152. loss: 3.297, 0.1226 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/18 14:11:53 visual_prompt]: 	Test 700/1152. loss: 3.259, 0.0951 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 14:12:09 visual_prompt]: 	Test 800/1152. loss: 3.277, 0.1130 s / batch. (data: 6.70e-05)max mem: 17.22454 GB 
[09/18 14:12:26 visual_prompt]: 	Test 900/1152. loss: 3.283, 0.0977 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/18 14:12:42 visual_prompt]: 	Test 1000/1152. loss: 3.273, 0.0948 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/18 14:12:58 visual_prompt]: 	Test 1100/1152. loss: 3.609, 0.0984 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/18 14:13:10 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1083, average loss: 3.3876
[09/18 14:13:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.36	
[09/18 14:13:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/18 14:13:21 visual_prompt]: Epoch 21 / 100: avg data time: 2.34e-01, avg batch time: 0.4544, average train loss: 3.3324
[09/18 14:13:28 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.0928, average loss: 3.3883
[09/18 14:13:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 33.00	
[09/18 14:13:47 visual_prompt]: 	Test 100/1152. loss: 3.598, 0.1117 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 14:14:02 visual_prompt]: 	Test 200/1152. loss: 3.427, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 14:14:18 visual_prompt]: 	Test 300/1152. loss: 3.610, 0.0967 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 14:14:33 visual_prompt]: 	Test 400/1152. loss: 3.400, 0.1120 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 14:14:49 visual_prompt]: 	Test 500/1152. loss: 3.381, 0.1039 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 14:15:04 visual_prompt]: 	Test 600/1152. loss: 3.525, 0.1032 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/18 14:15:20 visual_prompt]: 	Test 700/1152. loss: 3.307, 0.1025 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/18 14:15:37 visual_prompt]: 	Test 800/1152. loss: 3.488, 0.0945 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:15:53 visual_prompt]: 	Test 900/1152. loss: 3.590, 0.1071 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 14:16:10 visual_prompt]: 	Test 1000/1152. loss: 3.739, 0.0975 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/18 14:16:26 visual_prompt]: 	Test 1100/1152. loss: 3.456, 0.0956 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 14:16:38 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1089, average loss: 3.4152
[09/18 14:16:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.58	
[09/18 14:16:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/18 14:16:49 visual_prompt]: Epoch 22 / 100: avg data time: 2.34e-01, avg batch time: 0.4620, average train loss: 3.2896
[09/18 14:16:56 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0867, average loss: 3.0227
[09/18 14:16:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 31.50	
[09/18 14:17:16 visual_prompt]: 	Test 100/1152. loss: 2.995, 0.0968 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 14:17:31 visual_prompt]: 	Test 200/1152. loss: 3.076, 0.0970 s / batch. (data: 8.51e-05)max mem: 17.22454 GB 
[09/18 14:17:47 visual_prompt]: 	Test 300/1152. loss: 2.958, 0.1109 s / batch. (data: 2.63e-03)max mem: 17.22454 GB 
[09/18 14:18:02 visual_prompt]: 	Test 400/1152. loss: 3.048, 0.0968 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 14:18:17 visual_prompt]: 	Test 500/1152. loss: 3.023, 0.1074 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 14:18:33 visual_prompt]: 	Test 600/1152. loss: 2.970, 0.1014 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/18 14:18:49 visual_prompt]: 	Test 700/1152. loss: 3.047, 0.1482 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 14:19:05 visual_prompt]: 	Test 800/1152. loss: 2.905, 0.1063 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 14:19:22 visual_prompt]: 	Test 900/1152. loss: 2.936, 0.0948 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 14:19:38 visual_prompt]: 	Test 1000/1152. loss: 2.937, 0.1430 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 14:19:55 visual_prompt]: 	Test 1100/1152. loss: 2.952, 0.1273 s / batch. (data: 2.66e-02)max mem: 17.22454 GB 
[09/18 14:20:07 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1091, average loss: 3.0113
[09/18 14:20:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 32.40	
[09/18 14:20:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/18 14:20:18 visual_prompt]: Epoch 23 / 100: avg data time: 2.37e-01, avg batch time: 0.4652, average train loss: 3.0599
[09/18 14:20:25 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.0866, average loss: 3.0615
[09/18 14:20:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 32.50	
[09/18 14:20:44 visual_prompt]: 	Test 100/1152. loss: 3.047, 0.1247 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 14:21:00 visual_prompt]: 	Test 200/1152. loss: 3.051, 0.0965 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 14:21:15 visual_prompt]: 	Test 300/1152. loss: 2.879, 0.1097 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 14:21:31 visual_prompt]: 	Test 400/1152. loss: 2.971, 0.1038 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 14:21:47 visual_prompt]: 	Test 500/1152. loss: 3.042, 0.0979 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 14:22:02 visual_prompt]: 	Test 600/1152. loss: 2.946, 0.1069 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 14:22:19 visual_prompt]: 	Test 700/1152. loss: 3.067, 0.1005 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 14:22:36 visual_prompt]: 	Test 800/1152. loss: 3.073, 0.1171 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 14:22:52 visual_prompt]: 	Test 900/1152. loss: 3.138, 0.0970 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 14:23:09 visual_prompt]: 	Test 1000/1152. loss: 3.152, 0.1040 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 14:23:25 visual_prompt]: 	Test 1100/1152. loss: 3.088, 0.0954 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/18 14:23:37 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1088, average loss: 3.0357
[09/18 14:23:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.02	
[09/18 14:23:38 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/18 14:23:48 visual_prompt]: Epoch 24 / 100: avg data time: 2.38e-01, avg batch time: 0.4622, average train loss: 3.0158
[09/18 14:23:56 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.0910, average loss: 2.8237
[09/18 14:23:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 35.50	
[09/18 14:24:15 visual_prompt]: 	Test 100/1152. loss: 2.820, 0.1137 s / batch. (data: 2.93e-05)max mem: 17.22454 GB 
[09/18 14:24:31 visual_prompt]: 	Test 200/1152. loss: 2.787, 0.1360 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 14:24:46 visual_prompt]: 	Test 300/1152. loss: 2.771, 0.1197 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 14:25:01 visual_prompt]: 	Test 400/1152. loss: 2.781, 0.1199 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 14:25:17 visual_prompt]: 	Test 500/1152. loss: 2.875, 0.1453 s / batch. (data: 1.84e-02)max mem: 17.22454 GB 
[09/18 14:25:33 visual_prompt]: 	Test 600/1152. loss: 2.840, 0.1117 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 14:25:49 visual_prompt]: 	Test 700/1152. loss: 2.831, 0.0974 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 14:26:06 visual_prompt]: 	Test 800/1152. loss: 2.793, 0.1278 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 14:26:22 visual_prompt]: 	Test 900/1152. loss: 2.812, 0.1215 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/18 14:26:38 visual_prompt]: 	Test 1000/1152. loss: 2.765, 0.1041 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 14:26:54 visual_prompt]: 	Test 1100/1152. loss: 2.886, 0.0976 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 14:27:06 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1088, average loss: 2.8306
[09/18 14:27:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.08	
[09/18 14:27:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/18 14:27:17 visual_prompt]: Epoch 25 / 100: avg data time: 2.25e-01, avg batch time: 0.4543, average train loss: 2.9667
[09/18 14:27:24 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0956, average loss: 2.9573
[09/18 14:27:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 36.00	
[09/18 14:27:44 visual_prompt]: 	Test 100/1152. loss: 3.089, 0.1172 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 14:27:59 visual_prompt]: 	Test 200/1152. loss: 2.978, 0.1039 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 14:28:15 visual_prompt]: 	Test 300/1152. loss: 2.898, 0.1034 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 14:28:30 visual_prompt]: 	Test 400/1152. loss: 3.048, 0.0999 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 14:28:46 visual_prompt]: 	Test 500/1152. loss: 3.019, 0.1098 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 14:29:02 visual_prompt]: 	Test 600/1152. loss: 2.965, 0.1131 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 14:29:18 visual_prompt]: 	Test 700/1152. loss: 3.080, 0.1398 s / batch. (data: 2.18e-02)max mem: 17.22454 GB 
[09/18 14:29:34 visual_prompt]: 	Test 800/1152. loss: 3.075, 0.1116 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 14:29:51 visual_prompt]: 	Test 900/1152. loss: 3.056, 0.0979 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 14:30:07 visual_prompt]: 	Test 1000/1152. loss: 3.054, 0.0995 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:30:23 visual_prompt]: 	Test 1100/1152. loss: 2.933, 0.1002 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 14:30:35 visual_prompt]: Inference (test):avg data time: 2.41e-03, avg batch time: 0.1092, average loss: 2.9819
[09/18 14:30:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.67	
[09/18 14:30:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/18 14:30:46 visual_prompt]: Epoch 26 / 100: avg data time: 2.30e-01, avg batch time: 0.4571, average train loss: 3.0769
[09/18 14:30:53 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.0869, average loss: 3.2196
[09/18 14:30:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 29.50	
[09/18 14:31:13 visual_prompt]: 	Test 100/1152. loss: 3.270, 0.1064 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 14:31:29 visual_prompt]: 	Test 200/1152. loss: 3.072, 0.0947 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/18 14:31:44 visual_prompt]: 	Test 300/1152. loss: 2.789, 0.0948 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:31:59 visual_prompt]: 	Test 400/1152. loss: 3.040, 0.1190 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/18 14:32:15 visual_prompt]: 	Test 500/1152. loss: 3.156, 0.1051 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 14:32:31 visual_prompt]: 	Test 600/1152. loss: 3.067, 0.0982 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 14:32:47 visual_prompt]: 	Test 700/1152. loss: 3.000, 0.1175 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 14:33:03 visual_prompt]: 	Test 800/1152. loss: 3.112, 0.1229 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 14:33:20 visual_prompt]: 	Test 900/1152. loss: 3.310, 0.1021 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 14:33:36 visual_prompt]: 	Test 1000/1152. loss: 3.061, 0.0968 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 14:33:52 visual_prompt]: 	Test 1100/1152. loss: 3.156, 0.1119 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 14:34:04 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1087, average loss: 3.0853
[09/18 14:34:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.68	
[09/18 14:34:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/18 14:34:15 visual_prompt]: Epoch 27 / 100: avg data time: 2.36e-01, avg batch time: 0.4580, average train loss: 3.1501
[09/18 14:34:22 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.0906, average loss: 3.0116
[09/18 14:34:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 27.00	
[09/18 14:34:41 visual_prompt]: 	Test 100/1152. loss: 3.258, 0.0969 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 14:34:57 visual_prompt]: 	Test 200/1152. loss: 2.959, 0.0979 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 14:35:12 visual_prompt]: 	Test 300/1152. loss: 3.115, 0.1001 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 14:35:28 visual_prompt]: 	Test 400/1152. loss: 2.953, 0.1033 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 14:35:44 visual_prompt]: 	Test 500/1152. loss: 3.134, 0.0988 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 14:35:59 visual_prompt]: 	Test 600/1152. loss: 3.063, 0.1094 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 14:36:16 visual_prompt]: 	Test 700/1152. loss: 2.839, 0.1303 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/18 14:36:32 visual_prompt]: 	Test 800/1152. loss: 3.176, 0.1118 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 14:36:49 visual_prompt]: 	Test 900/1152. loss: 3.083, 0.1068 s / batch. (data: 8.63e-03)max mem: 17.22454 GB 
[09/18 14:37:05 visual_prompt]: 	Test 1000/1152. loss: 2.990, 0.1347 s / batch. (data: 9.16e-03)max mem: 17.22454 GB 
[09/18 14:37:21 visual_prompt]: 	Test 1100/1152. loss: 3.125, 0.1199 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:37:34 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1087, average loss: 3.0273
[09/18 14:37:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 30.02	
[09/18 14:37:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/18 14:37:44 visual_prompt]: Epoch 28 / 100: avg data time: 2.27e-01, avg batch time: 0.4549, average train loss: 3.0822
[09/18 14:37:51 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.0923, average loss: 3.1081
[09/18 14:37:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 31.50	
[09/18 14:38:11 visual_prompt]: 	Test 100/1152. loss: 3.191, 0.0989 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 14:38:27 visual_prompt]: 	Test 200/1152. loss: 3.096, 0.1110 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 14:38:42 visual_prompt]: 	Test 300/1152. loss: 3.072, 0.1038 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:38:58 visual_prompt]: 	Test 400/1152. loss: 3.181, 0.1023 s / batch. (data: 2.67e-05)max mem: 17.22454 GB 
[09/18 14:39:13 visual_prompt]: 	Test 500/1152. loss: 3.076, 0.1154 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 14:39:29 visual_prompt]: 	Test 600/1152. loss: 3.197, 0.1090 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 14:39:45 visual_prompt]: 	Test 700/1152. loss: 3.003, 0.0954 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 14:40:02 visual_prompt]: 	Test 800/1152. loss: 3.188, 0.0984 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/18 14:40:19 visual_prompt]: 	Test 900/1152. loss: 3.240, 0.0999 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 14:40:35 visual_prompt]: 	Test 1000/1152. loss: 3.176, 0.1348 s / batch. (data: 2.22e-02)max mem: 17.22454 GB 
[09/18 14:40:52 visual_prompt]: 	Test 1100/1152. loss: 3.047, 0.1156 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 14:41:04 visual_prompt]: Inference (test):avg data time: 1.50e-03, avg batch time: 0.1081, average loss: 3.0909
[09/18 14:41:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.51	top5: 33.09	
[09/18 14:41:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/18 14:41:15 visual_prompt]: Epoch 29 / 100: avg data time: 2.43e-01, avg batch time: 0.4667, average train loss: 3.1666
[09/18 14:41:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.0868, average loss: 3.1240
[09/18 14:41:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 28.00	
[09/18 14:41:42 visual_prompt]: 	Test 100/1152. loss: 3.163, 0.1228 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 14:41:57 visual_prompt]: 	Test 200/1152. loss: 3.158, 0.1061 s / batch. (data: 6.84e-05)max mem: 17.22454 GB 
[09/18 14:42:13 visual_prompt]: 	Test 300/1152. loss: 3.011, 0.1258 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 14:42:29 visual_prompt]: 	Test 400/1152. loss: 3.050, 0.1108 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/18 14:42:44 visual_prompt]: 	Test 500/1152. loss: 3.145, 0.1103 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 14:43:00 visual_prompt]: 	Test 600/1152. loss: 3.002, 0.1177 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/18 14:43:17 visual_prompt]: 	Test 700/1152. loss: 3.069, 0.0950 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/18 14:43:33 visual_prompt]: 	Test 800/1152. loss: 2.941, 0.0952 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 14:43:50 visual_prompt]: 	Test 900/1152. loss: 3.058, 0.0948 s / batch. (data: 6.56e-05)max mem: 17.22454 GB 
[09/18 14:44:06 visual_prompt]: 	Test 1000/1152. loss: 3.064, 0.0951 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/18 14:44:22 visual_prompt]: 	Test 1100/1152. loss: 3.159, 0.1172 s / batch. (data: 5.10e-05)max mem: 17.22454 GB 
[09/18 14:44:35 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1098, average loss: 3.0919
[09/18 14:44:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 29.82	
[09/18 14:44:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/18 14:44:46 visual_prompt]: Epoch 30 / 100: avg data time: 2.37e-01, avg batch time: 0.4657, average train loss: 3.2640
[09/18 14:44:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.0944, average loss: 3.2478
[09/18 14:44:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.50	
[09/18 14:45:12 visual_prompt]: 	Test 100/1152. loss: 3.309, 0.1271 s / batch. (data: 2.26e-02)max mem: 17.22454 GB 
[09/18 14:45:28 visual_prompt]: 	Test 200/1152. loss: 3.094, 0.0963 s / batch. (data: 9.42e-05)max mem: 17.22454 GB 
[09/18 14:45:43 visual_prompt]: 	Test 300/1152. loss: 3.362, 0.1039 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:45:58 visual_prompt]: 	Test 400/1152. loss: 3.201, 0.1198 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/18 14:46:13 visual_prompt]: 	Test 500/1152. loss: 3.432, 0.0981 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 14:46:29 visual_prompt]: 	Test 600/1152. loss: 3.259, 0.1326 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 14:46:46 visual_prompt]: 	Test 700/1152. loss: 3.250, 0.0982 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 14:47:02 visual_prompt]: 	Test 800/1152. loss: 3.499, 0.0947 s / batch. (data: 5.08e-05)max mem: 17.22454 GB 
[09/18 14:47:18 visual_prompt]: 	Test 900/1152. loss: 3.156, 0.1011 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/18 14:47:35 visual_prompt]: 	Test 1000/1152. loss: 3.459, 0.0976 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 14:47:51 visual_prompt]: 	Test 1100/1152. loss: 3.337, 0.1128 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/18 14:48:03 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1090, average loss: 3.3147
[09/18 14:48:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.82	
[09/18 14:48:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/18 14:48:14 visual_prompt]: Epoch 31 / 100: avg data time: 2.41e-01, avg batch time: 0.4647, average train loss: 3.1954
[09/18 14:48:21 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.0900, average loss: 2.8824
[09/18 14:48:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 29.50	
[09/18 14:48:40 visual_prompt]: 	Test 100/1152. loss: 2.900, 0.1119 s / batch. (data: 7.34e-03)max mem: 17.22454 GB 
[09/18 14:48:56 visual_prompt]: 	Test 200/1152. loss: 2.862, 0.0962 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 14:49:11 visual_prompt]: 	Test 300/1152. loss: 2.976, 0.0982 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 14:49:26 visual_prompt]: 	Test 400/1152. loss: 2.902, 0.1124 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/18 14:49:42 visual_prompt]: 	Test 500/1152. loss: 2.872, 0.1305 s / batch. (data: 9.96e-03)max mem: 17.22454 GB 
[09/18 14:49:57 visual_prompt]: 	Test 600/1152. loss: 2.873, 0.1041 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 14:50:14 visual_prompt]: 	Test 700/1152. loss: 2.950, 0.1025 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 14:50:31 visual_prompt]: 	Test 800/1152. loss: 2.842, 0.1557 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 14:50:47 visual_prompt]: 	Test 900/1152. loss: 2.876, 0.1076 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/18 14:51:04 visual_prompt]: 	Test 1000/1152. loss: 2.877, 0.0957 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/18 14:51:20 visual_prompt]: 	Test 1100/1152. loss: 2.950, 0.0952 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 14:51:32 visual_prompt]: Inference (test):avg data time: 1.41e-03, avg batch time: 0.1078, average loss: 2.8943
[09/18 14:51:33 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 30.70	
[09/18 14:51:33 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/18 14:51:43 visual_prompt]: Epoch 32 / 100: avg data time: 2.27e-01, avg batch time: 0.4588, average train loss: 3.0755
[09/18 14:51:50 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.0927, average loss: 3.0457
[09/18 14:51:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 27.50	
[09/18 14:52:09 visual_prompt]: 	Test 100/1152. loss: 2.910, 0.0961 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:52:25 visual_prompt]: 	Test 200/1152. loss: 3.071, 0.0977 s / batch. (data: 2.67e-05)max mem: 17.22454 GB 
[09/18 14:52:41 visual_prompt]: 	Test 300/1152. loss: 2.867, 0.1270 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 14:52:56 visual_prompt]: 	Test 400/1152. loss: 2.989, 0.1151 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 14:53:12 visual_prompt]: 	Test 500/1152. loss: 2.992, 0.1039 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:53:28 visual_prompt]: 	Test 600/1152. loss: 2.885, 0.0978 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 14:53:44 visual_prompt]: 	Test 700/1152. loss: 2.970, 0.1037 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 14:54:00 visual_prompt]: 	Test 800/1152. loss: 3.043, 0.1114 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 14:54:17 visual_prompt]: 	Test 900/1152. loss: 2.912, 0.1259 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/18 14:54:34 visual_prompt]: 	Test 1000/1152. loss: 2.921, 0.1156 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 14:54:50 visual_prompt]: 	Test 1100/1152. loss: 2.994, 0.1217 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:55:02 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1084, average loss: 3.0052
[09/18 14:55:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 30.05	
[09/18 14:55:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/18 14:55:12 visual_prompt]: Epoch 33 / 100: avg data time: 2.43e-01, avg batch time: 0.4648, average train loss: 3.0309
[09/18 14:55:19 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.0868, average loss: 2.8592
[09/18 14:55:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 41.00	
[09/18 14:55:39 visual_prompt]: 	Test 100/1152. loss: 3.100, 0.0991 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 14:55:54 visual_prompt]: 	Test 200/1152. loss: 2.992, 0.1038 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 14:56:10 visual_prompt]: 	Test 300/1152. loss: 3.012, 0.1159 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 14:56:25 visual_prompt]: 	Test 400/1152. loss: 3.037, 0.1084 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 14:56:41 visual_prompt]: 	Test 500/1152. loss: 2.985, 0.1079 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 14:56:56 visual_prompt]: 	Test 600/1152. loss: 3.071, 0.0973 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 14:57:13 visual_prompt]: 	Test 700/1152. loss: 2.971, 0.1040 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/18 14:57:29 visual_prompt]: 	Test 800/1152. loss: 3.022, 0.0965 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 14:57:45 visual_prompt]: 	Test 900/1152. loss: 3.066, 0.1058 s / batch. (data: 1.31e-05)max mem: 17.22454 GB 
[09/18 14:58:02 visual_prompt]: 	Test 1000/1152. loss: 3.108, 0.1209 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 14:58:18 visual_prompt]: 	Test 1100/1152. loss: 2.975, 0.1120 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 14:58:30 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1084, average loss: 2.9561
[09/18 14:58:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.58	
[09/18 14:58:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/18 14:58:41 visual_prompt]: Epoch 34 / 100: avg data time: 2.30e-01, avg batch time: 0.4569, average train loss: 3.0688
[09/18 14:58:48 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0944, average loss: 3.3244
[09/18 14:58:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.50	top5: 24.50	
[09/18 14:59:08 visual_prompt]: 	Test 100/1152. loss: 2.921, 0.1256 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 14:59:24 visual_prompt]: 	Test 200/1152. loss: 3.107, 0.0984 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 14:59:39 visual_prompt]: 	Test 300/1152. loss: 3.237, 0.0984 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 14:59:55 visual_prompt]: 	Test 400/1152. loss: 3.294, 0.0971 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:00:10 visual_prompt]: 	Test 500/1152. loss: 3.116, 0.1088 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 15:00:26 visual_prompt]: 	Test 600/1152. loss: 3.124, 0.1108 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 15:00:42 visual_prompt]: 	Test 700/1152. loss: 3.412, 0.1016 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 15:00:59 visual_prompt]: 	Test 800/1152. loss: 3.049, 0.0948 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:01:15 visual_prompt]: 	Test 900/1152. loss: 3.146, 0.1168 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/18 15:01:32 visual_prompt]: 	Test 1000/1152. loss: 2.965, 0.0945 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/18 15:01:48 visual_prompt]: 	Test 1100/1152. loss: 3.159, 0.0973 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 15:02:00 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1082, average loss: 3.2548
[09/18 15:02:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.71	top5: 30.00	
[09/18 15:02:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/18 15:02:10 visual_prompt]: Epoch 35 / 100: avg data time: 2.31e-01, avg batch time: 0.4564, average train loss: 3.1042
[09/18 15:02:18 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.0974, average loss: 2.9472
[09/18 15:02:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 32.50	
[09/18 15:02:37 visual_prompt]: 	Test 100/1152. loss: 3.215, 0.0981 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:02:53 visual_prompt]: 	Test 200/1152. loss: 3.265, 0.1000 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 15:03:08 visual_prompt]: 	Test 300/1152. loss: 3.114, 0.1087 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 15:03:23 visual_prompt]: 	Test 400/1152. loss: 3.164, 0.0993 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 15:03:39 visual_prompt]: 	Test 500/1152. loss: 3.057, 0.0954 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 15:03:54 visual_prompt]: 	Test 600/1152. loss: 3.161, 0.1091 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 15:04:10 visual_prompt]: 	Test 700/1152. loss: 2.949, 0.1046 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 15:04:27 visual_prompt]: 	Test 800/1152. loss: 3.102, 0.1199 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 15:04:43 visual_prompt]: 	Test 900/1152. loss: 3.074, 0.1125 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 15:05:00 visual_prompt]: 	Test 1000/1152. loss: 3.037, 0.0987 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 15:05:17 visual_prompt]: 	Test 1100/1152. loss: 3.059, 0.0994 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 15:05:29 visual_prompt]: Inference (test):avg data time: 1.77e-03, avg batch time: 0.1086, average loss: 3.0322
[09/18 15:05:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.47	
[09/18 15:05:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/18 15:05:40 visual_prompt]: Epoch 36 / 100: avg data time: 2.46e-01, avg batch time: 0.4666, average train loss: 3.0354
[09/18 15:05:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.0894, average loss: 2.8952
[09/18 15:05:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.50	
[09/18 15:06:07 visual_prompt]: 	Test 100/1152. loss: 3.046, 0.1333 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 15:06:22 visual_prompt]: 	Test 200/1152. loss: 2.933, 0.1508 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 15:06:38 visual_prompt]: 	Test 300/1152. loss: 2.956, 0.1482 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 15:06:53 visual_prompt]: 	Test 400/1152. loss: 2.943, 0.1040 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 15:07:08 visual_prompt]: 	Test 500/1152. loss: 2.949, 0.0963 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 15:07:24 visual_prompt]: 	Test 600/1152. loss: 2.927, 0.1215 s / batch. (data: 8.85e-03)max mem: 17.22454 GB 
[09/18 15:07:40 visual_prompt]: 	Test 700/1152. loss: 2.804, 0.0999 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 15:07:56 visual_prompt]: 	Test 800/1152. loss: 2.908, 0.1259 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 15:08:13 visual_prompt]: 	Test 900/1152. loss: 2.966, 0.1086 s / batch. (data: 1.17e-02)max mem: 17.22454 GB 
[09/18 15:08:29 visual_prompt]: 	Test 1000/1152. loss: 2.889, 0.1018 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 15:08:45 visual_prompt]: 	Test 1100/1152. loss: 3.018, 0.1100 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 15:08:58 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1088, average loss: 2.9349
[09/18 15:08:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.05	
[09/18 15:08:58 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/18 15:09:08 visual_prompt]: Epoch 37 / 100: avg data time: 2.34e-01, avg batch time: 0.4605, average train loss: 2.9601
[09/18 15:09:15 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.0906, average loss: 2.8837
[09/18 15:09:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 41.00	
[09/18 15:09:35 visual_prompt]: 	Test 100/1152. loss: 2.775, 0.1097 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 15:09:50 visual_prompt]: 	Test 200/1152. loss: 3.026, 0.1125 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 15:10:05 visual_prompt]: 	Test 300/1152. loss: 2.992, 0.0989 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 15:10:21 visual_prompt]: 	Test 400/1152. loss: 2.963, 0.0963 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 15:10:36 visual_prompt]: 	Test 500/1152. loss: 2.883, 0.1080 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 15:10:52 visual_prompt]: 	Test 600/1152. loss: 2.916, 0.1093 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/18 15:11:08 visual_prompt]: 	Test 700/1152. loss: 2.911, 0.1071 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 15:11:25 visual_prompt]: 	Test 800/1152. loss: 2.896, 0.1159 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 15:11:41 visual_prompt]: 	Test 900/1152. loss: 2.863, 0.1180 s / batch. (data: 4.41e-05)max mem: 17.22454 GB 
[09/18 15:11:58 visual_prompt]: 	Test 1000/1152. loss: 3.007, 0.1045 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 15:12:14 visual_prompt]: 	Test 1100/1152. loss: 2.881, 0.1120 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 15:12:26 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1092, average loss: 2.9541
[09/18 15:12:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 32.46	
[09/18 15:12:26 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/18 15:12:37 visual_prompt]: Epoch 38 / 100: avg data time: 2.38e-01, avg batch time: 0.4636, average train loss: 3.0130
[09/18 15:12:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.0898, average loss: 3.0001
[09/18 15:12:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 33.50	
[09/18 15:13:04 visual_prompt]: 	Test 100/1152. loss: 2.945, 0.0998 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 15:13:19 visual_prompt]: 	Test 200/1152. loss: 2.947, 0.1198 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 15:13:35 visual_prompt]: 	Test 300/1152. loss: 2.839, 0.0980 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 15:13:50 visual_prompt]: 	Test 400/1152. loss: 2.963, 0.0964 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 15:14:05 visual_prompt]: 	Test 500/1152. loss: 2.936, 0.0978 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 15:14:21 visual_prompt]: 	Test 600/1152. loss: 2.832, 0.1036 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 15:14:37 visual_prompt]: 	Test 700/1152. loss: 3.051, 0.1255 s / batch. (data: 8.93e-03)max mem: 17.22454 GB 
[09/18 15:14:54 visual_prompt]: 	Test 800/1152. loss: 2.944, 0.1052 s / batch. (data: 3.34e-05)max mem: 17.22454 GB 
[09/18 15:15:10 visual_prompt]: 	Test 900/1152. loss: 3.046, 0.1225 s / batch. (data: 2.57e-02)max mem: 17.22454 GB 
[09/18 15:15:26 visual_prompt]: 	Test 1000/1152. loss: 3.117, 0.0949 s / batch. (data: 5.13e-05)max mem: 17.22454 GB 
[09/18 15:15:43 visual_prompt]: 	Test 1100/1152. loss: 2.887, 0.1071 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 15:15:55 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1091, average loss: 2.9650
[09/18 15:15:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 32.62	
[09/18 15:15:55 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/18 15:16:06 visual_prompt]: Epoch 39 / 100: avg data time: 2.33e-01, avg batch time: 0.4610, average train loss: 3.0158
[09/18 15:16:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0952, average loss: 3.0017
[09/18 15:16:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 25.50	
[09/18 15:16:32 visual_prompt]: 	Test 100/1152. loss: 2.908, 0.1038 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 15:16:48 visual_prompt]: 	Test 200/1152. loss: 2.995, 0.1037 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 15:17:04 visual_prompt]: 	Test 300/1152. loss: 3.005, 0.1199 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 15:17:19 visual_prompt]: 	Test 400/1152. loss: 2.870, 0.1199 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 15:17:34 visual_prompt]: 	Test 500/1152. loss: 2.917, 0.0991 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 15:17:51 visual_prompt]: 	Test 600/1152. loss: 2.969, 0.1190 s / batch. (data: 6.51e-03)max mem: 17.22454 GB 
[09/18 15:18:07 visual_prompt]: 	Test 700/1152. loss: 2.837, 0.1054 s / batch. (data: 9.53e-03)max mem: 17.22454 GB 
[09/18 15:18:24 visual_prompt]: 	Test 800/1152. loss: 2.838, 0.1066 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 15:18:40 visual_prompt]: 	Test 900/1152. loss: 3.004, 0.0993 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 15:18:56 visual_prompt]: 	Test 1000/1152. loss: 2.968, 0.1313 s / batch. (data: 2.66e-02)max mem: 17.22454 GB 
[09/18 15:19:13 visual_prompt]: 	Test 1100/1152. loss: 2.957, 0.1240 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/18 15:19:25 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1082, average loss: 2.9590
[09/18 15:19:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 29.75	
[09/18 15:19:25 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/18 15:19:36 visual_prompt]: Epoch 40 / 100: avg data time: 2.42e-01, avg batch time: 0.4700, average train loss: 2.9343
[09/18 15:19:43 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.0926, average loss: 2.8496
[09/18 15:19:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 29.50	
[09/18 15:20:02 visual_prompt]: 	Test 100/1152. loss: 2.909, 0.0976 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 15:20:18 visual_prompt]: 	Test 200/1152. loss: 2.695, 0.0999 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 15:20:33 visual_prompt]: 	Test 300/1152. loss: 2.795, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 15:20:49 visual_prompt]: 	Test 400/1152. loss: 2.832, 0.1087 s / batch. (data: 8.46e-05)max mem: 17.22454 GB 
[09/18 15:21:04 visual_prompt]: 	Test 500/1152. loss: 2.871, 0.1053 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/18 15:21:20 visual_prompt]: 	Test 600/1152. loss: 2.786, 0.0962 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:21:36 visual_prompt]: 	Test 700/1152. loss: 2.795, 0.0987 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 15:21:52 visual_prompt]: 	Test 800/1152. loss: 2.828, 0.1079 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 15:22:09 visual_prompt]: 	Test 900/1152. loss: 2.866, 0.1079 s / batch. (data: 9.16e-05)max mem: 17.22454 GB 
[09/18 15:22:25 visual_prompt]: 	Test 1000/1152. loss: 2.803, 0.1205 s / batch. (data: 1.20e-02)max mem: 17.22454 GB 
[09/18 15:22:42 visual_prompt]: 	Test 1100/1152. loss: 2.886, 0.0951 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 15:22:54 visual_prompt]: Inference (test):avg data time: 1.58e-03, avg batch time: 0.1080, average loss: 2.8409
[09/18 15:22:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.76	
[09/18 15:22:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/18 15:23:05 visual_prompt]: Epoch 41 / 100: avg data time: 2.39e-01, avg batch time: 0.4644, average train loss: 2.9421
[09/18 15:23:11 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0951, average loss: 2.9658
[09/18 15:23:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 29.00	
[09/18 15:23:31 visual_prompt]: 	Test 100/1152. loss: 2.887, 0.1108 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/18 15:23:47 visual_prompt]: 	Test 200/1152. loss: 3.125, 0.1364 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/18 15:24:02 visual_prompt]: 	Test 300/1152. loss: 2.846, 0.1279 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/18 15:24:17 visual_prompt]: 	Test 400/1152. loss: 2.908, 0.0979 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 15:24:33 visual_prompt]: 	Test 500/1152. loss: 2.904, 0.1034 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 15:24:49 visual_prompt]: 	Test 600/1152. loss: 2.929, 0.1321 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/18 15:25:05 visual_prompt]: 	Test 700/1152. loss: 2.824, 0.0971 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 15:25:21 visual_prompt]: 	Test 800/1152. loss: 2.843, 0.1198 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 15:25:38 visual_prompt]: 	Test 900/1152. loss: 2.907, 0.0941 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 15:25:54 visual_prompt]: 	Test 1000/1152. loss: 2.865, 0.1079 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/18 15:26:10 visual_prompt]: 	Test 1100/1152. loss: 2.933, 0.0950 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 15:26:22 visual_prompt]: Inference (test):avg data time: 1.92e-03, avg batch time: 0.1088, average loss: 2.9239
[09/18 15:26:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 29.97	
[09/18 15:26:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/18 15:26:33 visual_prompt]: Epoch 42 / 100: avg data time: 2.35e-01, avg batch time: 0.4633, average train loss: 2.9415
[09/18 15:26:40 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.0869, average loss: 2.9308
[09/18 15:26:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.50	
[09/18 15:26:59 visual_prompt]: 	Test 100/1152. loss: 2.933, 0.1041 s / batch. (data: 3.37e-03)max mem: 17.22454 GB 
[09/18 15:27:15 visual_prompt]: 	Test 200/1152. loss: 2.988, 0.1007 s / batch. (data: 1.29e-05)max mem: 17.22454 GB 
[09/18 15:27:30 visual_prompt]: 	Test 300/1152. loss: 2.961, 0.1016 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 15:27:46 visual_prompt]: 	Test 400/1152. loss: 2.834, 0.1037 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 15:28:01 visual_prompt]: 	Test 500/1152. loss: 2.903, 0.1287 s / batch. (data: 1.36e-05)max mem: 17.22454 GB 
[09/18 15:28:17 visual_prompt]: 	Test 600/1152. loss: 2.854, 0.1072 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:28:34 visual_prompt]: 	Test 700/1152. loss: 2.801, 0.1327 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 15:28:50 visual_prompt]: 	Test 800/1152. loss: 2.894, 0.1118 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:29:07 visual_prompt]: 	Test 900/1152. loss: 2.910, 0.1138 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 15:29:23 visual_prompt]: 	Test 1000/1152. loss: 2.978, 0.1079 s / batch. (data: 2.74e-05)max mem: 17.22454 GB 
[09/18 15:29:39 visual_prompt]: 	Test 1100/1152. loss: 2.929, 0.0989 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 15:29:51 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1092, average loss: 2.9165
[09/18 15:29:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.65	
[09/18 15:29:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/18 15:30:02 visual_prompt]: Epoch 43 / 100: avg data time: 2.41e-01, avg batch time: 0.4690, average train loss: 2.9638
[09/18 15:30:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.0920, average loss: 2.9956
[09/18 15:30:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 31.00	
[09/18 15:30:28 visual_prompt]: 	Test 100/1152. loss: 3.081, 0.0977 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 15:30:44 visual_prompt]: 	Test 200/1152. loss: 2.818, 0.1216 s / batch. (data: 9.06e-03)max mem: 17.22454 GB 
[09/18 15:30:59 visual_prompt]: 	Test 300/1152. loss: 2.987, 0.1216 s / batch. (data: 2.46e-02)max mem: 17.22454 GB 
[09/18 15:31:14 visual_prompt]: 	Test 400/1152. loss: 3.108, 0.1112 s / batch. (data: 2.16e-04)max mem: 17.22454 GB 
[09/18 15:31:30 visual_prompt]: 	Test 500/1152. loss: 3.055, 0.1079 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 15:31:46 visual_prompt]: 	Test 600/1152. loss: 2.917, 0.1241 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:32:02 visual_prompt]: 	Test 700/1152. loss: 3.203, 0.1413 s / batch. (data: 2.46e-02)max mem: 17.22454 GB 
[09/18 15:32:18 visual_prompt]: 	Test 800/1152. loss: 3.094, 0.0984 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 15:32:35 visual_prompt]: 	Test 900/1152. loss: 3.013, 0.0978 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 15:32:51 visual_prompt]: 	Test 1000/1152. loss: 3.096, 0.1011 s / batch. (data: 3.26e-03)max mem: 17.22454 GB 
[09/18 15:33:07 visual_prompt]: 	Test 1100/1152. loss: 2.995, 0.1176 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 15:33:19 visual_prompt]: Inference (test):avg data time: 2.72e-03, avg batch time: 0.1098, average loss: 3.0174
[09/18 15:33:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.16	top5: 32.72	
[09/18 15:33:20 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/18 15:33:30 visual_prompt]: Epoch 44 / 100: avg data time: 2.43e-01, avg batch time: 0.4666, average train loss: 2.9523
[09/18 15:33:37 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.0959, average loss: 3.0313
[09/18 15:33:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 23.00	
[09/18 15:33:56 visual_prompt]: 	Test 100/1152. loss: 3.076, 0.0993 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 15:34:12 visual_prompt]: 	Test 200/1152. loss: 2.919, 0.1244 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/18 15:34:27 visual_prompt]: 	Test 300/1152. loss: 2.960, 0.1040 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 15:34:43 visual_prompt]: 	Test 400/1152. loss: 2.892, 0.1119 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/18 15:34:58 visual_prompt]: 	Test 500/1152. loss: 2.957, 0.1117 s / batch. (data: 7.12e-03)max mem: 17.22454 GB 
[09/18 15:35:14 visual_prompt]: 	Test 600/1152. loss: 2.979, 0.0961 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 15:35:30 visual_prompt]: 	Test 700/1152. loss: 3.049, 0.1284 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/18 15:35:47 visual_prompt]: 	Test 800/1152. loss: 2.932, 0.0950 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/18 15:36:03 visual_prompt]: 	Test 900/1152. loss: 3.062, 0.0943 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/18 15:36:20 visual_prompt]: 	Test 1000/1152. loss: 2.890, 0.0974 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 15:36:36 visual_prompt]: 	Test 1100/1152. loss: 3.133, 0.1132 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/18 15:36:48 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1085, average loss: 2.9715
[09/18 15:36:48 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.01	
[09/18 15:36:48 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/18 15:36:59 visual_prompt]: Epoch 45 / 100: avg data time: 2.33e-01, avg batch time: 0.4560, average train loss: 2.9396
[09/18 15:37:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0900, average loss: 2.7772
[09/18 15:37:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.00	
[09/18 15:37:25 visual_prompt]: 	Test 100/1152. loss: 2.809, 0.0964 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 15:37:41 visual_prompt]: 	Test 200/1152. loss: 2.741, 0.1207 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 15:37:56 visual_prompt]: 	Test 300/1152. loss: 2.777, 0.1110 s / batch. (data: 1.04e-02)max mem: 17.22454 GB 
[09/18 15:38:11 visual_prompt]: 	Test 400/1152. loss: 2.798, 0.1119 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 15:38:27 visual_prompt]: 	Test 500/1152. loss: 2.794, 0.1001 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 15:38:42 visual_prompt]: 	Test 600/1152. loss: 2.827, 0.0949 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 15:38:59 visual_prompt]: 	Test 700/1152. loss: 2.815, 0.1072 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/18 15:39:15 visual_prompt]: 	Test 800/1152. loss: 2.840, 0.0955 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 15:39:31 visual_prompt]: 	Test 900/1152. loss: 2.872, 0.0956 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 15:39:48 visual_prompt]: 	Test 1000/1152. loss: 2.834, 0.0979 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 15:40:04 visual_prompt]: 	Test 1100/1152. loss: 2.823, 0.1095 s / batch. (data: 5.10e-05)max mem: 17.22454 GB 
[09/18 15:40:16 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1081, average loss: 2.8025
[09/18 15:40:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 35.22	
[09/18 15:40:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/18 15:40:27 visual_prompt]: Epoch 46 / 100: avg data time: 2.32e-01, avg batch time: 0.4645, average train loss: 2.9321
[09/18 15:40:34 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.0866, average loss: 2.8466
[09/18 15:40:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 34.50	
[09/18 15:40:54 visual_prompt]: 	Test 100/1152. loss: 2.778, 0.1182 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 15:41:09 visual_prompt]: 	Test 200/1152. loss: 2.903, 0.1061 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 15:41:25 visual_prompt]: 	Test 300/1152. loss: 2.826, 0.0990 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 15:41:40 visual_prompt]: 	Test 400/1152. loss: 2.826, 0.1116 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 15:41:56 visual_prompt]: 	Test 500/1152. loss: 2.834, 0.1195 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 15:42:11 visual_prompt]: 	Test 600/1152. loss: 2.758, 0.1313 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 15:42:28 visual_prompt]: 	Test 700/1152. loss: 2.802, 0.1039 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 15:42:44 visual_prompt]: 	Test 800/1152. loss: 2.801, 0.0965 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 15:43:00 visual_prompt]: 	Test 900/1152. loss: 2.808, 0.1219 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 15:43:17 visual_prompt]: 	Test 1000/1152. loss: 2.937, 0.1060 s / batch. (data: 2.91e-05)max mem: 17.22454 GB 
[09/18 15:43:33 visual_prompt]: 	Test 1100/1152. loss: 2.865, 0.0973 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 15:43:45 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1086, average loss: 2.8694
[09/18 15:43:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.34	top5: 32.38	
[09/18 15:43:45 visual_prompt]: Best epoch 46: best metric: 0.115
[09/18 15:43:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/18 15:43:55 visual_prompt]: Epoch 47 / 100: avg data time: 2.31e-01, avg batch time: 0.4611, average train loss: 2.9756
[09/18 15:44:02 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.0898, average loss: 2.8996
[09/18 15:44:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 33.00	
[09/18 15:44:22 visual_prompt]: 	Test 100/1152. loss: 3.112, 0.0976 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 15:44:37 visual_prompt]: 	Test 200/1152. loss: 2.943, 0.1031 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 15:44:53 visual_prompt]: 	Test 300/1152. loss: 2.957, 0.1036 s / batch. (data: 7.98e-03)max mem: 17.22454 GB 
[09/18 15:45:08 visual_prompt]: 	Test 400/1152. loss: 2.939, 0.1244 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 15:45:24 visual_prompt]: 	Test 500/1152. loss: 3.096, 0.1098 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/18 15:45:39 visual_prompt]: 	Test 600/1152. loss: 3.075, 0.1113 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 15:45:56 visual_prompt]: 	Test 700/1152. loss: 2.871, 0.0950 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/18 15:46:12 visual_prompt]: 	Test 800/1152. loss: 3.061, 0.1396 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 15:46:29 visual_prompt]: 	Test 900/1152. loss: 2.946, 0.1028 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 15:46:46 visual_prompt]: 	Test 1000/1152. loss: 2.878, 0.1114 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/18 15:47:02 visual_prompt]: 	Test 1100/1152. loss: 3.028, 0.1517 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 15:47:14 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1084, average loss: 2.9539
[09/18 15:47:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.48	
[09/18 15:47:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/18 15:47:26 visual_prompt]: Epoch 48 / 100: avg data time: 2.55e-01, avg batch time: 0.4748, average train loss: 2.9575
[09/18 15:47:33 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.0961, average loss: 2.8135
[09/18 15:47:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 43.00	
[09/18 15:47:52 visual_prompt]: 	Test 100/1152. loss: 2.915, 0.1050 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 15:48:08 visual_prompt]: 	Test 200/1152. loss: 2.903, 0.1000 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 15:48:24 visual_prompt]: 	Test 300/1152. loss: 3.027, 0.0980 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 15:48:39 visual_prompt]: 	Test 400/1152. loss: 2.903, 0.1038 s / batch. (data: 3.15e-03)max mem: 17.22454 GB 
[09/18 15:48:54 visual_prompt]: 	Test 500/1152. loss: 2.924, 0.1159 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 15:49:10 visual_prompt]: 	Test 600/1152. loss: 2.959, 0.1109 s / batch. (data: 6.94e-05)max mem: 17.22454 GB 
[09/18 15:49:27 visual_prompt]: 	Test 700/1152. loss: 2.765, 0.1085 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 15:49:43 visual_prompt]: 	Test 800/1152. loss: 2.924, 0.1175 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/18 15:50:00 visual_prompt]: 	Test 900/1152. loss: 2.818, 0.1404 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 15:50:16 visual_prompt]: 	Test 1000/1152. loss: 2.862, 0.0984 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/18 15:50:32 visual_prompt]: 	Test 1100/1152. loss: 2.909, 0.1096 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 15:50:45 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1092, average loss: 2.8936
[09/18 15:50:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 31.76	
[09/18 15:50:45 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/18 15:50:56 visual_prompt]: Epoch 49 / 100: avg data time: 2.36e-01, avg batch time: 0.4617, average train loss: 2.8931
[09/18 15:51:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.0935, average loss: 2.9055
[09/18 15:51:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 39.50	
[09/18 15:51:22 visual_prompt]: 	Test 100/1152. loss: 2.791, 0.1079 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 15:51:38 visual_prompt]: 	Test 200/1152. loss: 2.819, 0.1040 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 15:51:53 visual_prompt]: 	Test 300/1152. loss: 2.895, 0.1189 s / batch. (data: 3.39e-05)max mem: 17.22454 GB 
[09/18 15:52:09 visual_prompt]: 	Test 400/1152. loss: 2.901, 0.1105 s / batch. (data: 9.83e-03)max mem: 17.22454 GB 
[09/18 15:52:24 visual_prompt]: 	Test 500/1152. loss: 2.913, 0.0974 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 15:52:40 visual_prompt]: 	Test 600/1152. loss: 2.959, 0.0971 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:52:56 visual_prompt]: 	Test 700/1152. loss: 3.032, 0.1022 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 15:53:13 visual_prompt]: 	Test 800/1152. loss: 2.885, 0.1218 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 15:53:30 visual_prompt]: 	Test 900/1152. loss: 2.950, 0.1040 s / batch. (data: 7.27e-03)max mem: 17.22454 GB 
[09/18 15:53:46 visual_prompt]: 	Test 1000/1152. loss: 2.916, 0.0952 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/18 15:54:03 visual_prompt]: 	Test 1100/1152. loss: 2.923, 0.0948 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/18 15:54:15 visual_prompt]: Inference (test):avg data time: 2.12e-03, avg batch time: 0.1093, average loss: 2.9317
[09/18 15:54:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.37	top5: 35.24	
[09/18 15:54:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/18 15:54:26 visual_prompt]: Epoch 50 / 100: avg data time: 2.40e-01, avg batch time: 0.4643, average train loss: 2.9404
[09/18 15:54:32 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.0864, average loss: 2.8665
[09/18 15:54:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 34.00	
[09/18 15:54:52 visual_prompt]: 	Test 100/1152. loss: 3.014, 0.0997 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 15:55:08 visual_prompt]: 	Test 200/1152. loss: 2.933, 0.1255 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 15:55:23 visual_prompt]: 	Test 300/1152. loss: 2.810, 0.1131 s / batch. (data: 3.89e-05)max mem: 17.22454 GB 
[09/18 15:55:39 visual_prompt]: 	Test 400/1152. loss: 2.915, 0.1123 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:55:54 visual_prompt]: 	Test 500/1152. loss: 2.845, 0.1480 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 15:56:10 visual_prompt]: 	Test 600/1152. loss: 2.925, 0.1038 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 15:56:26 visual_prompt]: 	Test 700/1152. loss: 2.837, 0.1159 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/18 15:56:43 visual_prompt]: 	Test 800/1152. loss: 2.924, 0.0993 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 15:56:59 visual_prompt]: 	Test 900/1152. loss: 3.039, 0.0951 s / batch. (data: 9.63e-05)max mem: 17.22454 GB 
[09/18 15:57:16 visual_prompt]: 	Test 1000/1152. loss: 2.946, 0.0951 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 15:57:32 visual_prompt]: 	Test 1100/1152. loss: 2.926, 0.1179 s / batch. (data: 8.17e-03)max mem: 17.22454 GB 
[09/18 15:57:44 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1090, average loss: 2.8657
[09/18 15:57:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.91	
[09/18 15:57:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/18 15:57:55 visual_prompt]: Epoch 51 / 100: avg data time: 2.39e-01, avg batch time: 0.4625, average train loss: 2.9633
[09/18 15:58:01 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.0898, average loss: 2.9465
[09/18 15:58:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 31.00	
[09/18 15:58:21 visual_prompt]: 	Test 100/1152. loss: 3.072, 0.0953 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 15:58:36 visual_prompt]: 	Test 200/1152. loss: 3.100, 0.0988 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 15:58:52 visual_prompt]: 	Test 300/1152. loss: 2.775, 0.0980 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 15:59:07 visual_prompt]: 	Test 400/1152. loss: 2.959, 0.1002 s / batch. (data: 3.96e-05)max mem: 17.22454 GB 
[09/18 15:59:22 visual_prompt]: 	Test 500/1152. loss: 2.931, 0.0969 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 15:59:38 visual_prompt]: 	Test 600/1152. loss: 2.929, 0.1086 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 15:59:55 visual_prompt]: 	Test 700/1152. loss: 2.922, 0.1041 s / batch. (data: 7.35e-03)max mem: 17.22454 GB 
[09/18 16:00:11 visual_prompt]: 	Test 800/1152. loss: 2.962, 0.1360 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 16:00:27 visual_prompt]: 	Test 900/1152. loss: 2.987, 0.1118 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 16:00:43 visual_prompt]: 	Test 1000/1152. loss: 2.927, 0.1024 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/18 16:01:00 visual_prompt]: 	Test 1100/1152. loss: 3.050, 0.1033 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 16:01:12 visual_prompt]: Inference (test):avg data time: 1.67e-03, avg batch time: 0.1087, average loss: 2.9329
[09/18 16:01:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.28	top5: 32.52	
[09/18 16:01:12 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/18 16:01:22 visual_prompt]: Epoch 52 / 100: avg data time: 2.38e-01, avg batch time: 0.4630, average train loss: 2.8928
[09/18 16:01:29 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.0860, average loss: 2.9027
[09/18 16:01:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 37.50	
[09/18 16:01:49 visual_prompt]: 	Test 100/1152. loss: 2.969, 0.0971 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 16:02:05 visual_prompt]: 	Test 200/1152. loss: 2.917, 0.1104 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 16:02:20 visual_prompt]: 	Test 300/1152. loss: 3.132, 0.0998 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/18 16:02:35 visual_prompt]: 	Test 400/1152. loss: 2.918, 0.0983 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 16:02:51 visual_prompt]: 	Test 500/1152. loss: 3.057, 0.1039 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:03:07 visual_prompt]: 	Test 600/1152. loss: 3.005, 0.1062 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 16:03:23 visual_prompt]: 	Test 700/1152. loss: 2.945, 0.1084 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 16:03:39 visual_prompt]: 	Test 800/1152. loss: 3.032, 0.1079 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 16:03:56 visual_prompt]: 	Test 900/1152. loss: 2.858, 0.1199 s / batch. (data: 1.12e-05)max mem: 17.22454 GB 
[09/18 16:04:12 visual_prompt]: 	Test 1000/1152. loss: 2.981, 0.0979 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 16:04:28 visual_prompt]: 	Test 1100/1152. loss: 3.074, 0.1295 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:04:40 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1085, average loss: 3.0063
[09/18 16:04:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.33	
[09/18 16:04:41 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/18 16:04:51 visual_prompt]: Epoch 53 / 100: avg data time: 2.31e-01, avg batch time: 0.4581, average train loss: 2.9608
[09/18 16:04:58 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.0894, average loss: 3.1324
[09/18 16:04:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 32.50	
[09/18 16:05:18 visual_prompt]: 	Test 100/1152. loss: 3.219, 0.1008 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 16:05:34 visual_prompt]: 	Test 200/1152. loss: 3.214, 0.0977 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:05:49 visual_prompt]: 	Test 300/1152. loss: 3.187, 0.1118 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 16:06:05 visual_prompt]: 	Test 400/1152. loss: 3.067, 0.0980 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 16:06:20 visual_prompt]: 	Test 500/1152. loss: 3.161, 0.1164 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 16:06:36 visual_prompt]: 	Test 600/1152. loss: 3.161, 0.1046 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 16:06:53 visual_prompt]: 	Test 700/1152. loss: 2.820, 0.1120 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/18 16:07:09 visual_prompt]: 	Test 800/1152. loss: 3.052, 0.1032 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 16:07:26 visual_prompt]: 	Test 900/1152. loss: 3.127, 0.0966 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 16:07:42 visual_prompt]: 	Test 1000/1152. loss: 3.046, 0.0994 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 16:07:59 visual_prompt]: 	Test 1100/1152. loss: 3.098, 0.0996 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 16:08:11 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1088, average loss: 3.0865
[09/18 16:08:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.36	top5: 30.56	
[09/18 16:08:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/18 16:08:22 visual_prompt]: Epoch 54 / 100: avg data time: 2.28e-01, avg batch time: 0.4538, average train loss: 2.9344
[09/18 16:08:29 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.0926, average loss: 2.9554
[09/18 16:08:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 26.50	
[09/18 16:08:48 visual_prompt]: 	Test 100/1152. loss: 3.120, 0.1165 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:09:04 visual_prompt]: 	Test 200/1152. loss: 3.134, 0.1346 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 16:09:19 visual_prompt]: 	Test 300/1152. loss: 2.760, 0.0986 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 16:09:35 visual_prompt]: 	Test 400/1152. loss: 2.894, 0.1016 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 16:09:50 visual_prompt]: 	Test 500/1152. loss: 2.963, 0.1036 s / batch. (data: 9.47e-05)max mem: 17.22454 GB 
[09/18 16:10:06 visual_prompt]: 	Test 600/1152. loss: 2.894, 0.1032 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 16:10:23 visual_prompt]: 	Test 700/1152. loss: 2.696, 0.1421 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 16:10:39 visual_prompt]: 	Test 800/1152. loss: 2.906, 0.1019 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 16:10:56 visual_prompt]: 	Test 900/1152. loss: 2.985, 0.1058 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 16:11:13 visual_prompt]: 	Test 1000/1152. loss: 2.935, 0.0977 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 16:11:28 visual_prompt]: 	Test 1100/1152. loss: 3.107, 0.1001 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 16:11:41 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1084, average loss: 2.9345
[09/18 16:11:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.87	top5: 32.20	
[09/18 16:11:41 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/18 16:11:52 visual_prompt]: Epoch 55 / 100: avg data time: 2.29e-01, avg batch time: 0.4561, average train loss: 2.8843
[09/18 16:11:59 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.0960, average loss: 2.8682
[09/18 16:11:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 38.00	
[09/18 16:12:18 visual_prompt]: 	Test 100/1152. loss: 2.891, 0.0955 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 16:12:34 visual_prompt]: 	Test 200/1152. loss: 3.066, 0.1172 s / batch. (data: 4.84e-03)max mem: 17.22454 GB 
[09/18 16:12:49 visual_prompt]: 	Test 300/1152. loss: 2.921, 0.0968 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 16:13:04 visual_prompt]: 	Test 400/1152. loss: 2.935, 0.1417 s / batch. (data: 2.81e-02)max mem: 17.22454 GB 
[09/18 16:13:20 visual_prompt]: 	Test 500/1152. loss: 2.904, 0.1037 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 16:13:36 visual_prompt]: 	Test 600/1152. loss: 3.010, 0.1096 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 16:13:52 visual_prompt]: 	Test 700/1152. loss: 2.918, 0.0942 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 16:14:09 visual_prompt]: 	Test 800/1152. loss: 2.875, 0.1068 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 16:14:25 visual_prompt]: 	Test 900/1152. loss: 2.920, 0.1131 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/18 16:14:42 visual_prompt]: 	Test 1000/1152. loss: 2.892, 0.0953 s / batch. (data: 5.08e-05)max mem: 17.22454 GB 
[09/18 16:14:58 visual_prompt]: 	Test 1100/1152. loss: 2.987, 0.0987 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 16:15:10 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1086, average loss: 2.9177
[09/18 16:15:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 36.44	
[09/18 16:15:10 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/18 16:15:21 visual_prompt]: Epoch 56 / 100: avg data time: 2.33e-01, avg batch time: 0.4593, average train loss: 2.8306
[09/18 16:15:28 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.0876, average loss: 2.8303
[09/18 16:15:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 39.00	
[09/18 16:15:47 visual_prompt]: 	Test 100/1152. loss: 2.960, 0.0996 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:16:03 visual_prompt]: 	Test 200/1152. loss: 2.929, 0.1021 s / batch. (data: 4.95e-03)max mem: 17.22454 GB 
[09/18 16:16:19 visual_prompt]: 	Test 300/1152. loss: 2.939, 0.1134 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:16:34 visual_prompt]: 	Test 400/1152. loss: 3.022, 0.1086 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 16:16:49 visual_prompt]: 	Test 500/1152. loss: 2.942, 0.1069 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 16:17:05 visual_prompt]: 	Test 600/1152. loss: 2.939, 0.1196 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 16:17:22 visual_prompt]: 	Test 700/1152. loss: 2.924, 0.0958 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:17:38 visual_prompt]: 	Test 800/1152. loss: 2.895, 0.0994 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 16:17:55 visual_prompt]: 	Test 900/1152. loss: 2.892, 0.1078 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:18:12 visual_prompt]: 	Test 1000/1152. loss: 2.924, 0.1366 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/18 16:18:28 visual_prompt]: 	Test 1100/1152. loss: 2.927, 0.1013 s / batch. (data: 4.03e-05)max mem: 17.22454 GB 
[09/18 16:18:41 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1088, average loss: 2.9072
[09/18 16:18:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 33.27	
[09/18 16:18:41 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/18 16:18:51 visual_prompt]: Epoch 57 / 100: avg data time: 2.37e-01, avg batch time: 0.4565, average train loss: 2.8806
[09/18 16:18:58 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0938, average loss: 2.8494
[09/18 16:18:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 31.00	
[09/18 16:19:18 visual_prompt]: 	Test 100/1152. loss: 2.929, 0.0950 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/18 16:19:34 visual_prompt]: 	Test 200/1152. loss: 2.945, 0.1256 s / batch. (data: 3.06e-02)max mem: 17.22454 GB 
[09/18 16:19:50 visual_prompt]: 	Test 300/1152. loss: 2.782, 0.1153 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/18 16:20:05 visual_prompt]: 	Test 400/1152. loss: 2.808, 0.0993 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 16:20:21 visual_prompt]: 	Test 500/1152. loss: 2.912, 0.0980 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 16:20:36 visual_prompt]: 	Test 600/1152. loss: 2.876, 0.1109 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:20:53 visual_prompt]: 	Test 700/1152. loss: 2.753, 0.1663 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 16:21:09 visual_prompt]: 	Test 800/1152. loss: 2.888, 0.1109 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 16:21:26 visual_prompt]: 	Test 900/1152. loss: 2.832, 0.1070 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 16:21:42 visual_prompt]: 	Test 1000/1152. loss: 2.816, 0.1132 s / batch. (data: 8.52e-03)max mem: 17.22454 GB 
[09/18 16:21:58 visual_prompt]: 	Test 1100/1152. loss: 2.886, 0.1118 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/18 16:22:11 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1100, average loss: 2.8451
[09/18 16:22:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 31.26	
[09/18 16:22:11 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/18 16:22:21 visual_prompt]: Epoch 58 / 100: avg data time: 2.41e-01, avg batch time: 0.4678, average train loss: 2.8954
[09/18 16:22:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.0964, average loss: 2.9331
[09/18 16:22:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 37.00	
[09/18 16:22:48 visual_prompt]: 	Test 100/1152. loss: 3.169, 0.1119 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 16:23:03 visual_prompt]: 	Test 200/1152. loss: 2.998, 0.0999 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:23:19 visual_prompt]: 	Test 300/1152. loss: 2.961, 0.1274 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:23:34 visual_prompt]: 	Test 400/1152. loss: 2.990, 0.1217 s / batch. (data: 9.03e-03)max mem: 17.22454 GB 
[09/18 16:23:49 visual_prompt]: 	Test 500/1152. loss: 3.044, 0.1078 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 16:24:05 visual_prompt]: 	Test 600/1152. loss: 2.959, 0.1187 s / batch. (data: 1.17e-02)max mem: 17.22454 GB 
[09/18 16:24:22 visual_prompt]: 	Test 700/1152. loss: 2.916, 0.1128 s / batch. (data: 3.46e-05)max mem: 17.22454 GB 
[09/18 16:24:38 visual_prompt]: 	Test 800/1152. loss: 3.040, 0.1079 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/18 16:24:54 visual_prompt]: 	Test 900/1152. loss: 2.995, 0.1302 s / batch. (data: 2.29e-02)max mem: 17.22454 GB 
[09/18 16:25:11 visual_prompt]: 	Test 1000/1152. loss: 2.988, 0.1362 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 16:25:27 visual_prompt]: 	Test 1100/1152. loss: 2.960, 0.0970 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:25:40 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1087, average loss: 2.9523
[09/18 16:25:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.07	top5: 34.59	
[09/18 16:25:40 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/18 16:25:50 visual_prompt]: Epoch 59 / 100: avg data time: 2.36e-01, avg batch time: 0.4591, average train loss: 2.8929
[09/18 16:25:57 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.0912, average loss: 2.8402
[09/18 16:25:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 34.00	
[09/18 16:26:17 visual_prompt]: 	Test 100/1152. loss: 2.968, 0.0983 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 16:26:33 visual_prompt]: 	Test 200/1152. loss: 3.063, 0.1044 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 16:26:49 visual_prompt]: 	Test 300/1152. loss: 2.907, 0.0968 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 16:27:04 visual_prompt]: 	Test 400/1152. loss: 2.868, 0.0948 s / batch. (data: 4.98e-05)max mem: 17.22454 GB 
[09/18 16:27:20 visual_prompt]: 	Test 500/1152. loss: 2.928, 0.0964 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 16:27:35 visual_prompt]: 	Test 600/1152. loss: 3.026, 0.0967 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/18 16:27:52 visual_prompt]: 	Test 700/1152. loss: 2.892, 0.1267 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 16:28:08 visual_prompt]: 	Test 800/1152. loss: 2.982, 0.1103 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 16:28:24 visual_prompt]: 	Test 900/1152. loss: 2.898, 0.0975 s / batch. (data: 9.92e-05)max mem: 17.22454 GB 
[09/18 16:28:41 visual_prompt]: 	Test 1000/1152. loss: 2.839, 0.1179 s / batch. (data: 2.15e-02)max mem: 17.22454 GB 
[09/18 16:28:57 visual_prompt]: 	Test 1100/1152. loss: 2.997, 0.1395 s / batch. (data: 3.15e-05)max mem: 17.22454 GB 
[09/18 16:29:09 visual_prompt]: Inference (test):avg data time: 2.06e-03, avg batch time: 0.1094, average loss: 2.9001
[09/18 16:29:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 34.96	
[09/18 16:29:09 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/18 16:29:20 visual_prompt]: Epoch 60 / 100: avg data time: 2.41e-01, avg batch time: 0.4675, average train loss: 2.9073
[09/18 16:29:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0936, average loss: 2.8360
[09/18 16:29:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 42.00	
[09/18 16:29:47 visual_prompt]: 	Test 100/1152. loss: 2.907, 0.1082 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 16:30:02 visual_prompt]: 	Test 200/1152. loss: 2.879, 0.0978 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:30:18 visual_prompt]: 	Test 300/1152. loss: 3.040, 0.0983 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 16:30:33 visual_prompt]: 	Test 400/1152. loss: 2.965, 0.1067 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:30:48 visual_prompt]: 	Test 500/1152. loss: 2.876, 0.1068 s / batch. (data: 1.22e-05)max mem: 17.22454 GB 
[09/18 16:31:04 visual_prompt]: 	Test 600/1152. loss: 2.979, 0.0988 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:31:20 visual_prompt]: 	Test 700/1152. loss: 3.083, 0.0989 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 16:31:37 visual_prompt]: 	Test 800/1152. loss: 2.931, 0.1278 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/18 16:31:53 visual_prompt]: 	Test 900/1152. loss: 2.892, 0.1174 s / batch. (data: 2.19e-02)max mem: 17.22454 GB 
[09/18 16:32:10 visual_prompt]: 	Test 1000/1152. loss: 2.861, 0.1079 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/18 16:32:26 visual_prompt]: 	Test 1100/1152. loss: 2.973, 0.1090 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 16:32:38 visual_prompt]: Inference (test):avg data time: 2.17e-03, avg batch time: 0.1093, average loss: 2.9154
[09/18 16:32:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 34.98	
[09/18 16:32:39 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/18 16:32:49 visual_prompt]: Epoch 61 / 100: avg data time: 2.34e-01, avg batch time: 0.4626, average train loss: 2.8787
[09/18 16:32:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.0906, average loss: 2.8405
[09/18 16:32:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 35.00	
[09/18 16:33:16 visual_prompt]: 	Test 100/1152. loss: 3.049, 0.0951 s / batch. (data: 4.10e-05)max mem: 17.22454 GB 
[09/18 16:33:31 visual_prompt]: 	Test 200/1152. loss: 2.836, 0.0979 s / batch. (data: 4.82e-05)max mem: 17.22454 GB 
[09/18 16:33:47 visual_prompt]: 	Test 300/1152. loss: 2.850, 0.1249 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 16:34:02 visual_prompt]: 	Test 400/1152. loss: 2.828, 0.0962 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 16:34:17 visual_prompt]: 	Test 500/1152. loss: 2.854, 0.1900 s / batch. (data: 2.70e-02)max mem: 17.22454 GB 
[09/18 16:34:33 visual_prompt]: 	Test 600/1152. loss: 2.832, 0.1044 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/18 16:34:49 visual_prompt]: 	Test 700/1152. loss: 2.740, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 16:35:05 visual_prompt]: 	Test 800/1152. loss: 2.848, 0.1167 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 16:35:22 visual_prompt]: 	Test 900/1152. loss: 2.921, 0.1280 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 16:35:38 visual_prompt]: 	Test 1000/1152. loss: 2.812, 0.1237 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 16:35:54 visual_prompt]: 	Test 1100/1152. loss: 2.997, 0.0963 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:36:06 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1091, average loss: 2.8443
[09/18 16:36:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.88	
[09/18 16:36:07 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/18 16:36:17 visual_prompt]: Epoch 62 / 100: avg data time: 2.41e-01, avg batch time: 0.4656, average train loss: 2.8613
[09/18 16:36:24 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0956, average loss: 2.8197
[09/18 16:36:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 32.00	
[09/18 16:36:43 visual_prompt]: 	Test 100/1152. loss: 2.936, 0.1076 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/18 16:36:59 visual_prompt]: 	Test 200/1152. loss: 2.993, 0.0954 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 16:37:14 visual_prompt]: 	Test 300/1152. loss: 2.819, 0.0992 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:37:30 visual_prompt]: 	Test 400/1152. loss: 2.791, 0.1278 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 16:37:45 visual_prompt]: 	Test 500/1152. loss: 2.921, 0.0983 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 16:38:01 visual_prompt]: 	Test 600/1152. loss: 3.010, 0.1199 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:38:17 visual_prompt]: 	Test 700/1152. loss: 2.767, 0.1163 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/18 16:38:33 visual_prompt]: 	Test 800/1152. loss: 2.944, 0.1074 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 16:38:50 visual_prompt]: 	Test 900/1152. loss: 2.894, 0.0999 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 16:39:06 visual_prompt]: 	Test 1000/1152. loss: 2.813, 0.1125 s / batch. (data: 1.20e-02)max mem: 17.22454 GB 
[09/18 16:39:22 visual_prompt]: 	Test 1100/1152. loss: 2.976, 0.0983 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 16:39:34 visual_prompt]: Inference (test):avg data time: 1.60e-03, avg batch time: 0.1081, average loss: 2.8573
[09/18 16:39:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.01	
[09/18 16:39:35 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/18 16:39:45 visual_prompt]: Epoch 63 / 100: avg data time: 2.45e-01, avg batch time: 0.4678, average train loss: 2.9052
[09/18 16:39:53 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.0927, average loss: 2.8266
[09/18 16:39:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 41.00	
[09/18 16:40:12 visual_prompt]: 	Test 100/1152. loss: 2.901, 0.0992 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 16:40:27 visual_prompt]: 	Test 200/1152. loss: 2.919, 0.1081 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:40:43 visual_prompt]: 	Test 300/1152. loss: 2.853, 0.1031 s / batch. (data: 6.53e-03)max mem: 17.22454 GB 
[09/18 16:40:58 visual_prompt]: 	Test 400/1152. loss: 2.828, 0.1329 s / batch. (data: 3.19e-05)max mem: 17.22454 GB 
[09/18 16:41:14 visual_prompt]: 	Test 500/1152. loss: 2.805, 0.1040 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/18 16:41:29 visual_prompt]: 	Test 600/1152. loss: 2.885, 0.0996 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 16:41:46 visual_prompt]: 	Test 700/1152. loss: 2.885, 0.1000 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 16:42:02 visual_prompt]: 	Test 800/1152. loss: 2.872, 0.1199 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 16:42:19 visual_prompt]: 	Test 900/1152. loss: 2.888, 0.1118 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:42:35 visual_prompt]: 	Test 1000/1152. loss: 2.838, 0.1216 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 16:42:51 visual_prompt]: 	Test 1100/1152. loss: 3.022, 0.1271 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/18 16:43:04 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1085, average loss: 2.8571
[09/18 16:43:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 37.46	
[09/18 16:43:04 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/18 16:43:15 visual_prompt]: Epoch 64 / 100: avg data time: 2.28e-01, avg batch time: 0.4565, average train loss: 2.8807
[09/18 16:43:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0967, average loss: 2.9559
[09/18 16:43:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 31.00	
[09/18 16:43:41 visual_prompt]: 	Test 100/1152. loss: 2.886, 0.1059 s / batch. (data: 8.27e-03)max mem: 17.22454 GB 
[09/18 16:43:57 visual_prompt]: 	Test 200/1152. loss: 3.007, 0.1038 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:44:12 visual_prompt]: 	Test 300/1152. loss: 2.892, 0.1383 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 16:44:28 visual_prompt]: 	Test 400/1152. loss: 2.952, 0.1402 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 16:44:43 visual_prompt]: 	Test 500/1152. loss: 2.928, 0.1313 s / batch. (data: 2.28e-02)max mem: 17.22454 GB 
[09/18 16:44:59 visual_prompt]: 	Test 600/1152. loss: 2.855, 0.1197 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 16:45:15 visual_prompt]: 	Test 700/1152. loss: 3.005, 0.0985 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:45:32 visual_prompt]: 	Test 800/1152. loss: 2.817, 0.1174 s / batch. (data: 1.48e-05)max mem: 17.22454 GB 
[09/18 16:45:48 visual_prompt]: 	Test 900/1152. loss: 2.860, 0.1118 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 16:46:04 visual_prompt]: 	Test 1000/1152. loss: 2.842, 0.1304 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 16:46:20 visual_prompt]: 	Test 1100/1152. loss: 3.027, 0.1092 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/18 16:46:32 visual_prompt]: Inference (test):avg data time: 1.78e-03, avg batch time: 0.1089, average loss: 2.9662
[09/18 16:46:33 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 32.47	
[09/18 16:46:33 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/18 16:46:43 visual_prompt]: Epoch 65 / 100: avg data time: 2.29e-01, avg batch time: 0.4539, average train loss: 2.8870
[09/18 16:46:50 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.0965, average loss: 2.8340
[09/18 16:46:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 41.00	
[09/18 16:47:10 visual_prompt]: 	Test 100/1152. loss: 2.877, 0.0965 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 16:47:25 visual_prompt]: 	Test 200/1152. loss: 2.894, 0.1118 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 16:47:41 visual_prompt]: 	Test 300/1152. loss: 2.856, 0.1176 s / batch. (data: 9.51e-05)max mem: 17.22454 GB 
[09/18 16:47:56 visual_prompt]: 	Test 400/1152. loss: 2.798, 0.0994 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 16:48:12 visual_prompt]: 	Test 500/1152. loss: 2.823, 0.0969 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 16:48:28 visual_prompt]: 	Test 600/1152. loss: 2.870, 0.1192 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 16:48:44 visual_prompt]: 	Test 700/1152. loss: 2.793, 0.0989 s / batch. (data: 9.54e-05)max mem: 17.22454 GB 
[09/18 16:49:00 visual_prompt]: 	Test 800/1152. loss: 2.833, 0.1029 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 16:49:17 visual_prompt]: 	Test 900/1152. loss: 2.879, 0.1242 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/18 16:49:33 visual_prompt]: 	Test 1000/1152. loss: 2.787, 0.1243 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:49:49 visual_prompt]: 	Test 1100/1152. loss: 2.908, 0.1110 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 16:50:01 visual_prompt]: Inference (test):avg data time: 2.32e-03, avg batch time: 0.1094, average loss: 2.8389
[09/18 16:50:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 37.51	
[09/18 16:50:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/18 16:50:12 visual_prompt]: Epoch 66 / 100: avg data time: 2.41e-01, avg batch time: 0.4640, average train loss: 2.8851
[09/18 16:50:19 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0915, average loss: 2.7850
[09/18 16:50:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.00	
[09/18 16:50:39 visual_prompt]: 	Test 100/1152. loss: 2.942, 0.0953 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/18 16:50:55 visual_prompt]: 	Test 200/1152. loss: 2.833, 0.1229 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 16:51:10 visual_prompt]: 	Test 300/1152. loss: 2.758, 0.0963 s / batch. (data: 7.87e-05)max mem: 17.22454 GB 
[09/18 16:51:26 visual_prompt]: 	Test 400/1152. loss: 2.839, 0.0998 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 16:51:41 visual_prompt]: 	Test 500/1152. loss: 2.886, 0.0968 s / batch. (data: 4.41e-05)max mem: 17.22454 GB 
[09/18 16:51:57 visual_prompt]: 	Test 600/1152. loss: 2.876, 0.1333 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 16:52:13 visual_prompt]: 	Test 700/1152. loss: 2.747, 0.1036 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 16:52:29 visual_prompt]: 	Test 800/1152. loss: 2.834, 0.0961 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 16:52:46 visual_prompt]: 	Test 900/1152. loss: 2.868, 0.1322 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/18 16:53:02 visual_prompt]: 	Test 1000/1152. loss: 2.839, 0.1058 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/18 16:53:19 visual_prompt]: 	Test 1100/1152. loss: 2.854, 0.1380 s / batch. (data: 1.74e-02)max mem: 17.22454 GB 
[09/18 16:53:31 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1083, average loss: 2.8208
[09/18 16:53:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 34.95	
[09/18 16:53:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/18 16:53:42 visual_prompt]: Epoch 67 / 100: avg data time: 2.51e-01, avg batch time: 0.4731, average train loss: 2.8733
[09/18 16:53:49 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.0917, average loss: 2.8638
[09/18 16:53:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 36.00	
[09/18 16:54:09 visual_prompt]: 	Test 100/1152. loss: 3.054, 0.1040 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 16:54:24 visual_prompt]: 	Test 200/1152. loss: 2.926, 0.0980 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 16:54:40 visual_prompt]: 	Test 300/1152. loss: 2.834, 0.1202 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 16:54:55 visual_prompt]: 	Test 400/1152. loss: 2.949, 0.1097 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 16:55:11 visual_prompt]: 	Test 500/1152. loss: 2.900, 0.1004 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 16:55:26 visual_prompt]: 	Test 600/1152. loss: 2.902, 0.1434 s / batch. (data: 3.63e-02)max mem: 17.22454 GB 
[09/18 16:55:43 visual_prompt]: 	Test 700/1152. loss: 2.826, 0.1159 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 16:55:59 visual_prompt]: 	Test 800/1152. loss: 2.914, 0.1162 s / batch. (data: 2.05e-02)max mem: 17.22454 GB 
[09/18 16:56:15 visual_prompt]: 	Test 900/1152. loss: 3.000, 0.0977 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 16:56:32 visual_prompt]: 	Test 1000/1152. loss: 3.069, 0.1000 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 16:56:48 visual_prompt]: 	Test 1100/1152. loss: 2.911, 0.1034 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 16:57:00 visual_prompt]: Inference (test):avg data time: 2.16e-03, avg batch time: 0.1091, average loss: 2.8841
[09/18 16:57:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.44	
[09/18 16:57:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/18 16:57:11 visual_prompt]: Epoch 68 / 100: avg data time: 2.40e-01, avg batch time: 0.4646, average train loss: 2.8782
[09/18 16:57:18 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.0861, average loss: 2.8111
[09/18 16:57:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.00	
[09/18 16:57:37 visual_prompt]: 	Test 100/1152. loss: 2.932, 0.0950 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 16:57:53 visual_prompt]: 	Test 200/1152. loss: 2.893, 0.1016 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 16:58:08 visual_prompt]: 	Test 300/1152. loss: 2.737, 0.0991 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 16:58:24 visual_prompt]: 	Test 400/1152. loss: 2.824, 0.0976 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 16:58:39 visual_prompt]: 	Test 500/1152. loss: 2.839, 0.0998 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 16:58:55 visual_prompt]: 	Test 600/1152. loss: 2.833, 0.1125 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 16:59:11 visual_prompt]: 	Test 700/1152. loss: 2.735, 0.1196 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 16:59:27 visual_prompt]: 	Test 800/1152. loss: 2.768, 0.0990 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 16:59:44 visual_prompt]: 	Test 900/1152. loss: 2.887, 0.1049 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:00:00 visual_prompt]: 	Test 1000/1152. loss: 2.863, 0.0980 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 17:00:16 visual_prompt]: 	Test 1100/1152. loss: 2.854, 0.1236 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 17:00:28 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1085, average loss: 2.8103
[09/18 17:00:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.89	
[09/18 17:00:28 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/18 17:00:39 visual_prompt]: Epoch 69 / 100: avg data time: 2.39e-01, avg batch time: 0.4683, average train loss: 2.8389
[09/18 17:00:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.0880, average loss: 2.8280
[09/18 17:00:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 36.00	
[09/18 17:01:06 visual_prompt]: 	Test 100/1152. loss: 3.009, 0.0985 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 17:01:22 visual_prompt]: 	Test 200/1152. loss: 2.994, 0.1268 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/18 17:01:37 visual_prompt]: 	Test 300/1152. loss: 2.853, 0.0978 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 17:01:53 visual_prompt]: 	Test 400/1152. loss: 2.920, 0.1235 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/18 17:02:09 visual_prompt]: 	Test 500/1152. loss: 2.867, 0.1177 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 17:02:25 visual_prompt]: 	Test 600/1152. loss: 2.894, 0.1114 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:02:41 visual_prompt]: 	Test 700/1152. loss: 2.833, 0.1197 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 17:02:58 visual_prompt]: 	Test 800/1152. loss: 2.849, 0.1198 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:03:14 visual_prompt]: 	Test 900/1152. loss: 2.930, 0.0999 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:03:30 visual_prompt]: 	Test 1000/1152. loss: 2.940, 0.0954 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:03:47 visual_prompt]: 	Test 1100/1152. loss: 2.890, 0.0953 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 17:03:59 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1084, average loss: 2.8580
[09/18 17:03:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.87	
[09/18 17:03:59 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/18 17:04:10 visual_prompt]: Epoch 70 / 100: avg data time: 2.36e-01, avg batch time: 0.4655, average train loss: 2.8331
[09/18 17:04:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.0954, average loss: 2.8332
[09/18 17:04:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.00	
[09/18 17:04:37 visual_prompt]: 	Test 100/1152. loss: 2.883, 0.1148 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 17:04:52 visual_prompt]: 	Test 200/1152. loss: 2.916, 0.1039 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 17:05:07 visual_prompt]: 	Test 300/1152. loss: 2.884, 0.1187 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 17:05:23 visual_prompt]: 	Test 400/1152. loss: 2.758, 0.1159 s / batch. (data: 7.19e-03)max mem: 17.22454 GB 
[09/18 17:05:38 visual_prompt]: 	Test 500/1152. loss: 2.885, 0.1159 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 17:05:54 visual_prompt]: 	Test 600/1152. loss: 2.949, 0.1037 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/18 17:06:10 visual_prompt]: 	Test 700/1152. loss: 2.790, 0.0999 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 17:06:26 visual_prompt]: 	Test 800/1152. loss: 2.875, 0.0995 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 17:06:43 visual_prompt]: 	Test 900/1152. loss: 2.882, 0.1221 s / batch. (data: 8.87e-05)max mem: 17.22454 GB 
[09/18 17:07:00 visual_prompt]: 	Test 1000/1152. loss: 2.869, 0.1247 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 17:07:16 visual_prompt]: 	Test 1100/1152. loss: 2.930, 0.1225 s / batch. (data: 3.09e-03)max mem: 17.22454 GB 
[09/18 17:07:28 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1089, average loss: 2.8515
[09/18 17:07:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.54	
[09/18 17:07:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/18 17:07:39 visual_prompt]: Epoch 71 / 100: avg data time: 2.40e-01, avg batch time: 0.4665, average train loss: 2.8185
[09/18 17:07:46 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.0917, average loss: 2.7765
[09/18 17:07:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.50	top5: 27.50	
[09/18 17:08:06 visual_prompt]: 	Test 100/1152. loss: 2.809, 0.1008 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:08:21 visual_prompt]: 	Test 200/1152. loss: 2.785, 0.0989 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:08:37 visual_prompt]: 	Test 300/1152. loss: 2.770, 0.1258 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/18 17:08:52 visual_prompt]: 	Test 400/1152. loss: 2.745, 0.1185 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/18 17:09:08 visual_prompt]: 	Test 500/1152. loss: 2.803, 0.1159 s / batch. (data: 3.43e-03)max mem: 17.22454 GB 
[09/18 17:09:24 visual_prompt]: 	Test 600/1152. loss: 2.812, 0.1254 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/18 17:09:40 visual_prompt]: 	Test 700/1152. loss: 2.713, 0.1162 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/18 17:09:56 visual_prompt]: 	Test 800/1152. loss: 2.758, 0.0979 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:10:13 visual_prompt]: 	Test 900/1152. loss: 2.798, 0.0950 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 17:10:29 visual_prompt]: 	Test 1000/1152. loss: 2.722, 0.1068 s / batch. (data: 7.49e-05)max mem: 17.22454 GB 
[09/18 17:10:46 visual_prompt]: 	Test 1100/1152. loss: 2.795, 0.1222 s / batch. (data: 6.68e-05)max mem: 17.22454 GB 
[09/18 17:10:58 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1087, average loss: 2.7765
[09/18 17:10:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.99	top5: 30.96	
[09/18 17:10:58 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/18 17:11:09 visual_prompt]: Epoch 72 / 100: avg data time: 2.42e-01, avg batch time: 0.4641, average train loss: 2.7835
[09/18 17:11:16 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.0969, average loss: 2.7701
[09/18 17:11:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 38.50	
[09/18 17:11:36 visual_prompt]: 	Test 100/1152. loss: 2.851, 0.1191 s / batch. (data: 1.45e-02)max mem: 17.22454 GB 
[09/18 17:11:51 visual_prompt]: 	Test 200/1152. loss: 2.797, 0.0945 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 17:12:07 visual_prompt]: 	Test 300/1152. loss: 2.716, 0.1078 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 17:12:22 visual_prompt]: 	Test 400/1152. loss: 2.808, 0.0943 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/18 17:12:38 visual_prompt]: 	Test 500/1152. loss: 2.808, 0.1076 s / batch. (data: 5.15e-05)max mem: 17.22454 GB 
[09/18 17:12:54 visual_prompt]: 	Test 600/1152. loss: 2.785, 0.1157 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 17:13:10 visual_prompt]: 	Test 700/1152. loss: 2.743, 0.0971 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 17:13:26 visual_prompt]: 	Test 800/1152. loss: 2.662, 0.0999 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 17:13:43 visual_prompt]: 	Test 900/1152. loss: 2.846, 0.1224 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 17:13:59 visual_prompt]: 	Test 1000/1152. loss: 2.803, 0.1198 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:14:15 visual_prompt]: 	Test 1100/1152. loss: 2.808, 0.1239 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:14:27 visual_prompt]: Inference (test):avg data time: 2.34e-03, avg batch time: 0.1092, average loss: 2.7914
[09/18 17:14:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.20	top5: 36.00	
[09/18 17:14:28 visual_prompt]: Best epoch 72: best metric: 0.125
[09/18 17:14:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/18 17:14:38 visual_prompt]: Epoch 73 / 100: avg data time: 2.39e-01, avg batch time: 0.4675, average train loss: 2.7777
[09/18 17:14:45 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.0906, average loss: 2.7757
[09/18 17:14:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.00	top5: 41.50	
[09/18 17:15:05 visual_prompt]: 	Test 100/1152. loss: 2.885, 0.0944 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 17:15:20 visual_prompt]: 	Test 200/1152. loss: 2.830, 0.0943 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 17:15:36 visual_prompt]: 	Test 300/1152. loss: 2.887, 0.1169 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:15:51 visual_prompt]: 	Test 400/1152. loss: 2.817, 0.0953 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 17:16:06 visual_prompt]: 	Test 500/1152. loss: 2.842, 0.1138 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 17:16:22 visual_prompt]: 	Test 600/1152. loss: 2.831, 0.1412 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 17:16:39 visual_prompt]: 	Test 700/1152. loss: 2.826, 0.1028 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 17:16:55 visual_prompt]: 	Test 800/1152. loss: 2.913, 0.1070 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:17:11 visual_prompt]: 	Test 900/1152. loss: 2.795, 0.1217 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 17:17:28 visual_prompt]: 	Test 1000/1152. loss: 2.871, 0.1021 s / batch. (data: 4.39e-05)max mem: 17.22454 GB 
[09/18 17:17:44 visual_prompt]: 	Test 1100/1152. loss: 2.915, 0.1201 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:17:57 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1085, average loss: 2.8408
[09/18 17:17:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.00	top5: 34.45	
[09/18 17:17:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/18 17:18:08 visual_prompt]: Epoch 74 / 100: avg data time: 2.33e-01, avg batch time: 0.4575, average train loss: 2.8259
[09/18 17:18:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.0954, average loss: 2.7485
[09/18 17:18:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 42.00	
[09/18 17:18:34 visual_prompt]: 	Test 100/1152. loss: 2.785, 0.0996 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 17:18:50 visual_prompt]: 	Test 200/1152. loss: 2.817, 0.1045 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/18 17:19:05 visual_prompt]: 	Test 300/1152. loss: 2.724, 0.1318 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 17:19:21 visual_prompt]: 	Test 400/1152. loss: 2.776, 0.1108 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 17:19:36 visual_prompt]: 	Test 500/1152. loss: 2.781, 0.0969 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 17:19:52 visual_prompt]: 	Test 600/1152. loss: 2.770, 0.1157 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 17:20:08 visual_prompt]: 	Test 700/1152. loss: 2.728, 0.1118 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/18 17:20:25 visual_prompt]: 	Test 800/1152. loss: 2.778, 0.0959 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 17:20:41 visual_prompt]: 	Test 900/1152. loss: 2.783, 0.1156 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 17:20:58 visual_prompt]: 	Test 1000/1152. loss: 2.792, 0.0954 s / batch. (data: 6.46e-05)max mem: 17.22454 GB 
[09/18 17:21:14 visual_prompt]: 	Test 1100/1152. loss: 2.832, 0.1028 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/18 17:21:26 visual_prompt]: Inference (test):avg data time: 2.10e-03, avg batch time: 0.1095, average loss: 2.7824
[09/18 17:21:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 39.02	
[09/18 17:21:26 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/18 17:21:37 visual_prompt]: Epoch 75 / 100: avg data time: 2.33e-01, avg batch time: 0.4604, average train loss: 2.7882
[09/18 17:21:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.0879, average loss: 2.7329
[09/18 17:21:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.00	top5: 37.50	
[09/18 17:22:04 visual_prompt]: 	Test 100/1152. loss: 2.812, 0.1087 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 17:22:19 visual_prompt]: 	Test 200/1152. loss: 2.780, 0.0993 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 17:22:35 visual_prompt]: 	Test 300/1152. loss: 2.726, 0.1197 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 17:22:50 visual_prompt]: 	Test 400/1152. loss: 2.782, 0.1358 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 17:23:05 visual_prompt]: 	Test 500/1152. loss: 2.745, 0.0956 s / batch. (data: 3.03e-05)max mem: 17.22454 GB 
[09/18 17:23:21 visual_prompt]: 	Test 600/1152. loss: 2.731, 0.0998 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 17:23:37 visual_prompt]: 	Test 700/1152. loss: 2.719, 0.1212 s / batch. (data: 2.53e-02)max mem: 17.22454 GB 
[09/18 17:23:54 visual_prompt]: 	Test 800/1152. loss: 2.738, 0.1146 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 17:24:10 visual_prompt]: 	Test 900/1152. loss: 2.766, 0.0997 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 17:24:27 visual_prompt]: 	Test 1000/1152. loss: 2.772, 0.1222 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 17:24:43 visual_prompt]: 	Test 1100/1152. loss: 2.745, 0.1083 s / batch. (data: 4.08e-05)max mem: 17.22454 GB 
[09/18 17:24:55 visual_prompt]: Inference (test):avg data time: 1.65e-03, avg batch time: 0.1089, average loss: 2.7456
[09/18 17:24:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.88	top5: 39.04	
[09/18 17:24:55 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/18 17:25:06 visual_prompt]: Epoch 76 / 100: avg data time: 2.38e-01, avg batch time: 0.4672, average train loss: 2.7388
[09/18 17:25:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.0923, average loss: 2.6706
[09/18 17:25:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 46.00	
[09/18 17:25:33 visual_prompt]: 	Test 100/1152. loss: 2.812, 0.1090 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/18 17:25:48 visual_prompt]: 	Test 200/1152. loss: 2.714, 0.1119 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 17:26:04 visual_prompt]: 	Test 300/1152. loss: 2.732, 0.1158 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 17:26:19 visual_prompt]: 	Test 400/1152. loss: 2.794, 0.1207 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/18 17:26:34 visual_prompt]: 	Test 500/1152. loss: 2.761, 0.0960 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 17:26:50 visual_prompt]: 	Test 600/1152. loss: 2.751, 0.1513 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/18 17:27:07 visual_prompt]: 	Test 700/1152. loss: 2.731, 0.1099 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 17:27:23 visual_prompt]: 	Test 800/1152. loss: 2.657, 0.0993 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 17:27:40 visual_prompt]: 	Test 900/1152. loss: 2.711, 0.1069 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:27:56 visual_prompt]: 	Test 1000/1152. loss: 2.710, 0.1187 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 17:28:13 visual_prompt]: 	Test 1100/1152. loss: 2.765, 0.1195 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 17:28:25 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1091, average loss: 2.7330
[09/18 17:28:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.14	top5: 41.65	
[09/18 17:28:25 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/18 17:28:36 visual_prompt]: Epoch 77 / 100: avg data time: 2.36e-01, avg batch time: 0.4612, average train loss: 2.7478
[09/18 17:28:43 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.0945, average loss: 2.6591
[09/18 17:28:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.00	top5: 47.00	
[09/18 17:29:03 visual_prompt]: 	Test 100/1152. loss: 2.667, 0.1340 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 17:29:18 visual_prompt]: 	Test 200/1152. loss: 2.715, 0.0985 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 17:29:34 visual_prompt]: 	Test 300/1152. loss: 2.786, 0.0999 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 17:29:49 visual_prompt]: 	Test 400/1152. loss: 2.694, 0.1013 s / batch. (data: 4.15e-05)max mem: 17.22454 GB 
[09/18 17:30:05 visual_prompt]: 	Test 500/1152. loss: 2.664, 0.1327 s / batch. (data: 3.61e-02)max mem: 17.22454 GB 
[09/18 17:30:21 visual_prompt]: 	Test 600/1152. loss: 2.756, 0.0977 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 17:30:37 visual_prompt]: 	Test 700/1152. loss: 2.792, 0.1174 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 17:30:54 visual_prompt]: 	Test 800/1152. loss: 2.640, 0.0979 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/18 17:31:10 visual_prompt]: 	Test 900/1152. loss: 2.676, 0.1275 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 17:31:27 visual_prompt]: 	Test 1000/1152. loss: 2.742, 0.1140 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 17:31:43 visual_prompt]: 	Test 1100/1152. loss: 2.735, 0.1019 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 17:31:55 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1078, average loss: 2.7265
[09/18 17:31:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.44	top5: 41.99	
[09/18 17:31:55 visual_prompt]: Best epoch 77: best metric: 0.140
[09/18 17:31:55 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/18 17:32:06 visual_prompt]: Epoch 78 / 100: avg data time: 2.35e-01, avg batch time: 0.4620, average train loss: 2.6983
[09/18 17:32:13 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.0874, average loss: 2.6941
[09/18 17:32:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 39.50	
[09/18 17:32:32 visual_prompt]: 	Test 100/1152. loss: 2.770, 0.0972 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 17:32:48 visual_prompt]: 	Test 200/1152. loss: 2.710, 0.1079 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 17:33:03 visual_prompt]: 	Test 300/1152. loss: 2.691, 0.1013 s / batch. (data: 1.04e-03)max mem: 17.22454 GB 
[09/18 17:33:19 visual_prompt]: 	Test 400/1152. loss: 2.743, 0.1199 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 17:33:34 visual_prompt]: 	Test 500/1152. loss: 2.676, 0.1143 s / batch. (data: 5.68e-03)max mem: 17.22454 GB 
[09/18 17:33:50 visual_prompt]: 	Test 600/1152. loss: 2.745, 0.0971 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 17:34:06 visual_prompt]: 	Test 700/1152. loss: 2.785, 0.1098 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 17:34:23 visual_prompt]: 	Test 800/1152. loss: 2.628, 0.0998 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 17:34:39 visual_prompt]: 	Test 900/1152. loss: 2.733, 0.1324 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/18 17:34:55 visual_prompt]: 	Test 1000/1152. loss: 2.740, 0.0978 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 17:35:12 visual_prompt]: 	Test 1100/1152. loss: 2.735, 0.1120 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:35:24 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1085, average loss: 2.7367
[09/18 17:35:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.78	top5: 39.64	
[09/18 17:35:24 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/18 17:35:35 visual_prompt]: Epoch 79 / 100: avg data time: 2.35e-01, avg batch time: 0.4615, average train loss: 2.6988
[09/18 17:35:42 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.0942, average loss: 2.7468
[09/18 17:35:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 41.00	
[09/18 17:36:01 visual_prompt]: 	Test 100/1152. loss: 2.815, 0.0982 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 17:36:16 visual_prompt]: 	Test 200/1152. loss: 2.821, 0.0950 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/18 17:36:32 visual_prompt]: 	Test 300/1152. loss: 2.760, 0.1091 s / batch. (data: 2.93e-05)max mem: 17.22454 GB 
[09/18 17:36:47 visual_prompt]: 	Test 400/1152. loss: 2.712, 0.0996 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 17:37:03 visual_prompt]: 	Test 500/1152. loss: 2.815, 0.1150 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:37:19 visual_prompt]: 	Test 600/1152. loss: 2.792, 0.1125 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:37:35 visual_prompt]: 	Test 700/1152. loss: 2.704, 0.1039 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 17:37:51 visual_prompt]: 	Test 800/1152. loss: 2.796, 0.1373 s / batch. (data: 3.27e-02)max mem: 17.22454 GB 
[09/18 17:38:08 visual_prompt]: 	Test 900/1152. loss: 2.746, 0.1192 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 17:38:24 visual_prompt]: 	Test 1000/1152. loss: 2.751, 0.0972 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:38:41 visual_prompt]: 	Test 1100/1152. loss: 2.835, 0.1319 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 17:38:53 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1095, average loss: 2.7916
[09/18 17:38:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.28	top5: 37.66	
[09/18 17:38:53 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/18 17:39:04 visual_prompt]: Epoch 80 / 100: avg data time: 2.29e-01, avg batch time: 0.4591, average train loss: 2.6810
[09/18 17:39:11 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0916, average loss: 2.5781
[09/18 17:39:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.00	top5: 52.50	
[09/18 17:39:30 visual_prompt]: 	Test 100/1152. loss: 2.691, 0.1562 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 17:39:46 visual_prompt]: 	Test 200/1152. loss: 2.622, 0.0952 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 17:40:01 visual_prompt]: 	Test 300/1152. loss: 2.770, 0.1041 s / batch. (data: 3.36e-05)max mem: 17.22454 GB 
[09/18 17:40:16 visual_prompt]: 	Test 400/1152. loss: 2.655, 0.0999 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:40:32 visual_prompt]: 	Test 500/1152. loss: 2.687, 0.0952 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:40:48 visual_prompt]: 	Test 600/1152. loss: 2.730, 0.1040 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 17:41:04 visual_prompt]: 	Test 700/1152. loss: 2.786, 0.1000 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 17:41:20 visual_prompt]: 	Test 800/1152. loss: 2.655, 0.1114 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:41:37 visual_prompt]: 	Test 900/1152. loss: 2.680, 0.1108 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 17:41:53 visual_prompt]: 	Test 1000/1152. loss: 2.689, 0.1198 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 17:42:09 visual_prompt]: 	Test 1100/1152. loss: 2.713, 0.1179 s / batch. (data: 1.93e-02)max mem: 17.22454 GB 
[09/18 17:42:21 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1094, average loss: 2.7012
[09/18 17:42:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.10	top5: 43.71	
[09/18 17:42:22 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/18 17:42:32 visual_prompt]: Epoch 81 / 100: avg data time: 2.34e-01, avg batch time: 0.4612, average train loss: 2.6696
[09/18 17:42:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.0969, average loss: 2.5733
[09/18 17:42:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.00	top5: 53.50	
[09/18 17:42:59 visual_prompt]: 	Test 100/1152. loss: 2.721, 0.1000 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 17:43:15 visual_prompt]: 	Test 200/1152. loss: 2.662, 0.1042 s / batch. (data: 8.42e-03)max mem: 17.22454 GB 
[09/18 17:43:30 visual_prompt]: 	Test 300/1152. loss: 2.715, 0.1079 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 17:43:45 visual_prompt]: 	Test 400/1152. loss: 2.667, 0.1064 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 17:44:01 visual_prompt]: 	Test 500/1152. loss: 2.711, 0.1118 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 17:44:17 visual_prompt]: 	Test 600/1152. loss: 2.832, 0.0955 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/18 17:44:33 visual_prompt]: 	Test 700/1152. loss: 2.698, 0.1077 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/18 17:44:49 visual_prompt]: 	Test 800/1152. loss: 2.674, 0.1004 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 17:45:06 visual_prompt]: 	Test 900/1152. loss: 2.690, 0.1216 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/18 17:45:22 visual_prompt]: 	Test 1000/1152. loss: 2.732, 0.0963 s / batch. (data: 9.25e-05)max mem: 17.22454 GB 
[09/18 17:45:38 visual_prompt]: 	Test 1100/1152. loss: 2.769, 0.1120 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 17:45:50 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1087, average loss: 2.7278
[09/18 17:45:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.90	top5: 44.52	
[09/18 17:45:51 visual_prompt]: Best epoch 81: best metric: 0.150
[09/18 17:45:51 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/18 17:46:01 visual_prompt]: Epoch 82 / 100: avg data time: 2.32e-01, avg batch time: 0.4581, average train loss: 2.6539
[09/18 17:46:08 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.0888, average loss: 2.5602
[09/18 17:46:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.00	top5: 47.00	
[09/18 17:46:28 visual_prompt]: 	Test 100/1152. loss: 2.704, 0.1131 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 17:46:43 visual_prompt]: 	Test 200/1152. loss: 2.626, 0.0994 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 17:46:58 visual_prompt]: 	Test 300/1152. loss: 2.650, 0.1038 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 17:47:14 visual_prompt]: 	Test 400/1152. loss: 2.639, 0.1641 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/18 17:47:29 visual_prompt]: 	Test 500/1152. loss: 2.622, 0.1100 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 17:47:45 visual_prompt]: 	Test 600/1152. loss: 2.724, 0.0980 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 17:48:01 visual_prompt]: 	Test 700/1152. loss: 2.642, 0.1222 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 17:48:17 visual_prompt]: 	Test 800/1152. loss: 2.582, 0.0987 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 17:48:34 visual_prompt]: 	Test 900/1152. loss: 2.635, 0.0954 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/18 17:48:50 visual_prompt]: 	Test 1000/1152. loss: 2.699, 0.0988 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 17:49:06 visual_prompt]: 	Test 1100/1152. loss: 2.674, 0.0996 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 17:49:18 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1087, average loss: 2.6661
[09/18 17:49:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.95	top5: 46.33	
[09/18 17:49:19 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/18 17:49:29 visual_prompt]: Epoch 83 / 100: avg data time: 2.33e-01, avg batch time: 0.4604, average train loss: 2.6384
[09/18 17:49:36 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.0940, average loss: 2.6732
[09/18 17:49:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 40.00	
[09/18 17:49:56 visual_prompt]: 	Test 100/1152. loss: 2.781, 0.0991 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 17:50:11 visual_prompt]: 	Test 200/1152. loss: 2.755, 0.1043 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 17:50:27 visual_prompt]: 	Test 300/1152. loss: 2.761, 0.0959 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 17:50:42 visual_prompt]: 	Test 400/1152. loss: 2.780, 0.1387 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 17:50:57 visual_prompt]: 	Test 500/1152. loss: 2.797, 0.0988 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 17:51:13 visual_prompt]: 	Test 600/1152. loss: 2.740, 0.1060 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 17:51:29 visual_prompt]: 	Test 700/1152. loss: 2.727, 0.0967 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 17:51:46 visual_prompt]: 	Test 800/1152. loss: 2.759, 0.1227 s / batch. (data: 3.81e-05)max mem: 17.22454 GB 
[09/18 17:52:02 visual_prompt]: 	Test 900/1152. loss: 2.666, 0.1008 s / batch. (data: 1.87e-04)max mem: 17.22454 GB 
[09/18 17:52:19 visual_prompt]: 	Test 1000/1152. loss: 2.740, 0.1521 s / batch. (data: 4.22e-05)max mem: 17.22454 GB 
[09/18 17:52:35 visual_prompt]: 	Test 1100/1152. loss: 2.795, 0.1063 s / batch. (data: 3.72e-05)max mem: 17.22454 GB 
[09/18 17:52:47 visual_prompt]: Inference (test):avg data time: 2.31e-03, avg batch time: 0.1095, average loss: 2.7766
[09/18 17:52:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.64	top5: 37.75	
[09/18 17:52:47 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/18 17:52:58 visual_prompt]: Epoch 84 / 100: avg data time: 2.43e-01, avg batch time: 0.4652, average train loss: 2.6706
[09/18 17:53:05 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.0870, average loss: 2.5183
[09/18 17:53:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.50	top5: 57.50	
[09/18 17:53:24 visual_prompt]: 	Test 100/1152. loss: 2.674, 0.1184 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 17:53:40 visual_prompt]: 	Test 200/1152. loss: 2.684, 0.1079 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/18 17:53:55 visual_prompt]: 	Test 300/1152. loss: 2.703, 0.0980 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 17:54:11 visual_prompt]: 	Test 400/1152. loss: 2.662, 0.1003 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 17:54:26 visual_prompt]: 	Test 500/1152. loss: 2.664, 0.1240 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/18 17:54:42 visual_prompt]: 	Test 600/1152. loss: 2.692, 0.0962 s / batch. (data: 8.94e-05)max mem: 17.22454 GB 
[09/18 17:54:59 visual_prompt]: 	Test 700/1152. loss: 2.639, 0.1029 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 17:55:15 visual_prompt]: 	Test 800/1152. loss: 2.556, 0.1140 s / batch. (data: 8.66e-03)max mem: 17.22454 GB 
[09/18 17:55:32 visual_prompt]: 	Test 900/1152. loss: 2.628, 0.1076 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 17:55:48 visual_prompt]: 	Test 1000/1152. loss: 2.650, 0.1120 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 17:56:04 visual_prompt]: 	Test 1100/1152. loss: 2.679, 0.1298 s / batch. (data: 3.49e-02)max mem: 17.22454 GB 
[09/18 17:56:16 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1088, average loss: 2.6709
[09/18 17:56:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.10	top5: 46.56	
[09/18 17:56:17 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/18 17:56:27 visual_prompt]: Epoch 85 / 100: avg data time: 2.31e-01, avg batch time: 0.4583, average train loss: 2.6314
[09/18 17:56:34 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.0890, average loss: 2.5435
[09/18 17:56:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.50	top5: 52.50	
[09/18 17:56:54 visual_prompt]: 	Test 100/1152. loss: 2.664, 0.1000 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 17:57:09 visual_prompt]: 	Test 200/1152. loss: 2.625, 0.1332 s / batch. (data: 3.67e-05)max mem: 17.22454 GB 
[09/18 17:57:25 visual_prompt]: 	Test 300/1152. loss: 2.686, 0.0998 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 17:57:40 visual_prompt]: 	Test 400/1152. loss: 2.673, 0.1067 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 17:57:55 visual_prompt]: 	Test 500/1152. loss: 2.641, 0.1109 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 17:58:12 visual_prompt]: 	Test 600/1152. loss: 2.759, 0.0971 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 17:58:28 visual_prompt]: 	Test 700/1152. loss: 2.724, 0.0963 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 17:58:44 visual_prompt]: 	Test 800/1152. loss: 2.521, 0.1244 s / batch. (data: 1.18e-02)max mem: 17.22454 GB 
[09/18 17:59:01 visual_prompt]: 	Test 900/1152. loss: 2.651, 0.1148 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 17:59:17 visual_prompt]: 	Test 1000/1152. loss: 2.670, 0.1054 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 17:59:33 visual_prompt]: 	Test 1100/1152. loss: 2.680, 0.1125 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/18 17:59:45 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1083, average loss: 2.6596
[09/18 17:59:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.88	top5: 46.15	
[09/18 17:59:46 visual_prompt]: Best epoch 85: best metric: 0.165
[09/18 17:59:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/18 17:59:56 visual_prompt]: Epoch 86 / 100: avg data time: 2.38e-01, avg batch time: 0.4647, average train loss: 2.6049
[09/18 18:00:03 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.0916, average loss: 2.7253
[09/18 18:00:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 42.00	
[09/18 18:00:22 visual_prompt]: 	Test 100/1152. loss: 2.873, 0.1158 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 18:00:38 visual_prompt]: 	Test 200/1152. loss: 2.829, 0.1359 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:00:54 visual_prompt]: 	Test 300/1152. loss: 2.769, 0.1083 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 18:01:09 visual_prompt]: 	Test 400/1152. loss: 2.788, 0.1147 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 18:01:24 visual_prompt]: 	Test 500/1152. loss: 2.831, 0.1479 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/18 18:01:40 visual_prompt]: 	Test 600/1152. loss: 2.774, 0.1038 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 18:01:57 visual_prompt]: 	Test 700/1152. loss: 2.720, 0.0981 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 18:02:13 visual_prompt]: 	Test 800/1152. loss: 2.876, 0.1079 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 18:02:30 visual_prompt]: 	Test 900/1152. loss: 2.725, 0.1032 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:02:46 visual_prompt]: 	Test 1000/1152. loss: 2.736, 0.1179 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 18:03:02 visual_prompt]: 	Test 1100/1152. loss: 2.847, 0.0999 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 18:03:14 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1088, average loss: 2.8062
[09/18 18:03:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.51	top5: 39.42	
[09/18 18:03:15 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/18 18:03:25 visual_prompt]: Epoch 87 / 100: avg data time: 2.43e-01, avg batch time: 0.4670, average train loss: 2.6917
[09/18 18:03:33 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0868, average loss: 2.5674
[09/18 18:03:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.00	top5: 47.50	
[09/18 18:03:52 visual_prompt]: 	Test 100/1152. loss: 2.721, 0.0978 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:04:08 visual_prompt]: 	Test 200/1152. loss: 2.709, 0.0999 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 18:04:23 visual_prompt]: 	Test 300/1152. loss: 2.662, 0.1083 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:04:38 visual_prompt]: 	Test 400/1152. loss: 2.683, 0.0962 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:04:54 visual_prompt]: 	Test 500/1152. loss: 2.678, 0.0964 s / batch. (data: 9.78e-05)max mem: 17.22454 GB 
[09/18 18:05:10 visual_prompt]: 	Test 600/1152. loss: 2.719, 0.1098 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 18:05:26 visual_prompt]: 	Test 700/1152. loss: 2.642, 0.1383 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 18:05:42 visual_prompt]: 	Test 800/1152. loss: 2.636, 0.0992 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/18 18:05:59 visual_prompt]: 	Test 900/1152. loss: 2.646, 0.1001 s / batch. (data: 9.30e-05)max mem: 17.22454 GB 
[09/18 18:06:15 visual_prompt]: 	Test 1000/1152. loss: 2.708, 0.1042 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 18:06:32 visual_prompt]: 	Test 1100/1152. loss: 2.722, 0.1279 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 18:06:44 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1080, average loss: 2.6889
[09/18 18:06:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.14	top5: 44.79	
[09/18 18:06:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/18 18:06:55 visual_prompt]: Epoch 88 / 100: avg data time: 2.32e-01, avg batch time: 0.4565, average train loss: 2.5960
[09/18 18:07:02 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.0935, average loss: 2.4745
[09/18 18:07:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.00	top5: 62.50	
[09/18 18:07:21 visual_prompt]: 	Test 100/1152. loss: 2.720, 0.0985 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 18:07:37 visual_prompt]: 	Test 200/1152. loss: 2.660, 0.1040 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 18:07:53 visual_prompt]: 	Test 300/1152. loss: 2.704, 0.1300 s / batch. (data: 3.46e-02)max mem: 17.22454 GB 
[09/18 18:08:09 visual_prompt]: 	Test 400/1152. loss: 2.641, 0.1178 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 18:08:24 visual_prompt]: 	Test 500/1152. loss: 2.631, 0.1436 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 18:08:40 visual_prompt]: 	Test 600/1152. loss: 2.743, 0.1223 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 18:08:56 visual_prompt]: 	Test 700/1152. loss: 2.682, 0.1119 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 18:09:13 visual_prompt]: 	Test 800/1152. loss: 2.545, 0.1067 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 18:09:29 visual_prompt]: 	Test 900/1152. loss: 2.643, 0.1078 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:09:46 visual_prompt]: 	Test 1000/1152. loss: 2.684, 0.1105 s / batch. (data: 3.10e-05)max mem: 17.22454 GB 
[09/18 18:10:02 visual_prompt]: 	Test 1100/1152. loss: 2.751, 0.1084 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 18:10:14 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1091, average loss: 2.6613
[09/18 18:10:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.04	top5: 48.03	
[09/18 18:10:14 visual_prompt]: Best epoch 88: best metric: 0.180
[09/18 18:10:14 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/18 18:10:25 visual_prompt]: Epoch 89 / 100: avg data time: 2.31e-01, avg batch time: 0.4599, average train loss: 2.5410
[09/18 18:10:32 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.0912, average loss: 2.4511
[09/18 18:10:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.00	top5: 62.00	
[09/18 18:10:52 visual_prompt]: 	Test 100/1152. loss: 2.622, 0.1280 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 18:11:07 visual_prompt]: 	Test 200/1152. loss: 2.685, 0.0996 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/18 18:11:23 visual_prompt]: 	Test 300/1152. loss: 2.753, 0.1202 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 18:11:39 visual_prompt]: 	Test 400/1152. loss: 2.636, 0.0949 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/18 18:11:54 visual_prompt]: 	Test 500/1152. loss: 2.663, 0.1263 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 18:12:10 visual_prompt]: 	Test 600/1152. loss: 2.779, 0.0949 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/18 18:12:27 visual_prompt]: 	Test 700/1152. loss: 2.734, 0.1199 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 18:12:43 visual_prompt]: 	Test 800/1152. loss: 2.521, 0.1061 s / batch. (data: 4.22e-05)max mem: 17.22454 GB 
[09/18 18:12:59 visual_prompt]: 	Test 900/1152. loss: 2.675, 0.0998 s / batch. (data: 3.89e-05)max mem: 17.22454 GB 
[09/18 18:13:16 visual_prompt]: 	Test 1000/1152. loss: 2.631, 0.1112 s / batch. (data: 6.73e-03)max mem: 17.22454 GB 
[09/18 18:13:32 visual_prompt]: 	Test 1100/1152. loss: 2.795, 0.1101 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 18:13:45 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1095, average loss: 2.6794
[09/18 18:13:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.48	top5: 47.80	
[09/18 18:13:45 visual_prompt]: Best epoch 89: best metric: 0.190
[09/18 18:13:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/18 18:13:55 visual_prompt]: Epoch 90 / 100: avg data time: 2.37e-01, avg batch time: 0.4590, average train loss: 2.5258
[09/18 18:14:02 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.0868, average loss: 2.4542
[09/18 18:14:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.00	top5: 61.00	
[09/18 18:14:22 visual_prompt]: 	Test 100/1152. loss: 2.665, 0.1080 s / batch. (data: 1.26e-02)max mem: 17.22454 GB 
[09/18 18:14:37 visual_prompt]: 	Test 200/1152. loss: 2.671, 0.0988 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 18:14:53 visual_prompt]: 	Test 300/1152. loss: 2.673, 0.1144 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 18:15:08 visual_prompt]: 	Test 400/1152. loss: 2.709, 0.0963 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 18:15:24 visual_prompt]: 	Test 500/1152. loss: 2.643, 0.1417 s / batch. (data: 1.24e-05)max mem: 17.22454 GB 
[09/18 18:15:40 visual_prompt]: 	Test 600/1152. loss: 2.732, 0.1454 s / batch. (data: 4.10e-02)max mem: 17.22454 GB 
[09/18 18:15:56 visual_prompt]: 	Test 700/1152. loss: 2.707, 0.1002 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 18:16:13 visual_prompt]: 	Test 800/1152. loss: 2.526, 0.1284 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 18:16:29 visual_prompt]: 	Test 900/1152. loss: 2.701, 0.1229 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 18:16:46 visual_prompt]: 	Test 1000/1152. loss: 2.666, 0.1059 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 18:17:02 visual_prompt]: 	Test 1100/1152. loss: 2.711, 0.1329 s / batch. (data: 8.69e-03)max mem: 17.22454 GB 
[09/18 18:17:14 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1089, average loss: 2.6561
[09/18 18:17:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.18	top5: 49.47	
[09/18 18:17:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/18 18:17:25 visual_prompt]: Epoch 91 / 100: avg data time: 2.30e-01, avg batch time: 0.4552, average train loss: 2.5058
[09/18 18:17:32 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.0943, average loss: 2.4338
[09/18 18:17:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.00	top5: 63.50	
[09/18 18:17:52 visual_prompt]: 	Test 100/1152. loss: 2.688, 0.1154 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 18:18:07 visual_prompt]: 	Test 200/1152. loss: 2.699, 0.1123 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:18:23 visual_prompt]: 	Test 300/1152. loss: 2.645, 0.1121 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 18:18:38 visual_prompt]: 	Test 400/1152. loss: 2.671, 0.1238 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 18:18:53 visual_prompt]: 	Test 500/1152. loss: 2.667, 0.1078 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:19:09 visual_prompt]: 	Test 600/1152. loss: 2.762, 0.1207 s / batch. (data: 1.99e-02)max mem: 17.22454 GB 
[09/18 18:19:26 visual_prompt]: 	Test 700/1152. loss: 2.690, 0.1130 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 18:19:43 visual_prompt]: 	Test 800/1152. loss: 2.553, 0.0948 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 18:19:59 visual_prompt]: 	Test 900/1152. loss: 2.711, 0.0952 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 18:20:16 visual_prompt]: 	Test 1000/1152. loss: 2.606, 0.1046 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 18:20:32 visual_prompt]: 	Test 1100/1152. loss: 2.818, 0.1185 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/18 18:20:44 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1085, average loss: 2.6753
[09/18 18:20:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.29	top5: 49.02	
[09/18 18:20:44 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/18 18:20:55 visual_prompt]: Epoch 92 / 100: avg data time: 2.50e-01, avg batch time: 0.4724, average train loss: 2.4839
[09/18 18:21:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0997, average loss: 2.3894
[09/18 18:21:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.00	top5: 62.50	
[09/18 18:21:21 visual_prompt]: 	Test 100/1152. loss: 2.639, 0.1238 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 18:21:37 visual_prompt]: 	Test 200/1152. loss: 2.718, 0.1252 s / batch. (data: 1.25e-02)max mem: 17.22454 GB 
[09/18 18:21:53 visual_prompt]: 	Test 300/1152. loss: 2.642, 0.1026 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 18:22:08 visual_prompt]: 	Test 400/1152. loss: 2.718, 0.1315 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 18:22:23 visual_prompt]: 	Test 500/1152. loss: 2.703, 0.1024 s / batch. (data: 4.63e-05)max mem: 17.22454 GB 
[09/18 18:22:39 visual_prompt]: 	Test 600/1152. loss: 2.771, 0.0981 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/18 18:22:56 visual_prompt]: 	Test 700/1152. loss: 2.634, 0.1019 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/18 18:23:12 visual_prompt]: 	Test 800/1152. loss: 2.590, 0.1059 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/18 18:23:29 visual_prompt]: 	Test 900/1152. loss: 2.629, 0.1255 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 18:23:45 visual_prompt]: 	Test 1000/1152. loss: 2.541, 0.1122 s / batch. (data: 7.34e-03)max mem: 17.22454 GB 
[09/18 18:24:01 visual_prompt]: 	Test 1100/1152. loss: 2.759, 0.0974 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 18:24:13 visual_prompt]: Inference (test):avg data time: 1.92e-03, avg batch time: 0.1088, average loss: 2.6716
[09/18 18:24:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.75	top5: 48.93	
[09/18 18:24:13 visual_prompt]: Best epoch 92: best metric: 0.200
[09/18 18:24:13 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/18 18:24:24 visual_prompt]: Epoch 93 / 100: avg data time: 2.40e-01, avg batch time: 0.4650, average train loss: 2.4730
[09/18 18:24:31 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.0864, average loss: 2.4339
[09/18 18:24:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.00	top5: 61.50	
[09/18 18:24:50 visual_prompt]: 	Test 100/1152. loss: 2.663, 0.1108 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:25:06 visual_prompt]: 	Test 200/1152. loss: 2.724, 0.1297 s / batch. (data: 2.11e-02)max mem: 17.22454 GB 
[09/18 18:25:21 visual_prompt]: 	Test 300/1152. loss: 2.698, 0.0992 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 18:25:37 visual_prompt]: 	Test 400/1152. loss: 2.720, 0.1486 s / batch. (data: 2.04e-02)max mem: 17.22454 GB 
[09/18 18:25:52 visual_prompt]: 	Test 500/1152. loss: 2.669, 0.1039 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/18 18:26:08 visual_prompt]: 	Test 600/1152. loss: 2.797, 0.1077 s / batch. (data: 8.70e-05)max mem: 17.22454 GB 
[09/18 18:26:25 visual_prompt]: 	Test 700/1152. loss: 2.711, 0.1239 s / batch. (data: 1.90e-04)max mem: 17.22454 GB 
[09/18 18:26:41 visual_prompt]: 	Test 800/1152. loss: 2.528, 0.1428 s / batch. (data: 7.08e-03)max mem: 17.22454 GB 
[09/18 18:26:58 visual_prompt]: 	Test 900/1152. loss: 2.759, 0.1057 s / batch. (data: 6.36e-03)max mem: 17.22454 GB 
[09/18 18:27:15 visual_prompt]: 	Test 1000/1152. loss: 2.573, 0.1279 s / batch. (data: 5.60e-03)max mem: 17.22454 GB 
[09/18 18:27:31 visual_prompt]: 	Test 1100/1152. loss: 2.789, 0.1175 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 18:27:43 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1083, average loss: 2.6785
[09/18 18:27:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.34	top5: 48.49	
[09/18 18:27:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/18 18:27:54 visual_prompt]: Epoch 94 / 100: avg data time: 2.33e-01, avg batch time: 0.4635, average train loss: 2.4431
[09/18 18:28:01 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.0936, average loss: 2.3779
[09/18 18:28:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.00	top5: 63.00	
[09/18 18:28:20 visual_prompt]: 	Test 100/1152. loss: 2.645, 0.1141 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 18:28:36 visual_prompt]: 	Test 200/1152. loss: 2.739, 0.1038 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/18 18:28:51 visual_prompt]: 	Test 300/1152. loss: 2.659, 0.1140 s / batch. (data: 1.72e-02)max mem: 17.22454 GB 
[09/18 18:29:06 visual_prompt]: 	Test 400/1152. loss: 2.726, 0.0990 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 18:29:22 visual_prompt]: 	Test 500/1152. loss: 2.703, 0.0999 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 18:29:38 visual_prompt]: 	Test 600/1152. loss: 2.746, 0.1107 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 18:29:54 visual_prompt]: 	Test 700/1152. loss: 2.664, 0.0977 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:30:10 visual_prompt]: 	Test 800/1152. loss: 2.570, 0.1035 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/18 18:30:26 visual_prompt]: 	Test 900/1152. loss: 2.611, 0.1187 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 18:30:43 visual_prompt]: 	Test 1000/1152. loss: 2.532, 0.0971 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 18:30:59 visual_prompt]: 	Test 1100/1152. loss: 2.781, 0.1512 s / batch. (data: 4.73e-03)max mem: 17.22454 GB 
[09/18 18:31:11 visual_prompt]: Inference (test):avg data time: 2.44e-03, avg batch time: 0.1093, average loss: 2.6740
[09/18 18:31:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.87	top5: 49.65	
[09/18 18:31:12 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/18 18:31:22 visual_prompt]: Epoch 95 / 100: avg data time: 2.36e-01, avg batch time: 0.4592, average train loss: 2.4226
[09/18 18:31:30 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0891, average loss: 2.3941
[09/18 18:31:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.00	top5: 63.00	
[09/18 18:31:49 visual_prompt]: 	Test 100/1152. loss: 2.633, 0.1278 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/18 18:32:05 visual_prompt]: 	Test 200/1152. loss: 2.800, 0.1078 s / batch. (data: 2.81e-05)max mem: 17.22454 GB 
[09/18 18:32:21 visual_prompt]: 	Test 300/1152. loss: 2.709, 0.1411 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 18:32:36 visual_prompt]: 	Test 400/1152. loss: 2.740, 0.1436 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 18:32:52 visual_prompt]: 	Test 500/1152. loss: 2.737, 0.1163 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 18:33:08 visual_prompt]: 	Test 600/1152. loss: 2.724, 0.1077 s / batch. (data: 8.61e-05)max mem: 17.22454 GB 
[09/18 18:33:24 visual_prompt]: 	Test 700/1152. loss: 2.671, 0.1093 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 18:33:41 visual_prompt]: 	Test 800/1152. loss: 2.593, 0.1079 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/18 18:33:58 visual_prompt]: 	Test 900/1152. loss: 2.586, 0.1292 s / batch. (data: 2.87e-02)max mem: 17.22454 GB 
[09/18 18:34:14 visual_prompt]: 	Test 1000/1152. loss: 2.524, 0.1302 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 18:34:30 visual_prompt]: 	Test 1100/1152. loss: 2.723, 0.0989 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 18:34:42 visual_prompt]: Inference (test):avg data time: 1.61e-03, avg batch time: 0.1082, average loss: 2.6814
[09/18 18:34:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.39	top5: 47.48	
[09/18 18:34:43 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/18 18:34:53 visual_prompt]: Epoch 96 / 100: avg data time: 2.42e-01, avg batch time: 0.4643, average train loss: 2.4227
[09/18 18:35:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.0907, average loss: 2.3513
[09/18 18:35:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.00	top5: 62.50	
[09/18 18:35:20 visual_prompt]: 	Test 100/1152. loss: 2.647, 0.0998 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 18:35:36 visual_prompt]: 	Test 200/1152. loss: 2.786, 0.1148 s / batch. (data: 3.43e-05)max mem: 17.22454 GB 
[09/18 18:35:51 visual_prompt]: 	Test 300/1152. loss: 2.653, 0.0988 s / batch. (data: 8.39e-05)max mem: 17.22454 GB 
[09/18 18:36:06 visual_prompt]: 	Test 400/1152. loss: 2.735, 0.1125 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:36:22 visual_prompt]: 	Test 500/1152. loss: 2.693, 0.0943 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 18:36:38 visual_prompt]: 	Test 600/1152. loss: 2.774, 0.1045 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 18:36:54 visual_prompt]: 	Test 700/1152. loss: 2.683, 0.0957 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 18:37:10 visual_prompt]: 	Test 800/1152. loss: 2.566, 0.1019 s / batch. (data: 7.03e-05)max mem: 17.22454 GB 
[09/18 18:37:27 visual_prompt]: 	Test 900/1152. loss: 2.606, 0.1035 s / batch. (data: 5.22e-05)max mem: 17.22454 GB 
[09/18 18:37:43 visual_prompt]: 	Test 1000/1152. loss: 2.475, 0.0975 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 18:37:59 visual_prompt]: 	Test 1100/1152. loss: 2.752, 0.1047 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 18:38:11 visual_prompt]: Inference (test):avg data time: 1.64e-03, avg batch time: 0.1091, average loss: 2.6777
[09/18 18:38:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.08	top5: 49.82	
[09/18 18:38:11 visual_prompt]: Best epoch 96: best metric: 0.210
[09/18 18:38:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/18 18:38:22 visual_prompt]: Epoch 97 / 100: avg data time: 2.30e-01, avg batch time: 0.4588, average train loss: 2.4004
[09/18 18:38:29 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0917, average loss: 2.3467
[09/18 18:38:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.50	top5: 64.50	
[09/18 18:38:49 visual_prompt]: 	Test 100/1152. loss: 2.646, 0.0999 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:39:04 visual_prompt]: 	Test 200/1152. loss: 2.805, 0.0959 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:39:19 visual_prompt]: 	Test 300/1152. loss: 2.659, 0.1046 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 18:39:35 visual_prompt]: 	Test 400/1152. loss: 2.763, 0.1052 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:39:50 visual_prompt]: 	Test 500/1152. loss: 2.684, 0.1079 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 18:40:06 visual_prompt]: 	Test 600/1152. loss: 2.779, 0.1265 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/18 18:40:23 visual_prompt]: 	Test 700/1152. loss: 2.687, 0.1053 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/18 18:40:39 visual_prompt]: 	Test 800/1152. loss: 2.568, 0.1398 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 18:40:55 visual_prompt]: 	Test 900/1152. loss: 2.642, 0.1159 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 18:41:12 visual_prompt]: 	Test 1000/1152. loss: 2.472, 0.1168 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 18:41:28 visual_prompt]: 	Test 1100/1152. loss: 2.760, 0.1078 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/18 18:41:40 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1087, average loss: 2.6742
[09/18 18:41:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.32	top5: 50.32	
[09/18 18:41:41 visual_prompt]: Best epoch 97: best metric: 0.215
[09/18 18:41:41 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/18 18:41:51 visual_prompt]: Epoch 98 / 100: avg data time: 2.36e-01, avg batch time: 0.4590, average train loss: 2.3767
[09/18 18:41:58 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0953, average loss: 2.3358
[09/18 18:41:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.50	top5: 65.50	
[09/18 18:42:18 visual_prompt]: 	Test 100/1152. loss: 2.658, 0.1134 s / batch. (data: 8.82e-03)max mem: 17.22454 GB 
[09/18 18:42:33 visual_prompt]: 	Test 200/1152. loss: 2.801, 0.1400 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 18:42:49 visual_prompt]: 	Test 300/1152. loss: 2.684, 0.1043 s / batch. (data: 5.99e-03)max mem: 17.22454 GB 
[09/18 18:43:04 visual_prompt]: 	Test 400/1152. loss: 2.762, 0.1093 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 18:43:19 visual_prompt]: 	Test 500/1152. loss: 2.677, 0.1050 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 18:43:36 visual_prompt]: 	Test 600/1152. loss: 2.809, 0.0976 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:43:52 visual_prompt]: 	Test 700/1152. loss: 2.722, 0.1496 s / batch. (data: 2.10e-03)max mem: 17.22454 GB 
[09/18 18:44:08 visual_prompt]: 	Test 800/1152. loss: 2.546, 0.1032 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 18:44:25 visual_prompt]: 	Test 900/1152. loss: 2.651, 0.1300 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/18 18:44:41 visual_prompt]: 	Test 1000/1152. loss: 2.491, 0.1457 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 18:44:58 visual_prompt]: 	Test 1100/1152. loss: 2.817, 0.0959 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 18:45:10 visual_prompt]: Inference (test):avg data time: 2.20e-03, avg batch time: 0.1095, average loss: 2.6868
[09/18 18:45:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.35	top5: 50.68	
[09/18 18:45:10 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/18 18:45:21 visual_prompt]: Epoch 99 / 100: avg data time: 2.36e-01, avg batch time: 0.4668, average train loss: 2.3741
[09/18 18:45:28 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.0926, average loss: 2.3331
[09/18 18:45:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.00	top5: 65.50	
[09/18 18:45:47 visual_prompt]: 	Test 100/1152. loss: 2.653, 0.0981 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 18:46:03 visual_prompt]: 	Test 200/1152. loss: 2.797, 0.1046 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 18:46:19 visual_prompt]: 	Test 300/1152. loss: 2.676, 0.1151 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 18:46:34 visual_prompt]: 	Test 400/1152. loss: 2.766, 0.1241 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 18:46:49 visual_prompt]: 	Test 500/1152. loss: 2.679, 0.1000 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 18:47:05 visual_prompt]: 	Test 600/1152. loss: 2.806, 0.0965 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 18:47:21 visual_prompt]: 	Test 700/1152. loss: 2.725, 0.1666 s / batch. (data: 4.99e-03)max mem: 17.22454 GB 
[09/18 18:47:38 visual_prompt]: 	Test 800/1152. loss: 2.555, 0.1007 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 18:47:54 visual_prompt]: 	Test 900/1152. loss: 2.648, 0.1290 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 18:48:11 visual_prompt]: 	Test 1000/1152. loss: 2.485, 0.1183 s / batch. (data: 2.32e-02)max mem: 17.22454 GB 
[09/18 18:48:27 visual_prompt]: 	Test 1100/1152. loss: 2.816, 0.1063 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 18:48:39 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1087, average loss: 2.6873
[09/18 18:48:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.34	top5: 50.75	
[09/18 18:48:39 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/18 18:48:50 visual_prompt]: Epoch 100 / 100: avg data time: 2.32e-01, avg batch time: 0.4594, average train loss: 2.3680
[09/18 18:48:57 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.0894, average loss: 2.3334
[09/18 18:48:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.00	top5: 65.50	
[09/18 18:49:16 visual_prompt]: 	Test 100/1152. loss: 2.651, 0.0986 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 18:49:32 visual_prompt]: 	Test 200/1152. loss: 2.797, 0.1079 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 18:49:47 visual_prompt]: 	Test 300/1152. loss: 2.678, 0.1066 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 18:50:02 visual_prompt]: 	Test 400/1152. loss: 2.765, 0.0991 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 18:50:18 visual_prompt]: 	Test 500/1152. loss: 2.678, 0.1215 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 18:50:34 visual_prompt]: 	Test 600/1152. loss: 2.807, 0.1056 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/18 18:50:50 visual_prompt]: 	Test 700/1152. loss: 2.726, 0.1003 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 18:51:07 visual_prompt]: 	Test 800/1152. loss: 2.555, 0.0997 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 18:51:23 visual_prompt]: 	Test 900/1152. loss: 2.651, 0.1010 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 18:51:40 visual_prompt]: 	Test 1000/1152. loss: 2.486, 0.1182 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 18:51:56 visual_prompt]: 	Test 1100/1152. loss: 2.818, 0.1516 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/18 18:52:08 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1089, average loss: 2.6880
[09/18 18:52:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.35	top5: 50.78	
[09/18 18:52:44 visual_prompt]: Rank of current process: 0. World size: 1
[09/18 18:52:44 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/18 18:52:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/18 18:52:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/18 18:52:44 visual_prompt]: Training with config:
[09/18 18:52:44 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/18 18:52:44 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-18 18:52:44.829155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-18 18:52:45.041297: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-18 18:52:49.015470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 18:52:49.015634: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 18:52:49.015646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-18 18:52:57.330935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 18:52:57.331210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-18 18:52:57.331235: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/18 18:52:57 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-18 18:52:57.410203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 18:52:59 visual_prompt]: Number of images: 1000
[09/18 18:52:59 visual_prompt]: Number of classes: 16 / 16
[09/18 18:52:59 visual_prompt]: Loading validation data...
[09/18 18:52:59 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 18:52:59 visual_prompt]: Number of images: 200
[09/18 18:52:59 visual_prompt]: Number of classes: 16 / 16
[09/18 18:52:59 visual_prompt]: Loading test data...
[09/18 18:52:59 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/18 18:54:29 visual_prompt]: Number of images: 73728
[09/18 18:54:29 visual_prompt]: Number of classes: 16 / 16
[09/18 18:54:29 visual_prompt]: Constructing models...
[09/18 18:54:32 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/18 18:54:32 visual_prompt]: tuned percent:1.077
[09/18 18:54:35 visual_prompt]: Device used for model: 0
[09/18 18:54:35 visual_prompt]: Setting up Evalutator...
[09/18 18:54:35 visual_prompt]: Setting up Trainer...
[09/18 18:54:35 visual_prompt]: 	Setting up the optimizer...
[09/18 18:54:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/18 18:54:47 visual_prompt]: Epoch 1 / 100: avg data time: 2.53e-01, avg batch time: 0.5732, average train loss: 2.9046
[09/18 18:54:55 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.0907, average loss: 2.8619
[09/18 18:54:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 30.00	
[09/18 18:55:15 visual_prompt]: 	Test 100/1152. loss: 2.840, 0.0978 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 18:55:31 visual_prompt]: 	Test 200/1152. loss: 2.982, 0.0964 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 18:55:48 visual_prompt]: 	Test 300/1152. loss: 2.947, 0.1116 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 18:56:04 visual_prompt]: 	Test 400/1152. loss: 2.875, 0.1341 s / batch. (data: 2.89e-03)max mem: 17.22454 GB 
[09/18 18:56:20 visual_prompt]: 	Test 500/1152. loss: 2.966, 0.1046 s / batch. (data: 8.03e-03)max mem: 17.22454 GB 
[09/18 18:56:36 visual_prompt]: 	Test 600/1152. loss: 2.980, 0.1025 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 18:56:52 visual_prompt]: 	Test 700/1152. loss: 2.883, 0.1152 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 18:57:08 visual_prompt]: 	Test 800/1152. loss: 2.916, 0.1135 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/18 18:57:24 visual_prompt]: 	Test 900/1152. loss: 2.777, 0.0978 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 18:57:41 visual_prompt]: 	Test 1000/1152. loss: 2.805, 0.1119 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 18:57:57 visual_prompt]: 	Test 1100/1152. loss: 2.970, 0.0974 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 18:58:09 visual_prompt]: Inference (test):avg data time: 1.59e-03, avg batch time: 0.1092, average loss: 2.9221
[09/18 18:58:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.92	top5: 28.13	
[09/18 18:58:10 visual_prompt]: Best epoch 1: best metric: 0.050
[09/18 18:58:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/18 18:58:20 visual_prompt]: Epoch 2 / 100: avg data time: 2.49e-01, avg batch time: 0.4780, average train loss: 3.2548
[09/18 18:58:27 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.0945, average loss: 3.0165
[09/18 18:58:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 30.00	
[09/18 18:58:47 visual_prompt]: 	Test 100/1152. loss: 2.980, 0.1268 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/18 18:59:03 visual_prompt]: 	Test 200/1152. loss: 3.156, 0.1118 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 18:59:20 visual_prompt]: 	Test 300/1152. loss: 2.880, 0.0981 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 18:59:36 visual_prompt]: 	Test 400/1152. loss: 2.962, 0.0960 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 18:59:52 visual_prompt]: 	Test 500/1152. loss: 2.904, 0.1047 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/18 19:00:08 visual_prompt]: 	Test 600/1152. loss: 2.911, 0.1170 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 19:00:24 visual_prompt]: 	Test 700/1152. loss: 2.858, 0.1102 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 19:00:40 visual_prompt]: 	Test 800/1152. loss: 2.960, 0.0982 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 19:00:56 visual_prompt]: 	Test 900/1152. loss: 2.996, 0.1094 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 19:01:13 visual_prompt]: 	Test 1000/1152. loss: 2.968, 0.1038 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 19:01:29 visual_prompt]: 	Test 1100/1152. loss: 2.967, 0.0979 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 19:01:41 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1098, average loss: 2.9669
[09/18 19:01:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.45	
[09/18 19:01:41 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/18 19:01:51 visual_prompt]: Epoch 3 / 100: avg data time: 2.40e-01, avg batch time: 0.4634, average train loss: 3.0091
[09/18 19:01:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.0980, average loss: 2.9033
[09/18 19:01:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 31.50	
[09/18 19:02:19 visual_prompt]: 	Test 100/1152. loss: 2.970, 0.0990 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 19:02:35 visual_prompt]: 	Test 200/1152. loss: 3.059, 0.1097 s / batch. (data: 1.22e-02)max mem: 17.22454 GB 
[09/18 19:02:51 visual_prompt]: 	Test 300/1152. loss: 2.974, 0.0963 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 19:03:07 visual_prompt]: 	Test 400/1152. loss: 3.014, 0.1006 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/18 19:03:23 visual_prompt]: 	Test 500/1152. loss: 3.037, 0.1164 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 19:03:39 visual_prompt]: 	Test 600/1152. loss: 3.053, 0.1162 s / batch. (data: 3.98e-05)max mem: 17.22454 GB 
[09/18 19:03:55 visual_prompt]: 	Test 700/1152. loss: 2.937, 0.1165 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/18 19:04:12 visual_prompt]: 	Test 800/1152. loss: 2.957, 0.1121 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/18 19:04:28 visual_prompt]: 	Test 900/1152. loss: 3.037, 0.0952 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/18 19:04:44 visual_prompt]: 	Test 1000/1152. loss: 3.019, 0.0953 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/18 19:05:00 visual_prompt]: 	Test 1100/1152. loss: 2.920, 0.1001 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 19:05:12 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1089, average loss: 2.9846
[09/18 19:05:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 32.34	
[09/18 19:05:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/18 19:05:23 visual_prompt]: Epoch 4 / 100: avg data time: 2.43e-01, avg batch time: 0.4765, average train loss: 3.0951
[09/18 19:05:30 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0913, average loss: 3.1700
[09/18 19:05:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 32.00	
[09/18 19:05:51 visual_prompt]: 	Test 100/1152. loss: 3.122, 0.1024 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 19:06:07 visual_prompt]: 	Test 200/1152. loss: 3.212, 0.1013 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 19:06:23 visual_prompt]: 	Test 300/1152. loss: 3.154, 0.1184 s / batch. (data: 6.58e-05)max mem: 17.22454 GB 
[09/18 19:06:39 visual_prompt]: 	Test 400/1152. loss: 3.196, 0.0983 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 19:06:55 visual_prompt]: 	Test 500/1152. loss: 3.270, 0.1045 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/18 19:07:12 visual_prompt]: 	Test 600/1152. loss: 3.340, 0.0947 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/18 19:07:28 visual_prompt]: 	Test 700/1152. loss: 3.341, 0.1116 s / batch. (data: 6.96e-05)max mem: 17.22454 GB 
[09/18 19:07:44 visual_prompt]: 	Test 800/1152. loss: 3.182, 0.0962 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/18 19:08:00 visual_prompt]: 	Test 900/1152. loss: 3.104, 0.1027 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 19:08:16 visual_prompt]: 	Test 1000/1152. loss: 3.098, 0.0967 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 19:08:32 visual_prompt]: 	Test 1100/1152. loss: 3.147, 0.0998 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/18 19:08:45 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1090, average loss: 3.1856
[09/18 19:08:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 29.99	
[09/18 19:08:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/18 19:08:56 visual_prompt]: Epoch 5 / 100: avg data time: 2.50e-01, avg batch time: 0.4782, average train loss: 3.1344
[09/18 19:09:03 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.0883, average loss: 3.3435
[09/18 19:09:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.50	
[09/18 19:09:23 visual_prompt]: 	Test 100/1152. loss: 3.147, 0.1154 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 19:09:39 visual_prompt]: 	Test 200/1152. loss: 3.228, 0.1069 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/18 19:09:56 visual_prompt]: 	Test 300/1152. loss: 3.061, 0.1957 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/18 19:10:12 visual_prompt]: 	Test 400/1152. loss: 3.043, 0.1076 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/18 19:10:29 visual_prompt]: 	Test 500/1152. loss: 3.220, 0.1189 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 19:10:45 visual_prompt]: 	Test 600/1152. loss: 3.230, 0.1103 s / batch. (data: 1.27e-02)max mem: 17.22454 GB 
[09/18 19:11:01 visual_prompt]: 	Test 700/1152. loss: 3.202, 0.1207 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 19:11:17 visual_prompt]: 	Test 800/1152. loss: 3.199, 0.1196 s / batch. (data: 1.79e-04)max mem: 17.22454 GB 
[09/18 19:11:33 visual_prompt]: 	Test 900/1152. loss: 3.524, 0.1153 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/18 19:11:49 visual_prompt]: 	Test 1000/1152. loss: 3.478, 0.0969 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 19:12:05 visual_prompt]: 	Test 1100/1152. loss: 3.286, 0.1151 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 19:12:18 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1085, average loss: 3.2574
[09/18 19:12:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.44	
[09/18 19:12:18 visual_prompt]: Best epoch 5: best metric: 0.075
[09/18 19:12:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/18 19:12:29 visual_prompt]: Epoch 6 / 100: avg data time: 2.44e-01, avg batch time: 0.4731, average train loss: 3.0784
[09/18 19:12:36 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.0950, average loss: 2.9029
[09/18 19:12:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 40.50	
[09/18 19:12:56 visual_prompt]: 	Test 100/1152. loss: 3.261, 0.1073 s / batch. (data: 1.79e-04)max mem: 17.22454 GB 
[09/18 19:13:12 visual_prompt]: 	Test 200/1152. loss: 3.228, 0.1082 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 19:13:29 visual_prompt]: 	Test 300/1152. loss: 2.984, 0.1156 s / batch. (data: 4.63e-05)max mem: 17.22454 GB 
[09/18 19:13:45 visual_prompt]: 	Test 400/1152. loss: 3.088, 0.0944 s / batch. (data: 7.10e-05)max mem: 17.22454 GB 
[09/18 19:14:01 visual_prompt]: 	Test 500/1152. loss: 3.170, 0.1108 s / batch. (data: 1.86e-04)max mem: 17.22454 GB 
[09/18 19:14:17 visual_prompt]: 	Test 600/1152. loss: 3.107, 0.0950 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/18 19:14:33 visual_prompt]: 	Test 700/1152. loss: 2.704, 0.1053 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/18 19:14:49 visual_prompt]: 	Test 800/1152. loss: 3.091, 0.1132 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 19:15:06 visual_prompt]: 	Test 900/1152. loss: 2.993, 0.1239 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/18 19:15:22 visual_prompt]: 	Test 1000/1152. loss: 3.074, 0.1074 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 19:15:38 visual_prompt]: 	Test 1100/1152. loss: 3.175, 0.1119 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 19:15:50 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1093, average loss: 3.0527
[09/18 19:15:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.13	
[09/18 19:15:50 visual_prompt]: Best epoch 6: best metric: 0.105
[09/18 19:15:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/18 19:16:01 visual_prompt]: Epoch 7 / 100: avg data time: 2.32e-01, avg batch time: 0.4629, average train loss: 3.1659
[09/18 19:16:08 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.0862, average loss: 3.0613
[09/18 19:16:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 36.50	
[09/18 19:16:28 visual_prompt]: 	Test 100/1152. loss: 3.203, 0.1524 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 19:16:45 visual_prompt]: 	Test 200/1152. loss: 3.200, 0.1263 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/18 19:17:01 visual_prompt]: 	Test 300/1152. loss: 2.863, 0.1070 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 19:17:17 visual_prompt]: 	Test 400/1152. loss: 3.210, 0.1299 s / batch. (data: 7.22e-05)max mem: 17.22454 GB 
[09/18 19:17:33 visual_prompt]: 	Test 500/1152. loss: 3.094, 0.1136 s / batch. (data: 9.76e-03)max mem: 17.22454 GB 
[09/18 19:17:49 visual_prompt]: 	Test 600/1152. loss: 3.095, 0.1308 s / batch. (data: 9.86e-03)max mem: 17.22454 GB 
[09/18 19:18:05 visual_prompt]: 	Test 700/1152. loss: 3.062, 0.1078 s / batch. (data: 3.22e-03)max mem: 17.22454 GB 
[09/18 19:18:21 visual_prompt]: 	Test 800/1152. loss: 2.959, 0.0971 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 19:18:37 visual_prompt]: 	Test 900/1152. loss: 3.157, 0.1011 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 19:18:53 visual_prompt]: 	Test 1000/1152. loss: 3.079, 0.1043 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/18 19:19:10 visual_prompt]: 	Test 1100/1152. loss: 3.154, 0.1248 s / batch. (data: 7.56e-05)max mem: 17.22454 GB 
[09/18 19:19:22 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1088, average loss: 3.0783
[09/18 19:19:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 35.05	
[09/18 19:19:22 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/18 19:19:33 visual_prompt]: Epoch 8 / 100: avg data time: 2.39e-01, avg batch time: 0.4646, average train loss: 3.2080
[09/18 19:19:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0896, average loss: 3.6593
[09/18 19:19:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 29.50	
[09/18 19:20:00 visual_prompt]: 	Test 100/1152. loss: 4.256, 0.1070 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 19:20:16 visual_prompt]: 	Test 200/1152. loss: 3.608, 0.1038 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 19:20:33 visual_prompt]: 	Test 300/1152. loss: 3.998, 0.1058 s / batch. (data: 1.86e-04)max mem: 17.22454 GB 
[09/18 19:20:49 visual_prompt]: 	Test 400/1152. loss: 4.008, 0.1133 s / batch. (data: 4.08e-05)max mem: 17.22454 GB 
[09/18 19:21:05 visual_prompt]: 	Test 500/1152. loss: 3.751, 0.1227 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 19:21:21 visual_prompt]: 	Test 600/1152. loss: 3.994, 0.0995 s / batch. (data: 1.89e-04)max mem: 17.22454 GB 
[09/18 19:21:37 visual_prompt]: 	Test 700/1152. loss: 3.928, 0.0974 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 19:21:54 visual_prompt]: 	Test 800/1152. loss: 4.041, 0.0987 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 19:22:10 visual_prompt]: 	Test 900/1152. loss: 4.055, 0.1490 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 19:22:26 visual_prompt]: 	Test 1000/1152. loss: 3.778, 0.0989 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/18 19:22:43 visual_prompt]: 	Test 1100/1152. loss: 3.931, 0.0979 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/18 19:22:55 visual_prompt]: Inference (test):avg data time: 1.58e-03, avg batch time: 0.1091, average loss: 3.7614
[09/18 19:22:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.62	
[09/18 19:22:55 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/18 19:23:06 visual_prompt]: Epoch 9 / 100: avg data time: 2.52e-01, avg batch time: 0.4778, average train loss: 3.5326
[09/18 19:23:13 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.0913, average loss: 3.4205
[09/18 19:23:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 35.00	
[09/18 19:23:33 visual_prompt]: 	Test 100/1152. loss: 3.497, 0.0974 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 19:23:49 visual_prompt]: 	Test 200/1152. loss: 3.113, 0.1251 s / batch. (data: 1.93e-04)max mem: 17.22454 GB 
[09/18 19:24:05 visual_prompt]: 	Test 300/1152. loss: 3.549, 0.1040 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 19:24:21 visual_prompt]: 	Test 400/1152. loss: 3.538, 0.1013 s / batch. (data: 2.28e-04)max mem: 17.22454 GB 
[09/18 19:24:37 visual_prompt]: 	Test 500/1152. loss: 3.346, 0.1118 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 19:24:53 visual_prompt]: 	Test 600/1152. loss: 3.337, 0.1050 s / batch. (data: 7.11e-03)max mem: 17.22454 GB 
[09/18 19:25:10 visual_prompt]: 	Test 700/1152. loss: 3.569, 0.0961 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 19:25:25 visual_prompt]: 	Test 800/1152. loss: 3.470, 0.0983 s / batch. (data: 2.27e-04)max mem: 17.22454 GB 
[09/18 19:25:42 visual_prompt]: 	Test 900/1152. loss: 3.479, 0.1158 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 19:25:58 visual_prompt]: 	Test 1000/1152. loss: 3.239, 0.1118 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 19:26:14 visual_prompt]: 	Test 1100/1152. loss: 3.561, 0.0954 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/18 19:26:26 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1096, average loss: 3.4291
[09/18 19:26:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.16	
[09/18 19:26:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/18 19:26:37 visual_prompt]: Epoch 10 / 100: avg data time: 2.49e-01, avg batch time: 0.4732, average train loss: 3.2419
[09/18 19:26:44 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.0883, average loss: 2.9955
[09/18 19:26:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 34.50	
[09/18 19:27:04 visual_prompt]: 	Test 100/1152. loss: 3.068, 0.1107 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/18 19:27:21 visual_prompt]: 	Test 200/1152. loss: 2.793, 0.1104 s / batch. (data: 2.57e-04)max mem: 17.22454 GB 
[09/18 19:27:37 visual_prompt]: 	Test 300/1152. loss: 2.958, 0.1524 s / batch. (data: 8.28e-03)max mem: 17.22454 GB 
[09/18 19:27:53 visual_prompt]: 	Test 400/1152. loss: 3.060, 0.1117 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 19:28:09 visual_prompt]: 	Test 500/1152. loss: 2.924, 0.1152 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 19:28:25 visual_prompt]: 	Test 600/1152. loss: 2.915, 0.1117 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 19:28:41 visual_prompt]: 	Test 700/1152. loss: 3.059, 0.1083 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 19:28:58 visual_prompt]: 	Test 800/1152. loss: 2.942, 0.1281 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/18 19:29:14 visual_prompt]: 	Test 900/1152. loss: 3.031, 0.0969 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 19:29:30 visual_prompt]: 	Test 1000/1152. loss: 2.854, 0.1039 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 19:29:46 visual_prompt]: 	Test 1100/1152. loss: 3.101, 0.0991 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 19:29:58 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1083, average loss: 2.9772
[09/18 19:29:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.75	
[09/18 19:29:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/18 19:30:09 visual_prompt]: Epoch 11 / 100: avg data time: 2.41e-01, avg batch time: 0.4676, average train loss: 3.1035
[09/18 19:30:16 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0947, average loss: 3.3370
[09/18 19:30:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.50	
[09/18 19:30:36 visual_prompt]: 	Test 100/1152. loss: 3.378, 0.1119 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 19:30:53 visual_prompt]: 	Test 200/1152. loss: 3.426, 0.0966 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 19:31:09 visual_prompt]: 	Test 300/1152. loss: 3.110, 0.0942 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 19:31:25 visual_prompt]: 	Test 400/1152. loss: 3.163, 0.1444 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 19:31:41 visual_prompt]: 	Test 500/1152. loss: 3.264, 0.0960 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 19:31:57 visual_prompt]: 	Test 600/1152. loss: 3.334, 0.1137 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 19:32:13 visual_prompt]: 	Test 700/1152. loss: 3.279, 0.1057 s / batch. (data: 8.74e-03)max mem: 17.22454 GB 
[09/18 19:32:30 visual_prompt]: 	Test 800/1152. loss: 3.173, 0.1378 s / batch. (data: 3.78e-02)max mem: 17.22454 GB 
[09/18 19:32:46 visual_prompt]: 	Test 900/1152. loss: 3.389, 0.1346 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 19:33:02 visual_prompt]: 	Test 1000/1152. loss: 3.302, 0.1078 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 19:33:18 visual_prompt]: 	Test 1100/1152. loss: 3.591, 0.1319 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/18 19:33:31 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1089, average loss: 3.2909
[09/18 19:33:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.69	
[09/18 19:33:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/18 19:33:42 visual_prompt]: Epoch 12 / 100: avg data time: 2.40e-01, avg batch time: 0.4687, average train loss: 3.1738
[09/18 19:33:49 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.0936, average loss: 3.0910
[09/18 19:33:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 34.50	
[09/18 19:34:09 visual_prompt]: 	Test 100/1152. loss: 3.269, 0.1078 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 19:34:25 visual_prompt]: 	Test 200/1152. loss: 3.119, 0.1133 s / batch. (data: 4.08e-05)max mem: 17.22454 GB 
[09/18 19:34:41 visual_prompt]: 	Test 300/1152. loss: 3.108, 0.1199 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 19:34:58 visual_prompt]: 	Test 400/1152. loss: 3.055, 0.1128 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 19:35:14 visual_prompt]: 	Test 500/1152. loss: 3.119, 0.0993 s / batch. (data: 2.46e-04)max mem: 17.22454 GB 
[09/18 19:35:30 visual_prompt]: 	Test 600/1152. loss: 3.393, 0.1257 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 19:35:46 visual_prompt]: 	Test 700/1152. loss: 3.068, 0.1112 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/18 19:36:02 visual_prompt]: 	Test 800/1152. loss: 3.040, 0.1216 s / batch. (data: 7.08e-03)max mem: 17.22454 GB 
[09/18 19:36:18 visual_prompt]: 	Test 900/1152. loss: 3.404, 0.0970 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 19:36:34 visual_prompt]: 	Test 1000/1152. loss: 3.056, 0.0965 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 19:36:50 visual_prompt]: 	Test 1100/1152. loss: 3.273, 0.1310 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 19:37:03 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1086, average loss: 3.1068
[09/18 19:37:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 34.78	
[09/18 19:37:03 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/18 19:37:13 visual_prompt]: Epoch 13 / 100: avg data time: 2.40e-01, avg batch time: 0.4697, average train loss: 3.2926
[09/18 19:37:20 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.0966, average loss: 3.2908
[09/18 19:37:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 34.00	
[09/18 19:37:40 visual_prompt]: 	Test 100/1152. loss: 3.431, 0.1197 s / batch. (data: 7.06e-03)max mem: 17.22454 GB 
[09/18 19:37:57 visual_prompt]: 	Test 200/1152. loss: 3.471, 0.1067 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 19:38:13 visual_prompt]: 	Test 300/1152. loss: 3.808, 0.0974 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 19:38:29 visual_prompt]: 	Test 400/1152. loss: 3.569, 0.0994 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 19:38:45 visual_prompt]: 	Test 500/1152. loss: 3.493, 0.1203 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 19:39:01 visual_prompt]: 	Test 600/1152. loss: 3.683, 0.1286 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 19:39:17 visual_prompt]: 	Test 700/1152. loss: 3.516, 0.1425 s / batch. (data: 3.28e-02)max mem: 17.22454 GB 
[09/18 19:39:33 visual_prompt]: 	Test 800/1152. loss: 3.553, 0.0992 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 19:39:50 visual_prompt]: 	Test 900/1152. loss: 3.280, 0.1157 s / batch. (data: 2.16e-04)max mem: 17.22454 GB 
[09/18 19:40:06 visual_prompt]: 	Test 1000/1152. loss: 3.438, 0.1001 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 19:40:22 visual_prompt]: 	Test 1100/1152. loss: 3.590, 0.1270 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/18 19:40:34 visual_prompt]: Inference (test):avg data time: 2.44e-03, avg batch time: 0.1095, average loss: 3.4841
[09/18 19:40:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 30.03	
[09/18 19:40:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/18 19:40:45 visual_prompt]: Epoch 14 / 100: avg data time: 2.45e-01, avg batch time: 0.4683, average train loss: 3.1506
[09/18 19:40:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0970, average loss: 2.9044
[09/18 19:40:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 39.50	
[09/18 19:41:12 visual_prompt]: 	Test 100/1152. loss: 3.005, 0.1045 s / batch. (data: 1.48e-05)max mem: 17.22454 GB 
[09/18 19:41:28 visual_prompt]: 	Test 200/1152. loss: 3.028, 0.1078 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 19:41:45 visual_prompt]: 	Test 300/1152. loss: 2.970, 0.1120 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 19:42:01 visual_prompt]: 	Test 400/1152. loss: 2.932, 0.1195 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 19:42:17 visual_prompt]: 	Test 500/1152. loss: 2.962, 0.1108 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 19:42:33 visual_prompt]: 	Test 600/1152. loss: 2.933, 0.1117 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 19:42:50 visual_prompt]: 	Test 700/1152. loss: 2.751, 0.1074 s / batch. (data: 4.30e-03)max mem: 17.22454 GB 
[09/18 19:43:06 visual_prompt]: 	Test 800/1152. loss: 2.933, 0.1000 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/18 19:43:21 visual_prompt]: 	Test 900/1152. loss: 2.880, 0.0987 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 19:43:37 visual_prompt]: 	Test 1000/1152. loss: 2.906, 0.0964 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/18 19:43:54 visual_prompt]: 	Test 1100/1152. loss: 2.961, 0.0943 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 19:44:06 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1091, average loss: 2.9414
[09/18 19:44:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.46	
[09/18 19:44:06 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/18 19:44:17 visual_prompt]: Epoch 15 / 100: avg data time: 2.34e-01, avg batch time: 0.4612, average train loss: 2.9985
[09/18 19:44:24 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.0948, average loss: 2.9750
[09/18 19:44:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 36.00	
[09/18 19:44:44 visual_prompt]: 	Test 100/1152. loss: 3.321, 0.1276 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 19:45:00 visual_prompt]: 	Test 200/1152. loss: 2.933, 0.1110 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 19:45:17 visual_prompt]: 	Test 300/1152. loss: 3.145, 0.0959 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 19:45:33 visual_prompt]: 	Test 400/1152. loss: 3.104, 0.1246 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 19:45:49 visual_prompt]: 	Test 500/1152. loss: 3.060, 0.1030 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/18 19:46:05 visual_prompt]: 	Test 600/1152. loss: 3.030, 0.1548 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 19:46:21 visual_prompt]: 	Test 700/1152. loss: 3.027, 0.0986 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 19:46:36 visual_prompt]: 	Test 800/1152. loss: 3.045, 0.0960 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 19:46:53 visual_prompt]: 	Test 900/1152. loss: 3.150, 0.0943 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 19:47:09 visual_prompt]: 	Test 1000/1152. loss: 3.143, 0.1178 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/18 19:47:25 visual_prompt]: 	Test 1100/1152. loss: 3.182, 0.1008 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 19:47:37 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1091, average loss: 3.0444
[09/18 19:47:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 34.77	
[09/18 19:47:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/18 19:47:48 visual_prompt]: Epoch 16 / 100: avg data time: 2.47e-01, avg batch time: 0.4738, average train loss: 2.9786
[09/18 19:47:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.0882, average loss: 2.8892
[09/18 19:47:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 32.50	
[09/18 19:48:16 visual_prompt]: 	Test 100/1152. loss: 3.022, 0.1087 s / batch. (data: 1.87e-04)max mem: 17.22454 GB 
[09/18 19:48:33 visual_prompt]: 	Test 200/1152. loss: 2.934, 0.1115 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/18 19:48:49 visual_prompt]: 	Test 300/1152. loss: 2.849, 0.1222 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 19:49:06 visual_prompt]: 	Test 400/1152. loss: 2.854, 0.1218 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/18 19:49:22 visual_prompt]: 	Test 500/1152. loss: 2.859, 0.1277 s / batch. (data: 1.90e-04)max mem: 17.22454 GB 
[09/18 19:49:38 visual_prompt]: 	Test 600/1152. loss: 2.937, 0.0996 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/18 19:49:54 visual_prompt]: 	Test 700/1152. loss: 2.880, 0.1246 s / batch. (data: 2.14e-02)max mem: 17.22454 GB 
[09/18 19:50:10 visual_prompt]: 	Test 800/1152. loss: 2.988, 0.1182 s / batch. (data: 2.27e-02)max mem: 17.22454 GB 
[09/18 19:50:27 visual_prompt]: 	Test 900/1152. loss: 3.078, 0.1136 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/18 19:50:43 visual_prompt]: 	Test 1000/1152. loss: 3.042, 0.0977 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/18 19:50:59 visual_prompt]: 	Test 1100/1152. loss: 2.997, 0.1019 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/18 19:51:11 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1097, average loss: 2.8817
[09/18 19:51:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.97	
[09/18 19:51:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/18 19:51:22 visual_prompt]: Epoch 17 / 100: avg data time: 2.32e-01, avg batch time: 0.4625, average train loss: 2.9805
[09/18 19:51:29 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.0876, average loss: 2.9381
[09/18 19:51:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.00	top5: 33.00	
[09/18 19:51:49 visual_prompt]: 	Test 100/1152. loss: 3.010, 0.1234 s / batch. (data: 7.08e-03)max mem: 17.22454 GB 
[09/18 19:52:05 visual_prompt]: 	Test 200/1152. loss: 2.948, 0.0991 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/18 19:52:21 visual_prompt]: 	Test 300/1152. loss: 3.107, 0.1235 s / batch. (data: 4.43e-05)max mem: 17.22454 GB 
[09/18 19:52:37 visual_prompt]: 	Test 400/1152. loss: 2.921, 0.1076 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/18 19:52:54 visual_prompt]: 	Test 500/1152. loss: 3.056, 0.0968 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 19:53:10 visual_prompt]: 	Test 600/1152. loss: 3.191, 0.0986 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/18 19:53:26 visual_prompt]: 	Test 700/1152. loss: 2.931, 0.0972 s / batch. (data: 7.10e-05)max mem: 17.22454 GB 
[09/18 19:53:42 visual_prompt]: 	Test 800/1152. loss: 3.187, 0.0941 s / batch. (data: 6.72e-05)max mem: 17.22454 GB 
[09/18 19:53:58 visual_prompt]: 	Test 900/1152. loss: 3.028, 0.1197 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/18 19:54:14 visual_prompt]: 	Test 1000/1152. loss: 2.980, 0.1201 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 19:54:31 visual_prompt]: 	Test 1100/1152. loss: 3.016, 0.1335 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 19:54:43 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1088, average loss: 3.0020
[09/18 19:54:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.87	top5: 32.64	
[09/18 19:54:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/18 19:54:54 visual_prompt]: Epoch 18 / 100: avg data time: 2.34e-01, avg batch time: 0.4667, average train loss: 3.0087
[09/18 19:55:01 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.0933, average loss: 2.8326
[09/18 19:55:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 37.00	
[09/18 19:55:21 visual_prompt]: 	Test 100/1152. loss: 2.826, 0.0947 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/18 19:55:37 visual_prompt]: 	Test 200/1152. loss: 2.864, 0.1033 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 19:55:53 visual_prompt]: 	Test 300/1152. loss: 2.930, 0.0985 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 19:56:09 visual_prompt]: 	Test 400/1152. loss: 2.894, 0.0995 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 19:56:25 visual_prompt]: 	Test 500/1152. loss: 2.841, 0.1229 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 19:56:41 visual_prompt]: 	Test 600/1152. loss: 2.901, 0.1035 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 19:56:57 visual_prompt]: 	Test 700/1152. loss: 3.114, 0.1113 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/18 19:57:14 visual_prompt]: 	Test 800/1152. loss: 2.927, 0.0983 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 19:57:30 visual_prompt]: 	Test 900/1152. loss: 2.890, 0.0992 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 19:57:46 visual_prompt]: 	Test 1000/1152. loss: 2.899, 0.1142 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 19:58:02 visual_prompt]: 	Test 1100/1152. loss: 2.893, 0.0959 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 19:58:15 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1089, average loss: 2.8838
[09/18 19:58:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 35.10	
[09/18 19:58:15 visual_prompt]: Best epoch 18: best metric: 0.115
[09/18 19:58:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/18 19:58:26 visual_prompt]: Epoch 19 / 100: avg data time: 2.43e-01, avg batch time: 0.4716, average train loss: 2.9539
[09/18 19:58:33 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.0937, average loss: 3.1384
[09/18 19:58:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 38.00	
[09/18 19:58:53 visual_prompt]: 	Test 100/1152. loss: 3.193, 0.0992 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 19:59:09 visual_prompt]: 	Test 200/1152. loss: 3.331, 0.0991 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 19:59:25 visual_prompt]: 	Test 300/1152. loss: 3.223, 0.1154 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/18 19:59:41 visual_prompt]: 	Test 400/1152. loss: 3.050, 0.1131 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 19:59:57 visual_prompt]: 	Test 500/1152. loss: 3.231, 0.1073 s / batch. (data: 1.97e-04)max mem: 17.22454 GB 
[09/18 20:00:13 visual_prompt]: 	Test 600/1152. loss: 3.353, 0.1183 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 20:00:29 visual_prompt]: 	Test 700/1152. loss: 3.112, 0.1198 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 20:00:45 visual_prompt]: 	Test 800/1152. loss: 3.395, 0.0978 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 20:01:01 visual_prompt]: 	Test 900/1152. loss: 3.229, 0.1079 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 20:01:18 visual_prompt]: 	Test 1000/1152. loss: 3.277, 0.0964 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 20:01:34 visual_prompt]: 	Test 1100/1152. loss: 3.413, 0.0993 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 20:01:46 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1090, average loss: 3.2289
[09/18 20:01:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 34.96	
[09/18 20:01:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/18 20:01:57 visual_prompt]: Epoch 20 / 100: avg data time: 2.43e-01, avg batch time: 0.4672, average train loss: 3.0574
[09/18 20:02:04 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.0968, average loss: 2.9689
[09/18 20:02:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.50	
[09/18 20:02:24 visual_prompt]: 	Test 100/1152. loss: 2.829, 0.0985 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 20:02:40 visual_prompt]: 	Test 200/1152. loss: 2.816, 0.1105 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 20:02:56 visual_prompt]: 	Test 300/1152. loss: 3.037, 0.0964 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/18 20:03:13 visual_prompt]: 	Test 400/1152. loss: 3.032, 0.1046 s / batch. (data: 7.87e-05)max mem: 17.22454 GB 
[09/18 20:03:29 visual_prompt]: 	Test 500/1152. loss: 2.936, 0.1054 s / batch. (data: 4.82e-03)max mem: 17.22454 GB 
[09/18 20:03:45 visual_prompt]: 	Test 600/1152. loss: 2.919, 0.0992 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/18 20:04:01 visual_prompt]: 	Test 700/1152. loss: 3.169, 0.1073 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 20:04:17 visual_prompt]: 	Test 800/1152. loss: 2.864, 0.1064 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 20:04:33 visual_prompt]: 	Test 900/1152. loss: 2.949, 0.1121 s / batch. (data: 6.96e-05)max mem: 17.22454 GB 
[09/18 20:04:49 visual_prompt]: 	Test 1000/1152. loss: 2.935, 0.0956 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 20:05:06 visual_prompt]: 	Test 1100/1152. loss: 2.948, 0.0942 s / batch. (data: 7.53e-05)max mem: 17.22454 GB 
[09/18 20:05:17 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1091, average loss: 2.9983
[09/18 20:05:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.63	
[09/18 20:05:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/18 20:05:28 visual_prompt]: Epoch 21 / 100: avg data time: 2.42e-01, avg batch time: 0.4709, average train loss: 3.0655
[09/18 20:05:35 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.0877, average loss: 3.3000
[09/18 20:05:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 38.00	
[09/18 20:05:55 visual_prompt]: 	Test 100/1152. loss: 3.140, 0.1328 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/18 20:06:11 visual_prompt]: 	Test 200/1152. loss: 3.397, 0.0970 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 20:06:28 visual_prompt]: 	Test 300/1152. loss: 2.922, 0.0961 s / batch. (data: 4.60e-05)max mem: 17.22454 GB 
[09/18 20:06:44 visual_prompt]: 	Test 400/1152. loss: 3.167, 0.1000 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/18 20:07:00 visual_prompt]: 	Test 500/1152. loss: 3.165, 0.1058 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 20:07:16 visual_prompt]: 	Test 600/1152. loss: 3.145, 0.0965 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 20:07:32 visual_prompt]: 	Test 700/1152. loss: 3.485, 0.1177 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/18 20:07:48 visual_prompt]: 	Test 800/1152. loss: 3.184, 0.1028 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 20:08:04 visual_prompt]: 	Test 900/1152. loss: 3.203, 0.1078 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 20:08:21 visual_prompt]: 	Test 1000/1152. loss: 3.115, 0.1278 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/18 20:08:36 visual_prompt]: 	Test 1100/1152. loss: 3.438, 0.1078 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/18 20:08:49 visual_prompt]: Inference (test):avg data time: 1.83e-03, avg batch time: 0.1093, average loss: 3.2499
[09/18 20:08:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 35.09	
[09/18 20:08:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/18 20:09:00 visual_prompt]: Epoch 22 / 100: avg data time: 2.41e-01, avg batch time: 0.4681, average train loss: 3.0683
[09/18 20:09:07 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.0896, average loss: 2.8024
[09/18 20:09:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 38.00	
[09/18 20:09:27 visual_prompt]: 	Test 100/1152. loss: 2.867, 0.1199 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 20:09:44 visual_prompt]: 	Test 200/1152. loss: 2.880, 0.1354 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 20:10:00 visual_prompt]: 	Test 300/1152. loss: 2.873, 0.0987 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 20:10:17 visual_prompt]: 	Test 400/1152. loss: 2.895, 0.0951 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 20:10:33 visual_prompt]: 	Test 500/1152. loss: 2.836, 0.0941 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/18 20:10:49 visual_prompt]: 	Test 600/1152. loss: 2.911, 0.1155 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 20:11:05 visual_prompt]: 	Test 700/1152. loss: 2.838, 0.1184 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/18 20:11:21 visual_prompt]: 	Test 800/1152. loss: 2.920, 0.1053 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/18 20:11:37 visual_prompt]: 	Test 900/1152. loss: 2.841, 0.1043 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/18 20:11:53 visual_prompt]: 	Test 1000/1152. loss: 2.851, 0.1122 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 20:12:09 visual_prompt]: 	Test 1100/1152. loss: 2.812, 0.0949 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:12:21 visual_prompt]: Inference (test):avg data time: 2.13e-03, avg batch time: 0.1090, average loss: 2.8443
[09/18 20:12:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.13	top5: 32.57	
[09/18 20:12:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/18 20:12:32 visual_prompt]: Epoch 23 / 100: avg data time: 2.41e-01, avg batch time: 0.4655, average train loss: 2.9060
[09/18 20:12:39 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.0958, average loss: 3.0290
[09/18 20:12:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 25.50	
[09/18 20:12:59 visual_prompt]: 	Test 100/1152. loss: 2.866, 0.1004 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 20:13:15 visual_prompt]: 	Test 200/1152. loss: 2.970, 0.0977 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 20:13:32 visual_prompt]: 	Test 300/1152. loss: 2.803, 0.1063 s / batch. (data: 1.81e-04)max mem: 17.22454 GB 
[09/18 20:13:48 visual_prompt]: 	Test 400/1152. loss: 2.872, 0.1033 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/18 20:14:04 visual_prompt]: 	Test 500/1152. loss: 2.923, 0.1001 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 20:14:20 visual_prompt]: 	Test 600/1152. loss: 2.905, 0.1192 s / batch. (data: 9.25e-03)max mem: 17.22454 GB 
[09/18 20:14:36 visual_prompt]: 	Test 700/1152. loss: 2.942, 0.1186 s / batch. (data: 1.88e-04)max mem: 17.22454 GB 
[09/18 20:14:52 visual_prompt]: 	Test 800/1152. loss: 2.881, 0.1134 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 20:15:08 visual_prompt]: 	Test 900/1152. loss: 3.022, 0.1038 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 20:15:24 visual_prompt]: 	Test 1000/1152. loss: 2.971, 0.1079 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 20:15:40 visual_prompt]: 	Test 1100/1152. loss: 2.869, 0.0998 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 20:15:52 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1090, average loss: 2.9368
[09/18 20:15:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 29.81	
[09/18 20:15:53 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/18 20:16:03 visual_prompt]: Epoch 24 / 100: avg data time: 2.34e-01, avg batch time: 0.4593, average train loss: 2.9726
[09/18 20:16:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0873, average loss: 2.9576
[09/18 20:16:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 38.00	
[09/18 20:16:30 visual_prompt]: 	Test 100/1152. loss: 3.188, 0.1017 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 20:16:46 visual_prompt]: 	Test 200/1152. loss: 3.162, 0.0966 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 20:17:03 visual_prompt]: 	Test 300/1152. loss: 2.892, 0.1519 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 20:17:18 visual_prompt]: 	Test 400/1152. loss: 2.956, 0.0979 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 20:17:35 visual_prompt]: 	Test 500/1152. loss: 3.007, 0.0985 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/18 20:17:51 visual_prompt]: 	Test 600/1152. loss: 2.942, 0.1031 s / batch. (data: 1.86e-04)max mem: 17.22454 GB 
[09/18 20:18:07 visual_prompt]: 	Test 700/1152. loss: 2.764, 0.1036 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 20:18:23 visual_prompt]: 	Test 800/1152. loss: 3.053, 0.1158 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 20:18:39 visual_prompt]: 	Test 900/1152. loss: 3.008, 0.1162 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/18 20:18:55 visual_prompt]: 	Test 1000/1152. loss: 3.033, 0.1164 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/18 20:19:12 visual_prompt]: 	Test 1100/1152. loss: 2.976, 0.1160 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 20:19:24 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1089, average loss: 2.9533
[09/18 20:19:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 36.98	
[09/18 20:19:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/18 20:19:35 visual_prompt]: Epoch 25 / 100: avg data time: 2.43e-01, avg batch time: 0.4745, average train loss: 3.0120
[09/18 20:19:42 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.0870, average loss: 2.9351
[09/18 20:19:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 31.00	
[09/18 20:20:02 visual_prompt]: 	Test 100/1152. loss: 3.032, 0.1920 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 20:20:18 visual_prompt]: 	Test 200/1152. loss: 2.893, 0.1105 s / batch. (data: 8.09e-03)max mem: 17.22454 GB 
[09/18 20:20:34 visual_prompt]: 	Test 300/1152. loss: 3.222, 0.1078 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 20:20:51 visual_prompt]: 	Test 400/1152. loss: 3.067, 0.1032 s / batch. (data: 7.18e-03)max mem: 17.22454 GB 
[09/18 20:21:07 visual_prompt]: 	Test 500/1152. loss: 3.010, 0.0999 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 20:21:23 visual_prompt]: 	Test 600/1152. loss: 3.140, 0.1068 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 20:21:39 visual_prompt]: 	Test 700/1152. loss: 3.119, 0.1198 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/18 20:21:56 visual_prompt]: 	Test 800/1152. loss: 3.119, 0.1131 s / batch. (data: 2.05e-04)max mem: 17.22454 GB 
[09/18 20:22:12 visual_prompt]: 	Test 900/1152. loss: 3.001, 0.1053 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 20:22:28 visual_prompt]: 	Test 1000/1152. loss: 2.917, 0.1201 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 20:22:45 visual_prompt]: 	Test 1100/1152. loss: 2.978, 0.1013 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:22:57 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1089, average loss: 2.9949
[09/18 20:22:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 29.88	
[09/18 20:22:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/18 20:23:08 visual_prompt]: Epoch 26 / 100: avg data time: 2.47e-01, avg batch time: 0.4740, average train loss: 3.0045
[09/18 20:23:15 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.0937, average loss: 2.8605
[09/18 20:23:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 42.50	
[09/18 20:23:35 visual_prompt]: 	Test 100/1152. loss: 3.108, 0.1447 s / batch. (data: 1.88e-04)max mem: 17.22454 GB 
[09/18 20:23:51 visual_prompt]: 	Test 200/1152. loss: 3.063, 0.1181 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/18 20:24:08 visual_prompt]: 	Test 300/1152. loss: 2.997, 0.1000 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 20:24:24 visual_prompt]: 	Test 400/1152. loss: 3.056, 0.1009 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/18 20:24:40 visual_prompt]: 	Test 500/1152. loss: 2.991, 0.0972 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 20:24:56 visual_prompt]: 	Test 600/1152. loss: 2.859, 0.1297 s / batch. (data: 3.38e-02)max mem: 17.22454 GB 
[09/18 20:25:12 visual_prompt]: 	Test 700/1152. loss: 2.901, 0.1191 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 20:25:28 visual_prompt]: 	Test 800/1152. loss: 2.980, 0.1212 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 20:25:44 visual_prompt]: 	Test 900/1152. loss: 2.893, 0.1054 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 20:26:00 visual_prompt]: 	Test 1000/1152. loss: 3.086, 0.1519 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 20:26:16 visual_prompt]: 	Test 1100/1152. loss: 3.011, 0.1118 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 20:26:29 visual_prompt]: Inference (test):avg data time: 2.15e-03, avg batch time: 0.1095, average loss: 2.9775
[09/18 20:26:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.46	
[09/18 20:26:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/18 20:26:40 visual_prompt]: Epoch 27 / 100: avg data time: 2.43e-01, avg batch time: 0.4741, average train loss: 3.0448
[09/18 20:26:47 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.0962, average loss: 2.9801
[09/18 20:26:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 36.00	
[09/18 20:27:06 visual_prompt]: 	Test 100/1152. loss: 3.071, 0.1219 s / batch. (data: 2.12e-02)max mem: 17.22454 GB 
[09/18 20:27:23 visual_prompt]: 	Test 200/1152. loss: 3.136, 0.1001 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/18 20:27:39 visual_prompt]: 	Test 300/1152. loss: 2.854, 0.0943 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/18 20:27:56 visual_prompt]: 	Test 400/1152. loss: 3.109, 0.1019 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:28:12 visual_prompt]: 	Test 500/1152. loss: 3.161, 0.1141 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 20:28:28 visual_prompt]: 	Test 600/1152. loss: 3.188, 0.1147 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 20:28:44 visual_prompt]: 	Test 700/1152. loss: 3.117, 0.0947 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/18 20:29:00 visual_prompt]: 	Test 800/1152. loss: 3.054, 0.1416 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/18 20:29:16 visual_prompt]: 	Test 900/1152. loss: 3.045, 0.0983 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/18 20:29:32 visual_prompt]: 	Test 1000/1152. loss: 3.014, 0.1242 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 20:29:48 visual_prompt]: 	Test 1100/1152. loss: 3.091, 0.0981 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 20:30:00 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1096, average loss: 3.0577
[09/18 20:30:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 32.70	
[09/18 20:30:00 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/18 20:30:10 visual_prompt]: Epoch 28 / 100: avg data time: 2.36e-01, avg batch time: 0.4619, average train loss: 3.0508
[09/18 20:30:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.0934, average loss: 2.8168
[09/18 20:30:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 39.50	
[09/18 20:30:37 visual_prompt]: 	Test 100/1152. loss: 2.905, 0.0981 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 20:30:54 visual_prompt]: 	Test 200/1152. loss: 2.995, 0.1115 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/18 20:31:10 visual_prompt]: 	Test 300/1152. loss: 3.000, 0.0986 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/18 20:31:26 visual_prompt]: 	Test 400/1152. loss: 2.858, 0.1098 s / batch. (data: 1.88e-05)max mem: 17.22454 GB 
[09/18 20:31:42 visual_prompt]: 	Test 500/1152. loss: 2.905, 0.1384 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/18 20:31:58 visual_prompt]: 	Test 600/1152. loss: 2.882, 0.0970 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 20:32:14 visual_prompt]: 	Test 700/1152. loss: 2.831, 0.1159 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/18 20:32:31 visual_prompt]: 	Test 800/1152. loss: 2.911, 0.0994 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 20:32:47 visual_prompt]: 	Test 900/1152. loss: 2.778, 0.1260 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 20:33:03 visual_prompt]: 	Test 1000/1152. loss: 2.826, 0.1438 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/18 20:33:19 visual_prompt]: 	Test 1100/1152. loss: 2.936, 0.1272 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/18 20:33:32 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1089, average loss: 2.8945
[09/18 20:33:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 32.45	
[09/18 20:33:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/18 20:33:43 visual_prompt]: Epoch 29 / 100: avg data time: 2.36e-01, avg batch time: 0.4632, average train loss: 2.9547
[09/18 20:33:50 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.0877, average loss: 2.8216
[09/18 20:33:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 34.50	
[09/18 20:34:10 visual_prompt]: 	Test 100/1152. loss: 2.799, 0.1155 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/18 20:34:27 visual_prompt]: 	Test 200/1152. loss: 2.864, 0.0958 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 20:34:43 visual_prompt]: 	Test 300/1152. loss: 2.872, 0.1052 s / batch. (data: 1.31e-05)max mem: 17.22454 GB 
[09/18 20:34:59 visual_prompt]: 	Test 400/1152. loss: 2.989, 0.1040 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/18 20:35:15 visual_prompt]: 	Test 500/1152. loss: 2.858, 0.0972 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 20:35:32 visual_prompt]: 	Test 600/1152. loss: 2.851, 0.1018 s / batch. (data: 6.77e-05)max mem: 17.22454 GB 
[09/18 20:35:48 visual_prompt]: 	Test 700/1152. loss: 3.070, 0.1281 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 20:36:04 visual_prompt]: 	Test 800/1152. loss: 2.857, 0.1159 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 20:36:20 visual_prompt]: 	Test 900/1152. loss: 2.799, 0.0996 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 20:36:36 visual_prompt]: 	Test 1000/1152. loss: 2.927, 0.1035 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 20:36:53 visual_prompt]: 	Test 1100/1152. loss: 2.861, 0.0943 s / batch. (data: 6.53e-05)max mem: 17.22454 GB 
[09/18 20:37:05 visual_prompt]: Inference (test):avg data time: 1.54e-03, avg batch time: 0.1088, average loss: 2.8950
[09/18 20:37:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 30.15	
[09/18 20:37:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/18 20:37:16 visual_prompt]: Epoch 30 / 100: avg data time: 2.49e-01, avg batch time: 0.4766, average train loss: 3.0077
[09/18 20:37:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0942, average loss: 2.9617
[09/18 20:37:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 40.50	
[09/18 20:37:43 visual_prompt]: 	Test 100/1152. loss: 3.198, 0.0959 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 20:38:00 visual_prompt]: 	Test 200/1152. loss: 2.885, 0.1023 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 20:38:16 visual_prompt]: 	Test 300/1152. loss: 3.117, 0.1241 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 20:38:33 visual_prompt]: 	Test 400/1152. loss: 2.966, 0.1400 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 20:38:49 visual_prompt]: 	Test 500/1152. loss: 2.996, 0.1304 s / batch. (data: 9.75e-03)max mem: 17.22454 GB 
[09/18 20:39:05 visual_prompt]: 	Test 600/1152. loss: 2.982, 0.1158 s / batch. (data: 2.57e-05)max mem: 17.22454 GB 
[09/18 20:39:21 visual_prompt]: 	Test 700/1152. loss: 2.832, 0.1038 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 20:39:38 visual_prompt]: 	Test 800/1152. loss: 3.148, 0.1119 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 20:39:54 visual_prompt]: 	Test 900/1152. loss: 3.063, 0.1058 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 20:40:10 visual_prompt]: 	Test 1000/1152. loss: 3.023, 0.0987 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 20:40:27 visual_prompt]: 	Test 1100/1152. loss: 3.158, 0.1095 s / batch. (data: 4.91e-03)max mem: 17.22454 GB 
[09/18 20:40:39 visual_prompt]: Inference (test):avg data time: 1.97e-03, avg batch time: 0.1095, average loss: 3.0058
[09/18 20:40:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 36.48	
[09/18 20:40:40 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/18 20:40:50 visual_prompt]: Epoch 31 / 100: avg data time: 2.31e-01, avg batch time: 0.4598, average train loss: 3.0654
[09/18 20:40:57 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.0912, average loss: 2.9097
[09/18 20:40:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 37.50	
[09/18 20:41:17 visual_prompt]: 	Test 100/1152. loss: 3.079, 0.0999 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 20:41:33 visual_prompt]: 	Test 200/1152. loss: 3.094, 0.1256 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 20:41:50 visual_prompt]: 	Test 300/1152. loss: 3.028, 0.1040 s / batch. (data: 4.39e-05)max mem: 17.22454 GB 
[09/18 20:42:06 visual_prompt]: 	Test 400/1152. loss: 2.952, 0.1000 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 20:42:23 visual_prompt]: 	Test 500/1152. loss: 3.005, 0.1159 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 20:42:39 visual_prompt]: 	Test 600/1152. loss: 3.083, 0.1014 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/18 20:42:55 visual_prompt]: 	Test 700/1152. loss: 2.927, 0.1558 s / batch. (data: 7.01e-05)max mem: 17.22454 GB 
[09/18 20:43:11 visual_prompt]: 	Test 800/1152. loss: 3.121, 0.1028 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/18 20:43:27 visual_prompt]: 	Test 900/1152. loss: 3.007, 0.1014 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 20:43:43 visual_prompt]: 	Test 1000/1152. loss: 3.113, 0.1069 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 20:43:59 visual_prompt]: 	Test 1100/1152. loss: 3.153, 0.1118 s / batch. (data: 7.17e-03)max mem: 17.22454 GB 
[09/18 20:44:12 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1095, average loss: 2.9899
[09/18 20:44:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 32.58	
[09/18 20:44:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/18 20:44:22 visual_prompt]: Epoch 32 / 100: avg data time: 2.38e-01, avg batch time: 0.4680, average train loss: 2.9558
[09/18 20:44:29 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.0960, average loss: 2.9039
[09/18 20:44:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 33.00	
[09/18 20:44:49 visual_prompt]: 	Test 100/1152. loss: 2.837, 0.1355 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 20:45:05 visual_prompt]: 	Test 200/1152. loss: 2.929, 0.0994 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 20:45:22 visual_prompt]: 	Test 300/1152. loss: 2.934, 0.1072 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 20:45:38 visual_prompt]: 	Test 400/1152. loss: 2.832, 0.0955 s / batch. (data: 6.56e-05)max mem: 17.22454 GB 
[09/18 20:45:54 visual_prompt]: 	Test 500/1152. loss: 2.885, 0.1140 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/18 20:46:11 visual_prompt]: 	Test 600/1152. loss: 2.947, 0.0949 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/18 20:46:27 visual_prompt]: 	Test 700/1152. loss: 2.884, 0.1099 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/18 20:46:43 visual_prompt]: 	Test 800/1152. loss: 2.767, 0.0959 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/18 20:46:59 visual_prompt]: 	Test 900/1152. loss: 2.889, 0.1076 s / batch. (data: 7.01e-05)max mem: 17.22454 GB 
[09/18 20:47:15 visual_prompt]: 	Test 1000/1152. loss: 2.782, 0.1032 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 20:47:31 visual_prompt]: 	Test 1100/1152. loss: 2.939, 0.1003 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 20:47:43 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1085, average loss: 2.9146
[09/18 20:47:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 33.56	
[09/18 20:47:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/18 20:47:54 visual_prompt]: Epoch 33 / 100: avg data time: 2.38e-01, avg batch time: 0.4670, average train loss: 2.9215
[09/18 20:48:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.0894, average loss: 2.8153
[09/18 20:48:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.00	top5: 43.00	
[09/18 20:48:21 visual_prompt]: 	Test 100/1152. loss: 2.987, 0.1205 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 20:48:38 visual_prompt]: 	Test 200/1152. loss: 2.950, 0.1262 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 20:48:54 visual_prompt]: 	Test 300/1152. loss: 3.144, 0.1038 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 20:49:10 visual_prompt]: 	Test 400/1152. loss: 2.958, 0.0976 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:49:26 visual_prompt]: 	Test 500/1152. loss: 2.951, 0.0987 s / batch. (data: 1.76e-04)max mem: 17.22454 GB 
[09/18 20:49:42 visual_prompt]: 	Test 600/1152. loss: 3.079, 0.1168 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 20:49:58 visual_prompt]: 	Test 700/1152. loss: 2.956, 0.1024 s / batch. (data: 6.79e-05)max mem: 17.22454 GB 
[09/18 20:50:15 visual_prompt]: 	Test 800/1152. loss: 3.130, 0.0946 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/18 20:50:31 visual_prompt]: 	Test 900/1152. loss: 2.941, 0.1014 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 20:50:47 visual_prompt]: 	Test 1000/1152. loss: 3.019, 0.1244 s / batch. (data: 6.91e-05)max mem: 17.22454 GB 
[09/18 20:51:03 visual_prompt]: 	Test 1100/1152. loss: 2.962, 0.0963 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/18 20:51:15 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1088, average loss: 2.9460
[09/18 20:51:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.92	top5: 32.87	
[09/18 20:51:16 visual_prompt]: Best epoch 33: best metric: 0.130
[09/18 20:51:16 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/18 20:51:26 visual_prompt]: Epoch 34 / 100: avg data time: 2.32e-01, avg batch time: 0.4612, average train loss: 3.0679
[09/18 20:51:33 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.0898, average loss: 3.0875
[09/18 20:51:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 30.50	
[09/18 20:51:53 visual_prompt]: 	Test 100/1152. loss: 2.889, 0.1213 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/18 20:52:09 visual_prompt]: 	Test 200/1152. loss: 2.924, 0.1258 s / batch. (data: 2.12e-02)max mem: 17.22454 GB 
[09/18 20:52:25 visual_prompt]: 	Test 300/1152. loss: 3.108, 0.1190 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 20:52:42 visual_prompt]: 	Test 400/1152. loss: 3.083, 0.0984 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 20:52:57 visual_prompt]: 	Test 500/1152. loss: 2.981, 0.1075 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 20:53:14 visual_prompt]: 	Test 600/1152. loss: 2.907, 0.1042 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 20:53:30 visual_prompt]: 	Test 700/1152. loss: 3.054, 0.1198 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/18 20:53:46 visual_prompt]: 	Test 800/1152. loss: 3.017, 0.0984 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 20:54:02 visual_prompt]: 	Test 900/1152. loss: 2.899, 0.0999 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 20:54:19 visual_prompt]: 	Test 1000/1152. loss: 2.865, 0.1117 s / batch. (data: 7.13e-03)max mem: 17.22454 GB 
[09/18 20:54:35 visual_prompt]: 	Test 1100/1152. loss: 2.980, 0.1197 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 20:54:47 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1088, average loss: 3.0598
[09/18 20:54:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.98	
[09/18 20:54:47 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/18 20:54:58 visual_prompt]: Epoch 35 / 100: avg data time: 2.40e-01, avg batch time: 0.4675, average train loss: 2.9761
[09/18 20:55:05 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.0956, average loss: 2.8560
[09/18 20:55:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 41.00	
[09/18 20:55:25 visual_prompt]: 	Test 100/1152. loss: 3.059, 0.1134 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/18 20:55:41 visual_prompt]: 	Test 200/1152. loss: 2.926, 0.1198 s / batch. (data: 1.81e-04)max mem: 17.22454 GB 
[09/18 20:55:58 visual_prompt]: 	Test 300/1152. loss: 2.984, 0.0948 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 20:56:14 visual_prompt]: 	Test 400/1152. loss: 3.020, 0.0950 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 20:56:30 visual_prompt]: 	Test 500/1152. loss: 2.978, 0.1199 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/18 20:56:46 visual_prompt]: 	Test 600/1152. loss: 3.027, 0.1014 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/18 20:57:02 visual_prompt]: 	Test 700/1152. loss: 3.034, 0.1072 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/18 20:57:19 visual_prompt]: 	Test 800/1152. loss: 2.957, 0.1200 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/18 20:57:35 visual_prompt]: 	Test 900/1152. loss: 2.973, 0.0982 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 20:57:51 visual_prompt]: 	Test 1000/1152. loss: 3.033, 0.1009 s / batch. (data: 6.91e-05)max mem: 17.22454 GB 
[09/18 20:58:07 visual_prompt]: 	Test 1100/1152. loss: 3.034, 0.1017 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 20:58:20 visual_prompt]: Inference (test):avg data time: 2.17e-03, avg batch time: 0.1090, average loss: 2.9422
[09/18 20:58:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.00	
[09/18 20:58:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/18 20:58:31 visual_prompt]: Epoch 36 / 100: avg data time: 2.58e-01, avg batch time: 0.4843, average train loss: 2.9931
[09/18 20:58:38 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.0879, average loss: 3.0699
[09/18 20:58:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 33.50	
[09/18 20:58:58 visual_prompt]: 	Test 100/1152. loss: 2.990, 0.1039 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 20:59:15 visual_prompt]: 	Test 200/1152. loss: 3.290, 0.1161 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 20:59:31 visual_prompt]: 	Test 300/1152. loss: 3.172, 0.1280 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/18 20:59:47 visual_prompt]: 	Test 400/1152. loss: 3.003, 0.0958 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 21:00:03 visual_prompt]: 	Test 500/1152. loss: 3.013, 0.1076 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/18 21:00:20 visual_prompt]: 	Test 600/1152. loss: 3.206, 0.1200 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 21:00:36 visual_prompt]: 	Test 700/1152. loss: 3.045, 0.1078 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 21:00:52 visual_prompt]: 	Test 800/1152. loss: 3.123, 0.0970 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 21:01:08 visual_prompt]: 	Test 900/1152. loss: 3.142, 0.1079 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 21:01:24 visual_prompt]: 	Test 1000/1152. loss: 3.108, 0.1110 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 21:01:41 visual_prompt]: 	Test 1100/1152. loss: 3.195, 0.1035 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/18 21:01:53 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1080, average loss: 3.0907
[09/18 21:01:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.59	
[09/18 21:01:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/18 21:02:04 visual_prompt]: Epoch 37 / 100: avg data time: 2.27e-01, avg batch time: 0.4544, average train loss: 2.9654
[09/18 21:02:11 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0889, average loss: 3.0337
[09/18 21:02:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 31.50	
[09/18 21:02:31 visual_prompt]: 	Test 100/1152. loss: 3.180, 0.1105 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/18 21:02:48 visual_prompt]: 	Test 200/1152. loss: 3.062, 0.1079 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 21:03:04 visual_prompt]: 	Test 300/1152. loss: 2.687, 0.0985 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 21:03:21 visual_prompt]: 	Test 400/1152. loss: 3.017, 0.1159 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 21:03:37 visual_prompt]: 	Test 500/1152. loss: 2.949, 0.0963 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 21:03:53 visual_prompt]: 	Test 600/1152. loss: 2.850, 0.0949 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/18 21:04:09 visual_prompt]: 	Test 700/1152. loss: 2.910, 0.0989 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 21:04:25 visual_prompt]: 	Test 800/1152. loss: 2.881, 0.1106 s / batch. (data: 8.06e-05)max mem: 17.22454 GB 
[09/18 21:04:41 visual_prompt]: 	Test 900/1152. loss: 3.167, 0.1067 s / batch. (data: 7.20e-05)max mem: 17.22454 GB 
[09/18 21:04:58 visual_prompt]: 	Test 1000/1152. loss: 3.064, 0.1095 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/18 21:05:14 visual_prompt]: 	Test 1100/1152. loss: 3.050, 0.1055 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:05:27 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1091, average loss: 2.9695
[09/18 21:05:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 35.56	
[09/18 21:05:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/18 21:05:37 visual_prompt]: Epoch 38 / 100: avg data time: 2.34e-01, avg batch time: 0.4621, average train loss: 2.9759
[09/18 21:05:45 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0880, average loss: 2.7494
[09/18 21:05:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.50	top5: 40.00	
[09/18 21:06:05 visual_prompt]: 	Test 100/1152. loss: 2.903, 0.1136 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/18 21:06:21 visual_prompt]: 	Test 200/1152. loss: 3.024, 0.1239 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 21:06:37 visual_prompt]: 	Test 300/1152. loss: 2.819, 0.0980 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 21:06:54 visual_prompt]: 	Test 400/1152. loss: 2.880, 0.1142 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:07:10 visual_prompt]: 	Test 500/1152. loss: 2.892, 0.1078 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 21:07:26 visual_prompt]: 	Test 600/1152. loss: 2.839, 0.0998 s / batch. (data: 1.79e-04)max mem: 17.22454 GB 
[09/18 21:07:42 visual_prompt]: 	Test 700/1152. loss: 2.724, 0.1160 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 21:07:59 visual_prompt]: 	Test 800/1152. loss: 2.808, 0.0960 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:08:15 visual_prompt]: 	Test 900/1152. loss: 2.726, 0.1721 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/18 21:08:31 visual_prompt]: 	Test 1000/1152. loss: 2.852, 0.0962 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:08:47 visual_prompt]: 	Test 1100/1152. loss: 2.832, 0.1090 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 21:09:00 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1086, average loss: 2.8480
[09/18 21:09:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.21	top5: 37.52	
[09/18 21:09:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/18 21:09:11 visual_prompt]: Epoch 39 / 100: avg data time: 2.39e-01, avg batch time: 0.4683, average train loss: 2.8908
[09/18 21:09:17 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.0898, average loss: 2.9978
[09/18 21:09:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.00	
[09/18 21:09:37 visual_prompt]: 	Test 100/1152. loss: 2.996, 0.1078 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 21:09:53 visual_prompt]: 	Test 200/1152. loss: 2.989, 0.1080 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:10:10 visual_prompt]: 	Test 300/1152. loss: 2.963, 0.1233 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:10:26 visual_prompt]: 	Test 400/1152. loss: 2.933, 0.0966 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 21:10:42 visual_prompt]: 	Test 500/1152. loss: 2.950, 0.1138 s / batch. (data: 1.86e-04)max mem: 17.22454 GB 
[09/18 21:10:58 visual_prompt]: 	Test 600/1152. loss: 2.871, 0.1194 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 21:11:14 visual_prompt]: 	Test 700/1152. loss: 2.922, 0.1118 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 21:11:30 visual_prompt]: 	Test 800/1152. loss: 2.822, 0.0993 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 21:11:47 visual_prompt]: 	Test 900/1152. loss: 2.923, 0.1184 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/18 21:12:02 visual_prompt]: 	Test 1000/1152. loss: 2.946, 0.0954 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/18 21:12:19 visual_prompt]: 	Test 1100/1152. loss: 2.950, 0.1040 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/18 21:12:31 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1093, average loss: 2.9692
[09/18 21:12:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.58	top5: 32.09	
[09/18 21:12:31 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/18 21:12:42 visual_prompt]: Epoch 40 / 100: avg data time: 2.38e-01, avg batch time: 0.4659, average train loss: 2.9083
[09/18 21:12:49 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.0898, average loss: 3.0193
[09/18 21:12:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.00	top5: 38.50	
[09/18 21:13:09 visual_prompt]: 	Test 100/1152. loss: 2.943, 0.1266 s / batch. (data: 1.36e-05)max mem: 17.22454 GB 
[09/18 21:13:25 visual_prompt]: 	Test 200/1152. loss: 3.120, 0.1121 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 21:13:42 visual_prompt]: 	Test 300/1152. loss: 3.028, 0.1158 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:13:58 visual_prompt]: 	Test 400/1152. loss: 3.099, 0.0979 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/18 21:14:14 visual_prompt]: 	Test 500/1152. loss: 2.899, 0.1038 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/18 21:14:30 visual_prompt]: 	Test 600/1152. loss: 2.957, 0.0981 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/18 21:14:46 visual_prompt]: 	Test 700/1152. loss: 3.376, 0.1397 s / batch. (data: 1.86e-04)max mem: 17.22454 GB 
[09/18 21:15:02 visual_prompt]: 	Test 800/1152. loss: 2.989, 0.1185 s / batch. (data: 1.95e-04)max mem: 17.22454 GB 
[09/18 21:15:19 visual_prompt]: 	Test 900/1152. loss: 3.131, 0.1059 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/18 21:15:35 visual_prompt]: 	Test 1000/1152. loss: 3.202, 0.1030 s / batch. (data: 6.99e-05)max mem: 17.22454 GB 
[09/18 21:15:51 visual_prompt]: 	Test 1100/1152. loss: 2.943, 0.1193 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 21:16:04 visual_prompt]: Inference (test):avg data time: 2.27e-03, avg batch time: 0.1089, average loss: 3.0599
[09/18 21:16:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.42	top5: 36.52	
[09/18 21:16:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/18 21:16:14 visual_prompt]: Epoch 41 / 100: avg data time: 2.36e-01, avg batch time: 0.4620, average train loss: 2.9496
[09/18 21:16:21 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.0885, average loss: 2.9995
[09/18 21:16:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 42.50	
[09/18 21:16:41 visual_prompt]: 	Test 100/1152. loss: 3.142, 0.1377 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/18 21:16:58 visual_prompt]: 	Test 200/1152. loss: 2.965, 0.0946 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/18 21:17:14 visual_prompt]: 	Test 300/1152. loss: 3.259, 0.0949 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 21:17:30 visual_prompt]: 	Test 400/1152. loss: 3.165, 0.0960 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 21:17:46 visual_prompt]: 	Test 500/1152. loss: 3.005, 0.1158 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 21:18:03 visual_prompt]: 	Test 600/1152. loss: 3.137, 0.1096 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 21:18:19 visual_prompt]: 	Test 700/1152. loss: 3.197, 0.0995 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 21:18:35 visual_prompt]: 	Test 800/1152. loss: 3.102, 0.1023 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/18 21:18:51 visual_prompt]: 	Test 900/1152. loss: 3.140, 0.0981 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/18 21:19:07 visual_prompt]: 	Test 1000/1152. loss: 3.106, 0.0955 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/18 21:19:24 visual_prompt]: 	Test 1100/1152. loss: 2.946, 0.1045 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/18 21:19:36 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1091, average loss: 3.0594
[09/18 21:19:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.55	top5: 35.29	
[09/18 21:19:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/18 21:19:46 visual_prompt]: Epoch 42 / 100: avg data time: 2.32e-01, avg batch time: 0.4588, average train loss: 2.9747
[09/18 21:19:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0899, average loss: 3.0017
[09/18 21:19:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 36.00	
[09/18 21:20:14 visual_prompt]: 	Test 100/1152. loss: 3.181, 0.0979 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 21:20:30 visual_prompt]: 	Test 200/1152. loss: 3.185, 0.1143 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:20:46 visual_prompt]: 	Test 300/1152. loss: 3.044, 0.1047 s / batch. (data: 6.56e-05)max mem: 17.22454 GB 
[09/18 21:21:03 visual_prompt]: 	Test 400/1152. loss: 3.098, 0.0946 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 21:21:19 visual_prompt]: 	Test 500/1152. loss: 3.171, 0.0948 s / batch. (data: 7.82e-05)max mem: 17.22454 GB 
[09/18 21:21:35 visual_prompt]: 	Test 600/1152. loss: 3.033, 0.1075 s / batch. (data: 7.58e-05)max mem: 17.22454 GB 
[09/18 21:21:51 visual_prompt]: 	Test 700/1152. loss: 2.919, 0.0976 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 21:22:07 visual_prompt]: 	Test 800/1152. loss: 2.979, 0.1082 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 21:22:23 visual_prompt]: 	Test 900/1152. loss: 2.915, 0.1168 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/18 21:22:39 visual_prompt]: 	Test 1000/1152. loss: 2.992, 0.0956 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/18 21:22:56 visual_prompt]: 	Test 1100/1152. loss: 2.989, 0.0971 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 21:23:08 visual_prompt]: Inference (test):avg data time: 2.25e-03, avg batch time: 0.1090, average loss: 3.0661
[09/18 21:23:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 35.28	
[09/18 21:23:09 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/18 21:23:19 visual_prompt]: Epoch 43 / 100: avg data time: 2.37e-01, avg batch time: 0.4648, average train loss: 2.8408
[09/18 21:23:26 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.0955, average loss: 2.8079
[09/18 21:23:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.00	top5: 43.00	
[09/18 21:23:47 visual_prompt]: 	Test 100/1152. loss: 2.782, 0.0969 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/18 21:24:03 visual_prompt]: 	Test 200/1152. loss: 2.820, 0.0949 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 21:24:19 visual_prompt]: 	Test 300/1152. loss: 2.763, 0.1124 s / batch. (data: 1.81e-04)max mem: 17.22454 GB 
[09/18 21:24:35 visual_prompt]: 	Test 400/1152. loss: 2.799, 0.0950 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 21:24:52 visual_prompt]: 	Test 500/1152. loss: 2.883, 0.1159 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 21:25:08 visual_prompt]: 	Test 600/1152. loss: 2.805, 0.0955 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/18 21:25:24 visual_prompt]: 	Test 700/1152. loss: 2.825, 0.0949 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 21:25:40 visual_prompt]: 	Test 800/1152. loss: 2.749, 0.1008 s / batch. (data: 2.29e-03)max mem: 17.22454 GB 
[09/18 21:25:57 visual_prompt]: 	Test 900/1152. loss: 2.731, 0.1080 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 21:26:13 visual_prompt]: 	Test 1000/1152. loss: 2.874, 0.1199 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:26:29 visual_prompt]: 	Test 1100/1152. loss: 2.886, 0.1042 s / batch. (data: 4.82e-05)max mem: 17.22454 GB 
[09/18 21:26:42 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1085, average loss: 2.8832
[09/18 21:26:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.60	top5: 38.24	
[09/18 21:26:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/18 21:26:53 visual_prompt]: Epoch 44 / 100: avg data time: 2.45e-01, avg batch time: 0.4690, average train loss: 2.8431
[09/18 21:27:00 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.0999, average loss: 2.7113
[09/18 21:27:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.50	top5: 47.00	
[09/18 21:27:20 visual_prompt]: 	Test 100/1152. loss: 2.810, 0.1053 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 21:27:36 visual_prompt]: 	Test 200/1152. loss: 2.899, 0.1277 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 21:27:52 visual_prompt]: 	Test 300/1152. loss: 2.662, 0.1010 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/18 21:28:09 visual_prompt]: 	Test 400/1152. loss: 2.708, 0.0948 s / batch. (data: 7.01e-05)max mem: 17.22454 GB 
[09/18 21:28:25 visual_prompt]: 	Test 500/1152. loss: 2.722, 0.0952 s / batch. (data: 7.22e-05)max mem: 17.22454 GB 
[09/18 21:28:41 visual_prompt]: 	Test 600/1152. loss: 2.742, 0.1067 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 21:28:57 visual_prompt]: 	Test 700/1152. loss: 2.707, 0.1255 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/18 21:29:14 visual_prompt]: 	Test 800/1152. loss: 2.610, 0.1273 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/18 21:29:30 visual_prompt]: 	Test 900/1152. loss: 2.788, 0.1060 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 21:29:46 visual_prompt]: 	Test 1000/1152. loss: 2.794, 0.1109 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/18 21:30:02 visual_prompt]: 	Test 1100/1152. loss: 2.757, 0.1023 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 21:30:14 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1088, average loss: 2.7671
[09/18 21:30:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.71	top5: 43.06	
[09/18 21:30:15 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/18 21:30:25 visual_prompt]: Epoch 45 / 100: avg data time: 2.40e-01, avg batch time: 0.4647, average train loss: 2.9112
[09/18 21:30:32 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.0878, average loss: 2.7664
[09/18 21:30:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 46.50	
[09/18 21:30:52 visual_prompt]: 	Test 100/1152. loss: 3.062, 0.1035 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 21:31:09 visual_prompt]: 	Test 200/1152. loss: 3.029, 0.1168 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 21:31:25 visual_prompt]: 	Test 300/1152. loss: 2.936, 0.1125 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/18 21:31:41 visual_prompt]: 	Test 400/1152. loss: 2.874, 0.1273 s / batch. (data: 1.98e-04)max mem: 17.22454 GB 
[09/18 21:31:57 visual_prompt]: 	Test 500/1152. loss: 2.891, 0.1199 s / batch. (data: 2.42e-02)max mem: 17.22454 GB 
[09/18 21:32:14 visual_prompt]: 	Test 600/1152. loss: 3.082, 0.1171 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/18 21:32:30 visual_prompt]: 	Test 700/1152. loss: 2.682, 0.1249 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:32:46 visual_prompt]: 	Test 800/1152. loss: 2.920, 0.1083 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:33:02 visual_prompt]: 	Test 900/1152. loss: 2.922, 0.1021 s / batch. (data: 6.55e-03)max mem: 17.22454 GB 
[09/18 21:33:18 visual_prompt]: 	Test 1000/1152. loss: 2.915, 0.1154 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 21:33:35 visual_prompt]: 	Test 1100/1152. loss: 2.978, 0.1290 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 21:33:47 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1092, average loss: 2.8686
[09/18 21:33:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 40.68	
[09/18 21:33:47 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/18 21:33:57 visual_prompt]: Epoch 46 / 100: avg data time: 2.48e-01, avg batch time: 0.4733, average train loss: 2.8793
[09/18 21:34:04 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.0942, average loss: 2.7372
[09/18 21:34:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.00	top5: 49.50	
[09/18 21:34:24 visual_prompt]: 	Test 100/1152. loss: 2.910, 0.1121 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 21:34:41 visual_prompt]: 	Test 200/1152. loss: 2.906, 0.0999 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 21:34:57 visual_prompt]: 	Test 300/1152. loss: 2.760, 0.1158 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 21:35:14 visual_prompt]: 	Test 400/1152. loss: 2.950, 0.0967 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:35:30 visual_prompt]: 	Test 500/1152. loss: 2.877, 0.0999 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:35:47 visual_prompt]: 	Test 600/1152. loss: 2.842, 0.1051 s / batch. (data: 7.27e-05)max mem: 17.22454 GB 
[09/18 21:36:03 visual_prompt]: 	Test 700/1152. loss: 2.833, 0.1000 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 21:36:19 visual_prompt]: 	Test 800/1152. loss: 2.745, 0.1118 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:36:35 visual_prompt]: 	Test 900/1152. loss: 2.900, 0.0966 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 21:36:51 visual_prompt]: 	Test 1000/1152. loss: 3.057, 0.1120 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 21:37:08 visual_prompt]: 	Test 1100/1152. loss: 2.710, 0.1743 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 21:37:20 visual_prompt]: Inference (test):avg data time: 1.61e-03, avg batch time: 0.1086, average loss: 2.8568
[09/18 21:37:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.10	top5: 43.27	
[09/18 21:37:20 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/18 21:37:31 visual_prompt]: Epoch 47 / 100: avg data time: 2.41e-01, avg batch time: 0.4681, average train loss: 2.8227
[09/18 21:37:38 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0958, average loss: 2.7872
[09/18 21:37:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.00	top5: 44.50	
[09/18 21:37:58 visual_prompt]: 	Test 100/1152. loss: 2.908, 0.1017 s / batch. (data: 3.47e-03)max mem: 17.22454 GB 
[09/18 21:38:14 visual_prompt]: 	Test 200/1152. loss: 2.783, 0.1105 s / batch. (data: 3.19e-05)max mem: 17.22454 GB 
[09/18 21:38:31 visual_prompt]: 	Test 300/1152. loss: 2.880, 0.0987 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/18 21:38:47 visual_prompt]: 	Test 400/1152. loss: 2.939, 0.0971 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:39:03 visual_prompt]: 	Test 500/1152. loss: 2.676, 0.0998 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 21:39:19 visual_prompt]: 	Test 600/1152. loss: 2.797, 0.0961 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/18 21:39:35 visual_prompt]: 	Test 700/1152. loss: 2.711, 0.1181 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 21:39:52 visual_prompt]: 	Test 800/1152. loss: 2.655, 0.0946 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 21:40:07 visual_prompt]: 	Test 900/1152. loss: 2.966, 0.1032 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/18 21:40:24 visual_prompt]: 	Test 1000/1152. loss: 2.905, 0.1145 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/18 21:40:40 visual_prompt]: 	Test 1100/1152. loss: 2.893, 0.0947 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 21:40:52 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1092, average loss: 2.8472
[09/18 21:40:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.54	top5: 40.41	
[09/18 21:40:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/18 21:41:03 visual_prompt]: Epoch 48 / 100: avg data time: 2.27e-01, avg batch time: 0.4594, average train loss: 2.8103
[09/18 21:41:10 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.0932, average loss: 3.0859
[09/18 21:41:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 38.50	
[09/18 21:41:29 visual_prompt]: 	Test 100/1152. loss: 3.199, 0.0982 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 21:41:46 visual_prompt]: 	Test 200/1152. loss: 3.010, 0.1049 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:42:02 visual_prompt]: 	Test 300/1152. loss: 3.062, 0.1119 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 21:42:18 visual_prompt]: 	Test 400/1152. loss: 3.252, 0.1038 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:42:34 visual_prompt]: 	Test 500/1152. loss: 3.214, 0.1031 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:42:50 visual_prompt]: 	Test 600/1152. loss: 2.998, 0.1156 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 21:43:06 visual_prompt]: 	Test 700/1152. loss: 3.006, 0.1198 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/18 21:43:22 visual_prompt]: 	Test 800/1152. loss: 3.241, 0.0991 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 21:43:39 visual_prompt]: 	Test 900/1152. loss: 2.993, 0.1190 s / batch. (data: 1.39e-02)max mem: 17.22454 GB 
[09/18 21:43:55 visual_prompt]: 	Test 1000/1152. loss: 3.174, 0.1038 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/18 21:44:11 visual_prompt]: 	Test 1100/1152. loss: 3.069, 0.1200 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 21:44:23 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1092, average loss: 3.1343
[09/18 21:44:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 36.32	
[09/18 21:44:23 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/18 21:44:34 visual_prompt]: Epoch 49 / 100: avg data time: 2.25e-01, avg batch time: 0.4560, average train loss: 2.9172
[09/18 21:44:41 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.0876, average loss: 2.8561
[09/18 21:44:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 46.00	
[09/18 21:45:01 visual_prompt]: 	Test 100/1152. loss: 2.973, 0.1248 s / batch. (data: 4.29e-05)max mem: 17.22454 GB 
[09/18 21:45:17 visual_prompt]: 	Test 200/1152. loss: 2.968, 0.1287 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 21:45:33 visual_prompt]: 	Test 300/1152. loss: 2.789, 0.1199 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 21:45:49 visual_prompt]: 	Test 400/1152. loss: 2.798, 0.1071 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 21:46:05 visual_prompt]: 	Test 500/1152. loss: 2.852, 0.1078 s / batch. (data: 6.23e-04)max mem: 17.22454 GB 
[09/18 21:46:21 visual_prompt]: 	Test 600/1152. loss: 2.794, 0.1062 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 21:46:37 visual_prompt]: 	Test 700/1152. loss: 2.654, 0.1106 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/18 21:46:53 visual_prompt]: 	Test 800/1152. loss: 2.836, 0.1250 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:47:10 visual_prompt]: 	Test 900/1152. loss: 2.855, 0.1194 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 21:47:26 visual_prompt]: 	Test 1000/1152. loss: 3.055, 0.1038 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:47:42 visual_prompt]: 	Test 1100/1152. loss: 2.919, 0.1041 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 21:47:54 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1091, average loss: 2.9073
[09/18 21:47:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.89	top5: 40.02	
[09/18 21:47:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/18 21:48:05 visual_prompt]: Epoch 50 / 100: avg data time: 2.38e-01, avg batch time: 0.4698, average train loss: 2.8704
[09/18 21:48:12 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.0943, average loss: 2.6700
[09/18 21:48:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.00	top5: 50.00	
[09/18 21:48:32 visual_prompt]: 	Test 100/1152. loss: 2.937, 0.1159 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 21:48:48 visual_prompt]: 	Test 200/1152. loss: 2.931, 0.1428 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/18 21:49:04 visual_prompt]: 	Test 300/1152. loss: 2.746, 0.1083 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 21:49:20 visual_prompt]: 	Test 400/1152. loss: 2.791, 0.0985 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 21:49:36 visual_prompt]: 	Test 500/1152. loss: 2.854, 0.1032 s / batch. (data: 4.48e-05)max mem: 17.22454 GB 
[09/18 21:49:52 visual_prompt]: 	Test 600/1152. loss: 2.993, 0.0996 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 21:50:08 visual_prompt]: 	Test 700/1152. loss: 2.807, 0.1036 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 21:50:24 visual_prompt]: 	Test 800/1152. loss: 2.795, 0.0989 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 21:50:41 visual_prompt]: 	Test 900/1152. loss: 2.872, 0.1090 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 21:50:57 visual_prompt]: 	Test 1000/1152. loss: 2.892, 0.1313 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 21:51:13 visual_prompt]: 	Test 1100/1152. loss: 2.714, 0.1384 s / batch. (data: 1.96e-04)max mem: 17.22454 GB 
[09/18 21:51:25 visual_prompt]: Inference (test):avg data time: 2.35e-03, avg batch time: 0.1096, average loss: 2.7820
[09/18 21:51:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.80	top5: 46.07	
[09/18 21:51:25 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/18 21:51:36 visual_prompt]: Epoch 51 / 100: avg data time: 2.35e-01, avg batch time: 0.4623, average train loss: 2.7438
[09/18 21:51:43 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.0887, average loss: 2.5918
[09/18 21:51:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.00	top5: 57.50	
[09/18 21:52:03 visual_prompt]: 	Test 100/1152. loss: 2.813, 0.1018 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/18 21:52:19 visual_prompt]: 	Test 200/1152. loss: 2.947, 0.0969 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 21:52:35 visual_prompt]: 	Test 300/1152. loss: 2.713, 0.0954 s / batch. (data: 3.91e-05)max mem: 17.22454 GB 
[09/18 21:52:51 visual_prompt]: 	Test 400/1152. loss: 2.801, 0.1234 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 21:53:08 visual_prompt]: 	Test 500/1152. loss: 2.755, 0.1027 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 21:53:24 visual_prompt]: 	Test 600/1152. loss: 2.808, 0.1142 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 21:53:40 visual_prompt]: 	Test 700/1152. loss: 2.828, 0.1109 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 21:53:56 visual_prompt]: 	Test 800/1152. loss: 2.638, 0.0955 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 21:54:13 visual_prompt]: 	Test 900/1152. loss: 2.848, 0.1078 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 21:54:29 visual_prompt]: 	Test 1000/1152. loss: 2.983, 0.1237 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/18 21:54:45 visual_prompt]: 	Test 1100/1152. loss: 2.632, 0.1282 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 21:54:57 visual_prompt]: Inference (test):avg data time: 1.97e-03, avg batch time: 0.1083, average loss: 2.8070
[09/18 21:54:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.39	top5: 48.06	
[09/18 21:54:57 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/18 21:55:08 visual_prompt]: Epoch 52 / 100: avg data time: 2.38e-01, avg batch time: 0.4672, average train loss: 2.8116
[09/18 21:55:15 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.0880, average loss: 2.6021
[09/18 21:55:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.50	top5: 57.50	
[09/18 21:55:34 visual_prompt]: 	Test 100/1152. loss: 2.647, 0.1197 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 21:55:51 visual_prompt]: 	Test 200/1152. loss: 2.925, 0.1083 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:56:07 visual_prompt]: 	Test 300/1152. loss: 2.648, 0.1107 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 21:56:23 visual_prompt]: 	Test 400/1152. loss: 2.718, 0.1041 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 21:56:39 visual_prompt]: 	Test 500/1152. loss: 2.690, 0.1091 s / batch. (data: 8.47e-03)max mem: 17.22454 GB 
[09/18 21:56:55 visual_prompt]: 	Test 600/1152. loss: 2.663, 0.0998 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 21:57:11 visual_prompt]: 	Test 700/1152. loss: 2.577, 0.1124 s / batch. (data: 7.78e-03)max mem: 17.22454 GB 
[09/18 21:57:27 visual_prompt]: 	Test 800/1152. loss: 2.623, 0.1161 s / batch. (data: 7.19e-03)max mem: 17.22454 GB 
[09/18 21:57:44 visual_prompt]: 	Test 900/1152. loss: 2.669, 0.1214 s / batch. (data: 1.31e-05)max mem: 17.22454 GB 
[09/18 21:58:00 visual_prompt]: 	Test 1000/1152. loss: 2.842, 0.0947 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 21:58:16 visual_prompt]: 	Test 1100/1152. loss: 2.636, 0.1079 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 21:58:28 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1081, average loss: 2.7376
[09/18 21:58:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.92	top5: 51.29	
[09/18 21:58:28 visual_prompt]: Best epoch 52: best metric: 0.155
[09/18 21:58:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/18 21:58:39 visual_prompt]: Epoch 53 / 100: avg data time: 2.36e-01, avg batch time: 0.4637, average train loss: 2.6297
[09/18 21:58:46 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.0775, average loss: 2.5031
[09/18 21:58:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.00	top5: 59.50	
[09/18 21:59:06 visual_prompt]: 	Test 100/1152. loss: 2.834, 0.1731 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 21:59:22 visual_prompt]: 	Test 200/1152. loss: 2.683, 0.1038 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 21:59:38 visual_prompt]: 	Test 300/1152. loss: 2.549, 0.0982 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 21:59:55 visual_prompt]: 	Test 400/1152. loss: 2.720, 0.0988 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 22:00:11 visual_prompt]: 	Test 500/1152. loss: 2.603, 0.1163 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/18 22:00:27 visual_prompt]: 	Test 600/1152. loss: 2.711, 0.1174 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/18 22:00:43 visual_prompt]: 	Test 700/1152. loss: 2.626, 0.0947 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/18 22:00:59 visual_prompt]: 	Test 800/1152. loss: 2.583, 0.1178 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 22:01:15 visual_prompt]: 	Test 900/1152. loss: 2.850, 0.1398 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 22:01:31 visual_prompt]: 	Test 1000/1152. loss: 2.784, 0.1123 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 22:01:47 visual_prompt]: 	Test 1100/1152. loss: 2.702, 0.0963 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 22:02:00 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1092, average loss: 2.6624
[09/18 22:02:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.29	top5: 50.66	
[09/18 22:02:00 visual_prompt]: Best epoch 53: best metric: 0.180
[09/18 22:02:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/18 22:02:10 visual_prompt]: Epoch 54 / 100: avg data time: 2.36e-01, avg batch time: 0.4642, average train loss: 2.5933
[09/18 22:02:17 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.0874, average loss: 2.4189
[09/18 22:02:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.50	top5: 63.00	
[09/18 22:02:37 visual_prompt]: 	Test 100/1152. loss: 2.688, 0.0980 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 22:02:54 visual_prompt]: 	Test 200/1152. loss: 2.805, 0.0967 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 22:03:10 visual_prompt]: 	Test 300/1152. loss: 2.956, 0.0962 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:03:26 visual_prompt]: 	Test 400/1152. loss: 2.858, 0.0954 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 22:03:42 visual_prompt]: 	Test 500/1152. loss: 2.580, 0.0979 s / batch. (data: 6.82e-05)max mem: 17.22454 GB 
[09/18 22:03:59 visual_prompt]: 	Test 600/1152. loss: 2.765, 0.1175 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 22:04:15 visual_prompt]: 	Test 700/1152. loss: 2.528, 0.1049 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/18 22:04:31 visual_prompt]: 	Test 800/1152. loss: 2.657, 0.0949 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/18 22:04:46 visual_prompt]: 	Test 900/1152. loss: 2.668, 0.1204 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:05:03 visual_prompt]: 	Test 1000/1152. loss: 2.898, 0.1336 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/18 22:05:19 visual_prompt]: 	Test 1100/1152. loss: 2.738, 0.1147 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 22:05:31 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1082, average loss: 2.7449
[09/18 22:05:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.11	top5: 52.57	
[09/18 22:05:31 visual_prompt]: Best epoch 54: best metric: 0.245
[09/18 22:05:31 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/18 22:05:42 visual_prompt]: Epoch 55 / 100: avg data time: 2.32e-01, avg batch time: 0.4645, average train loss: 2.5180
[09/18 22:05:49 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.0991, average loss: 2.9589
[09/18 22:05:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.00	top5: 49.00	
[09/18 22:06:09 visual_prompt]: 	Test 100/1152. loss: 3.153, 0.1546 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/18 22:06:25 visual_prompt]: 	Test 200/1152. loss: 3.231, 0.1007 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 22:06:41 visual_prompt]: 	Test 300/1152. loss: 2.722, 0.0944 s / batch. (data: 8.20e-05)max mem: 17.22454 GB 
[09/18 22:06:57 visual_prompt]: 	Test 400/1152. loss: 2.993, 0.1081 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/18 22:07:13 visual_prompt]: 	Test 500/1152. loss: 2.988, 0.1089 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 22:07:29 visual_prompt]: 	Test 600/1152. loss: 2.892, 0.0967 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 22:07:45 visual_prompt]: 	Test 700/1152. loss: 2.640, 0.1636 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/18 22:08:01 visual_prompt]: 	Test 800/1152. loss: 2.777, 0.0947 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 22:08:18 visual_prompt]: 	Test 900/1152. loss: 3.062, 0.0947 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 22:08:34 visual_prompt]: 	Test 1000/1152. loss: 3.160, 0.0979 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/18 22:08:50 visual_prompt]: 	Test 1100/1152. loss: 2.923, 0.0956 s / batch. (data: 9.37e-05)max mem: 17.22454 GB 
[09/18 22:09:02 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1087, average loss: 2.9758
[09/18 22:09:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.56	top5: 46.96	
[09/18 22:09:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/18 22:09:13 visual_prompt]: Epoch 56 / 100: avg data time: 2.33e-01, avg batch time: 0.4528, average train loss: 2.6486
[09/18 22:09:20 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.0942, average loss: 2.4274
[09/18 22:09:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.50	top5: 62.00	
[09/18 22:09:40 visual_prompt]: 	Test 100/1152. loss: 2.673, 0.0974 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/18 22:09:56 visual_prompt]: 	Test 200/1152. loss: 2.506, 0.1119 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 22:10:12 visual_prompt]: 	Test 300/1152. loss: 2.748, 0.0974 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 22:10:28 visual_prompt]: 	Test 400/1152. loss: 2.767, 0.0979 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 22:10:45 visual_prompt]: 	Test 500/1152. loss: 2.641, 0.1079 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/18 22:11:00 visual_prompt]: 	Test 600/1152. loss: 2.750, 0.1078 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 22:11:16 visual_prompt]: 	Test 700/1152. loss: 2.635, 0.1370 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/18 22:11:33 visual_prompt]: 	Test 800/1152. loss: 2.667, 0.1355 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 22:11:49 visual_prompt]: 	Test 900/1152. loss: 2.709, 0.1206 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/18 22:12:05 visual_prompt]: 	Test 1000/1152. loss: 2.835, 0.0975 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 22:12:22 visual_prompt]: 	Test 1100/1152. loss: 2.628, 0.1119 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 22:12:34 visual_prompt]: Inference (test):avg data time: 2.14e-03, avg batch time: 0.1092, average loss: 2.7110
[09/18 22:12:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.25	top5: 52.32	
[09/18 22:12:34 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/18 22:12:45 visual_prompt]: Epoch 57 / 100: avg data time: 2.35e-01, avg batch time: 0.4604, average train loss: 2.5146
[09/18 22:12:52 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.0922, average loss: 2.7084
[09/18 22:12:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.00	top5: 61.50	
[09/18 22:13:12 visual_prompt]: 	Test 100/1152. loss: 3.006, 0.1171 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/18 22:13:28 visual_prompt]: 	Test 200/1152. loss: 2.912, 0.0942 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 22:13:45 visual_prompt]: 	Test 300/1152. loss: 2.651, 0.0959 s / batch. (data: 7.06e-05)max mem: 17.22454 GB 
[09/18 22:14:01 visual_prompt]: 	Test 400/1152. loss: 2.795, 0.1141 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:14:17 visual_prompt]: 	Test 500/1152. loss: 2.690, 0.1040 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 22:14:33 visual_prompt]: 	Test 600/1152. loss: 2.702, 0.0968 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 22:14:50 visual_prompt]: 	Test 700/1152. loss: 2.449, 0.0998 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 22:15:06 visual_prompt]: 	Test 800/1152. loss: 2.674, 0.0998 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:15:22 visual_prompt]: 	Test 900/1152. loss: 2.957, 0.1157 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 22:15:37 visual_prompt]: 	Test 1000/1152. loss: 2.967, 0.1031 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/18 22:15:54 visual_prompt]: 	Test 1100/1152. loss: 2.650, 0.0953 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 22:16:06 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1087, average loss: 2.7792
[09/18 22:16:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.25	top5: 52.39	
[09/18 22:16:06 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/18 22:16:16 visual_prompt]: Epoch 58 / 100: avg data time: 2.24e-01, avg batch time: 0.4509, average train loss: 2.4227
[09/18 22:16:23 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0926, average loss: 2.2042
[09/18 22:16:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.50	top5: 73.50	
[09/18 22:16:43 visual_prompt]: 	Test 100/1152. loss: 2.696, 0.1058 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/18 22:16:59 visual_prompt]: 	Test 200/1152. loss: 2.452, 0.1180 s / batch. (data: 9.35e-03)max mem: 17.22454 GB 
[09/18 22:17:16 visual_prompt]: 	Test 300/1152. loss: 2.613, 0.1277 s / batch. (data: 2.47e-02)max mem: 17.22454 GB 
[09/18 22:17:32 visual_prompt]: 	Test 400/1152. loss: 2.646, 0.0981 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/18 22:17:48 visual_prompt]: 	Test 500/1152. loss: 2.316, 0.0964 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 22:18:04 visual_prompt]: 	Test 600/1152. loss: 2.520, 0.1415 s / batch. (data: 5.96e-03)max mem: 17.22454 GB 
[09/18 22:18:20 visual_prompt]: 	Test 700/1152. loss: 2.240, 0.1270 s / batch. (data: 3.21e-02)max mem: 17.22454 GB 
[09/18 22:18:36 visual_prompt]: 	Test 800/1152. loss: 2.469, 0.1012 s / batch. (data: 5.17e-05)max mem: 17.22454 GB 
[09/18 22:18:52 visual_prompt]: 	Test 900/1152. loss: 2.753, 0.0980 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/18 22:19:08 visual_prompt]: 	Test 1000/1152. loss: 2.641, 0.1118 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/18 22:19:24 visual_prompt]: 	Test 1100/1152. loss: 2.334, 0.1158 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 22:19:37 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1088, average loss: 2.5184
[09/18 22:19:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.81	top5: 62.23	
[09/18 22:19:37 visual_prompt]: Best epoch 58: best metric: 0.255
[09/18 22:19:37 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/18 22:19:47 visual_prompt]: Epoch 59 / 100: avg data time: 2.37e-01, avg batch time: 0.4650, average train loss: 2.3520
[09/18 22:19:54 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.0894, average loss: 2.2671
[09/18 22:19:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.00	top5: 71.50	
[09/18 22:20:14 visual_prompt]: 	Test 100/1152. loss: 2.526, 0.1080 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/18 22:20:31 visual_prompt]: 	Test 200/1152. loss: 2.405, 0.0979 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 22:20:46 visual_prompt]: 	Test 300/1152. loss: 2.441, 0.0995 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:21:03 visual_prompt]: 	Test 400/1152. loss: 2.622, 0.1037 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 22:21:19 visual_prompt]: 	Test 500/1152. loss: 2.193, 0.0967 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 22:21:35 visual_prompt]: 	Test 600/1152. loss: 2.439, 0.0987 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 22:21:51 visual_prompt]: 	Test 700/1152. loss: 2.345, 0.1074 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 22:22:07 visual_prompt]: 	Test 800/1152. loss: 2.295, 0.1263 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 22:22:23 visual_prompt]: 	Test 900/1152. loss: 2.687, 0.0959 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/18 22:22:40 visual_prompt]: 	Test 1000/1152. loss: 2.351, 0.1160 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 22:22:56 visual_prompt]: 	Test 1100/1152. loss: 2.453, 0.1277 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/18 22:23:08 visual_prompt]: Inference (test):avg data time: 1.75e-03, avg batch time: 0.1087, average loss: 2.4934
[09/18 22:23:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 17.71	top5: 60.66	
[09/18 22:23:08 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/18 22:23:18 visual_prompt]: Epoch 60 / 100: avg data time: 2.29e-01, avg batch time: 0.4530, average train loss: 2.2458
[09/18 22:23:26 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0892, average loss: 2.3078
[09/18 22:23:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.50	top5: 77.50	
[09/18 22:23:45 visual_prompt]: 	Test 100/1152. loss: 2.772, 0.1060 s / batch. (data: 8.96e-03)max mem: 17.22454 GB 
[09/18 22:24:02 visual_prompt]: 	Test 200/1152. loss: 2.509, 0.1057 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 22:24:18 visual_prompt]: 	Test 300/1152. loss: 2.423, 0.0998 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 22:24:34 visual_prompt]: 	Test 400/1152. loss: 2.629, 0.1092 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 22:24:50 visual_prompt]: 	Test 500/1152. loss: 2.481, 0.1035 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/18 22:25:06 visual_prompt]: 	Test 600/1152. loss: 2.392, 0.1079 s / batch. (data: 3.70e-05)max mem: 17.22454 GB 
[09/18 22:25:23 visual_prompt]: 	Test 700/1152. loss: 2.511, 0.1078 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:25:39 visual_prompt]: 	Test 800/1152. loss: 2.607, 0.0948 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:25:55 visual_prompt]: 	Test 900/1152. loss: 2.694, 0.1132 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 22:26:11 visual_prompt]: 	Test 1000/1152. loss: 2.804, 0.1052 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:26:27 visual_prompt]: 	Test 1100/1152. loss: 2.701, 0.1123 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/18 22:26:39 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1087, average loss: 2.6387
[09/18 22:26:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.10	top5: 65.16	
[09/18 22:26:39 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/18 22:26:50 visual_prompt]: Epoch 61 / 100: avg data time: 2.26e-01, avg batch time: 0.4503, average train loss: 2.2930
[09/18 22:26:57 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.0927, average loss: 2.1559
[09/18 22:26:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 27.00	top5: 75.50	
[09/18 22:27:16 visual_prompt]: 	Test 100/1152. loss: 2.603, 0.0959 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 22:27:33 visual_prompt]: 	Test 200/1152. loss: 2.492, 0.1147 s / batch. (data: 6.12e-03)max mem: 17.22454 GB 
[09/18 22:27:49 visual_prompt]: 	Test 300/1152. loss: 2.425, 0.0950 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 22:28:05 visual_prompt]: 	Test 400/1152. loss: 2.579, 0.1441 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 22:28:21 visual_prompt]: 	Test 500/1152. loss: 2.315, 0.1055 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:28:37 visual_prompt]: 	Test 600/1152. loss: 2.317, 0.1125 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/18 22:28:53 visual_prompt]: 	Test 700/1152. loss: 2.137, 0.1040 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:29:10 visual_prompt]: 	Test 800/1152. loss: 2.494, 0.0951 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 22:29:26 visual_prompt]: 	Test 900/1152. loss: 2.441, 0.1000 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 22:29:42 visual_prompt]: 	Test 1000/1152. loss: 2.572, 0.0953 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 22:29:58 visual_prompt]: 	Test 1100/1152. loss: 2.397, 0.0949 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/18 22:30:10 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1092, average loss: 2.4578
[09/18 22:30:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.75	top5: 66.95	
[09/18 22:30:11 visual_prompt]: Best epoch 61: best metric: 0.270
[09/18 22:30:11 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/18 22:30:21 visual_prompt]: Epoch 62 / 100: avg data time: 2.18e-01, avg batch time: 0.4505, average train loss: 2.1168
[09/18 22:30:28 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.0877, average loss: 1.9093
[09/18 22:30:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.00	top5: 83.00	
[09/18 22:30:48 visual_prompt]: 	Test 100/1152. loss: 2.491, 0.1026 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 22:31:04 visual_prompt]: 	Test 200/1152. loss: 2.370, 0.1090 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/18 22:31:20 visual_prompt]: 	Test 300/1152. loss: 2.362, 0.0968 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 22:31:37 visual_prompt]: 	Test 400/1152. loss: 2.460, 0.1119 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/18 22:31:53 visual_prompt]: 	Test 500/1152. loss: 2.167, 0.1352 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 22:32:09 visual_prompt]: 	Test 600/1152. loss: 2.479, 0.1001 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 22:32:26 visual_prompt]: 	Test 700/1152. loss: 2.073, 0.1038 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/18 22:32:42 visual_prompt]: 	Test 800/1152. loss: 2.315, 0.1119 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 22:32:58 visual_prompt]: 	Test 900/1152. loss: 2.698, 0.1078 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/18 22:33:14 visual_prompt]: 	Test 1000/1152. loss: 2.436, 0.1039 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/18 22:33:30 visual_prompt]: 	Test 1100/1152. loss: 2.304, 0.1083 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/18 22:33:43 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1094, average loss: 2.3529
[09/18 22:33:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.22	top5: 70.87	
[09/18 22:33:43 visual_prompt]: Best epoch 62: best metric: 0.360
[09/18 22:33:43 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/18 22:33:54 visual_prompt]: Epoch 63 / 100: avg data time: 2.32e-01, avg batch time: 0.4608, average train loss: 2.0890
[09/18 22:34:01 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0921, average loss: 2.1556
[09/18 22:34:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.00	top5: 75.50	
[09/18 22:34:21 visual_prompt]: 	Test 100/1152. loss: 2.898, 0.1001 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 22:34:37 visual_prompt]: 	Test 200/1152. loss: 2.352, 0.1206 s / batch. (data: 3.98e-05)max mem: 17.22454 GB 
[09/18 22:34:53 visual_prompt]: 	Test 300/1152. loss: 2.540, 0.0953 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 22:35:09 visual_prompt]: 	Test 400/1152. loss: 2.733, 0.1118 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 22:35:26 visual_prompt]: 	Test 500/1152. loss: 2.390, 0.1280 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 22:35:42 visual_prompt]: 	Test 600/1152. loss: 2.493, 0.1031 s / batch. (data: 5.19e-03)max mem: 17.22454 GB 
[09/18 22:35:58 visual_prompt]: 	Test 700/1152. loss: 2.494, 0.1005 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 22:36:14 visual_prompt]: 	Test 800/1152. loss: 2.421, 0.0960 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:36:31 visual_prompt]: 	Test 900/1152. loss: 2.923, 0.1083 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 22:36:47 visual_prompt]: 	Test 1000/1152. loss: 2.593, 0.1104 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 22:37:03 visual_prompt]: 	Test 1100/1152. loss: 2.573, 0.0988 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/18 22:37:15 visual_prompt]: Inference (test):avg data time: 1.54e-03, avg batch time: 0.1091, average loss: 2.5618
[09/18 22:37:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.00	top5: 62.75	
[09/18 22:37:15 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/18 22:37:26 visual_prompt]: Epoch 64 / 100: avg data time: 2.34e-01, avg batch time: 0.4593, average train loss: 2.0399
[09/18 22:37:33 visual_prompt]: Inference (val):avg data time: 4.40e-05, avg batch time: 0.0864, average loss: 1.8404
[09/18 22:37:33 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 39.00	top5: 84.50	
[09/18 22:37:52 visual_prompt]: 	Test 100/1152. loss: 2.409, 0.1039 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 22:38:09 visual_prompt]: 	Test 200/1152. loss: 2.301, 0.1196 s / batch. (data: 3.91e-05)max mem: 17.22454 GB 
[09/18 22:38:25 visual_prompt]: 	Test 300/1152. loss: 2.231, 0.0968 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 22:38:42 visual_prompt]: 	Test 400/1152. loss: 2.390, 0.1028 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 22:38:58 visual_prompt]: 	Test 500/1152. loss: 2.090, 0.1197 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 22:39:14 visual_prompt]: 	Test 600/1152. loss: 2.169, 0.0940 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 22:39:31 visual_prompt]: 	Test 700/1152. loss: 2.135, 0.0967 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 22:39:47 visual_prompt]: 	Test 800/1152. loss: 2.147, 0.1159 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/18 22:40:03 visual_prompt]: 	Test 900/1152. loss: 2.260, 0.0949 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 22:40:19 visual_prompt]: 	Test 1000/1152. loss: 2.165, 0.0946 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 22:40:35 visual_prompt]: 	Test 1100/1152. loss: 2.188, 0.0951 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 22:40:47 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1089, average loss: 2.3081
[09/18 22:40:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.35	top5: 73.14	
[09/18 22:40:47 visual_prompt]: Best epoch 64: best metric: 0.390
[09/18 22:40:47 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/18 22:40:57 visual_prompt]: Epoch 65 / 100: avg data time: 2.29e-01, avg batch time: 0.4582, average train loss: 1.9433
[09/18 22:41:04 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0917, average loss: 1.6988
[09/18 22:41:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.50	top5: 90.00	
[09/18 22:41:24 visual_prompt]: 	Test 100/1152. loss: 2.188, 0.1119 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/18 22:41:40 visual_prompt]: 	Test 200/1152. loss: 2.157, 0.1220 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:41:57 visual_prompt]: 	Test 300/1152. loss: 2.267, 0.0944 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 22:42:13 visual_prompt]: 	Test 400/1152. loss: 2.182, 0.1187 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 22:42:29 visual_prompt]: 	Test 500/1152. loss: 2.021, 0.1083 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 22:42:45 visual_prompt]: 	Test 600/1152. loss: 2.234, 0.0993 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/18 22:43:01 visual_prompt]: 	Test 700/1152. loss: 2.051, 0.0950 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/18 22:43:17 visual_prompt]: 	Test 800/1152. loss: 2.103, 0.1070 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/18 22:43:33 visual_prompt]: 	Test 900/1152. loss: 2.217, 0.0943 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 22:43:49 visual_prompt]: 	Test 1000/1152. loss: 2.044, 0.1531 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/18 22:44:05 visual_prompt]: 	Test 1100/1152. loss: 2.230, 0.0944 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/18 22:44:17 visual_prompt]: Inference (test):avg data time: 1.92e-03, avg batch time: 0.1090, average loss: 2.1924
[09/18 22:44:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.82	top5: 75.03	
[09/18 22:44:18 visual_prompt]: Best epoch 65: best metric: 0.405
[09/18 22:44:18 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/18 22:44:28 visual_prompt]: Epoch 66 / 100: avg data time: 2.38e-01, avg batch time: 0.4636, average train loss: 1.8991
[09/18 22:44:35 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0949, average loss: 1.7488
[09/18 22:44:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.00	top5: 87.00	
[09/18 22:44:55 visual_prompt]: 	Test 100/1152. loss: 2.272, 0.0979 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:45:11 visual_prompt]: 	Test 200/1152. loss: 2.287, 0.1071 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 22:45:27 visual_prompt]: 	Test 300/1152. loss: 2.314, 0.1155 s / batch. (data: 6.93e-03)max mem: 17.22454 GB 
[09/18 22:45:43 visual_prompt]: 	Test 400/1152. loss: 2.309, 0.1157 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/18 22:45:59 visual_prompt]: 	Test 500/1152. loss: 1.982, 0.1158 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 22:46:15 visual_prompt]: 	Test 600/1152. loss: 2.178, 0.0969 s / batch. (data: 9.32e-05)max mem: 17.22454 GB 
[09/18 22:46:31 visual_prompt]: 	Test 700/1152. loss: 1.948, 0.1177 s / batch. (data: 5.17e-05)max mem: 17.22454 GB 
[09/18 22:46:47 visual_prompt]: 	Test 800/1152. loss: 2.175, 0.1164 s / batch. (data: 6.68e-05)max mem: 17.22454 GB 
[09/18 22:47:03 visual_prompt]: 	Test 900/1152. loss: 2.221, 0.1076 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/18 22:47:20 visual_prompt]: 	Test 1000/1152. loss: 2.032, 0.0998 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 22:47:36 visual_prompt]: 	Test 1100/1152. loss: 2.244, 0.0951 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 22:47:48 visual_prompt]: Inference (test):avg data time: 1.77e-03, avg batch time: 0.1097, average loss: 2.1898
[09/18 22:47:48 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 26.05	top5: 75.04	
[09/18 22:47:48 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/18 22:47:58 visual_prompt]: Epoch 67 / 100: avg data time: 2.30e-01, avg batch time: 0.4566, average train loss: 1.8848
[09/18 22:48:05 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.0950, average loss: 1.6322
[09/18 22:48:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 45.50	top5: 89.50	
[09/18 22:48:25 visual_prompt]: 	Test 100/1152. loss: 2.420, 0.0956 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/18 22:48:42 visual_prompt]: 	Test 200/1152. loss: 2.208, 0.1024 s / batch. (data: 7.41e-05)max mem: 17.22454 GB 
[09/18 22:48:58 visual_prompt]: 	Test 300/1152. loss: 2.333, 0.1199 s / batch. (data: 3.40e-03)max mem: 17.22454 GB 
[09/18 22:49:14 visual_prompt]: 	Test 400/1152. loss: 2.730, 0.1198 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 22:49:30 visual_prompt]: 	Test 500/1152. loss: 2.249, 0.1233 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 22:49:46 visual_prompt]: 	Test 600/1152. loss: 2.124, 0.1076 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 22:50:02 visual_prompt]: 	Test 700/1152. loss: 2.029, 0.1141 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/18 22:50:19 visual_prompt]: 	Test 800/1152. loss: 2.312, 0.1221 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/18 22:50:35 visual_prompt]: 	Test 900/1152. loss: 2.279, 0.0990 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 22:50:51 visual_prompt]: 	Test 1000/1152. loss: 2.054, 0.1356 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 22:51:07 visual_prompt]: 	Test 1100/1152. loss: 2.101, 0.0952 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 22:51:19 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1087, average loss: 2.3111
[09/18 22:51:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.66	top5: 73.26	
[09/18 22:51:20 visual_prompt]: Best epoch 67: best metric: 0.455
[09/18 22:51:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/18 22:51:30 visual_prompt]: Epoch 68 / 100: avg data time: 2.30e-01, avg batch time: 0.4618, average train loss: 1.8339
[09/18 22:51:37 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.0863, average loss: 1.6657
[09/18 22:51:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.50	top5: 91.00	
[09/18 22:51:56 visual_prompt]: 	Test 100/1152. loss: 2.313, 0.1030 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/18 22:52:13 visual_prompt]: 	Test 200/1152. loss: 2.131, 0.1017 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 22:52:29 visual_prompt]: 	Test 300/1152. loss: 2.474, 0.1209 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 22:52:45 visual_prompt]: 	Test 400/1152. loss: 2.448, 0.1435 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/18 22:53:01 visual_prompt]: 	Test 500/1152. loss: 2.088, 0.0987 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/18 22:53:17 visual_prompt]: 	Test 600/1152. loss: 2.301, 0.0968 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 22:53:33 visual_prompt]: 	Test 700/1152. loss: 2.083, 0.1188 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 22:53:49 visual_prompt]: 	Test 800/1152. loss: 2.103, 0.1040 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/18 22:54:05 visual_prompt]: 	Test 900/1152. loss: 2.313, 0.1304 s / batch. (data: 9.62e-03)max mem: 17.22454 GB 
[09/18 22:54:21 visual_prompt]: 	Test 1000/1152. loss: 2.028, 0.1079 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/18 22:54:37 visual_prompt]: 	Test 1100/1152. loss: 2.126, 0.0969 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 22:54:50 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1090, average loss: 2.2196
[09/18 22:54:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.27	top5: 76.92	
[09/18 22:54:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/18 22:55:00 visual_prompt]: Epoch 69 / 100: avg data time: 2.30e-01, avg batch time: 0.4544, average train loss: 1.6977
[09/18 22:55:07 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.0905, average loss: 1.6796
[09/18 22:55:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 39.50	top5: 90.00	
[09/18 22:55:27 visual_prompt]: 	Test 100/1152. loss: 2.392, 0.0953 s / batch. (data: 3.17e-05)max mem: 17.22454 GB 
[09/18 22:55:43 visual_prompt]: 	Test 200/1152. loss: 2.468, 0.1007 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 22:56:00 visual_prompt]: 	Test 300/1152. loss: 2.338, 0.1119 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 22:56:16 visual_prompt]: 	Test 400/1152. loss: 2.807, 0.1119 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/18 22:56:32 visual_prompt]: 	Test 500/1152. loss: 2.240, 0.1027 s / batch. (data: 5.48e-03)max mem: 17.22454 GB 
[09/18 22:56:48 visual_prompt]: 	Test 600/1152. loss: 2.496, 0.1288 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/18 22:57:04 visual_prompt]: 	Test 700/1152. loss: 2.138, 0.0999 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 22:57:20 visual_prompt]: 	Test 800/1152. loss: 2.300, 0.1339 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 22:57:36 visual_prompt]: 	Test 900/1152. loss: 2.282, 0.1059 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 22:57:52 visual_prompt]: 	Test 1000/1152. loss: 2.142, 0.1085 s / batch. (data: 7.94e-03)max mem: 17.22454 GB 
[09/18 22:58:08 visual_prompt]: 	Test 1100/1152. loss: 2.319, 0.1086 s / batch. (data: 7.99e-03)max mem: 17.22454 GB 
[09/18 22:58:21 visual_prompt]: Inference (test):avg data time: 2.16e-03, avg batch time: 0.1090, average loss: 2.4043
[09/18 22:58:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 23.78	top5: 76.74	
[09/18 22:58:21 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/18 22:58:31 visual_prompt]: Epoch 70 / 100: avg data time: 2.34e-01, avg batch time: 0.4598, average train loss: 1.9199
[09/18 22:58:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.0956, average loss: 1.7341
[09/18 22:58:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 37.50	top5: 89.50	
[09/18 22:58:58 visual_prompt]: 	Test 100/1152. loss: 2.435, 0.1070 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/18 22:59:14 visual_prompt]: 	Test 200/1152. loss: 2.397, 0.1198 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 22:59:30 visual_prompt]: 	Test 300/1152. loss: 2.326, 0.1004 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 22:59:46 visual_prompt]: 	Test 400/1152. loss: 2.400, 0.1239 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 23:00:03 visual_prompt]: 	Test 500/1152. loss: 2.028, 0.1199 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 23:00:19 visual_prompt]: 	Test 600/1152. loss: 2.216, 0.0986 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 23:00:35 visual_prompt]: 	Test 700/1152. loss: 2.074, 0.0959 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 23:00:51 visual_prompt]: 	Test 800/1152. loss: 2.036, 0.1000 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 23:01:07 visual_prompt]: 	Test 900/1152. loss: 2.451, 0.1024 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 23:01:24 visual_prompt]: 	Test 1000/1152. loss: 2.201, 0.1000 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 23:01:40 visual_prompt]: 	Test 1100/1152. loss: 2.602, 0.1106 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/18 23:01:52 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1084, average loss: 2.3604
[09/18 23:01:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.92	top5: 77.57	
[09/18 23:01:52 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/18 23:02:03 visual_prompt]: Epoch 71 / 100: avg data time: 2.23e-01, avg batch time: 0.4543, average train loss: 1.6637
[09/18 23:02:09 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0920, average loss: 1.6101
[09/18 23:02:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 42.50	top5: 93.50	
[09/18 23:02:30 visual_prompt]: 	Test 100/1152. loss: 2.488, 0.1090 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/18 23:02:46 visual_prompt]: 	Test 200/1152. loss: 2.317, 0.1119 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:03:02 visual_prompt]: 	Test 300/1152. loss: 2.351, 0.0989 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 23:03:18 visual_prompt]: 	Test 400/1152. loss: 2.532, 0.1190 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 23:03:34 visual_prompt]: 	Test 500/1152. loss: 2.202, 0.0995 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/18 23:03:50 visual_prompt]: 	Test 600/1152. loss: 2.233, 0.1064 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 23:04:06 visual_prompt]: 	Test 700/1152. loss: 2.007, 0.0978 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/18 23:04:23 visual_prompt]: 	Test 800/1152. loss: 2.353, 0.1079 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/18 23:04:39 visual_prompt]: 	Test 900/1152. loss: 2.099, 0.1201 s / batch. (data: 7.34e-03)max mem: 17.22454 GB 
[09/18 23:04:55 visual_prompt]: 	Test 1000/1152. loss: 2.436, 0.1154 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 23:05:11 visual_prompt]: 	Test 1100/1152. loss: 2.287, 0.1158 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 23:05:23 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1086, average loss: 2.3690
[09/18 23:05:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.94	top5: 76.11	
[09/18 23:05:23 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/18 23:05:34 visual_prompt]: Epoch 72 / 100: avg data time: 2.35e-01, avg batch time: 0.4645, average train loss: 1.5931
[09/18 23:05:41 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.0922, average loss: 1.2789
[09/18 23:05:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 52.00	top5: 96.00	
[09/18 23:06:01 visual_prompt]: 	Test 100/1152. loss: 2.276, 0.0988 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 23:06:17 visual_prompt]: 	Test 200/1152. loss: 2.207, 0.0976 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/18 23:06:33 visual_prompt]: 	Test 300/1152. loss: 2.291, 0.1078 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 23:06:49 visual_prompt]: 	Test 400/1152. loss: 2.383, 0.0945 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 23:07:05 visual_prompt]: 	Test 500/1152. loss: 2.153, 0.1238 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 23:07:21 visual_prompt]: 	Test 600/1152. loss: 2.033, 0.1114 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/18 23:07:37 visual_prompt]: 	Test 700/1152. loss: 1.754, 0.1127 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 23:07:53 visual_prompt]: 	Test 800/1152. loss: 2.076, 0.1037 s / batch. (data: 9.73e-05)max mem: 17.22454 GB 
[09/18 23:08:09 visual_prompt]: 	Test 900/1152. loss: 2.031, 0.1200 s / batch. (data: 1.78e-04)max mem: 17.22454 GB 
[09/18 23:08:25 visual_prompt]: 	Test 1000/1152. loss: 1.963, 0.0972 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 23:08:42 visual_prompt]: 	Test 1100/1152. loss: 2.113, 0.0969 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 23:08:54 visual_prompt]: Inference (test):avg data time: 2.10e-03, avg batch time: 0.1093, average loss: 2.1486
[09/18 23:08:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 28.64	top5: 82.49	
[09/18 23:08:54 visual_prompt]: Best epoch 72: best metric: 0.520
[09/18 23:08:54 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/18 23:09:04 visual_prompt]: Epoch 73 / 100: avg data time: 2.24e-01, avg batch time: 0.4542, average train loss: 1.4063
[09/18 23:09:11 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.0894, average loss: 1.5359
[09/18 23:09:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 44.00	top5: 93.50	
[09/18 23:09:31 visual_prompt]: 	Test 100/1152. loss: 2.593, 0.0993 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/18 23:09:47 visual_prompt]: 	Test 200/1152. loss: 2.332, 0.1199 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/18 23:10:04 visual_prompt]: 	Test 300/1152. loss: 2.247, 0.1041 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 23:10:20 visual_prompt]: 	Test 400/1152. loss: 2.570, 0.1166 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 23:10:36 visual_prompt]: 	Test 500/1152. loss: 2.152, 0.1358 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/18 23:10:52 visual_prompt]: 	Test 600/1152. loss: 1.957, 0.1236 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 23:11:08 visual_prompt]: 	Test 700/1152. loss: 2.132, 0.0973 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 23:11:24 visual_prompt]: 	Test 800/1152. loss: 2.288, 0.0981 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 23:11:40 visual_prompt]: 	Test 900/1152. loss: 2.132, 0.1216 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/18 23:11:57 visual_prompt]: 	Test 1000/1152. loss: 1.987, 0.1114 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/18 23:12:13 visual_prompt]: 	Test 1100/1152. loss: 2.234, 0.1062 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 23:12:25 visual_prompt]: Inference (test):avg data time: 1.97e-03, avg batch time: 0.1091, average loss: 2.3602
[09/18 23:12:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 27.12	top5: 81.13	
[09/18 23:12:26 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/18 23:12:36 visual_prompt]: Epoch 74 / 100: avg data time: 2.45e-01, avg batch time: 0.4685, average train loss: 1.3862
[09/18 23:12:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.0935, average loss: 1.2752
[09/18 23:12:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 45.00	top5: 98.00	
[09/18 23:13:03 visual_prompt]: 	Test 100/1152. loss: 2.361, 0.1259 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 23:13:19 visual_prompt]: 	Test 200/1152. loss: 2.292, 0.0990 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/18 23:13:36 visual_prompt]: 	Test 300/1152. loss: 2.194, 0.1518 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 23:13:52 visual_prompt]: 	Test 400/1152. loss: 2.285, 0.1038 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 23:14:09 visual_prompt]: 	Test 500/1152. loss: 1.961, 0.1222 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/18 23:14:25 visual_prompt]: 	Test 600/1152. loss: 2.154, 0.1278 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 23:14:41 visual_prompt]: 	Test 700/1152. loss: 1.947, 0.1150 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 23:14:58 visual_prompt]: 	Test 800/1152. loss: 2.133, 0.1447 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 23:15:14 visual_prompt]: 	Test 900/1152. loss: 2.081, 0.1103 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 23:15:30 visual_prompt]: 	Test 1000/1152. loss: 2.203, 0.1109 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 23:15:47 visual_prompt]: 	Test 1100/1152. loss: 2.136, 0.1342 s / batch. (data: 2.16e-02)max mem: 17.22454 GB 
[09/18 23:15:59 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1089, average loss: 2.1962
[09/18 23:15:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 28.93	top5: 82.32	
[09/18 23:15:59 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/18 23:16:10 visual_prompt]: Epoch 75 / 100: avg data time: 2.35e-01, avg batch time: 0.4595, average train loss: 1.3006
[09/18 23:16:17 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.0906, average loss: 1.3638
[09/18 23:16:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 49.50	top5: 95.50	
[09/18 23:16:37 visual_prompt]: 	Test 100/1152. loss: 2.346, 0.1120 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/18 23:16:53 visual_prompt]: 	Test 200/1152. loss: 2.513, 0.1158 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 23:17:09 visual_prompt]: 	Test 300/1152. loss: 2.424, 0.0974 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 23:17:25 visual_prompt]: 	Test 400/1152. loss: 2.243, 0.1053 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/18 23:17:41 visual_prompt]: 	Test 500/1152. loss: 2.141, 0.1252 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/18 23:17:57 visual_prompt]: 	Test 600/1152. loss: 2.072, 0.1427 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/18 23:18:13 visual_prompt]: 	Test 700/1152. loss: 1.810, 0.1115 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/18 23:18:29 visual_prompt]: 	Test 800/1152. loss: 2.202, 0.1056 s / batch. (data: 1.29e-05)max mem: 17.22454 GB 
[09/18 23:18:45 visual_prompt]: 	Test 900/1152. loss: 2.234, 0.1038 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 23:19:01 visual_prompt]: 	Test 1000/1152. loss: 1.965, 0.0999 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/18 23:19:17 visual_prompt]: 	Test 1100/1152. loss: 2.268, 0.0985 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 23:19:30 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1093, average loss: 2.3294
[09/18 23:19:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 28.02	top5: 82.29	
[09/18 23:19:30 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/18 23:19:41 visual_prompt]: Epoch 76 / 100: avg data time: 2.36e-01, avg batch time: 0.4569, average train loss: 1.2058
[09/18 23:19:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0924, average loss: 0.9913
[09/18 23:19:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 63.00	top5: 98.00	
[09/18 23:20:07 visual_prompt]: 	Test 100/1152. loss: 2.223, 0.1385 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/18 23:20:23 visual_prompt]: 	Test 200/1152. loss: 2.295, 0.1359 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/18 23:20:39 visual_prompt]: 	Test 300/1152. loss: 2.027, 0.0999 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 23:20:56 visual_prompt]: 	Test 400/1152. loss: 2.234, 0.1367 s / batch. (data: 1.21e-02)max mem: 17.22454 GB 
[09/18 23:21:12 visual_prompt]: 	Test 500/1152. loss: 1.918, 0.1079 s / batch. (data: 1.36e-05)max mem: 17.22454 GB 
[09/18 23:21:28 visual_prompt]: 	Test 600/1152. loss: 1.939, 0.0979 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 23:21:44 visual_prompt]: 	Test 700/1152. loss: 1.644, 0.1041 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/18 23:22:00 visual_prompt]: 	Test 800/1152. loss: 1.990, 0.1067 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 23:22:16 visual_prompt]: 	Test 900/1152. loss: 2.046, 0.1019 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/18 23:22:32 visual_prompt]: 	Test 1000/1152. loss: 1.792, 0.1354 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/18 23:22:48 visual_prompt]: 	Test 1100/1152. loss: 2.023, 0.1123 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/18 23:23:00 visual_prompt]: Inference (test):avg data time: 1.42e-03, avg batch time: 0.1082, average loss: 2.0752
[09/18 23:23:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 33.19	top5: 86.56	
[09/18 23:23:01 visual_prompt]: Best epoch 76: best metric: 0.630
[09/18 23:23:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/18 23:23:11 visual_prompt]: Epoch 77 / 100: avg data time: 2.28e-01, avg batch time: 0.4568, average train loss: 1.2105
[09/18 23:23:18 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.0886, average loss: 1.1109
[09/18 23:23:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 63.50	top5: 98.50	
[09/18 23:23:37 visual_prompt]: 	Test 100/1152. loss: 2.568, 0.1114 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/18 23:23:53 visual_prompt]: 	Test 200/1152. loss: 2.461, 0.0980 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/18 23:24:10 visual_prompt]: 	Test 300/1152. loss: 2.552, 0.1105 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 23:24:26 visual_prompt]: 	Test 400/1152. loss: 2.345, 0.0977 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/18 23:24:42 visual_prompt]: 	Test 500/1152. loss: 2.160, 0.0952 s / batch. (data: 7.10e-05)max mem: 17.22454 GB 
[09/18 23:24:58 visual_prompt]: 	Test 600/1152. loss: 2.070, 0.1054 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/18 23:25:14 visual_prompt]: 	Test 700/1152. loss: 1.841, 0.0967 s / batch. (data: 9.63e-05)max mem: 17.22454 GB 
[09/18 23:25:31 visual_prompt]: 	Test 800/1152. loss: 2.270, 0.0994 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/18 23:25:47 visual_prompt]: 	Test 900/1152. loss: 2.190, 0.1034 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/18 23:26:03 visual_prompt]: 	Test 1000/1152. loss: 1.691, 0.0970 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 23:26:20 visual_prompt]: 	Test 1100/1152. loss: 2.063, 0.0943 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/18 23:26:32 visual_prompt]: Inference (test):avg data time: 1.63e-03, avg batch time: 0.1084, average loss: 2.1821
[09/18 23:26:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.08	top5: 84.39	
[09/18 23:26:32 visual_prompt]: Best epoch 77: best metric: 0.635
[09/18 23:26:32 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/18 23:26:42 visual_prompt]: Epoch 78 / 100: avg data time: 2.23e-01, avg batch time: 0.4487, average train loss: 1.0567
[09/18 23:26:49 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.0869, average loss: 0.8748
[09/18 23:26:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 62.50	top5: 100.00	
[09/18 23:27:09 visual_prompt]: 	Test 100/1152. loss: 2.322, 0.1044 s / batch. (data: 2.10e-03)max mem: 17.22454 GB 
[09/18 23:27:25 visual_prompt]: 	Test 200/1152. loss: 2.440, 0.0999 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 23:27:42 visual_prompt]: 	Test 300/1152. loss: 2.225, 0.0958 s / batch. (data: 9.73e-05)max mem: 17.22454 GB 
[09/18 23:27:58 visual_prompt]: 	Test 400/1152. loss: 2.156, 0.0987 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 23:28:14 visual_prompt]: 	Test 500/1152. loss: 2.135, 0.0953 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 23:28:30 visual_prompt]: 	Test 600/1152. loss: 2.004, 0.0945 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/18 23:28:46 visual_prompt]: 	Test 700/1152. loss: 1.738, 0.1005 s / batch. (data: 7.39e-05)max mem: 17.22454 GB 
[09/18 23:29:02 visual_prompt]: 	Test 800/1152. loss: 2.189, 0.0947 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/18 23:29:18 visual_prompt]: 	Test 900/1152. loss: 2.225, 0.1295 s / batch. (data: 6.56e-05)max mem: 17.22454 GB 
[09/18 23:29:34 visual_prompt]: 	Test 1000/1152. loss: 1.732, 0.1359 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 23:29:50 visual_prompt]: 	Test 1100/1152. loss: 2.024, 0.0950 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 23:30:03 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1086, average loss: 2.1350
[09/18 23:30:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 33.73	top5: 86.38	
[09/18 23:30:03 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/18 23:30:13 visual_prompt]: Epoch 79 / 100: avg data time: 2.27e-01, avg batch time: 0.4547, average train loss: 0.8506
[09/18 23:30:20 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.0872, average loss: 0.7769
[09/18 23:30:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 70.00	top5: 100.00	
[09/18 23:30:40 visual_prompt]: 	Test 100/1152. loss: 3.143, 0.1116 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/18 23:30:56 visual_prompt]: 	Test 200/1152. loss: 2.783, 0.1022 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 23:31:12 visual_prompt]: 	Test 300/1152. loss: 2.967, 0.1118 s / batch. (data: 9.01e-05)max mem: 17.22454 GB 
[09/18 23:31:29 visual_prompt]: 	Test 400/1152. loss: 2.845, 0.1067 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 23:31:45 visual_prompt]: 	Test 500/1152. loss: 2.405, 0.1119 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/18 23:32:01 visual_prompt]: 	Test 600/1152. loss: 2.571, 0.1131 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/18 23:32:17 visual_prompt]: 	Test 700/1152. loss: 2.159, 0.0948 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/18 23:32:33 visual_prompt]: 	Test 800/1152. loss: 2.403, 0.0949 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 23:32:49 visual_prompt]: 	Test 900/1152. loss: 2.571, 0.1084 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/18 23:33:05 visual_prompt]: 	Test 1000/1152. loss: 2.202, 0.1187 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/18 23:33:21 visual_prompt]: 	Test 1100/1152. loss: 2.620, 0.0969 s / batch. (data: 9.94e-05)max mem: 17.22454 GB 
[09/18 23:33:34 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1084, average loss: 2.5809
[09/18 23:33:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 33.17	top5: 86.57	
[09/18 23:33:34 visual_prompt]: Best epoch 79: best metric: 0.700
[09/18 23:33:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/18 23:33:44 visual_prompt]: Epoch 80 / 100: avg data time: 2.35e-01, avg batch time: 0.4570, average train loss: 0.9192
[09/18 23:33:51 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.0931, average loss: 0.6736
[09/18 23:33:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 74.00	top5: 100.00	
[09/18 23:34:11 visual_prompt]: 	Test 100/1152. loss: 2.356, 0.1147 s / batch. (data: 9.08e-05)max mem: 17.22454 GB 
[09/18 23:34:27 visual_prompt]: 	Test 200/1152. loss: 2.422, 0.0995 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:34:43 visual_prompt]: 	Test 300/1152. loss: 2.317, 0.1161 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/18 23:34:59 visual_prompt]: 	Test 400/1152. loss: 2.242, 0.0983 s / batch. (data: 8.77e-05)max mem: 17.22454 GB 
[09/18 23:35:16 visual_prompt]: 	Test 500/1152. loss: 2.169, 0.1040 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/18 23:35:32 visual_prompt]: 	Test 600/1152. loss: 1.836, 0.1117 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 23:35:48 visual_prompt]: 	Test 700/1152. loss: 1.735, 0.1111 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/18 23:36:05 visual_prompt]: 	Test 800/1152. loss: 2.223, 0.1197 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/18 23:36:21 visual_prompt]: 	Test 900/1152. loss: 2.006, 0.0958 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/18 23:36:37 visual_prompt]: 	Test 1000/1152. loss: 1.964, 0.1119 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 23:36:53 visual_prompt]: 	Test 1100/1152. loss: 2.073, 0.0950 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 23:37:06 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1080, average loss: 2.1932
[09/18 23:37:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.38	top5: 87.90	
[09/18 23:37:06 visual_prompt]: Best epoch 80: best metric: 0.740
[09/18 23:37:06 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/18 23:37:17 visual_prompt]: Epoch 81 / 100: avg data time: 2.33e-01, avg batch time: 0.4563, average train loss: 0.8192
[09/18 23:37:24 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.0923, average loss: 0.5989
[09/18 23:37:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 77.00	top5: 99.00	
[09/18 23:37:43 visual_prompt]: 	Test 100/1152. loss: 2.384, 0.1079 s / batch. (data: 7.42e-03)max mem: 17.22454 GB 
[09/18 23:38:00 visual_prompt]: 	Test 200/1152. loss: 2.587, 0.0990 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:38:16 visual_prompt]: 	Test 300/1152. loss: 2.740, 0.1057 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:38:33 visual_prompt]: 	Test 400/1152. loss: 2.483, 0.0957 s / batch. (data: 3.67e-05)max mem: 17.22454 GB 
[09/18 23:38:49 visual_prompt]: 	Test 500/1152. loss: 2.410, 0.0957 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/18 23:39:05 visual_prompt]: 	Test 600/1152. loss: 2.092, 0.1055 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 23:39:21 visual_prompt]: 	Test 700/1152. loss: 1.920, 0.1079 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 23:39:37 visual_prompt]: 	Test 800/1152. loss: 2.213, 0.1128 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/18 23:39:53 visual_prompt]: 	Test 900/1152. loss: 1.996, 0.0988 s / batch. (data: 9.75e-05)max mem: 17.22454 GB 
[09/18 23:40:09 visual_prompt]: 	Test 1000/1152. loss: 2.186, 0.1014 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/18 23:40:25 visual_prompt]: 	Test 1100/1152. loss: 2.196, 0.1015 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/18 23:40:37 visual_prompt]: Inference (test):avg data time: 1.54e-03, avg batch time: 0.1084, average loss: 2.3922
[09/18 23:40:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 34.61	top5: 87.69	
[09/18 23:40:38 visual_prompt]: Best epoch 81: best metric: 0.770
[09/18 23:40:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/18 23:40:48 visual_prompt]: Epoch 82 / 100: avg data time: 2.37e-01, avg batch time: 0.4592, average train loss: 0.6578
[09/18 23:40:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.0868, average loss: 0.7450
[09/18 23:40:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 74.00	top5: 99.50	
[09/18 23:41:15 visual_prompt]: 	Test 100/1152. loss: 3.254, 0.1173 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 23:41:31 visual_prompt]: 	Test 200/1152. loss: 2.825, 0.0995 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/18 23:41:47 visual_prompt]: 	Test 300/1152. loss: 2.742, 0.0949 s / batch. (data: 5.15e-05)max mem: 17.22454 GB 
[09/18 23:42:04 visual_prompt]: 	Test 400/1152. loss: 2.962, 0.0946 s / batch. (data: 5.15e-05)max mem: 17.22454 GB 
[09/18 23:42:20 visual_prompt]: 	Test 500/1152. loss: 2.605, 0.1105 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/18 23:42:36 visual_prompt]: 	Test 600/1152. loss: 2.501, 0.1051 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/18 23:42:52 visual_prompt]: 	Test 700/1152. loss: 2.418, 0.1160 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 23:43:07 visual_prompt]: 	Test 800/1152. loss: 2.721, 0.1109 s / batch. (data: 5.03e-05)max mem: 17.22454 GB 
[09/18 23:43:24 visual_prompt]: 	Test 900/1152. loss: 2.529, 0.0948 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/18 23:43:40 visual_prompt]: 	Test 1000/1152. loss: 2.247, 0.1012 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/18 23:43:56 visual_prompt]: 	Test 1100/1152. loss: 2.743, 0.0946 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/18 23:44:08 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1087, average loss: 2.7637
[09/18 23:44:09 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 33.51	top5: 87.02	
[09/18 23:44:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/18 23:44:19 visual_prompt]: Epoch 83 / 100: avg data time: 2.24e-01, avg batch time: 0.4501, average train loss: 0.7138
[09/18 23:44:26 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.0935, average loss: 0.5865
[09/18 23:44:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 76.50	top5: 99.00	
[09/18 23:44:46 visual_prompt]: 	Test 100/1152. loss: 3.138, 0.1433 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/18 23:45:02 visual_prompt]: 	Test 200/1152. loss: 2.924, 0.0995 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/18 23:45:19 visual_prompt]: 	Test 300/1152. loss: 2.837, 0.1198 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 23:45:35 visual_prompt]: 	Test 400/1152. loss: 2.686, 0.1042 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/18 23:45:51 visual_prompt]: 	Test 500/1152. loss: 3.002, 0.1120 s / batch. (data: 1.16e-02)max mem: 17.22454 GB 
[09/18 23:46:07 visual_prompt]: 	Test 600/1152. loss: 2.271, 0.1113 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/18 23:46:23 visual_prompt]: 	Test 700/1152. loss: 2.173, 0.1024 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/18 23:46:39 visual_prompt]: 	Test 800/1152. loss: 2.602, 0.0983 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/18 23:46:55 visual_prompt]: 	Test 900/1152. loss: 2.182, 0.1019 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/18 23:47:11 visual_prompt]: 	Test 1000/1152. loss: 2.127, 0.1277 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/18 23:47:28 visual_prompt]: 	Test 1100/1152. loss: 2.478, 0.1087 s / batch. (data: 8.05e-03)max mem: 17.22454 GB 
[09/18 23:47:40 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1083, average loss: 2.6704
[09/18 23:47:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 32.56	top5: 85.91	
[09/18 23:47:40 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/18 23:47:51 visual_prompt]: Epoch 84 / 100: avg data time: 2.40e-01, avg batch time: 0.4618, average train loss: 0.5610
[09/18 23:47:58 visual_prompt]: Inference (val):avg data time: 1.05e-03, avg batch time: 0.0943, average loss: 0.5273
[09/18 23:47:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 81.50	top5: 100.00	
[09/18 23:48:17 visual_prompt]: 	Test 100/1152. loss: 3.236, 0.1076 s / batch. (data: 7.03e-03)max mem: 17.22454 GB 
[09/18 23:48:33 visual_prompt]: 	Test 200/1152. loss: 3.095, 0.1246 s / batch. (data: 8.09e-03)max mem: 17.22454 GB 
[09/18 23:48:50 visual_prompt]: 	Test 300/1152. loss: 2.755, 0.1106 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/18 23:49:06 visual_prompt]: 	Test 400/1152. loss: 3.030, 0.0948 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/18 23:49:22 visual_prompt]: 	Test 500/1152. loss: 2.733, 0.1100 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/18 23:49:38 visual_prompt]: 	Test 600/1152. loss: 2.768, 0.1176 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/18 23:49:54 visual_prompt]: 	Test 700/1152. loss: 2.256, 0.1060 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/18 23:50:11 visual_prompt]: 	Test 800/1152. loss: 2.776, 0.0975 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/18 23:50:27 visual_prompt]: 	Test 900/1152. loss: 2.358, 0.1159 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 23:50:43 visual_prompt]: 	Test 1000/1152. loss: 2.031, 0.1199 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/18 23:50:59 visual_prompt]: 	Test 1100/1152. loss: 2.459, 0.0986 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/18 23:51:11 visual_prompt]: Inference (test):avg data time: 1.54e-03, avg batch time: 0.1083, average loss: 2.8142
[09/18 23:51:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.10	top5: 87.39	
[09/18 23:51:11 visual_prompt]: Best epoch 84: best metric: 0.815
[09/18 23:51:11 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/18 23:51:22 visual_prompt]: Epoch 85 / 100: avg data time: 2.33e-01, avg batch time: 0.4565, average train loss: 0.5386
[09/18 23:51:28 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.0957, average loss: 0.4934
[09/18 23:51:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 82.00	top5: 100.00	
[09/18 23:51:48 visual_prompt]: 	Test 100/1152. loss: 3.099, 0.1126 s / batch. (data: 1.62e-02)max mem: 17.22454 GB 
[09/18 23:52:04 visual_prompt]: 	Test 200/1152. loss: 2.838, 0.1039 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 23:52:21 visual_prompt]: 	Test 300/1152. loss: 2.911, 0.1121 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/18 23:52:37 visual_prompt]: 	Test 400/1152. loss: 2.999, 0.1119 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/18 23:52:53 visual_prompt]: 	Test 500/1152. loss: 3.034, 0.1038 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:53:09 visual_prompt]: 	Test 600/1152. loss: 2.877, 0.1119 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/18 23:53:25 visual_prompt]: 	Test 700/1152. loss: 2.997, 0.0976 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/18 23:53:41 visual_prompt]: 	Test 800/1152. loss: 2.889, 0.0968 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/18 23:53:57 visual_prompt]: 	Test 900/1152. loss: 2.331, 0.1449 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/18 23:54:13 visual_prompt]: 	Test 1000/1152. loss: 2.546, 0.0960 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/18 23:54:30 visual_prompt]: 	Test 1100/1152. loss: 2.896, 0.0953 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/18 23:54:42 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1080, average loss: 2.8973
[09/18 23:54:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.57	top5: 87.19	
[09/18 23:54:42 visual_prompt]: Best epoch 85: best metric: 0.820
[09/18 23:54:42 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/18 23:54:53 visual_prompt]: Epoch 86 / 100: avg data time: 2.46e-01, avg batch time: 0.4724, average train loss: 0.4524
[09/18 23:55:00 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.0924, average loss: 0.4150
[09/18 23:55:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 86.00	top5: 100.00	
[09/18 23:55:19 visual_prompt]: 	Test 100/1152. loss: 3.749, 0.1011 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/18 23:55:36 visual_prompt]: 	Test 200/1152. loss: 3.487, 0.1199 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/18 23:55:52 visual_prompt]: 	Test 300/1152. loss: 3.343, 0.1046 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/18 23:56:08 visual_prompt]: 	Test 400/1152. loss: 3.395, 0.1119 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/18 23:56:24 visual_prompt]: 	Test 500/1152. loss: 3.218, 0.1040 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/18 23:56:40 visual_prompt]: 	Test 600/1152. loss: 2.631, 0.0961 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/18 23:56:56 visual_prompt]: 	Test 700/1152. loss: 2.772, 0.1269 s / batch. (data: 2.94e-02)max mem: 17.22454 GB 
[09/18 23:57:13 visual_prompt]: 	Test 800/1152. loss: 3.268, 0.1240 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/18 23:57:28 visual_prompt]: 	Test 900/1152. loss: 2.425, 0.1199 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/18 23:57:45 visual_prompt]: 	Test 1000/1152. loss: 2.601, 0.1183 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/18 23:58:01 visual_prompt]: 	Test 1100/1152. loss: 3.051, 0.1078 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/18 23:58:13 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1088, average loss: 3.0933
[09/18 23:58:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.42	top5: 87.02	
[09/18 23:58:13 visual_prompt]: Best epoch 86: best metric: 0.860
[09/18 23:58:13 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/18 23:58:24 visual_prompt]: Epoch 87 / 100: avg data time: 2.33e-01, avg batch time: 0.4599, average train loss: 0.3826
[09/18 23:58:31 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0927, average loss: 0.5641
[09/18 23:58:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 75.00	top5: 100.00	
[09/18 23:58:50 visual_prompt]: 	Test 100/1152. loss: 4.081, 0.1079 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/18 23:59:07 visual_prompt]: 	Test 200/1152. loss: 4.252, 0.0956 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/18 23:59:23 visual_prompt]: 	Test 300/1152. loss: 3.246, 0.1016 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/18 23:59:39 visual_prompt]: 	Test 400/1152. loss: 4.240, 0.0952 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/18 23:59:55 visual_prompt]: 	Test 500/1152. loss: 3.870, 0.0946 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/19 00:00:11 visual_prompt]: 	Test 600/1152. loss: 3.321, 0.0979 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 00:00:27 visual_prompt]: 	Test 700/1152. loss: 2.507, 0.1183 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 00:00:43 visual_prompt]: 	Test 800/1152. loss: 3.525, 0.1185 s / batch. (data: 3.89e-05)max mem: 17.22454 GB 
[09/19 00:00:59 visual_prompt]: 	Test 900/1152. loss: 3.179, 0.1042 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 00:01:15 visual_prompt]: 	Test 1000/1152. loss: 3.372, 0.0950 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 00:01:31 visual_prompt]: 	Test 1100/1152. loss: 3.363, 0.1644 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 00:01:44 visual_prompt]: Inference (test):avg data time: 1.32e-03, avg batch time: 0.1082, average loss: 3.6265
[09/19 00:01:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 34.89	top5: 87.75	
[09/19 00:01:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/19 00:01:54 visual_prompt]: Epoch 88 / 100: avg data time: 2.32e-01, avg batch time: 0.4555, average train loss: 0.4081
[09/19 00:02:01 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.0879, average loss: 0.2830
[09/19 00:02:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 89.00	top5: 100.00	
[09/19 00:02:21 visual_prompt]: 	Test 100/1152. loss: 4.141, 0.0968 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 00:02:38 visual_prompt]: 	Test 200/1152. loss: 3.782, 0.1000 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 00:02:54 visual_prompt]: 	Test 300/1152. loss: 3.554, 0.1411 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 00:03:10 visual_prompt]: 	Test 400/1152. loss: 3.817, 0.1356 s / batch. (data: 3.10e-02)max mem: 17.22454 GB 
[09/19 00:03:26 visual_prompt]: 	Test 500/1152. loss: 3.537, 0.0968 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 00:03:42 visual_prompt]: 	Test 600/1152. loss: 2.986, 0.1103 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 00:03:58 visual_prompt]: 	Test 700/1152. loss: 2.568, 0.1059 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 00:04:14 visual_prompt]: 	Test 800/1152. loss: 3.528, 0.1226 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/19 00:04:30 visual_prompt]: 	Test 900/1152. loss: 2.672, 0.0970 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 00:04:47 visual_prompt]: 	Test 1000/1152. loss: 2.889, 0.1150 s / batch. (data: 1.83e-02)max mem: 17.22454 GB 
[09/19 00:05:03 visual_prompt]: 	Test 1100/1152. loss: 3.194, 0.1199 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 00:05:15 visual_prompt]: Inference (test):avg data time: 2.19e-03, avg batch time: 0.1096, average loss: 3.3773
[09/19 00:05:15 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.88	top5: 88.29	
[09/19 00:05:15 visual_prompt]: Best epoch 88: best metric: 0.890
[09/19 00:05:15 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/19 00:05:26 visual_prompt]: Epoch 89 / 100: avg data time: 2.25e-01, avg batch time: 0.4482, average train loss: 0.3164
[09/19 00:05:32 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.0864, average loss: 0.3681
[09/19 00:05:32 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 85.50	top5: 99.50	
[09/19 00:05:52 visual_prompt]: 	Test 100/1152. loss: 4.043, 0.1290 s / batch. (data: 7.66e-03)max mem: 17.22454 GB 
[09/19 00:06:08 visual_prompt]: 	Test 200/1152. loss: 3.824, 0.0976 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 00:06:25 visual_prompt]: 	Test 300/1152. loss: 3.368, 0.1076 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 00:06:41 visual_prompt]: 	Test 400/1152. loss: 3.822, 0.0996 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 00:06:57 visual_prompt]: 	Test 500/1152. loss: 4.055, 0.0988 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 00:07:13 visual_prompt]: 	Test 600/1152. loss: 3.417, 0.1157 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/19 00:07:29 visual_prompt]: 	Test 700/1152. loss: 2.551, 0.0952 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 00:07:46 visual_prompt]: 	Test 800/1152. loss: 3.509, 0.1297 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 00:08:02 visual_prompt]: 	Test 900/1152. loss: 3.071, 0.1006 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 00:08:18 visual_prompt]: 	Test 1000/1152. loss: 3.053, 0.1077 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 00:08:34 visual_prompt]: 	Test 1100/1152. loss: 3.304, 0.1001 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 00:08:46 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1085, average loss: 3.4869
[09/19 00:08:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.06	top5: 87.86	
[09/19 00:08:46 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/19 00:08:57 visual_prompt]: Epoch 90 / 100: avg data time: 2.33e-01, avg batch time: 0.4611, average train loss: 0.2126
[09/19 00:09:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.0907, average loss: 0.1771
[09/19 00:09:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 94.50	top5: 100.00	
[09/19 00:09:23 visual_prompt]: 	Test 100/1152. loss: 4.205, 0.1075 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 00:09:40 visual_prompt]: 	Test 200/1152. loss: 3.952, 0.1183 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:09:56 visual_prompt]: 	Test 300/1152. loss: 3.790, 0.1121 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:10:12 visual_prompt]: 	Test 400/1152. loss: 3.953, 0.1081 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 00:10:28 visual_prompt]: 	Test 500/1152. loss: 3.913, 0.1065 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 00:10:44 visual_prompt]: 	Test 600/1152. loss: 3.195, 0.1063 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 00:11:00 visual_prompt]: 	Test 700/1152. loss: 2.790, 0.0952 s / batch. (data: 4.82e-05)max mem: 17.22454 GB 
[09/19 00:11:16 visual_prompt]: 	Test 800/1152. loss: 3.393, 0.1045 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 00:11:32 visual_prompt]: 	Test 900/1152. loss: 2.984, 0.0986 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 00:11:48 visual_prompt]: 	Test 1000/1152. loss: 2.983, 0.1131 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 00:12:04 visual_prompt]: 	Test 1100/1152. loss: 3.274, 0.0991 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 00:12:17 visual_prompt]: Inference (test):avg data time: 1.60e-03, avg batch time: 0.1086, average loss: 3.5325
[09/19 00:12:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.04	top5: 88.67	
[09/19 00:12:17 visual_prompt]: Best epoch 90: best metric: 0.945
[09/19 00:12:17 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/19 00:12:27 visual_prompt]: Epoch 91 / 100: avg data time: 2.28e-01, avg batch time: 0.4516, average train loss: 0.1578
[09/19 00:12:34 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.0881, average loss: 0.1328
[09/19 00:12:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 95.50	top5: 100.00	
[09/19 00:12:54 visual_prompt]: 	Test 100/1152. loss: 4.761, 0.1452 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 00:13:10 visual_prompt]: 	Test 200/1152. loss: 4.031, 0.1165 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 00:13:27 visual_prompt]: 	Test 300/1152. loss: 3.862, 0.1158 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 00:13:43 visual_prompt]: 	Test 400/1152. loss: 4.004, 0.1230 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 00:13:59 visual_prompt]: 	Test 500/1152. loss: 4.085, 0.1233 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 00:14:15 visual_prompt]: 	Test 600/1152. loss: 3.595, 0.1319 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 00:14:31 visual_prompt]: 	Test 700/1152. loss: 2.588, 0.0945 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 00:14:48 visual_prompt]: 	Test 800/1152. loss: 3.797, 0.1029 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 00:15:04 visual_prompt]: 	Test 900/1152. loss: 3.147, 0.1041 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 00:15:20 visual_prompt]: 	Test 1000/1152. loss: 2.997, 0.0950 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 00:15:36 visual_prompt]: 	Test 1100/1152. loss: 3.235, 0.1078 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 00:15:48 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1087, average loss: 3.7105
[09/19 00:15:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.35	top5: 88.65	
[09/19 00:15:49 visual_prompt]: Best epoch 91: best metric: 0.955
[09/19 00:15:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/19 00:15:59 visual_prompt]: Epoch 92 / 100: avg data time: 2.26e-01, avg batch time: 0.4505, average train loss: 0.1122
[09/19 00:16:06 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0898, average loss: 0.1020
[09/19 00:16:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 97.50	top5: 100.00	
[09/19 00:16:26 visual_prompt]: 	Test 100/1152. loss: 4.542, 0.0989 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 00:16:42 visual_prompt]: 	Test 200/1152. loss: 4.066, 0.1125 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 00:16:58 visual_prompt]: 	Test 300/1152. loss: 3.886, 0.1321 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 00:17:14 visual_prompt]: 	Test 400/1152. loss: 3.947, 0.0966 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 00:17:30 visual_prompt]: 	Test 500/1152. loss: 4.003, 0.1200 s / batch. (data: 9.92e-05)max mem: 17.22454 GB 
[09/19 00:17:46 visual_prompt]: 	Test 600/1152. loss: 3.480, 0.1202 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:18:02 visual_prompt]: 	Test 700/1152. loss: 2.703, 0.1237 s / batch. (data: 7.04e-03)max mem: 17.22454 GB 
[09/19 00:18:18 visual_prompt]: 	Test 800/1152. loss: 3.731, 0.0967 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 00:18:34 visual_prompt]: 	Test 900/1152. loss: 3.012, 0.1119 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 00:18:51 visual_prompt]: 	Test 1000/1152. loss: 3.065, 0.1499 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/19 00:19:07 visual_prompt]: 	Test 1100/1152. loss: 3.416, 0.1076 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 00:19:19 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1094, average loss: 3.7726
[09/19 00:19:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.21	top5: 88.87	
[09/19 00:19:19 visual_prompt]: Best epoch 92: best metric: 0.975
[09/19 00:19:19 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/19 00:19:30 visual_prompt]: Epoch 93 / 100: avg data time: 2.45e-01, avg batch time: 0.4683, average train loss: 0.0843
[09/19 00:19:37 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1049, average loss: 0.0956
[09/19 00:19:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 97.50	top5: 100.00	
[09/19 00:19:57 visual_prompt]: 	Test 100/1152. loss: 4.419, 0.1166 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 00:20:13 visual_prompt]: 	Test 200/1152. loss: 3.942, 0.1145 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 00:20:29 visual_prompt]: 	Test 300/1152. loss: 4.035, 0.1178 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 00:20:45 visual_prompt]: 	Test 400/1152. loss: 4.188, 0.0996 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 00:21:01 visual_prompt]: 	Test 500/1152. loss: 3.978, 0.1081 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 00:21:17 visual_prompt]: 	Test 600/1152. loss: 3.526, 0.0995 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 00:21:33 visual_prompt]: 	Test 700/1152. loss: 2.872, 0.1049 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/19 00:21:49 visual_prompt]: 	Test 800/1152. loss: 3.931, 0.1037 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:22:05 visual_prompt]: 	Test 900/1152. loss: 3.117, 0.1286 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:22:22 visual_prompt]: 	Test 1000/1152. loss: 3.000, 0.1241 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:22:38 visual_prompt]: 	Test 1100/1152. loss: 3.269, 0.1009 s / batch. (data: 3.72e-05)max mem: 17.22454 GB 
[09/19 00:22:50 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1088, average loss: 3.7549
[09/19 00:22:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.70	top5: 88.51	
[09/19 00:22:51 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/19 00:23:01 visual_prompt]: Epoch 94 / 100: avg data time: 2.33e-01, avg batch time: 0.4578, average train loss: 0.0780
[09/19 00:23:08 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.0917, average loss: 0.0798
[09/19 00:23:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 98.50	top5: 100.00	
[09/19 00:23:28 visual_prompt]: 	Test 100/1152. loss: 4.437, 0.0999 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 00:23:44 visual_prompt]: 	Test 200/1152. loss: 3.933, 0.1040 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 00:24:00 visual_prompt]: 	Test 300/1152. loss: 4.156, 0.1155 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 00:24:16 visual_prompt]: 	Test 400/1152. loss: 4.171, 0.1274 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 00:24:32 visual_prompt]: 	Test 500/1152. loss: 4.077, 0.1000 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 00:24:49 visual_prompt]: 	Test 600/1152. loss: 3.429, 0.1404 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 00:25:05 visual_prompt]: 	Test 700/1152. loss: 2.868, 0.1026 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 00:25:21 visual_prompt]: 	Test 800/1152. loss: 3.884, 0.0948 s / batch. (data: 6.91e-05)max mem: 17.22454 GB 
[09/19 00:25:37 visual_prompt]: 	Test 900/1152. loss: 3.084, 0.1086 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 00:25:53 visual_prompt]: 	Test 1000/1152. loss: 3.029, 0.0990 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 00:26:10 visual_prompt]: 	Test 1100/1152. loss: 3.283, 0.0967 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:26:23 visual_prompt]: Inference (test):avg data time: 1.67e-03, avg batch time: 0.1091, average loss: 3.7482
[09/19 00:26:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.66	top5: 88.60	
[09/19 00:26:23 visual_prompt]: Best epoch 94: best metric: 0.985
[09/19 00:26:23 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/19 00:26:34 visual_prompt]: Epoch 95 / 100: avg data time: 2.27e-01, avg batch time: 0.4582, average train loss: 0.0741
[09/19 00:26:41 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0941, average loss: 0.0992
[09/19 00:26:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 97.00	top5: 100.00	
[09/19 00:27:00 visual_prompt]: 	Test 100/1152. loss: 4.611, 0.1119 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 00:27:17 visual_prompt]: 	Test 200/1152. loss: 4.175, 0.1120 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:27:33 visual_prompt]: 	Test 300/1152. loss: 4.062, 0.1042 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 00:27:49 visual_prompt]: 	Test 400/1152. loss: 4.240, 0.1118 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 00:28:05 visual_prompt]: 	Test 500/1152. loss: 4.041, 0.1016 s / batch. (data: 2.83e-03)max mem: 17.22454 GB 
[09/19 00:28:21 visual_prompt]: 	Test 600/1152. loss: 3.489, 0.1195 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 00:28:37 visual_prompt]: 	Test 700/1152. loss: 3.026, 0.0966 s / batch. (data: 5.05e-05)max mem: 17.22454 GB 
[09/19 00:28:53 visual_prompt]: 	Test 800/1152. loss: 3.855, 0.1039 s / batch. (data: 7.08e-03)max mem: 17.22454 GB 
[09/19 00:29:09 visual_prompt]: 	Test 900/1152. loss: 3.197, 0.1049 s / batch. (data: 8.34e-03)max mem: 17.22454 GB 
[09/19 00:29:25 visual_prompt]: 	Test 1000/1152. loss: 3.001, 0.1118 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 00:29:42 visual_prompt]: 	Test 1100/1152. loss: 3.436, 0.1118 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 00:29:54 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1085, average loss: 3.8669
[09/19 00:29:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.22	top5: 88.23	
[09/19 00:29:54 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/19 00:30:04 visual_prompt]: Epoch 96 / 100: avg data time: 2.41e-01, avg batch time: 0.4667, average train loss: 0.0649
[09/19 00:30:11 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.0900, average loss: 0.0701
[09/19 00:30:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 99.00	top5: 100.00	
[09/19 00:30:31 visual_prompt]: 	Test 100/1152. loss: 4.717, 0.0970 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 00:30:48 visual_prompt]: 	Test 200/1152. loss: 4.157, 0.1398 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 00:31:04 visual_prompt]: 	Test 300/1152. loss: 4.151, 0.1149 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 00:31:20 visual_prompt]: 	Test 400/1152. loss: 4.235, 0.1157 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 00:31:36 visual_prompt]: 	Test 500/1152. loss: 4.152, 0.1171 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 00:31:52 visual_prompt]: 	Test 600/1152. loss: 3.559, 0.0997 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:32:08 visual_prompt]: 	Test 700/1152. loss: 2.803, 0.1173 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:32:25 visual_prompt]: 	Test 800/1152. loss: 3.981, 0.1046 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 00:32:41 visual_prompt]: 	Test 900/1152. loss: 3.053, 0.0963 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/19 00:32:57 visual_prompt]: 	Test 1000/1152. loss: 3.091, 0.0988 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 00:33:13 visual_prompt]: 	Test 1100/1152. loss: 3.476, 0.1169 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:33:25 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1086, average loss: 3.8375
[09/19 00:33:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.46	top5: 88.42	
[09/19 00:33:26 visual_prompt]: Best epoch 96: best metric: 0.990
[09/19 00:33:26 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/19 00:33:36 visual_prompt]: Epoch 97 / 100: avg data time: 2.30e-01, avg batch time: 0.4539, average train loss: 0.0586
[09/19 00:33:43 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.0865, average loss: 0.0692
[09/19 00:33:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 98.50	top5: 100.00	
[09/19 00:34:02 visual_prompt]: 	Test 100/1152. loss: 4.667, 0.1198 s / batch. (data: 9.16e-05)max mem: 17.22454 GB 
[09/19 00:34:19 visual_prompt]: 	Test 200/1152. loss: 4.187, 0.0958 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 00:34:35 visual_prompt]: 	Test 300/1152. loss: 4.129, 0.1439 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 00:34:51 visual_prompt]: 	Test 400/1152. loss: 4.233, 0.1476 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 00:35:07 visual_prompt]: 	Test 500/1152. loss: 4.165, 0.1120 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 00:35:24 visual_prompt]: 	Test 600/1152. loss: 3.565, 0.0945 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 00:35:40 visual_prompt]: 	Test 700/1152. loss: 2.827, 0.1028 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 00:35:56 visual_prompt]: 	Test 800/1152. loss: 3.979, 0.0961 s / batch. (data: 9.85e-05)max mem: 17.22454 GB 
[09/19 00:36:12 visual_prompt]: 	Test 900/1152. loss: 3.066, 0.1078 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 00:36:28 visual_prompt]: 	Test 1000/1152. loss: 3.091, 0.1205 s / batch. (data: 1.78e-04)max mem: 17.22454 GB 
[09/19 00:36:44 visual_prompt]: 	Test 1100/1152. loss: 3.500, 0.1182 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/19 00:36:56 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1091, average loss: 3.8530
[09/19 00:36:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.48	top5: 88.37	
[09/19 00:36:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/19 00:37:07 visual_prompt]: Epoch 98 / 100: avg data time: 2.25e-01, avg batch time: 0.4518, average train loss: 0.0530
[09/19 00:37:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0885, average loss: 0.0768
[09/19 00:37:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 98.50	top5: 100.00	
[09/19 00:37:34 visual_prompt]: 	Test 100/1152. loss: 4.643, 0.0974 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:37:50 visual_prompt]: 	Test 200/1152. loss: 4.225, 0.1503 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 00:38:06 visual_prompt]: 	Test 300/1152. loss: 4.082, 0.1457 s / batch. (data: 2.87e-02)max mem: 17.22454 GB 
[09/19 00:38:22 visual_prompt]: 	Test 400/1152. loss: 4.246, 0.1292 s / batch. (data: 1.92e-04)max mem: 17.22454 GB 
[09/19 00:38:38 visual_prompt]: 	Test 500/1152. loss: 4.202, 0.0975 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 00:38:55 visual_prompt]: 	Test 600/1152. loss: 3.562, 0.1067 s / batch. (data: 2.02e-04)max mem: 17.22454 GB 
[09/19 00:39:11 visual_prompt]: 	Test 700/1152. loss: 2.832, 0.1125 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 00:39:27 visual_prompt]: 	Test 800/1152. loss: 3.964, 0.1451 s / batch. (data: 4.17e-05)max mem: 17.22454 GB 
[09/19 00:39:43 visual_prompt]: 	Test 900/1152. loss: 3.119, 0.1326 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 00:39:59 visual_prompt]: 	Test 1000/1152. loss: 3.076, 0.1157 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 00:40:16 visual_prompt]: 	Test 1100/1152. loss: 3.475, 0.0994 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 00:40:28 visual_prompt]: Inference (test):avg data time: 2.13e-03, avg batch time: 0.1092, average loss: 3.8663
[09/19 00:40:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.26	top5: 88.24	
[09/19 00:40:28 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/19 00:40:39 visual_prompt]: Epoch 99 / 100: avg data time: 2.34e-01, avg batch time: 0.4572, average train loss: 0.0567
[09/19 00:40:46 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.0976, average loss: 0.0754
[09/19 00:40:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 98.50	top5: 100.00	
[09/19 00:41:05 visual_prompt]: 	Test 100/1152. loss: 4.643, 0.0973 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 00:41:21 visual_prompt]: 	Test 200/1152. loss: 4.218, 0.1015 s / batch. (data: 4.20e-05)max mem: 17.22454 GB 
[09/19 00:41:38 visual_prompt]: 	Test 300/1152. loss: 4.087, 0.1111 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 00:41:54 visual_prompt]: 	Test 400/1152. loss: 4.252, 0.0980 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 00:42:10 visual_prompt]: 	Test 500/1152. loss: 4.189, 0.0965 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 00:42:26 visual_prompt]: 	Test 600/1152. loss: 3.566, 0.1278 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 00:42:43 visual_prompt]: 	Test 700/1152. loss: 2.842, 0.1387 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 00:42:59 visual_prompt]: 	Test 800/1152. loss: 3.951, 0.1464 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 00:43:15 visual_prompt]: 	Test 900/1152. loss: 3.128, 0.1003 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 00:43:32 visual_prompt]: 	Test 1000/1152. loss: 3.062, 0.1048 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/19 00:43:48 visual_prompt]: 	Test 1100/1152. loss: 3.476, 0.0987 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 00:44:01 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1091, average loss: 3.8656
[09/19 00:44:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.28	top5: 88.25	
[09/19 00:44:01 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/19 00:44:11 visual_prompt]: Epoch 100 / 100: avg data time: 2.24e-01, avg batch time: 0.4465, average train loss: 0.0576
[09/19 00:44:18 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.0867, average loss: 0.0747
[09/19 00:44:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 98.50	top5: 100.00	
[09/19 00:44:38 visual_prompt]: 	Test 100/1152. loss: 4.646, 0.1498 s / batch. (data: 1.60e-02)max mem: 17.22454 GB 
[09/19 00:44:54 visual_prompt]: 	Test 200/1152. loss: 4.216, 0.1025 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 00:45:10 visual_prompt]: 	Test 300/1152. loss: 4.083, 0.1206 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 00:45:27 visual_prompt]: 	Test 400/1152. loss: 4.250, 0.0956 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 00:45:43 visual_prompt]: 	Test 500/1152. loss: 4.195, 0.1080 s / batch. (data: 3.18e-03)max mem: 17.22454 GB 
[09/19 00:45:59 visual_prompt]: 	Test 600/1152. loss: 3.563, 0.1306 s / batch. (data: 2.20e-02)max mem: 17.22454 GB 
[09/19 00:46:15 visual_prompt]: 	Test 700/1152. loss: 2.840, 0.1111 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 00:46:31 visual_prompt]: 	Test 800/1152. loss: 3.955, 0.1001 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 00:46:47 visual_prompt]: 	Test 900/1152. loss: 3.125, 0.1002 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 00:47:03 visual_prompt]: 	Test 1000/1152. loss: 3.065, 0.1078 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 00:47:19 visual_prompt]: 	Test 1100/1152. loss: 3.478, 0.1039 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 00:47:31 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1093, average loss: 3.8648
[09/19 00:47:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.31	top5: 88.26	
[09/19 00:48:11 visual_prompt]: Rank of current process: 0. World size: 1
[09/19 00:48:11 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/19 00:48:11 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/19 00:48:11 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/19 00:48:11 visual_prompt]: Training with config:
[09/19 00:48:11 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/19 00:48:11 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-19 00:48:12.000349: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-19 00:48:12.167026: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-19 00:48:18.177074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 00:48:18.177159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 00:48:18.177168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-19 00:48:26.872352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 00:48:26.872576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 00:48:26.872605: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/19 00:48:26 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-19 00:48:26.987548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 00:48:28 visual_prompt]: Number of images: 1000
[09/19 00:48:28 visual_prompt]: Number of classes: 16 / 16
[09/19 00:48:28 visual_prompt]: Loading validation data...
[09/19 00:48:28 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 00:48:29 visual_prompt]: Number of images: 200
[09/19 00:48:29 visual_prompt]: Number of classes: 16 / 16
[09/19 00:48:29 visual_prompt]: Loading test data...
[09/19 00:48:29 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 00:49:58 visual_prompt]: Number of images: 73728
[09/19 00:49:58 visual_prompt]: Number of classes: 16 / 16
[09/19 00:49:59 visual_prompt]: Constructing models...
[09/19 00:50:02 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/19 00:50:02 visual_prompt]: tuned percent:1.077
[09/19 00:50:05 visual_prompt]: Device used for model: 0
[09/19 00:50:05 visual_prompt]: Setting up Evalutator...
[09/19 00:50:05 visual_prompt]: Setting up Trainer...
[09/19 00:50:05 visual_prompt]: 	Setting up the optimizer...
[09/19 00:50:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/19 00:50:17 visual_prompt]: Epoch 1 / 100: avg data time: 2.80e-01, avg batch time: 0.5772, average train loss: 2.9520
[09/19 00:50:24 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.0927, average loss: 3.0447
[09/19 00:50:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 3.50	top5: 31.00	
[09/19 00:50:44 visual_prompt]: 	Test 100/1152. loss: 3.145, 0.1174 s / batch. (data: 1.28e-02)max mem: 17.22454 GB 
[09/19 00:51:01 visual_prompt]: 	Test 200/1152. loss: 3.170, 0.1837 s / batch. (data: 7.04e-03)max mem: 17.22454 GB 
[09/19 00:51:17 visual_prompt]: 	Test 300/1152. loss: 2.980, 0.1141 s / batch. (data: 3.93e-05)max mem: 17.22454 GB 
[09/19 00:51:34 visual_prompt]: 	Test 400/1152. loss: 2.976, 0.1037 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 00:51:50 visual_prompt]: 	Test 500/1152. loss: 2.941, 0.1009 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 00:52:06 visual_prompt]: 	Test 600/1152. loss: 2.943, 0.1102 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 00:52:23 visual_prompt]: 	Test 700/1152. loss: 2.835, 0.1030 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 00:52:39 visual_prompt]: 	Test 800/1152. loss: 2.878, 0.1039 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:52:55 visual_prompt]: 	Test 900/1152. loss: 3.084, 0.0989 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 00:53:11 visual_prompt]: 	Test 1000/1152. loss: 2.986, 0.1000 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 00:53:28 visual_prompt]: 	Test 1100/1152. loss: 3.034, 0.1069 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 00:53:40 visual_prompt]: Inference (test):avg data time: 2.27e-03, avg batch time: 0.1098, average loss: 2.9710
[09/19 00:53:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.12	top5: 33.03	
[09/19 00:53:40 visual_prompt]: Best epoch 1: best metric: 0.035
[09/19 00:53:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/19 00:53:51 visual_prompt]: Epoch 2 / 100: avg data time: 2.35e-01, avg batch time: 0.4743, average train loss: 3.0732
[09/19 00:53:58 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.0902, average loss: 2.8639
[09/19 00:53:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 30.50	
[09/19 00:54:18 visual_prompt]: 	Test 100/1152. loss: 2.982, 0.1037 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 00:54:34 visual_prompt]: 	Test 200/1152. loss: 2.936, 0.0957 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 00:54:51 visual_prompt]: 	Test 300/1152. loss: 2.844, 0.0960 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 00:55:07 visual_prompt]: 	Test 400/1152. loss: 2.930, 0.1227 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:55:24 visual_prompt]: 	Test 500/1152. loss: 2.974, 0.0980 s / batch. (data: 2.17e-04)max mem: 17.22454 GB 
[09/19 00:55:40 visual_prompt]: 	Test 600/1152. loss: 2.932, 0.1247 s / batch. (data: 7.05e-03)max mem: 17.22454 GB 
[09/19 00:55:56 visual_prompt]: 	Test 700/1152. loss: 2.813, 0.0971 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/19 00:56:12 visual_prompt]: 	Test 800/1152. loss: 2.875, 0.1318 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 00:56:28 visual_prompt]: 	Test 900/1152. loss: 2.893, 0.0962 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 00:56:44 visual_prompt]: 	Test 1000/1152. loss: 2.881, 0.1028 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 00:57:01 visual_prompt]: 	Test 1100/1152. loss: 2.861, 0.0943 s / batch. (data: 8.25e-05)max mem: 17.22454 GB 
[09/19 00:57:13 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1082, average loss: 2.8920
[09/19 00:57:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 32.39	
[09/19 00:57:13 visual_prompt]: Best epoch 2: best metric: 0.050
[09/19 00:57:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/19 00:57:24 visual_prompt]: Epoch 3 / 100: avg data time: 2.24e-01, avg batch time: 0.4505, average train loss: 2.9479
[09/19 00:57:31 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.0954, average loss: 2.9092
[09/19 00:57:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 36.00	
[09/19 00:57:51 visual_prompt]: 	Test 100/1152. loss: 2.962, 0.1181 s / batch. (data: 1.45e-05)max mem: 17.22454 GB 
[09/19 00:58:08 visual_prompt]: 	Test 200/1152. loss: 2.869, 0.1302 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 00:58:24 visual_prompt]: 	Test 300/1152. loss: 3.033, 0.1262 s / batch. (data: 2.07e-04)max mem: 17.22454 GB 
[09/19 00:58:40 visual_prompt]: 	Test 400/1152. loss: 3.060, 0.1081 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 00:58:57 visual_prompt]: 	Test 500/1152. loss: 2.922, 0.0953 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 00:59:13 visual_prompt]: 	Test 600/1152. loss: 3.084, 0.1031 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 00:59:29 visual_prompt]: 	Test 700/1152. loss: 3.074, 0.0966 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 00:59:45 visual_prompt]: 	Test 800/1152. loss: 3.003, 0.1049 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 01:00:01 visual_prompt]: 	Test 900/1152. loss: 3.104, 0.0962 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 01:00:17 visual_prompt]: 	Test 1000/1152. loss: 3.037, 0.1179 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 01:00:33 visual_prompt]: 	Test 1100/1152. loss: 2.903, 0.1128 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 01:00:45 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1088, average loss: 2.9593
[09/19 01:00:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 35.07	
[09/19 01:00:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/19 01:00:56 visual_prompt]: Epoch 4 / 100: avg data time: 2.30e-01, avg batch time: 0.4602, average train loss: 2.9618
[09/19 01:01:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.0864, average loss: 2.9544
[09/19 01:01:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 39.50	
[09/19 01:01:24 visual_prompt]: 	Test 100/1152. loss: 2.899, 0.0958 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 01:01:41 visual_prompt]: 	Test 200/1152. loss: 2.931, 0.1316 s / batch. (data: 4.25e-03)max mem: 17.22454 GB 
[09/19 01:01:57 visual_prompt]: 	Test 300/1152. loss: 2.730, 0.1054 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 01:02:13 visual_prompt]: 	Test 400/1152. loss: 2.828, 0.1210 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 01:02:30 visual_prompt]: 	Test 500/1152. loss: 2.880, 0.1000 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 01:02:46 visual_prompt]: 	Test 600/1152. loss: 2.841, 0.1161 s / batch. (data: 7.15e-05)max mem: 17.22454 GB 
[09/19 01:03:03 visual_prompt]: 	Test 700/1152. loss: 2.856, 0.0983 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/19 01:03:19 visual_prompt]: 	Test 800/1152. loss: 2.827, 0.1161 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 01:03:35 visual_prompt]: 	Test 900/1152. loss: 2.947, 0.0999 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 01:03:51 visual_prompt]: 	Test 1000/1152. loss: 2.888, 0.1301 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 01:04:07 visual_prompt]: 	Test 1100/1152. loss: 3.071, 0.1147 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 01:04:19 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1094, average loss: 2.9205
[09/19 01:04:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.24	
[09/19 01:04:19 visual_prompt]: Best epoch 4: best metric: 0.090
[09/19 01:04:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/19 01:04:30 visual_prompt]: Epoch 5 / 100: avg data time: 2.31e-01, avg batch time: 0.4598, average train loss: 3.0981
[09/19 01:04:37 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.0971, average loss: 3.1412
[09/19 01:04:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 38.00	
[09/19 01:04:57 visual_prompt]: 	Test 100/1152. loss: 3.097, 0.1039 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 01:05:13 visual_prompt]: 	Test 200/1152. loss: 3.277, 0.1100 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 01:05:30 visual_prompt]: 	Test 300/1152. loss: 3.108, 0.1038 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:05:46 visual_prompt]: 	Test 400/1152. loss: 3.231, 0.1119 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:06:02 visual_prompt]: 	Test 500/1152. loss: 3.136, 0.1139 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 01:06:18 visual_prompt]: 	Test 600/1152. loss: 3.002, 0.1037 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 01:06:35 visual_prompt]: 	Test 700/1152. loss: 3.271, 0.1004 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 01:06:50 visual_prompt]: 	Test 800/1152. loss: 3.140, 0.1040 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 01:07:07 visual_prompt]: 	Test 900/1152. loss: 2.992, 0.0999 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 01:07:23 visual_prompt]: 	Test 1000/1152. loss: 3.271, 0.1067 s / batch. (data: 5.92e-03)max mem: 17.22454 GB 
[09/19 01:07:39 visual_prompt]: 	Test 1100/1152. loss: 3.087, 0.1026 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 01:07:51 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1087, average loss: 3.1820
[09/19 01:07:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.43	
[09/19 01:07:51 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/19 01:08:02 visual_prompt]: Epoch 6 / 100: avg data time: 2.27e-01, avg batch time: 0.4603, average train loss: 3.2694
[09/19 01:08:09 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.0957, average loss: 3.0940
[09/19 01:08:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 38.00	
[09/19 01:08:29 visual_prompt]: 	Test 100/1152. loss: 3.096, 0.0954 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/19 01:08:46 visual_prompt]: 	Test 200/1152. loss: 3.186, 0.1277 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 01:09:02 visual_prompt]: 	Test 300/1152. loss: 3.055, 0.1078 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 01:09:19 visual_prompt]: 	Test 400/1152. loss: 3.039, 0.1043 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/19 01:09:35 visual_prompt]: 	Test 500/1152. loss: 3.069, 0.1030 s / batch. (data: 7.19e-03)max mem: 17.22454 GB 
[09/19 01:09:51 visual_prompt]: 	Test 600/1152. loss: 3.056, 0.1157 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 01:10:08 visual_prompt]: 	Test 700/1152. loss: 3.030, 0.0960 s / batch. (data: 3.36e-05)max mem: 17.22454 GB 
[09/19 01:10:24 visual_prompt]: 	Test 800/1152. loss: 3.088, 0.1319 s / batch. (data: 4.86e-05)max mem: 17.22454 GB 
[09/19 01:10:41 visual_prompt]: 	Test 900/1152. loss: 3.088, 0.1013 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 01:10:57 visual_prompt]: 	Test 1000/1152. loss: 3.063, 0.1235 s / batch. (data: 8.47e-03)max mem: 17.22454 GB 
[09/19 01:11:13 visual_prompt]: 	Test 1100/1152. loss: 3.177, 0.1028 s / batch. (data: 6.58e-03)max mem: 17.22454 GB 
[09/19 01:11:25 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1086, average loss: 3.1031
[09/19 01:11:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 34.91	
[09/19 01:11:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/19 01:11:36 visual_prompt]: Epoch 7 / 100: avg data time: 2.33e-01, avg batch time: 0.4622, average train loss: 3.1407
[09/19 01:11:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.0946, average loss: 3.0020
[09/19 01:11:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 35.00	
[09/19 01:12:03 visual_prompt]: 	Test 100/1152. loss: 3.057, 0.1096 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 01:12:20 visual_prompt]: 	Test 200/1152. loss: 3.288, 0.1023 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 01:12:36 visual_prompt]: 	Test 300/1152. loss: 3.003, 0.0939 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/19 01:12:53 visual_prompt]: 	Test 400/1152. loss: 3.070, 0.1038 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 01:13:09 visual_prompt]: 	Test 500/1152. loss: 3.065, 0.1119 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 01:13:25 visual_prompt]: 	Test 600/1152. loss: 2.959, 0.1000 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 01:13:41 visual_prompt]: 	Test 700/1152. loss: 2.980, 0.1190 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 01:13:58 visual_prompt]: 	Test 800/1152. loss: 3.114, 0.0987 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 01:14:14 visual_prompt]: 	Test 900/1152. loss: 2.876, 0.1321 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 01:14:30 visual_prompt]: 	Test 1000/1152. loss: 3.060, 0.0987 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 01:14:46 visual_prompt]: 	Test 1100/1152. loss: 3.091, 0.1181 s / batch. (data: 1.96e-04)max mem: 17.22454 GB 
[09/19 01:14:59 visual_prompt]: Inference (test):avg data time: 1.83e-03, avg batch time: 0.1093, average loss: 3.0644
[09/19 01:14:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.60	
[09/19 01:14:59 visual_prompt]: Best epoch 7: best metric: 0.115
[09/19 01:14:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/19 01:15:09 visual_prompt]: Epoch 8 / 100: avg data time: 2.32e-01, avg batch time: 0.4590, average train loss: 3.1371
[09/19 01:15:16 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0900, average loss: 3.0404
[09/19 01:15:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 35.50	
[09/19 01:15:37 visual_prompt]: 	Test 100/1152. loss: 2.851, 0.0987 s / batch. (data: 1.87e-04)max mem: 17.22454 GB 
[09/19 01:15:54 visual_prompt]: 	Test 200/1152. loss: 2.897, 0.1208 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/19 01:16:10 visual_prompt]: 	Test 300/1152. loss: 3.057, 0.1197 s / batch. (data: 1.98e-04)max mem: 17.22454 GB 
[09/19 01:16:26 visual_prompt]: 	Test 400/1152. loss: 2.959, 0.1198 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 01:16:43 visual_prompt]: 	Test 500/1152. loss: 3.015, 0.1097 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 01:16:59 visual_prompt]: 	Test 600/1152. loss: 2.953, 0.1064 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 01:17:15 visual_prompt]: 	Test 700/1152. loss: 3.035, 0.1078 s / batch. (data: 1.78e-04)max mem: 17.22454 GB 
[09/19 01:17:31 visual_prompt]: 	Test 800/1152. loss: 2.982, 0.1198 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 01:17:47 visual_prompt]: 	Test 900/1152. loss: 2.908, 0.1025 s / batch. (data: 1.88e-04)max mem: 17.22454 GB 
[09/19 01:18:03 visual_prompt]: 	Test 1000/1152. loss: 2.888, 0.1079 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 01:18:19 visual_prompt]: 	Test 1100/1152. loss: 2.987, 0.1360 s / batch. (data: 3.91e-05)max mem: 17.22454 GB 
[09/19 01:18:32 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1085, average loss: 3.0181
[09/19 01:18:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 29.91	
[09/19 01:18:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/19 01:18:42 visual_prompt]: Epoch 9 / 100: avg data time: 2.29e-01, avg batch time: 0.4568, average train loss: 3.2733
[09/19 01:18:49 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0943, average loss: 3.3116
[09/19 01:18:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 39.00	
[09/19 01:19:10 visual_prompt]: 	Test 100/1152. loss: 3.423, 0.1195 s / batch. (data: 4.32e-03)max mem: 17.22454 GB 
[09/19 01:19:26 visual_prompt]: 	Test 200/1152. loss: 3.446, 0.1439 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 01:19:43 visual_prompt]: 	Test 300/1152. loss: 3.230, 0.1379 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 01:19:59 visual_prompt]: 	Test 400/1152. loss: 3.327, 0.1069 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 01:20:16 visual_prompt]: 	Test 500/1152. loss: 3.170, 0.0988 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 01:20:32 visual_prompt]: 	Test 600/1152. loss: 3.136, 0.1158 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 01:20:48 visual_prompt]: 	Test 700/1152. loss: 3.032, 0.1119 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 01:21:05 visual_prompt]: 	Test 800/1152. loss: 3.198, 0.0957 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 01:21:21 visual_prompt]: 	Test 900/1152. loss: 3.366, 0.1157 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 01:21:37 visual_prompt]: 	Test 1000/1152. loss: 3.260, 0.1039 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 01:21:53 visual_prompt]: 	Test 1100/1152. loss: 3.285, 0.1065 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 01:22:05 visual_prompt]: Inference (test):avg data time: 2.31e-03, avg batch time: 0.1093, average loss: 3.2774
[09/19 01:22:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 37.50	
[09/19 01:22:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/19 01:22:16 visual_prompt]: Epoch 10 / 100: avg data time: 2.37e-01, avg batch time: 0.4606, average train loss: 3.2953
[09/19 01:22:22 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0945, average loss: 3.1400
[09/19 01:22:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 37.00	
[09/19 01:22:43 visual_prompt]: 	Test 100/1152. loss: 3.186, 0.0972 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 01:22:59 visual_prompt]: 	Test 200/1152. loss: 3.231, 0.0989 s / batch. (data: 3.98e-05)max mem: 17.22454 GB 
[09/19 01:23:16 visual_prompt]: 	Test 300/1152. loss: 3.191, 0.0992 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:23:32 visual_prompt]: 	Test 400/1152. loss: 3.317, 0.1318 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:23:49 visual_prompt]: 	Test 500/1152. loss: 3.179, 0.1093 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 01:24:05 visual_prompt]: 	Test 600/1152. loss: 3.109, 0.1072 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:24:21 visual_prompt]: 	Test 700/1152. loss: 3.312, 0.1038 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 01:24:37 visual_prompt]: 	Test 800/1152. loss: 3.329, 0.0963 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 01:24:53 visual_prompt]: 	Test 900/1152. loss: 3.205, 0.1280 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 01:25:09 visual_prompt]: 	Test 1000/1152. loss: 3.411, 0.0974 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 01:25:26 visual_prompt]: 	Test 1100/1152. loss: 3.140, 0.0945 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 01:25:39 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1085, average loss: 3.2237
[09/19 01:25:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 32.45	
[09/19 01:25:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/19 01:25:49 visual_prompt]: Epoch 11 / 100: avg data time: 2.33e-01, avg batch time: 0.4590, average train loss: 3.0981
[09/19 01:25:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0889, average loss: 3.0218
[09/19 01:25:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 34.50	
[09/19 01:26:16 visual_prompt]: 	Test 100/1152. loss: 3.120, 0.0998 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 01:26:33 visual_prompt]: 	Test 200/1152. loss: 3.222, 0.0988 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 01:26:49 visual_prompt]: 	Test 300/1152. loss: 2.964, 0.1393 s / batch. (data: 4.27e-05)max mem: 17.22454 GB 
[09/19 01:27:06 visual_prompt]: 	Test 400/1152. loss: 3.131, 0.0966 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 01:27:23 visual_prompt]: 	Test 500/1152. loss: 3.105, 0.0982 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 01:27:39 visual_prompt]: 	Test 600/1152. loss: 3.268, 0.1046 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 01:27:56 visual_prompt]: 	Test 700/1152. loss: 3.126, 0.1276 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 01:28:12 visual_prompt]: 	Test 800/1152. loss: 3.003, 0.0991 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:28:28 visual_prompt]: 	Test 900/1152. loss: 3.180, 0.0984 s / batch. (data: 1.76e-04)max mem: 17.22454 GB 
[09/19 01:28:44 visual_prompt]: 	Test 1000/1152. loss: 3.091, 0.0984 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 01:29:01 visual_prompt]: 	Test 1100/1152. loss: 3.242, 0.1149 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/19 01:29:13 visual_prompt]: Inference (test):avg data time: 2.14e-03, avg batch time: 0.1087, average loss: 3.0907
[09/19 01:29:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 32.41	
[09/19 01:29:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/19 01:29:24 visual_prompt]: Epoch 12 / 100: avg data time: 2.41e-01, avg batch time: 0.4686, average train loss: 2.9904
[09/19 01:29:31 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0880, average loss: 3.3729
[09/19 01:29:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.00	top5: 32.00	
[09/19 01:29:51 visual_prompt]: 	Test 100/1152. loss: 3.708, 0.0998 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 01:30:08 visual_prompt]: 	Test 200/1152. loss: 3.258, 0.1119 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 01:30:24 visual_prompt]: 	Test 300/1152. loss: 3.473, 0.1135 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 01:30:41 visual_prompt]: 	Test 400/1152. loss: 3.413, 0.0965 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 01:30:57 visual_prompt]: 	Test 500/1152. loss: 3.597, 0.1313 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 01:31:13 visual_prompt]: 	Test 600/1152. loss: 3.258, 0.0973 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 01:31:30 visual_prompt]: 	Test 700/1152. loss: 3.018, 0.1078 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 01:31:46 visual_prompt]: 	Test 800/1152. loss: 3.451, 0.1188 s / batch. (data: 7.34e-05)max mem: 17.22454 GB 
[09/19 01:32:02 visual_prompt]: 	Test 900/1152. loss: 3.380, 0.1079 s / batch. (data: 8.24e-03)max mem: 17.22454 GB 
[09/19 01:32:18 visual_prompt]: 	Test 1000/1152. loss: 3.523, 0.1418 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 01:32:35 visual_prompt]: 	Test 1100/1152. loss: 3.364, 0.0994 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 01:32:47 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1093, average loss: 3.4137
[09/19 01:32:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.87	top5: 32.39	
[09/19 01:32:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/19 01:32:58 visual_prompt]: Epoch 13 / 100: avg data time: 2.40e-01, avg batch time: 0.4701, average train loss: 3.1403
[09/19 01:33:05 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.0908, average loss: 3.1950
[09/19 01:33:05 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 32.50	
[09/19 01:33:25 visual_prompt]: 	Test 100/1152. loss: 3.088, 0.0966 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 01:33:42 visual_prompt]: 	Test 200/1152. loss: 3.191, 0.0998 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 01:33:58 visual_prompt]: 	Test 300/1152. loss: 3.192, 0.1240 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 01:34:15 visual_prompt]: 	Test 400/1152. loss: 3.301, 0.1052 s / batch. (data: 7.17e-03)max mem: 17.22454 GB 
[09/19 01:34:31 visual_prompt]: 	Test 500/1152. loss: 3.153, 0.1199 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 01:34:47 visual_prompt]: 	Test 600/1152. loss: 3.066, 0.1266 s / batch. (data: 1.00e-02)max mem: 17.22454 GB 
[09/19 01:35:04 visual_prompt]: 	Test 700/1152. loss: 3.327, 0.1505 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 01:35:20 visual_prompt]: 	Test 800/1152. loss: 3.279, 0.1489 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 01:35:36 visual_prompt]: 	Test 900/1152. loss: 3.003, 0.1400 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/19 01:35:52 visual_prompt]: 	Test 1000/1152. loss: 3.088, 0.1120 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 01:36:08 visual_prompt]: 	Test 1100/1152. loss: 3.249, 0.0999 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 01:36:21 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1089, average loss: 3.2170
[09/19 01:36:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 30.01	
[09/19 01:36:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/19 01:36:32 visual_prompt]: Epoch 14 / 100: avg data time: 2.34e-01, avg batch time: 0.4557, average train loss: 3.1172
[09/19 01:36:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.0905, average loss: 3.1672
[09/19 01:36:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 33.50	
[09/19 01:36:59 visual_prompt]: 	Test 100/1152. loss: 3.219, 0.1068 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 01:37:15 visual_prompt]: 	Test 200/1152. loss: 3.139, 0.1170 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 01:37:32 visual_prompt]: 	Test 300/1152. loss: 3.217, 0.1042 s / batch. (data: 7.17e-03)max mem: 17.22454 GB 
[09/19 01:37:48 visual_prompt]: 	Test 400/1152. loss: 3.215, 0.1068 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 01:38:05 visual_prompt]: 	Test 500/1152. loss: 2.966, 0.1377 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 01:38:21 visual_prompt]: 	Test 600/1152. loss: 3.125, 0.1033 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 01:38:37 visual_prompt]: 	Test 700/1152. loss: 3.178, 0.0966 s / batch. (data: 1.97e-04)max mem: 17.22454 GB 
[09/19 01:38:53 visual_prompt]: 	Test 800/1152. loss: 2.976, 0.1160 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 01:39:10 visual_prompt]: 	Test 900/1152. loss: 3.297, 0.1118 s / batch. (data: 6.05e-03)max mem: 17.22454 GB 
[09/19 01:39:26 visual_prompt]: 	Test 1000/1152. loss: 3.106, 0.0984 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 01:39:42 visual_prompt]: 	Test 1100/1152. loss: 3.225, 0.1078 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 01:39:55 visual_prompt]: Inference (test):avg data time: 2.21e-03, avg batch time: 0.1091, average loss: 3.1348
[09/19 01:39:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.88	
[09/19 01:39:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/19 01:40:05 visual_prompt]: Epoch 15 / 100: avg data time: 2.29e-01, avg batch time: 0.4595, average train loss: 3.0328
[09/19 01:40:13 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.0872, average loss: 2.8751
[09/19 01:40:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 38.50	
[09/19 01:40:33 visual_prompt]: 	Test 100/1152. loss: 2.912, 0.1382 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/19 01:40:49 visual_prompt]: 	Test 200/1152. loss: 2.974, 0.1272 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 01:41:06 visual_prompt]: 	Test 300/1152. loss: 3.033, 0.1073 s / batch. (data: 6.99e-05)max mem: 17.22454 GB 
[09/19 01:41:22 visual_prompt]: 	Test 400/1152. loss: 2.850, 0.0946 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 01:41:38 visual_prompt]: 	Test 500/1152. loss: 2.983, 0.1171 s / batch. (data: 8.47e-03)max mem: 17.22454 GB 
[09/19 01:41:55 visual_prompt]: 	Test 600/1152. loss: 3.146, 0.1187 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 01:42:11 visual_prompt]: 	Test 700/1152. loss: 2.892, 0.1246 s / batch. (data: 4.94e-05)max mem: 17.22454 GB 
[09/19 01:42:27 visual_prompt]: 	Test 800/1152. loss: 2.972, 0.1119 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 01:42:43 visual_prompt]: 	Test 900/1152. loss: 2.952, 0.1478 s / batch. (data: 1.81e-04)max mem: 17.22454 GB 
[09/19 01:42:59 visual_prompt]: 	Test 1000/1152. loss: 2.921, 0.1602 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 01:43:15 visual_prompt]: 	Test 1100/1152. loss: 2.995, 0.1117 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 01:43:27 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1092, average loss: 2.9358
[09/19 01:43:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 34.92	
[09/19 01:43:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/19 01:43:38 visual_prompt]: Epoch 16 / 100: avg data time: 2.34e-01, avg batch time: 0.4635, average train loss: 2.9901
[09/19 01:43:45 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.0907, average loss: 3.1030
[09/19 01:43:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 41.00	
[09/19 01:44:05 visual_prompt]: 	Test 100/1152. loss: 3.230, 0.0961 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 01:44:21 visual_prompt]: 	Test 200/1152. loss: 3.070, 0.0999 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 01:44:37 visual_prompt]: 	Test 300/1152. loss: 3.197, 0.1039 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 01:44:54 visual_prompt]: 	Test 400/1152. loss: 3.103, 0.0987 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 01:45:10 visual_prompt]: 	Test 500/1152. loss: 3.022, 0.1060 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 01:45:26 visual_prompt]: 	Test 600/1152. loss: 3.210, 0.1126 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 01:45:42 visual_prompt]: 	Test 700/1152. loss: 3.067, 0.1227 s / batch. (data: 5.63e-03)max mem: 17.22454 GB 
[09/19 01:45:59 visual_prompt]: 	Test 800/1152. loss: 3.033, 0.0970 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 01:46:15 visual_prompt]: 	Test 900/1152. loss: 3.324, 0.0991 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 01:46:31 visual_prompt]: 	Test 1000/1152. loss: 3.116, 0.1143 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 01:46:47 visual_prompt]: 	Test 1100/1152. loss: 3.223, 0.1160 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 01:46:59 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1086, average loss: 3.1202
[09/19 01:46:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 37.48	
[09/19 01:46:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/19 01:47:10 visual_prompt]: Epoch 17 / 100: avg data time: 2.35e-01, avg batch time: 0.4588, average train loss: 3.0532
[09/19 01:47:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0861, average loss: 3.1353
[09/19 01:47:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 25.50	
[09/19 01:47:37 visual_prompt]: 	Test 100/1152. loss: 2.919, 0.1019 s / batch. (data: 1.41e-05)max mem: 17.22454 GB 
[09/19 01:47:54 visual_prompt]: 	Test 200/1152. loss: 3.230, 0.1136 s / batch. (data: 6.71e-03)max mem: 17.22454 GB 
[09/19 01:48:10 visual_prompt]: 	Test 300/1152. loss: 2.884, 0.0999 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 01:48:26 visual_prompt]: 	Test 400/1152. loss: 2.974, 0.1044 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 01:48:43 visual_prompt]: 	Test 500/1152. loss: 2.962, 0.1106 s / batch. (data: 3.22e-05)max mem: 17.22454 GB 
[09/19 01:48:59 visual_prompt]: 	Test 600/1152. loss: 2.945, 0.1056 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 01:49:15 visual_prompt]: 	Test 700/1152. loss: 3.014, 0.0974 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 01:49:31 visual_prompt]: 	Test 800/1152. loss: 2.946, 0.1316 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 01:49:47 visual_prompt]: 	Test 900/1152. loss: 3.023, 0.1159 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 01:50:03 visual_prompt]: 	Test 1000/1152. loss: 2.968, 0.1398 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 01:50:20 visual_prompt]: 	Test 1100/1152. loss: 2.997, 0.0993 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 01:50:32 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1089, average loss: 3.0307
[09/19 01:50:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 29.90	
[09/19 01:50:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/19 01:50:43 visual_prompt]: Epoch 18 / 100: avg data time: 2.46e-01, avg batch time: 0.4701, average train loss: 2.9647
[09/19 01:50:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0865, average loss: 3.0124
[09/19 01:50:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 36.00	
[09/19 01:51:10 visual_prompt]: 	Test 100/1152. loss: 2.989, 0.0950 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 01:51:27 visual_prompt]: 	Test 200/1152. loss: 3.108, 0.1061 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 01:51:43 visual_prompt]: 	Test 300/1152. loss: 2.862, 0.1320 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 01:51:59 visual_prompt]: 	Test 400/1152. loss: 2.997, 0.0951 s / batch. (data: 9.70e-05)max mem: 17.22454 GB 
[09/19 01:52:16 visual_prompt]: 	Test 500/1152. loss: 3.022, 0.0946 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 01:52:32 visual_prompt]: 	Test 600/1152. loss: 2.917, 0.0956 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 01:52:48 visual_prompt]: 	Test 700/1152. loss: 3.034, 0.0978 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 01:53:05 visual_prompt]: 	Test 800/1152. loss: 2.935, 0.1108 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 01:53:20 visual_prompt]: 	Test 900/1152. loss: 2.923, 0.1200 s / batch. (data: 2.34e-02)max mem: 17.22454 GB 
[09/19 01:53:36 visual_prompt]: 	Test 1000/1152. loss: 2.956, 0.1000 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 01:53:52 visual_prompt]: 	Test 1100/1152. loss: 2.964, 0.1224 s / batch. (data: 1.98e-04)max mem: 17.22454 GB 
[09/19 01:54:05 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1089, average loss: 2.9992
[09/19 01:54:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.06	
[09/19 01:54:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/19 01:54:15 visual_prompt]: Epoch 19 / 100: avg data time: 2.30e-01, avg batch time: 0.4634, average train loss: 3.1020
[09/19 01:54:22 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.0930, average loss: 3.1044
[09/19 01:54:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 30.00	
[09/19 01:54:42 visual_prompt]: 	Test 100/1152. loss: 3.077, 0.0961 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 01:54:59 visual_prompt]: 	Test 200/1152. loss: 3.173, 0.1032 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 01:55:15 visual_prompt]: 	Test 300/1152. loss: 3.030, 0.0992 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 01:55:32 visual_prompt]: 	Test 400/1152. loss: 2.997, 0.1280 s / batch. (data: 1.03e-05)max mem: 17.22454 GB 
[09/19 01:55:48 visual_prompt]: 	Test 500/1152. loss: 3.069, 0.1199 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 01:56:05 visual_prompt]: 	Test 600/1152. loss: 2.965, 0.1196 s / batch. (data: 8.11e-03)max mem: 17.22454 GB 
[09/19 01:56:21 visual_prompt]: 	Test 700/1152. loss: 2.872, 0.1120 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 01:56:36 visual_prompt]: 	Test 800/1152. loss: 3.056, 0.1038 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 01:56:53 visual_prompt]: 	Test 900/1152. loss: 2.977, 0.1002 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 01:57:09 visual_prompt]: 	Test 1000/1152. loss: 3.072, 0.1124 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 01:57:25 visual_prompt]: 	Test 1100/1152. loss: 3.223, 0.1200 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 01:57:37 visual_prompt]: Inference (test):avg data time: 2.18e-03, avg batch time: 0.1087, average loss: 3.0762
[09/19 01:57:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 32.59	
[09/19 01:57:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/19 01:57:48 visual_prompt]: Epoch 20 / 100: avg data time: 2.23e-01, avg batch time: 0.4557, average train loss: 3.0489
[09/19 01:57:55 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.0923, average loss: 2.9326
[09/19 01:57:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 34.50	
[09/19 01:58:15 visual_prompt]: 	Test 100/1152. loss: 2.930, 0.1061 s / batch. (data: 4.24e-05)max mem: 17.22454 GB 
[09/19 01:58:32 visual_prompt]: 	Test 200/1152. loss: 3.067, 0.1399 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 01:58:48 visual_prompt]: 	Test 300/1152. loss: 3.011, 0.1300 s / batch. (data: 1.34e-02)max mem: 17.22454 GB 
[09/19 01:59:04 visual_prompt]: 	Test 400/1152. loss: 2.951, 0.0991 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 01:59:21 visual_prompt]: 	Test 500/1152. loss: 2.918, 0.1158 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 01:59:37 visual_prompt]: 	Test 600/1152. loss: 2.964, 0.1007 s / batch. (data: 7.20e-05)max mem: 17.22454 GB 
[09/19 01:59:53 visual_prompt]: 	Test 700/1152. loss: 2.896, 0.0948 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 02:00:09 visual_prompt]: 	Test 800/1152. loss: 2.928, 0.0946 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 02:00:25 visual_prompt]: 	Test 900/1152. loss: 2.965, 0.0952 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 02:00:41 visual_prompt]: 	Test 1000/1152. loss: 2.949, 0.1159 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 02:00:57 visual_prompt]: 	Test 1100/1152. loss: 3.034, 0.1148 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 02:01:10 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1085, average loss: 2.9539
[09/19 02:01:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.08	
[09/19 02:01:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/19 02:01:20 visual_prompt]: Epoch 21 / 100: avg data time: 2.24e-01, avg batch time: 0.4481, average train loss: 3.0248
[09/19 02:01:27 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.0938, average loss: 3.0884
[09/19 02:01:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 26.00	
[09/19 02:01:47 visual_prompt]: 	Test 100/1152. loss: 2.947, 0.1078 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:02:03 visual_prompt]: 	Test 200/1152. loss: 3.073, 0.1043 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 02:02:20 visual_prompt]: 	Test 300/1152. loss: 2.955, 0.1173 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:02:36 visual_prompt]: 	Test 400/1152. loss: 3.053, 0.1072 s / batch. (data: 6.50e-03)max mem: 17.22454 GB 
[09/19 02:02:52 visual_prompt]: 	Test 500/1152. loss: 3.000, 0.0960 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/19 02:03:08 visual_prompt]: 	Test 600/1152. loss: 2.931, 0.0999 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 02:03:25 visual_prompt]: 	Test 700/1152. loss: 2.975, 0.1129 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 02:03:41 visual_prompt]: 	Test 800/1152. loss: 2.906, 0.1052 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 02:03:57 visual_prompt]: 	Test 900/1152. loss: 3.043, 0.1000 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 02:04:13 visual_prompt]: 	Test 1000/1152. loss: 2.961, 0.1080 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 02:04:29 visual_prompt]: 	Test 1100/1152. loss: 2.880, 0.1075 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 02:04:42 visual_prompt]: Inference (test):avg data time: 1.66e-03, avg batch time: 0.1083, average loss: 3.0237
[09/19 02:04:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.44	
[09/19 02:04:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/19 02:04:52 visual_prompt]: Epoch 22 / 100: avg data time: 2.26e-01, avg batch time: 0.4512, average train loss: 3.0012
[09/19 02:04:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0920, average loss: 2.9613
[09/19 02:04:59 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 37.00	
[09/19 02:05:19 visual_prompt]: 	Test 100/1152. loss: 3.126, 0.1046 s / batch. (data: 7.35e-03)max mem: 17.22454 GB 
[09/19 02:05:36 visual_prompt]: 	Test 200/1152. loss: 3.319, 0.1078 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 02:05:52 visual_prompt]: 	Test 300/1152. loss: 2.953, 0.1043 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 02:06:08 visual_prompt]: 	Test 400/1152. loss: 3.110, 0.1037 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 02:06:25 visual_prompt]: 	Test 500/1152. loss: 3.147, 0.1049 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 02:06:41 visual_prompt]: 	Test 600/1152. loss: 2.987, 0.1455 s / batch. (data: 8.91e-03)max mem: 17.22454 GB 
[09/19 02:06:57 visual_prompt]: 	Test 700/1152. loss: 2.896, 0.1121 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 02:07:13 visual_prompt]: 	Test 800/1152. loss: 3.028, 0.1117 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/19 02:07:29 visual_prompt]: 	Test 900/1152. loss: 2.954, 0.0963 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 02:07:45 visual_prompt]: 	Test 1000/1152. loss: 3.158, 0.1379 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/19 02:08:01 visual_prompt]: 	Test 1100/1152. loss: 3.116, 0.1118 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 02:08:13 visual_prompt]: Inference (test):avg data time: 2.06e-03, avg batch time: 0.1087, average loss: 3.0726
[09/19 02:08:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 34.91	
[09/19 02:08:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/19 02:08:24 visual_prompt]: Epoch 23 / 100: avg data time: 2.31e-01, avg batch time: 0.4570, average train loss: 3.1652
[09/19 02:08:31 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.0880, average loss: 3.0503
[09/19 02:08:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 37.50	
[09/19 02:08:51 visual_prompt]: 	Test 100/1152. loss: 3.154, 0.1239 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 02:09:08 visual_prompt]: 	Test 200/1152. loss: 2.874, 0.1050 s / batch. (data: 1.22e-05)max mem: 17.22454 GB 
[09/19 02:09:24 visual_prompt]: 	Test 300/1152. loss: 3.163, 0.1038 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 02:09:41 visual_prompt]: 	Test 400/1152. loss: 3.228, 0.1119 s / batch. (data: 8.99e-05)max mem: 17.22454 GB 
[09/19 02:09:57 visual_prompt]: 	Test 500/1152. loss: 2.929, 0.1156 s / batch. (data: 1.26e-05)max mem: 17.22454 GB 
[09/19 02:10:13 visual_prompt]: 	Test 600/1152. loss: 2.991, 0.1238 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 02:10:30 visual_prompt]: 	Test 700/1152. loss: 3.214, 0.0988 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 02:10:46 visual_prompt]: 	Test 800/1152. loss: 3.050, 0.0949 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 02:11:02 visual_prompt]: 	Test 900/1152. loss: 3.306, 0.1039 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:11:18 visual_prompt]: 	Test 1000/1152. loss: 3.301, 0.1176 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 02:11:35 visual_prompt]: 	Test 1100/1152. loss: 3.181, 0.0951 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 02:11:47 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1084, average loss: 3.1015
[09/19 02:11:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 35.17	
[09/19 02:11:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/19 02:11:57 visual_prompt]: Epoch 24 / 100: avg data time: 2.40e-01, avg batch time: 0.4651, average train loss: 3.0792
[09/19 02:12:04 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.0921, average loss: 2.9918
[09/19 02:12:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 38.50	
[09/19 02:12:24 visual_prompt]: 	Test 100/1152. loss: 3.183, 0.1038 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 02:12:41 visual_prompt]: 	Test 200/1152. loss: 3.113, 0.1012 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 02:12:57 visual_prompt]: 	Test 300/1152. loss: 3.047, 0.0986 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 02:13:14 visual_prompt]: 	Test 400/1152. loss: 3.116, 0.1105 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 02:13:30 visual_prompt]: 	Test 500/1152. loss: 3.105, 0.1334 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/19 02:13:47 visual_prompt]: 	Test 600/1152. loss: 3.287, 0.0964 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 02:14:03 visual_prompt]: 	Test 700/1152. loss: 3.004, 0.1044 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 02:14:19 visual_prompt]: 	Test 800/1152. loss: 3.104, 0.1391 s / batch. (data: 1.85e-02)max mem: 17.22454 GB 
[09/19 02:14:35 visual_prompt]: 	Test 900/1152. loss: 3.166, 0.1108 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 02:14:51 visual_prompt]: 	Test 1000/1152. loss: 3.000, 0.1225 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 02:15:08 visual_prompt]: 	Test 1100/1152. loss: 3.199, 0.1179 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 02:15:20 visual_prompt]: Inference (test):avg data time: 1.83e-03, avg batch time: 0.1092, average loss: 3.0731
[09/19 02:15:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 34.86	
[09/19 02:15:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/19 02:15:31 visual_prompt]: Epoch 25 / 100: avg data time: 2.17e-01, avg batch time: 0.4424, average train loss: 3.1033
[09/19 02:15:37 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.0890, average loss: 3.0069
[09/19 02:15:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 34.00	
[09/19 02:15:58 visual_prompt]: 	Test 100/1152. loss: 3.157, 0.0988 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:16:15 visual_prompt]: 	Test 200/1152. loss: 3.117, 0.0959 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 02:16:32 visual_prompt]: 	Test 300/1152. loss: 2.941, 0.1033 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/19 02:16:48 visual_prompt]: 	Test 400/1152. loss: 3.139, 0.1035 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 02:17:05 visual_prompt]: 	Test 500/1152. loss: 3.013, 0.0953 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 02:17:21 visual_prompt]: 	Test 600/1152. loss: 2.908, 0.1029 s / batch. (data: 4.10e-05)max mem: 17.22454 GB 
[09/19 02:17:37 visual_prompt]: 	Test 700/1152. loss: 3.067, 0.0989 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 02:17:54 visual_prompt]: 	Test 800/1152. loss: 2.904, 0.1491 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 02:18:10 visual_prompt]: 	Test 900/1152. loss: 3.028, 0.1057 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 02:18:26 visual_prompt]: 	Test 1000/1152. loss: 3.103, 0.1029 s / batch. (data: 4.65e-05)max mem: 17.22454 GB 
[09/19 02:18:42 visual_prompt]: 	Test 1100/1152. loss: 3.129, 0.1418 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 02:18:54 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1085, average loss: 3.0287
[09/19 02:18:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.38	
[09/19 02:18:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/19 02:19:05 visual_prompt]: Epoch 26 / 100: avg data time: 2.22e-01, avg batch time: 0.4489, average train loss: 3.0060
[09/19 02:19:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.0916, average loss: 2.9846
[09/19 02:19:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 35.00	
[09/19 02:19:32 visual_prompt]: 	Test 100/1152. loss: 3.127, 0.0949 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 02:19:48 visual_prompt]: 	Test 200/1152. loss: 2.937, 0.1080 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 02:20:04 visual_prompt]: 	Test 300/1152. loss: 2.955, 0.0975 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:20:20 visual_prompt]: 	Test 400/1152. loss: 3.029, 0.0984 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 02:20:37 visual_prompt]: 	Test 500/1152. loss: 2.886, 0.1034 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 02:20:53 visual_prompt]: 	Test 600/1152. loss: 3.004, 0.1060 s / batch. (data: 3.15e-05)max mem: 17.22454 GB 
[09/19 02:21:09 visual_prompt]: 	Test 700/1152. loss: 2.944, 0.1288 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 02:21:25 visual_prompt]: 	Test 800/1152. loss: 2.962, 0.0946 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 02:21:41 visual_prompt]: 	Test 900/1152. loss: 3.318, 0.1174 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 02:21:57 visual_prompt]: 	Test 1000/1152. loss: 3.283, 0.0949 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 02:22:13 visual_prompt]: 	Test 1100/1152. loss: 2.974, 0.0946 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/19 02:22:25 visual_prompt]: Inference (test):avg data time: 2.26e-03, avg batch time: 0.1088, average loss: 2.9608
[09/19 02:22:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 37.39	
[09/19 02:22:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/19 02:22:36 visual_prompt]: Epoch 27 / 100: avg data time: 2.32e-01, avg batch time: 0.4571, average train loss: 3.0572
[09/19 02:22:43 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0872, average loss: 2.9171
[09/19 02:22:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 39.00	
[09/19 02:23:03 visual_prompt]: 	Test 100/1152. loss: 3.086, 0.0969 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 02:23:19 visual_prompt]: 	Test 200/1152. loss: 3.141, 0.0987 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:23:35 visual_prompt]: 	Test 300/1152. loss: 3.156, 0.1377 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 02:23:52 visual_prompt]: 	Test 400/1152. loss: 3.126, 0.0975 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:24:08 visual_prompt]: 	Test 500/1152. loss: 3.087, 0.0978 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:24:25 visual_prompt]: 	Test 600/1152. loss: 3.012, 0.0950 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 02:24:41 visual_prompt]: 	Test 700/1152. loss: 2.920, 0.1148 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 02:24:57 visual_prompt]: 	Test 800/1152. loss: 3.020, 0.1044 s / batch. (data: 7.12e-03)max mem: 17.22454 GB 
[09/19 02:25:14 visual_prompt]: 	Test 900/1152. loss: 2.882, 0.0980 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 02:25:30 visual_prompt]: 	Test 1000/1152. loss: 3.059, 0.1283 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:25:46 visual_prompt]: 	Test 1100/1152. loss: 3.059, 0.1159 s / batch. (data: 9.78e-05)max mem: 17.22454 GB 
[09/19 02:25:58 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1085, average loss: 3.0562
[09/19 02:25:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 34.91	
[09/19 02:25:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/19 02:26:09 visual_prompt]: Epoch 28 / 100: avg data time: 2.28e-01, avg batch time: 0.4543, average train loss: 3.0068
[09/19 02:26:16 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.0884, average loss: 2.9487
[09/19 02:26:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 38.50	
[09/19 02:26:35 visual_prompt]: 	Test 100/1152. loss: 2.947, 0.1071 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:26:52 visual_prompt]: 	Test 200/1152. loss: 3.204, 0.1035 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 02:27:08 visual_prompt]: 	Test 300/1152. loss: 3.119, 0.0992 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 02:27:25 visual_prompt]: 	Test 400/1152. loss: 3.004, 0.1079 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 02:27:41 visual_prompt]: 	Test 500/1152. loss: 2.948, 0.0944 s / batch. (data: 8.87e-05)max mem: 17.22454 GB 
[09/19 02:27:57 visual_prompt]: 	Test 600/1152. loss: 3.032, 0.1157 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 02:28:13 visual_prompt]: 	Test 700/1152. loss: 3.000, 0.0986 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 02:28:29 visual_prompt]: 	Test 800/1152. loss: 3.041, 0.1158 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 02:28:46 visual_prompt]: 	Test 900/1152. loss: 2.846, 0.1232 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 02:29:02 visual_prompt]: 	Test 1000/1152. loss: 2.943, 0.0948 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 02:29:18 visual_prompt]: 	Test 1100/1152. loss: 3.050, 0.1007 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 02:29:30 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1087, average loss: 3.0015
[09/19 02:29:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 29.97	
[09/19 02:29:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/19 02:29:41 visual_prompt]: Epoch 29 / 100: avg data time: 2.18e-01, avg batch time: 0.4421, average train loss: 2.9938
[09/19 02:29:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.0894, average loss: 2.9051
[09/19 02:29:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 30.00	
[09/19 02:30:07 visual_prompt]: 	Test 100/1152. loss: 2.927, 0.0993 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 02:30:24 visual_prompt]: 	Test 200/1152. loss: 2.887, 0.1199 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 02:30:40 visual_prompt]: 	Test 300/1152. loss: 2.949, 0.1876 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 02:30:57 visual_prompt]: 	Test 400/1152. loss: 2.845, 0.0992 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:31:13 visual_prompt]: 	Test 500/1152. loss: 2.904, 0.0966 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 02:31:29 visual_prompt]: 	Test 600/1152. loss: 2.986, 0.1045 s / batch. (data: 9.33e-03)max mem: 17.22454 GB 
[09/19 02:31:45 visual_prompt]: 	Test 700/1152. loss: 2.867, 0.1282 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/19 02:32:02 visual_prompt]: 	Test 800/1152. loss: 2.972, 0.0951 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 02:32:18 visual_prompt]: 	Test 900/1152. loss: 2.961, 0.1028 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/19 02:32:34 visual_prompt]: 	Test 1000/1152. loss: 2.941, 0.0933 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 02:32:50 visual_prompt]: 	Test 1100/1152. loss: 3.017, 0.1086 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/19 02:33:02 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1090, average loss: 2.9155
[09/19 02:33:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.65	
[09/19 02:33:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/19 02:33:12 visual_prompt]: Epoch 30 / 100: avg data time: 2.17e-01, avg batch time: 0.4464, average train loss: 2.9977
[09/19 02:33:19 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.0929, average loss: 3.0248
[09/19 02:33:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 35.00	
[09/19 02:33:40 visual_prompt]: 	Test 100/1152. loss: 3.142, 0.1056 s / batch. (data: 1.14e-05)max mem: 17.22454 GB 
[09/19 02:33:56 visual_prompt]: 	Test 200/1152. loss: 3.078, 0.0955 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 02:34:12 visual_prompt]: 	Test 300/1152. loss: 2.883, 0.1237 s / batch. (data: 1.34e-05)max mem: 17.22454 GB 
[09/19 02:34:29 visual_prompt]: 	Test 400/1152. loss: 3.078, 0.1105 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:34:45 visual_prompt]: 	Test 500/1152. loss: 2.954, 0.1058 s / batch. (data: 9.18e-03)max mem: 17.22454 GB 
[09/19 02:35:01 visual_prompt]: 	Test 600/1152. loss: 2.847, 0.1156 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 02:35:18 visual_prompt]: 	Test 700/1152. loss: 2.945, 0.1230 s / batch. (data: 2.24e-02)max mem: 17.22454 GB 
[09/19 02:35:34 visual_prompt]: 	Test 800/1152. loss: 2.803, 0.0994 s / batch. (data: 3.48e-05)max mem: 17.22454 GB 
[09/19 02:35:50 visual_prompt]: 	Test 900/1152. loss: 3.071, 0.0975 s / batch. (data: 4.17e-05)max mem: 17.22454 GB 
[09/19 02:36:07 visual_prompt]: 	Test 1000/1152. loss: 3.063, 0.1199 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 02:36:22 visual_prompt]: 	Test 1100/1152. loss: 3.065, 0.1236 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 02:36:35 visual_prompt]: Inference (test):avg data time: 1.77e-03, avg batch time: 0.1087, average loss: 2.9992
[09/19 02:36:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 34.83	
[09/19 02:36:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/19 02:36:45 visual_prompt]: Epoch 31 / 100: avg data time: 2.24e-01, avg batch time: 0.4520, average train loss: 3.0181
[09/19 02:36:52 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.0864, average loss: 3.0520
[09/19 02:36:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 32.50	
[09/19 02:37:12 visual_prompt]: 	Test 100/1152. loss: 3.040, 0.1127 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 02:37:29 visual_prompt]: 	Test 200/1152. loss: 3.211, 0.1044 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 02:37:46 visual_prompt]: 	Test 300/1152. loss: 3.030, 0.0948 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/19 02:38:02 visual_prompt]: 	Test 400/1152. loss: 3.056, 0.1064 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 02:38:18 visual_prompt]: 	Test 500/1152. loss: 2.960, 0.1029 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 02:38:34 visual_prompt]: 	Test 600/1152. loss: 3.145, 0.0973 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 02:38:50 visual_prompt]: 	Test 700/1152. loss: 2.981, 0.1140 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 02:39:06 visual_prompt]: 	Test 800/1152. loss: 3.009, 0.0957 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 02:39:23 visual_prompt]: 	Test 900/1152. loss: 3.120, 0.1407 s / batch. (data: 5.25e-05)max mem: 17.22454 GB 
[09/19 02:39:39 visual_prompt]: 	Test 1000/1152. loss: 3.004, 0.0945 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 02:39:55 visual_prompt]: 	Test 1100/1152. loss: 2.976, 0.0990 s / batch. (data: 7.53e-05)max mem: 17.22454 GB 
[09/19 02:40:07 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1085, average loss: 3.0120
[09/19 02:40:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.48	
[09/19 02:40:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/19 02:40:18 visual_prompt]: Epoch 32 / 100: avg data time: 2.30e-01, avg batch time: 0.4581, average train loss: 3.0223
[09/19 02:40:25 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.0968, average loss: 3.0384
[09/19 02:40:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 33.50	
[09/19 02:40:45 visual_prompt]: 	Test 100/1152. loss: 2.947, 0.1296 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 02:41:02 visual_prompt]: 	Test 200/1152. loss: 2.991, 0.0986 s / batch. (data: 9.27e-05)max mem: 17.22454 GB 
[09/19 02:41:18 visual_prompt]: 	Test 300/1152. loss: 2.924, 0.0998 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 02:41:34 visual_prompt]: 	Test 400/1152. loss: 2.954, 0.1046 s / batch. (data: 1.26e-05)max mem: 17.22454 GB 
[09/19 02:41:51 visual_prompt]: 	Test 500/1152. loss: 2.866, 0.1266 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 02:42:07 visual_prompt]: 	Test 600/1152. loss: 2.874, 0.0960 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 02:42:23 visual_prompt]: 	Test 700/1152. loss: 3.054, 0.0994 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:42:39 visual_prompt]: 	Test 800/1152. loss: 2.902, 0.1042 s / batch. (data: 9.26e-03)max mem: 17.22454 GB 
[09/19 02:42:55 visual_prompt]: 	Test 900/1152. loss: 3.110, 0.0986 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 02:43:11 visual_prompt]: 	Test 1000/1152. loss: 3.052, 0.1086 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:43:27 visual_prompt]: 	Test 1100/1152. loss: 3.188, 0.1197 s / batch. (data: 2.31e-02)max mem: 17.22454 GB 
[09/19 02:43:39 visual_prompt]: Inference (test):avg data time: 1.67e-03, avg batch time: 0.1081, average loss: 3.0107
[09/19 02:43:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 37.52	
[09/19 02:43:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/19 02:43:50 visual_prompt]: Epoch 33 / 100: avg data time: 2.17e-01, avg batch time: 0.4451, average train loss: 2.9813
[09/19 02:43:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.0886, average loss: 2.9134
[09/19 02:43:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 29.50	
[09/19 02:44:16 visual_prompt]: 	Test 100/1152. loss: 3.043, 0.1000 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:44:33 visual_prompt]: 	Test 200/1152. loss: 2.960, 0.0971 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 02:44:49 visual_prompt]: 	Test 300/1152. loss: 3.052, 0.1181 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/19 02:45:06 visual_prompt]: 	Test 400/1152. loss: 2.897, 0.1056 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 02:45:22 visual_prompt]: 	Test 500/1152. loss: 2.964, 0.1165 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 02:45:38 visual_prompt]: 	Test 600/1152. loss: 3.093, 0.1274 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 02:45:54 visual_prompt]: 	Test 700/1152. loss: 2.949, 0.1086 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 02:46:11 visual_prompt]: 	Test 800/1152. loss: 3.007, 0.1118 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 02:46:27 visual_prompt]: 	Test 900/1152. loss: 2.982, 0.1268 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 02:46:43 visual_prompt]: 	Test 1000/1152. loss: 2.874, 0.1437 s / batch. (data: 4.67e-05)max mem: 17.22454 GB 
[09/19 02:46:59 visual_prompt]: 	Test 1100/1152. loss: 3.066, 0.1142 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 02:47:12 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1093, average loss: 2.9463
[09/19 02:47:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.01	
[09/19 02:47:12 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/19 02:47:22 visual_prompt]: Epoch 34 / 100: avg data time: 2.26e-01, avg batch time: 0.4520, average train loss: 2.9741
[09/19 02:47:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.0952, average loss: 2.9551
[09/19 02:47:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 35.00	
[09/19 02:47:49 visual_prompt]: 	Test 100/1152. loss: 2.963, 0.0972 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 02:48:06 visual_prompt]: 	Test 200/1152. loss: 2.889, 0.1077 s / batch. (data: 3.46e-05)max mem: 17.22454 GB 
[09/19 02:48:22 visual_prompt]: 	Test 300/1152. loss: 3.054, 0.1163 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 02:48:38 visual_prompt]: 	Test 400/1152. loss: 2.942, 0.0992 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 02:48:55 visual_prompt]: 	Test 500/1152. loss: 2.899, 0.1119 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 02:49:12 visual_prompt]: 	Test 600/1152. loss: 3.020, 0.1078 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 02:49:28 visual_prompt]: 	Test 700/1152. loss: 3.008, 0.1077 s / batch. (data: 9.61e-05)max mem: 17.22454 GB 
[09/19 02:49:44 visual_prompt]: 	Test 800/1152. loss: 2.942, 0.0996 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 02:50:00 visual_prompt]: 	Test 900/1152. loss: 3.034, 0.0948 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 02:50:16 visual_prompt]: 	Test 1000/1152. loss: 2.919, 0.0988 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:50:32 visual_prompt]: 	Test 1100/1152. loss: 2.960, 0.0953 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 02:50:45 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1083, average loss: 2.9330
[09/19 02:50:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 34.97	
[09/19 02:50:45 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/19 02:50:55 visual_prompt]: Epoch 35 / 100: avg data time: 2.21e-01, avg batch time: 0.4459, average train loss: 2.9562
[09/19 02:51:02 visual_prompt]: Inference (val):avg data time: 4.48e-05, avg batch time: 0.0930, average loss: 2.9285
[09/19 02:51:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 34.00	
[09/19 02:51:22 visual_prompt]: 	Test 100/1152. loss: 2.880, 0.1119 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 02:51:39 visual_prompt]: 	Test 200/1152. loss: 3.157, 0.1355 s / batch. (data: 1.76e-04)max mem: 17.22454 GB 
[09/19 02:51:55 visual_prompt]: 	Test 300/1152. loss: 3.102, 0.1168 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 02:52:11 visual_prompt]: 	Test 400/1152. loss: 3.036, 0.0952 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:52:28 visual_prompt]: 	Test 500/1152. loss: 3.000, 0.1071 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 02:52:44 visual_prompt]: 	Test 600/1152. loss: 3.229, 0.1137 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 02:53:01 visual_prompt]: 	Test 700/1152. loss: 3.029, 0.0967 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 02:53:17 visual_prompt]: 	Test 800/1152. loss: 2.970, 0.0952 s / batch. (data: 7.89e-05)max mem: 17.22454 GB 
[09/19 02:53:33 visual_prompt]: 	Test 900/1152. loss: 3.025, 0.1278 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 02:53:50 visual_prompt]: 	Test 1000/1152. loss: 2.921, 0.1188 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 02:54:06 visual_prompt]: 	Test 1100/1152. loss: 2.978, 0.0975 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 02:54:18 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1093, average loss: 3.0205
[09/19 02:54:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.36	
[09/19 02:54:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/19 02:54:29 visual_prompt]: Epoch 36 / 100: avg data time: 2.36e-01, avg batch time: 0.4614, average train loss: 2.9165
[09/19 02:54:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.0925, average loss: 3.0641
[09/19 02:54:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.50	top5: 28.00	
[09/19 02:54:56 visual_prompt]: 	Test 100/1152. loss: 3.165, 0.0950 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 02:55:12 visual_prompt]: 	Test 200/1152. loss: 3.098, 0.0945 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 02:55:29 visual_prompt]: 	Test 300/1152. loss: 2.928, 0.1094 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 02:55:45 visual_prompt]: 	Test 400/1152. loss: 2.983, 0.1126 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/19 02:56:02 visual_prompt]: 	Test 500/1152. loss: 3.023, 0.1079 s / batch. (data: 7.53e-05)max mem: 17.22454 GB 
[09/19 02:56:18 visual_prompt]: 	Test 600/1152. loss: 2.944, 0.1163 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 02:56:34 visual_prompt]: 	Test 700/1152. loss: 2.724, 0.1023 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/19 02:56:50 visual_prompt]: 	Test 800/1152. loss: 2.961, 0.1024 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 02:57:07 visual_prompt]: 	Test 900/1152. loss: 3.021, 0.0984 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 02:57:22 visual_prompt]: 	Test 1000/1152. loss: 2.855, 0.1129 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 02:57:39 visual_prompt]: 	Test 1100/1152. loss: 3.101, 0.1262 s / batch. (data: 2.16e-02)max mem: 17.22454 GB 
[09/19 02:57:51 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1087, average loss: 3.0106
[09/19 02:57:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.11	top5: 32.42	
[09/19 02:57:51 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/19 02:58:01 visual_prompt]: Epoch 37 / 100: avg data time: 2.23e-01, avg batch time: 0.4495, average train loss: 3.0046
[09/19 02:58:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.0901, average loss: 2.8535
[09/19 02:58:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 41.50	
[09/19 02:58:28 visual_prompt]: 	Test 100/1152. loss: 2.914, 0.0934 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 02:58:45 visual_prompt]: 	Test 200/1152. loss: 3.140, 0.0986 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 02:59:01 visual_prompt]: 	Test 300/1152. loss: 3.070, 0.0997 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 02:59:17 visual_prompt]: 	Test 400/1152. loss: 2.984, 0.0988 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 02:59:34 visual_prompt]: 	Test 500/1152. loss: 2.989, 0.1007 s / batch. (data: 1.88e-03)max mem: 17.22454 GB 
[09/19 02:59:50 visual_prompt]: 	Test 600/1152. loss: 3.136, 0.1195 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 03:00:05 visual_prompt]: 	Test 700/1152. loss: 2.886, 0.1169 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 03:00:22 visual_prompt]: 	Test 800/1152. loss: 3.029, 0.1030 s / batch. (data: 5.08e-05)max mem: 17.22454 GB 
[09/19 03:00:38 visual_prompt]: 	Test 900/1152. loss: 2.933, 0.0952 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 03:00:54 visual_prompt]: 	Test 1000/1152. loss: 3.026, 0.1247 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 03:01:11 visual_prompt]: 	Test 1100/1152. loss: 2.995, 0.0954 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 03:01:23 visual_prompt]: Inference (test):avg data time: 2.38e-03, avg batch time: 0.1095, average loss: 2.9738
[09/19 03:01:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 35.11	
[09/19 03:01:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/19 03:01:33 visual_prompt]: Epoch 38 / 100: avg data time: 2.28e-01, avg batch time: 0.4558, average train loss: 3.0106
[09/19 03:01:40 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.0890, average loss: 2.8614
[09/19 03:01:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 32.50	
[09/19 03:02:00 visual_prompt]: 	Test 100/1152. loss: 2.897, 0.0952 s / batch. (data: 5.01e-05)max mem: 17.22454 GB 
[09/19 03:02:17 visual_prompt]: 	Test 200/1152. loss: 2.868, 0.1083 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 03:02:33 visual_prompt]: 	Test 300/1152. loss: 2.885, 0.1133 s / batch. (data: 1.00e-05)max mem: 17.22454 GB 
[09/19 03:02:49 visual_prompt]: 	Test 400/1152. loss: 2.971, 0.1079 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/19 03:03:06 visual_prompt]: 	Test 500/1152. loss: 2.889, 0.1172 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 03:03:22 visual_prompt]: 	Test 600/1152. loss: 2.891, 0.0964 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 03:03:38 visual_prompt]: 	Test 700/1152. loss: 2.905, 0.1065 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 03:03:54 visual_prompt]: 	Test 800/1152. loss: 2.853, 0.0992 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 03:04:10 visual_prompt]: 	Test 900/1152. loss: 2.846, 0.1221 s / batch. (data: 2.86e-05)max mem: 17.22454 GB 
[09/19 03:04:27 visual_prompt]: 	Test 1000/1152. loss: 2.840, 0.1218 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/19 03:04:43 visual_prompt]: 	Test 1100/1152. loss: 2.959, 0.0953 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/19 03:04:55 visual_prompt]: Inference (test):avg data time: 1.64e-03, avg batch time: 0.1083, average loss: 2.8950
[09/19 03:04:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 29.92	
[09/19 03:04:55 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/19 03:05:06 visual_prompt]: Epoch 39 / 100: avg data time: 2.27e-01, avg batch time: 0.4590, average train loss: 2.9392
[09/19 03:05:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0906, average loss: 2.9021
[09/19 03:05:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.00	
[09/19 03:05:33 visual_prompt]: 	Test 100/1152. loss: 2.929, 0.1275 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 03:05:49 visual_prompt]: 	Test 200/1152. loss: 2.959, 0.1091 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 03:06:06 visual_prompt]: 	Test 300/1152. loss: 2.956, 0.0981 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 03:06:23 visual_prompt]: 	Test 400/1152. loss: 2.913, 0.1003 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 03:06:39 visual_prompt]: 	Test 500/1152. loss: 2.969, 0.0949 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/19 03:06:56 visual_prompt]: 	Test 600/1152. loss: 2.852, 0.1013 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 03:07:12 visual_prompt]: 	Test 700/1152. loss: 3.022, 0.1493 s / batch. (data: 3.26e-02)max mem: 17.22454 GB 
[09/19 03:07:28 visual_prompt]: 	Test 800/1152. loss: 3.010, 0.1060 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 03:07:44 visual_prompt]: 	Test 900/1152. loss: 2.813, 0.1168 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 03:08:00 visual_prompt]: 	Test 1000/1152. loss: 2.996, 0.0978 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 03:08:16 visual_prompt]: 	Test 1100/1152. loss: 2.979, 0.1657 s / batch. (data: 9.24e-03)max mem: 17.22454 GB 
[09/19 03:08:28 visual_prompt]: Inference (test):avg data time: 1.59e-03, avg batch time: 0.1082, average loss: 2.9508
[09/19 03:08:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.59	
[09/19 03:08:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/19 03:08:38 visual_prompt]: Epoch 40 / 100: avg data time: 2.36e-01, avg batch time: 0.4601, average train loss: 2.9218
[09/19 03:08:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.0881, average loss: 2.9805
[09/19 03:08:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 42.50	
[09/19 03:09:05 visual_prompt]: 	Test 100/1152. loss: 3.099, 0.1039 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 03:09:22 visual_prompt]: 	Test 200/1152. loss: 3.073, 0.0994 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 03:09:38 visual_prompt]: 	Test 300/1152. loss: 3.201, 0.1450 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 03:09:55 visual_prompt]: 	Test 400/1152. loss: 3.013, 0.1335 s / batch. (data: 2.10e-02)max mem: 17.22454 GB 
[09/19 03:10:11 visual_prompt]: 	Test 500/1152. loss: 3.083, 0.0971 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 03:10:27 visual_prompt]: 	Test 600/1152. loss: 3.305, 0.1161 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 03:10:43 visual_prompt]: 	Test 700/1152. loss: 3.063, 0.1206 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 03:10:59 visual_prompt]: 	Test 800/1152. loss: 3.172, 0.1042 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 03:11:15 visual_prompt]: 	Test 900/1152. loss: 3.129, 0.0948 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 03:11:31 visual_prompt]: 	Test 1000/1152. loss: 2.996, 0.0980 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 03:11:47 visual_prompt]: 	Test 1100/1152. loss: 3.160, 0.0991 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 03:11:59 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1087, average loss: 3.0538
[09/19 03:12:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 37.54	
[09/19 03:12:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/19 03:12:10 visual_prompt]: Epoch 41 / 100: avg data time: 2.30e-01, avg batch time: 0.4572, average train loss: 2.9805
[09/19 03:12:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.0889, average loss: 2.8643
[09/19 03:12:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 40.50	
[09/19 03:12:37 visual_prompt]: 	Test 100/1152. loss: 2.971, 0.1121 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 03:12:53 visual_prompt]: 	Test 200/1152. loss: 2.814, 0.1081 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/19 03:13:10 visual_prompt]: 	Test 300/1152. loss: 2.784, 0.1211 s / batch. (data: 9.28e-03)max mem: 17.22454 GB 
[09/19 03:13:26 visual_prompt]: 	Test 400/1152. loss: 2.840, 0.0986 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 03:13:42 visual_prompt]: 	Test 500/1152. loss: 2.956, 0.1153 s / batch. (data: 1.32e-03)max mem: 17.22454 GB 
[09/19 03:13:58 visual_prompt]: 	Test 600/1152. loss: 2.883, 0.0988 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 03:14:15 visual_prompt]: 	Test 700/1152. loss: 2.854, 0.1000 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 03:14:31 visual_prompt]: 	Test 800/1152. loss: 2.917, 0.0983 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 03:14:47 visual_prompt]: 	Test 900/1152. loss: 2.952, 0.0965 s / batch. (data: 9.87e-05)max mem: 17.22454 GB 
[09/19 03:15:03 visual_prompt]: 	Test 1000/1152. loss: 2.923, 0.1042 s / batch. (data: 7.55e-03)max mem: 17.22454 GB 
[09/19 03:15:19 visual_prompt]: 	Test 1100/1152. loss: 2.931, 0.1290 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 03:15:31 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1082, average loss: 2.8920
[09/19 03:15:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 35.19	
[09/19 03:15:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/19 03:15:42 visual_prompt]: Epoch 42 / 100: avg data time: 2.21e-01, avg batch time: 0.4536, average train loss: 2.9606
[09/19 03:15:49 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.0916, average loss: 2.7927
[09/19 03:15:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 39.50	
[09/19 03:16:09 visual_prompt]: 	Test 100/1152. loss: 2.818, 0.1127 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 03:16:25 visual_prompt]: 	Test 200/1152. loss: 2.956, 0.0999 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 03:16:42 visual_prompt]: 	Test 300/1152. loss: 2.830, 0.1138 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 03:16:58 visual_prompt]: 	Test 400/1152. loss: 2.839, 0.1078 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 03:17:15 visual_prompt]: 	Test 500/1152. loss: 2.832, 0.1159 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 03:17:31 visual_prompt]: 	Test 600/1152. loss: 2.806, 0.1046 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 03:17:47 visual_prompt]: 	Test 700/1152. loss: 2.849, 0.0998 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 03:18:03 visual_prompt]: 	Test 800/1152. loss: 2.840, 0.1033 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 03:18:19 visual_prompt]: 	Test 900/1152. loss: 2.751, 0.1300 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 03:18:35 visual_prompt]: 	Test 1000/1152. loss: 2.816, 0.1047 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/19 03:18:52 visual_prompt]: 	Test 1100/1152. loss: 2.913, 0.0988 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 03:19:04 visual_prompt]: Inference (test):avg data time: 2.24e-03, avg batch time: 0.1095, average loss: 2.8553
[09/19 03:19:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 37.59	
[09/19 03:19:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/19 03:19:14 visual_prompt]: Epoch 43 / 100: avg data time: 2.24e-01, avg batch time: 0.4510, average train loss: 2.9060
[09/19 03:19:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.0908, average loss: 2.8816
[09/19 03:19:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 26.50	
[09/19 03:19:41 visual_prompt]: 	Test 100/1152. loss: 2.896, 0.1006 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 03:19:58 visual_prompt]: 	Test 200/1152. loss: 3.014, 0.1134 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 03:20:14 visual_prompt]: 	Test 300/1152. loss: 2.833, 0.0951 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 03:20:30 visual_prompt]: 	Test 400/1152. loss: 2.854, 0.0948 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 03:20:47 visual_prompt]: 	Test 500/1152. loss: 2.892, 0.1450 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/19 03:21:03 visual_prompt]: 	Test 600/1152. loss: 2.896, 0.0990 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/19 03:21:19 visual_prompt]: 	Test 700/1152. loss: 2.764, 0.1037 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 03:21:35 visual_prompt]: 	Test 800/1152. loss: 2.846, 0.0996 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 03:21:51 visual_prompt]: 	Test 900/1152. loss: 2.854, 0.1029 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 03:22:07 visual_prompt]: 	Test 1000/1152. loss: 2.830, 0.1040 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 03:22:23 visual_prompt]: 	Test 1100/1152. loss: 2.886, 0.0978 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 03:22:35 visual_prompt]: Inference (test):avg data time: 1.42e-03, avg batch time: 0.1082, average loss: 2.8704
[09/19 03:22:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 27.32	
[09/19 03:22:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/19 03:22:46 visual_prompt]: Epoch 44 / 100: avg data time: 2.30e-01, avg batch time: 0.4568, average train loss: 2.9103
[09/19 03:22:52 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.0917, average loss: 2.8365
[09/19 03:22:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 39.50	
[09/19 03:23:12 visual_prompt]: 	Test 100/1152. loss: 2.926, 0.1148 s / batch. (data: 2.03e-02)max mem: 17.22454 GB 
[09/19 03:23:29 visual_prompt]: 	Test 200/1152. loss: 3.047, 0.0984 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 03:23:46 visual_prompt]: 	Test 300/1152. loss: 2.841, 0.1079 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 03:24:02 visual_prompt]: 	Test 400/1152. loss: 2.896, 0.0951 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/19 03:24:18 visual_prompt]: 	Test 500/1152. loss: 3.020, 0.0993 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/19 03:24:35 visual_prompt]: 	Test 600/1152. loss: 3.015, 0.1136 s / batch. (data: 8.85e-03)max mem: 17.22454 GB 
[09/19 03:24:51 visual_prompt]: 	Test 700/1152. loss: 2.833, 0.1110 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 03:25:07 visual_prompt]: 	Test 800/1152. loss: 2.993, 0.1450 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 03:25:23 visual_prompt]: 	Test 900/1152. loss: 2.837, 0.1247 s / batch. (data: 1.61e-02)max mem: 17.22454 GB 
[09/19 03:25:39 visual_prompt]: 	Test 1000/1152. loss: 2.905, 0.1150 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 03:25:55 visual_prompt]: 	Test 1100/1152. loss: 3.028, 0.0975 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 03:26:07 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1084, average loss: 2.9358
[09/19 03:26:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.16	
[09/19 03:26:08 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/19 03:26:18 visual_prompt]: Epoch 45 / 100: avg data time: 2.32e-01, avg batch time: 0.4565, average train loss: 2.9097
[09/19 03:26:25 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0911, average loss: 2.8404
[09/19 03:26:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 38.50	
[09/19 03:26:45 visual_prompt]: 	Test 100/1152. loss: 2.996, 0.0979 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 03:27:02 visual_prompt]: 	Test 200/1152. loss: 2.948, 0.1054 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:27:18 visual_prompt]: 	Test 300/1152. loss: 2.919, 0.1165 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 03:27:34 visual_prompt]: 	Test 400/1152. loss: 2.988, 0.0962 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/19 03:27:51 visual_prompt]: 	Test 500/1152. loss: 2.926, 0.0989 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 03:28:07 visual_prompt]: 	Test 600/1152. loss: 3.006, 0.1284 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 03:28:23 visual_prompt]: 	Test 700/1152. loss: 2.941, 0.0999 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 03:28:39 visual_prompt]: 	Test 800/1152. loss: 3.010, 0.1154 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 03:28:55 visual_prompt]: 	Test 900/1152. loss: 3.019, 0.0952 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 03:29:12 visual_prompt]: 	Test 1000/1152. loss: 3.082, 0.1167 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 03:29:28 visual_prompt]: 	Test 1100/1152. loss: 2.922, 0.1314 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 03:29:40 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1085, average loss: 2.9170
[09/19 03:29:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.07	
[09/19 03:29:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/19 03:29:50 visual_prompt]: Epoch 46 / 100: avg data time: 2.22e-01, avg batch time: 0.4514, average train loss: 2.9365
[09/19 03:29:57 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.0877, average loss: 2.9136
[09/19 03:29:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 29.00	
[09/19 03:30:17 visual_prompt]: 	Test 100/1152. loss: 2.893, 0.0999 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 03:30:33 visual_prompt]: 	Test 200/1152. loss: 2.886, 0.0992 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 03:30:50 visual_prompt]: 	Test 300/1152. loss: 2.822, 0.1137 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 03:31:06 visual_prompt]: 	Test 400/1152. loss: 2.798, 0.0974 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 03:31:23 visual_prompt]: 	Test 500/1152. loss: 2.826, 0.1280 s / batch. (data: 1.93e-02)max mem: 17.22454 GB 
[09/19 03:31:39 visual_prompt]: 	Test 600/1152. loss: 2.804, 0.1011 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 03:31:55 visual_prompt]: 	Test 700/1152. loss: 2.914, 0.1183 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 03:32:11 visual_prompt]: 	Test 800/1152. loss: 2.884, 0.1115 s / batch. (data: 2.00e-04)max mem: 17.22454 GB 
[09/19 03:32:28 visual_prompt]: 	Test 900/1152. loss: 2.936, 0.0967 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 03:32:44 visual_prompt]: 	Test 1000/1152. loss: 2.925, 0.1133 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 03:33:00 visual_prompt]: 	Test 1100/1152. loss: 2.882, 0.0991 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:33:12 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1086, average loss: 2.8696
[09/19 03:33:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.05	
[09/19 03:33:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/19 03:33:23 visual_prompt]: Epoch 47 / 100: avg data time: 2.23e-01, avg batch time: 0.4477, average train loss: 2.9339
[09/19 03:33:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0964, average loss: 2.8747
[09/19 03:33:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 37.50	
[09/19 03:33:50 visual_prompt]: 	Test 100/1152. loss: 2.972, 0.1040 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 03:34:06 visual_prompt]: 	Test 200/1152. loss: 2.957, 0.1077 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 03:34:23 visual_prompt]: 	Test 300/1152. loss: 2.976, 0.0981 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 03:34:39 visual_prompt]: 	Test 400/1152. loss: 2.867, 0.1038 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 03:34:56 visual_prompt]: 	Test 500/1152. loss: 2.864, 0.1232 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 03:35:12 visual_prompt]: 	Test 600/1152. loss: 2.832, 0.0950 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 03:35:28 visual_prompt]: 	Test 700/1152. loss: 2.862, 0.1130 s / batch. (data: 6.37e-03)max mem: 17.22454 GB 
[09/19 03:35:44 visual_prompt]: 	Test 800/1152. loss: 2.914, 0.1143 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 03:36:00 visual_prompt]: 	Test 900/1152. loss: 2.837, 0.0958 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/19 03:36:17 visual_prompt]: 	Test 1000/1152. loss: 2.843, 0.1240 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:36:32 visual_prompt]: 	Test 1100/1152. loss: 2.981, 0.0973 s / batch. (data: 9.39e-05)max mem: 17.22454 GB 
[09/19 03:36:45 visual_prompt]: Inference (test):avg data time: 1.83e-03, avg batch time: 0.1089, average loss: 2.8952
[09/19 03:36:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 35.87	
[09/19 03:36:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/19 03:36:55 visual_prompt]: Epoch 48 / 100: avg data time: 2.23e-01, avg batch time: 0.4474, average train loss: 2.9545
[09/19 03:37:02 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.0880, average loss: 2.8446
[09/19 03:37:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 33.00	
[09/19 03:37:22 visual_prompt]: 	Test 100/1152. loss: 3.167, 0.1094 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 03:37:39 visual_prompt]: 	Test 200/1152. loss: 3.075, 0.1463 s / batch. (data: 2.79e-03)max mem: 17.22454 GB 
[09/19 03:37:55 visual_prompt]: 	Test 300/1152. loss: 2.963, 0.1026 s / batch. (data: 7.36e-03)max mem: 17.22454 GB 
[09/19 03:38:11 visual_prompt]: 	Test 400/1152. loss: 3.105, 0.1166 s / batch. (data: 1.20e-02)max mem: 17.22454 GB 
[09/19 03:38:27 visual_prompt]: 	Test 500/1152. loss: 3.179, 0.0975 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 03:38:44 visual_prompt]: 	Test 600/1152. loss: 3.233, 0.1015 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 03:39:00 visual_prompt]: 	Test 700/1152. loss: 2.893, 0.1376 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 03:39:16 visual_prompt]: 	Test 800/1152. loss: 3.136, 0.1114 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 03:39:32 visual_prompt]: 	Test 900/1152. loss: 3.050, 0.1158 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 03:39:48 visual_prompt]: 	Test 1000/1152. loss: 3.058, 0.1103 s / batch. (data: 9.83e-03)max mem: 17.22454 GB 
[09/19 03:40:04 visual_prompt]: 	Test 1100/1152. loss: 2.976, 0.1161 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 03:40:16 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1093, average loss: 3.0023
[09/19 03:40:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 30.01	
[09/19 03:40:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/19 03:40:27 visual_prompt]: Epoch 49 / 100: avg data time: 2.27e-01, avg batch time: 0.4539, average train loss: 2.9715
[09/19 03:40:34 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.0884, average loss: 2.8923
[09/19 03:40:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 34.50	
[09/19 03:40:54 visual_prompt]: 	Test 100/1152. loss: 2.954, 0.1001 s / batch. (data: 2.23e-03)max mem: 17.22454 GB 
[09/19 03:41:10 visual_prompt]: 	Test 200/1152. loss: 3.103, 0.1099 s / batch. (data: 1.87e-04)max mem: 17.22454 GB 
[09/19 03:41:27 visual_prompt]: 	Test 300/1152. loss: 2.930, 0.0947 s / batch. (data: 9.75e-05)max mem: 17.22454 GB 
[09/19 03:41:43 visual_prompt]: 	Test 400/1152. loss: 2.983, 0.1231 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/19 03:42:00 visual_prompt]: 	Test 500/1152. loss: 2.916, 0.1028 s / batch. (data: 1.79e-04)max mem: 17.22454 GB 
[09/19 03:42:16 visual_prompt]: 	Test 600/1152. loss: 2.892, 0.1398 s / batch. (data: 6.60e-03)max mem: 17.22454 GB 
[09/19 03:42:32 visual_prompt]: 	Test 700/1152. loss: 2.857, 0.1095 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 03:42:48 visual_prompt]: 	Test 800/1152. loss: 3.026, 0.0969 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 03:43:05 visual_prompt]: 	Test 900/1152. loss: 2.909, 0.1079 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 03:43:21 visual_prompt]: 	Test 1000/1152. loss: 2.974, 0.1079 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 03:43:37 visual_prompt]: 	Test 1100/1152. loss: 2.860, 0.0997 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 03:43:50 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1086, average loss: 2.9378
[09/19 03:43:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.95	
[09/19 03:43:50 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/19 03:44:00 visual_prompt]: Epoch 50 / 100: avg data time: 2.37e-01, avg batch time: 0.4616, average train loss: 2.9241
[09/19 03:44:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.0922, average loss: 2.9398
[09/19 03:44:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 35.50	
[09/19 03:44:27 visual_prompt]: 	Test 100/1152. loss: 2.882, 0.0991 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:44:44 visual_prompt]: 	Test 200/1152. loss: 3.087, 0.1160 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 03:45:01 visual_prompt]: 	Test 300/1152. loss: 2.958, 0.1079 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 03:45:17 visual_prompt]: 	Test 400/1152. loss: 3.029, 0.1093 s / batch. (data: 1.26e-05)max mem: 17.22454 GB 
[09/19 03:45:33 visual_prompt]: 	Test 500/1152. loss: 2.937, 0.0947 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 03:45:49 visual_prompt]: 	Test 600/1152. loss: 2.803, 0.0948 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/19 03:46:06 visual_prompt]: 	Test 700/1152. loss: 2.880, 0.0991 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 03:46:22 visual_prompt]: 	Test 800/1152. loss: 2.909, 0.0998 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 03:46:38 visual_prompt]: 	Test 900/1152. loss: 2.757, 0.1038 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 03:46:54 visual_prompt]: 	Test 1000/1152. loss: 2.960, 0.1229 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 03:47:10 visual_prompt]: 	Test 1100/1152. loss: 2.924, 0.1107 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 03:47:22 visual_prompt]: Inference (test):avg data time: 2.16e-03, avg batch time: 0.1089, average loss: 2.9793
[09/19 03:47:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 32.49	
[09/19 03:47:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/19 03:47:33 visual_prompt]: Epoch 51 / 100: avg data time: 2.20e-01, avg batch time: 0.4466, average train loss: 2.9754
[09/19 03:47:40 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.0882, average loss: 2.9813
[09/19 03:47:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 36.00	
[09/19 03:48:00 visual_prompt]: 	Test 100/1152. loss: 2.857, 0.0958 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 03:48:17 visual_prompt]: 	Test 200/1152. loss: 2.964, 0.0970 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 03:48:33 visual_prompt]: 	Test 300/1152. loss: 2.965, 0.0967 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 03:48:49 visual_prompt]: 	Test 400/1152. loss: 2.891, 0.1201 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 03:49:06 visual_prompt]: 	Test 500/1152. loss: 2.939, 0.0990 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 03:49:22 visual_prompt]: 	Test 600/1152. loss: 2.968, 0.1067 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 03:49:38 visual_prompt]: 	Test 700/1152. loss: 3.029, 0.1079 s / batch. (data: 7.27e-03)max mem: 17.22454 GB 
[09/19 03:49:54 visual_prompt]: 	Test 800/1152. loss: 2.989, 0.0975 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/19 03:50:11 visual_prompt]: 	Test 900/1152. loss: 2.996, 0.1198 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:50:27 visual_prompt]: 	Test 1000/1152. loss: 2.975, 0.1106 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 03:50:43 visual_prompt]: 	Test 1100/1152. loss: 3.084, 0.0992 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 03:50:55 visual_prompt]: Inference (test):avg data time: 2.15e-03, avg batch time: 0.1091, average loss: 2.9867
[09/19 03:50:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.11	
[09/19 03:50:56 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/19 03:51:06 visual_prompt]: Epoch 52 / 100: avg data time: 2.26e-01, avg batch time: 0.4499, average train loss: 2.9535
[09/19 03:51:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.0928, average loss: 3.0582
[09/19 03:51:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 26.00	
[09/19 03:51:33 visual_prompt]: 	Test 100/1152. loss: 3.052, 0.0978 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 03:51:50 visual_prompt]: 	Test 200/1152. loss: 3.110, 0.1160 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/19 03:52:06 visual_prompt]: 	Test 300/1152. loss: 2.902, 0.0981 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 03:52:22 visual_prompt]: 	Test 400/1152. loss: 2.922, 0.1254 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 03:52:39 visual_prompt]: 	Test 500/1152. loss: 2.930, 0.0943 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 03:52:55 visual_prompt]: 	Test 600/1152. loss: 2.851, 0.1056 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 03:53:11 visual_prompt]: 	Test 700/1152. loss: 2.917, 0.1142 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 03:53:28 visual_prompt]: 	Test 800/1152. loss: 2.981, 0.0963 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 03:53:44 visual_prompt]: 	Test 900/1152. loss: 3.004, 0.0992 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 03:54:01 visual_prompt]: 	Test 1000/1152. loss: 3.074, 0.1006 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 03:54:17 visual_prompt]: 	Test 1100/1152. loss: 3.131, 0.1047 s / batch. (data: 7.77e-05)max mem: 17.22454 GB 
[09/19 03:54:29 visual_prompt]: Inference (test):avg data time: 1.51e-03, avg batch time: 0.1082, average loss: 2.9866
[09/19 03:54:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 30.13	
[09/19 03:54:29 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/19 03:54:40 visual_prompt]: Epoch 53 / 100: avg data time: 2.22e-01, avg batch time: 0.4486, average train loss: 2.9618
[09/19 03:54:46 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.0908, average loss: 3.0250
[09/19 03:54:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 27.00	
[09/19 03:55:06 visual_prompt]: 	Test 100/1152. loss: 3.012, 0.1195 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 03:55:23 visual_prompt]: 	Test 200/1152. loss: 2.996, 0.1039 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 03:55:39 visual_prompt]: 	Test 300/1152. loss: 2.896, 0.0984 s / batch. (data: 3.27e-05)max mem: 17.22454 GB 
[09/19 03:55:56 visual_prompt]: 	Test 400/1152. loss: 2.911, 0.1005 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 03:56:12 visual_prompt]: 	Test 500/1152. loss: 2.891, 0.0995 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 03:56:28 visual_prompt]: 	Test 600/1152. loss: 2.965, 0.1077 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 03:56:45 visual_prompt]: 	Test 700/1152. loss: 2.977, 0.0998 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 03:57:01 visual_prompt]: 	Test 800/1152. loss: 2.979, 0.1000 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 03:57:17 visual_prompt]: 	Test 900/1152. loss: 3.080, 0.0984 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 03:57:33 visual_prompt]: 	Test 1000/1152. loss: 2.875, 0.1238 s / batch. (data: 1.93e-02)max mem: 17.22454 GB 
[09/19 03:57:50 visual_prompt]: 	Test 1100/1152. loss: 3.099, 0.1050 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 03:58:02 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1087, average loss: 2.9565
[09/19 03:58:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.71	
[09/19 03:58:02 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/19 03:58:13 visual_prompt]: Epoch 54 / 100: avg data time: 2.22e-01, avg batch time: 0.4477, average train loss: 2.9170
[09/19 03:58:19 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.0867, average loss: 2.8301
[09/19 03:58:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.00	top5: 43.50	
[09/19 03:58:40 visual_prompt]: 	Test 100/1152. loss: 2.707, 0.1039 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 03:58:56 visual_prompt]: 	Test 200/1152. loss: 2.829, 0.1090 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/19 03:59:12 visual_prompt]: 	Test 300/1152. loss: 2.991, 0.0950 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 03:59:29 visual_prompt]: 	Test 400/1152. loss: 2.890, 0.0985 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 03:59:45 visual_prompt]: 	Test 500/1152. loss: 2.857, 0.0991 s / batch. (data: 6.99e-05)max mem: 17.22454 GB 
[09/19 04:00:01 visual_prompt]: 	Test 600/1152. loss: 3.070, 0.0946 s / batch. (data: 7.25e-05)max mem: 17.22454 GB 
[09/19 04:00:17 visual_prompt]: 	Test 700/1152. loss: 2.975, 0.0964 s / batch. (data: 6.58e-05)max mem: 17.22454 GB 
[09/19 04:00:33 visual_prompt]: 	Test 800/1152. loss: 2.906, 0.0951 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/19 04:00:49 visual_prompt]: 	Test 900/1152. loss: 2.831, 0.0956 s / batch. (data: 6.72e-05)max mem: 17.22454 GB 
[09/19 04:01:05 visual_prompt]: 	Test 1000/1152. loss: 2.728, 0.0948 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 04:01:21 visual_prompt]: 	Test 1100/1152. loss: 2.874, 0.1118 s / batch. (data: 7.18e-03)max mem: 17.22454 GB 
[09/19 04:01:34 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1089, average loss: 2.8889
[09/19 04:01:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.42	top5: 41.46	
[09/19 04:01:34 visual_prompt]: Best epoch 54: best metric: 0.130
[09/19 04:01:34 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/19 04:01:44 visual_prompt]: Epoch 55 / 100: avg data time: 2.41e-01, avg batch time: 0.4652, average train loss: 2.8818
[09/19 04:01:51 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.0907, average loss: 2.8996
[09/19 04:01:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.00	
[09/19 04:02:11 visual_prompt]: 	Test 100/1152. loss: 2.892, 0.1015 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 04:02:28 visual_prompt]: 	Test 200/1152. loss: 2.965, 0.1118 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 04:02:44 visual_prompt]: 	Test 300/1152. loss: 2.912, 0.1079 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 04:03:01 visual_prompt]: 	Test 400/1152. loss: 2.866, 0.1038 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 04:03:17 visual_prompt]: 	Test 500/1152. loss: 2.967, 0.1146 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 04:03:33 visual_prompt]: 	Test 600/1152. loss: 3.084, 0.1234 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/19 04:03:49 visual_prompt]: 	Test 700/1152. loss: 3.106, 0.0943 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 04:04:05 visual_prompt]: 	Test 800/1152. loss: 2.948, 0.1021 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 04:04:22 visual_prompt]: 	Test 900/1152. loss: 2.934, 0.1105 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 04:04:38 visual_prompt]: 	Test 1000/1152. loss: 2.845, 0.1131 s / batch. (data: 7.01e-05)max mem: 17.22454 GB 
[09/19 04:04:54 visual_prompt]: 	Test 1100/1152. loss: 3.004, 0.1005 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 04:05:06 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1088, average loss: 2.9329
[09/19 04:05:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.49	
[09/19 04:05:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/19 04:05:17 visual_prompt]: Epoch 56 / 100: avg data time: 2.29e-01, avg batch time: 0.4494, average train loss: 2.8583
[09/19 04:05:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.0877, average loss: 2.6968
[09/19 04:05:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.50	top5: 46.00	
[09/19 04:05:44 visual_prompt]: 	Test 100/1152. loss: 2.869, 0.1068 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 04:06:01 visual_prompt]: 	Test 200/1152. loss: 2.716, 0.0988 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 04:06:17 visual_prompt]: 	Test 300/1152. loss: 2.820, 0.1037 s / batch. (data: 7.16e-03)max mem: 17.22454 GB 
[09/19 04:06:34 visual_prompt]: 	Test 400/1152. loss: 2.873, 0.0979 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 04:06:51 visual_prompt]: 	Test 500/1152. loss: 2.711, 0.1252 s / batch. (data: 2.04e-02)max mem: 17.22454 GB 
[09/19 04:07:07 visual_prompt]: 	Test 600/1152. loss: 2.772, 0.0966 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 04:07:23 visual_prompt]: 	Test 700/1152. loss: 2.783, 0.1117 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:07:39 visual_prompt]: 	Test 800/1152. loss: 2.810, 0.1291 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 04:07:55 visual_prompt]: 	Test 900/1152. loss: 2.766, 0.1033 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 04:08:11 visual_prompt]: 	Test 1000/1152. loss: 2.760, 0.1281 s / batch. (data: 8.82e-05)max mem: 17.22454 GB 
[09/19 04:08:27 visual_prompt]: 	Test 1100/1152. loss: 2.742, 0.1222 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 04:08:40 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1084, average loss: 2.7683
[09/19 04:08:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.48	top5: 39.40	
[09/19 04:08:40 visual_prompt]: Best epoch 56: best metric: 0.135
[09/19 04:08:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/19 04:08:50 visual_prompt]: Epoch 57 / 100: avg data time: 2.33e-01, avg batch time: 0.4578, average train loss: 2.8171
[09/19 04:08:57 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.0926, average loss: 2.7692
[09/19 04:08:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 42.50	
[09/19 04:09:17 visual_prompt]: 	Test 100/1152. loss: 2.813, 0.1120 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 04:09:34 visual_prompt]: 	Test 200/1152. loss: 2.781, 0.0985 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 04:09:50 visual_prompt]: 	Test 300/1152. loss: 2.887, 0.1224 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 04:10:06 visual_prompt]: 	Test 400/1152. loss: 2.783, 0.1042 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 04:10:23 visual_prompt]: 	Test 500/1152. loss: 2.849, 0.0990 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:10:40 visual_prompt]: 	Test 600/1152. loss: 2.897, 0.1192 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 04:10:56 visual_prompt]: 	Test 700/1152. loss: 2.849, 0.1080 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 04:11:12 visual_prompt]: 	Test 800/1152. loss: 2.942, 0.0982 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 04:11:28 visual_prompt]: 	Test 900/1152. loss: 2.788, 0.1114 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 04:11:44 visual_prompt]: 	Test 1000/1152. loss: 2.862, 0.1198 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 04:12:00 visual_prompt]: 	Test 1100/1152. loss: 2.816, 0.0975 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 04:12:12 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1089, average loss: 2.8449
[09/19 04:12:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 33.68	
[09/19 04:12:12 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/19 04:12:23 visual_prompt]: Epoch 58 / 100: avg data time: 2.23e-01, avg batch time: 0.4534, average train loss: 2.8143
[09/19 04:12:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0886, average loss: 2.6669
[09/19 04:12:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.00	top5: 50.50	
[09/19 04:12:50 visual_prompt]: 	Test 100/1152. loss: 2.939, 0.1207 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:13:06 visual_prompt]: 	Test 200/1152. loss: 2.815, 0.1044 s / batch. (data: 7.25e-05)max mem: 17.22454 GB 
[09/19 04:13:23 visual_prompt]: 	Test 300/1152. loss: 2.946, 0.0946 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/19 04:13:40 visual_prompt]: 	Test 400/1152. loss: 2.912, 0.1116 s / batch. (data: 7.06e-05)max mem: 17.22454 GB 
[09/19 04:13:56 visual_prompt]: 	Test 500/1152. loss: 2.796, 0.0983 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 04:14:12 visual_prompt]: 	Test 600/1152. loss: 2.901, 0.1199 s / batch. (data: 2.36e-02)max mem: 17.22454 GB 
[09/19 04:14:28 visual_prompt]: 	Test 700/1152. loss: 2.848, 0.1066 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 04:14:44 visual_prompt]: 	Test 800/1152. loss: 2.896, 0.1006 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 04:15:00 visual_prompt]: 	Test 900/1152. loss: 2.826, 0.0982 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 04:15:16 visual_prompt]: 	Test 1000/1152. loss: 2.855, 0.1062 s / batch. (data: 9.58e-03)max mem: 17.22454 GB 
[09/19 04:15:33 visual_prompt]: 	Test 1100/1152. loss: 2.900, 0.1199 s / batch. (data: 1.76e-04)max mem: 17.22454 GB 
[09/19 04:15:45 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1085, average loss: 2.8205
[09/19 04:15:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.46	top5: 40.68	
[09/19 04:15:45 visual_prompt]: Best epoch 58: best metric: 0.150
[09/19 04:15:45 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/19 04:15:55 visual_prompt]: Epoch 59 / 100: avg data time: 2.24e-01, avg batch time: 0.4523, average train loss: 2.7959
[09/19 04:16:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.0951, average loss: 2.8706
[09/19 04:16:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 42.00	
[09/19 04:16:22 visual_prompt]: 	Test 100/1152. loss: 2.870, 0.1195 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:16:39 visual_prompt]: 	Test 200/1152. loss: 3.005, 0.0944 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 04:16:55 visual_prompt]: 	Test 300/1152. loss: 2.866, 0.0945 s / batch. (data: 7.49e-05)max mem: 17.22454 GB 
[09/19 04:17:12 visual_prompt]: 	Test 400/1152. loss: 2.805, 0.0947 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 04:17:28 visual_prompt]: 	Test 500/1152. loss: 2.807, 0.1141 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 04:17:44 visual_prompt]: 	Test 600/1152. loss: 2.963, 0.1204 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 04:18:00 visual_prompt]: 	Test 700/1152. loss: 2.846, 0.1184 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 04:18:17 visual_prompt]: 	Test 800/1152. loss: 2.828, 0.0964 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/19 04:18:33 visual_prompt]: 	Test 900/1152. loss: 2.994, 0.1051 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 04:18:49 visual_prompt]: 	Test 1000/1152. loss: 2.838, 0.0960 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 04:19:05 visual_prompt]: 	Test 1100/1152. loss: 2.953, 0.1256 s / batch. (data: 8.93e-03)max mem: 17.22454 GB 
[09/19 04:19:18 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1083, average loss: 2.8864
[09/19 04:19:18 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 38.79	
[09/19 04:19:18 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/19 04:19:28 visual_prompt]: Epoch 60 / 100: avg data time: 2.28e-01, avg batch time: 0.4516, average train loss: 2.8413
[09/19 04:19:35 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0958, average loss: 2.7063
[09/19 04:19:35 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.50	top5: 50.50	
[09/19 04:19:55 visual_prompt]: 	Test 100/1152. loss: 2.686, 0.1062 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 04:20:11 visual_prompt]: 	Test 200/1152. loss: 2.730, 0.0968 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 04:20:27 visual_prompt]: 	Test 300/1152. loss: 2.945, 0.1019 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 04:20:44 visual_prompt]: 	Test 400/1152. loss: 2.828, 0.1283 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 04:21:00 visual_prompt]: 	Test 500/1152. loss: 2.662, 0.1133 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/19 04:21:16 visual_prompt]: 	Test 600/1152. loss: 2.831, 0.1318 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 04:21:33 visual_prompt]: 	Test 700/1152. loss: 2.864, 0.1086 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 04:21:49 visual_prompt]: 	Test 800/1152. loss: 2.774, 0.1356 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/19 04:22:05 visual_prompt]: 	Test 900/1152. loss: 2.808, 0.1103 s / batch. (data: 9.63e-03)max mem: 17.22454 GB 
[09/19 04:22:21 visual_prompt]: 	Test 1000/1152. loss: 2.742, 0.1000 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 04:22:37 visual_prompt]: 	Test 1100/1152. loss: 2.789, 0.1123 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 04:22:50 visual_prompt]: Inference (test):avg data time: 1.64e-03, avg batch time: 0.1079, average loss: 2.7816
[09/19 04:22:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.70	top5: 41.27	
[09/19 04:22:50 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/19 04:23:00 visual_prompt]: Epoch 61 / 100: avg data time: 2.33e-01, avg batch time: 0.4605, average train loss: 2.7702
[09/19 04:23:07 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.0911, average loss: 2.7263
[09/19 04:23:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.00	top5: 48.50	
[09/19 04:23:27 visual_prompt]: 	Test 100/1152. loss: 2.815, 0.0999 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:23:43 visual_prompt]: 	Test 200/1152. loss: 2.791, 0.0990 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 04:24:00 visual_prompt]: 	Test 300/1152. loss: 2.755, 0.0978 s / batch. (data: 4.84e-05)max mem: 17.22454 GB 
[09/19 04:24:16 visual_prompt]: 	Test 400/1152. loss: 2.806, 0.1080 s / batch. (data: 7.42e-03)max mem: 17.22454 GB 
[09/19 04:24:32 visual_prompt]: 	Test 500/1152. loss: 2.821, 0.1072 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 04:24:49 visual_prompt]: 	Test 600/1152. loss: 2.825, 0.1020 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 04:25:05 visual_prompt]: 	Test 700/1152. loss: 2.729, 0.1262 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 04:25:21 visual_prompt]: 	Test 800/1152. loss: 2.907, 0.0958 s / batch. (data: 4.32e-05)max mem: 17.22454 GB 
[09/19 04:25:37 visual_prompt]: 	Test 900/1152. loss: 2.864, 0.1435 s / batch. (data: 3.31e-02)max mem: 17.22454 GB 
[09/19 04:25:53 visual_prompt]: 	Test 1000/1152. loss: 2.901, 0.1158 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 04:26:09 visual_prompt]: 	Test 1100/1152. loss: 2.854, 0.1090 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 04:26:21 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1083, average loss: 2.8131
[09/19 04:26:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.86	top5: 39.95	
[09/19 04:26:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/19 04:26:32 visual_prompt]: Epoch 62 / 100: avg data time: 2.18e-01, avg batch time: 0.4459, average train loss: 2.7910
[09/19 04:26:39 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.0877, average loss: 2.6966
[09/19 04:26:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.50	top5: 48.00	
[09/19 04:26:59 visual_prompt]: 	Test 100/1152. loss: 2.767, 0.1035 s / batch. (data: 6.69e-03)max mem: 17.22454 GB 
[09/19 04:27:15 visual_prompt]: 	Test 200/1152. loss: 2.896, 0.1638 s / batch. (data: 2.33e-02)max mem: 17.22454 GB 
[09/19 04:27:31 visual_prompt]: 	Test 300/1152. loss: 3.094, 0.1079 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/19 04:27:48 visual_prompt]: 	Test 400/1152. loss: 2.910, 0.1040 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 04:28:04 visual_prompt]: 	Test 500/1152. loss: 2.772, 0.1079 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/19 04:28:20 visual_prompt]: 	Test 600/1152. loss: 2.941, 0.0996 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 04:28:36 visual_prompt]: 	Test 700/1152. loss: 2.838, 0.1235 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 04:28:52 visual_prompt]: 	Test 800/1152. loss: 2.940, 0.1253 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 04:29:08 visual_prompt]: 	Test 900/1152. loss: 2.745, 0.1422 s / batch. (data: 9.48e-03)max mem: 17.22454 GB 
[09/19 04:29:25 visual_prompt]: 	Test 1000/1152. loss: 2.818, 0.1036 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 04:29:41 visual_prompt]: 	Test 1100/1152. loss: 2.857, 0.1158 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 04:29:53 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1089, average loss: 2.8494
[09/19 04:29:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.23	top5: 38.20	
[09/19 04:29:53 visual_prompt]: Best epoch 62: best metric: 0.155
[09/19 04:29:53 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/19 04:30:03 visual_prompt]: Epoch 63 / 100: avg data time: 2.36e-01, avg batch time: 0.4588, average train loss: 2.7542
[09/19 04:30:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0943, average loss: 2.8731
[09/19 04:30:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 40.50	
[09/19 04:30:30 visual_prompt]: 	Test 100/1152. loss: 2.873, 0.0983 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 04:30:47 visual_prompt]: 	Test 200/1152. loss: 2.958, 0.1426 s / batch. (data: 1.89e-02)max mem: 17.22454 GB 
[09/19 04:31:04 visual_prompt]: 	Test 300/1152. loss: 2.806, 0.1160 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 04:31:20 visual_prompt]: 	Test 400/1152. loss: 2.814, 0.1455 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 04:31:36 visual_prompt]: 	Test 500/1152. loss: 2.749, 0.1107 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 04:31:52 visual_prompt]: 	Test 600/1152. loss: 2.890, 0.1087 s / batch. (data: 8.01e-03)max mem: 17.22454 GB 
[09/19 04:32:09 visual_prompt]: 	Test 700/1152. loss: 2.842, 0.1080 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 04:32:25 visual_prompt]: 	Test 800/1152. loss: 2.849, 0.1106 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 04:32:41 visual_prompt]: 	Test 900/1152. loss: 3.049, 0.0958 s / batch. (data: 2.98e-05)max mem: 17.22454 GB 
[09/19 04:32:57 visual_prompt]: 	Test 1000/1152. loss: 2.799, 0.0998 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 04:33:13 visual_prompt]: 	Test 1100/1152. loss: 2.945, 0.0986 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 04:33:25 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1086, average loss: 2.8655
[09/19 04:33:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.79	top5: 39.76	
[09/19 04:33:25 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/19 04:33:36 visual_prompt]: Epoch 64 / 100: avg data time: 2.20e-01, avg batch time: 0.4500, average train loss: 2.7724
[09/19 04:33:43 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0887, average loss: 2.5970
[09/19 04:33:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.50	top5: 56.00	
[09/19 04:34:03 visual_prompt]: 	Test 100/1152. loss: 2.620, 0.1103 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/19 04:34:19 visual_prompt]: 	Test 200/1152. loss: 2.668, 0.0946 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 04:34:36 visual_prompt]: 	Test 300/1152. loss: 2.799, 0.0973 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 04:34:52 visual_prompt]: 	Test 400/1152. loss: 2.748, 0.0945 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 04:35:08 visual_prompt]: 	Test 500/1152. loss: 2.573, 0.1118 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 04:35:25 visual_prompt]: 	Test 600/1152. loss: 2.648, 0.1301 s / batch. (data: 7.16e-03)max mem: 17.22454 GB 
[09/19 04:35:41 visual_prompt]: 	Test 700/1152. loss: 2.723, 0.1065 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 04:35:57 visual_prompt]: 	Test 800/1152. loss: 2.633, 0.0950 s / batch. (data: 3.27e-05)max mem: 17.22454 GB 
[09/19 04:36:13 visual_prompt]: 	Test 900/1152. loss: 2.711, 0.1179 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 04:36:29 visual_prompt]: 	Test 1000/1152. loss: 2.633, 0.1144 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 04:36:45 visual_prompt]: 	Test 1100/1152. loss: 2.789, 0.0990 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 04:36:58 visual_prompt]: Inference (test):avg data time: 1.55e-03, avg batch time: 0.1083, average loss: 2.6967
[09/19 04:36:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.19	top5: 47.89	
[09/19 04:36:58 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/19 04:37:08 visual_prompt]: Epoch 65 / 100: avg data time: 2.24e-01, avg batch time: 0.4533, average train loss: 2.7327
[09/19 04:37:15 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.0878, average loss: 2.6586
[09/19 04:37:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.50	top5: 42.00	
[09/19 04:37:35 visual_prompt]: 	Test 100/1152. loss: 2.769, 0.1079 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 04:37:52 visual_prompt]: 	Test 200/1152. loss: 2.769, 0.1116 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 04:38:08 visual_prompt]: 	Test 300/1152. loss: 2.658, 0.1084 s / batch. (data: 9.87e-05)max mem: 17.22454 GB 
[09/19 04:38:24 visual_prompt]: 	Test 400/1152. loss: 2.732, 0.0966 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 04:38:41 visual_prompt]: 	Test 500/1152. loss: 2.674, 0.1154 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 04:38:57 visual_prompt]: 	Test 600/1152. loss: 2.728, 0.1118 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 04:39:13 visual_prompt]: 	Test 700/1152. loss: 2.647, 0.1159 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 04:39:29 visual_prompt]: 	Test 800/1152. loss: 2.637, 0.1039 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 04:39:45 visual_prompt]: 	Test 900/1152. loss: 2.777, 0.0956 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 04:40:01 visual_prompt]: 	Test 1000/1152. loss: 2.674, 0.1145 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/19 04:40:18 visual_prompt]: 	Test 1100/1152. loss: 2.743, 0.1010 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/19 04:40:30 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1090, average loss: 2.7010
[09/19 04:40:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.53	top5: 44.17	
[09/19 04:40:30 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/19 04:40:40 visual_prompt]: Epoch 66 / 100: avg data time: 2.24e-01, avg batch time: 0.4513, average train loss: 2.7203
[09/19 04:40:47 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.0926, average loss: 2.6596
[09/19 04:40:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.00	top5: 46.50	
[09/19 04:41:07 visual_prompt]: 	Test 100/1152. loss: 2.813, 0.1029 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 04:41:23 visual_prompt]: 	Test 200/1152. loss: 2.659, 0.1135 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 04:41:40 visual_prompt]: 	Test 300/1152. loss: 2.775, 0.0991 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 04:41:56 visual_prompt]: 	Test 400/1152. loss: 2.884, 0.1467 s / batch. (data: 4.20e-05)max mem: 17.22454 GB 
[09/19 04:42:13 visual_prompt]: 	Test 500/1152. loss: 2.598, 0.1403 s / batch. (data: 4.78e-03)max mem: 17.22454 GB 
[09/19 04:42:29 visual_prompt]: 	Test 600/1152. loss: 2.661, 0.1128 s / batch. (data: 8.17e-03)max mem: 17.22454 GB 
[09/19 04:42:45 visual_prompt]: 	Test 700/1152. loss: 2.653, 0.1036 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:43:01 visual_prompt]: 	Test 800/1152. loss: 2.641, 0.0973 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 04:43:18 visual_prompt]: 	Test 900/1152. loss: 2.818, 0.1179 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 04:43:33 visual_prompt]: 	Test 1000/1152. loss: 2.768, 0.1181 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 04:43:50 visual_prompt]: 	Test 1100/1152. loss: 2.719, 0.1161 s / batch. (data: 1.16e-02)max mem: 17.22454 GB 
[09/19 04:44:02 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1091, average loss: 2.7324
[09/19 04:44:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.64	top5: 43.76	
[09/19 04:44:02 visual_prompt]: Best epoch 66: best metric: 0.160
[09/19 04:44:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/19 04:44:13 visual_prompt]: Epoch 67 / 100: avg data time: 2.28e-01, avg batch time: 0.4553, average train loss: 2.6822
[09/19 04:44:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.0960, average loss: 2.6158
[09/19 04:44:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.00	top5: 53.00	
[09/19 04:44:40 visual_prompt]: 	Test 100/1152. loss: 2.646, 0.1241 s / batch. (data: 3.91e-05)max mem: 17.22454 GB 
[09/19 04:44:56 visual_prompt]: 	Test 200/1152. loss: 2.774, 0.0970 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 04:45:13 visual_prompt]: 	Test 300/1152. loss: 2.694, 0.1046 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 04:45:29 visual_prompt]: 	Test 400/1152. loss: 2.750, 0.1079 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 04:45:46 visual_prompt]: 	Test 500/1152. loss: 2.552, 0.1127 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 04:46:02 visual_prompt]: 	Test 600/1152. loss: 2.665, 0.1014 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:46:19 visual_prompt]: 	Test 700/1152. loss: 2.687, 0.0981 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 04:46:35 visual_prompt]: 	Test 800/1152. loss: 2.589, 0.0974 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:46:51 visual_prompt]: 	Test 900/1152. loss: 2.791, 0.0999 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 04:47:07 visual_prompt]: 	Test 1000/1152. loss: 2.655, 0.1048 s / batch. (data: 7.62e-03)max mem: 17.22454 GB 
[09/19 04:47:23 visual_prompt]: 	Test 1100/1152. loss: 2.655, 0.1203 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:47:35 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1081, average loss: 2.6819
[09/19 04:47:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.31	top5: 48.05	
[09/19 04:47:36 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/19 04:47:46 visual_prompt]: Epoch 68 / 100: avg data time: 2.31e-01, avg batch time: 0.4532, average train loss: 2.6396
[09/19 04:47:53 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.0903, average loss: 2.5444
[09/19 04:47:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.50	top5: 55.50	
[09/19 04:48:13 visual_prompt]: 	Test 100/1152. loss: 2.912, 0.1105 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 04:48:29 visual_prompt]: 	Test 200/1152. loss: 2.741, 0.1193 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 04:48:45 visual_prompt]: 	Test 300/1152. loss: 2.807, 0.1025 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 04:49:02 visual_prompt]: 	Test 400/1152. loss: 2.700, 0.1110 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 04:49:18 visual_prompt]: 	Test 500/1152. loss: 2.773, 0.1049 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 04:49:34 visual_prompt]: 	Test 600/1152. loss: 2.795, 0.1150 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 04:49:50 visual_prompt]: 	Test 700/1152. loss: 2.641, 0.1251 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/19 04:50:07 visual_prompt]: 	Test 800/1152. loss: 2.774, 0.1304 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/19 04:50:23 visual_prompt]: 	Test 900/1152. loss: 2.873, 0.1497 s / batch. (data: 3.91e-02)max mem: 17.22454 GB 
[09/19 04:50:39 visual_prompt]: 	Test 1000/1152. loss: 2.742, 0.1116 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 04:50:56 visual_prompt]: 	Test 1100/1152. loss: 2.661, 0.0999 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 04:51:08 visual_prompt]: Inference (test):avg data time: 1.97e-03, avg batch time: 0.1087, average loss: 2.7247
[09/19 04:51:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.04	top5: 45.55	
[09/19 04:51:08 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/19 04:51:19 visual_prompt]: Epoch 69 / 100: avg data time: 2.41e-01, avg batch time: 0.4612, average train loss: 2.5911
[09/19 04:51:26 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.0861, average loss: 2.4240
[09/19 04:51:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.00	top5: 62.50	
[09/19 04:51:46 visual_prompt]: 	Test 100/1152. loss: 2.735, 0.1005 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:52:02 visual_prompt]: 	Test 200/1152. loss: 2.592, 0.1001 s / batch. (data: 3.12e-05)max mem: 17.22454 GB 
[09/19 04:52:18 visual_prompt]: 	Test 300/1152. loss: 2.783, 0.1199 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 04:52:35 visual_prompt]: 	Test 400/1152. loss: 2.687, 0.1083 s / batch. (data: 1.04e-02)max mem: 17.22454 GB 
[09/19 04:52:51 visual_prompt]: 	Test 500/1152. loss: 2.667, 0.1005 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 04:53:07 visual_prompt]: 	Test 600/1152. loss: 2.693, 0.1398 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 04:53:24 visual_prompt]: 	Test 700/1152. loss: 2.628, 0.0990 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 04:53:39 visual_prompt]: 	Test 800/1152. loss: 2.603, 0.1039 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 04:53:56 visual_prompt]: 	Test 900/1152. loss: 2.816, 0.1006 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 04:54:12 visual_prompt]: 	Test 1000/1152. loss: 2.679, 0.1018 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:54:28 visual_prompt]: 	Test 1100/1152. loss: 2.603, 0.1045 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 04:54:40 visual_prompt]: Inference (test):avg data time: 2.43e-03, avg batch time: 0.1093, average loss: 2.6588
[09/19 04:54:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.76	top5: 49.46	
[09/19 04:54:40 visual_prompt]: Best epoch 69: best metric: 0.190
[09/19 04:54:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/19 04:54:51 visual_prompt]: Epoch 70 / 100: avg data time: 2.27e-01, avg batch time: 0.4500, average train loss: 2.5621
[09/19 04:54:57 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.0903, average loss: 2.4968
[09/19 04:54:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.00	top5: 61.50	
[09/19 04:55:17 visual_prompt]: 	Test 100/1152. loss: 2.845, 0.1118 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 04:55:34 visual_prompt]: 	Test 200/1152. loss: 2.745, 0.1190 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 04:55:50 visual_prompt]: 	Test 300/1152. loss: 3.055, 0.1092 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 04:56:06 visual_prompt]: 	Test 400/1152. loss: 2.850, 0.1443 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 04:56:23 visual_prompt]: 	Test 500/1152. loss: 2.740, 0.0990 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 04:56:39 visual_prompt]: 	Test 600/1152. loss: 2.940, 0.1325 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 04:56:55 visual_prompt]: 	Test 700/1152. loss: 2.702, 0.0962 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 04:57:11 visual_prompt]: 	Test 800/1152. loss: 2.740, 0.1185 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 04:57:27 visual_prompt]: 	Test 900/1152. loss: 2.957, 0.1469 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 04:57:44 visual_prompt]: 	Test 1000/1152. loss: 2.743, 0.0983 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 04:58:00 visual_prompt]: 	Test 1100/1152. loss: 2.593, 0.1134 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 04:58:12 visual_prompt]: Inference (test):avg data time: 2.17e-03, avg batch time: 0.1094, average loss: 2.7455
[09/19 04:58:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.91	top5: 48.50	
[09/19 04:58:12 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/19 04:58:22 visual_prompt]: Epoch 71 / 100: avg data time: 2.29e-01, avg batch time: 0.4503, average train loss: 2.5693
[09/19 04:58:29 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0955, average loss: 2.4495
[09/19 04:58:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.00	top5: 62.50	
[09/19 04:58:49 visual_prompt]: 	Test 100/1152. loss: 2.803, 0.1105 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 04:59:06 visual_prompt]: 	Test 200/1152. loss: 2.687, 0.1131 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 04:59:22 visual_prompt]: 	Test 300/1152. loss: 2.765, 0.1439 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 04:59:38 visual_prompt]: 	Test 400/1152. loss: 2.738, 0.1171 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 04:59:55 visual_prompt]: 	Test 500/1152. loss: 2.728, 0.1170 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 05:00:11 visual_prompt]: 	Test 600/1152. loss: 2.710, 0.1117 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/19 05:00:27 visual_prompt]: 	Test 700/1152. loss: 2.719, 0.1116 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 05:00:44 visual_prompt]: 	Test 800/1152. loss: 2.654, 0.1083 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 05:00:59 visual_prompt]: 	Test 900/1152. loss: 2.776, 0.0988 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 05:01:16 visual_prompt]: 	Test 1000/1152. loss: 2.824, 0.0969 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 05:01:32 visual_prompt]: 	Test 1100/1152. loss: 2.621, 0.1038 s / batch. (data: 3.33e-03)max mem: 17.22454 GB 
[09/19 05:01:44 visual_prompt]: Inference (test):avg data time: 1.46e-03, avg batch time: 0.1077, average loss: 2.6988
[09/19 05:01:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.75	top5: 50.51	
[09/19 05:01:44 visual_prompt]: Best epoch 71: best metric: 0.220
[09/19 05:01:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/19 05:01:55 visual_prompt]: Epoch 72 / 100: avg data time: 2.25e-01, avg batch time: 0.4502, average train loss: 2.5348
[09/19 05:02:02 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.0891, average loss: 2.4571
[09/19 05:02:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.50	top5: 59.00	
[09/19 05:02:22 visual_prompt]: 	Test 100/1152. loss: 2.773, 0.1241 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 05:02:38 visual_prompt]: 	Test 200/1152. loss: 2.718, 0.1079 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 05:02:55 visual_prompt]: 	Test 300/1152. loss: 2.616, 0.1078 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 05:03:11 visual_prompt]: 	Test 400/1152. loss: 2.628, 0.1251 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 05:03:28 visual_prompt]: 	Test 500/1152. loss: 2.681, 0.1079 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/19 05:03:44 visual_prompt]: 	Test 600/1152. loss: 2.619, 0.0972 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 05:04:00 visual_prompt]: 	Test 700/1152. loss: 2.508, 0.1192 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 05:04:16 visual_prompt]: 	Test 800/1152. loss: 2.605, 0.0947 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 05:04:32 visual_prompt]: 	Test 900/1152. loss: 2.742, 0.0978 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 05:04:48 visual_prompt]: 	Test 1000/1152. loss: 2.777, 0.1005 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 05:05:04 visual_prompt]: 	Test 1100/1152. loss: 2.661, 0.0957 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 05:05:17 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1089, average loss: 2.6606
[09/19 05:05:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.54	top5: 52.75	
[09/19 05:05:17 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/19 05:05:27 visual_prompt]: Epoch 73 / 100: avg data time: 2.32e-01, avg batch time: 0.4544, average train loss: 2.4865
[09/19 05:05:34 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.0873, average loss: 2.3703
[09/19 05:05:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.00	top5: 69.00	
[09/19 05:05:54 visual_prompt]: 	Test 100/1152. loss: 2.787, 0.1356 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 05:06:10 visual_prompt]: 	Test 200/1152. loss: 2.741, 0.1078 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 05:06:27 visual_prompt]: 	Test 300/1152. loss: 2.665, 0.1424 s / batch. (data: 6.16e-03)max mem: 17.22454 GB 
[09/19 05:06:43 visual_prompt]: 	Test 400/1152. loss: 2.642, 0.1161 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 05:07:00 visual_prompt]: 	Test 500/1152. loss: 2.625, 0.1065 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 05:07:16 visual_prompt]: 	Test 600/1152. loss: 2.552, 0.1092 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 05:07:32 visual_prompt]: 	Test 700/1152. loss: 2.503, 0.0999 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 05:07:48 visual_prompt]: 	Test 800/1152. loss: 2.539, 0.0951 s / batch. (data: 6.58e-05)max mem: 17.22454 GB 
[09/19 05:08:04 visual_prompt]: 	Test 900/1152. loss: 2.749, 0.1150 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 05:08:20 visual_prompt]: 	Test 1000/1152. loss: 2.749, 0.0950 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 05:08:36 visual_prompt]: 	Test 1100/1152. loss: 2.642, 0.1177 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 05:08:49 visual_prompt]: Inference (test):avg data time: 1.50e-03, avg batch time: 0.1089, average loss: 2.6716
[09/19 05:08:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.21	top5: 53.63	
[09/19 05:08:49 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/19 05:08:59 visual_prompt]: Epoch 74 / 100: avg data time: 2.34e-01, avg batch time: 0.4548, average train loss: 2.4528
[09/19 05:09:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.0941, average loss: 2.3404
[09/19 05:09:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.50	top5: 66.00	
[09/19 05:09:26 visual_prompt]: 	Test 100/1152. loss: 2.701, 0.1100 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 05:09:43 visual_prompt]: 	Test 200/1152. loss: 2.613, 0.1279 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 05:09:59 visual_prompt]: 	Test 300/1152. loss: 2.647, 0.0950 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 05:10:15 visual_prompt]: 	Test 400/1152. loss: 2.647, 0.1178 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 05:10:32 visual_prompt]: 	Test 500/1152. loss: 2.589, 0.1096 s / batch. (data: 7.08e-05)max mem: 17.22454 GB 
[09/19 05:10:48 visual_prompt]: 	Test 600/1152. loss: 2.714, 0.1148 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 05:11:04 visual_prompt]: 	Test 700/1152. loss: 2.602, 0.1112 s / batch. (data: 6.94e-05)max mem: 17.22454 GB 
[09/19 05:11:20 visual_prompt]: 	Test 800/1152. loss: 2.499, 0.0992 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 05:11:36 visual_prompt]: 	Test 900/1152. loss: 2.730, 0.1223 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 05:11:52 visual_prompt]: 	Test 1000/1152. loss: 2.696, 0.1038 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/19 05:12:08 visual_prompt]: 	Test 1100/1152. loss: 2.592, 0.0944 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 05:12:20 visual_prompt]: Inference (test):avg data time: 2.06e-03, avg batch time: 0.1087, average loss: 2.6534
[09/19 05:12:21 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.20	top5: 51.57	
[09/19 05:12:21 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/19 05:12:31 visual_prompt]: Epoch 75 / 100: avg data time: 2.34e-01, avg batch time: 0.4627, average train loss: 2.4115
[09/19 05:12:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0889, average loss: 2.2501
[09/19 05:12:38 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.00	top5: 73.50	
[09/19 05:12:58 visual_prompt]: 	Test 100/1152. loss: 2.716, 0.1060 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 05:13:14 visual_prompt]: 	Test 200/1152. loss: 2.546, 0.1198 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/19 05:13:31 visual_prompt]: 	Test 300/1152. loss: 2.652, 0.0980 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 05:13:47 visual_prompt]: 	Test 400/1152. loss: 2.595, 0.1076 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 05:14:03 visual_prompt]: 	Test 500/1152. loss: 2.484, 0.1050 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 05:14:20 visual_prompt]: 	Test 600/1152. loss: 2.820, 0.0944 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 05:14:35 visual_prompt]: 	Test 700/1152. loss: 2.664, 0.0971 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 05:14:51 visual_prompt]: 	Test 800/1152. loss: 2.443, 0.0979 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 05:15:08 visual_prompt]: 	Test 900/1152. loss: 2.788, 0.0995 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 05:15:24 visual_prompt]: 	Test 1000/1152. loss: 2.639, 0.0965 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 05:15:40 visual_prompt]: 	Test 1100/1152. loss: 2.496, 0.0961 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 05:15:53 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1082, average loss: 2.6189
[09/19 05:15:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.10	top5: 54.31	
[09/19 05:15:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/19 05:16:03 visual_prompt]: Epoch 76 / 100: avg data time: 2.31e-01, avg batch time: 0.4529, average train loss: 2.3897
[09/19 05:16:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.0924, average loss: 2.3360
[09/19 05:16:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.50	top5: 67.00	
[09/19 05:16:30 visual_prompt]: 	Test 100/1152. loss: 2.726, 0.1079 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 05:16:46 visual_prompt]: 	Test 200/1152. loss: 2.775, 0.1234 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 05:17:02 visual_prompt]: 	Test 300/1152. loss: 2.492, 0.1070 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 05:17:19 visual_prompt]: 	Test 400/1152. loss: 2.619, 0.0998 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 05:17:35 visual_prompt]: 	Test 500/1152. loss: 2.731, 0.1020 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 05:17:51 visual_prompt]: 	Test 600/1152. loss: 2.580, 0.0964 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 05:18:07 visual_prompt]: 	Test 700/1152. loss: 2.634, 0.0958 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 05:18:24 visual_prompt]: 	Test 800/1152. loss: 2.573, 0.1199 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 05:18:40 visual_prompt]: 	Test 900/1152. loss: 2.767, 0.1067 s / batch. (data: 9.51e-03)max mem: 17.22454 GB 
[09/19 05:18:56 visual_prompt]: 	Test 1000/1152. loss: 2.754, 0.1040 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 05:19:12 visual_prompt]: 	Test 1100/1152. loss: 2.551, 0.0962 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 05:19:25 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1088, average loss: 2.6788
[09/19 05:19:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.62	top5: 54.29	
[09/19 05:19:25 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/19 05:19:36 visual_prompt]: Epoch 77 / 100: avg data time: 2.27e-01, avg batch time: 0.4520, average train loss: 2.3405
[09/19 05:19:42 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.0869, average loss: 2.2338
[09/19 05:19:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.50	top5: 76.50	
[09/19 05:20:03 visual_prompt]: 	Test 100/1152. loss: 2.552, 0.0997 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 05:20:19 visual_prompt]: 	Test 200/1152. loss: 2.481, 0.1104 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 05:20:35 visual_prompt]: 	Test 300/1152. loss: 2.468, 0.1076 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 05:20:52 visual_prompt]: 	Test 400/1152. loss: 2.594, 0.0973 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/19 05:21:08 visual_prompt]: 	Test 500/1152. loss: 2.507, 0.1039 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 05:21:24 visual_prompt]: 	Test 600/1152. loss: 2.489, 0.1033 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 05:21:41 visual_prompt]: 	Test 700/1152. loss: 2.609, 0.1078 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 05:21:57 visual_prompt]: 	Test 800/1152. loss: 2.370, 0.1438 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 05:22:13 visual_prompt]: 	Test 900/1152. loss: 2.650, 0.1055 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 05:22:29 visual_prompt]: 	Test 1000/1152. loss: 2.527, 0.1186 s / batch. (data: 6.79e-05)max mem: 17.22454 GB 
[09/19 05:22:45 visual_prompt]: 	Test 1100/1152. loss: 2.459, 0.1039 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 05:22:57 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1086, average loss: 2.5578
[09/19 05:22:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.86	top5: 56.48	
[09/19 05:22:57 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/19 05:23:07 visual_prompt]: Epoch 78 / 100: avg data time: 2.26e-01, avg batch time: 0.4526, average train loss: 2.2495
[09/19 05:23:14 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.0865, average loss: 2.0804
[09/19 05:23:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.00	top5: 80.50	
[09/19 05:23:34 visual_prompt]: 	Test 100/1152. loss: 2.546, 0.1159 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 05:23:50 visual_prompt]: 	Test 200/1152. loss: 2.479, 0.0991 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 05:24:07 visual_prompt]: 	Test 300/1152. loss: 2.620, 0.1251 s / batch. (data: 3.60e-05)max mem: 17.22454 GB 
[09/19 05:24:24 visual_prompt]: 	Test 400/1152. loss: 2.519, 0.1158 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 05:24:40 visual_prompt]: 	Test 500/1152. loss: 2.570, 0.1077 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 05:24:56 visual_prompt]: 	Test 600/1152. loss: 2.526, 0.1140 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 05:25:12 visual_prompt]: 	Test 700/1152. loss: 2.454, 0.1342 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/19 05:25:28 visual_prompt]: 	Test 800/1152. loss: 2.529, 0.1138 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 05:25:44 visual_prompt]: 	Test 900/1152. loss: 2.545, 0.1062 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 05:26:00 visual_prompt]: 	Test 1000/1152. loss: 2.393, 0.1215 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 05:26:16 visual_prompt]: 	Test 1100/1152. loss: 2.472, 0.1133 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 05:26:29 visual_prompt]: Inference (test):avg data time: 1.71e-03, avg batch time: 0.1091, average loss: 2.5163
[09/19 05:26:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.81	top5: 58.75	
[09/19 05:26:29 visual_prompt]: Best epoch 78: best metric: 0.240
[09/19 05:26:29 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/19 05:26:40 visual_prompt]: Epoch 79 / 100: avg data time: 2.22e-01, avg batch time: 0.4506, average train loss: 2.2056
[09/19 05:26:47 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.0901, average loss: 2.2190
[09/19 05:26:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.00	top5: 73.50	
[09/19 05:27:07 visual_prompt]: 	Test 100/1152. loss: 2.713, 0.1077 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/19 05:27:23 visual_prompt]: 	Test 200/1152. loss: 2.568, 0.1132 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/19 05:27:40 visual_prompt]: 	Test 300/1152. loss: 2.645, 0.1165 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/19 05:27:56 visual_prompt]: 	Test 400/1152. loss: 2.645, 0.0983 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 05:28:13 visual_prompt]: 	Test 500/1152. loss: 2.563, 0.1022 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 05:28:29 visual_prompt]: 	Test 600/1152. loss: 2.643, 0.1161 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 05:28:45 visual_prompt]: 	Test 700/1152. loss: 2.661, 0.0988 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 05:29:01 visual_prompt]: 	Test 800/1152. loss: 2.507, 0.1028 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 05:29:17 visual_prompt]: 	Test 900/1152. loss: 2.732, 0.1199 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 05:29:33 visual_prompt]: 	Test 1000/1152. loss: 2.492, 0.0998 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 05:29:49 visual_prompt]: 	Test 1100/1152. loss: 2.437, 0.1036 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 05:30:02 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1087, average loss: 2.6176
[09/19 05:30:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.01	top5: 58.80	
[09/19 05:30:02 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/19 05:30:12 visual_prompt]: Epoch 80 / 100: avg data time: 2.26e-01, avg batch time: 0.4534, average train loss: 2.2021
[09/19 05:30:19 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0942, average loss: 1.9815
[09/19 05:30:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 29.50	top5: 83.00	
[09/19 05:30:39 visual_prompt]: 	Test 100/1152. loss: 2.662, 0.0980 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 05:30:56 visual_prompt]: 	Test 200/1152. loss: 2.455, 0.1159 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 05:31:13 visual_prompt]: 	Test 300/1152. loss: 2.530, 0.1011 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 05:31:29 visual_prompt]: 	Test 400/1152. loss: 2.491, 0.0999 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 05:31:45 visual_prompt]: 	Test 500/1152. loss: 2.603, 0.1079 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 05:32:01 visual_prompt]: 	Test 600/1152. loss: 2.825, 0.1086 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 05:32:18 visual_prompt]: 	Test 700/1152. loss: 2.499, 0.1026 s / batch. (data: 6.68e-05)max mem: 17.22454 GB 
[09/19 05:32:34 visual_prompt]: 	Test 800/1152. loss: 2.528, 0.1045 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/19 05:32:50 visual_prompt]: 	Test 900/1152. loss: 2.711, 0.0945 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/19 05:33:06 visual_prompt]: 	Test 1000/1152. loss: 2.681, 0.1150 s / batch. (data: 5.01e-05)max mem: 17.22454 GB 
[09/19 05:33:22 visual_prompt]: 	Test 1100/1152. loss: 2.446, 0.1099 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 05:33:34 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1088, average loss: 2.5772
[09/19 05:33:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.26	top5: 61.69	
[09/19 05:33:35 visual_prompt]: Best epoch 80: best metric: 0.295
[09/19 05:33:35 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/19 05:33:45 visual_prompt]: Epoch 81 / 100: avg data time: 2.34e-01, avg batch time: 0.4537, average train loss: 2.1388
[09/19 05:33:52 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.0905, average loss: 2.2523
[09/19 05:33:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.50	top5: 73.50	
[09/19 05:34:12 visual_prompt]: 	Test 100/1152. loss: 2.920, 0.0942 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 05:34:28 visual_prompt]: 	Test 200/1152. loss: 2.735, 0.0946 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 05:34:45 visual_prompt]: 	Test 300/1152. loss: 2.675, 0.1144 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 05:35:01 visual_prompt]: 	Test 400/1152. loss: 2.686, 0.0952 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 05:35:18 visual_prompt]: 	Test 500/1152. loss: 2.657, 0.0949 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 05:35:34 visual_prompt]: 	Test 600/1152. loss: 2.696, 0.0946 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 05:35:50 visual_prompt]: 	Test 700/1152. loss: 2.678, 0.1292 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 05:36:06 visual_prompt]: 	Test 800/1152. loss: 2.563, 0.1158 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 05:36:22 visual_prompt]: 	Test 900/1152. loss: 2.982, 0.1201 s / batch. (data: 4.20e-05)max mem: 17.22454 GB 
[09/19 05:36:38 visual_prompt]: 	Test 1000/1152. loss: 2.603, 0.0973 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 05:36:54 visual_prompt]: 	Test 1100/1152. loss: 2.791, 0.0981 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 05:37:07 visual_prompt]: Inference (test):avg data time: 1.83e-03, avg batch time: 0.1088, average loss: 2.7147
[09/19 05:37:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.70	top5: 60.53	
[09/19 05:37:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/19 05:37:17 visual_prompt]: Epoch 82 / 100: avg data time: 2.17e-01, avg batch time: 0.4491, average train loss: 2.1132
[09/19 05:37:24 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.0883, average loss: 1.8974
[09/19 05:37:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 29.00	top5: 83.50	
[09/19 05:37:44 visual_prompt]: 	Test 100/1152. loss: 2.408, 0.1398 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 05:38:01 visual_prompt]: 	Test 200/1152. loss: 2.470, 0.0999 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 05:38:17 visual_prompt]: 	Test 300/1152. loss: 2.590, 0.1080 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:38:33 visual_prompt]: 	Test 400/1152. loss: 2.365, 0.0980 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 05:38:50 visual_prompt]: 	Test 500/1152. loss: 2.322, 0.1078 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 05:39:06 visual_prompt]: 	Test 600/1152. loss: 2.592, 0.1031 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 05:39:22 visual_prompt]: 	Test 700/1152. loss: 2.355, 0.0946 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/19 05:39:38 visual_prompt]: 	Test 800/1152. loss: 2.468, 0.0943 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 05:39:54 visual_prompt]: 	Test 900/1152. loss: 2.497, 0.1338 s / batch. (data: 3.89e-02)max mem: 17.22454 GB 
[09/19 05:40:10 visual_prompt]: 	Test 1000/1152. loss: 2.280, 0.0974 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:40:27 visual_prompt]: 	Test 1100/1152. loss: 2.349, 0.1527 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 05:40:39 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1097, average loss: 2.4562
[09/19 05:40:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.74	top5: 65.62	
[09/19 05:40:40 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/19 05:40:50 visual_prompt]: Epoch 83 / 100: avg data time: 2.27e-01, avg batch time: 0.4560, average train loss: 1.9391
[09/19 05:40:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.0926, average loss: 1.7611
[09/19 05:40:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.50	top5: 89.50	
[09/19 05:41:17 visual_prompt]: 	Test 100/1152. loss: 2.477, 0.1210 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 05:41:33 visual_prompt]: 	Test 200/1152. loss: 2.437, 0.0951 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 05:41:49 visual_prompt]: 	Test 300/1152. loss: 2.559, 0.1238 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/19 05:42:06 visual_prompt]: 	Test 400/1152. loss: 2.568, 0.1046 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 05:42:23 visual_prompt]: 	Test 500/1152. loss: 2.293, 0.0968 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:42:40 visual_prompt]: 	Test 600/1152. loss: 2.599, 0.1082 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 05:42:56 visual_prompt]: 	Test 700/1152. loss: 2.519, 0.1272 s / batch. (data: 4.01e-05)max mem: 17.22454 GB 
[09/19 05:43:12 visual_prompt]: 	Test 800/1152. loss: 2.430, 0.1240 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 05:43:29 visual_prompt]: 	Test 900/1152. loss: 2.654, 0.1082 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 05:43:45 visual_prompt]: 	Test 1000/1152. loss: 2.355, 0.1226 s / batch. (data: 2.33e-02)max mem: 17.22454 GB 
[09/19 05:44:01 visual_prompt]: 	Test 1100/1152. loss: 2.412, 0.1106 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 05:44:13 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1082, average loss: 2.4980
[09/19 05:44:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.34	top5: 67.93	
[09/19 05:44:13 visual_prompt]: Best epoch 83: best metric: 0.315
[09/19 05:44:13 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/19 05:44:24 visual_prompt]: Epoch 84 / 100: avg data time: 2.32e-01, avg batch time: 0.4534, average train loss: 1.9164
[09/19 05:44:30 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.0907, average loss: 1.8073
[09/19 05:44:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 33.50	top5: 86.50	
[09/19 05:44:50 visual_prompt]: 	Test 100/1152. loss: 2.672, 0.1079 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 05:45:07 visual_prompt]: 	Test 200/1152. loss: 2.485, 0.1079 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 05:45:23 visual_prompt]: 	Test 300/1152. loss: 2.731, 0.0984 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 05:45:39 visual_prompt]: 	Test 400/1152. loss: 2.713, 0.1288 s / batch. (data: 8.19e-03)max mem: 17.22454 GB 
[09/19 05:45:56 visual_prompt]: 	Test 500/1152. loss: 2.313, 0.1072 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 05:46:12 visual_prompt]: 	Test 600/1152. loss: 2.497, 0.1140 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 05:46:28 visual_prompt]: 	Test 700/1152. loss: 2.373, 0.0993 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 05:46:45 visual_prompt]: 	Test 800/1152. loss: 2.364, 0.0983 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 05:47:01 visual_prompt]: 	Test 900/1152. loss: 2.739, 0.1079 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 05:47:17 visual_prompt]: 	Test 1000/1152. loss: 2.529, 0.1331 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 05:47:33 visual_prompt]: 	Test 1100/1152. loss: 2.333, 0.1197 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 05:47:45 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1085, average loss: 2.5439
[09/19 05:47:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.20	top5: 67.07	
[09/19 05:47:46 visual_prompt]: Best epoch 84: best metric: 0.335
[09/19 05:47:46 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/19 05:47:56 visual_prompt]: Epoch 85 / 100: avg data time: 2.33e-01, avg batch time: 0.4593, average train loss: 1.7917
[09/19 05:48:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.0949, average loss: 1.5963
[09/19 05:48:03 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 41.50	top5: 91.50	
[09/19 05:48:23 visual_prompt]: 	Test 100/1152. loss: 2.714, 0.1285 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 05:48:39 visual_prompt]: 	Test 200/1152. loss: 2.413, 0.0999 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 05:48:56 visual_prompt]: 	Test 300/1152. loss: 2.614, 0.0982 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 05:49:12 visual_prompt]: 	Test 400/1152. loss: 2.689, 0.0959 s / batch. (data: 3.00e-05)max mem: 17.22454 GB 
[09/19 05:49:28 visual_prompt]: 	Test 500/1152. loss: 2.229, 0.0979 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 05:49:44 visual_prompt]: 	Test 600/1152. loss: 2.661, 0.1077 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 05:50:01 visual_prompt]: 	Test 700/1152. loss: 2.388, 0.0967 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 05:50:16 visual_prompt]: 	Test 800/1152. loss: 2.236, 0.0977 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 05:50:33 visual_prompt]: 	Test 900/1152. loss: 2.824, 0.1008 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 05:50:49 visual_prompt]: 	Test 1000/1152. loss: 2.289, 0.1148 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 05:51:05 visual_prompt]: 	Test 1100/1152. loss: 2.253, 0.1123 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 05:51:17 visual_prompt]: Inference (test):avg data time: 1.64e-03, avg batch time: 0.1084, average loss: 2.5406
[09/19 05:51:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.84	top5: 70.39	
[09/19 05:51:17 visual_prompt]: Best epoch 85: best metric: 0.415
[09/19 05:51:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/19 05:51:28 visual_prompt]: Epoch 86 / 100: avg data time: 2.32e-01, avg batch time: 0.4554, average train loss: 1.7655
[09/19 05:51:34 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.0884, average loss: 1.8022
[09/19 05:51:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 34.00	top5: 89.00	
[09/19 05:51:54 visual_prompt]: 	Test 100/1152. loss: 2.840, 0.1612 s / batch. (data: 7.16e-03)max mem: 17.22454 GB 
[09/19 05:52:11 visual_prompt]: 	Test 200/1152. loss: 2.588, 0.1227 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 05:52:27 visual_prompt]: 	Test 300/1152. loss: 2.718, 0.0996 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 05:52:43 visual_prompt]: 	Test 400/1152. loss: 2.634, 0.0990 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 05:52:59 visual_prompt]: 	Test 500/1152. loss: 2.756, 0.0997 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 05:53:16 visual_prompt]: 	Test 600/1152. loss: 2.683, 0.1028 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 05:53:32 visual_prompt]: 	Test 700/1152. loss: 2.754, 0.1159 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 05:53:48 visual_prompt]: 	Test 800/1152. loss: 2.616, 0.1119 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 05:54:05 visual_prompt]: 	Test 900/1152. loss: 2.847, 0.1077 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 05:54:21 visual_prompt]: 	Test 1000/1152. loss: 2.372, 0.1249 s / batch. (data: 2.02e-02)max mem: 17.22454 GB 
[09/19 05:54:38 visual_prompt]: 	Test 1100/1152. loss: 2.667, 0.0958 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 05:54:50 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1094, average loss: 2.6789
[09/19 05:54:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.24	top5: 67.09	
[09/19 05:54:50 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/19 05:55:01 visual_prompt]: Epoch 87 / 100: avg data time: 2.25e-01, avg batch time: 0.4618, average train loss: 1.7528
[09/19 05:55:08 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.0906, average loss: 1.4326
[09/19 05:55:08 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 51.00	top5: 95.00	
[09/19 05:55:28 visual_prompt]: 	Test 100/1152. loss: 2.490, 0.1023 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 05:55:44 visual_prompt]: 	Test 200/1152. loss: 2.113, 0.0982 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 05:56:01 visual_prompt]: 	Test 300/1152. loss: 2.354, 0.1289 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 05:56:17 visual_prompt]: 	Test 400/1152. loss: 2.309, 0.0976 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 05:56:33 visual_prompt]: 	Test 500/1152. loss: 2.296, 0.0970 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 05:56:50 visual_prompt]: 	Test 600/1152. loss: 2.487, 0.1131 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 05:57:06 visual_prompt]: 	Test 700/1152. loss: 2.188, 0.1559 s / batch. (data: 2.19e-02)max mem: 17.22454 GB 
[09/19 05:57:21 visual_prompt]: 	Test 800/1152. loss: 2.216, 0.1003 s / batch. (data: 4.22e-05)max mem: 17.22454 GB 
[09/19 05:57:38 visual_prompt]: 	Test 900/1152. loss: 2.615, 0.1038 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 05:57:54 visual_prompt]: 	Test 1000/1152. loss: 2.219, 0.1124 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 05:58:10 visual_prompt]: 	Test 1100/1152. loss: 2.206, 0.1109 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 05:58:22 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1092, average loss: 2.3322
[09/19 05:58:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 23.35	top5: 75.93	
[09/19 05:58:22 visual_prompt]: Best epoch 87: best metric: 0.510
[09/19 05:58:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/19 05:58:33 visual_prompt]: Epoch 88 / 100: avg data time: 2.21e-01, avg batch time: 0.4508, average train loss: 1.5494
[09/19 05:58:39 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.0903, average loss: 1.3765
[09/19 05:58:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 53.00	top5: 95.00	
[09/19 05:59:00 visual_prompt]: 	Test 100/1152. loss: 2.650, 0.0989 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 05:59:16 visual_prompt]: 	Test 200/1152. loss: 2.476, 0.1059 s / batch. (data: 7.15e-03)max mem: 17.22454 GB 
[09/19 05:59:32 visual_prompt]: 	Test 300/1152. loss: 2.876, 0.0953 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 05:59:49 visual_prompt]: 	Test 400/1152. loss: 2.700, 0.0999 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 06:00:06 visual_prompt]: 	Test 500/1152. loss: 2.202, 0.1248 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 06:00:22 visual_prompt]: 	Test 600/1152. loss: 2.528, 0.1049 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 06:00:38 visual_prompt]: 	Test 700/1152. loss: 2.588, 0.1198 s / batch. (data: 7.18e-03)max mem: 17.22454 GB 
[09/19 06:00:54 visual_prompt]: 	Test 800/1152. loss: 2.478, 0.0999 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 06:01:11 visual_prompt]: 	Test 900/1152. loss: 2.938, 0.1294 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/19 06:01:27 visual_prompt]: 	Test 1000/1152. loss: 2.487, 0.1204 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/19 06:01:43 visual_prompt]: 	Test 1100/1152. loss: 2.487, 0.0989 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 06:01:55 visual_prompt]: Inference (test):avg data time: 1.78e-03, avg batch time: 0.1087, average loss: 2.5963
[09/19 06:01:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 23.91	top5: 74.64	
[09/19 06:01:55 visual_prompt]: Best epoch 88: best metric: 0.530
[09/19 06:01:55 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/19 06:02:05 visual_prompt]: Epoch 89 / 100: avg data time: 2.24e-01, avg batch time: 0.4516, average train loss: 1.4829
[09/19 06:02:12 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.0868, average loss: 1.2072
[09/19 06:02:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 52.50	top5: 97.50	
[09/19 06:02:32 visual_prompt]: 	Test 100/1152. loss: 2.664, 0.1007 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 06:02:48 visual_prompt]: 	Test 200/1152. loss: 2.439, 0.0968 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 06:03:05 visual_prompt]: 	Test 300/1152. loss: 2.854, 0.1092 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 06:03:21 visual_prompt]: 	Test 400/1152. loss: 2.561, 0.1114 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 06:03:37 visual_prompt]: 	Test 500/1152. loss: 2.522, 0.1015 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 06:03:54 visual_prompt]: 	Test 600/1152. loss: 2.402, 0.1146 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 06:04:10 visual_prompt]: 	Test 700/1152. loss: 2.544, 0.0983 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 06:04:26 visual_prompt]: 	Test 800/1152. loss: 2.406, 0.0997 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 06:04:42 visual_prompt]: 	Test 900/1152. loss: 2.766, 0.1080 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 06:04:58 visual_prompt]: 	Test 1000/1152. loss: 2.435, 0.1010 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 06:05:14 visual_prompt]: 	Test 1100/1152. loss: 2.239, 0.1362 s / batch. (data: 3.46e-05)max mem: 17.22454 GB 
[09/19 06:05:27 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1086, average loss: 2.5995
[09/19 06:05:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.49	top5: 76.64	
[09/19 06:05:27 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/19 06:05:37 visual_prompt]: Epoch 90 / 100: avg data time: 2.22e-01, avg batch time: 0.4492, average train loss: 1.3509
[09/19 06:05:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.0873, average loss: 1.1420
[09/19 06:05:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 58.00	top5: 97.00	
[09/19 06:06:04 visual_prompt]: 	Test 100/1152. loss: 2.533, 0.1078 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/19 06:06:21 visual_prompt]: 	Test 200/1152. loss: 2.441, 0.1319 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/19 06:06:37 visual_prompt]: 	Test 300/1152. loss: 2.709, 0.1077 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 06:06:54 visual_prompt]: 	Test 400/1152. loss: 2.520, 0.1008 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 06:07:10 visual_prompt]: 	Test 500/1152. loss: 2.559, 0.1181 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 06:07:27 visual_prompt]: 	Test 600/1152. loss: 2.383, 0.0990 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 06:07:42 visual_prompt]: 	Test 700/1152. loss: 2.462, 0.1220 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 06:07:58 visual_prompt]: 	Test 800/1152. loss: 2.449, 0.1319 s / batch. (data: 4.05e-05)max mem: 17.22454 GB 
[09/19 06:08:14 visual_prompt]: 	Test 900/1152. loss: 2.868, 0.1015 s / batch. (data: 5.47e-03)max mem: 17.22454 GB 
[09/19 06:08:30 visual_prompt]: 	Test 1000/1152. loss: 2.417, 0.1320 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 06:08:47 visual_prompt]: 	Test 1100/1152. loss: 2.258, 0.1828 s / batch. (data: 3.43e-05)max mem: 17.22454 GB 
[09/19 06:08:59 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1093, average loss: 2.6090
[09/19 06:09:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.52	top5: 76.64	
[09/19 06:09:00 visual_prompt]: Best epoch 90: best metric: 0.580
[09/19 06:09:00 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/19 06:09:10 visual_prompt]: Epoch 91 / 100: avg data time: 2.28e-01, avg batch time: 0.4518, average train loss: 1.3002
[09/19 06:09:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.0909, average loss: 1.1584
[09/19 06:09:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 58.50	top5: 99.00	
[09/19 06:09:36 visual_prompt]: 	Test 100/1152. loss: 2.930, 0.1029 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 06:09:53 visual_prompt]: 	Test 200/1152. loss: 2.481, 0.0971 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 06:10:10 visual_prompt]: 	Test 300/1152. loss: 3.114, 0.1100 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 06:10:26 visual_prompt]: 	Test 400/1152. loss: 2.632, 0.1165 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 06:10:42 visual_prompt]: 	Test 500/1152. loss: 2.733, 0.0943 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/19 06:10:58 visual_prompt]: 	Test 600/1152. loss: 2.820, 0.0949 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/19 06:11:14 visual_prompt]: 	Test 700/1152. loss: 2.792, 0.1137 s / batch. (data: 9.07e-03)max mem: 17.22454 GB 
[09/19 06:11:30 visual_prompt]: 	Test 800/1152. loss: 2.232, 0.0990 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 06:11:47 visual_prompt]: 	Test 900/1152. loss: 3.010, 0.0970 s / batch. (data: 8.87e-05)max mem: 17.22454 GB 
[09/19 06:12:03 visual_prompt]: 	Test 1000/1152. loss: 2.486, 0.0945 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 06:12:19 visual_prompt]: 	Test 1100/1152. loss: 2.373, 0.0987 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 06:12:31 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1086, average loss: 2.7415
[09/19 06:12:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.03	top5: 76.73	
[09/19 06:12:31 visual_prompt]: Best epoch 91: best metric: 0.585
[09/19 06:12:31 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/19 06:12:41 visual_prompt]: Epoch 92 / 100: avg data time: 2.21e-01, avg batch time: 0.4448, average train loss: 1.1894
[09/19 06:12:48 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.0891, average loss: 1.0744
[09/19 06:12:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 64.00	top5: 98.50	
[09/19 06:13:08 visual_prompt]: 	Test 100/1152. loss: 2.831, 0.0986 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/19 06:13:25 visual_prompt]: 	Test 200/1152. loss: 2.493, 0.1240 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:13:41 visual_prompt]: 	Test 300/1152. loss: 3.030, 0.0958 s / batch. (data: 4.17e-05)max mem: 17.22454 GB 
[09/19 06:13:57 visual_prompt]: 	Test 400/1152. loss: 2.608, 0.1038 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 06:14:13 visual_prompt]: 	Test 500/1152. loss: 2.834, 0.1079 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 06:14:30 visual_prompt]: 	Test 600/1152. loss: 2.558, 0.1233 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 06:14:46 visual_prompt]: 	Test 700/1152. loss: 2.890, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 06:15:02 visual_prompt]: 	Test 800/1152. loss: 2.491, 0.0950 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 06:15:18 visual_prompt]: 	Test 900/1152. loss: 3.034, 0.1082 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/19 06:15:35 visual_prompt]: 	Test 1000/1152. loss: 2.536, 0.1030 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 06:15:51 visual_prompt]: 	Test 1100/1152. loss: 2.635, 0.1085 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 06:16:03 visual_prompt]: Inference (test):avg data time: 1.52e-03, avg batch time: 0.1084, average loss: 2.7681
[09/19 06:16:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 26.44	top5: 77.73	
[09/19 06:16:04 visual_prompt]: Best epoch 92: best metric: 0.640
[09/19 06:16:04 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/19 06:16:14 visual_prompt]: Epoch 93 / 100: avg data time: 2.29e-01, avg batch time: 0.4559, average train loss: 1.1077
[09/19 06:16:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.0870, average loss: 0.9238
[09/19 06:16:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 65.50	top5: 99.00	
[09/19 06:16:40 visual_prompt]: 	Test 100/1152. loss: 2.932, 0.1028 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 06:16:57 visual_prompt]: 	Test 200/1152. loss: 2.605, 0.0996 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:17:13 visual_prompt]: 	Test 300/1152. loss: 2.984, 0.1079 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/19 06:17:29 visual_prompt]: 	Test 400/1152. loss: 2.498, 0.1059 s / batch. (data: 9.47e-03)max mem: 17.22454 GB 
[09/19 06:17:46 visual_prompt]: 	Test 500/1152. loss: 2.919, 0.1038 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 06:18:02 visual_prompt]: 	Test 600/1152. loss: 2.986, 0.1035 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 06:18:18 visual_prompt]: 	Test 700/1152. loss: 2.684, 0.1123 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 06:18:34 visual_prompt]: 	Test 800/1152. loss: 2.482, 0.0983 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 06:18:51 visual_prompt]: 	Test 900/1152. loss: 3.135, 0.1125 s / batch. (data: 8.46e-05)max mem: 17.22454 GB 
[09/19 06:19:07 visual_prompt]: 	Test 1000/1152. loss: 2.612, 0.0978 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 06:19:23 visual_prompt]: 	Test 1100/1152. loss: 2.339, 0.0946 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 06:19:35 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1087, average loss: 2.7979
[09/19 06:19:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 27.20	top5: 80.00	
[09/19 06:19:36 visual_prompt]: Best epoch 93: best metric: 0.655
[09/19 06:19:36 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/19 06:19:46 visual_prompt]: Epoch 94 / 100: avg data time: 2.25e-01, avg batch time: 0.4506, average train loss: 0.9868
[09/19 06:19:53 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.0927, average loss: 0.9825
[09/19 06:19:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 61.50	top5: 100.00	
[09/19 06:20:12 visual_prompt]: 	Test 100/1152. loss: 3.243, 0.1246 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 06:20:29 visual_prompt]: 	Test 200/1152. loss: 2.747, 0.1222 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 06:20:45 visual_prompt]: 	Test 300/1152. loss: 3.290, 0.1165 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 06:21:02 visual_prompt]: 	Test 400/1152. loss: 2.653, 0.1056 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 06:21:18 visual_prompt]: 	Test 500/1152. loss: 2.865, 0.1128 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 06:21:34 visual_prompt]: 	Test 600/1152. loss: 3.175, 0.1066 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/19 06:21:50 visual_prompt]: 	Test 700/1152. loss: 2.981, 0.0999 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 06:22:06 visual_prompt]: 	Test 800/1152. loss: 2.624, 0.1085 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 06:22:22 visual_prompt]: 	Test 900/1152. loss: 3.041, 0.1005 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 06:22:39 visual_prompt]: 	Test 1000/1152. loss: 2.802, 0.1105 s / batch. (data: 1.86e-04)max mem: 17.22454 GB 
[09/19 06:22:55 visual_prompt]: 	Test 1100/1152. loss: 2.433, 0.0958 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 06:23:07 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1091, average loss: 2.9448
[09/19 06:23:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 26.85	top5: 78.58	
[09/19 06:23:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/19 06:23:18 visual_prompt]: Epoch 95 / 100: avg data time: 2.21e-01, avg batch time: 0.4514, average train loss: 0.9405
[09/19 06:23:24 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0866, average loss: 0.8247
[09/19 06:23:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 69.50	top5: 99.50	
[09/19 06:23:44 visual_prompt]: 	Test 100/1152. loss: 2.855, 0.0995 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/19 06:24:01 visual_prompt]: 	Test 200/1152. loss: 2.794, 0.1029 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/19 06:24:17 visual_prompt]: 	Test 300/1152. loss: 3.228, 0.1157 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/19 06:24:33 visual_prompt]: 	Test 400/1152. loss: 3.008, 0.0945 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 06:24:50 visual_prompt]: 	Test 500/1152. loss: 3.063, 0.1212 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 06:25:06 visual_prompt]: 	Test 600/1152. loss: 2.887, 0.1130 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 06:25:22 visual_prompt]: 	Test 700/1152. loss: 3.116, 0.1169 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 06:25:38 visual_prompt]: 	Test 800/1152. loss: 2.586, 0.1027 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 06:25:54 visual_prompt]: 	Test 900/1152. loss: 3.314, 0.0953 s / batch. (data: 8.03e-05)max mem: 17.22454 GB 
[09/19 06:26:10 visual_prompt]: 	Test 1000/1152. loss: 2.908, 0.1120 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 06:26:26 visual_prompt]: 	Test 1100/1152. loss: 2.779, 0.1213 s / batch. (data: 6.25e-05)max mem: 17.22454 GB 
[09/19 06:26:38 visual_prompt]: Inference (test):avg data time: 2.10e-03, avg batch time: 0.1096, average loss: 3.0164
[09/19 06:26:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 28.46	top5: 78.73	
[09/19 06:26:38 visual_prompt]: Best epoch 95: best metric: 0.695
[09/19 06:26:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/19 06:26:49 visual_prompt]: Epoch 96 / 100: avg data time: 2.25e-01, avg batch time: 0.4543, average train loss: 0.8859
[09/19 06:26:56 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.0936, average loss: 0.7604
[09/19 06:26:56 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 71.00	top5: 99.50	
[09/19 06:27:16 visual_prompt]: 	Test 100/1152. loss: 2.751, 0.0988 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 06:27:32 visual_prompt]: 	Test 200/1152. loss: 2.969, 0.1253 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 06:27:49 visual_prompt]: 	Test 300/1152. loss: 3.350, 0.0945 s / batch. (data: 5.25e-05)max mem: 17.22454 GB 
[09/19 06:28:05 visual_prompt]: 	Test 400/1152. loss: 3.244, 0.1721 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 06:28:22 visual_prompt]: 	Test 500/1152. loss: 3.135, 0.0967 s / batch. (data: 2.11e-04)max mem: 17.22454 GB 
[09/19 06:28:39 visual_prompt]: 	Test 600/1152. loss: 3.012, 0.1004 s / batch. (data: 6.53e-05)max mem: 17.22454 GB 
[09/19 06:28:55 visual_prompt]: 	Test 700/1152. loss: 3.100, 0.1311 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 06:29:11 visual_prompt]: 	Test 800/1152. loss: 2.650, 0.0972 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 06:29:27 visual_prompt]: 	Test 900/1152. loss: 3.343, 0.0955 s / batch. (data: 5.25e-05)max mem: 17.22454 GB 
[09/19 06:29:43 visual_prompt]: 	Test 1000/1152. loss: 2.901, 0.0949 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 06:29:59 visual_prompt]: 	Test 1100/1152. loss: 2.618, 0.1235 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 06:30:12 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1087, average loss: 3.0898
[09/19 06:30:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 28.06	top5: 78.83	
[09/19 06:30:12 visual_prompt]: Best epoch 96: best metric: 0.710
[09/19 06:30:12 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/19 06:30:23 visual_prompt]: Epoch 97 / 100: avg data time: 2.37e-01, avg batch time: 0.4594, average train loss: 0.8026
[09/19 06:30:30 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0956, average loss: 0.7421
[09/19 06:30:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 73.50	top5: 100.00	
[09/19 06:30:49 visual_prompt]: 	Test 100/1152. loss: 2.949, 0.0982 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 06:31:06 visual_prompt]: 	Test 200/1152. loss: 2.842, 0.1159 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:31:22 visual_prompt]: 	Test 300/1152. loss: 3.338, 0.1107 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/19 06:31:39 visual_prompt]: 	Test 400/1152. loss: 2.955, 0.1315 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 06:31:55 visual_prompt]: 	Test 500/1152. loss: 3.215, 0.0997 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/19 06:32:11 visual_prompt]: 	Test 600/1152. loss: 2.997, 0.1078 s / batch. (data: 1.04e-02)max mem: 17.22454 GB 
[09/19 06:32:27 visual_prompt]: 	Test 700/1152. loss: 3.077, 0.1078 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/19 06:32:44 visual_prompt]: 	Test 800/1152. loss: 2.556, 0.0948 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 06:33:00 visual_prompt]: 	Test 900/1152. loss: 3.247, 0.1104 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 06:33:17 visual_prompt]: 	Test 1000/1152. loss: 2.757, 0.1166 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 06:33:33 visual_prompt]: 	Test 1100/1152. loss: 2.520, 0.0975 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 06:33:45 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1081, average loss: 3.0359
[09/19 06:33:45 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 28.97	top5: 79.83	
[09/19 06:33:45 visual_prompt]: Best epoch 97: best metric: 0.735
[09/19 06:33:45 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/19 06:33:55 visual_prompt]: Epoch 98 / 100: avg data time: 2.25e-01, avg batch time: 0.4471, average train loss: 0.7606
[09/19 06:34:02 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.0865, average loss: 0.6367
[09/19 06:34:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 79.50	top5: 99.50	
[09/19 06:34:22 visual_prompt]: 	Test 100/1152. loss: 2.915, 0.0941 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 06:34:39 visual_prompt]: 	Test 200/1152. loss: 2.841, 0.0944 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 06:34:55 visual_prompt]: 	Test 300/1152. loss: 3.185, 0.0939 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/19 06:35:12 visual_prompt]: 	Test 400/1152. loss: 2.879, 0.0945 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/19 06:35:28 visual_prompt]: 	Test 500/1152. loss: 3.069, 0.0980 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 06:35:44 visual_prompt]: 	Test 600/1152. loss: 2.934, 0.1356 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 06:36:00 visual_prompt]: 	Test 700/1152. loss: 3.057, 0.0998 s / batch. (data: 9.85e-05)max mem: 17.22454 GB 
[09/19 06:36:16 visual_prompt]: 	Test 800/1152. loss: 2.601, 0.0962 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 06:36:32 visual_prompt]: 	Test 900/1152. loss: 3.504, 0.0976 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 06:36:48 visual_prompt]: 	Test 1000/1152. loss: 2.824, 0.1139 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 06:37:04 visual_prompt]: 	Test 1100/1152. loss: 2.502, 0.1039 s / batch. (data: 4.94e-03)max mem: 17.22454 GB 
[09/19 06:37:17 visual_prompt]: Inference (test):avg data time: 1.56e-03, avg batch time: 0.1076, average loss: 3.0258
[09/19 06:37:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 29.40	top5: 80.18	
[09/19 06:37:17 visual_prompt]: Best epoch 98: best metric: 0.795
[09/19 06:37:17 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/19 06:37:27 visual_prompt]: Epoch 99 / 100: avg data time: 2.21e-01, avg batch time: 0.4497, average train loss: 0.7155
[09/19 06:37:34 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.0958, average loss: 0.6512
[09/19 06:37:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 79.00	top5: 99.50	
[09/19 06:37:54 visual_prompt]: 	Test 100/1152. loss: 2.929, 0.1094 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 06:38:11 visual_prompt]: 	Test 200/1152. loss: 2.913, 0.1237 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:38:27 visual_prompt]: 	Test 300/1152. loss: 3.264, 0.1207 s / batch. (data: 2.49e-02)max mem: 17.22454 GB 
[09/19 06:38:43 visual_prompt]: 	Test 400/1152. loss: 2.957, 0.1069 s / batch. (data: 3.67e-05)max mem: 17.22454 GB 
[09/19 06:39:00 visual_prompt]: 	Test 500/1152. loss: 3.138, 0.1066 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 06:39:16 visual_prompt]: 	Test 600/1152. loss: 3.009, 0.1155 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 06:39:31 visual_prompt]: 	Test 700/1152. loss: 3.099, 0.1203 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 06:39:48 visual_prompt]: 	Test 800/1152. loss: 2.618, 0.1421 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 06:40:04 visual_prompt]: 	Test 900/1152. loss: 3.480, 0.1038 s / batch. (data: 8.63e-05)max mem: 17.22454 GB 
[09/19 06:40:20 visual_prompt]: 	Test 1000/1152. loss: 2.791, 0.1202 s / batch. (data: 2.45e-02)max mem: 17.22454 GB 
[09/19 06:40:36 visual_prompt]: 	Test 1100/1152. loss: 2.548, 0.0998 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 06:40:49 visual_prompt]: Inference (test):avg data time: 1.66e-03, avg batch time: 0.1080, average loss: 3.0726
[09/19 06:40:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 29.34	top5: 80.03	
[09/19 06:40:49 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/19 06:40:59 visual_prompt]: Epoch 100 / 100: avg data time: 2.29e-01, avg batch time: 0.4520, average train loss: 0.7095
[09/19 06:41:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.0908, average loss: 0.6372
[09/19 06:41:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 80.00	top5: 99.50	
[09/19 06:41:26 visual_prompt]: 	Test 100/1152. loss: 2.908, 0.1238 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 06:41:42 visual_prompt]: 	Test 200/1152. loss: 2.894, 0.0962 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 06:41:59 visual_prompt]: 	Test 300/1152. loss: 3.257, 0.1231 s / batch. (data: 1.16e-02)max mem: 17.22454 GB 
[09/19 06:42:15 visual_prompt]: 	Test 400/1152. loss: 2.922, 0.1079 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 06:42:32 visual_prompt]: 	Test 500/1152. loss: 3.121, 0.1283 s / batch. (data: 3.20e-02)max mem: 17.22454 GB 
[09/19 06:42:48 visual_prompt]: 	Test 600/1152. loss: 3.015, 0.1114 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 06:43:04 visual_prompt]: 	Test 700/1152. loss: 3.090, 0.0999 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 06:43:21 visual_prompt]: 	Test 800/1152. loss: 2.625, 0.1224 s / batch. (data: 9.16e-05)max mem: 17.22454 GB 
[09/19 06:43:37 visual_prompt]: 	Test 900/1152. loss: 3.474, 0.0955 s / batch. (data: 3.65e-05)max mem: 17.22454 GB 
[09/19 06:43:53 visual_prompt]: 	Test 1000/1152. loss: 2.788, 0.1065 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 06:44:09 visual_prompt]: 	Test 1100/1152. loss: 2.538, 0.1078 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 06:44:21 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1086, average loss: 3.0620
[09/19 06:44:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 29.38	top5: 80.09	
[09/19 06:44:22 visual_prompt]: Best epoch 100: best metric: 0.800
[09/19 06:44:56 visual_prompt]: Rank of current process: 0. World size: 1
[09/19 06:44:56 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/19 06:44:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/19 06:44:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/19 06:44:56 visual_prompt]: Training with config:
[09/19 06:44:56 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/19 06:44:56 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-19 06:44:56.506962: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-19 06:44:56.669100: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-19 06:45:05.031349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 06:45:05.031434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 06:45:05.031443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-19 06:45:14.142589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 06:45:14.142794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 06:45:14.142830: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/19 06:45:14 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-19 06:45:14.247071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 06:45:15 visual_prompt]: Number of images: 1000
[09/19 06:45:15 visual_prompt]: Number of classes: 16 / 16
[09/19 06:45:15 visual_prompt]: Loading validation data...
[09/19 06:45:15 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 06:45:16 visual_prompt]: Number of images: 200
[09/19 06:45:16 visual_prompt]: Number of classes: 16 / 16
[09/19 06:45:16 visual_prompt]: Loading test data...
[09/19 06:45:16 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 06:46:45 visual_prompt]: Number of images: 73728
[09/19 06:46:45 visual_prompt]: Number of classes: 16 / 16
[09/19 06:46:45 visual_prompt]: Constructing models...
[09/19 06:46:48 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/19 06:46:48 visual_prompt]: tuned percent:1.077
[09/19 06:46:51 visual_prompt]: Device used for model: 0
[09/19 06:46:51 visual_prompt]: Setting up Evalutator...
[09/19 06:46:51 visual_prompt]: Setting up Trainer...
[09/19 06:46:51 visual_prompt]: 	Setting up the optimizer...
[09/19 06:46:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/19 06:47:03 visual_prompt]: Epoch 1 / 100: avg data time: 2.47e-01, avg batch time: 0.5637, average train loss: 3.0810
[09/19 06:47:10 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0962, average loss: 3.0534
[09/19 06:47:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 32.50	
[09/19 06:47:30 visual_prompt]: 	Test 100/1152. loss: 2.913, 0.0974 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 06:47:46 visual_prompt]: 	Test 200/1152. loss: 3.109, 0.1168 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 06:48:03 visual_prompt]: 	Test 300/1152. loss: 3.181, 0.1199 s / batch. (data: 7.17e-03)max mem: 17.22454 GB 
[09/19 06:48:19 visual_prompt]: 	Test 400/1152. loss: 3.095, 0.0999 s / batch. (data: 1.41e-05)max mem: 17.22454 GB 
[09/19 06:48:35 visual_prompt]: 	Test 500/1152. loss: 3.055, 0.1182 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 06:48:51 visual_prompt]: 	Test 600/1152. loss: 3.136, 0.1156 s / batch. (data: 6.95e-03)max mem: 17.22454 GB 
[09/19 06:49:07 visual_prompt]: 	Test 700/1152. loss: 3.134, 0.0999 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:49:23 visual_prompt]: 	Test 800/1152. loss: 3.162, 0.0956 s / batch. (data: 6.70e-05)max mem: 17.22454 GB 
[09/19 06:49:39 visual_prompt]: 	Test 900/1152. loss: 2.923, 0.0985 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 06:49:55 visual_prompt]: 	Test 1000/1152. loss: 2.849, 0.1038 s / batch. (data: 2.05e-04)max mem: 17.22454 GB 
[09/19 06:50:11 visual_prompt]: 	Test 1100/1152. loss: 3.146, 0.0974 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 06:50:24 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1095, average loss: 3.1146
[09/19 06:50:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.69	
[09/19 06:50:24 visual_prompt]: Best epoch 1: best metric: 0.115
[09/19 06:50:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/19 06:50:34 visual_prompt]: Epoch 2 / 100: avg data time: 2.29e-01, avg batch time: 0.4566, average train loss: 3.7101
[09/19 06:50:41 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.0871, average loss: 3.5998
[09/19 06:50:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 30.00	
[09/19 06:51:01 visual_prompt]: 	Test 100/1152. loss: 3.689, 0.1106 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 06:51:17 visual_prompt]: 	Test 200/1152. loss: 3.524, 0.1268 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/19 06:51:34 visual_prompt]: 	Test 300/1152. loss: 3.113, 0.0997 s / batch. (data: 3.36e-05)max mem: 17.22454 GB 
[09/19 06:51:50 visual_prompt]: 	Test 400/1152. loss: 3.310, 0.1099 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 06:52:06 visual_prompt]: 	Test 500/1152. loss: 3.460, 0.1196 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 06:52:22 visual_prompt]: 	Test 600/1152. loss: 3.285, 0.1405 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 06:52:38 visual_prompt]: 	Test 700/1152. loss: 2.987, 0.1096 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 06:52:54 visual_prompt]: 	Test 800/1152. loss: 3.213, 0.1064 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 06:53:10 visual_prompt]: 	Test 900/1152. loss: 3.617, 0.1479 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 06:53:26 visual_prompt]: 	Test 1000/1152. loss: 3.410, 0.1225 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 06:53:42 visual_prompt]: 	Test 1100/1152. loss: 3.335, 0.1036 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 06:53:55 visual_prompt]: Inference (test):avg data time: 2.20e-03, avg batch time: 0.1099, average loss: 3.3468
[09/19 06:53:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 32.59	
[09/19 06:53:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/19 06:54:05 visual_prompt]: Epoch 3 / 100: avg data time: 2.36e-01, avg batch time: 0.4596, average train loss: 3.0048
[09/19 06:54:12 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.0896, average loss: 3.0569
[09/19 06:54:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 37.00	
[09/19 06:54:32 visual_prompt]: 	Test 100/1152. loss: 3.034, 0.1079 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 06:54:48 visual_prompt]: 	Test 200/1152. loss: 3.180, 0.1120 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 06:55:05 visual_prompt]: 	Test 300/1152. loss: 2.839, 0.0970 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 06:55:21 visual_prompt]: 	Test 400/1152. loss: 2.998, 0.1071 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 06:55:37 visual_prompt]: 	Test 500/1152. loss: 2.993, 0.1039 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 06:55:54 visual_prompt]: 	Test 600/1152. loss: 3.026, 0.1489 s / batch. (data: 5.40e-02)max mem: 17.22454 GB 
[09/19 06:56:09 visual_prompt]: 	Test 700/1152. loss: 2.950, 0.1193 s / batch. (data: 1.45e-05)max mem: 17.22454 GB 
[09/19 06:56:26 visual_prompt]: 	Test 800/1152. loss: 2.888, 0.0990 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 06:56:41 visual_prompt]: 	Test 900/1152. loss: 3.110, 0.1484 s / batch. (data: 5.35e-02)max mem: 17.22454 GB 
[09/19 06:56:58 visual_prompt]: 	Test 1000/1152. loss: 3.093, 0.0948 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 06:57:14 visual_prompt]: 	Test 1100/1152. loss: 3.122, 0.1027 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 06:57:26 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1092, average loss: 3.0268
[09/19 06:57:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 34.95	
[09/19 06:57:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/19 06:57:37 visual_prompt]: Epoch 4 / 100: avg data time: 2.36e-01, avg batch time: 0.4655, average train loss: 3.0101
[09/19 06:57:44 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0918, average loss: 3.0148
[09/19 06:57:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 30.50	
[09/19 06:58:04 visual_prompt]: 	Test 100/1152. loss: 3.171, 0.0949 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 06:58:20 visual_prompt]: 	Test 200/1152. loss: 2.939, 0.1183 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 06:58:36 visual_prompt]: 	Test 300/1152. loss: 2.924, 0.1159 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 06:58:52 visual_prompt]: 	Test 400/1152. loss: 2.972, 0.1066 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/19 06:59:08 visual_prompt]: 	Test 500/1152. loss: 3.039, 0.1453 s / batch. (data: 3.66e-02)max mem: 17.22454 GB 
[09/19 06:59:24 visual_prompt]: 	Test 600/1152. loss: 3.088, 0.1117 s / batch. (data: 6.98e-03)max mem: 17.22454 GB 
[09/19 06:59:40 visual_prompt]: 	Test 700/1152. loss: 2.959, 0.0958 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 06:59:56 visual_prompt]: 	Test 800/1152. loss: 3.064, 0.1118 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 07:00:13 visual_prompt]: 	Test 900/1152. loss: 3.248, 0.1060 s / batch. (data: 1.92e-04)max mem: 17.22454 GB 
[09/19 07:00:29 visual_prompt]: 	Test 1000/1152. loss: 3.061, 0.1017 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 07:00:45 visual_prompt]: 	Test 1100/1152. loss: 3.004, 0.1313 s / batch. (data: 2.16e-04)max mem: 17.22454 GB 
[09/19 07:00:57 visual_prompt]: Inference (test):avg data time: 2.12e-03, avg batch time: 0.1087, average loss: 2.9798
[09/19 07:00:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.52	
[09/19 07:00:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/19 07:01:07 visual_prompt]: Epoch 5 / 100: avg data time: 2.19e-01, avg batch time: 0.4461, average train loss: 3.1627
[09/19 07:01:14 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.0898, average loss: 3.2168
[09/19 07:01:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 36.50	
[09/19 07:01:34 visual_prompt]: 	Test 100/1152. loss: 3.549, 0.1077 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 07:01:50 visual_prompt]: 	Test 200/1152. loss: 3.245, 0.1169 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/19 07:02:07 visual_prompt]: 	Test 300/1152. loss: 3.228, 0.0985 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 07:02:23 visual_prompt]: 	Test 400/1152. loss: 3.358, 0.0983 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/19 07:02:39 visual_prompt]: 	Test 500/1152. loss: 3.413, 0.1081 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 07:02:55 visual_prompt]: 	Test 600/1152. loss: 3.273, 0.1073 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 07:03:11 visual_prompt]: 	Test 700/1152. loss: 2.976, 0.1039 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 07:03:27 visual_prompt]: 	Test 800/1152. loss: 3.299, 0.1363 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 07:03:43 visual_prompt]: 	Test 900/1152. loss: 3.229, 0.1040 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 07:03:59 visual_prompt]: 	Test 1000/1152. loss: 3.321, 0.1056 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 07:04:15 visual_prompt]: 	Test 1100/1152. loss: 3.451, 0.1357 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 07:04:27 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1091, average loss: 3.2795
[09/19 07:04:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.97	
[09/19 07:04:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/19 07:04:38 visual_prompt]: Epoch 6 / 100: avg data time: 2.28e-01, avg batch time: 0.4585, average train loss: 3.3256
[09/19 07:04:45 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.0959, average loss: 2.9479
[09/19 07:04:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 39.00	
[09/19 07:05:05 visual_prompt]: 	Test 100/1152. loss: 3.300, 0.1384 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 07:05:21 visual_prompt]: 	Test 200/1152. loss: 3.028, 0.1438 s / batch. (data: 4.27e-05)max mem: 17.22454 GB 
[09/19 07:05:37 visual_prompt]: 	Test 300/1152. loss: 3.093, 0.0945 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 07:05:53 visual_prompt]: 	Test 400/1152. loss: 3.264, 0.0948 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/19 07:06:10 visual_prompt]: 	Test 500/1152. loss: 3.183, 0.1253 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 07:06:26 visual_prompt]: 	Test 600/1152. loss: 3.092, 0.0959 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 07:06:42 visual_prompt]: 	Test 700/1152. loss: 3.116, 0.0952 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 07:06:58 visual_prompt]: 	Test 800/1152. loss: 3.238, 0.1279 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 07:07:14 visual_prompt]: 	Test 900/1152. loss: 3.114, 0.1239 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 07:07:31 visual_prompt]: 	Test 1000/1152. loss: 3.374, 0.0986 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/19 07:07:47 visual_prompt]: 	Test 1100/1152. loss: 3.164, 0.0993 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 07:07:59 visual_prompt]: Inference (test):avg data time: 1.66e-03, avg batch time: 0.1083, average loss: 3.1022
[09/19 07:07:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 34.97	
[09/19 07:07:59 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/19 07:08:10 visual_prompt]: Epoch 7 / 100: avg data time: 2.36e-01, avg batch time: 0.4575, average train loss: 3.3576
[09/19 07:08:17 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0921, average loss: 3.7686
[09/19 07:08:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 31.50	
[09/19 07:08:37 visual_prompt]: 	Test 100/1152. loss: 3.464, 0.0958 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 07:08:53 visual_prompt]: 	Test 200/1152. loss: 3.438, 0.0983 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 07:09:10 visual_prompt]: 	Test 300/1152. loss: 3.244, 0.0968 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 07:09:26 visual_prompt]: 	Test 400/1152. loss: 3.420, 0.1077 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/19 07:09:42 visual_prompt]: 	Test 500/1152. loss: 3.799, 0.1175 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/19 07:09:58 visual_prompt]: 	Test 600/1152. loss: 3.509, 0.0991 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 07:10:14 visual_prompt]: 	Test 700/1152. loss: 3.522, 0.1087 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 07:10:30 visual_prompt]: 	Test 800/1152. loss: 3.638, 0.0957 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 07:10:47 visual_prompt]: 	Test 900/1152. loss: 3.610, 0.1252 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/19 07:11:03 visual_prompt]: 	Test 1000/1152. loss: 3.610, 0.1039 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 07:11:19 visual_prompt]: 	Test 1100/1152. loss: 3.401, 0.0989 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 07:11:31 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1093, average loss: 3.6066
[09/19 07:11:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 29.99	
[09/19 07:11:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/19 07:11:42 visual_prompt]: Epoch 8 / 100: avg data time: 2.23e-01, avg batch time: 0.4568, average train loss: 3.2951
[09/19 07:11:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.0888, average loss: 3.2859
[09/19 07:11:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 40.50	
[09/19 07:12:09 visual_prompt]: 	Test 100/1152. loss: 3.577, 0.0947 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 07:12:25 visual_prompt]: 	Test 200/1152. loss: 3.358, 0.1171 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 07:12:42 visual_prompt]: 	Test 300/1152. loss: 3.455, 0.1089 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 07:12:58 visual_prompt]: 	Test 400/1152. loss: 3.449, 0.1044 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 07:13:14 visual_prompt]: 	Test 500/1152. loss: 3.452, 0.1105 s / batch. (data: 7.34e-05)max mem: 17.22454 GB 
[09/19 07:13:30 visual_prompt]: 	Test 600/1152. loss: 3.359, 0.1101 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/19 07:13:47 visual_prompt]: 	Test 700/1152. loss: 3.117, 0.0952 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 07:14:03 visual_prompt]: 	Test 800/1152. loss: 3.724, 0.1166 s / batch. (data: 6.77e-05)max mem: 17.22454 GB 
[09/19 07:14:19 visual_prompt]: 	Test 900/1152. loss: 3.298, 0.1078 s / batch. (data: 4.86e-03)max mem: 17.22454 GB 
[09/19 07:14:35 visual_prompt]: 	Test 1000/1152. loss: 3.482, 0.0983 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 07:14:51 visual_prompt]: 	Test 1100/1152. loss: 3.455, 0.0998 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 07:15:03 visual_prompt]: Inference (test):avg data time: 1.67e-03, avg batch time: 0.1092, average loss: 3.3947
[09/19 07:15:03 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 37.56	
[09/19 07:15:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/19 07:15:14 visual_prompt]: Epoch 9 / 100: avg data time: 2.28e-01, avg batch time: 0.4557, average train loss: 3.1680
[09/19 07:15:20 visual_prompt]: Inference (val):avg data time: 1.20e-03, avg batch time: 0.0884, average loss: 3.2165
[09/19 07:15:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.00	
[09/19 07:15:40 visual_prompt]: 	Test 100/1152. loss: 3.217, 0.1177 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 07:15:57 visual_prompt]: 	Test 200/1152. loss: 3.333, 0.1118 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 07:16:13 visual_prompt]: 	Test 300/1152. loss: 2.994, 0.0952 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 07:16:30 visual_prompt]: 	Test 400/1152. loss: 3.246, 0.0949 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 07:16:46 visual_prompt]: 	Test 500/1152. loss: 3.086, 0.1267 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:17:02 visual_prompt]: 	Test 600/1152. loss: 3.204, 0.0969 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 07:17:18 visual_prompt]: 	Test 700/1152. loss: 3.273, 0.1072 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 07:17:34 visual_prompt]: 	Test 800/1152. loss: 3.141, 0.0997 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:17:51 visual_prompt]: 	Test 900/1152. loss: 3.310, 0.0961 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 07:18:07 visual_prompt]: 	Test 1000/1152. loss: 3.188, 0.0958 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 07:18:23 visual_prompt]: 	Test 1100/1152. loss: 3.194, 0.0974 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 07:18:35 visual_prompt]: Inference (test):avg data time: 1.51e-03, avg batch time: 0.1084, average loss: 3.1644
[09/19 07:18:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 35.05	
[09/19 07:18:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/19 07:18:46 visual_prompt]: Epoch 10 / 100: avg data time: 2.17e-01, avg batch time: 0.4435, average train loss: 3.2210
[09/19 07:18:53 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.0865, average loss: 3.4755
[09/19 07:18:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 27.00	
[09/19 07:19:13 visual_prompt]: 	Test 100/1152. loss: 3.418, 0.1276 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 07:19:29 visual_prompt]: 	Test 200/1152. loss: 3.530, 0.1161 s / batch. (data: 7.35e-03)max mem: 17.22454 GB 
[09/19 07:19:45 visual_prompt]: 	Test 300/1152. loss: 3.383, 0.0966 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 07:20:02 visual_prompt]: 	Test 400/1152. loss: 3.313, 0.1193 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 07:20:18 visual_prompt]: 	Test 500/1152. loss: 3.349, 0.0951 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 07:20:34 visual_prompt]: 	Test 600/1152. loss: 3.377, 0.1033 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/19 07:20:50 visual_prompt]: 	Test 700/1152. loss: 3.328, 0.1130 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/19 07:21:07 visual_prompt]: 	Test 800/1152. loss: 3.457, 0.1107 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 07:21:23 visual_prompt]: 	Test 900/1152. loss: 3.509, 0.0981 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 07:21:39 visual_prompt]: 	Test 1000/1152. loss: 3.390, 0.1048 s / batch. (data: 7.10e-05)max mem: 17.22454 GB 
[09/19 07:21:55 visual_prompt]: 	Test 1100/1152. loss: 3.357, 0.0979 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 07:22:07 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1089, average loss: 3.3771
[09/19 07:22:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 29.71	
[09/19 07:22:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/19 07:22:17 visual_prompt]: Epoch 11 / 100: avg data time: 2.21e-01, avg batch time: 0.4462, average train loss: 3.1622
[09/19 07:22:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.0960, average loss: 3.3678
[09/19 07:22:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 33.00	
[09/19 07:22:44 visual_prompt]: 	Test 100/1152. loss: 3.044, 0.0957 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 07:23:00 visual_prompt]: 	Test 200/1152. loss: 3.350, 0.1157 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 07:23:16 visual_prompt]: 	Test 300/1152. loss: 3.555, 0.1121 s / batch. (data: 7.41e-03)max mem: 17.22454 GB 
[09/19 07:23:32 visual_prompt]: 	Test 400/1152. loss: 3.440, 0.1329 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 07:23:48 visual_prompt]: 	Test 500/1152. loss: 3.288, 0.1162 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 07:24:05 visual_prompt]: 	Test 600/1152. loss: 3.419, 0.0955 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 07:24:20 visual_prompt]: 	Test 700/1152. loss: 3.596, 0.0966 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 07:24:37 visual_prompt]: 	Test 800/1152. loss: 3.302, 0.1000 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 07:24:53 visual_prompt]: 	Test 900/1152. loss: 3.215, 0.1034 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 07:25:09 visual_prompt]: 	Test 1000/1152. loss: 3.105, 0.1004 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 07:25:25 visual_prompt]: 	Test 1100/1152. loss: 3.339, 0.1104 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 07:25:37 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1093, average loss: 3.4267
[09/19 07:25:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.40	
[09/19 07:25:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/19 07:25:47 visual_prompt]: Epoch 12 / 100: avg data time: 2.17e-01, avg batch time: 0.4444, average train loss: 3.3514
[09/19 07:25:54 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.0902, average loss: 3.3298
[09/19 07:25:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 29.00	
[09/19 07:26:14 visual_prompt]: 	Test 100/1152. loss: 3.287, 0.1039 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 07:26:31 visual_prompt]: 	Test 200/1152. loss: 3.333, 0.1462 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 07:26:47 visual_prompt]: 	Test 300/1152. loss: 3.099, 0.1000 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 07:27:03 visual_prompt]: 	Test 400/1152. loss: 3.158, 0.0979 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 07:27:19 visual_prompt]: 	Test 500/1152. loss: 3.127, 0.1045 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 07:27:35 visual_prompt]: 	Test 600/1152. loss: 2.979, 0.0965 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 07:27:51 visual_prompt]: 	Test 700/1152. loss: 3.026, 0.1041 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 07:28:07 visual_prompt]: 	Test 800/1152. loss: 3.104, 0.0987 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 07:28:24 visual_prompt]: 	Test 900/1152. loss: 3.236, 0.1273 s / batch. (data: 6.15e-03)max mem: 17.22454 GB 
[09/19 07:28:40 visual_prompt]: 	Test 1000/1152. loss: 3.256, 0.0986 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:28:56 visual_prompt]: 	Test 1100/1152. loss: 3.187, 0.1038 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 07:29:08 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1086, average loss: 3.1668
[09/19 07:29:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 30.03	
[09/19 07:29:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/19 07:29:18 visual_prompt]: Epoch 13 / 100: avg data time: 2.21e-01, avg batch time: 0.4525, average train loss: 3.3166
[09/19 07:29:25 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.0905, average loss: 3.2922
[09/19 07:29:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 32.50	
[09/19 07:29:45 visual_prompt]: 	Test 100/1152. loss: 2.997, 0.1674 s / batch. (data: 1.90e-04)max mem: 17.22454 GB 
[09/19 07:30:02 visual_prompt]: 	Test 200/1152. loss: 3.279, 0.0962 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 07:30:18 visual_prompt]: 	Test 300/1152. loss: 3.026, 0.1159 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 07:30:34 visual_prompt]: 	Test 400/1152. loss: 3.230, 0.0998 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 07:30:51 visual_prompt]: 	Test 500/1152. loss: 3.082, 0.0955 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 07:31:07 visual_prompt]: 	Test 600/1152. loss: 2.835, 0.1035 s / batch. (data: 7.56e-05)max mem: 17.22454 GB 
[09/19 07:31:23 visual_prompt]: 	Test 700/1152. loss: 3.413, 0.1088 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 07:31:39 visual_prompt]: 	Test 800/1152. loss: 3.122, 0.1114 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:31:55 visual_prompt]: 	Test 900/1152. loss: 3.070, 0.1033 s / batch. (data: 7.63e-05)max mem: 17.22454 GB 
[09/19 07:32:12 visual_prompt]: 	Test 1000/1152. loss: 3.220, 0.1197 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 07:32:28 visual_prompt]: 	Test 1100/1152. loss: 3.106, 0.1202 s / batch. (data: 2.35e-02)max mem: 17.22454 GB 
[09/19 07:32:40 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1080, average loss: 3.2192
[09/19 07:32:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 32.56	
[09/19 07:32:41 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/19 07:32:51 visual_prompt]: Epoch 14 / 100: avg data time: 2.23e-01, avg batch time: 0.4503, average train loss: 3.3995
[09/19 07:32:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0931, average loss: 3.0720
[09/19 07:32:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 25.50	
[09/19 07:33:18 visual_prompt]: 	Test 100/1152. loss: 3.008, 0.0999 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 07:33:34 visual_prompt]: 	Test 200/1152. loss: 2.998, 0.1038 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 07:33:50 visual_prompt]: 	Test 300/1152. loss: 2.850, 0.1474 s / batch. (data: 3.68e-02)max mem: 17.22454 GB 
[09/19 07:34:06 visual_prompt]: 	Test 400/1152. loss: 3.033, 0.1047 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 07:34:22 visual_prompt]: 	Test 500/1152. loss: 3.130, 0.1167 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/19 07:34:38 visual_prompt]: 	Test 600/1152. loss: 2.899, 0.1036 s / batch. (data: 4.01e-05)max mem: 17.22454 GB 
[09/19 07:34:54 visual_prompt]: 	Test 700/1152. loss: 3.001, 0.1267 s / batch. (data: 4.32e-05)max mem: 17.22454 GB 
[09/19 07:35:10 visual_prompt]: 	Test 800/1152. loss: 2.987, 0.1096 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 07:35:27 visual_prompt]: 	Test 900/1152. loss: 2.950, 0.1230 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 07:35:43 visual_prompt]: 	Test 1000/1152. loss: 2.975, 0.1119 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 07:35:59 visual_prompt]: 	Test 1100/1152. loss: 3.003, 0.1066 s / batch. (data: 7.19e-03)max mem: 17.22454 GB 
[09/19 07:36:11 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1091, average loss: 3.0503
[09/19 07:36:12 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 28.55	
[09/19 07:36:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/19 07:36:22 visual_prompt]: Epoch 15 / 100: avg data time: 2.37e-01, avg batch time: 0.4624, average train loss: 3.3817
[09/19 07:36:29 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.0917, average loss: 3.1372
[09/19 07:36:29 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 22.00	
[09/19 07:36:49 visual_prompt]: 	Test 100/1152. loss: 2.810, 0.0981 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 07:37:05 visual_prompt]: 	Test 200/1152. loss: 3.073, 0.1287 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 07:37:21 visual_prompt]: 	Test 300/1152. loss: 3.143, 0.1068 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 07:37:38 visual_prompt]: 	Test 400/1152. loss: 2.918, 0.0950 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 07:37:54 visual_prompt]: 	Test 500/1152. loss: 3.032, 0.0995 s / batch. (data: 7.61e-05)max mem: 17.22454 GB 
[09/19 07:38:10 visual_prompt]: 	Test 600/1152. loss: 3.244, 0.1066 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 07:38:27 visual_prompt]: 	Test 700/1152. loss: 3.262, 0.0945 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 07:38:43 visual_prompt]: 	Test 800/1152. loss: 3.061, 0.1040 s / batch. (data: 7.01e-05)max mem: 17.22454 GB 
[09/19 07:38:59 visual_prompt]: 	Test 900/1152. loss: 3.059, 0.1002 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 07:39:15 visual_prompt]: 	Test 1000/1152. loss: 2.887, 0.1088 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 07:39:31 visual_prompt]: 	Test 1100/1152. loss: 3.074, 0.0955 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 07:39:44 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1088, average loss: 3.0790
[09/19 07:39:44 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 29.65	
[09/19 07:39:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/19 07:39:54 visual_prompt]: Epoch 16 / 100: avg data time: 2.29e-01, avg batch time: 0.4582, average train loss: 3.1366
[09/19 07:40:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0954, average loss: 3.2591
[09/19 07:40:01 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 38.50	
[09/19 07:40:21 visual_prompt]: 	Test 100/1152. loss: 3.236, 0.0964 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 07:40:37 visual_prompt]: 	Test 200/1152. loss: 3.333, 0.1079 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 07:40:54 visual_prompt]: 	Test 300/1152. loss: 3.223, 0.0947 s / batch. (data: 8.01e-05)max mem: 17.22454 GB 
[09/19 07:41:10 visual_prompt]: 	Test 400/1152. loss: 3.150, 0.1223 s / batch. (data: 3.89e-03)max mem: 17.22454 GB 
[09/19 07:41:26 visual_prompt]: 	Test 500/1152. loss: 3.269, 0.1216 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 07:41:43 visual_prompt]: 	Test 600/1152. loss: 3.178, 0.1229 s / batch. (data: 2.79e-02)max mem: 17.22454 GB 
[09/19 07:41:59 visual_prompt]: 	Test 700/1152. loss: 3.397, 0.1152 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 07:42:15 visual_prompt]: 	Test 800/1152. loss: 3.474, 0.1282 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 07:42:31 visual_prompt]: 	Test 900/1152. loss: 3.165, 0.1159 s / batch. (data: 7.16e-03)max mem: 17.22454 GB 
[09/19 07:42:48 visual_prompt]: 	Test 1000/1152. loss: 3.261, 0.0955 s / batch. (data: 2.91e-05)max mem: 17.22454 GB 
[09/19 07:43:04 visual_prompt]: 	Test 1100/1152. loss: 3.439, 0.1200 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 07:43:16 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1087, average loss: 3.2782
[09/19 07:43:16 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 35.11	
[09/19 07:43:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/19 07:43:27 visual_prompt]: Epoch 17 / 100: avg data time: 2.35e-01, avg batch time: 0.4649, average train loss: 3.1559
[09/19 07:43:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0969, average loss: 3.1493
[09/19 07:43:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.50	
[09/19 07:43:54 visual_prompt]: 	Test 100/1152. loss: 3.142, 0.1146 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 07:44:11 visual_prompt]: 	Test 200/1152. loss: 3.484, 0.0974 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:44:27 visual_prompt]: 	Test 300/1152. loss: 2.990, 0.1170 s / batch. (data: 7.25e-05)max mem: 17.22454 GB 
[09/19 07:44:44 visual_prompt]: 	Test 400/1152. loss: 3.171, 0.1001 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 07:45:00 visual_prompt]: 	Test 500/1152. loss: 3.227, 0.1048 s / batch. (data: 7.09e-03)max mem: 17.22454 GB 
[09/19 07:45:16 visual_prompt]: 	Test 600/1152. loss: 3.306, 0.1196 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 07:45:32 visual_prompt]: 	Test 700/1152. loss: 3.055, 0.1000 s / batch. (data: 3.96e-05)max mem: 17.22454 GB 
[09/19 07:45:49 visual_prompt]: 	Test 800/1152. loss: 3.101, 0.1157 s / batch. (data: 7.09e-03)max mem: 17.22454 GB 
[09/19 07:46:05 visual_prompt]: 	Test 900/1152. loss: 3.310, 0.1225 s / batch. (data: 1.96e-04)max mem: 17.22454 GB 
[09/19 07:46:21 visual_prompt]: 	Test 1000/1152. loss: 3.309, 0.1150 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 07:46:37 visual_prompt]: 	Test 1100/1152. loss: 3.151, 0.0972 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 07:46:49 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1094, average loss: 3.2042
[09/19 07:46:50 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.37	
[09/19 07:46:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/19 07:47:00 visual_prompt]: Epoch 18 / 100: avg data time: 2.32e-01, avg batch time: 0.4620, average train loss: 3.1952
[09/19 07:47:07 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.0918, average loss: 3.2035
[09/19 07:47:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 33.00	
[09/19 07:47:27 visual_prompt]: 	Test 100/1152. loss: 3.101, 0.1042 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/19 07:47:43 visual_prompt]: 	Test 200/1152. loss: 3.147, 0.1252 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/19 07:47:59 visual_prompt]: 	Test 300/1152. loss: 3.223, 0.1142 s / batch. (data: 7.15e-05)max mem: 17.22454 GB 
[09/19 07:48:16 visual_prompt]: 	Test 400/1152. loss: 3.187, 0.0982 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 07:48:32 visual_prompt]: 	Test 500/1152. loss: 3.317, 0.0979 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 07:48:48 visual_prompt]: 	Test 600/1152. loss: 3.437, 0.0978 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 07:49:05 visual_prompt]: 	Test 700/1152. loss: 3.257, 0.1253 s / batch. (data: 3.84e-05)max mem: 17.22454 GB 
[09/19 07:49:21 visual_prompt]: 	Test 800/1152. loss: 3.228, 0.1160 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 07:49:37 visual_prompt]: 	Test 900/1152. loss: 3.164, 0.1276 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 07:49:53 visual_prompt]: 	Test 1000/1152. loss: 2.932, 0.1098 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/19 07:50:10 visual_prompt]: 	Test 1100/1152. loss: 3.221, 0.1008 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/19 07:50:22 visual_prompt]: Inference (test):avg data time: 1.62e-03, avg batch time: 0.1086, average loss: 3.2494
[09/19 07:50:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 30.11	
[09/19 07:50:23 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/19 07:50:33 visual_prompt]: Epoch 19 / 100: avg data time: 2.18e-01, avg batch time: 0.4467, average train loss: 3.1736
[09/19 07:50:39 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.0874, average loss: 3.2482
[09/19 07:50:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 33.00	
[09/19 07:51:00 visual_prompt]: 	Test 100/1152. loss: 3.106, 0.1170 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 07:51:16 visual_prompt]: 	Test 200/1152. loss: 3.377, 0.1239 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 07:51:33 visual_prompt]: 	Test 300/1152. loss: 3.299, 0.0961 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 07:51:49 visual_prompt]: 	Test 400/1152. loss: 3.193, 0.1199 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 07:52:05 visual_prompt]: 	Test 500/1152. loss: 3.227, 0.0967 s / batch. (data: 3.93e-05)max mem: 17.22454 GB 
[09/19 07:52:21 visual_prompt]: 	Test 600/1152. loss: 3.271, 0.1076 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 07:52:37 visual_prompt]: 	Test 700/1152. loss: 3.295, 0.1197 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 07:52:53 visual_prompt]: 	Test 800/1152. loss: 3.384, 0.1038 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:53:09 visual_prompt]: 	Test 900/1152. loss: 3.182, 0.0978 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 07:53:26 visual_prompt]: 	Test 1000/1152. loss: 3.416, 0.1115 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 07:53:41 visual_prompt]: 	Test 1100/1152. loss: 3.336, 0.1038 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:53:54 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1083, average loss: 3.3164
[09/19 07:53:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.40	
[09/19 07:53:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/19 07:54:04 visual_prompt]: Epoch 20 / 100: avg data time: 2.23e-01, avg batch time: 0.4458, average train loss: 3.1340
[09/19 07:54:11 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.0875, average loss: 2.9575
[09/19 07:54:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 32.50	
[09/19 07:54:31 visual_prompt]: 	Test 100/1152. loss: 3.162, 0.1504 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 07:54:47 visual_prompt]: 	Test 200/1152. loss: 2.987, 0.0953 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 07:55:03 visual_prompt]: 	Test 300/1152. loss: 2.925, 0.0949 s / batch. (data: 6.72e-05)max mem: 17.22454 GB 
[09/19 07:55:20 visual_prompt]: 	Test 400/1152. loss: 2.908, 0.1026 s / batch. (data: 6.79e-05)max mem: 17.22454 GB 
[09/19 07:55:36 visual_prompt]: 	Test 500/1152. loss: 3.043, 0.0953 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 07:55:52 visual_prompt]: 	Test 600/1152. loss: 2.916, 0.0965 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 07:56:08 visual_prompt]: 	Test 700/1152. loss: 2.794, 0.0957 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 07:56:25 visual_prompt]: 	Test 800/1152. loss: 3.131, 0.0992 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 07:56:41 visual_prompt]: 	Test 900/1152. loss: 2.955, 0.1076 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 07:56:57 visual_prompt]: 	Test 1000/1152. loss: 2.979, 0.0957 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 07:57:13 visual_prompt]: 	Test 1100/1152. loss: 3.045, 0.1034 s / batch. (data: 6.91e-05)max mem: 17.22454 GB 
[09/19 07:57:25 visual_prompt]: Inference (test):avg data time: 1.68e-03, avg batch time: 0.1089, average loss: 2.9545
[09/19 07:57:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 32.53	
[09/19 07:57:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/19 07:57:36 visual_prompt]: Epoch 21 / 100: avg data time: 2.24e-01, avg batch time: 0.4594, average train loss: 2.9859
[09/19 07:57:42 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.0883, average loss: 2.9393
[09/19 07:57:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 33.50	
[09/19 07:58:02 visual_prompt]: 	Test 100/1152. loss: 3.137, 0.0972 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 07:58:18 visual_prompt]: 	Test 200/1152. loss: 3.068, 0.0965 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 07:58:35 visual_prompt]: 	Test 300/1152. loss: 2.924, 0.0981 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 07:58:51 visual_prompt]: 	Test 400/1152. loss: 3.127, 0.1159 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 07:59:07 visual_prompt]: 	Test 500/1152. loss: 3.150, 0.0962 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 07:59:23 visual_prompt]: 	Test 600/1152. loss: 2.993, 0.1119 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 07:59:39 visual_prompt]: 	Test 700/1152. loss: 2.802, 0.1126 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 07:59:55 visual_prompt]: 	Test 800/1152. loss: 2.993, 0.1085 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 08:00:12 visual_prompt]: 	Test 900/1152. loss: 2.950, 0.0985 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 08:00:27 visual_prompt]: 	Test 1000/1152. loss: 3.063, 0.0999 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 08:00:44 visual_prompt]: 	Test 1100/1152. loss: 2.942, 0.1170 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 08:00:56 visual_prompt]: Inference (test):avg data time: 1.66e-03, avg batch time: 0.1089, average loss: 3.0046
[09/19 08:00:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 32.50	
[09/19 08:00:56 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/19 08:01:06 visual_prompt]: Epoch 22 / 100: avg data time: 2.20e-01, avg batch time: 0.4483, average train loss: 2.9511
[09/19 08:01:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.0876, average loss: 3.1477
[09/19 08:01:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 28.00	
[09/19 08:01:33 visual_prompt]: 	Test 100/1152. loss: 2.963, 0.1771 s / batch. (data: 4.69e-02)max mem: 17.22454 GB 
[09/19 08:01:49 visual_prompt]: 	Test 200/1152. loss: 3.068, 0.0990 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 08:02:05 visual_prompt]: 	Test 300/1152. loss: 3.003, 0.1093 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 08:02:21 visual_prompt]: 	Test 400/1152. loss: 2.982, 0.1063 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 08:02:38 visual_prompt]: 	Test 500/1152. loss: 2.961, 0.0948 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 08:02:54 visual_prompt]: 	Test 600/1152. loss: 3.089, 0.1140 s / batch. (data: 7.03e-05)max mem: 17.22454 GB 
[09/19 08:03:10 visual_prompt]: 	Test 700/1152. loss: 3.131, 0.0947 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:03:26 visual_prompt]: 	Test 800/1152. loss: 2.985, 0.1009 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 08:03:42 visual_prompt]: 	Test 900/1152. loss: 3.226, 0.1036 s / batch. (data: 4.77e-05)max mem: 17.22454 GB 
[09/19 08:03:59 visual_prompt]: 	Test 1000/1152. loss: 3.067, 0.1061 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 08:04:15 visual_prompt]: 	Test 1100/1152. loss: 3.024, 0.1022 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 08:04:27 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1084, average loss: 3.0453
[09/19 08:04:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.28	
[09/19 08:04:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/19 08:04:37 visual_prompt]: Epoch 23 / 100: avg data time: 2.13e-01, avg batch time: 0.4414, average train loss: 2.9853
[09/19 08:04:44 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.0867, average loss: 3.0874
[09/19 08:04:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 29.50	
[09/19 08:05:04 visual_prompt]: 	Test 100/1152. loss: 3.137, 0.1486 s / batch. (data: 8.11e-03)max mem: 17.22454 GB 
[09/19 08:05:20 visual_prompt]: 	Test 200/1152. loss: 3.138, 0.0959 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 08:05:36 visual_prompt]: 	Test 300/1152. loss: 2.953, 0.1108 s / batch. (data: 3.81e-05)max mem: 17.22454 GB 
[09/19 08:05:52 visual_prompt]: 	Test 400/1152. loss: 2.951, 0.1278 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 08:06:08 visual_prompt]: 	Test 500/1152. loss: 3.122, 0.1285 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 08:06:24 visual_prompt]: 	Test 600/1152. loss: 3.171, 0.1154 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 08:06:40 visual_prompt]: 	Test 700/1152. loss: 3.028, 0.0950 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/19 08:06:57 visual_prompt]: 	Test 800/1152. loss: 3.211, 0.0968 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/19 08:07:13 visual_prompt]: 	Test 900/1152. loss: 3.180, 0.0939 s / batch. (data: 7.51e-05)max mem: 17.22454 GB 
[09/19 08:07:29 visual_prompt]: 	Test 1000/1152. loss: 3.094, 0.1181 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/19 08:07:45 visual_prompt]: 	Test 1100/1152. loss: 3.218, 0.0946 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/19 08:07:57 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1090, average loss: 3.0831
[09/19 08:07:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.62	
[09/19 08:07:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/19 08:08:08 visual_prompt]: Epoch 24 / 100: avg data time: 2.24e-01, avg batch time: 0.4553, average train loss: 3.0076
[09/19 08:08:15 visual_prompt]: Inference (val):avg data time: 1.07e-03, avg batch time: 0.0955, average loss: 3.3352
[09/19 08:08:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 42.50	
[09/19 08:08:35 visual_prompt]: 	Test 100/1152. loss: 3.513, 0.1085 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 08:08:51 visual_prompt]: 	Test 200/1152. loss: 3.335, 0.0958 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 08:09:07 visual_prompt]: 	Test 300/1152. loss: 3.381, 0.0985 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 08:09:23 visual_prompt]: 	Test 400/1152. loss: 3.545, 0.0978 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 08:09:39 visual_prompt]: 	Test 500/1152. loss: 3.296, 0.0998 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 08:09:55 visual_prompt]: 	Test 600/1152. loss: 3.238, 0.1155 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 08:10:11 visual_prompt]: 	Test 700/1152. loss: 3.488, 0.1105 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 08:10:27 visual_prompt]: 	Test 800/1152. loss: 3.274, 0.0985 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 08:10:43 visual_prompt]: 	Test 900/1152. loss: 3.420, 0.0988 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/19 08:10:59 visual_prompt]: 	Test 1000/1152. loss: 3.417, 0.1118 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 08:11:16 visual_prompt]: 	Test 1100/1152. loss: 3.487, 0.1078 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 08:11:28 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1085, average loss: 3.3928
[09/19 08:11:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 37.54	
[09/19 08:11:28 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/19 08:11:39 visual_prompt]: Epoch 25 / 100: avg data time: 2.23e-01, avg batch time: 0.4519, average train loss: 3.1712
[09/19 08:11:45 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.0920, average loss: 2.9928
[09/19 08:11:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 34.00	
[09/19 08:12:05 visual_prompt]: 	Test 100/1152. loss: 2.934, 0.1106 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 08:12:21 visual_prompt]: 	Test 200/1152. loss: 3.037, 0.0961 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 08:12:38 visual_prompt]: 	Test 300/1152. loss: 2.775, 0.1065 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 08:12:54 visual_prompt]: 	Test 400/1152. loss: 2.859, 0.0980 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 08:13:10 visual_prompt]: 	Test 500/1152. loss: 2.986, 0.1468 s / batch. (data: 1.83e-04)max mem: 17.22454 GB 
[09/19 08:13:26 visual_prompt]: 	Test 600/1152. loss: 2.863, 0.0950 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 08:13:42 visual_prompt]: 	Test 700/1152. loss: 2.792, 0.1119 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:13:58 visual_prompt]: 	Test 800/1152. loss: 2.953, 0.1080 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/19 08:14:14 visual_prompt]: 	Test 900/1152. loss: 2.978, 0.0997 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 08:14:30 visual_prompt]: 	Test 1000/1152. loss: 3.037, 0.1072 s / batch. (data: 6.61e-03)max mem: 17.22454 GB 
[09/19 08:14:46 visual_prompt]: 	Test 1100/1152. loss: 3.007, 0.1198 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 08:14:58 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1096, average loss: 2.9623
[09/19 08:14:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 37.80	
[09/19 08:14:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/19 08:15:09 visual_prompt]: Epoch 26 / 100: avg data time: 2.19e-01, avg batch time: 0.4461, average train loss: 3.1354
[09/19 08:15:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.0895, average loss: 3.0653
[09/19 08:15:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 37.00	
[09/19 08:15:35 visual_prompt]: 	Test 100/1152. loss: 3.119, 0.1111 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 08:15:52 visual_prompt]: 	Test 200/1152. loss: 3.178, 0.0964 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 08:16:08 visual_prompt]: 	Test 300/1152. loss: 3.317, 0.0961 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:16:24 visual_prompt]: 	Test 400/1152. loss: 3.128, 0.1041 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 08:16:40 visual_prompt]: 	Test 500/1152. loss: 3.194, 0.1149 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 08:16:57 visual_prompt]: 	Test 600/1152. loss: 3.360, 0.0991 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 08:17:13 visual_prompt]: 	Test 700/1152. loss: 3.236, 0.0947 s / batch. (data: 6.58e-05)max mem: 17.22454 GB 
[09/19 08:17:29 visual_prompt]: 	Test 800/1152. loss: 3.161, 0.1220 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:17:45 visual_prompt]: 	Test 900/1152. loss: 3.119, 0.0985 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 08:18:01 visual_prompt]: 	Test 1000/1152. loss: 3.118, 0.0982 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 08:18:18 visual_prompt]: 	Test 1100/1152. loss: 3.013, 0.1473 s / batch. (data: 1.50e-02)max mem: 17.22454 GB 
[09/19 08:18:30 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1082, average loss: 3.1212
[09/19 08:18:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.05	top5: 32.47	
[09/19 08:18:30 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/19 08:18:41 visual_prompt]: Epoch 27 / 100: avg data time: 2.23e-01, avg batch time: 0.4529, average train loss: 2.9610
[09/19 08:18:47 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.0936, average loss: 2.9495
[09/19 08:18:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 25.00	
[09/19 08:19:07 visual_prompt]: 	Test 100/1152. loss: 2.858, 0.0950 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 08:19:24 visual_prompt]: 	Test 200/1152. loss: 2.930, 0.1246 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 08:19:40 visual_prompt]: 	Test 300/1152. loss: 2.922, 0.0964 s / batch. (data: 1.94e-04)max mem: 17.22454 GB 
[09/19 08:19:56 visual_prompt]: 	Test 400/1152. loss: 2.829, 0.1159 s / batch. (data: 3.17e-05)max mem: 17.22454 GB 
[09/19 08:20:12 visual_prompt]: 	Test 500/1152. loss: 2.822, 0.1120 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 08:20:28 visual_prompt]: 	Test 600/1152. loss: 2.789, 0.1057 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 08:20:45 visual_prompt]: 	Test 700/1152. loss: 2.836, 0.1086 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 08:21:01 visual_prompt]: 	Test 800/1152. loss: 2.816, 0.0943 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 08:21:17 visual_prompt]: 	Test 900/1152. loss: 2.824, 0.1081 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/19 08:21:33 visual_prompt]: 	Test 1000/1152. loss: 2.764, 0.1001 s / batch. (data: 6.94e-05)max mem: 17.22454 GB 
[09/19 08:21:49 visual_prompt]: 	Test 1100/1152. loss: 3.056, 0.1181 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 08:22:01 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1083, average loss: 2.9029
[09/19 08:22:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 32.38	
[09/19 08:22:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/19 08:22:11 visual_prompt]: Epoch 28 / 100: avg data time: 2.17e-01, avg batch time: 0.4422, average train loss: 3.0577
[09/19 08:22:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.0895, average loss: 2.9888
[09/19 08:22:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 41.00	
[09/19 08:22:38 visual_prompt]: 	Test 100/1152. loss: 3.058, 0.1277 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 08:22:54 visual_prompt]: 	Test 200/1152. loss: 3.355, 0.1160 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:23:10 visual_prompt]: 	Test 300/1152. loss: 3.216, 0.1397 s / batch. (data: 7.08e-03)max mem: 17.22454 GB 
[09/19 08:23:26 visual_prompt]: 	Test 400/1152. loss: 3.282, 0.0965 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 08:23:43 visual_prompt]: 	Test 500/1152. loss: 3.083, 0.0943 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 08:23:59 visual_prompt]: 	Test 600/1152. loss: 3.251, 0.1038 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 08:24:15 visual_prompt]: 	Test 700/1152. loss: 3.156, 0.0995 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 08:24:31 visual_prompt]: 	Test 800/1152. loss: 3.060, 0.1120 s / batch. (data: 7.41e-03)max mem: 17.22454 GB 
[09/19 08:24:47 visual_prompt]: 	Test 900/1152. loss: 3.203, 0.1079 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 08:25:03 visual_prompt]: 	Test 1000/1152. loss: 3.411, 0.1134 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 08:25:19 visual_prompt]: 	Test 1100/1152. loss: 3.149, 0.0942 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 08:25:31 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1090, average loss: 3.1748
[09/19 08:25:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 34.96	
[09/19 08:25:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/19 08:25:42 visual_prompt]: Epoch 29 / 100: avg data time: 2.16e-01, avg batch time: 0.4486, average train loss: 3.0758
[09/19 08:25:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0960, average loss: 2.8747
[09/19 08:25:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 35.00	
[09/19 08:26:08 visual_prompt]: 	Test 100/1152. loss: 3.025, 0.1057 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 08:26:24 visual_prompt]: 	Test 200/1152. loss: 2.880, 0.0949 s / batch. (data: 4.63e-05)max mem: 17.22454 GB 
[09/19 08:26:41 visual_prompt]: 	Test 300/1152. loss: 3.002, 0.1159 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 08:26:57 visual_prompt]: 	Test 400/1152. loss: 3.137, 0.1598 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:27:13 visual_prompt]: 	Test 500/1152. loss: 2.957, 0.1115 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 08:27:29 visual_prompt]: 	Test 600/1152. loss: 2.984, 0.1196 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 08:27:45 visual_prompt]: 	Test 700/1152. loss: 3.050, 0.0999 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 08:28:01 visual_prompt]: 	Test 800/1152. loss: 2.960, 0.1110 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/19 08:28:17 visual_prompt]: 	Test 900/1152. loss: 3.019, 0.1097 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 08:28:34 visual_prompt]: 	Test 1000/1152. loss: 2.998, 0.1164 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/19 08:28:50 visual_prompt]: 	Test 1100/1152. loss: 2.961, 0.1173 s / batch. (data: 4.05e-05)max mem: 17.22454 GB 
[09/19 08:29:02 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1091, average loss: 2.9672
[09/19 08:29:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.36	
[09/19 08:29:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/19 08:29:13 visual_prompt]: Epoch 30 / 100: avg data time: 2.26e-01, avg batch time: 0.4511, average train loss: 3.0157
[09/19 08:29:19 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.0887, average loss: 3.1520
[09/19 08:29:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 26.50	
[09/19 08:29:39 visual_prompt]: 	Test 100/1152. loss: 2.878, 0.1017 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 08:29:55 visual_prompt]: 	Test 200/1152. loss: 3.168, 0.0964 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 08:30:12 visual_prompt]: 	Test 300/1152. loss: 3.188, 0.1158 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 08:30:28 visual_prompt]: 	Test 400/1152. loss: 3.174, 0.1076 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 08:30:44 visual_prompt]: 	Test 500/1152. loss: 2.992, 0.0964 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:31:00 visual_prompt]: 	Test 600/1152. loss: 3.157, 0.1010 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 08:31:16 visual_prompt]: 	Test 700/1152. loss: 3.281, 0.0993 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 08:31:33 visual_prompt]: 	Test 800/1152. loss: 2.989, 0.1037 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 08:31:49 visual_prompt]: 	Test 900/1152. loss: 3.144, 0.0984 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 08:32:05 visual_prompt]: 	Test 1000/1152. loss: 2.995, 0.0987 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:32:21 visual_prompt]: 	Test 1100/1152. loss: 2.993, 0.0986 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 08:32:33 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1090, average loss: 3.1304
[09/19 08:32:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 29.85	
[09/19 08:32:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/19 08:32:44 visual_prompt]: Epoch 31 / 100: avg data time: 2.20e-01, avg batch time: 0.4432, average train loss: 3.0296
[09/19 08:32:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0910, average loss: 3.1039
[09/19 08:32:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 33.00	
[09/19 08:33:10 visual_prompt]: 	Test 100/1152. loss: 2.954, 0.1099 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 08:33:26 visual_prompt]: 	Test 200/1152. loss: 3.148, 0.1039 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 08:33:42 visual_prompt]: 	Test 300/1152. loss: 3.123, 0.1218 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 08:33:58 visual_prompt]: 	Test 400/1152. loss: 2.931, 0.1044 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/19 08:34:14 visual_prompt]: 	Test 500/1152. loss: 3.077, 0.1118 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 08:34:30 visual_prompt]: 	Test 600/1152. loss: 2.991, 0.1077 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 08:34:47 visual_prompt]: 	Test 700/1152. loss: 2.897, 0.1117 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/19 08:35:03 visual_prompt]: 	Test 800/1152. loss: 2.903, 0.1074 s / batch. (data: 1.78e-04)max mem: 17.22454 GB 
[09/19 08:35:19 visual_prompt]: 	Test 900/1152. loss: 2.910, 0.0996 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 08:35:35 visual_prompt]: 	Test 1000/1152. loss: 2.797, 0.1010 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 08:35:51 visual_prompt]: 	Test 1100/1152. loss: 3.234, 0.1020 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 08:36:03 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1086, average loss: 3.1119
[09/19 08:36:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 29.94	
[09/19 08:36:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/19 08:36:14 visual_prompt]: Epoch 32 / 100: avg data time: 2.12e-01, avg batch time: 0.4416, average train loss: 3.0682
[09/19 08:36:20 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.0865, average loss: 2.9029
[09/19 08:36:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 30.50	
[09/19 08:36:40 visual_prompt]: 	Test 100/1152. loss: 2.807, 0.0961 s / batch. (data: 1.06e-03)max mem: 17.22454 GB 
[09/19 08:36:56 visual_prompt]: 	Test 200/1152. loss: 3.049, 0.1094 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 08:37:13 visual_prompt]: 	Test 300/1152. loss: 3.006, 0.1059 s / batch. (data: 3.55e-05)max mem: 17.22454 GB 
[09/19 08:37:29 visual_prompt]: 	Test 400/1152. loss: 2.849, 0.0985 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 08:37:45 visual_prompt]: 	Test 500/1152. loss: 2.894, 0.0950 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 08:38:01 visual_prompt]: 	Test 600/1152. loss: 3.020, 0.1123 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 08:38:17 visual_prompt]: 	Test 700/1152. loss: 2.961, 0.1088 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/19 08:38:33 visual_prompt]: 	Test 800/1152. loss: 2.943, 0.1292 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 08:38:49 visual_prompt]: 	Test 900/1152. loss: 2.863, 0.1052 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 08:39:06 visual_prompt]: 	Test 1000/1152. loss: 2.803, 0.1310 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 08:39:22 visual_prompt]: 	Test 1100/1152. loss: 2.950, 0.1119 s / batch. (data: 1.49e-02)max mem: 17.22454 GB 
[09/19 08:39:34 visual_prompt]: Inference (test):avg data time: 2.02e-03, avg batch time: 0.1086, average loss: 2.9230
[09/19 08:39:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.05	
[09/19 08:39:34 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/19 08:39:44 visual_prompt]: Epoch 33 / 100: avg data time: 2.20e-01, avg batch time: 0.4452, average train loss: 3.0374
[09/19 08:39:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.0951, average loss: 2.9807
[09/19 08:39:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 44.00	
[09/19 08:40:11 visual_prompt]: 	Test 100/1152. loss: 3.126, 0.1193 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 08:40:27 visual_prompt]: 	Test 200/1152. loss: 2.974, 0.0974 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:40:43 visual_prompt]: 	Test 300/1152. loss: 3.064, 0.1342 s / batch. (data: 1.36e-02)max mem: 17.22454 GB 
[09/19 08:40:59 visual_prompt]: 	Test 400/1152. loss: 3.039, 0.1119 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 08:41:15 visual_prompt]: 	Test 500/1152. loss: 3.002, 0.0954 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 08:41:31 visual_prompt]: 	Test 600/1152. loss: 3.108, 0.1129 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 08:41:48 visual_prompt]: 	Test 700/1152. loss: 3.107, 0.0964 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 08:42:04 visual_prompt]: 	Test 800/1152. loss: 3.072, 0.1118 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/19 08:42:20 visual_prompt]: 	Test 900/1152. loss: 3.208, 0.0947 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 08:42:36 visual_prompt]: 	Test 1000/1152. loss: 3.197, 0.0989 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 08:42:52 visual_prompt]: 	Test 1100/1152. loss: 3.193, 0.1205 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 08:43:04 visual_prompt]: Inference (test):avg data time: 1.92e-03, avg batch time: 0.1090, average loss: 3.0582
[09/19 08:43:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 38.22	
[09/19 08:43:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/19 08:43:14 visual_prompt]: Epoch 34 / 100: avg data time: 2.14e-01, avg batch time: 0.4459, average train loss: 2.9712
[09/19 08:43:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.0940, average loss: 2.9145
[09/19 08:43:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 44.00	
[09/19 08:43:41 visual_prompt]: 	Test 100/1152. loss: 3.129, 0.0976 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 08:43:58 visual_prompt]: 	Test 200/1152. loss: 2.973, 0.1427 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 08:44:14 visual_prompt]: 	Test 300/1152. loss: 3.037, 0.1163 s / batch. (data: 2.02e-02)max mem: 17.22454 GB 
[09/19 08:44:30 visual_prompt]: 	Test 400/1152. loss: 2.962, 0.1307 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/19 08:44:46 visual_prompt]: 	Test 500/1152. loss: 3.018, 0.0951 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 08:45:02 visual_prompt]: 	Test 600/1152. loss: 3.068, 0.0989 s / batch. (data: 1.85e-04)max mem: 17.22454 GB 
[09/19 08:45:18 visual_prompt]: 	Test 700/1152. loss: 2.885, 0.0952 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/19 08:45:34 visual_prompt]: 	Test 800/1152. loss: 3.131, 0.0944 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 08:45:50 visual_prompt]: 	Test 900/1152. loss: 3.041, 0.1066 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/19 08:46:07 visual_prompt]: 	Test 1000/1152. loss: 2.953, 0.1070 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 08:46:23 visual_prompt]: 	Test 1100/1152. loss: 3.029, 0.1051 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 08:46:35 visual_prompt]: Inference (test):avg data time: 1.97e-03, avg batch time: 0.1092, average loss: 2.9776
[09/19 08:46:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 36.88	
[09/19 08:46:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/19 08:46:46 visual_prompt]: Epoch 35 / 100: avg data time: 2.20e-01, avg batch time: 0.4456, average train loss: 3.0025
[09/19 08:46:52 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.0895, average loss: 2.9331
[09/19 08:46:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 41.00	
[09/19 08:47:12 visual_prompt]: 	Test 100/1152. loss: 2.935, 0.1002 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 08:47:28 visual_prompt]: 	Test 200/1152. loss: 2.892, 0.1078 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 08:47:45 visual_prompt]: 	Test 300/1152. loss: 2.989, 0.1120 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 08:48:01 visual_prompt]: 	Test 400/1152. loss: 3.007, 0.0978 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 08:48:17 visual_prompt]: 	Test 500/1152. loss: 2.933, 0.0982 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 08:48:33 visual_prompt]: 	Test 600/1152. loss: 3.011, 0.1328 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 08:48:49 visual_prompt]: 	Test 700/1152. loss: 3.099, 0.1239 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 08:49:05 visual_prompt]: 	Test 800/1152. loss: 3.010, 0.1077 s / batch. (data: 8.99e-05)max mem: 17.22454 GB 
[09/19 08:49:21 visual_prompt]: 	Test 900/1152. loss: 3.053, 0.0991 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 08:49:37 visual_prompt]: 	Test 1000/1152. loss: 3.085, 0.0956 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 08:49:53 visual_prompt]: 	Test 1100/1152. loss: 3.080, 0.1136 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 08:50:05 visual_prompt]: Inference (test):avg data time: 1.57e-03, avg batch time: 0.1083, average loss: 3.0239
[09/19 08:50:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 36.89	
[09/19 08:50:06 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/19 08:50:16 visual_prompt]: Epoch 36 / 100: avg data time: 2.19e-01, avg batch time: 0.4464, average train loss: 3.0139
[09/19 08:50:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0899, average loss: 3.0961
[09/19 08:50:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 38.50	
[09/19 08:50:42 visual_prompt]: 	Test 100/1152. loss: 3.053, 0.0999 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 08:50:59 visual_prompt]: 	Test 200/1152. loss: 3.309, 0.0992 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 08:51:15 visual_prompt]: 	Test 300/1152. loss: 2.873, 0.1198 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 08:51:31 visual_prompt]: 	Test 400/1152. loss: 3.034, 0.1038 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 08:51:47 visual_prompt]: 	Test 500/1152. loss: 3.118, 0.1218 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 08:52:03 visual_prompt]: 	Test 600/1152. loss: 3.192, 0.1087 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 08:52:19 visual_prompt]: 	Test 700/1152. loss: 3.212, 0.0951 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 08:52:36 visual_prompt]: 	Test 800/1152. loss: 3.178, 0.1221 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 08:52:51 visual_prompt]: 	Test 900/1152. loss: 3.166, 0.0986 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 08:53:07 visual_prompt]: 	Test 1000/1152. loss: 3.097, 0.0979 s / batch. (data: 8.51e-05)max mem: 17.22454 GB 
[09/19 08:53:23 visual_prompt]: 	Test 1100/1152. loss: 3.190, 0.1320 s / batch. (data: 2.29e-02)max mem: 17.22454 GB 
[09/19 08:53:36 visual_prompt]: Inference (test):avg data time: 2.36e-03, avg batch time: 0.1089, average loss: 3.1185
[09/19 08:53:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.11	
[09/19 08:53:36 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/19 08:53:46 visual_prompt]: Epoch 37 / 100: avg data time: 2.21e-01, avg batch time: 0.4445, average train loss: 3.0490
[09/19 08:53:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.0960, average loss: 3.0848
[09/19 08:53:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 38.00	
[09/19 08:54:12 visual_prompt]: 	Test 100/1152. loss: 3.022, 0.1031 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 08:54:28 visual_prompt]: 	Test 200/1152. loss: 3.027, 0.1188 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 08:54:45 visual_prompt]: 	Test 300/1152. loss: 3.226, 0.1060 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 08:55:01 visual_prompt]: 	Test 400/1152. loss: 3.075, 0.0959 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 08:55:17 visual_prompt]: 	Test 500/1152. loss: 3.154, 0.0986 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 08:55:33 visual_prompt]: 	Test 600/1152. loss: 3.290, 0.0947 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 08:55:49 visual_prompt]: 	Test 700/1152. loss: 3.213, 0.0953 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 08:56:06 visual_prompt]: 	Test 800/1152. loss: 3.197, 0.1380 s / batch. (data: 9.78e-06)max mem: 17.22454 GB 
[09/19 08:56:22 visual_prompt]: 	Test 900/1152. loss: 3.207, 0.0949 s / batch. (data: 7.15e-05)max mem: 17.22454 GB 
[09/19 08:56:38 visual_prompt]: 	Test 1000/1152. loss: 3.114, 0.1176 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/19 08:56:54 visual_prompt]: 	Test 1100/1152. loss: 3.103, 0.1039 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 08:57:06 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1083, average loss: 3.1397
[09/19 08:57:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.04	
[09/19 08:57:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/19 08:57:17 visual_prompt]: Epoch 38 / 100: avg data time: 2.19e-01, avg batch time: 0.4431, average train loss: 2.9918
[09/19 08:57:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0928, average loss: 3.0773
[09/19 08:57:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 42.50	
[09/19 08:57:43 visual_prompt]: 	Test 100/1152. loss: 3.143, 0.1027 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 08:57:59 visual_prompt]: 	Test 200/1152. loss: 3.301, 0.0996 s / batch. (data: 3.05e-05)max mem: 17.22454 GB 
[09/19 08:58:15 visual_prompt]: 	Test 300/1152. loss: 3.192, 0.1062 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 08:58:31 visual_prompt]: 	Test 400/1152. loss: 3.243, 0.1119 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 08:58:47 visual_prompt]: 	Test 500/1152. loss: 3.050, 0.1105 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 08:59:04 visual_prompt]: 	Test 600/1152. loss: 3.215, 0.1221 s / batch. (data: 9.36e-03)max mem: 17.22454 GB 
[09/19 08:59:20 visual_prompt]: 	Test 700/1152. loss: 3.438, 0.1104 s / batch. (data: 1.33e-02)max mem: 17.22454 GB 
[09/19 08:59:36 visual_prompt]: 	Test 800/1152. loss: 3.128, 0.1273 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 08:59:52 visual_prompt]: 	Test 900/1152. loss: 3.163, 0.1123 s / batch. (data: 1.72e-04)max mem: 17.22454 GB 
[09/19 09:00:08 visual_prompt]: 	Test 1000/1152. loss: 3.142, 0.1079 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 09:00:24 visual_prompt]: 	Test 1100/1152. loss: 3.213, 0.1039 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 09:00:36 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1091, average loss: 3.1419
[09/19 09:00:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 35.90	
[09/19 09:00:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/19 09:00:46 visual_prompt]: Epoch 39 / 100: avg data time: 2.20e-01, avg batch time: 0.4466, average train loss: 2.9729
[09/19 09:00:53 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.0919, average loss: 2.8240
[09/19 09:00:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 41.00	
[09/19 09:01:13 visual_prompt]: 	Test 100/1152. loss: 2.811, 0.1185 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 09:01:29 visual_prompt]: 	Test 200/1152. loss: 2.993, 0.1159 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 09:01:45 visual_prompt]: 	Test 300/1152. loss: 2.821, 0.0980 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 09:02:02 visual_prompt]: 	Test 400/1152. loss: 2.891, 0.1199 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:02:18 visual_prompt]: 	Test 500/1152. loss: 2.855, 0.1070 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/19 09:02:34 visual_prompt]: 	Test 600/1152. loss: 2.910, 0.1011 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:02:50 visual_prompt]: 	Test 700/1152. loss: 2.739, 0.0943 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 09:03:07 visual_prompt]: 	Test 800/1152. loss: 2.736, 0.1272 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 09:03:23 visual_prompt]: 	Test 900/1152. loss: 2.917, 0.1054 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 09:03:39 visual_prompt]: 	Test 1000/1152. loss: 2.878, 0.0935 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 09:03:55 visual_prompt]: 	Test 1100/1152. loss: 2.898, 0.0945 s / batch. (data: 6.68e-05)max mem: 17.22454 GB 
[09/19 09:04:07 visual_prompt]: Inference (test):avg data time: 1.68e-03, avg batch time: 0.1080, average loss: 2.9083
[09/19 09:04:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.90	top5: 37.84	
[09/19 09:04:07 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/19 09:04:17 visual_prompt]: Epoch 40 / 100: avg data time: 2.14e-01, avg batch time: 0.4430, average train loss: 2.9240
[09/19 09:04:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0918, average loss: 2.8689
[09/19 09:04:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 42.50	
[09/19 09:04:44 visual_prompt]: 	Test 100/1152. loss: 2.998, 0.1400 s / batch. (data: 4.15e-03)max mem: 17.22454 GB 
[09/19 09:05:00 visual_prompt]: 	Test 200/1152. loss: 2.885, 0.0977 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 09:05:16 visual_prompt]: 	Test 300/1152. loss: 3.069, 0.0984 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 09:05:32 visual_prompt]: 	Test 400/1152. loss: 3.005, 0.1079 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 09:05:49 visual_prompt]: 	Test 500/1152. loss: 2.847, 0.0942 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 09:06:05 visual_prompt]: 	Test 600/1152. loss: 2.901, 0.0945 s / batch. (data: 7.94e-05)max mem: 17.22454 GB 
[09/19 09:06:21 visual_prompt]: 	Test 700/1152. loss: 3.027, 0.0950 s / batch. (data: 6.56e-05)max mem: 17.22454 GB 
[09/19 09:06:37 visual_prompt]: 	Test 800/1152. loss: 2.962, 0.1119 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 09:06:53 visual_prompt]: 	Test 900/1152. loss: 2.958, 0.1077 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 09:07:09 visual_prompt]: 	Test 1000/1152. loss: 2.991, 0.0948 s / batch. (data: 5.13e-05)max mem: 17.22454 GB 
[09/19 09:07:25 visual_prompt]: 	Test 1100/1152. loss: 2.902, 0.1159 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:07:38 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1092, average loss: 2.9324
[09/19 09:07:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.17	top5: 36.05	
[09/19 09:07:38 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/19 09:07:48 visual_prompt]: Epoch 41 / 100: avg data time: 2.25e-01, avg batch time: 0.4548, average train loss: 2.9164
[09/19 09:07:55 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.0908, average loss: 2.9429
[09/19 09:07:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 32.50	
[09/19 09:08:15 visual_prompt]: 	Test 100/1152. loss: 3.043, 0.0958 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:08:31 visual_prompt]: 	Test 200/1152. loss: 3.025, 0.0989 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 09:08:48 visual_prompt]: 	Test 300/1152. loss: 2.974, 0.1199 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 09:09:05 visual_prompt]: 	Test 400/1152. loss: 2.991, 0.1135 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 09:09:21 visual_prompt]: 	Test 500/1152. loss: 3.027, 0.1194 s / batch. (data: 8.58e-03)max mem: 17.22454 GB 
[09/19 09:09:37 visual_prompt]: 	Test 600/1152. loss: 2.950, 0.0981 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 09:09:53 visual_prompt]: 	Test 700/1152. loss: 2.771, 0.1138 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 09:10:09 visual_prompt]: 	Test 800/1152. loss: 2.912, 0.1031 s / batch. (data: 9.23e-05)max mem: 17.22454 GB 
[09/19 09:10:25 visual_prompt]: 	Test 900/1152. loss: 2.921, 0.1127 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 09:10:41 visual_prompt]: 	Test 1000/1152. loss: 2.967, 0.1319 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:10:58 visual_prompt]: 	Test 1100/1152. loss: 2.953, 0.1039 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 09:11:10 visual_prompt]: Inference (test):avg data time: 1.66e-03, avg batch time: 0.1083, average loss: 2.9697
[09/19 09:11:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 32.21	
[09/19 09:11:10 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/19 09:11:20 visual_prompt]: Epoch 42 / 100: avg data time: 2.13e-01, avg batch time: 0.4370, average train loss: 2.9249
[09/19 09:11:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.0897, average loss: 3.0197
[09/19 09:11:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.00	top5: 40.00	
[09/19 09:11:47 visual_prompt]: 	Test 100/1152. loss: 3.213, 0.0986 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 09:12:03 visual_prompt]: 	Test 200/1152. loss: 2.944, 0.1120 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 09:12:19 visual_prompt]: 	Test 300/1152. loss: 2.908, 0.1149 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 09:12:35 visual_prompt]: 	Test 400/1152. loss: 2.926, 0.1115 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/19 09:12:51 visual_prompt]: 	Test 500/1152. loss: 3.024, 0.1278 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:13:07 visual_prompt]: 	Test 600/1152. loss: 2.949, 0.1206 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 09:13:23 visual_prompt]: 	Test 700/1152. loss: 2.639, 0.0996 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 09:13:40 visual_prompt]: 	Test 800/1152. loss: 2.816, 0.0957 s / batch. (data: 3.19e-05)max mem: 17.22454 GB 
[09/19 09:13:56 visual_prompt]: 	Test 900/1152. loss: 3.152, 0.1179 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 09:14:12 visual_prompt]: 	Test 1000/1152. loss: 3.015, 0.0990 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 09:14:28 visual_prompt]: 	Test 1100/1152. loss: 3.122, 0.1206 s / batch. (data: 8.06e-05)max mem: 17.22454 GB 
[09/19 09:14:40 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1093, average loss: 2.9867
[09/19 09:14:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.66	top5: 38.17	
[09/19 09:14:40 visual_prompt]: Best epoch 42: best metric: 0.130
[09/19 09:14:40 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/19 09:14:50 visual_prompt]: Epoch 43 / 100: avg data time: 2.21e-01, avg batch time: 0.4487, average train loss: 2.9712
[09/19 09:14:57 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.0919, average loss: 2.8911
[09/19 09:14:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 37.00	
[09/19 09:15:17 visual_prompt]: 	Test 100/1152. loss: 2.702, 0.1222 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 09:15:33 visual_prompt]: 	Test 200/1152. loss: 3.117, 0.0981 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 09:15:49 visual_prompt]: 	Test 300/1152. loss: 2.856, 0.1379 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 09:16:06 visual_prompt]: 	Test 400/1152. loss: 2.850, 0.1239 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:16:21 visual_prompt]: 	Test 500/1152. loss: 2.821, 0.0968 s / batch. (data: 3.70e-05)max mem: 17.22454 GB 
[09/19 09:16:38 visual_prompt]: 	Test 600/1152. loss: 2.860, 0.1104 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 09:16:54 visual_prompt]: 	Test 700/1152. loss: 3.039, 0.1046 s / batch. (data: 7.25e-05)max mem: 17.22454 GB 
[09/19 09:17:10 visual_prompt]: 	Test 800/1152. loss: 2.865, 0.1137 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 09:17:26 visual_prompt]: 	Test 900/1152. loss: 2.796, 0.1494 s / batch. (data: 4.22e-05)max mem: 17.22454 GB 
[09/19 09:17:42 visual_prompt]: 	Test 1000/1152. loss: 2.931, 0.0982 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 09:17:58 visual_prompt]: 	Test 1100/1152. loss: 2.882, 0.1038 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 09:18:10 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1089, average loss: 2.9137
[09/19 09:18:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.60	top5: 34.78	
[09/19 09:18:10 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/19 09:18:20 visual_prompt]: Epoch 44 / 100: avg data time: 2.18e-01, avg batch time: 0.4485, average train loss: 2.9011
[09/19 09:18:27 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.0870, average loss: 2.8976
[09/19 09:18:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.00	top5: 41.00	
[09/19 09:18:47 visual_prompt]: 	Test 100/1152. loss: 2.862, 0.1377 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 09:19:03 visual_prompt]: 	Test 200/1152. loss: 3.138, 0.1238 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 09:19:20 visual_prompt]: 	Test 300/1152. loss: 3.100, 0.1076 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 09:19:36 visual_prompt]: 	Test 400/1152. loss: 3.068, 0.1034 s / batch. (data: 6.85e-03)max mem: 17.22454 GB 
[09/19 09:19:52 visual_prompt]: 	Test 500/1152. loss: 2.911, 0.1109 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 09:20:08 visual_prompt]: 	Test 600/1152. loss: 3.206, 0.1127 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 09:20:25 visual_prompt]: 	Test 700/1152. loss: 2.989, 0.1086 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 09:20:41 visual_prompt]: 	Test 800/1152. loss: 2.930, 0.1158 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 09:20:57 visual_prompt]: 	Test 900/1152. loss: 3.028, 0.1118 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:21:13 visual_prompt]: 	Test 1000/1152. loss: 2.960, 0.1143 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 09:21:29 visual_prompt]: 	Test 1100/1152. loss: 2.840, 0.0949 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 09:21:41 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1089, average loss: 2.9874
[09/19 09:21:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.24	top5: 34.28	
[09/19 09:21:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/19 09:21:51 visual_prompt]: Epoch 45 / 100: avg data time: 2.14e-01, avg batch time: 0.4355, average train loss: 2.9317
[09/19 09:21:58 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.0918, average loss: 2.7535
[09/19 09:21:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 45.00	
[09/19 09:22:18 visual_prompt]: 	Test 100/1152. loss: 2.927, 0.0985 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 09:22:35 visual_prompt]: 	Test 200/1152. loss: 3.054, 0.1181 s / batch. (data: 9.54e-03)max mem: 17.22454 GB 
[09/19 09:22:51 visual_prompt]: 	Test 300/1152. loss: 2.750, 0.1227 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/19 09:23:08 visual_prompt]: 	Test 400/1152. loss: 2.880, 0.1227 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 09:23:24 visual_prompt]: 	Test 500/1152. loss: 2.896, 0.0950 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 09:23:40 visual_prompt]: 	Test 600/1152. loss: 3.003, 0.0952 s / batch. (data: 8.99e-05)max mem: 17.22454 GB 
[09/19 09:23:56 visual_prompt]: 	Test 700/1152. loss: 2.768, 0.0948 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 09:24:12 visual_prompt]: 	Test 800/1152. loss: 2.875, 0.0969 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 09:24:29 visual_prompt]: 	Test 900/1152. loss: 2.916, 0.1007 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 09:24:45 visual_prompt]: 	Test 1000/1152. loss: 2.858, 0.1081 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 09:25:01 visual_prompt]: 	Test 1100/1152. loss: 2.876, 0.1065 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 09:25:13 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1092, average loss: 2.8516
[09/19 09:25:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.30	top5: 40.57	
[09/19 09:25:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/19 09:25:24 visual_prompt]: Epoch 46 / 100: avg data time: 2.11e-01, avg batch time: 0.4373, average train loss: 2.9512
[09/19 09:25:30 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0877, average loss: 2.9541
[09/19 09:25:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.00	top5: 39.00	
[09/19 09:25:50 visual_prompt]: 	Test 100/1152. loss: 3.228, 0.1172 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/19 09:26:06 visual_prompt]: 	Test 200/1152. loss: 3.209, 0.0970 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 09:26:22 visual_prompt]: 	Test 300/1152. loss: 3.154, 0.1113 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 09:26:38 visual_prompt]: 	Test 400/1152. loss: 3.215, 0.0946 s / batch. (data: 5.13e-05)max mem: 17.22454 GB 
[09/19 09:26:55 visual_prompt]: 	Test 500/1152. loss: 3.226, 0.1115 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 09:27:11 visual_prompt]: 	Test 600/1152. loss: 3.235, 0.0959 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/19 09:27:27 visual_prompt]: 	Test 700/1152. loss: 3.022, 0.0949 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 09:27:43 visual_prompt]: 	Test 800/1152. loss: 3.297, 0.0940 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 09:27:59 visual_prompt]: 	Test 900/1152. loss: 3.053, 0.1036 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 09:28:15 visual_prompt]: 	Test 1000/1152. loss: 3.168, 0.1478 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:28:31 visual_prompt]: 	Test 1100/1152. loss: 3.059, 0.0974 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 09:28:43 visual_prompt]: Inference (test):avg data time: 2.16e-03, avg batch time: 0.1087, average loss: 3.1216
[09/19 09:28:43 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.67	top5: 34.30	
[09/19 09:28:43 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/19 09:28:53 visual_prompt]: Epoch 47 / 100: avg data time: 2.16e-01, avg batch time: 0.4375, average train loss: 2.9952
[09/19 09:29:00 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.0939, average loss: 2.8526
[09/19 09:29:00 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 50.00	
[09/19 09:29:20 visual_prompt]: 	Test 100/1152. loss: 2.939, 0.1160 s / batch. (data: 3.44e-03)max mem: 17.22454 GB 
[09/19 09:29:36 visual_prompt]: 	Test 200/1152. loss: 3.202, 0.1118 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 09:29:52 visual_prompt]: 	Test 300/1152. loss: 3.146, 0.1138 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 09:30:08 visual_prompt]: 	Test 400/1152. loss: 2.923, 0.1032 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 09:30:24 visual_prompt]: 	Test 500/1152. loss: 2.940, 0.0950 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 09:30:40 visual_prompt]: 	Test 600/1152. loss: 3.074, 0.0994 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:30:56 visual_prompt]: 	Test 700/1152. loss: 2.748, 0.1159 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 09:31:12 visual_prompt]: 	Test 800/1152. loss: 2.868, 0.1001 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 09:31:28 visual_prompt]: 	Test 900/1152. loss: 2.939, 0.0955 s / batch. (data: 5.10e-05)max mem: 17.22454 GB 
[09/19 09:31:45 visual_prompt]: 	Test 1000/1152. loss: 2.944, 0.1339 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 09:32:01 visual_prompt]: 	Test 1100/1152. loss: 3.085, 0.0999 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 09:32:13 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1090, average loss: 3.0153
[09/19 09:32:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.49	top5: 40.93	
[09/19 09:32:14 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/19 09:32:24 visual_prompt]: Epoch 48 / 100: avg data time: 2.29e-01, avg batch time: 0.4554, average train loss: 2.9232
[09/19 09:32:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.0868, average loss: 2.7934
[09/19 09:32:31 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.50	top5: 36.50	
[09/19 09:32:51 visual_prompt]: 	Test 100/1152. loss: 2.808, 0.1308 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/19 09:33:07 visual_prompt]: 	Test 200/1152. loss: 2.955, 0.1037 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 09:33:23 visual_prompt]: 	Test 300/1152. loss: 2.845, 0.1029 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 09:33:40 visual_prompt]: 	Test 400/1152. loss: 2.820, 0.1196 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 09:33:56 visual_prompt]: 	Test 500/1152. loss: 2.836, 0.1327 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 09:34:12 visual_prompt]: 	Test 600/1152. loss: 2.865, 0.1071 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 09:34:29 visual_prompt]: 	Test 700/1152. loss: 2.766, 0.1023 s / batch. (data: 3.32e-03)max mem: 17.22454 GB 
[09/19 09:34:45 visual_prompt]: 	Test 800/1152. loss: 2.767, 0.1520 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 09:35:02 visual_prompt]: 	Test 900/1152. loss: 2.727, 0.0944 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 09:35:18 visual_prompt]: 	Test 1000/1152. loss: 2.776, 0.1025 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:35:34 visual_prompt]: 	Test 1100/1152. loss: 2.777, 0.0970 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 09:35:47 visual_prompt]: Inference (test):avg data time: 2.24e-03, avg batch time: 0.1092, average loss: 2.8313
[09/19 09:35:47 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.12	top5: 34.43	
[09/19 09:35:47 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/19 09:35:57 visual_prompt]: Epoch 49 / 100: avg data time: 2.20e-01, avg batch time: 0.4439, average train loss: 2.8916
[09/19 09:36:04 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.0906, average loss: 2.7638
[09/19 09:36:04 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.50	top5: 42.50	
[09/19 09:36:24 visual_prompt]: 	Test 100/1152. loss: 2.734, 0.0950 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/19 09:36:40 visual_prompt]: 	Test 200/1152. loss: 2.980, 0.1182 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/19 09:36:57 visual_prompt]: 	Test 300/1152. loss: 2.729, 0.0943 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 09:37:13 visual_prompt]: 	Test 400/1152. loss: 2.820, 0.1403 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 09:37:29 visual_prompt]: 	Test 500/1152. loss: 2.824, 0.1198 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 09:37:46 visual_prompt]: 	Test 600/1152. loss: 2.773, 0.1006 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 09:38:02 visual_prompt]: 	Test 700/1152. loss: 2.742, 0.1150 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 09:38:18 visual_prompt]: 	Test 800/1152. loss: 2.687, 0.1433 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:38:34 visual_prompt]: 	Test 900/1152. loss: 2.799, 0.0985 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 09:38:50 visual_prompt]: 	Test 1000/1152. loss: 2.850, 0.1451 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/19 09:39:06 visual_prompt]: 	Test 1100/1152. loss: 2.726, 0.1019 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 09:39:18 visual_prompt]: Inference (test):avg data time: 2.12e-03, avg batch time: 0.1093, average loss: 2.8395
[09/19 09:39:19 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.75	top5: 40.77	
[09/19 09:39:19 visual_prompt]: Best epoch 49: best metric: 0.135
[09/19 09:39:19 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/19 09:39:29 visual_prompt]: Epoch 50 / 100: avg data time: 2.31e-01, avg batch time: 0.4570, average train loss: 2.8327
[09/19 09:39:36 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.0879, average loss: 2.7392
[09/19 09:39:36 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.00	top5: 46.50	
[09/19 09:39:56 visual_prompt]: 	Test 100/1152. loss: 2.759, 0.0999 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 09:40:12 visual_prompt]: 	Test 200/1152. loss: 2.852, 0.1080 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 09:40:28 visual_prompt]: 	Test 300/1152. loss: 2.853, 0.0979 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:40:45 visual_prompt]: 	Test 400/1152. loss: 2.845, 0.0973 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 09:41:01 visual_prompt]: 	Test 500/1152. loss: 2.767, 0.1320 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 09:41:17 visual_prompt]: 	Test 600/1152. loss: 2.823, 0.0955 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 09:41:34 visual_prompt]: 	Test 700/1152. loss: 2.843, 0.1099 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 09:41:50 visual_prompt]: 	Test 800/1152. loss: 2.741, 0.1828 s / batch. (data: 1.38e-05)max mem: 17.22454 GB 
[09/19 09:42:06 visual_prompt]: 	Test 900/1152. loss: 2.812, 0.1085 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 09:42:23 visual_prompt]: 	Test 1000/1152. loss: 2.834, 0.1238 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 09:42:39 visual_prompt]: 	Test 1100/1152. loss: 2.803, 0.1199 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 09:42:52 visual_prompt]: Inference (test):avg data time: 1.60e-03, avg batch time: 0.1081, average loss: 2.8236
[09/19 09:42:52 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.90	top5: 39.83	
[09/19 09:42:52 visual_prompt]: Best epoch 50: best metric: 0.140
[09/19 09:42:52 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/19 09:43:02 visual_prompt]: Epoch 51 / 100: avg data time: 2.26e-01, avg batch time: 0.4519, average train loss: 2.9249
[09/19 09:43:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1034, average loss: 3.0230
[09/19 09:43:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.00	top5: 35.50	
[09/19 09:43:29 visual_prompt]: 	Test 100/1152. loss: 3.235, 0.1191 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/19 09:43:45 visual_prompt]: 	Test 200/1152. loss: 3.009, 0.1041 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 09:44:02 visual_prompt]: 	Test 300/1152. loss: 3.057, 0.0992 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 09:44:18 visual_prompt]: 	Test 400/1152. loss: 3.049, 0.1138 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 09:44:34 visual_prompt]: 	Test 500/1152. loss: 3.090, 0.0956 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 09:44:51 visual_prompt]: 	Test 600/1152. loss: 3.148, 0.1382 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 09:45:07 visual_prompt]: 	Test 700/1152. loss: 2.837, 0.0958 s / batch. (data: 1.24e-05)max mem: 17.22454 GB 
[09/19 09:45:23 visual_prompt]: 	Test 800/1152. loss: 3.092, 0.1106 s / batch. (data: 9.93e-03)max mem: 17.22454 GB 
[09/19 09:45:38 visual_prompt]: 	Test 900/1152. loss: 3.210, 0.1004 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 09:45:55 visual_prompt]: 	Test 1000/1152. loss: 3.102, 0.1117 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 09:46:11 visual_prompt]: 	Test 1100/1152. loss: 2.938, 0.1070 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 09:46:23 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1084, average loss: 3.0106
[09/19 09:46:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.55	top5: 34.43	
[09/19 09:46:23 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/19 09:46:33 visual_prompt]: Epoch 52 / 100: avg data time: 2.08e-01, avg batch time: 0.4324, average train loss: 2.9393
[09/19 09:46:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.0868, average loss: 2.8534
[09/19 09:46:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 39.50	
[09/19 09:46:59 visual_prompt]: 	Test 100/1152. loss: 3.084, 0.0944 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 09:47:15 visual_prompt]: 	Test 200/1152. loss: 2.867, 0.0946 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 09:47:32 visual_prompt]: 	Test 300/1152. loss: 3.063, 0.1078 s / batch. (data: 9.25e-05)max mem: 17.22454 GB 
[09/19 09:47:48 visual_prompt]: 	Test 400/1152. loss: 3.019, 0.1000 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 09:48:04 visual_prompt]: 	Test 500/1152. loss: 3.041, 0.1279 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 09:48:20 visual_prompt]: 	Test 600/1152. loss: 3.145, 0.1079 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 09:48:36 visual_prompt]: 	Test 700/1152. loss: 2.990, 0.1067 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 09:48:52 visual_prompt]: 	Test 800/1152. loss: 3.160, 0.1275 s / batch. (data: 7.45e-03)max mem: 17.22454 GB 
[09/19 09:49:08 visual_prompt]: 	Test 900/1152. loss: 3.094, 0.0968 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 09:49:24 visual_prompt]: 	Test 1000/1152. loss: 3.078, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 09:49:40 visual_prompt]: 	Test 1100/1152. loss: 2.840, 0.1119 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 09:49:52 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1086, average loss: 2.9732
[09/19 09:49:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.19	top5: 36.66	
[09/19 09:49:53 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/19 09:50:03 visual_prompt]: Epoch 53 / 100: avg data time: 2.19e-01, avg batch time: 0.4440, average train loss: 2.8123
[09/19 09:50:09 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.0880, average loss: 2.7853
[09/19 09:50:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.00	top5: 34.50	
[09/19 09:50:29 visual_prompt]: 	Test 100/1152. loss: 2.985, 0.0985 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 09:50:45 visual_prompt]: 	Test 200/1152. loss: 2.812, 0.1010 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 09:51:02 visual_prompt]: 	Test 300/1152. loss: 2.825, 0.1556 s / batch. (data: 2.31e-02)max mem: 17.22454 GB 
[09/19 09:51:18 visual_prompt]: 	Test 400/1152. loss: 2.810, 0.0979 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 09:51:34 visual_prompt]: 	Test 500/1152. loss: 2.843, 0.1199 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 09:51:50 visual_prompt]: 	Test 600/1152. loss: 2.785, 0.0976 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 09:52:06 visual_prompt]: 	Test 700/1152. loss: 2.798, 0.0962 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 09:52:22 visual_prompt]: 	Test 800/1152. loss: 2.872, 0.1278 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 09:52:39 visual_prompt]: 	Test 900/1152. loss: 2.915, 0.1198 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 09:52:54 visual_prompt]: 	Test 1000/1152. loss: 2.982, 0.1118 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 09:53:10 visual_prompt]: 	Test 1100/1152. loss: 2.796, 0.1104 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 09:53:23 visual_prompt]: Inference (test):avg data time: 2.25e-03, avg batch time: 0.1094, average loss: 2.8539
[09/19 09:53:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.25	top5: 38.11	
[09/19 09:53:23 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/19 09:53:33 visual_prompt]: Epoch 54 / 100: avg data time: 2.27e-01, avg batch time: 0.4539, average train loss: 2.8132
[09/19 09:53:40 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.0905, average loss: 2.7192
[09/19 09:53:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 42.50	
[09/19 09:53:59 visual_prompt]: 	Test 100/1152. loss: 2.839, 0.1039 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 09:54:16 visual_prompt]: 	Test 200/1152. loss: 2.786, 0.1237 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/19 09:54:32 visual_prompt]: 	Test 300/1152. loss: 2.742, 0.1168 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 09:54:48 visual_prompt]: 	Test 400/1152. loss: 2.803, 0.0961 s / batch. (data: 6.96e-05)max mem: 17.22454 GB 
[09/19 09:55:05 visual_prompt]: 	Test 500/1152. loss: 2.824, 0.1027 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 09:55:21 visual_prompt]: 	Test 600/1152. loss: 2.825, 0.1091 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 09:55:37 visual_prompt]: 	Test 700/1152. loss: 2.779, 0.1128 s / batch. (data: 3.15e-03)max mem: 17.22454 GB 
[09/19 09:55:53 visual_prompt]: 	Test 800/1152. loss: 2.790, 0.1229 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 09:56:09 visual_prompt]: 	Test 900/1152. loss: 2.799, 0.0985 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 09:56:25 visual_prompt]: 	Test 1000/1152. loss: 2.811, 0.1076 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 09:56:42 visual_prompt]: 	Test 1100/1152. loss: 2.724, 0.1078 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 09:56:54 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1088, average loss: 2.7768
[09/19 09:56:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.75	top5: 37.96	
[09/19 09:56:54 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/19 09:57:04 visual_prompt]: Epoch 55 / 100: avg data time: 2.12e-01, avg batch time: 0.4386, average train loss: 2.7930
[09/19 09:57:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.0904, average loss: 2.9110
[09/19 09:57:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.00	top5: 37.00	
[09/19 09:57:30 visual_prompt]: 	Test 100/1152. loss: 2.990, 0.0978 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 09:57:47 visual_prompt]: 	Test 200/1152. loss: 3.017, 0.0981 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 09:58:03 visual_prompt]: 	Test 300/1152. loss: 3.056, 0.1318 s / batch. (data: 9.75e-05)max mem: 17.22454 GB 
[09/19 09:58:19 visual_prompt]: 	Test 400/1152. loss: 2.901, 0.0984 s / batch. (data: 9.47e-05)max mem: 17.22454 GB 
[09/19 09:58:35 visual_prompt]: 	Test 500/1152. loss: 3.048, 0.1079 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 09:58:51 visual_prompt]: 	Test 600/1152. loss: 3.002, 0.1116 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 09:59:08 visual_prompt]: 	Test 700/1152. loss: 2.720, 0.1080 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 09:59:24 visual_prompt]: 	Test 800/1152. loss: 3.024, 0.1430 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 09:59:41 visual_prompt]: 	Test 900/1152. loss: 2.948, 0.1302 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 09:59:57 visual_prompt]: 	Test 1000/1152. loss: 2.970, 0.0950 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 10:00:13 visual_prompt]: 	Test 1100/1152. loss: 2.978, 0.1121 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 10:00:26 visual_prompt]: Inference (test):avg data time: 1.54e-03, avg batch time: 0.1076, average loss: 2.9933
[09/19 10:00:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.36	top5: 34.77	
[09/19 10:00:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/19 10:00:36 visual_prompt]: Epoch 56 / 100: avg data time: 2.22e-01, avg batch time: 0.4482, average train loss: 2.8385
[09/19 10:00:43 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.0954, average loss: 2.7938
[09/19 10:00:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 36.50	
[09/19 10:01:03 visual_prompt]: 	Test 100/1152. loss: 2.734, 0.1263 s / batch. (data: 1.55e-02)max mem: 17.22454 GB 
[09/19 10:01:19 visual_prompt]: 	Test 200/1152. loss: 2.846, 0.1078 s / batch. (data: 3.30e-03)max mem: 17.22454 GB 
[09/19 10:01:35 visual_prompt]: 	Test 300/1152. loss: 2.769, 0.1104 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 10:01:51 visual_prompt]: 	Test 400/1152. loss: 2.841, 0.0950 s / batch. (data: 4.63e-05)max mem: 17.22454 GB 
[09/19 10:02:08 visual_prompt]: 	Test 500/1152. loss: 2.749, 0.0971 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 10:02:24 visual_prompt]: 	Test 600/1152. loss: 2.761, 0.1164 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 10:02:40 visual_prompt]: 	Test 700/1152. loss: 2.816, 0.1072 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:02:56 visual_prompt]: 	Test 800/1152. loss: 2.756, 0.0946 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/19 10:03:12 visual_prompt]: 	Test 900/1152. loss: 2.807, 0.1397 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:03:28 visual_prompt]: 	Test 1000/1152. loss: 2.930, 0.0997 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 10:03:44 visual_prompt]: 	Test 1100/1152. loss: 2.769, 0.0997 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 10:03:57 visual_prompt]: Inference (test):avg data time: 1.92e-03, avg batch time: 0.1092, average loss: 2.8398
[09/19 10:03:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.19	top5: 36.06	
[09/19 10:03:57 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/19 10:04:07 visual_prompt]: Epoch 57 / 100: avg data time: 2.16e-01, avg batch time: 0.4428, average train loss: 2.7910
[09/19 10:04:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0915, average loss: 2.6513
[09/19 10:04:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 55.50	
[09/19 10:04:33 visual_prompt]: 	Test 100/1152. loss: 2.802, 0.1197 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 10:04:49 visual_prompt]: 	Test 200/1152. loss: 2.877, 0.1185 s / batch. (data: 9.90e-03)max mem: 17.22454 GB 
[09/19 10:05:06 visual_prompt]: 	Test 300/1152. loss: 2.842, 0.1040 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 10:05:22 visual_prompt]: 	Test 400/1152. loss: 2.771, 0.1235 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 10:05:38 visual_prompt]: 	Test 500/1152. loss: 2.736, 0.0976 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 10:05:54 visual_prompt]: 	Test 600/1152. loss: 2.886, 0.0978 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/19 10:06:10 visual_prompt]: 	Test 700/1152. loss: 2.607, 0.0998 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:06:26 visual_prompt]: 	Test 800/1152. loss: 2.706, 0.0949 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 10:06:42 visual_prompt]: 	Test 900/1152. loss: 2.771, 0.0989 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 10:06:58 visual_prompt]: 	Test 1000/1152. loss: 2.947, 0.1054 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 10:07:14 visual_prompt]: 	Test 1100/1152. loss: 2.673, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 10:07:26 visual_prompt]: Inference (test):avg data time: 2.21e-03, avg batch time: 0.1088, average loss: 2.7842
[09/19 10:07:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.17	top5: 45.10	
[09/19 10:07:27 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/19 10:07:37 visual_prompt]: Epoch 58 / 100: avg data time: 2.19e-01, avg batch time: 0.4458, average train loss: 2.7689
[09/19 10:07:43 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.0944, average loss: 2.7327
[09/19 10:07:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.50	top5: 42.50	
[09/19 10:08:03 visual_prompt]: 	Test 100/1152. loss: 2.746, 0.0987 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 10:08:20 visual_prompt]: 	Test 200/1152. loss: 2.942, 0.0973 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:08:36 visual_prompt]: 	Test 300/1152. loss: 2.819, 0.1180 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:08:52 visual_prompt]: 	Test 400/1152. loss: 2.840, 0.1038 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 10:09:08 visual_prompt]: 	Test 500/1152. loss: 2.709, 0.1215 s / batch. (data: 8.82e-03)max mem: 17.22454 GB 
[09/19 10:09:24 visual_prompt]: 	Test 600/1152. loss: 2.874, 0.1106 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 10:09:40 visual_prompt]: 	Test 700/1152. loss: 2.777, 0.0950 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/19 10:09:56 visual_prompt]: 	Test 800/1152. loss: 2.700, 0.0950 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/19 10:10:13 visual_prompt]: 	Test 900/1152. loss: 2.816, 0.1094 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 10:10:29 visual_prompt]: 	Test 1000/1152. loss: 2.800, 0.0952 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 10:10:45 visual_prompt]: 	Test 1100/1152. loss: 2.846, 0.0946 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 10:10:57 visual_prompt]: Inference (test):avg data time: 1.52e-03, avg batch time: 0.1081, average loss: 2.7930
[09/19 10:10:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.52	top5: 39.49	
[09/19 10:10:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/19 10:11:07 visual_prompt]: Epoch 59 / 100: avg data time: 2.21e-01, avg batch time: 0.4423, average train loss: 2.7443
[09/19 10:11:14 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.0873, average loss: 2.7916
[09/19 10:11:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 39.00	
[09/19 10:11:33 visual_prompt]: 	Test 100/1152. loss: 2.743, 0.1119 s / batch. (data: 8.73e-05)max mem: 17.22454 GB 
[09/19 10:11:50 visual_prompt]: 	Test 200/1152. loss: 2.804, 0.1171 s / batch. (data: 2.09e-02)max mem: 17.22454 GB 
[09/19 10:12:06 visual_prompt]: 	Test 300/1152. loss: 2.776, 0.1089 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 10:12:22 visual_prompt]: 	Test 400/1152. loss: 2.703, 0.1194 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 10:12:39 visual_prompt]: 	Test 500/1152. loss: 2.756, 0.0995 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:12:55 visual_prompt]: 	Test 600/1152. loss: 2.788, 0.1313 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 10:13:11 visual_prompt]: 	Test 700/1152. loss: 2.775, 0.0952 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 10:13:27 visual_prompt]: 	Test 800/1152. loss: 2.731, 0.1239 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 10:13:43 visual_prompt]: 	Test 900/1152. loss: 2.826, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 10:13:59 visual_prompt]: 	Test 1000/1152. loss: 2.818, 0.1742 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 10:14:15 visual_prompt]: 	Test 1100/1152. loss: 2.740, 0.1047 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 10:14:27 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1089, average loss: 2.7795
[09/19 10:14:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.38	top5: 40.49	
[09/19 10:14:28 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/19 10:14:38 visual_prompt]: Epoch 60 / 100: avg data time: 2.29e-01, avg batch time: 0.4511, average train loss: 2.7092
[09/19 10:14:45 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0887, average loss: 2.7318
[09/19 10:14:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.00	top5: 44.50	
[09/19 10:15:04 visual_prompt]: 	Test 100/1152. loss: 2.906, 0.1290 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 10:15:20 visual_prompt]: 	Test 200/1152. loss: 2.775, 0.1119 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 10:15:37 visual_prompt]: 	Test 300/1152. loss: 2.896, 0.0952 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:15:53 visual_prompt]: 	Test 400/1152. loss: 2.874, 0.0998 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 10:16:09 visual_prompt]: 	Test 500/1152. loss: 2.775, 0.0977 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 10:16:25 visual_prompt]: 	Test 600/1152. loss: 2.899, 0.1108 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/19 10:16:41 visual_prompt]: 	Test 700/1152. loss: 2.801, 0.1035 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 10:16:58 visual_prompt]: 	Test 800/1152. loss: 2.718, 0.1003 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 10:17:14 visual_prompt]: 	Test 900/1152. loss: 2.866, 0.1077 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 10:17:30 visual_prompt]: 	Test 1000/1152. loss: 2.843, 0.1172 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 10:17:46 visual_prompt]: 	Test 1100/1152. loss: 2.777, 0.0986 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 10:17:58 visual_prompt]: Inference (test):avg data time: 1.97e-03, avg batch time: 0.1078, average loss: 2.8237
[09/19 10:17:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.08	top5: 40.54	
[09/19 10:17:58 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/19 10:18:08 visual_prompt]: Epoch 61 / 100: avg data time: 2.14e-01, avg batch time: 0.4401, average train loss: 2.6976
[09/19 10:18:15 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.0928, average loss: 2.6817
[09/19 10:18:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 45.50	
[09/19 10:18:34 visual_prompt]: 	Test 100/1152. loss: 2.980, 0.1158 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 10:18:51 visual_prompt]: 	Test 200/1152. loss: 2.907, 0.1078 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 10:19:07 visual_prompt]: 	Test 300/1152. loss: 2.805, 0.1083 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 10:19:23 visual_prompt]: 	Test 400/1152. loss: 2.853, 0.1120 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:19:39 visual_prompt]: 	Test 500/1152. loss: 2.781, 0.1083 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 10:19:55 visual_prompt]: 	Test 600/1152. loss: 2.982, 0.1153 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 10:20:12 visual_prompt]: 	Test 700/1152. loss: 2.731, 0.1037 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 10:20:28 visual_prompt]: 	Test 800/1152. loss: 2.825, 0.1107 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 10:20:44 visual_prompt]: 	Test 900/1152. loss: 2.996, 0.0980 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 10:21:00 visual_prompt]: 	Test 1000/1152. loss: 2.914, 0.1451 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 10:21:17 visual_prompt]: 	Test 1100/1152. loss: 2.887, 0.1477 s / batch. (data: 4.79e-05)max mem: 17.22454 GB 
[09/19 10:21:29 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1088, average loss: 2.8243
[09/19 10:21:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 39.96	
[09/19 10:21:29 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/19 10:21:39 visual_prompt]: Epoch 62 / 100: avg data time: 2.05e-01, avg batch time: 0.4373, average train loss: 2.7521
[09/19 10:21:46 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.0931, average loss: 2.6272
[09/19 10:21:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.00	top5: 49.50	
[09/19 10:22:05 visual_prompt]: 	Test 100/1152. loss: 2.882, 0.0990 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 10:22:22 visual_prompt]: 	Test 200/1152. loss: 2.827, 0.1040 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 10:22:38 visual_prompt]: 	Test 300/1152. loss: 2.727, 0.1158 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 10:22:54 visual_prompt]: 	Test 400/1152. loss: 2.797, 0.1083 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 10:23:10 visual_prompt]: 	Test 500/1152. loss: 2.857, 0.1042 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:23:26 visual_prompt]: 	Test 600/1152. loss: 2.950, 0.0996 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 10:23:42 visual_prompt]: 	Test 700/1152. loss: 2.645, 0.0980 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:23:58 visual_prompt]: 	Test 800/1152. loss: 2.783, 0.0998 s / batch. (data: 4.08e-05)max mem: 17.22454 GB 
[09/19 10:24:14 visual_prompt]: 	Test 900/1152. loss: 2.867, 0.1237 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 10:24:30 visual_prompt]: 	Test 1000/1152. loss: 2.806, 0.0949 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 10:24:46 visual_prompt]: 	Test 1100/1152. loss: 2.745, 0.0952 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 10:24:58 visual_prompt]: Inference (test):avg data time: 2.13e-03, avg batch time: 0.1089, average loss: 2.7712
[09/19 10:24:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.86	top5: 42.16	
[09/19 10:24:59 visual_prompt]: Best epoch 62: best metric: 0.150
[09/19 10:24:59 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/19 10:25:09 visual_prompt]: Epoch 63 / 100: avg data time: 2.15e-01, avg batch time: 0.4407, average train loss: 2.7133
[09/19 10:25:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.0874, average loss: 2.5949
[09/19 10:25:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 52.50	
[09/19 10:25:35 visual_prompt]: 	Test 100/1152. loss: 2.690, 0.1048 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 10:25:51 visual_prompt]: 	Test 200/1152. loss: 2.740, 0.1160 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 10:26:07 visual_prompt]: 	Test 300/1152. loss: 2.745, 0.0999 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:26:24 visual_prompt]: 	Test 400/1152. loss: 2.748, 0.1148 s / batch. (data: 9.97e-03)max mem: 17.22454 GB 
[09/19 10:26:40 visual_prompt]: 	Test 500/1152. loss: 2.800, 0.1118 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 10:26:56 visual_prompt]: 	Test 600/1152. loss: 2.918, 0.0971 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 10:27:12 visual_prompt]: 	Test 700/1152. loss: 2.754, 0.1200 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 10:27:28 visual_prompt]: 	Test 800/1152. loss: 2.677, 0.1079 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 10:27:44 visual_prompt]: 	Test 900/1152. loss: 2.746, 0.1108 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 10:28:00 visual_prompt]: 	Test 1000/1152. loss: 2.730, 0.0998 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 10:28:16 visual_prompt]: 	Test 1100/1152. loss: 2.605, 0.0995 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 10:28:28 visual_prompt]: Inference (test):avg data time: 2.38e-03, avg batch time: 0.1097, average loss: 2.7412
[09/19 10:28:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.13	top5: 45.55	
[09/19 10:28:28 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/19 10:28:38 visual_prompt]: Epoch 64 / 100: avg data time: 2.15e-01, avg batch time: 0.4410, average train loss: 2.6835
[09/19 10:28:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.0904, average loss: 2.6873
[09/19 10:28:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 43.50	
[09/19 10:29:04 visual_prompt]: 	Test 100/1152. loss: 2.769, 0.1012 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 10:29:21 visual_prompt]: 	Test 200/1152. loss: 2.876, 0.1040 s / batch. (data: 8.01e-03)max mem: 17.22454 GB 
[09/19 10:29:37 visual_prompt]: 	Test 300/1152. loss: 2.760, 0.1083 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:29:54 visual_prompt]: 	Test 400/1152. loss: 2.849, 0.0982 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 10:30:10 visual_prompt]: 	Test 500/1152. loss: 2.734, 0.0962 s / batch. (data: 8.96e-05)max mem: 17.22454 GB 
[09/19 10:30:26 visual_prompt]: 	Test 600/1152. loss: 2.748, 0.1105 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 10:30:42 visual_prompt]: 	Test 700/1152. loss: 2.710, 0.1158 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:30:59 visual_prompt]: 	Test 800/1152. loss: 2.688, 0.0945 s / batch. (data: 6.70e-05)max mem: 17.22454 GB 
[09/19 10:31:15 visual_prompt]: 	Test 900/1152. loss: 2.766, 0.1003 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 10:31:31 visual_prompt]: 	Test 1000/1152. loss: 2.904, 0.0948 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 10:31:47 visual_prompt]: 	Test 1100/1152. loss: 2.687, 0.1148 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 10:31:59 visual_prompt]: Inference (test):avg data time: 2.14e-03, avg batch time: 0.1088, average loss: 2.7796
[09/19 10:32:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.89	top5: 39.88	
[09/19 10:32:00 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/19 10:32:10 visual_prompt]: Epoch 65 / 100: avg data time: 2.14e-01, avg batch time: 0.4419, average train loss: 2.6588
[09/19 10:32:17 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.0971, average loss: 2.6245
[09/19 10:32:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.50	top5: 48.00	
[09/19 10:32:36 visual_prompt]: 	Test 100/1152. loss: 2.702, 0.1239 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 10:32:53 visual_prompt]: 	Test 200/1152. loss: 2.775, 0.1118 s / batch. (data: 8.56e-05)max mem: 17.22454 GB 
[09/19 10:33:09 visual_prompt]: 	Test 300/1152. loss: 2.687, 0.1033 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 10:33:25 visual_prompt]: 	Test 400/1152. loss: 2.717, 0.1120 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/19 10:33:41 visual_prompt]: 	Test 500/1152. loss: 2.716, 0.1413 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 10:33:57 visual_prompt]: 	Test 600/1152. loss: 2.727, 0.0965 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 10:34:14 visual_prompt]: 	Test 700/1152. loss: 2.606, 0.1079 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 10:34:30 visual_prompt]: 	Test 800/1152. loss: 2.676, 0.1118 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 10:34:46 visual_prompt]: 	Test 900/1152. loss: 2.712, 0.1083 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/19 10:35:02 visual_prompt]: 	Test 1000/1152. loss: 2.910, 0.1158 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 10:35:18 visual_prompt]: 	Test 1100/1152. loss: 2.695, 0.0975 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:35:30 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1086, average loss: 2.7665
[09/19 10:35:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.37	top5: 39.00	
[09/19 10:35:31 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/19 10:35:41 visual_prompt]: Epoch 66 / 100: avg data time: 2.11e-01, avg batch time: 0.4416, average train loss: 2.6337
[09/19 10:35:47 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.0875, average loss: 2.5350
[09/19 10:35:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.00	top5: 59.50	
[09/19 10:36:07 visual_prompt]: 	Test 100/1152. loss: 2.818, 0.1048 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:36:24 visual_prompt]: 	Test 200/1152. loss: 2.887, 0.1334 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 10:36:40 visual_prompt]: 	Test 300/1152. loss: 2.840, 0.1084 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 10:36:57 visual_prompt]: 	Test 400/1152. loss: 2.773, 0.1265 s / batch. (data: 1.19e-02)max mem: 17.22454 GB 
[09/19 10:37:13 visual_prompt]: 	Test 500/1152. loss: 2.709, 0.0958 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 10:37:29 visual_prompt]: 	Test 600/1152. loss: 2.866, 0.0994 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 10:37:46 visual_prompt]: 	Test 700/1152. loss: 2.551, 0.1279 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 10:38:02 visual_prompt]: 	Test 800/1152. loss: 2.700, 0.0967 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:38:18 visual_prompt]: 	Test 900/1152. loss: 2.730, 0.1158 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 10:38:34 visual_prompt]: 	Test 1000/1152. loss: 2.910, 0.0988 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 10:38:51 visual_prompt]: 	Test 1100/1152. loss: 2.638, 0.0956 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 10:39:03 visual_prompt]: Inference (test):avg data time: 2.30e-03, avg batch time: 0.1093, average loss: 2.7633
[09/19 10:39:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.03	top5: 45.44	
[09/19 10:39:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/19 10:39:14 visual_prompt]: Epoch 67 / 100: avg data time: 2.16e-01, avg batch time: 0.4431, average train loss: 2.5885
[09/19 10:39:20 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.0866, average loss: 2.5330
[09/19 10:39:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.50	top5: 57.00	
[09/19 10:39:40 visual_prompt]: 	Test 100/1152. loss: 2.731, 0.1127 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:39:56 visual_prompt]: 	Test 200/1152. loss: 2.713, 0.1040 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 10:40:13 visual_prompt]: 	Test 300/1152. loss: 2.754, 0.1110 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 10:40:29 visual_prompt]: 	Test 400/1152. loss: 2.688, 0.1015 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/19 10:40:45 visual_prompt]: 	Test 500/1152. loss: 2.747, 0.1111 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 10:41:01 visual_prompt]: 	Test 600/1152. loss: 2.767, 0.1090 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 10:41:17 visual_prompt]: 	Test 700/1152. loss: 2.477, 0.0995 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:41:33 visual_prompt]: 	Test 800/1152. loss: 2.611, 0.1038 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 10:41:49 visual_prompt]: 	Test 900/1152. loss: 2.647, 0.1207 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 10:42:06 visual_prompt]: 	Test 1000/1152. loss: 2.624, 0.1360 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 10:42:22 visual_prompt]: 	Test 1100/1152. loss: 2.562, 0.1004 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 10:42:34 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1084, average loss: 2.6865
[09/19 10:42:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.52	top5: 46.07	
[09/19 10:42:35 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/19 10:42:45 visual_prompt]: Epoch 68 / 100: avg data time: 2.24e-01, avg batch time: 0.4470, average train loss: 2.6374
[09/19 10:42:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.0883, average loss: 2.5779
[09/19 10:42:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.50	top5: 57.00	
[09/19 10:43:11 visual_prompt]: 	Test 100/1152. loss: 2.769, 0.1039 s / batch. (data: 9.94e-05)max mem: 17.22454 GB 
[09/19 10:43:27 visual_prompt]: 	Test 200/1152. loss: 2.685, 0.0999 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 10:43:43 visual_prompt]: 	Test 300/1152. loss: 2.729, 0.1024 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 10:44:00 visual_prompt]: 	Test 400/1152. loss: 2.748, 0.0983 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 10:44:16 visual_prompt]: 	Test 500/1152. loss: 2.704, 0.0989 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 10:44:32 visual_prompt]: 	Test 600/1152. loss: 2.824, 0.1206 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 10:44:48 visual_prompt]: 	Test 700/1152. loss: 2.734, 0.1077 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 10:45:05 visual_prompt]: 	Test 800/1152. loss: 2.654, 0.1000 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 10:45:21 visual_prompt]: 	Test 900/1152. loss: 2.732, 0.1038 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 10:45:38 visual_prompt]: 	Test 1000/1152. loss: 2.841, 0.1285 s / batch. (data: 3.28e-02)max mem: 17.22454 GB 
[09/19 10:45:54 visual_prompt]: 	Test 1100/1152. loss: 2.557, 0.1135 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/19 10:46:06 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1087, average loss: 2.7354
[09/19 10:46:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.92	top5: 45.52	
[09/19 10:46:07 visual_prompt]: Best epoch 68: best metric: 0.155
[09/19 10:46:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/19 10:46:17 visual_prompt]: Epoch 69 / 100: avg data time: 2.18e-01, avg batch time: 0.4477, average train loss: 2.6467
[09/19 10:46:23 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.0905, average loss: 2.5672
[09/19 10:46:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.00	top5: 54.50	
[09/19 10:46:43 visual_prompt]: 	Test 100/1152. loss: 2.855, 0.1046 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 10:46:59 visual_prompt]: 	Test 200/1152. loss: 2.715, 0.1145 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 10:47:15 visual_prompt]: 	Test 300/1152. loss: 2.757, 0.1038 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 10:47:32 visual_prompt]: 	Test 400/1152. loss: 2.737, 0.0970 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 10:47:48 visual_prompt]: 	Test 500/1152. loss: 2.754, 0.1271 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:48:04 visual_prompt]: 	Test 600/1152. loss: 2.840, 0.0998 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 10:48:20 visual_prompt]: 	Test 700/1152. loss: 2.593, 0.1130 s / batch. (data: 6.60e-05)max mem: 17.22454 GB 
[09/19 10:48:36 visual_prompt]: 	Test 800/1152. loss: 2.708, 0.1038 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 10:48:52 visual_prompt]: 	Test 900/1152. loss: 2.713, 0.1030 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/19 10:49:08 visual_prompt]: 	Test 1000/1152. loss: 2.901, 0.1093 s / batch. (data: 7.27e-03)max mem: 17.22454 GB 
[09/19 10:49:24 visual_prompt]: 	Test 1100/1152. loss: 2.623, 0.1075 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 10:49:37 visual_prompt]: Inference (test):avg data time: 1.56e-03, avg batch time: 0.1080, average loss: 2.7419
[09/19 10:49:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.68	top5: 48.74	
[09/19 10:49:37 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/19 10:49:47 visual_prompt]: Epoch 70 / 100: avg data time: 2.12e-01, avg batch time: 0.4335, average train loss: 2.6133
[09/19 10:49:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0905, average loss: 2.6197
[09/19 10:49:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.50	top5: 53.00	
[09/19 10:50:13 visual_prompt]: 	Test 100/1152. loss: 2.835, 0.1015 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 10:50:29 visual_prompt]: 	Test 200/1152. loss: 2.660, 0.1317 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 10:50:46 visual_prompt]: 	Test 300/1152. loss: 2.671, 0.1281 s / batch. (data: 4.15e-05)max mem: 17.22454 GB 
[09/19 10:51:02 visual_prompt]: 	Test 400/1152. loss: 2.694, 0.0966 s / batch. (data: 3.53e-05)max mem: 17.22454 GB 
[09/19 10:51:18 visual_prompt]: 	Test 500/1152. loss: 2.745, 0.1159 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 10:51:34 visual_prompt]: 	Test 600/1152. loss: 2.746, 0.1079 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 10:51:50 visual_prompt]: 	Test 700/1152. loss: 2.421, 0.1048 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 10:52:06 visual_prompt]: 	Test 800/1152. loss: 2.746, 0.1234 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/19 10:52:22 visual_prompt]: 	Test 900/1152. loss: 2.750, 0.0950 s / batch. (data: 5.77e-05)max mem: 17.22454 GB 
[09/19 10:52:38 visual_prompt]: 	Test 1000/1152. loss: 2.787, 0.0997 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 10:52:54 visual_prompt]: 	Test 1100/1152. loss: 2.586, 0.0952 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 10:53:07 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1087, average loss: 2.7093
[09/19 10:53:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.10	top5: 49.08	
[09/19 10:53:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/19 10:53:17 visual_prompt]: Epoch 71 / 100: avg data time: 2.14e-01, avg batch time: 0.4394, average train loss: 2.5891
[09/19 10:53:24 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.0873, average loss: 2.4745
[09/19 10:53:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.00	top5: 58.00	
[09/19 10:53:43 visual_prompt]: 	Test 100/1152. loss: 2.842, 0.1074 s / batch. (data: 7.22e-03)max mem: 17.22454 GB 
[09/19 10:53:59 visual_prompt]: 	Test 200/1152. loss: 2.651, 0.1205 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/19 10:54:16 visual_prompt]: 	Test 300/1152. loss: 2.569, 0.1022 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 10:54:32 visual_prompt]: 	Test 400/1152. loss: 2.822, 0.1453 s / batch. (data: 4.55e-05)max mem: 17.22454 GB 
[09/19 10:54:47 visual_prompt]: 	Test 500/1152. loss: 2.663, 0.0971 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 10:55:04 visual_prompt]: 	Test 600/1152. loss: 2.682, 0.0964 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:55:20 visual_prompt]: 	Test 700/1152. loss: 2.725, 0.0945 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 10:55:36 visual_prompt]: 	Test 800/1152. loss: 2.555, 0.1300 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 10:55:52 visual_prompt]: 	Test 900/1152. loss: 2.628, 0.0987 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 10:56:08 visual_prompt]: 	Test 1000/1152. loss: 2.939, 0.1197 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 10:56:24 visual_prompt]: 	Test 1100/1152. loss: 2.613, 0.0991 s / batch. (data: 6.82e-05)max mem: 17.22454 GB 
[09/19 10:56:36 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1087, average loss: 2.6929
[09/19 10:56:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.06	top5: 48.88	
[09/19 10:56:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/19 10:56:47 visual_prompt]: Epoch 72 / 100: avg data time: 2.18e-01, avg batch time: 0.4506, average train loss: 2.5453
[09/19 10:56:53 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.0940, average loss: 2.5262
[09/19 10:56:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.50	top5: 55.50	
[09/19 10:57:13 visual_prompt]: 	Test 100/1152. loss: 2.913, 0.1037 s / batch. (data: 9.89e-05)max mem: 17.22454 GB 
[09/19 10:57:29 visual_prompt]: 	Test 200/1152. loss: 2.773, 0.1045 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 10:57:45 visual_prompt]: 	Test 300/1152. loss: 2.715, 0.0973 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 10:58:02 visual_prompt]: 	Test 400/1152. loss: 2.788, 0.1094 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 10:58:18 visual_prompt]: 	Test 500/1152. loss: 2.642, 0.1278 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/19 10:58:34 visual_prompt]: 	Test 600/1152. loss: 2.718, 0.0991 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 10:58:50 visual_prompt]: 	Test 700/1152. loss: 2.511, 0.1310 s / batch. (data: 2.25e-02)max mem: 17.22454 GB 
[09/19 10:59:06 visual_prompt]: 	Test 800/1152. loss: 2.616, 0.1492 s / batch. (data: 3.25e-02)max mem: 17.22454 GB 
[09/19 10:59:23 visual_prompt]: 	Test 900/1152. loss: 2.778, 0.1188 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 10:59:39 visual_prompt]: 	Test 1000/1152. loss: 2.793, 0.1177 s / batch. (data: 2.18e-02)max mem: 17.22454 GB 
[09/19 10:59:55 visual_prompt]: 	Test 1100/1152. loss: 2.607, 0.1078 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 11:00:07 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1087, average loss: 2.6864
[09/19 11:00:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.97	top5: 46.81	
[09/19 11:00:07 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/19 11:00:18 visual_prompt]: Epoch 73 / 100: avg data time: 2.33e-01, avg batch time: 0.4558, average train loss: 2.5198
[09/19 11:00:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.0959, average loss: 2.4196
[09/19 11:00:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.50	top5: 61.00	
[09/19 11:00:44 visual_prompt]: 	Test 100/1152. loss: 2.927, 0.1156 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 11:01:00 visual_prompt]: 	Test 200/1152. loss: 2.766, 0.0999 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 11:01:16 visual_prompt]: 	Test 300/1152. loss: 2.677, 0.1163 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 11:01:33 visual_prompt]: 	Test 400/1152. loss: 2.785, 0.1199 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 11:01:49 visual_prompt]: 	Test 500/1152. loss: 2.788, 0.1119 s / batch. (data: 7.21e-03)max mem: 17.22454 GB 
[09/19 11:02:05 visual_prompt]: 	Test 600/1152. loss: 2.783, 0.0972 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 11:02:21 visual_prompt]: 	Test 700/1152. loss: 2.594, 0.1025 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 11:02:37 visual_prompt]: 	Test 800/1152. loss: 2.728, 0.1069 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 11:02:54 visual_prompt]: 	Test 900/1152. loss: 2.791, 0.0974 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 11:03:10 visual_prompt]: 	Test 1000/1152. loss: 2.801, 0.1005 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 11:03:26 visual_prompt]: 	Test 1100/1152. loss: 2.561, 0.1133 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/19 11:03:38 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1082, average loss: 2.6987
[09/19 11:03:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.92	top5: 51.33	
[09/19 11:03:39 visual_prompt]: Best epoch 73: best metric: 0.165
[09/19 11:03:39 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/19 11:03:49 visual_prompt]: Epoch 74 / 100: avg data time: 2.15e-01, avg batch time: 0.4416, average train loss: 2.5372
[09/19 11:03:55 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.0931, average loss: 2.4671
[09/19 11:03:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.00	top5: 60.00	
[09/19 11:04:15 visual_prompt]: 	Test 100/1152. loss: 2.795, 0.0999 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 11:04:31 visual_prompt]: 	Test 200/1152. loss: 2.756, 0.1083 s / batch. (data: 1.15e-02)max mem: 17.22454 GB 
[09/19 11:04:47 visual_prompt]: 	Test 300/1152. loss: 2.635, 0.1027 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 11:05:04 visual_prompt]: 	Test 400/1152. loss: 2.715, 0.0996 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 11:05:20 visual_prompt]: 	Test 500/1152. loss: 2.695, 0.1040 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/19 11:05:36 visual_prompt]: 	Test 600/1152. loss: 2.733, 0.1264 s / batch. (data: 9.69e-03)max mem: 17.22454 GB 
[09/19 11:05:52 visual_prompt]: 	Test 700/1152. loss: 2.464, 0.1174 s / batch. (data: 3.03e-05)max mem: 17.22454 GB 
[09/19 11:06:09 visual_prompt]: 	Test 800/1152. loss: 2.655, 0.1147 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/19 11:06:25 visual_prompt]: 	Test 900/1152. loss: 2.665, 0.0998 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 11:06:41 visual_prompt]: 	Test 1000/1152. loss: 2.745, 0.1142 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/19 11:06:57 visual_prompt]: 	Test 1100/1152. loss: 2.525, 0.1261 s / batch. (data: 9.36e-03)max mem: 17.22454 GB 
[09/19 11:07:09 visual_prompt]: Inference (test):avg data time: 2.26e-03, avg batch time: 0.1099, average loss: 2.6692
[09/19 11:07:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 12.89	top5: 48.44	
[09/19 11:07:10 visual_prompt]: Best epoch 74: best metric: 0.200
[09/19 11:07:10 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/19 11:07:20 visual_prompt]: Epoch 75 / 100: avg data time: 2.12e-01, avg batch time: 0.4382, average train loss: 2.5026
[09/19 11:07:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.0900, average loss: 2.3862
[09/19 11:07:26 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.50	top5: 67.50	
[09/19 11:07:46 visual_prompt]: 	Test 100/1152. loss: 2.821, 0.1243 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 11:08:02 visual_prompt]: 	Test 200/1152. loss: 2.821, 0.1444 s / batch. (data: 4.10e-05)max mem: 17.22454 GB 
[09/19 11:08:19 visual_prompt]: 	Test 300/1152. loss: 2.676, 0.1176 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 11:08:35 visual_prompt]: 	Test 400/1152. loss: 2.645, 0.1027 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 11:08:51 visual_prompt]: 	Test 500/1152. loss: 2.629, 0.1067 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 11:09:07 visual_prompt]: 	Test 600/1152. loss: 2.725, 0.1010 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 11:09:24 visual_prompt]: 	Test 700/1152. loss: 2.535, 0.1439 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 11:09:40 visual_prompt]: 	Test 800/1152. loss: 2.610, 0.1021 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 11:09:56 visual_prompt]: 	Test 900/1152. loss: 2.619, 0.1555 s / batch. (data: 8.95e-03)max mem: 17.22454 GB 
[09/19 11:10:13 visual_prompt]: 	Test 1000/1152. loss: 2.728, 0.1083 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 11:10:29 visual_prompt]: 	Test 1100/1152. loss: 2.490, 0.1158 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 11:10:41 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1094, average loss: 2.6381
[09/19 11:10:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.35	top5: 54.37	
[09/19 11:10:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/19 11:10:52 visual_prompt]: Epoch 76 / 100: avg data time: 2.21e-01, avg batch time: 0.4440, average train loss: 2.4611
[09/19 11:10:58 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.0868, average loss: 2.3108
[09/19 11:10:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.50	top5: 69.00	
[09/19 11:11:18 visual_prompt]: 	Test 100/1152. loss: 2.809, 0.0957 s / batch. (data: 4.03e-05)max mem: 17.22454 GB 
[09/19 11:11:34 visual_prompt]: 	Test 200/1152. loss: 2.705, 0.1045 s / batch. (data: 9.25e-03)max mem: 17.22454 GB 
[09/19 11:11:51 visual_prompt]: 	Test 300/1152. loss: 2.719, 0.0995 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 11:12:07 visual_prompt]: 	Test 400/1152. loss: 2.681, 0.0972 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:12:24 visual_prompt]: 	Test 500/1152. loss: 2.598, 0.0989 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 11:12:40 visual_prompt]: 	Test 600/1152. loss: 2.842, 0.1077 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 11:12:56 visual_prompt]: 	Test 700/1152. loss: 2.561, 0.1199 s / batch. (data: 2.07e-04)max mem: 17.22454 GB 
[09/19 11:13:12 visual_prompt]: 	Test 800/1152. loss: 2.618, 0.1045 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 11:13:29 visual_prompt]: 	Test 900/1152. loss: 2.745, 0.1078 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/19 11:13:45 visual_prompt]: 	Test 1000/1152. loss: 2.778, 0.1039 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 11:14:01 visual_prompt]: 	Test 1100/1152. loss: 2.377, 0.1203 s / batch. (data: 1.90e-02)max mem: 17.22454 GB 
[09/19 11:14:13 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1082, average loss: 2.6530
[09/19 11:14:14 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.42	top5: 54.13	
[09/19 11:14:14 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/19 11:14:24 visual_prompt]: Epoch 77 / 100: avg data time: 2.13e-01, avg batch time: 0.4404, average train loss: 2.3775
[09/19 11:14:30 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.0865, average loss: 2.2416
[09/19 11:14:30 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.00	top5: 69.00	
[09/19 11:14:50 visual_prompt]: 	Test 100/1152. loss: 2.686, 0.0986 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 11:15:07 visual_prompt]: 	Test 200/1152. loss: 2.601, 0.1156 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:15:23 visual_prompt]: 	Test 300/1152. loss: 2.600, 0.1117 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 11:15:39 visual_prompt]: 	Test 400/1152. loss: 2.641, 0.1114 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 11:15:56 visual_prompt]: 	Test 500/1152. loss: 2.588, 0.0976 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 11:16:12 visual_prompt]: 	Test 600/1152. loss: 2.676, 0.1572 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 11:16:28 visual_prompt]: 	Test 700/1152. loss: 2.636, 0.1040 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 11:16:45 visual_prompt]: 	Test 800/1152. loss: 2.591, 0.1394 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 11:17:01 visual_prompt]: 	Test 900/1152. loss: 2.634, 0.1112 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 11:17:17 visual_prompt]: 	Test 1000/1152. loss: 2.620, 0.1039 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 11:17:34 visual_prompt]: 	Test 1100/1152. loss: 2.278, 0.1278 s / batch. (data: 3.93e-03)max mem: 17.22454 GB 
[09/19 11:17:46 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1087, average loss: 2.6004
[09/19 11:17:46 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.82	top5: 56.48	
[09/19 11:17:46 visual_prompt]: Best epoch 77: best metric: 0.240
[09/19 11:17:46 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/19 11:17:56 visual_prompt]: Epoch 78 / 100: avg data time: 2.15e-01, avg batch time: 0.4400, average train loss: 2.3305
[09/19 11:18:02 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0861, average loss: 2.2159
[09/19 11:18:02 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 27.00	top5: 71.00	
[09/19 11:18:23 visual_prompt]: 	Test 100/1152. loss: 2.706, 0.1094 s / batch. (data: 1.24e-02)max mem: 17.22454 GB 
[09/19 11:18:39 visual_prompt]: 	Test 200/1152. loss: 2.570, 0.1428 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 11:18:55 visual_prompt]: 	Test 300/1152. loss: 2.492, 0.1042 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 11:19:11 visual_prompt]: 	Test 400/1152. loss: 2.640, 0.1068 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 11:19:28 visual_prompt]: 	Test 500/1152. loss: 2.509, 0.1073 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 11:19:44 visual_prompt]: 	Test 600/1152. loss: 2.703, 0.0952 s / batch. (data: 6.20e-05)max mem: 17.22454 GB 
[09/19 11:20:00 visual_prompt]: 	Test 700/1152. loss: 2.495, 0.0955 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 11:20:16 visual_prompt]: 	Test 800/1152. loss: 2.457, 0.1191 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 11:20:33 visual_prompt]: 	Test 900/1152. loss: 2.599, 0.1094 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 11:20:49 visual_prompt]: 	Test 1000/1152. loss: 2.642, 0.1129 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 11:21:05 visual_prompt]: 	Test 1100/1152. loss: 2.401, 0.0944 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 11:21:17 visual_prompt]: Inference (test):avg data time: 2.32e-03, avg batch time: 0.1090, average loss: 2.5497
[09/19 11:21:17 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.89	top5: 57.80	
[09/19 11:21:17 visual_prompt]: Best epoch 78: best metric: 0.270
[09/19 11:21:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/19 11:21:27 visual_prompt]: Epoch 79 / 100: avg data time: 2.17e-01, avg batch time: 0.4462, average train loss: 2.3321
[09/19 11:21:34 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0960, average loss: 2.2763
[09/19 11:21:34 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.00	top5: 69.50	
[09/19 11:21:54 visual_prompt]: 	Test 100/1152. loss: 2.730, 0.1159 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 11:22:11 visual_prompt]: 	Test 200/1152. loss: 2.647, 0.1000 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 11:22:27 visual_prompt]: 	Test 300/1152. loss: 2.487, 0.0965 s / batch. (data: 1.87e-04)max mem: 17.22454 GB 
[09/19 11:22:44 visual_prompt]: 	Test 400/1152. loss: 2.903, 0.1289 s / batch. (data: 2.03e-02)max mem: 17.22454 GB 
[09/19 11:23:00 visual_prompt]: 	Test 500/1152. loss: 2.739, 0.1291 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 11:23:16 visual_prompt]: 	Test 600/1152. loss: 2.806, 0.1158 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 11:23:32 visual_prompt]: 	Test 700/1152. loss: 2.506, 0.1040 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 11:23:48 visual_prompt]: 	Test 800/1152. loss: 2.480, 0.1080 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 11:24:05 visual_prompt]: 	Test 900/1152. loss: 2.659, 0.1023 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 11:24:21 visual_prompt]: 	Test 1000/1152. loss: 2.586, 0.1199 s / batch. (data: 3.30e-03)max mem: 17.22454 GB 
[09/19 11:24:37 visual_prompt]: 	Test 1100/1152. loss: 2.441, 0.0961 s / batch. (data: 9.85e-05)max mem: 17.22454 GB 
[09/19 11:24:49 visual_prompt]: Inference (test):avg data time: 1.77e-03, avg batch time: 0.1086, average loss: 2.6517
[09/19 11:24:49 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.15	top5: 56.04	
[09/19 11:24:49 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/19 11:24:59 visual_prompt]: Epoch 80 / 100: avg data time: 2.15e-01, avg batch time: 0.4403, average train loss: 2.3360
[09/19 11:25:06 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.0873, average loss: 2.2115
[09/19 11:25:06 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.50	top5: 71.00	
[09/19 11:25:26 visual_prompt]: 	Test 100/1152. loss: 2.765, 0.1177 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 11:25:42 visual_prompt]: 	Test 200/1152. loss: 2.619, 0.1027 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 11:25:59 visual_prompt]: 	Test 300/1152. loss: 2.573, 0.0957 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 11:26:15 visual_prompt]: 	Test 400/1152. loss: 2.646, 0.1087 s / batch. (data: 3.48e-05)max mem: 17.22454 GB 
[09/19 11:26:31 visual_prompt]: 	Test 500/1152. loss: 2.656, 0.0966 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 11:26:47 visual_prompt]: 	Test 600/1152. loss: 2.662, 0.0997 s / batch. (data: 8.58e-05)max mem: 17.22454 GB 
[09/19 11:27:04 visual_prompt]: 	Test 700/1152. loss: 2.606, 0.0991 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 11:27:20 visual_prompt]: 	Test 800/1152. loss: 2.396, 0.1112 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 11:27:36 visual_prompt]: 	Test 900/1152. loss: 2.585, 0.1107 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 11:27:52 visual_prompt]: 	Test 1000/1152. loss: 2.643, 0.1180 s / batch. (data: 6.70e-05)max mem: 17.22454 GB 
[09/19 11:28:08 visual_prompt]: 	Test 1100/1152. loss: 2.397, 0.1061 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 11:28:20 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1090, average loss: 2.5717
[09/19 11:28:20 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.92	top5: 55.73	
[09/19 11:28:20 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/19 11:28:30 visual_prompt]: Epoch 81 / 100: avg data time: 2.16e-01, avg batch time: 0.4410, average train loss: 2.3188
[09/19 11:28:37 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.0952, average loss: 2.2683
[09/19 11:28:37 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 26.00	top5: 67.50	
[09/19 11:28:57 visual_prompt]: 	Test 100/1152. loss: 2.665, 0.0979 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 11:29:13 visual_prompt]: 	Test 200/1152. loss: 2.531, 0.1197 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 11:29:30 visual_prompt]: 	Test 300/1152. loss: 2.521, 0.0993 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 11:29:46 visual_prompt]: 	Test 400/1152. loss: 2.574, 0.1360 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 11:30:02 visual_prompt]: 	Test 500/1152. loss: 2.578, 0.1062 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 11:30:18 visual_prompt]: 	Test 600/1152. loss: 2.592, 0.0997 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 11:30:34 visual_prompt]: 	Test 700/1152. loss: 2.432, 0.1039 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 11:30:50 visual_prompt]: 	Test 800/1152. loss: 2.417, 0.1126 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 11:31:06 visual_prompt]: 	Test 900/1152. loss: 2.519, 0.0991 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 11:31:22 visual_prompt]: 	Test 1000/1152. loss: 2.567, 0.0976 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:31:38 visual_prompt]: 	Test 1100/1152. loss: 2.262, 0.1118 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 11:31:50 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1093, average loss: 2.5409
[09/19 11:31:51 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.97	top5: 57.20	
[09/19 11:31:51 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/19 11:32:01 visual_prompt]: Epoch 82 / 100: avg data time: 2.21e-01, avg batch time: 0.4445, average train loss: 2.2501
[09/19 11:32:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.0910, average loss: 2.1437
[09/19 11:32:07 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.50	top5: 73.00	
[09/19 11:32:27 visual_prompt]: 	Test 100/1152. loss: 2.587, 0.0962 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 11:32:43 visual_prompt]: 	Test 200/1152. loss: 2.465, 0.1228 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 11:33:00 visual_prompt]: 	Test 300/1152. loss: 2.447, 0.0961 s / batch. (data: 3.89e-05)max mem: 17.22454 GB 
[09/19 11:33:16 visual_prompt]: 	Test 400/1152. loss: 2.799, 0.0948 s / batch. (data: 6.96e-05)max mem: 17.22454 GB 
[09/19 11:33:32 visual_prompt]: 	Test 500/1152. loss: 2.613, 0.0953 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 11:33:48 visual_prompt]: 	Test 600/1152. loss: 2.690, 0.1045 s / batch. (data: 6.53e-05)max mem: 17.22454 GB 
[09/19 11:34:04 visual_prompt]: 	Test 700/1152. loss: 2.524, 0.1111 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 11:34:21 visual_prompt]: 	Test 800/1152. loss: 2.438, 0.0952 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 11:34:37 visual_prompt]: 	Test 900/1152. loss: 2.741, 0.1064 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 11:34:53 visual_prompt]: 	Test 1000/1152. loss: 2.475, 0.1100 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 11:35:09 visual_prompt]: 	Test 1100/1152. loss: 2.229, 0.0945 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 11:35:21 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1082, average loss: 2.5636
[09/19 11:35:22 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 17.13	top5: 58.15	
[09/19 11:35:22 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/19 11:35:32 visual_prompt]: Epoch 83 / 100: avg data time: 2.25e-01, avg batch time: 0.4520, average train loss: 2.1529
[09/19 11:35:39 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.0925, average loss: 2.0575
[09/19 11:35:39 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 23.50	top5: 80.50	
[09/19 11:35:58 visual_prompt]: 	Test 100/1152. loss: 2.714, 0.1451 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 11:36:14 visual_prompt]: 	Test 200/1152. loss: 2.570, 0.0980 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 11:36:31 visual_prompt]: 	Test 300/1152. loss: 2.628, 0.1463 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 11:36:47 visual_prompt]: 	Test 400/1152. loss: 2.835, 0.1272 s / batch. (data: 2.24e-02)max mem: 17.22454 GB 
[09/19 11:37:03 visual_prompt]: 	Test 500/1152. loss: 2.643, 0.1119 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 11:37:19 visual_prompt]: 	Test 600/1152. loss: 2.818, 0.1257 s / batch. (data: 9.82e-03)max mem: 17.22454 GB 
[09/19 11:37:36 visual_prompt]: 	Test 700/1152. loss: 2.623, 0.1022 s / batch. (data: 4.65e-05)max mem: 17.22454 GB 
[09/19 11:37:52 visual_prompt]: 	Test 800/1152. loss: 2.629, 0.0999 s / batch. (data: 8.65e-05)max mem: 17.22454 GB 
[09/19 11:38:08 visual_prompt]: 	Test 900/1152. loss: 2.875, 0.0989 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 11:38:24 visual_prompt]: 	Test 1000/1152. loss: 2.573, 0.1106 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 11:38:40 visual_prompt]: 	Test 1100/1152. loss: 2.325, 0.1039 s / batch. (data: 8.47e-03)max mem: 17.22454 GB 
[09/19 11:38:52 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1086, average loss: 2.5801
[09/19 11:38:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 17.83	top5: 61.21	
[09/19 11:38:53 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/19 11:39:03 visual_prompt]: Epoch 84 / 100: avg data time: 2.11e-01, avg batch time: 0.4366, average train loss: 2.1091
[09/19 11:39:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0942, average loss: 1.9971
[09/19 11:39:09 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.50	top5: 78.00	
[09/19 11:39:29 visual_prompt]: 	Test 100/1152. loss: 2.705, 0.1394 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 11:39:45 visual_prompt]: 	Test 200/1152. loss: 2.555, 0.0987 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 11:40:01 visual_prompt]: 	Test 300/1152. loss: 2.408, 0.1198 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 11:40:18 visual_prompt]: 	Test 400/1152. loss: 2.804, 0.0962 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 11:40:34 visual_prompt]: 	Test 500/1152. loss: 2.439, 0.1197 s / batch. (data: 7.17e-03)max mem: 17.22454 GB 
[09/19 11:40:50 visual_prompt]: 	Test 600/1152. loss: 2.639, 0.1199 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 11:41:06 visual_prompt]: 	Test 700/1152. loss: 2.422, 0.0948 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 11:41:22 visual_prompt]: 	Test 800/1152. loss: 2.468, 0.1217 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 11:41:39 visual_prompt]: 	Test 900/1152. loss: 2.502, 0.1078 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 11:41:55 visual_prompt]: 	Test 1000/1152. loss: 2.423, 0.0995 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 11:42:11 visual_prompt]: 	Test 1100/1152. loss: 2.319, 0.0985 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/19 11:42:23 visual_prompt]: Inference (test):avg data time: 2.19e-03, avg batch time: 0.1093, average loss: 2.5355
[09/19 11:42:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.14	top5: 62.83	
[09/19 11:42:23 visual_prompt]: Best epoch 84: best metric: 0.315
[09/19 11:42:23 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/19 11:42:34 visual_prompt]: Epoch 85 / 100: avg data time: 2.17e-01, avg batch time: 0.4393, average train loss: 2.0767
[09/19 11:42:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0928, average loss: 1.9286
[09/19 11:42:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 32.50	top5: 81.00	
[09/19 11:43:00 visual_prompt]: 	Test 100/1152. loss: 2.759, 0.1122 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 11:43:16 visual_prompt]: 	Test 200/1152. loss: 2.480, 0.0988 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 11:43:32 visual_prompt]: 	Test 300/1152. loss: 2.687, 0.1077 s / batch. (data: 7.12e-03)max mem: 17.22454 GB 
[09/19 11:43:48 visual_prompt]: 	Test 400/1152. loss: 2.852, 0.1026 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 11:44:04 visual_prompt]: 	Test 500/1152. loss: 2.612, 0.1310 s / batch. (data: 6.87e-05)max mem: 17.22454 GB 
[09/19 11:44:20 visual_prompt]: 	Test 600/1152. loss: 2.628, 0.1047 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 11:44:36 visual_prompt]: 	Test 700/1152. loss: 2.415, 0.1091 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 11:44:52 visual_prompt]: 	Test 800/1152. loss: 2.661, 0.0988 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 11:45:09 visual_prompt]: 	Test 900/1152. loss: 2.518, 0.1054 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 11:45:25 visual_prompt]: 	Test 1000/1152. loss: 2.371, 0.1083 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 11:45:41 visual_prompt]: 	Test 1100/1152. loss: 2.312, 0.0988 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 11:45:53 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1087, average loss: 2.5199
[09/19 11:45:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.16	top5: 62.87	
[09/19 11:45:53 visual_prompt]: Best epoch 85: best metric: 0.325
[09/19 11:45:53 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/19 11:46:03 visual_prompt]: Epoch 86 / 100: avg data time: 2.24e-01, avg batch time: 0.4509, average train loss: 2.0174
[09/19 11:46:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.0968, average loss: 1.8662
[09/19 11:46:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 37.00	top5: 83.50	
[09/19 11:46:30 visual_prompt]: 	Test 100/1152. loss: 2.885, 0.1145 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 11:46:46 visual_prompt]: 	Test 200/1152. loss: 2.516, 0.2179 s / batch. (data: 3.30e-02)max mem: 17.22454 GB 
[09/19 11:47:02 visual_prompt]: 	Test 300/1152. loss: 2.645, 0.0962 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 11:47:19 visual_prompt]: 	Test 400/1152. loss: 2.966, 0.1190 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 11:47:35 visual_prompt]: 	Test 500/1152. loss: 2.595, 0.1133 s / batch. (data: 8.76e-03)max mem: 17.22454 GB 
[09/19 11:47:51 visual_prompt]: 	Test 600/1152. loss: 2.814, 0.1037 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 11:48:07 visual_prompt]: 	Test 700/1152. loss: 2.317, 0.1038 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/19 11:48:23 visual_prompt]: 	Test 800/1152. loss: 2.555, 0.0997 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 11:48:39 visual_prompt]: 	Test 900/1152. loss: 2.850, 0.1039 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 11:48:55 visual_prompt]: 	Test 1000/1152. loss: 2.582, 0.1170 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/19 11:49:11 visual_prompt]: 	Test 1100/1152. loss: 2.214, 0.0952 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 11:49:24 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1088, average loss: 2.5712
[09/19 11:49:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.92	top5: 64.62	
[09/19 11:49:24 visual_prompt]: Best epoch 86: best metric: 0.370
[09/19 11:49:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/19 11:49:34 visual_prompt]: Epoch 87 / 100: avg data time: 2.16e-01, avg batch time: 0.4444, average train loss: 2.0177
[09/19 11:49:41 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.0956, average loss: 1.9576
[09/19 11:49:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 32.00	top5: 79.00	
[09/19 11:50:00 visual_prompt]: 	Test 100/1152. loss: 2.682, 0.1117 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 11:50:16 visual_prompt]: 	Test 200/1152. loss: 2.506, 0.1143 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 11:50:33 visual_prompt]: 	Test 300/1152. loss: 2.529, 0.1125 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 11:50:49 visual_prompt]: 	Test 400/1152. loss: 2.874, 0.1145 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 11:51:05 visual_prompt]: 	Test 500/1152. loss: 2.571, 0.0944 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 11:51:21 visual_prompt]: 	Test 600/1152. loss: 2.710, 0.0975 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/19 11:51:37 visual_prompt]: 	Test 700/1152. loss: 2.409, 0.1042 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 11:51:53 visual_prompt]: 	Test 800/1152. loss: 2.512, 0.1074 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 11:52:09 visual_prompt]: 	Test 900/1152. loss: 2.535, 0.0983 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 11:52:25 visual_prompt]: 	Test 1000/1152. loss: 2.581, 0.1336 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 11:52:41 visual_prompt]: 	Test 1100/1152. loss: 2.251, 0.1118 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/19 11:52:53 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1097, average loss: 2.5513
[09/19 11:52:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.67	top5: 63.84	
[09/19 11:52:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/19 11:53:04 visual_prompt]: Epoch 88 / 100: avg data time: 2.15e-01, avg batch time: 0.4449, average train loss: 1.9194
[09/19 11:53:10 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.0912, average loss: 1.7754
[09/19 11:53:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 35.50	top5: 88.50	
[09/19 11:53:30 visual_prompt]: 	Test 100/1152. loss: 2.765, 0.1106 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 11:53:46 visual_prompt]: 	Test 200/1152. loss: 2.492, 0.0992 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/19 11:54:02 visual_prompt]: 	Test 300/1152. loss: 2.656, 0.1130 s / batch. (data: 5.25e-05)max mem: 17.22454 GB 
[09/19 11:54:18 visual_prompt]: 	Test 400/1152. loss: 2.796, 0.0975 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 11:54:34 visual_prompt]: 	Test 500/1152. loss: 2.611, 0.0989 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 11:54:50 visual_prompt]: 	Test 600/1152. loss: 2.745, 0.0987 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:55:06 visual_prompt]: 	Test 700/1152. loss: 2.432, 0.1406 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 11:55:22 visual_prompt]: 	Test 800/1152. loss: 2.548, 0.1025 s / batch. (data: 5.20e-05)max mem: 17.22454 GB 
[09/19 11:55:39 visual_prompt]: 	Test 900/1152. loss: 2.617, 0.1122 s / batch. (data: 4.01e-05)max mem: 17.22454 GB 
[09/19 11:55:55 visual_prompt]: 	Test 1000/1152. loss: 2.212, 0.1120 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 11:56:11 visual_prompt]: 	Test 1100/1152. loss: 2.301, 0.1040 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 11:56:23 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1083, average loss: 2.5507
[09/19 11:56:23 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 18.81	top5: 66.60	
[09/19 11:56:23 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/19 11:56:33 visual_prompt]: Epoch 89 / 100: avg data time: 2.09e-01, avg batch time: 0.4359, average train loss: 1.8386
[09/19 11:56:40 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.0901, average loss: 1.6476
[09/19 11:56:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.50	top5: 88.00	
[09/19 11:56:59 visual_prompt]: 	Test 100/1152. loss: 2.807, 0.1701 s / batch. (data: 7.95e-03)max mem: 17.22454 GB 
[09/19 11:57:15 visual_prompt]: 	Test 200/1152. loss: 2.588, 0.0994 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 11:57:31 visual_prompt]: 	Test 300/1152. loss: 2.492, 0.1077 s / batch. (data: 7.27e-03)max mem: 17.22454 GB 
[09/19 11:57:48 visual_prompt]: 	Test 400/1152. loss: 2.985, 0.1120 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 11:58:04 visual_prompt]: 	Test 500/1152. loss: 2.554, 0.1273 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/19 11:58:20 visual_prompt]: 	Test 600/1152. loss: 2.708, 0.0954 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/19 11:58:36 visual_prompt]: 	Test 700/1152. loss: 2.413, 0.0945 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 11:58:52 visual_prompt]: 	Test 800/1152. loss: 2.562, 0.1238 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 11:59:08 visual_prompt]: 	Test 900/1152. loss: 2.629, 0.1039 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/19 11:59:25 visual_prompt]: 	Test 1000/1152. loss: 2.514, 0.0935 s / batch. (data: 5.15e-05)max mem: 17.22454 GB 
[09/19 11:59:41 visual_prompt]: 	Test 1100/1152. loss: 2.253, 0.1089 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 11:59:53 visual_prompt]: Inference (test):avg data time: 2.05e-03, avg batch time: 0.1089, average loss: 2.5417
[09/19 11:59:53 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.56	top5: 67.85	
[09/19 11:59:53 visual_prompt]: Best epoch 89: best metric: 0.405
[09/19 11:59:53 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/19 12:00:04 visual_prompt]: Epoch 90 / 100: avg data time: 2.20e-01, avg batch time: 0.4476, average train loss: 1.7371
[09/19 12:00:10 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.0884, average loss: 1.5618
[09/19 12:00:10 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 41.50	top5: 92.50	
[09/19 12:00:30 visual_prompt]: 	Test 100/1152. loss: 2.957, 0.0974 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 12:00:46 visual_prompt]: 	Test 200/1152. loss: 2.624, 0.1199 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 12:01:02 visual_prompt]: 	Test 300/1152. loss: 2.698, 0.1009 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 12:01:19 visual_prompt]: 	Test 400/1152. loss: 3.008, 0.1186 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 12:01:35 visual_prompt]: 	Test 500/1152. loss: 2.641, 0.1159 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 12:01:51 visual_prompt]: 	Test 600/1152. loss: 2.944, 0.1247 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 12:02:07 visual_prompt]: 	Test 700/1152. loss: 2.489, 0.1202 s / batch. (data: 9.04e-05)max mem: 17.22454 GB 
[09/19 12:02:23 visual_prompt]: 	Test 800/1152. loss: 2.660, 0.1066 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 12:02:39 visual_prompt]: 	Test 900/1152. loss: 2.723, 0.1025 s / batch. (data: 3.12e-05)max mem: 17.22454 GB 
[09/19 12:02:55 visual_prompt]: 	Test 1000/1152. loss: 2.606, 0.1057 s / batch. (data: 4.94e-03)max mem: 17.22454 GB 
[09/19 12:03:11 visual_prompt]: 	Test 1100/1152. loss: 2.167, 0.1662 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/19 12:03:23 visual_prompt]: Inference (test):avg data time: 2.13e-03, avg batch time: 0.1088, average loss: 2.6411
[09/19 12:03:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.77	top5: 67.67	
[09/19 12:03:24 visual_prompt]: Best epoch 90: best metric: 0.415
[09/19 12:03:24 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/19 12:03:33 visual_prompt]: Epoch 91 / 100: avg data time: 2.15e-01, avg batch time: 0.4387, average train loss: 1.6954
[09/19 12:03:40 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.0969, average loss: 1.5879
[09/19 12:03:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.50	top5: 91.00	
[09/19 12:04:00 visual_prompt]: 	Test 100/1152. loss: 2.768, 0.1258 s / batch. (data: 1.32e-02)max mem: 17.22454 GB 
[09/19 12:04:16 visual_prompt]: 	Test 200/1152. loss: 2.612, 0.1126 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 12:04:32 visual_prompt]: 	Test 300/1152. loss: 2.551, 0.1067 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 12:04:48 visual_prompt]: 	Test 400/1152. loss: 2.923, 0.0970 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 12:05:05 visual_prompt]: 	Test 500/1152. loss: 2.732, 0.1034 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 12:05:21 visual_prompt]: 	Test 600/1152. loss: 2.694, 0.0952 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 12:05:37 visual_prompt]: 	Test 700/1152. loss: 2.468, 0.1414 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/19 12:05:53 visual_prompt]: 	Test 800/1152. loss: 2.514, 0.0964 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 12:06:10 visual_prompt]: 	Test 900/1152. loss: 2.548, 0.1090 s / batch. (data: 6.91e-05)max mem: 17.22454 GB 
[09/19 12:06:26 visual_prompt]: 	Test 1000/1152. loss: 2.471, 0.0940 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 12:06:42 visual_prompt]: 	Test 1100/1152. loss: 2.257, 0.0945 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 12:06:54 visual_prompt]: Inference (test):avg data time: 1.87e-03, avg batch time: 0.1087, average loss: 2.6082
[09/19 12:06:54 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.52	top5: 66.70	
[09/19 12:06:54 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/19 12:07:04 visual_prompt]: Epoch 92 / 100: avg data time: 2.13e-01, avg batch time: 0.4372, average train loss: 1.6646
[09/19 12:07:11 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.0981, average loss: 1.6958
[09/19 12:07:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 41.50	top5: 88.50	
[09/19 12:07:30 visual_prompt]: 	Test 100/1152. loss: 2.661, 0.1277 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 12:07:47 visual_prompt]: 	Test 200/1152. loss: 2.560, 0.0972 s / batch. (data: 3.74e-05)max mem: 17.22454 GB 
[09/19 12:08:03 visual_prompt]: 	Test 300/1152. loss: 2.375, 0.1040 s / batch. (data: 7.39e-03)max mem: 17.22454 GB 
[09/19 12:08:19 visual_prompt]: 	Test 400/1152. loss: 2.677, 0.1096 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 12:08:36 visual_prompt]: 	Test 500/1152. loss: 2.583, 0.0976 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 12:08:52 visual_prompt]: 	Test 600/1152. loss: 2.467, 0.0957 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 12:09:08 visual_prompt]: 	Test 700/1152. loss: 2.284, 0.0998 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 12:09:24 visual_prompt]: 	Test 800/1152. loss: 2.365, 0.1069 s / batch. (data: 8.92e-05)max mem: 17.22454 GB 
[09/19 12:09:41 visual_prompt]: 	Test 900/1152. loss: 2.309, 0.1259 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 12:09:57 visual_prompt]: 	Test 1000/1152. loss: 2.343, 0.0964 s / batch. (data: 3.53e-05)max mem: 17.22454 GB 
[09/19 12:10:13 visual_prompt]: 	Test 1100/1152. loss: 2.289, 0.1119 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 12:10:25 visual_prompt]: Inference (test):avg data time: 2.12e-03, avg batch time: 0.1096, average loss: 2.4697
[09/19 12:10:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.82	top5: 66.15	
[09/19 12:10:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/19 12:10:36 visual_prompt]: Epoch 93 / 100: avg data time: 2.38e-01, avg batch time: 0.4605, average train loss: 1.6135
[09/19 12:10:43 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.0916, average loss: 1.5310
[09/19 12:10:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 45.00	top5: 91.50	
[09/19 12:11:02 visual_prompt]: 	Test 100/1152. loss: 2.917, 0.1039 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 12:11:18 visual_prompt]: 	Test 200/1152. loss: 2.810, 0.1319 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 12:11:35 visual_prompt]: 	Test 300/1152. loss: 2.800, 0.1119 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 12:11:51 visual_prompt]: 	Test 400/1152. loss: 3.172, 0.0991 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 12:12:07 visual_prompt]: 	Test 500/1152. loss: 2.809, 0.1000 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 12:12:23 visual_prompt]: 	Test 600/1152. loss: 2.770, 0.1148 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 12:12:39 visual_prompt]: 	Test 700/1152. loss: 2.619, 0.0947 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 12:12:55 visual_prompt]: 	Test 800/1152. loss: 2.683, 0.0942 s / batch. (data: 7.25e-05)max mem: 17.22454 GB 
[09/19 12:13:11 visual_prompt]: 	Test 900/1152. loss: 2.801, 0.0965 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 12:13:28 visual_prompt]: 	Test 1000/1152. loss: 2.849, 0.1057 s / batch. (data: 5.16e-03)max mem: 17.22454 GB 
[09/19 12:13:44 visual_prompt]: 	Test 1100/1152. loss: 2.422, 0.0986 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 12:13:57 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1084, average loss: 2.7250
[09/19 12:13:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.86	top5: 68.45	
[09/19 12:13:57 visual_prompt]: Best epoch 93: best metric: 0.450
[09/19 12:13:57 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/19 12:14:07 visual_prompt]: Epoch 94 / 100: avg data time: 2.19e-01, avg batch time: 0.4437, average train loss: 1.5229
[09/19 12:14:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.0918, average loss: 1.3700
[09/19 12:14:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 52.00	top5: 93.00	
[09/19 12:14:33 visual_prompt]: 	Test 100/1152. loss: 2.986, 0.0970 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 12:14:49 visual_prompt]: 	Test 200/1152. loss: 2.739, 0.1050 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 12:15:06 visual_prompt]: 	Test 300/1152. loss: 2.732, 0.1198 s / batch. (data: 2.33e-02)max mem: 17.22454 GB 
[09/19 12:15:21 visual_prompt]: 	Test 400/1152. loss: 3.185, 0.1297 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 12:15:38 visual_prompt]: 	Test 500/1152. loss: 2.812, 0.1105 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 12:15:54 visual_prompt]: 	Test 600/1152. loss: 2.865, 0.0961 s / batch. (data: 9.78e-05)max mem: 17.22454 GB 
[09/19 12:16:10 visual_prompt]: 	Test 700/1152. loss: 2.516, 0.0982 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 12:16:26 visual_prompt]: 	Test 800/1152. loss: 2.620, 0.1039 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 12:16:42 visual_prompt]: 	Test 900/1152. loss: 2.693, 0.1062 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 12:16:58 visual_prompt]: 	Test 1000/1152. loss: 2.627, 0.1316 s / batch. (data: 2.71e-02)max mem: 17.22454 GB 
[09/19 12:17:14 visual_prompt]: 	Test 1100/1152. loss: 2.261, 0.1089 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 12:17:27 visual_prompt]: Inference (test):avg data time: 2.21e-03, avg batch time: 0.1092, average loss: 2.7237
[09/19 12:17:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.41	top5: 69.57	
[09/19 12:17:27 visual_prompt]: Best epoch 94: best metric: 0.520
[09/19 12:17:27 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/19 12:17:37 visual_prompt]: Epoch 95 / 100: avg data time: 2.27e-01, avg batch time: 0.4518, average train loss: 1.4404
[09/19 12:17:44 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.0891, average loss: 1.3003
[09/19 12:17:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 54.50	top5: 93.00	
[09/19 12:18:03 visual_prompt]: 	Test 100/1152. loss: 3.097, 0.1386 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 12:18:20 visual_prompt]: 	Test 200/1152. loss: 2.817, 0.1105 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 12:18:36 visual_prompt]: 	Test 300/1152. loss: 2.824, 0.0946 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 12:18:52 visual_prompt]: 	Test 400/1152. loss: 3.260, 0.1063 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 12:19:08 visual_prompt]: 	Test 500/1152. loss: 2.849, 0.0982 s / batch. (data: 9.44e-05)max mem: 17.22454 GB 
[09/19 12:19:24 visual_prompt]: 	Test 600/1152. loss: 2.898, 0.1009 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/19 12:19:41 visual_prompt]: 	Test 700/1152. loss: 2.432, 0.0949 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 12:19:57 visual_prompt]: 	Test 800/1152. loss: 2.618, 0.0996 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/19 12:20:13 visual_prompt]: 	Test 900/1152. loss: 2.683, 0.1054 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 12:20:29 visual_prompt]: 	Test 1000/1152. loss: 2.648, 0.0965 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 12:20:45 visual_prompt]: 	Test 1100/1152. loss: 2.360, 0.1223 s / batch. (data: 2.18e-02)max mem: 17.22454 GB 
[09/19 12:20:57 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1086, average loss: 2.7401
[09/19 12:20:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.68	top5: 70.08	
[09/19 12:20:58 visual_prompt]: Best epoch 95: best metric: 0.545
[09/19 12:20:58 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/19 12:21:07 visual_prompt]: Epoch 96 / 100: avg data time: 2.15e-01, avg batch time: 0.4438, average train loss: 1.3993
[09/19 12:21:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.0918, average loss: 1.2720
[09/19 12:21:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 56.00	top5: 94.50	
[09/19 12:21:34 visual_prompt]: 	Test 100/1152. loss: 3.068, 0.1202 s / batch. (data: 1.56e-02)max mem: 17.22454 GB 
[09/19 12:21:50 visual_prompt]: 	Test 200/1152. loss: 2.790, 0.1080 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 12:22:06 visual_prompt]: 	Test 300/1152. loss: 2.750, 0.1049 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 12:22:22 visual_prompt]: 	Test 400/1152. loss: 3.098, 0.1067 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 12:22:39 visual_prompt]: 	Test 500/1152. loss: 2.957, 0.0952 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/19 12:22:55 visual_prompt]: 	Test 600/1152. loss: 2.824, 0.1150 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 12:23:11 visual_prompt]: 	Test 700/1152. loss: 2.497, 0.1002 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 12:23:27 visual_prompt]: 	Test 800/1152. loss: 2.608, 0.0994 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 12:23:42 visual_prompt]: 	Test 900/1152. loss: 2.456, 0.0989 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 12:23:59 visual_prompt]: 	Test 1000/1152. loss: 2.616, 0.1074 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 12:24:15 visual_prompt]: 	Test 1100/1152. loss: 2.472, 0.1018 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 12:24:27 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1083, average loss: 2.7328
[09/19 12:24:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.72	top5: 69.76	
[09/19 12:24:27 visual_prompt]: Best epoch 96: best metric: 0.560
[09/19 12:24:27 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/19 12:24:37 visual_prompt]: Epoch 97 / 100: avg data time: 2.11e-01, avg batch time: 0.4347, average train loss: 1.3681
[09/19 12:24:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0921, average loss: 1.2275
[09/19 12:24:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 54.50	top5: 95.50	
[09/19 12:25:03 visual_prompt]: 	Test 100/1152. loss: 3.104, 0.1207 s / batch. (data: 2.38e-02)max mem: 17.22454 GB 
[09/19 12:25:20 visual_prompt]: 	Test 200/1152. loss: 2.817, 0.1067 s / batch. (data: 6.07e-03)max mem: 17.22454 GB 
[09/19 12:25:36 visual_prompt]: 	Test 300/1152. loss: 2.850, 0.0965 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 12:25:52 visual_prompt]: 	Test 400/1152. loss: 3.237, 0.0946 s / batch. (data: 6.68e-05)max mem: 17.22454 GB 
[09/19 12:26:09 visual_prompt]: 	Test 500/1152. loss: 3.005, 0.1036 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 12:26:25 visual_prompt]: 	Test 600/1152. loss: 2.904, 0.0950 s / batch. (data: 6.46e-05)max mem: 17.22454 GB 
[09/19 12:26:41 visual_prompt]: 	Test 700/1152. loss: 2.523, 0.1109 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 12:26:57 visual_prompt]: 	Test 800/1152. loss: 2.549, 0.1076 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 12:27:13 visual_prompt]: 	Test 900/1152. loss: 2.589, 0.1171 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/19 12:27:29 visual_prompt]: 	Test 1000/1152. loss: 2.731, 0.1177 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 12:27:45 visual_prompt]: 	Test 1100/1152. loss: 2.380, 0.0999 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 12:27:57 visual_prompt]: Inference (test):avg data time: 1.67e-03, avg batch time: 0.1091, average loss: 2.7914
[09/19 12:27:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.87	top5: 70.69	
[09/19 12:27:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/19 12:28:07 visual_prompt]: Epoch 98 / 100: avg data time: 2.15e-01, avg batch time: 0.4420, average train loss: 1.3140
[09/19 12:28:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.0931, average loss: 1.1718
[09/19 12:28:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 59.50	top5: 96.50	
[09/19 12:28:34 visual_prompt]: 	Test 100/1152. loss: 3.135, 0.1046 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 12:28:50 visual_prompt]: 	Test 200/1152. loss: 2.820, 0.1634 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 12:29:06 visual_prompt]: 	Test 300/1152. loss: 2.972, 0.1424 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 12:29:22 visual_prompt]: 	Test 400/1152. loss: 3.252, 0.1079 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 12:29:38 visual_prompt]: 	Test 500/1152. loss: 3.030, 0.0972 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 12:29:54 visual_prompt]: 	Test 600/1152. loss: 2.917, 0.1030 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 12:30:11 visual_prompt]: 	Test 700/1152. loss: 2.592, 0.1120 s / batch. (data: 1.54e-02)max mem: 17.22454 GB 
[09/19 12:30:27 visual_prompt]: 	Test 800/1152. loss: 2.649, 0.1159 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/19 12:30:43 visual_prompt]: 	Test 900/1152. loss: 2.635, 0.1223 s / batch. (data: 1.76e-04)max mem: 17.22454 GB 
[09/19 12:30:59 visual_prompt]: 	Test 1000/1152. loss: 2.780, 0.1360 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 12:31:15 visual_prompt]: 	Test 1100/1152. loss: 2.453, 0.0942 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 12:31:27 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1092, average loss: 2.7933
[09/19 12:31:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.02	top5: 70.36	
[09/19 12:31:27 visual_prompt]: Best epoch 98: best metric: 0.595
[09/19 12:31:27 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/19 12:31:37 visual_prompt]: Epoch 99 / 100: avg data time: 2.20e-01, avg batch time: 0.4432, average train loss: 1.2664
[09/19 12:31:44 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.0874, average loss: 1.1484
[09/19 12:31:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 61.00	top5: 96.00	
[09/19 12:32:03 visual_prompt]: 	Test 100/1152. loss: 3.196, 0.0983 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 12:32:20 visual_prompt]: 	Test 200/1152. loss: 2.893, 0.1039 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 12:32:36 visual_prompt]: 	Test 300/1152. loss: 2.928, 0.1420 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 12:32:52 visual_prompt]: 	Test 400/1152. loss: 3.310, 0.1272 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 12:33:08 visual_prompt]: 	Test 500/1152. loss: 3.096, 0.1109 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 12:33:24 visual_prompt]: 	Test 600/1152. loss: 2.973, 0.1037 s / batch. (data: 7.10e-03)max mem: 17.22454 GB 
[09/19 12:33:40 visual_prompt]: 	Test 700/1152. loss: 2.609, 0.1125 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 12:33:57 visual_prompt]: 	Test 800/1152. loss: 2.742, 0.1210 s / batch. (data: 8.45e-03)max mem: 17.22454 GB 
[09/19 12:34:13 visual_prompt]: 	Test 900/1152. loss: 2.644, 0.0993 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 12:34:29 visual_prompt]: 	Test 1000/1152. loss: 2.812, 0.1042 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 12:34:45 visual_prompt]: 	Test 1100/1152. loss: 2.431, 0.1144 s / batch. (data: 9.84e-03)max mem: 17.22454 GB 
[09/19 12:34:57 visual_prompt]: Inference (test):avg data time: 2.13e-03, avg batch time: 0.1089, average loss: 2.8230
[09/19 12:34:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.10	top5: 70.72	
[09/19 12:34:57 visual_prompt]: Best epoch 99: best metric: 0.610
[09/19 12:34:57 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/19 12:35:08 visual_prompt]: Epoch 100 / 100: avg data time: 2.21e-01, avg batch time: 0.4462, average train loss: 1.2462
[09/19 12:35:14 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.0966, average loss: 1.1491
[09/19 12:35:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 59.50	top5: 96.00	
[09/19 12:35:34 visual_prompt]: 	Test 100/1152. loss: 3.242, 0.1279 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 12:35:50 visual_prompt]: 	Test 200/1152. loss: 2.922, 0.0964 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 12:36:06 visual_prompt]: 	Test 300/1152. loss: 2.942, 0.1149 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 12:36:22 visual_prompt]: 	Test 400/1152. loss: 3.323, 0.1016 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 12:36:38 visual_prompt]: 	Test 500/1152. loss: 3.130, 0.0985 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 12:36:55 visual_prompt]: 	Test 600/1152. loss: 2.989, 0.0977 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 12:37:11 visual_prompt]: 	Test 700/1152. loss: 2.608, 0.2088 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/19 12:37:27 visual_prompt]: 	Test 800/1152. loss: 2.737, 0.1078 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 12:37:43 visual_prompt]: 	Test 900/1152. loss: 2.662, 0.1078 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 12:37:59 visual_prompt]: 	Test 1000/1152. loss: 2.802, 0.1039 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 12:38:16 visual_prompt]: 	Test 1100/1152. loss: 2.448, 0.0963 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 12:38:28 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1088, average loss: 2.8416
[09/19 12:38:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.17	top5: 70.78	
[09/19 12:39:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/19 12:39:03 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A100-PCIE-40GB
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/19 12:39:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)', 'DATA.NUMBER_CLASSES', '16', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/19 12:39:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/19 12:39:03 visual_prompt]: Training with config:
[09/19 12:39:03 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)',
          'NO_TEST': False,
          'NUMBER_CLASSES': 16,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-dsprites(predicted_attribute="label_orientation",num_classes=16)/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/19 12:39:03 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-19 12:39:03.330622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-19 12:39:03.510010: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-19 12:39:08.880976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 12:39:08.881078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 12:39:08.881089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-19 12:39:18.017280: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 12:39:18.017392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-19 12:39:18.017405: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/19 12:39:18 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
2023-09-19 12:39:18.034840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[:800]+train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 12:39:19 visual_prompt]: Number of images: 1000
[09/19 12:39:19 visual_prompt]: Number of classes: 16 / 16
[09/19 12:39:19 visual_prompt]: Loading validation data...
[09/19 12:39:19 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[589824:590024], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 12:39:20 visual_prompt]: Number of images: 200
[09/19 12:39:20 visual_prompt]: Number of classes: 16 / 16
[09/19 12:39:20 visual_prompt]: Loading test data...
[09/19 12:39:20 visual_prompt]: Constructing vtab-dsprites(predicted_attribute="label_orientation",num_classes=16) dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dsprites/2.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset dsprites (visual_prompt_tuning/data_path/dsprites/2.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dsprites for split train[663552:], from visual_prompt_tuning/data_path/dsprites/2.0.0
[WARNING: feature.py:   71]: `FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.
[09/19 12:40:49 visual_prompt]: Number of images: 73728
[09/19 12:40:49 visual_prompt]: Number of classes: 16 / 16
[09/19 12:40:49 visual_prompt]: Constructing models...
[09/19 12:40:52 visual_prompt]: Total Parameters: 86732560	 Gradient Parameters: 933904
[09/19 12:40:52 visual_prompt]: tuned percent:1.077
[09/19 12:40:54 visual_prompt]: Device used for model: 0
[09/19 12:40:54 visual_prompt]: Setting up Evalutator...
[09/19 12:40:54 visual_prompt]: Setting up Trainer...
[09/19 12:40:54 visual_prompt]: 	Setting up the optimizer...
[09/19 12:40:54 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/19 12:41:06 visual_prompt]: Epoch 1 / 100: avg data time: 2.30e-01, avg batch time: 0.5586, average train loss: 3.0172
[09/19 12:41:13 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.0965, average loss: 3.0723
[09/19 12:41:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 32.00	
[09/19 12:41:33 visual_prompt]: 	Test 100/1152. loss: 3.174, 0.1162 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 12:41:49 visual_prompt]: 	Test 200/1152. loss: 3.052, 0.0976 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 12:42:05 visual_prompt]: 	Test 300/1152. loss: 2.977, 0.0968 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 12:42:21 visual_prompt]: 	Test 400/1152. loss: 2.948, 0.1200 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 12:42:38 visual_prompt]: 	Test 500/1152. loss: 3.133, 0.1293 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 12:42:53 visual_prompt]: 	Test 600/1152. loss: 3.190, 0.0959 s / batch. (data: 4.01e-05)max mem: 17.22454 GB 
[09/19 12:43:10 visual_prompt]: 	Test 700/1152. loss: 2.887, 0.1104 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 12:43:26 visual_prompt]: 	Test 800/1152. loss: 3.041, 0.1039 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 12:43:42 visual_prompt]: 	Test 900/1152. loss: 3.243, 0.1038 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 12:43:58 visual_prompt]: 	Test 1000/1152. loss: 3.104, 0.1244 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/19 12:44:14 visual_prompt]: 	Test 1100/1152. loss: 3.039, 0.0954 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 12:44:26 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1093, average loss: 3.0261
[09/19 12:44:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 30.64	
[09/19 12:44:26 visual_prompt]: Best epoch 1: best metric: 0.050
[09/19 12:44:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/19 12:44:37 visual_prompt]: Epoch 2 / 100: avg data time: 2.23e-01, avg batch time: 0.4497, average train loss: 3.3555
[09/19 12:44:43 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.0864, average loss: 2.8419
[09/19 12:44:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 38.50	
[09/19 12:45:03 visual_prompt]: 	Test 100/1152. loss: 2.976, 0.1159 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 12:45:19 visual_prompt]: 	Test 200/1152. loss: 3.029, 0.0985 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 12:45:35 visual_prompt]: 	Test 300/1152. loss: 2.878, 0.1287 s / batch. (data: 2.23e-03)max mem: 17.22454 GB 
[09/19 12:45:51 visual_prompt]: 	Test 400/1152. loss: 2.993, 0.0999 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 12:46:07 visual_prompt]: 	Test 500/1152. loss: 2.939, 0.1089 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 12:46:23 visual_prompt]: 	Test 600/1152. loss: 2.883, 0.1119 s / batch. (data: 6.17e-03)max mem: 17.22454 GB 
[09/19 12:46:40 visual_prompt]: 	Test 700/1152. loss: 2.849, 0.1130 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 12:46:56 visual_prompt]: 	Test 800/1152. loss: 2.969, 0.1012 s / batch. (data: 8.49e-05)max mem: 17.22454 GB 
[09/19 12:47:12 visual_prompt]: 	Test 900/1152. loss: 2.808, 0.1353 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 12:47:28 visual_prompt]: 	Test 1000/1152. loss: 2.898, 0.1540 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 12:47:44 visual_prompt]: 	Test 1100/1152. loss: 2.890, 0.1199 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 12:47:57 visual_prompt]: Inference (test):avg data time: 1.56e-03, avg batch time: 0.1089, average loss: 2.9158
[09/19 12:47:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.66	
[09/19 12:47:57 visual_prompt]: Best epoch 2: best metric: 0.105
[09/19 12:47:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/19 12:48:07 visual_prompt]: Epoch 3 / 100: avg data time: 2.16e-01, avg batch time: 0.4471, average train loss: 2.9392
[09/19 12:48:14 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.0923, average loss: 2.8995
[09/19 12:48:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 40.50	
[09/19 12:48:34 visual_prompt]: 	Test 100/1152. loss: 2.979, 0.1027 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 12:48:50 visual_prompt]: 	Test 200/1152. loss: 2.961, 0.1238 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 12:49:06 visual_prompt]: 	Test 300/1152. loss: 2.904, 0.0972 s / batch. (data: 2.06e-04)max mem: 17.22454 GB 
[09/19 12:49:22 visual_prompt]: 	Test 400/1152. loss: 2.996, 0.0956 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 12:49:38 visual_prompt]: 	Test 500/1152. loss: 2.986, 0.1000 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 12:49:54 visual_prompt]: 	Test 600/1152. loss: 2.983, 0.1181 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 12:50:11 visual_prompt]: 	Test 700/1152. loss: 3.037, 0.1199 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 12:50:27 visual_prompt]: 	Test 800/1152. loss: 2.924, 0.1025 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 12:50:43 visual_prompt]: 	Test 900/1152. loss: 2.913, 0.1025 s / batch. (data: 1.78e-04)max mem: 17.22454 GB 
[09/19 12:50:59 visual_prompt]: 	Test 1000/1152. loss: 2.880, 0.1155 s / batch. (data: 2.27e-04)max mem: 17.22454 GB 
[09/19 12:51:15 visual_prompt]: 	Test 1100/1152. loss: 3.126, 0.0985 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 12:51:27 visual_prompt]: Inference (test):avg data time: 2.12e-03, avg batch time: 0.1088, average loss: 2.9779
[09/19 12:51:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 35.07	
[09/19 12:51:27 visual_prompt]: Best epoch 3: best metric: 0.115
[09/19 12:51:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/19 12:51:38 visual_prompt]: Epoch 4 / 100: avg data time: 2.15e-01, avg batch time: 0.4487, average train loss: 2.9764
[09/19 12:51:44 visual_prompt]: Inference (val):avg data time: 1.75e-03, avg batch time: 0.0974, average loss: 3.2063
[09/19 12:51:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 29.00	
[09/19 12:52:04 visual_prompt]: 	Test 100/1152. loss: 3.053, 0.0978 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 12:52:20 visual_prompt]: 	Test 200/1152. loss: 3.338, 0.1038 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 12:52:36 visual_prompt]: 	Test 300/1152. loss: 3.080, 0.0958 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 12:52:52 visual_prompt]: 	Test 400/1152. loss: 3.102, 0.1079 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 12:53:09 visual_prompt]: 	Test 500/1152. loss: 3.053, 0.1444 s / batch. (data: 2.37e-02)max mem: 17.22454 GB 
[09/19 12:53:25 visual_prompt]: 	Test 600/1152. loss: 3.020, 0.1037 s / batch. (data: 1.62e-05)max mem: 17.22454 GB 
[09/19 12:53:41 visual_prompt]: 	Test 700/1152. loss: 3.077, 0.1129 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/19 12:53:57 visual_prompt]: 	Test 800/1152. loss: 3.136, 0.1296 s / batch. (data: 6.91e-05)max mem: 17.22454 GB 
[09/19 12:54:13 visual_prompt]: 	Test 900/1152. loss: 3.113, 0.1000 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 12:54:29 visual_prompt]: 	Test 1000/1152. loss: 3.218, 0.1123 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/19 12:54:45 visual_prompt]: 	Test 1100/1152. loss: 3.174, 0.1075 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 12:54:57 visual_prompt]: Inference (test):avg data time: 2.13e-03, avg batch time: 0.1091, average loss: 3.1505
[09/19 12:54:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.44	
[09/19 12:54:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/19 12:55:07 visual_prompt]: Epoch 5 / 100: avg data time: 2.16e-01, avg batch time: 0.4445, average train loss: 3.1233
[09/19 12:55:14 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.0881, average loss: 3.0562
[09/19 12:55:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 38.00	
[09/19 12:55:33 visual_prompt]: 	Test 100/1152. loss: 3.023, 0.1068 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 12:55:49 visual_prompt]: 	Test 200/1152. loss: 3.062, 0.1099 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 12:56:06 visual_prompt]: 	Test 300/1152. loss: 2.871, 0.1076 s / batch. (data: 6.77e-05)max mem: 17.22454 GB 
[09/19 12:56:22 visual_prompt]: 	Test 400/1152. loss: 3.042, 0.0949 s / batch. (data: 7.20e-05)max mem: 17.22454 GB 
[09/19 12:56:38 visual_prompt]: 	Test 500/1152. loss: 3.220, 0.1030 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 12:56:54 visual_prompt]: 	Test 600/1152. loss: 3.065, 0.1077 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 12:57:10 visual_prompt]: 	Test 700/1152. loss: 3.067, 0.1351 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 12:57:26 visual_prompt]: 	Test 800/1152. loss: 3.004, 0.1271 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 12:57:42 visual_prompt]: 	Test 900/1152. loss: 2.995, 0.1127 s / batch. (data: 6.75e-05)max mem: 17.22454 GB 
[09/19 12:57:58 visual_prompt]: 	Test 1000/1152. loss: 2.908, 0.0958 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 12:58:14 visual_prompt]: 	Test 1100/1152. loss: 3.105, 0.1207 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 12:58:26 visual_prompt]: Inference (test):avg data time: 1.70e-03, avg batch time: 0.1091, average loss: 3.0942
[09/19 12:58:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 32.67	
[09/19 12:58:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/19 12:58:36 visual_prompt]: Epoch 6 / 100: avg data time: 2.06e-01, avg batch time: 0.4363, average train loss: 3.2148
[09/19 12:58:43 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.0929, average loss: 3.4992
[09/19 12:58:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 26.50	
[09/19 12:59:02 visual_prompt]: 	Test 100/1152. loss: 3.462, 0.1139 s / batch. (data: 6.39e-05)max mem: 17.22454 GB 
[09/19 12:59:19 visual_prompt]: 	Test 200/1152. loss: 3.309, 0.0943 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 12:59:35 visual_prompt]: 	Test 300/1152. loss: 3.360, 0.1111 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 12:59:51 visual_prompt]: 	Test 400/1152. loss: 3.241, 0.1755 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 13:00:07 visual_prompt]: 	Test 500/1152. loss: 3.412, 0.1067 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 13:00:23 visual_prompt]: 	Test 600/1152. loss: 3.317, 0.0975 s / batch. (data: 1.87e-04)max mem: 17.22454 GB 
[09/19 13:00:39 visual_prompt]: 	Test 700/1152. loss: 3.536, 0.0952 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 13:00:55 visual_prompt]: 	Test 800/1152. loss: 3.304, 0.1069 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 13:01:11 visual_prompt]: 	Test 900/1152. loss: 3.422, 0.1019 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 13:01:28 visual_prompt]: 	Test 1000/1152. loss: 3.362, 0.0979 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 13:01:44 visual_prompt]: 	Test 1100/1152. loss: 3.631, 0.0966 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 13:01:56 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1080, average loss: 3.4139
[09/19 13:01:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.00	
[09/19 13:01:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/19 13:02:06 visual_prompt]: Epoch 7 / 100: avg data time: 2.13e-01, avg batch time: 0.4412, average train loss: 3.1969
[09/19 13:02:13 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.0867, average loss: 3.3988
[09/19 13:02:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 26.50	
[09/19 13:02:33 visual_prompt]: 	Test 100/1152. loss: 3.625, 0.1214 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 13:02:49 visual_prompt]: 	Test 200/1152. loss: 3.434, 0.1327 s / batch. (data: 2.00e-02)max mem: 17.22454 GB 
[09/19 13:03:05 visual_prompt]: 	Test 300/1152. loss: 3.187, 0.0999 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 13:03:22 visual_prompt]: 	Test 400/1152. loss: 3.349, 0.1167 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 13:03:38 visual_prompt]: 	Test 500/1152. loss: 3.377, 0.1155 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 13:03:53 visual_prompt]: 	Test 600/1152. loss: 3.494, 0.0991 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 13:04:09 visual_prompt]: 	Test 700/1152. loss: 3.088, 0.0978 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 13:04:26 visual_prompt]: 	Test 800/1152. loss: 3.265, 0.1000 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 13:04:42 visual_prompt]: 	Test 900/1152. loss: 3.771, 0.0980 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 13:04:58 visual_prompt]: 	Test 1000/1152. loss: 3.494, 0.1284 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 13:05:13 visual_prompt]: 	Test 1100/1152. loss: 3.248, 0.0994 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 13:05:26 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1085, average loss: 3.2963
[09/19 13:05:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 29.78	
[09/19 13:05:26 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/19 13:05:36 visual_prompt]: Epoch 8 / 100: avg data time: 2.17e-01, avg batch time: 0.4496, average train loss: 3.4180
[09/19 13:05:43 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.0864, average loss: 3.5963
[09/19 13:05:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 29.50	
[09/19 13:06:02 visual_prompt]: 	Test 100/1152. loss: 3.358, 0.1309 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 13:06:19 visual_prompt]: 	Test 200/1152. loss: 3.357, 0.0984 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 13:06:35 visual_prompt]: 	Test 300/1152. loss: 3.677, 0.1315 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 13:06:51 visual_prompt]: 	Test 400/1152. loss: 3.524, 0.1117 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 13:07:08 visual_prompt]: 	Test 500/1152. loss: 3.443, 0.1239 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:07:24 visual_prompt]: 	Test 600/1152. loss: 3.467, 0.1106 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 13:07:40 visual_prompt]: 	Test 700/1152. loss: 3.938, 0.0975 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/19 13:07:56 visual_prompt]: 	Test 800/1152. loss: 3.649, 0.0963 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/19 13:08:12 visual_prompt]: 	Test 900/1152. loss: 3.582, 0.1171 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 13:08:28 visual_prompt]: 	Test 1000/1152. loss: 3.669, 0.1202 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 13:08:44 visual_prompt]: 	Test 1100/1152. loss: 3.616, 0.1302 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 13:08:56 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1087, average loss: 3.5784
[09/19 13:08:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 30.11	
[09/19 13:08:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/19 13:09:06 visual_prompt]: Epoch 9 / 100: avg data time: 2.09e-01, avg batch time: 0.4347, average train loss: 3.4391
[09/19 13:09:13 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0868, average loss: 3.6972
[09/19 13:09:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 26.00	
[09/19 13:09:32 visual_prompt]: 	Test 100/1152. loss: 3.757, 0.1042 s / batch. (data: 6.17e-03)max mem: 17.22454 GB 
[09/19 13:09:49 visual_prompt]: 	Test 200/1152. loss: 3.751, 0.1277 s / batch. (data: 1.47e-02)max mem: 17.22454 GB 
[09/19 13:10:05 visual_prompt]: 	Test 300/1152. loss: 3.504, 0.1090 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 13:10:21 visual_prompt]: 	Test 400/1152. loss: 3.624, 0.0978 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 13:10:37 visual_prompt]: 	Test 500/1152. loss: 3.868, 0.0990 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 13:10:53 visual_prompt]: 	Test 600/1152. loss: 3.628, 0.1037 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 13:11:09 visual_prompt]: 	Test 700/1152. loss: 3.456, 0.0999 s / batch. (data: 9.13e-05)max mem: 17.22454 GB 
[09/19 13:11:25 visual_prompt]: 	Test 800/1152. loss: 3.642, 0.0985 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 13:11:41 visual_prompt]: 	Test 900/1152. loss: 3.512, 0.0992 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 13:11:58 visual_prompt]: 	Test 1000/1152. loss: 3.442, 0.1139 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:12:14 visual_prompt]: 	Test 1100/1152. loss: 3.647, 0.1171 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 13:12:25 visual_prompt]: Inference (test):avg data time: 2.17e-03, avg batch time: 0.1091, average loss: 3.6586
[09/19 13:12:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 27.46	
[09/19 13:12:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/19 13:12:36 visual_prompt]: Epoch 10 / 100: avg data time: 2.12e-01, avg batch time: 0.4443, average train loss: 3.5073
[09/19 13:12:42 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.0904, average loss: 3.3753
[09/19 13:12:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 33.50	
[09/19 13:13:02 visual_prompt]: 	Test 100/1152. loss: 3.501, 0.1117 s / batch. (data: 1.06e-02)max mem: 17.22454 GB 
[09/19 13:13:18 visual_prompt]: 	Test 200/1152. loss: 3.942, 0.1121 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 13:13:35 visual_prompt]: 	Test 300/1152. loss: 3.029, 0.1159 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:13:51 visual_prompt]: 	Test 400/1152. loss: 3.476, 0.1040 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 13:14:07 visual_prompt]: 	Test 500/1152. loss: 3.679, 0.1002 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 13:14:23 visual_prompt]: 	Test 600/1152. loss: 3.400, 0.1034 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 13:14:40 visual_prompt]: 	Test 700/1152. loss: 2.972, 0.1121 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 13:14:56 visual_prompt]: 	Test 800/1152. loss: 3.169, 0.1165 s / batch. (data: 2.19e-02)max mem: 17.22454 GB 
[09/19 13:15:12 visual_prompt]: 	Test 900/1152. loss: 3.389, 0.0985 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 13:15:28 visual_prompt]: 	Test 1000/1152. loss: 3.452, 0.1277 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 13:15:44 visual_prompt]: 	Test 1100/1152. loss: 3.408, 0.0979 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 13:15:56 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1085, average loss: 3.4649
[09/19 13:15:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 34.24	
[09/19 13:15:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/19 13:16:07 visual_prompt]: Epoch 11 / 100: avg data time: 2.19e-01, avg batch time: 0.4457, average train loss: 3.3286
[09/19 13:16:13 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.0929, average loss: 3.1594
[09/19 13:16:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 28.50	
[09/19 13:16:33 visual_prompt]: 	Test 100/1152. loss: 3.135, 0.1081 s / batch. (data: 9.32e-05)max mem: 17.22454 GB 
[09/19 13:16:49 visual_prompt]: 	Test 200/1152. loss: 3.104, 0.1105 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 13:17:05 visual_prompt]: 	Test 300/1152. loss: 2.924, 0.0957 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 13:17:21 visual_prompt]: 	Test 400/1152. loss: 3.102, 0.1117 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 13:17:38 visual_prompt]: 	Test 500/1152. loss: 3.083, 0.1238 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 13:17:54 visual_prompt]: 	Test 600/1152. loss: 3.185, 0.1119 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 13:18:10 visual_prompt]: 	Test 700/1152. loss: 3.110, 0.1092 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 13:18:26 visual_prompt]: 	Test 800/1152. loss: 2.979, 0.1225 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 13:18:42 visual_prompt]: 	Test 900/1152. loss: 3.352, 0.1161 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 13:18:58 visual_prompt]: 	Test 1000/1152. loss: 3.229, 0.0998 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 13:19:15 visual_prompt]: 	Test 1100/1152. loss: 3.272, 0.1061 s / batch. (data: 1.79e-04)max mem: 17.22454 GB 
[09/19 13:19:26 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1087, average loss: 3.1334
[09/19 13:19:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 32.46	
[09/19 13:19:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/19 13:19:37 visual_prompt]: Epoch 12 / 100: avg data time: 2.16e-01, avg batch time: 0.4458, average train loss: 3.1924
[09/19 13:19:43 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.0877, average loss: 3.2894
[09/19 13:19:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.50	
[09/19 13:20:03 visual_prompt]: 	Test 100/1152. loss: 3.150, 0.1163 s / batch. (data: 4.74e-05)max mem: 17.22454 GB 
[09/19 13:20:19 visual_prompt]: 	Test 200/1152. loss: 3.263, 0.1222 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 13:20:35 visual_prompt]: 	Test 300/1152. loss: 3.051, 0.1077 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 13:20:51 visual_prompt]: 	Test 400/1152. loss: 3.110, 0.0948 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 13:21:07 visual_prompt]: 	Test 500/1152. loss: 3.131, 0.1058 s / batch. (data: 4.82e-05)max mem: 17.22454 GB 
[09/19 13:21:23 visual_prompt]: 	Test 600/1152. loss: 3.141, 0.0983 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 13:21:39 visual_prompt]: 	Test 700/1152. loss: 3.339, 0.1391 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 13:21:55 visual_prompt]: 	Test 800/1152. loss: 3.033, 0.1278 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 13:22:12 visual_prompt]: 	Test 900/1152. loss: 3.294, 0.0963 s / batch. (data: 3.08e-05)max mem: 17.22454 GB 
[09/19 13:22:27 visual_prompt]: 	Test 1000/1152. loss: 3.176, 0.0952 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 13:22:43 visual_prompt]: 	Test 1100/1152. loss: 3.241, 0.1258 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 13:22:56 visual_prompt]: Inference (test):avg data time: 1.33e-03, avg batch time: 0.1086, average loss: 3.1955
[09/19 13:22:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.87	
[09/19 13:22:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/19 13:23:06 visual_prompt]: Epoch 13 / 100: avg data time: 2.15e-01, avg batch time: 0.4441, average train loss: 3.1692
[09/19 13:23:13 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.0888, average loss: 3.1839
[09/19 13:23:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.00	top5: 29.00	
[09/19 13:23:33 visual_prompt]: 	Test 100/1152. loss: 3.249, 0.1007 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 13:23:49 visual_prompt]: 	Test 200/1152. loss: 3.076, 0.0988 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 13:24:06 visual_prompt]: 	Test 300/1152. loss: 2.808, 0.0948 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 13:24:22 visual_prompt]: 	Test 400/1152. loss: 2.932, 0.0952 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 13:24:38 visual_prompt]: 	Test 500/1152. loss: 3.006, 0.0974 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 13:24:54 visual_prompt]: 	Test 600/1152. loss: 2.980, 0.0959 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 13:25:10 visual_prompt]: 	Test 700/1152. loss: 2.960, 0.1177 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/19 13:25:26 visual_prompt]: 	Test 800/1152. loss: 2.980, 0.1094 s / batch. (data: 4.60e-05)max mem: 17.22454 GB 
[09/19 13:25:42 visual_prompt]: 	Test 900/1152. loss: 3.322, 0.1095 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 13:25:59 visual_prompt]: 	Test 1000/1152. loss: 3.114, 0.0991 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 13:26:15 visual_prompt]: 	Test 1100/1152. loss: 3.104, 0.1173 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 13:26:27 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1075, average loss: 3.0222
[09/19 13:26:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.07	top5: 35.05	
[09/19 13:26:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/19 13:26:38 visual_prompt]: Epoch 14 / 100: avg data time: 2.22e-01, avg batch time: 0.4488, average train loss: 3.1649
[09/19 13:26:44 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0907, average loss: 2.8962
[09/19 13:26:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.00	top5: 38.50	
[09/19 13:27:04 visual_prompt]: 	Test 100/1152. loss: 2.947, 0.1040 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 13:27:20 visual_prompt]: 	Test 200/1152. loss: 3.132, 0.0990 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 13:27:36 visual_prompt]: 	Test 300/1152. loss: 2.830, 0.0967 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 13:27:53 visual_prompt]: 	Test 400/1152. loss: 2.928, 0.1062 s / batch. (data: 3.70e-05)max mem: 17.22454 GB 
[09/19 13:28:09 visual_prompt]: 	Test 500/1152. loss: 3.045, 0.1131 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 13:28:24 visual_prompt]: 	Test 600/1152. loss: 3.063, 0.1038 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 13:28:41 visual_prompt]: 	Test 700/1152. loss: 3.016, 0.1331 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:28:56 visual_prompt]: 	Test 800/1152. loss: 2.929, 0.0984 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 13:29:13 visual_prompt]: 	Test 900/1152. loss: 2.923, 0.1082 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 13:29:29 visual_prompt]: 	Test 1000/1152. loss: 2.935, 0.1013 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 13:29:44 visual_prompt]: 	Test 1100/1152. loss: 2.945, 0.1039 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 13:29:57 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1086, average loss: 2.9641
[09/19 13:29:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.17	top5: 36.45	
[09/19 13:29:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/19 13:30:07 visual_prompt]: Epoch 15 / 100: avg data time: 2.15e-01, avg batch time: 0.4399, average train loss: 2.9664
[09/19 13:30:14 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.0911, average loss: 2.8193
[09/19 13:30:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 40.50	
[09/19 13:30:34 visual_prompt]: 	Test 100/1152. loss: 2.926, 0.1135 s / batch. (data: 8.91e-03)max mem: 17.22454 GB 
[09/19 13:30:50 visual_prompt]: 	Test 200/1152. loss: 2.867, 0.0983 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 13:31:07 visual_prompt]: 	Test 300/1152. loss: 2.863, 0.0977 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 13:31:23 visual_prompt]: 	Test 400/1152. loss: 2.912, 0.0967 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 13:31:39 visual_prompt]: 	Test 500/1152. loss: 2.850, 0.0999 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 13:31:55 visual_prompt]: 	Test 600/1152. loss: 2.718, 0.1471 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 13:32:11 visual_prompt]: 	Test 700/1152. loss: 2.764, 0.1089 s / batch. (data: 6.46e-05)max mem: 17.22454 GB 
[09/19 13:32:28 visual_prompt]: 	Test 800/1152. loss: 2.931, 0.0948 s / batch. (data: 6.41e-05)max mem: 17.22454 GB 
[09/19 13:32:44 visual_prompt]: 	Test 900/1152. loss: 2.812, 0.0970 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/19 13:33:00 visual_prompt]: 	Test 1000/1152. loss: 3.021, 0.0975 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 13:33:16 visual_prompt]: 	Test 1100/1152. loss: 2.749, 0.0993 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 13:33:28 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1082, average loss: 2.8676
[09/19 13:33:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 36.61	
[09/19 13:33:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/19 13:33:38 visual_prompt]: Epoch 16 / 100: avg data time: 2.07e-01, avg batch time: 0.4370, average train loss: 3.7207
[09/19 13:33:45 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.0950, average loss: 4.2564
[09/19 13:33:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 41.00	
[09/19 13:34:04 visual_prompt]: 	Test 100/1152. loss: 4.391, 0.1059 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 13:34:21 visual_prompt]: 	Test 200/1152. loss: 4.425, 0.0943 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/19 13:34:37 visual_prompt]: 	Test 300/1152. loss: 5.027, 0.1184 s / batch. (data: 2.21e-02)max mem: 17.22454 GB 
[09/19 13:34:53 visual_prompt]: 	Test 400/1152. loss: 4.846, 0.1199 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 13:35:09 visual_prompt]: 	Test 500/1152. loss: 4.277, 0.1069 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/19 13:35:25 visual_prompt]: 	Test 600/1152. loss: 4.676, 0.0971 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 13:35:41 visual_prompt]: 	Test 700/1152. loss: 4.958, 0.1235 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 13:35:57 visual_prompt]: 	Test 800/1152. loss: 4.206, 0.0990 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 13:36:13 visual_prompt]: 	Test 900/1152. loss: 4.381, 0.1118 s / batch. (data: 7.42e-03)max mem: 17.22454 GB 
[09/19 13:36:30 visual_prompt]: 	Test 1000/1152. loss: 4.346, 0.1240 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 13:36:45 visual_prompt]: 	Test 1100/1152. loss: 4.236, 0.1138 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 13:36:58 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1087, average loss: 4.4711
[09/19 13:36:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.03	
[09/19 13:36:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/19 13:37:08 visual_prompt]: Epoch 17 / 100: avg data time: 2.09e-01, avg batch time: 0.4363, average train loss: 6.3708
[09/19 13:37:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0875, average loss: 8.3820
[09/19 13:37:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 25.50	
[09/19 13:37:34 visual_prompt]: 	Test 100/1152. loss: 6.494, 0.1145 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 13:37:50 visual_prompt]: 	Test 200/1152. loss: 6.754, 0.1320 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:38:06 visual_prompt]: 	Test 300/1152. loss: 8.296, 0.1002 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 13:38:22 visual_prompt]: 	Test 400/1152. loss: 8.723, 0.1287 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/19 13:38:38 visual_prompt]: 	Test 500/1152. loss: 6.939, 0.1192 s / batch. (data: 1.07e-02)max mem: 17.22454 GB 
[09/19 13:38:55 visual_prompt]: 	Test 600/1152. loss: 6.736, 0.1077 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 13:39:11 visual_prompt]: 	Test 700/1152. loss: 10.328, 0.1005 s / batch. (data: 1.14e-05)max mem: 17.22454 GB 
[09/19 13:39:27 visual_prompt]: 	Test 800/1152. loss: 7.240, 0.0988 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 13:39:43 visual_prompt]: 	Test 900/1152. loss: 7.502, 0.0990 s / batch. (data: 3.19e-05)max mem: 17.22454 GB 
[09/19 13:39:59 visual_prompt]: 	Test 1000/1152. loss: 6.997, 0.1199 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 13:40:15 visual_prompt]: 	Test 1100/1152. loss: 7.483, 0.1037 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 13:40:27 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1083, average loss: 8.0323
[09/19 13:40:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 27.52	
[09/19 13:40:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/19 13:40:37 visual_prompt]: Epoch 18 / 100: avg data time: 2.13e-01, avg batch time: 0.4335, average train loss: 13.8176
[09/19 13:40:44 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0913, average loss: 17.6873
[09/19 13:40:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 28.50	
[09/19 13:41:03 visual_prompt]: 	Test 100/1152. loss: 17.396, 0.1078 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 13:41:19 visual_prompt]: 	Test 200/1152. loss: 17.547, 0.0971 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 13:41:36 visual_prompt]: 	Test 300/1152. loss: 17.170, 0.0986 s / batch. (data: 3.12e-05)max mem: 17.22454 GB 
[09/19 13:41:52 visual_prompt]: 	Test 400/1152. loss: 17.932, 0.1129 s / batch. (data: 3.62e-05)max mem: 17.22454 GB 
[09/19 13:42:08 visual_prompt]: 	Test 500/1152. loss: 17.442, 0.0997 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 13:42:24 visual_prompt]: 	Test 600/1152. loss: 17.805, 0.0998 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 13:42:40 visual_prompt]: 	Test 700/1152. loss: 16.443, 0.1006 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 13:42:56 visual_prompt]: 	Test 800/1152. loss: 17.852, 0.1046 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 13:43:12 visual_prompt]: 	Test 900/1152. loss: 17.120, 0.1039 s / batch. (data: 1.90e-04)max mem: 17.22454 GB 
[09/19 13:43:28 visual_prompt]: 	Test 1000/1152. loss: 15.648, 0.1078 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 13:43:45 visual_prompt]: 	Test 1100/1152. loss: 15.237, 0.1088 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/19 13:43:57 visual_prompt]: Inference (test):avg data time: 1.68e-03, avg batch time: 0.1083, average loss: 16.8423
[09/19 13:43:57 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 30.13	
[09/19 13:43:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/19 13:44:07 visual_prompt]: Epoch 19 / 100: avg data time: 2.14e-01, avg batch time: 0.4386, average train loss: 22.1481
[09/19 13:44:13 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.0881, average loss: 17.2899
[09/19 13:44:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 40.00	
[09/19 13:44:33 visual_prompt]: 	Test 100/1152. loss: 17.905, 0.1118 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 13:44:49 visual_prompt]: 	Test 200/1152. loss: 21.164, 0.1313 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 13:45:05 visual_prompt]: 	Test 300/1152. loss: 20.044, 0.1107 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 13:45:21 visual_prompt]: 	Test 400/1152. loss: 19.363, 0.1074 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:45:37 visual_prompt]: 	Test 500/1152. loss: 18.005, 0.1380 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 13:45:53 visual_prompt]: 	Test 600/1152. loss: 19.934, 0.0967 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 13:46:09 visual_prompt]: 	Test 700/1152. loss: 18.930, 0.0958 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 13:46:26 visual_prompt]: 	Test 800/1152. loss: 19.828, 0.1007 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 13:46:41 visual_prompt]: 	Test 900/1152. loss: 17.470, 0.1106 s / batch. (data: 6.02e-03)max mem: 17.22454 GB 
[09/19 13:46:57 visual_prompt]: 	Test 1000/1152. loss: 19.652, 0.1311 s / batch. (data: 2.02e-02)max mem: 17.22454 GB 
[09/19 13:47:13 visual_prompt]: 	Test 1100/1152. loss: 21.416, 0.0949 s / batch. (data: 6.82e-05)max mem: 17.22454 GB 
[09/19 13:47:25 visual_prompt]: Inference (test):avg data time: 2.06e-03, avg batch time: 0.1092, average loss: 19.1095
[09/19 13:47:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 32.60	
[09/19 13:47:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/19 13:47:36 visual_prompt]: Epoch 20 / 100: avg data time: 2.14e-01, avg batch time: 0.4396, average train loss: 19.2622
[09/19 13:47:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.0937, average loss: 17.7245
[09/19 13:47:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 28.00	
[09/19 13:48:02 visual_prompt]: 	Test 100/1152. loss: 17.785, 0.1196 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 13:48:18 visual_prompt]: 	Test 200/1152. loss: 17.664, 0.1191 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 13:48:34 visual_prompt]: 	Test 300/1152. loss: 15.476, 0.1043 s / batch. (data: 1.77e-04)max mem: 17.22454 GB 
[09/19 13:48:50 visual_prompt]: 	Test 400/1152. loss: 16.691, 0.0965 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 13:49:07 visual_prompt]: 	Test 500/1152. loss: 17.092, 0.1419 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 13:49:22 visual_prompt]: 	Test 600/1152. loss: 17.583, 0.0997 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 13:49:38 visual_prompt]: 	Test 700/1152. loss: 16.241, 0.1042 s / batch. (data: 7.20e-03)max mem: 17.22454 GB 
[09/19 13:49:54 visual_prompt]: 	Test 800/1152. loss: 17.621, 0.1039 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 13:50:10 visual_prompt]: 	Test 900/1152. loss: 18.178, 0.0969 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 13:50:27 visual_prompt]: 	Test 1000/1152. loss: 16.171, 0.1021 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/19 13:50:43 visual_prompt]: 	Test 1100/1152. loss: 16.121, 0.1029 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/19 13:50:55 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1082, average loss: 16.7375
[09/19 13:50:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.50	
[09/19 13:50:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/19 13:51:06 visual_prompt]: Epoch 21 / 100: avg data time: 2.14e-01, avg batch time: 0.4379, average train loss: 17.9098
[09/19 13:51:12 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.0948, average loss: 10.7552
[09/19 13:51:12 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 34.50	
[09/19 13:51:32 visual_prompt]: 	Test 100/1152. loss: 14.844, 0.1110 s / batch. (data: 4.24e-05)max mem: 17.22454 GB 
[09/19 13:51:48 visual_prompt]: 	Test 200/1152. loss: 9.413, 0.1158 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 13:52:04 visual_prompt]: 	Test 300/1152. loss: 12.763, 0.0968 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 13:52:20 visual_prompt]: 	Test 400/1152. loss: 12.297, 0.1249 s / batch. (data: 3.36e-05)max mem: 17.22454 GB 
[09/19 13:52:36 visual_prompt]: 	Test 500/1152. loss: 13.395, 0.1095 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 13:52:53 visual_prompt]: 	Test 600/1152. loss: 12.028, 0.1030 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 13:53:09 visual_prompt]: 	Test 700/1152. loss: 10.429, 0.0964 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 13:53:25 visual_prompt]: 	Test 800/1152. loss: 14.173, 0.1186 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 13:53:41 visual_prompt]: 	Test 900/1152. loss: 12.110, 0.1109 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 13:53:57 visual_prompt]: 	Test 1000/1152. loss: 12.928, 0.1089 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 13:54:13 visual_prompt]: 	Test 1100/1152. loss: 12.939, 0.1519 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 13:54:25 visual_prompt]: Inference (test):avg data time: 1.77e-03, avg batch time: 0.1086, average loss: 11.9210
[09/19 13:54:25 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 32.65	
[09/19 13:54:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/19 13:54:35 visual_prompt]: Epoch 22 / 100: avg data time: 2.14e-01, avg batch time: 0.4384, average train loss: 13.4912
[09/19 13:54:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0868, average loss: 13.2674
[09/19 13:54:41 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 28.00	
[09/19 13:55:01 visual_prompt]: 	Test 100/1152. loss: 13.396, 0.1268 s / batch. (data: 1.43e-02)max mem: 17.22454 GB 
[09/19 13:55:17 visual_prompt]: 	Test 200/1152. loss: 14.584, 0.1079 s / batch. (data: 4.51e-05)max mem: 17.22454 GB 
[09/19 13:55:34 visual_prompt]: 	Test 300/1152. loss: 9.277, 0.1060 s / batch. (data: 6.44e-05)max mem: 17.22454 GB 
[09/19 13:55:50 visual_prompt]: 	Test 400/1152. loss: 11.541, 0.1048 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 13:56:06 visual_prompt]: 	Test 500/1152. loss: 13.965, 0.1028 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 13:56:22 visual_prompt]: 	Test 600/1152. loss: 12.462, 0.0998 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 13:56:38 visual_prompt]: 	Test 700/1152. loss: 10.232, 0.0990 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 13:56:54 visual_prompt]: 	Test 800/1152. loss: 12.684, 0.1059 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 13:57:10 visual_prompt]: 	Test 900/1152. loss: 12.965, 0.0965 s / batch. (data: 3.89e-05)max mem: 17.22454 GB 
[09/19 13:57:26 visual_prompt]: 	Test 1000/1152. loss: 11.584, 0.0959 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 13:57:42 visual_prompt]: 	Test 1100/1152. loss: 12.015, 0.1198 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 13:57:55 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1095, average loss: 12.5962
[09/19 13:57:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 32.50	
[09/19 13:57:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/19 13:58:05 visual_prompt]: Epoch 23 / 100: avg data time: 2.13e-01, avg batch time: 0.4332, average train loss: 11.1667
[09/19 13:58:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.0944, average loss: 9.9426
[09/19 13:58:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 27.00	
[09/19 13:58:31 visual_prompt]: 	Test 100/1152. loss: 8.967, 0.1077 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 13:58:47 visual_prompt]: 	Test 200/1152. loss: 10.039, 0.1038 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 13:59:03 visual_prompt]: 	Test 300/1152. loss: 10.292, 0.1304 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 13:59:19 visual_prompt]: 	Test 400/1152. loss: 10.708, 0.1041 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 13:59:35 visual_prompt]: 	Test 500/1152. loss: 8.640, 0.1078 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 13:59:51 visual_prompt]: 	Test 600/1152. loss: 8.588, 0.1036 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 14:00:07 visual_prompt]: 	Test 700/1152. loss: 11.095, 0.1158 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 14:00:23 visual_prompt]: 	Test 800/1152. loss: 10.081, 0.1267 s / batch. (data: 6.17e-03)max mem: 17.22454 GB 
[09/19 14:00:39 visual_prompt]: 	Test 900/1152. loss: 9.821, 0.1037 s / batch. (data: 7.09e-03)max mem: 17.22454 GB 
[09/19 14:00:55 visual_prompt]: 	Test 1000/1152. loss: 10.449, 0.1073 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 14:01:11 visual_prompt]: 	Test 1100/1152. loss: 8.332, 0.1139 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 14:01:23 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1086, average loss: 9.8355
[09/19 14:01:24 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 29.86	
[09/19 14:01:24 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/19 14:01:34 visual_prompt]: Epoch 24 / 100: avg data time: 2.24e-01, avg batch time: 0.4476, average train loss: 13.2470
[09/19 14:01:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.0942, average loss: 17.6319
[09/19 14:01:40 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 2.50	top5: 31.50	
[09/19 14:02:00 visual_prompt]: 	Test 100/1152. loss: 18.509, 0.1109 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 14:02:16 visual_prompt]: 	Test 200/1152. loss: 14.196, 0.1224 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 14:02:33 visual_prompt]: 	Test 300/1152. loss: 19.164, 0.1118 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 14:02:49 visual_prompt]: 	Test 400/1152. loss: 17.619, 0.1278 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 14:03:06 visual_prompt]: 	Test 500/1152. loss: 17.940, 0.1276 s / batch. (data: 1.90e-02)max mem: 17.22454 GB 
[09/19 14:03:22 visual_prompt]: 	Test 600/1152. loss: 18.777, 0.1084 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 14:03:38 visual_prompt]: 	Test 700/1152. loss: 16.994, 0.1063 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 14:03:54 visual_prompt]: 	Test 800/1152. loss: 17.473, 0.1145 s / batch. (data: 9.85e-03)max mem: 17.22454 GB 
[09/19 14:04:10 visual_prompt]: 	Test 900/1152. loss: 19.051, 0.1318 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 14:04:26 visual_prompt]: 	Test 1000/1152. loss: 17.105, 0.0971 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 14:04:43 visual_prompt]: 	Test 1100/1152. loss: 15.933, 0.1078 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 14:04:55 visual_prompt]: Inference (test):avg data time: 2.37e-03, avg batch time: 0.1092, average loss: 17.2014
[09/19 14:04:55 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.13	top5: 30.04	
[09/19 14:04:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/19 14:05:05 visual_prompt]: Epoch 25 / 100: avg data time: 2.17e-01, avg batch time: 0.4409, average train loss: 14.8928
[09/19 14:05:11 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.0861, average loss: 13.9125
[09/19 14:05:11 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 25.00	
[09/19 14:05:31 visual_prompt]: 	Test 100/1152. loss: 12.595, 0.0993 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 14:05:47 visual_prompt]: 	Test 200/1152. loss: 12.391, 0.1111 s / batch. (data: 1.02e-02)max mem: 17.22454 GB 
[09/19 14:06:04 visual_prompt]: 	Test 300/1152. loss: 15.493, 0.1326 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 14:06:20 visual_prompt]: 	Test 400/1152. loss: 13.328, 0.1125 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 14:06:36 visual_prompt]: 	Test 500/1152. loss: 11.711, 0.0981 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 14:06:52 visual_prompt]: 	Test 600/1152. loss: 12.051, 0.0940 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 14:07:08 visual_prompt]: 	Test 700/1152. loss: 14.193, 0.1101 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 14:07:24 visual_prompt]: 	Test 800/1152. loss: 13.469, 0.1083 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 14:07:41 visual_prompt]: 	Test 900/1152. loss: 13.128, 0.1069 s / batch. (data: 6.28e-03)max mem: 17.22454 GB 
[09/19 14:07:57 visual_prompt]: 	Test 1000/1152. loss: 12.872, 0.1070 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 14:08:13 visual_prompt]: 	Test 1100/1152. loss: 12.963, 0.0963 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 14:08:25 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1085, average loss: 13.2795
[09/19 14:08:26 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 30.00	
[09/19 14:08:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/19 14:08:35 visual_prompt]: Epoch 26 / 100: avg data time: 2.13e-01, avg batch time: 0.4389, average train loss: 13.1089
[09/19 14:08:42 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.0904, average loss: 11.0050
[09/19 14:08:42 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 38.00	
[09/19 14:09:02 visual_prompt]: 	Test 100/1152. loss: 10.548, 0.1101 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 14:09:18 visual_prompt]: 	Test 200/1152. loss: 12.695, 0.1117 s / batch. (data: 1.69e-04)max mem: 17.22454 GB 
[09/19 14:09:35 visual_prompt]: 	Test 300/1152. loss: 12.731, 0.1017 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 14:09:51 visual_prompt]: 	Test 400/1152. loss: 10.891, 0.1200 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 14:10:07 visual_prompt]: 	Test 500/1152. loss: 10.790, 0.1001 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 14:10:23 visual_prompt]: 	Test 600/1152. loss: 11.577, 0.0986 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 14:10:39 visual_prompt]: 	Test 700/1152. loss: 11.870, 0.1044 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 14:10:55 visual_prompt]: 	Test 800/1152. loss: 12.076, 0.1051 s / batch. (data: 4.91e-05)max mem: 17.22454 GB 
[09/19 14:11:12 visual_prompt]: 	Test 900/1152. loss: 11.692, 0.1240 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 14:11:28 visual_prompt]: 	Test 1000/1152. loss: 13.059, 0.1270 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 14:11:44 visual_prompt]: 	Test 1100/1152. loss: 11.672, 0.1158 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 14:11:56 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1094, average loss: 11.6160
[09/19 14:11:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.44	top5: 35.01	
[09/19 14:11:56 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/19 14:12:06 visual_prompt]: Epoch 27 / 100: avg data time: 2.15e-01, avg batch time: 0.4408, average train loss: 9.5908
[09/19 14:12:13 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.0913, average loss: 7.3786
[09/19 14:12:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.00	
[09/19 14:12:32 visual_prompt]: 	Test 100/1152. loss: 7.788, 0.1059 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 14:12:48 visual_prompt]: 	Test 200/1152. loss: 8.191, 0.1006 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 14:13:05 visual_prompt]: 	Test 300/1152. loss: 6.933, 0.0952 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 14:13:21 visual_prompt]: 	Test 400/1152. loss: 7.517, 0.1159 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 14:13:37 visual_prompt]: 	Test 500/1152. loss: 7.475, 0.0961 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 14:13:53 visual_prompt]: 	Test 600/1152. loss: 7.776, 0.1049 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 14:14:09 visual_prompt]: 	Test 700/1152. loss: 6.952, 0.1032 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 14:14:25 visual_prompt]: 	Test 800/1152. loss: 7.313, 0.0999 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 14:14:41 visual_prompt]: 	Test 900/1152. loss: 8.341, 0.1227 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 14:14:57 visual_prompt]: 	Test 1000/1152. loss: 8.297, 0.0950 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 14:15:14 visual_prompt]: 	Test 1100/1152. loss: 6.701, 0.0950 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 14:15:26 visual_prompt]: Inference (test):avg data time: 1.67e-03, avg batch time: 0.1085, average loss: 7.3645
[09/19 14:15:27 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 32.35	
[09/19 14:15:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/19 14:15:37 visual_prompt]: Epoch 28 / 100: avg data time: 2.09e-01, avg batch time: 0.4337, average train loss: 6.8859
[09/19 14:15:43 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.0907, average loss: 6.1591
[09/19 14:15:43 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 29.00	
[09/19 14:16:03 visual_prompt]: 	Test 100/1152. loss: 6.603, 0.0965 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 14:16:19 visual_prompt]: 	Test 200/1152. loss: 7.188, 0.1000 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 14:16:35 visual_prompt]: 	Test 300/1152. loss: 5.538, 0.1113 s / batch. (data: 6.77e-03)max mem: 17.22454 GB 
[09/19 14:16:51 visual_prompt]: 	Test 400/1152. loss: 6.118, 0.0982 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 14:17:07 visual_prompt]: 	Test 500/1152. loss: 6.049, 0.1303 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/19 14:17:23 visual_prompt]: 	Test 600/1152. loss: 6.308, 0.0961 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 14:17:39 visual_prompt]: 	Test 700/1152. loss: 5.130, 0.0970 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/19 14:17:56 visual_prompt]: 	Test 800/1152. loss: 6.221, 0.1089 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 14:18:12 visual_prompt]: 	Test 900/1152. loss: 6.980, 0.0950 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 14:18:28 visual_prompt]: 	Test 1000/1152. loss: 7.005, 0.1080 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/19 14:18:44 visual_prompt]: 	Test 1100/1152. loss: 6.738, 0.0943 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 14:18:56 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1091, average loss: 6.1406
[09/19 14:18:56 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 32.54	
[09/19 14:18:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/19 14:19:06 visual_prompt]: Epoch 29 / 100: avg data time: 2.09e-01, avg batch time: 0.4383, average train loss: 5.2353
[09/19 14:19:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0929, average loss: 3.7664
[09/19 14:19:13 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 29.00	
[09/19 14:19:32 visual_prompt]: 	Test 100/1152. loss: 3.820, 0.0945 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 14:19:49 visual_prompt]: 	Test 200/1152. loss: 4.560, 0.1024 s / batch. (data: 6.27e-05)max mem: 17.22454 GB 
[09/19 14:20:05 visual_prompt]: 	Test 300/1152. loss: 3.827, 0.0950 s / batch. (data: 5.05e-05)max mem: 17.22454 GB 
[09/19 14:20:22 visual_prompt]: 	Test 400/1152. loss: 3.966, 0.1011 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 14:20:38 visual_prompt]: 	Test 500/1152. loss: 4.312, 0.1037 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 14:20:54 visual_prompt]: 	Test 600/1152. loss: 4.278, 0.1076 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 14:21:11 visual_prompt]: 	Test 700/1152. loss: 3.731, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 14:21:27 visual_prompt]: 	Test 800/1152. loss: 3.904, 0.1568 s / batch. (data: 4.39e-02)max mem: 17.22454 GB 
[09/19 14:21:43 visual_prompt]: 	Test 900/1152. loss: 3.587, 0.1054 s / batch. (data: 4.29e-05)max mem: 17.22454 GB 
[09/19 14:21:59 visual_prompt]: 	Test 1000/1152. loss: 3.582, 0.1088 s / batch. (data: 7.39e-03)max mem: 17.22454 GB 
[09/19 14:22:15 visual_prompt]: 	Test 1100/1152. loss: 3.817, 0.0948 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 14:22:28 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1089, average loss: 3.9938
[09/19 14:22:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 29.94	
[09/19 14:22:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/19 14:22:38 visual_prompt]: Epoch 30 / 100: avg data time: 2.12e-01, avg batch time: 0.4369, average train loss: 3.7444
[09/19 14:22:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.0962, average loss: 3.5294
[09/19 14:22:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 35.50	
[09/19 14:23:04 visual_prompt]: 	Test 100/1152. loss: 3.837, 0.0996 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 14:23:21 visual_prompt]: 	Test 200/1152. loss: 4.167, 0.1198 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 14:23:37 visual_prompt]: 	Test 300/1152. loss: 3.779, 0.0964 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 14:23:54 visual_prompt]: 	Test 400/1152. loss: 3.670, 0.1083 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 14:24:10 visual_prompt]: 	Test 500/1152. loss: 3.742, 0.1050 s / batch. (data: 6.22e-05)max mem: 17.22454 GB 
[09/19 14:24:26 visual_prompt]: 	Test 600/1152. loss: 4.100, 0.0958 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 14:24:42 visual_prompt]: 	Test 700/1152. loss: 3.308, 0.1288 s / batch. (data: 3.32e-02)max mem: 17.22454 GB 
[09/19 14:24:58 visual_prompt]: 	Test 800/1152. loss: 3.604, 0.1368 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 14:25:14 visual_prompt]: 	Test 900/1152. loss: 3.903, 0.1189 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 14:25:30 visual_prompt]: 	Test 1000/1152. loss: 3.824, 0.1082 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 14:25:46 visual_prompt]: 	Test 1100/1152. loss: 3.649, 0.0999 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 14:25:58 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1080, average loss: 3.6311
[09/19 14:25:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 29.75	
[09/19 14:25:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/19 14:26:08 visual_prompt]: Epoch 31 / 100: avg data time: 2.17e-01, avg batch time: 0.4417, average train loss: 3.5586
[09/19 14:26:15 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.0895, average loss: 3.4094
[09/19 14:26:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 31.50	
[09/19 14:26:35 visual_prompt]: 	Test 100/1152. loss: 3.842, 0.1029 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 14:26:51 visual_prompt]: 	Test 200/1152. loss: 3.548, 0.1163 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 14:27:07 visual_prompt]: 	Test 300/1152. loss: 3.071, 0.0997 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 14:27:23 visual_prompt]: 	Test 400/1152. loss: 3.272, 0.1039 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 14:27:39 visual_prompt]: 	Test 500/1152. loss: 3.412, 0.0977 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 14:27:55 visual_prompt]: 	Test 600/1152. loss: 3.295, 0.0999 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 14:28:12 visual_prompt]: 	Test 700/1152. loss: 2.880, 0.0995 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 14:28:28 visual_prompt]: 	Test 800/1152. loss: 3.458, 0.0965 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 14:28:44 visual_prompt]: 	Test 900/1152. loss: 3.564, 0.1053 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 14:29:00 visual_prompt]: 	Test 1000/1152. loss: 3.429, 0.1199 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 14:29:16 visual_prompt]: 	Test 1100/1152. loss: 3.532, 0.1161 s / batch. (data: 5.28e-03)max mem: 17.22454 GB 
[09/19 14:29:28 visual_prompt]: Inference (test):avg data time: 1.78e-03, avg batch time: 0.1089, average loss: 3.2977
[09/19 14:29:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 34.84	
[09/19 14:29:28 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/19 14:29:38 visual_prompt]: Epoch 32 / 100: avg data time: 2.10e-01, avg batch time: 0.4365, average train loss: 3.2200
[09/19 14:29:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.0871, average loss: 3.2886
[09/19 14:29:44 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 25.50	
[09/19 14:30:04 visual_prompt]: 	Test 100/1152. loss: 3.286, 0.0999 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 14:30:20 visual_prompt]: 	Test 200/1152. loss: 3.370, 0.1338 s / batch. (data: 2.11e-02)max mem: 17.22454 GB 
[09/19 14:30:36 visual_prompt]: 	Test 300/1152. loss: 3.357, 0.1117 s / batch. (data: 7.18e-03)max mem: 17.22454 GB 
[09/19 14:30:53 visual_prompt]: 	Test 400/1152. loss: 3.227, 0.1350 s / batch. (data: 2.27e-02)max mem: 17.22454 GB 
[09/19 14:31:09 visual_prompt]: 	Test 500/1152. loss: 3.291, 0.1130 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/19 14:31:25 visual_prompt]: 	Test 600/1152. loss: 3.186, 0.1117 s / batch. (data: 7.13e-03)max mem: 17.22454 GB 
[09/19 14:31:41 visual_prompt]: 	Test 700/1152. loss: 3.196, 0.1054 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 14:31:57 visual_prompt]: 	Test 800/1152. loss: 3.367, 0.0980 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 14:32:13 visual_prompt]: 	Test 900/1152. loss: 3.198, 0.1319 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 14:32:30 visual_prompt]: 	Test 1000/1152. loss: 3.356, 0.1285 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 14:32:46 visual_prompt]: 	Test 1100/1152. loss: 3.077, 0.1167 s / batch. (data: 3.65e-05)max mem: 17.22454 GB 
[09/19 14:32:58 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1083, average loss: 3.2521
[09/19 14:32:59 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 27.42	
[09/19 14:32:59 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/19 14:33:09 visual_prompt]: Epoch 33 / 100: avg data time: 2.19e-01, avg batch time: 0.4475, average train loss: 3.1747
[09/19 14:33:15 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.0950, average loss: 3.3601
[09/19 14:33:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 34.50	
[09/19 14:33:35 visual_prompt]: 	Test 100/1152. loss: 3.702, 0.1040 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 14:33:51 visual_prompt]: 	Test 200/1152. loss: 3.672, 0.1060 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 14:34:07 visual_prompt]: 	Test 300/1152. loss: 3.473, 0.1057 s / batch. (data: 9.75e-05)max mem: 17.22454 GB 
[09/19 14:34:24 visual_prompt]: 	Test 400/1152. loss: 3.342, 0.1159 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 14:34:40 visual_prompt]: 	Test 500/1152. loss: 3.514, 0.1201 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 14:34:56 visual_prompt]: 	Test 600/1152. loss: 3.491, 0.0998 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 14:35:12 visual_prompt]: 	Test 700/1152. loss: 2.841, 0.0998 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 14:35:29 visual_prompt]: 	Test 800/1152. loss: 3.453, 0.1071 s / batch. (data: 4.96e-05)max mem: 17.22454 GB 
[09/19 14:35:45 visual_prompt]: 	Test 900/1152. loss: 3.468, 0.0947 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 14:36:02 visual_prompt]: 	Test 1000/1152. loss: 3.455, 0.1072 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 14:36:18 visual_prompt]: 	Test 1100/1152. loss: 3.539, 0.1017 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/19 14:36:30 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1088, average loss: 3.4129
[09/19 14:36:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.90	top5: 32.14	
[09/19 14:36:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/19 14:36:40 visual_prompt]: Epoch 34 / 100: avg data time: 2.12e-01, avg batch time: 0.4464, average train loss: 3.3493
[09/19 14:36:47 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.0964, average loss: 3.2249
[09/19 14:36:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 30.50	
[09/19 14:37:06 visual_prompt]: 	Test 100/1152. loss: 3.454, 0.0966 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 14:37:23 visual_prompt]: 	Test 200/1152. loss: 3.128, 0.0963 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 14:37:39 visual_prompt]: 	Test 300/1152. loss: 3.020, 0.0959 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 14:37:55 visual_prompt]: 	Test 400/1152. loss: 3.149, 0.1458 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 14:38:11 visual_prompt]: 	Test 500/1152. loss: 3.317, 0.0973 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 14:38:28 visual_prompt]: 	Test 600/1152. loss: 3.202, 0.1166 s / batch. (data: 1.82e-04)max mem: 17.22454 GB 
[09/19 14:38:44 visual_prompt]: 	Test 700/1152. loss: 2.999, 0.1198 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 14:38:59 visual_prompt]: 	Test 800/1152. loss: 3.128, 0.1079 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 14:39:16 visual_prompt]: 	Test 900/1152. loss: 3.341, 0.1041 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/19 14:39:33 visual_prompt]: 	Test 1000/1152. loss: 3.304, 0.0984 s / batch. (data: 6.89e-05)max mem: 17.22454 GB 
[09/19 14:39:49 visual_prompt]: 	Test 1100/1152. loss: 3.231, 0.0945 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 14:40:01 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1089, average loss: 3.1637
[09/19 14:40:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.03	top5: 32.69	
[09/19 14:40:01 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/19 14:40:11 visual_prompt]: Epoch 35 / 100: avg data time: 2.18e-01, avg batch time: 0.4452, average train loss: 3.2100
[09/19 14:40:18 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0950, average loss: 2.9828
[09/19 14:40:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 39.00	
[09/19 14:40:37 visual_prompt]: 	Test 100/1152. loss: 3.279, 0.1025 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 14:40:54 visual_prompt]: 	Test 200/1152. loss: 2.951, 0.1114 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 14:41:10 visual_prompt]: 	Test 300/1152. loss: 3.059, 0.1002 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 14:41:26 visual_prompt]: 	Test 400/1152. loss: 3.117, 0.1354 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 14:41:43 visual_prompt]: 	Test 500/1152. loss: 3.066, 0.1170 s / batch. (data: 2.05e-02)max mem: 17.22454 GB 
[09/19 14:41:59 visual_prompt]: 	Test 600/1152. loss: 2.972, 0.1029 s / batch. (data: 7.13e-03)max mem: 17.22454 GB 
[09/19 14:42:15 visual_prompt]: 	Test 700/1152. loss: 3.066, 0.1008 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 14:42:31 visual_prompt]: 	Test 800/1152. loss: 3.140, 0.1077 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 14:42:47 visual_prompt]: 	Test 900/1152. loss: 3.179, 0.0970 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 14:43:03 visual_prompt]: 	Test 1000/1152. loss: 3.252, 0.1039 s / batch. (data: 7.31e-03)max mem: 17.22454 GB 
[09/19 14:43:19 visual_prompt]: 	Test 1100/1152. loss: 3.185, 0.1118 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 14:43:31 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1095, average loss: 3.0548
[09/19 14:43:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.02	
[09/19 14:43:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/19 14:43:41 visual_prompt]: Epoch 36 / 100: avg data time: 2.17e-01, avg batch time: 0.4450, average train loss: 3.1817
[09/19 14:43:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.0889, average loss: 3.2355
[09/19 14:43:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 30.50	
[09/19 14:44:08 visual_prompt]: 	Test 100/1152. loss: 3.147, 0.1374 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 14:44:24 visual_prompt]: 	Test 200/1152. loss: 3.393, 0.1120 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 14:44:40 visual_prompt]: 	Test 300/1152. loss: 3.070, 0.0949 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 14:44:56 visual_prompt]: 	Test 400/1152. loss: 3.204, 0.1095 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 14:45:12 visual_prompt]: 	Test 500/1152. loss: 3.054, 0.1080 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 14:45:29 visual_prompt]: 	Test 600/1152. loss: 3.154, 0.0994 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 14:45:45 visual_prompt]: 	Test 700/1152. loss: 3.264, 0.1199 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 14:46:01 visual_prompt]: 	Test 800/1152. loss: 3.075, 0.1239 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 14:46:17 visual_prompt]: 	Test 900/1152. loss: 3.376, 0.0999 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 14:46:33 visual_prompt]: 	Test 1000/1152. loss: 3.321, 0.1494 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 14:46:49 visual_prompt]: 	Test 1100/1152. loss: 3.110, 0.1119 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 14:47:02 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1089, average loss: 3.1750
[09/19 14:47:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 34.87	
[09/19 14:47:02 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/19 14:47:12 visual_prompt]: Epoch 37 / 100: avg data time: 2.13e-01, avg batch time: 0.4411, average train loss: 3.0355
[09/19 14:47:18 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.0889, average loss: 2.9971
[09/19 14:47:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.00	top5: 42.00	
[09/19 14:47:38 visual_prompt]: 	Test 100/1152. loss: 3.103, 0.1039 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 14:47:54 visual_prompt]: 	Test 200/1152. loss: 3.274, 0.1302 s / batch. (data: 2.18e-04)max mem: 17.22454 GB 
[09/19 14:48:10 visual_prompt]: 	Test 300/1152. loss: 3.211, 0.0984 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 14:48:26 visual_prompt]: 	Test 400/1152. loss: 3.179, 0.0974 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 14:48:42 visual_prompt]: 	Test 500/1152. loss: 3.124, 0.1234 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 14:48:58 visual_prompt]: 	Test 600/1152. loss: 3.129, 0.1101 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 14:49:14 visual_prompt]: 	Test 700/1152. loss: 3.046, 0.1133 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 14:49:31 visual_prompt]: 	Test 800/1152. loss: 3.126, 0.0945 s / batch. (data: 5.10e-05)max mem: 17.22454 GB 
[09/19 14:49:47 visual_prompt]: 	Test 900/1152. loss: 3.000, 0.1125 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 14:50:03 visual_prompt]: 	Test 1000/1152. loss: 3.130, 0.1156 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 14:50:19 visual_prompt]: 	Test 1100/1152. loss: 3.060, 0.0948 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 14:50:31 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1087, average loss: 3.1183
[09/19 14:50:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.87	top5: 32.45	
[09/19 14:50:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/19 14:50:41 visual_prompt]: Epoch 38 / 100: avg data time: 2.14e-01, avg batch time: 0.4437, average train loss: 3.1013
[09/19 14:50:48 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0955, average loss: 3.0627
[09/19 14:50:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 33.50	
[09/19 14:51:07 visual_prompt]: 	Test 100/1152. loss: 3.220, 0.0998 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 14:51:23 visual_prompt]: 	Test 200/1152. loss: 3.066, 0.0977 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 14:51:40 visual_prompt]: 	Test 300/1152. loss: 2.905, 0.1038 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 14:51:56 visual_prompt]: 	Test 400/1152. loss: 3.004, 0.1124 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 14:52:13 visual_prompt]: 	Test 500/1152. loss: 3.059, 0.1364 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 14:52:29 visual_prompt]: 	Test 600/1152. loss: 2.884, 0.1159 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 14:52:45 visual_prompt]: 	Test 700/1152. loss: 2.894, 0.0984 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/19 14:53:01 visual_prompt]: 	Test 800/1152. loss: 3.025, 0.0999 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 14:53:17 visual_prompt]: 	Test 900/1152. loss: 3.180, 0.1216 s / batch. (data: 3.49e-03)max mem: 17.22454 GB 
[09/19 14:53:33 visual_prompt]: 	Test 1000/1152. loss: 3.262, 0.1121 s / batch. (data: 1.96e-04)max mem: 17.22454 GB 
[09/19 14:53:49 visual_prompt]: 	Test 1100/1152. loss: 3.203, 0.1091 s / batch. (data: 1.18e-02)max mem: 17.22454 GB 
[09/19 14:54:01 visual_prompt]: Inference (test):avg data time: 1.72e-03, avg batch time: 0.1086, average loss: 3.0542
[09/19 14:54:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.46	top5: 37.45	
[09/19 14:54:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/19 14:54:11 visual_prompt]: Epoch 39 / 100: avg data time: 2.12e-01, avg batch time: 0.4391, average train loss: 3.0161
[09/19 14:54:18 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.0962, average loss: 2.9995
[09/19 14:54:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 26.00	
[09/19 14:54:37 visual_prompt]: 	Test 100/1152. loss: 3.010, 0.0956 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 14:54:53 visual_prompt]: 	Test 200/1152. loss: 2.880, 0.0952 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 14:55:10 visual_prompt]: 	Test 300/1152. loss: 2.886, 0.1307 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 14:55:26 visual_prompt]: 	Test 400/1152. loss: 2.911, 0.1502 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 14:55:42 visual_prompt]: 	Test 500/1152. loss: 2.991, 0.0980 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 14:55:58 visual_prompt]: 	Test 600/1152. loss: 2.849, 0.1005 s / batch. (data: 5.46e-05)max mem: 17.22454 GB 
[09/19 14:56:14 visual_prompt]: 	Test 700/1152. loss: 2.857, 0.1033 s / batch. (data: 7.19e-03)max mem: 17.22454 GB 
[09/19 14:56:30 visual_prompt]: 	Test 800/1152. loss: 2.891, 0.1081 s / batch. (data: 7.60e-03)max mem: 17.22454 GB 
[09/19 14:56:46 visual_prompt]: 	Test 900/1152. loss: 2.904, 0.1158 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 14:57:02 visual_prompt]: 	Test 1000/1152. loss: 2.843, 0.1372 s / batch. (data: 9.54e-05)max mem: 17.22454 GB 
[09/19 14:57:18 visual_prompt]: 	Test 1100/1152. loss: 2.956, 0.1200 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 14:57:30 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1090, average loss: 2.9376
[09/19 14:57:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.02	top5: 29.78	
[09/19 14:57:31 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/19 14:57:40 visual_prompt]: Epoch 40 / 100: avg data time: 2.14e-01, avg batch time: 0.4389, average train loss: 3.1409
[09/19 14:57:47 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0912, average loss: 3.0232
[09/19 14:57:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 33.50	
[09/19 14:58:06 visual_prompt]: 	Test 100/1152. loss: 3.173, 0.1136 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 14:58:23 visual_prompt]: 	Test 200/1152. loss: 3.294, 0.1131 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 14:58:39 visual_prompt]: 	Test 300/1152. loss: 2.896, 0.1028 s / batch. (data: 5.94e-05)max mem: 17.22454 GB 
[09/19 14:58:56 visual_prompt]: 	Test 400/1152. loss: 3.079, 0.1238 s / batch. (data: 1.59e-02)max mem: 17.22454 GB 
[09/19 14:59:12 visual_prompt]: 	Test 500/1152. loss: 3.050, 0.1000 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 14:59:28 visual_prompt]: 	Test 600/1152. loss: 3.200, 0.0963 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 14:59:45 visual_prompt]: 	Test 700/1152. loss: 2.920, 0.1828 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 15:00:01 visual_prompt]: 	Test 800/1152. loss: 2.993, 0.1118 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 15:00:17 visual_prompt]: 	Test 900/1152. loss: 3.347, 0.1038 s / batch. (data: 7.28e-03)max mem: 17.22454 GB 
[09/19 15:00:33 visual_prompt]: 	Test 1000/1152. loss: 3.329, 0.1006 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 15:00:49 visual_prompt]: 	Test 1100/1152. loss: 3.104, 0.1065 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 15:01:01 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1085, average loss: 3.0628
[09/19 15:01:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.91	
[09/19 15:01:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/19 15:01:11 visual_prompt]: Epoch 41 / 100: avg data time: 2.17e-01, avg batch time: 0.4402, average train loss: 3.2147
[09/19 15:01:18 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.0863, average loss: 3.2936
[09/19 15:01:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 26.00	
[09/19 15:01:37 visual_prompt]: 	Test 100/1152. loss: 3.034, 0.1152 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 15:01:53 visual_prompt]: 	Test 200/1152. loss: 3.393, 0.1118 s / batch. (data: 4.24e-05)max mem: 17.22454 GB 
[09/19 15:02:10 visual_prompt]: 	Test 300/1152. loss: 3.345, 0.0986 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 15:02:26 visual_prompt]: 	Test 400/1152. loss: 3.303, 0.1159 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 15:02:42 visual_prompt]: 	Test 500/1152. loss: 3.110, 0.1008 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 15:02:58 visual_prompt]: 	Test 600/1152. loss: 3.055, 0.1117 s / batch. (data: 5.67e-05)max mem: 17.22454 GB 
[09/19 15:03:14 visual_prompt]: 	Test 700/1152. loss: 3.214, 0.1184 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 15:03:31 visual_prompt]: 	Test 800/1152. loss: 3.136, 0.1079 s / batch. (data: 6.53e-05)max mem: 17.22454 GB 
[09/19 15:03:47 visual_prompt]: 	Test 900/1152. loss: 3.090, 0.1150 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 15:04:03 visual_prompt]: 	Test 1000/1152. loss: 3.188, 0.1198 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 15:04:19 visual_prompt]: 	Test 1100/1152. loss: 3.077, 0.0938 s / batch. (data: 6.53e-05)max mem: 17.22454 GB 
[09/19 15:04:31 visual_prompt]: Inference (test):avg data time: 1.73e-03, avg batch time: 0.1087, average loss: 3.2536
[09/19 15:04:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 29.75	
[09/19 15:04:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/19 15:04:41 visual_prompt]: Epoch 42 / 100: avg data time: 2.13e-01, avg batch time: 0.4370, average train loss: 3.1199
[09/19 15:04:48 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.0955, average loss: 3.1365
[09/19 15:04:48 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 36.00	
[09/19 15:05:07 visual_prompt]: 	Test 100/1152. loss: 3.430, 0.1149 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/19 15:05:23 visual_prompt]: 	Test 200/1152. loss: 3.230, 0.0966 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 15:05:40 visual_prompt]: 	Test 300/1152. loss: 3.184, 0.1066 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 15:05:56 visual_prompt]: 	Test 400/1152. loss: 3.138, 0.0990 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 15:06:12 visual_prompt]: 	Test 500/1152. loss: 3.312, 0.0998 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 15:06:28 visual_prompt]: 	Test 600/1152. loss: 3.454, 0.1122 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 15:06:44 visual_prompt]: 	Test 700/1152. loss: 3.034, 0.1153 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 15:07:00 visual_prompt]: 	Test 800/1152. loss: 3.316, 0.0998 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 15:07:16 visual_prompt]: 	Test 900/1152. loss: 3.345, 0.1181 s / batch. (data: 6.95e-03)max mem: 17.22454 GB 
[09/19 15:07:32 visual_prompt]: 	Test 1000/1152. loss: 3.122, 0.0990 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 15:07:48 visual_prompt]: 	Test 1100/1152. loss: 3.396, 0.0966 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 15:08:01 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1081, average loss: 3.1833
[09/19 15:08:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 32.47	
[09/19 15:08:01 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/19 15:08:11 visual_prompt]: Epoch 43 / 100: avg data time: 2.16e-01, avg batch time: 0.4395, average train loss: 3.2475
[09/19 15:08:17 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.0951, average loss: 3.4635
[09/19 15:08:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 30.50	
[09/19 15:08:37 visual_prompt]: 	Test 100/1152. loss: 3.604, 0.0986 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 15:08:54 visual_prompt]: 	Test 200/1152. loss: 3.358, 0.1017 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 15:09:10 visual_prompt]: 	Test 300/1152. loss: 3.355, 0.1080 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 15:09:26 visual_prompt]: 	Test 400/1152. loss: 3.357, 0.1330 s / batch. (data: 8.27e-03)max mem: 17.22454 GB 
[09/19 15:09:42 visual_prompt]: 	Test 500/1152. loss: 3.517, 0.0970 s / batch. (data: 1.43e-05)max mem: 17.22454 GB 
[09/19 15:09:58 visual_prompt]: 	Test 600/1152. loss: 3.703, 0.0957 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 15:10:14 visual_prompt]: 	Test 700/1152. loss: 3.384, 0.0979 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 15:10:30 visual_prompt]: 	Test 800/1152. loss: 3.366, 0.0951 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 15:10:46 visual_prompt]: 	Test 900/1152. loss: 3.679, 0.0954 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 15:11:02 visual_prompt]: 	Test 1000/1152. loss: 3.421, 0.1577 s / batch. (data: 1.31e-02)max mem: 17.22454 GB 
[09/19 15:11:18 visual_prompt]: 	Test 1100/1152. loss: 3.344, 0.1041 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 15:11:31 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1095, average loss: 3.3571
[09/19 15:11:31 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 30.09	
[09/19 15:11:31 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/19 15:11:41 visual_prompt]: Epoch 44 / 100: avg data time: 2.13e-01, avg batch time: 0.4412, average train loss: 3.1267
[09/19 15:11:47 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.0882, average loss: 3.0331
[09/19 15:11:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.00	top5: 28.50	
[09/19 15:12:07 visual_prompt]: 	Test 100/1152. loss: 2.896, 0.0971 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 15:12:23 visual_prompt]: 	Test 200/1152. loss: 2.973, 0.1423 s / batch. (data: 2.22e-02)max mem: 17.22454 GB 
[09/19 15:12:40 visual_prompt]: 	Test 300/1152. loss: 2.987, 0.0984 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 15:12:56 visual_prompt]: 	Test 400/1152. loss: 2.947, 0.1046 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 15:13:12 visual_prompt]: 	Test 500/1152. loss: 3.100, 0.1117 s / batch. (data: 7.14e-03)max mem: 17.22454 GB 
[09/19 15:13:28 visual_prompt]: 	Test 600/1152. loss: 3.085, 0.1113 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/19 15:13:44 visual_prompt]: 	Test 700/1152. loss: 3.069, 0.1366 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 15:14:00 visual_prompt]: 	Test 800/1152. loss: 2.953, 0.1032 s / batch. (data: 7.26e-03)max mem: 17.22454 GB 
[09/19 15:14:16 visual_prompt]: 	Test 900/1152. loss: 2.924, 0.1038 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 15:14:32 visual_prompt]: 	Test 1000/1152. loss: 2.911, 0.1219 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 15:14:48 visual_prompt]: 	Test 1100/1152. loss: 2.990, 0.0998 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 15:15:00 visual_prompt]: Inference (test):avg data time: 2.03e-03, avg batch time: 0.1086, average loss: 3.0225
[09/19 15:15:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 4.95	top5: 30.03	
[09/19 15:15:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/19 15:15:11 visual_prompt]: Epoch 45 / 100: avg data time: 2.10e-01, avg batch time: 0.4354, average train loss: 2.9632
[09/19 15:15:17 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.0913, average loss: 2.9615
[09/19 15:15:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.50	top5: 37.50	
[09/19 15:15:37 visual_prompt]: 	Test 100/1152. loss: 3.134, 0.1159 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 15:15:53 visual_prompt]: 	Test 200/1152. loss: 3.277, 0.0997 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 15:16:09 visual_prompt]: 	Test 300/1152. loss: 3.003, 0.1228 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 15:16:26 visual_prompt]: 	Test 400/1152. loss: 3.046, 0.1154 s / batch. (data: 1.92e-02)max mem: 17.22454 GB 
[09/19 15:16:42 visual_prompt]: 	Test 500/1152. loss: 2.977, 0.1155 s / batch. (data: 7.04e-03)max mem: 17.22454 GB 
[09/19 15:16:58 visual_prompt]: 	Test 600/1152. loss: 3.091, 0.0974 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 15:17:14 visual_prompt]: 	Test 700/1152. loss: 2.875, 0.1303 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 15:17:30 visual_prompt]: 	Test 800/1152. loss: 3.077, 0.1074 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 15:17:46 visual_prompt]: 	Test 900/1152. loss: 3.048, 0.0959 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 15:18:02 visual_prompt]: 	Test 1000/1152. loss: 3.042, 0.1002 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 15:18:18 visual_prompt]: 	Test 1100/1152. loss: 3.112, 0.1039 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 15:18:30 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1095, average loss: 3.0166
[09/19 15:18:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 35.03	
[09/19 15:18:30 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/19 15:18:40 visual_prompt]: Epoch 46 / 100: avg data time: 2.12e-01, avg batch time: 0.4367, average train loss: 2.9737
[09/19 15:18:47 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.0883, average loss: 2.9788
[09/19 15:18:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.00	top5: 39.00	
[09/19 15:19:06 visual_prompt]: 	Test 100/1152. loss: 3.162, 0.1172 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/19 15:19:22 visual_prompt]: 	Test 200/1152. loss: 3.010, 0.1025 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 15:19:39 visual_prompt]: 	Test 300/1152. loss: 3.072, 0.0994 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 15:19:55 visual_prompt]: 	Test 400/1152. loss: 3.096, 0.1038 s / batch. (data: 7.32e-03)max mem: 17.22454 GB 
[09/19 15:20:11 visual_prompt]: 	Test 500/1152. loss: 3.110, 0.1394 s / batch. (data: 2.69e-02)max mem: 17.22454 GB 
[09/19 15:20:27 visual_prompt]: 	Test 600/1152. loss: 3.172, 0.1270 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 15:20:43 visual_prompt]: 	Test 700/1152. loss: 3.209, 0.0968 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 15:20:59 visual_prompt]: 	Test 800/1152. loss: 3.154, 0.0999 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 15:21:15 visual_prompt]: 	Test 900/1152. loss: 3.114, 0.0984 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 15:21:31 visual_prompt]: 	Test 1000/1152. loss: 3.005, 0.1157 s / batch. (data: 7.17e-03)max mem: 17.22454 GB 
[09/19 15:21:47 visual_prompt]: 	Test 1100/1152. loss: 3.201, 0.1159 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 15:21:59 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1090, average loss: 3.0641
[09/19 15:22:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.59	top5: 35.34	
[09/19 15:22:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/19 15:22:10 visual_prompt]: Epoch 47 / 100: avg data time: 2.27e-01, avg batch time: 0.4463, average train loss: 3.0152
[09/19 15:22:16 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0957, average loss: 2.9732
[09/19 15:22:16 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 2.50	top5: 26.50	
[09/19 15:22:36 visual_prompt]: 	Test 100/1152. loss: 2.933, 0.1051 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 15:22:52 visual_prompt]: 	Test 200/1152. loss: 2.882, 0.1239 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 15:23:08 visual_prompt]: 	Test 300/1152. loss: 2.908, 0.1045 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 15:23:24 visual_prompt]: 	Test 400/1152. loss: 2.891, 0.0950 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 15:23:40 visual_prompt]: 	Test 500/1152. loss: 2.792, 0.1163 s / batch. (data: 5.65e-05)max mem: 17.22454 GB 
[09/19 15:23:56 visual_prompt]: 	Test 600/1152. loss: 2.783, 0.0948 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 15:24:12 visual_prompt]: 	Test 700/1152. loss: 2.916, 0.1142 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 15:24:28 visual_prompt]: 	Test 800/1152. loss: 2.868, 0.0994 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 15:24:44 visual_prompt]: 	Test 900/1152. loss: 2.927, 0.1152 s / batch. (data: 5.48e-05)max mem: 17.22454 GB 
[09/19 15:25:00 visual_prompt]: 	Test 1000/1152. loss: 2.880, 0.1038 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 15:25:16 visual_prompt]: 	Test 1100/1152. loss: 2.981, 0.0958 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/19 15:25:28 visual_prompt]: Inference (test):avg data time: 1.96e-03, avg batch time: 0.1094, average loss: 2.9058
[09/19 15:25:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.13	top5: 32.52	
[09/19 15:25:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/19 15:25:38 visual_prompt]: Epoch 48 / 100: avg data time: 2.10e-01, avg batch time: 0.4372, average train loss: 2.9074
[09/19 15:25:45 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.0908, average loss: 2.9715
[09/19 15:25:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 38.50	
[09/19 15:26:05 visual_prompt]: 	Test 100/1152. loss: 3.311, 0.1079 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 15:26:21 visual_prompt]: 	Test 200/1152. loss: 3.017, 0.1147 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 15:26:37 visual_prompt]: 	Test 300/1152. loss: 2.944, 0.0978 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 15:26:53 visual_prompt]: 	Test 400/1152. loss: 2.982, 0.1039 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 15:27:09 visual_prompt]: 	Test 500/1152. loss: 3.111, 0.1079 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 15:27:25 visual_prompt]: 	Test 600/1152. loss: 3.012, 0.1189 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 15:27:42 visual_prompt]: 	Test 700/1152. loss: 2.680, 0.1340 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 15:27:58 visual_prompt]: 	Test 800/1152. loss: 3.156, 0.0966 s / batch. (data: 3.31e-05)max mem: 17.22454 GB 
[09/19 15:28:14 visual_prompt]: 	Test 900/1152. loss: 3.129, 0.1095 s / batch. (data: 3.15e-05)max mem: 17.22454 GB 
[09/19 15:28:30 visual_prompt]: 	Test 1000/1152. loss: 3.167, 0.0999 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 15:28:46 visual_prompt]: 	Test 1100/1152. loss: 2.988, 0.1040 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 15:28:58 visual_prompt]: Inference (test):avg data time: 2.29e-03, avg batch time: 0.1094, average loss: 2.9811
[09/19 15:28:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.45	top5: 34.82	
[09/19 15:28:58 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/19 15:29:08 visual_prompt]: Epoch 49 / 100: avg data time: 2.18e-01, avg batch time: 0.4438, average train loss: 3.0880
[09/19 15:29:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0911, average loss: 3.0429
[09/19 15:29:15 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.50	top5: 32.00	
[09/19 15:29:34 visual_prompt]: 	Test 100/1152. loss: 3.217, 0.1128 s / batch. (data: 6.86e-03)max mem: 17.22454 GB 
[09/19 15:29:51 visual_prompt]: 	Test 200/1152. loss: 3.035, 0.1150 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/19 15:30:07 visual_prompt]: 	Test 300/1152. loss: 3.212, 0.1161 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 15:30:23 visual_prompt]: 	Test 400/1152. loss: 3.193, 0.0988 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 15:30:39 visual_prompt]: 	Test 500/1152. loss: 3.206, 0.0945 s / batch. (data: 7.13e-05)max mem: 17.22454 GB 
[09/19 15:30:55 visual_prompt]: 	Test 600/1152. loss: 3.262, 0.0982 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 15:31:11 visual_prompt]: 	Test 700/1152. loss: 3.154, 0.1174 s / batch. (data: 5.63e-05)max mem: 17.22454 GB 
[09/19 15:31:27 visual_prompt]: 	Test 800/1152. loss: 3.245, 0.1026 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 15:31:43 visual_prompt]: 	Test 900/1152. loss: 3.138, 0.1182 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/19 15:32:00 visual_prompt]: 	Test 1000/1152. loss: 3.061, 0.1353 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 15:32:16 visual_prompt]: 	Test 1100/1152. loss: 2.986, 0.1054 s / batch. (data: 1.74e-04)max mem: 17.22454 GB 
[09/19 15:32:28 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1092, average loss: 3.0929
[09/19 15:32:28 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.52	top5: 30.29	
[09/19 15:32:28 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/19 15:32:38 visual_prompt]: Epoch 50 / 100: avg data time: 2.27e-01, avg batch time: 0.4459, average train loss: 2.9537
[09/19 15:32:45 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.0913, average loss: 3.0187
[09/19 15:32:45 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.00	top5: 23.50	
[09/19 15:33:04 visual_prompt]: 	Test 100/1152. loss: 3.045, 0.0965 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 15:33:20 visual_prompt]: 	Test 200/1152. loss: 2.843, 0.1038 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 15:33:36 visual_prompt]: 	Test 300/1152. loss: 3.026, 0.1333 s / batch. (data: 8.56e-03)max mem: 17.22454 GB 
[09/19 15:33:53 visual_prompt]: 	Test 400/1152. loss: 2.992, 0.1038 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 15:34:09 visual_prompt]: 	Test 500/1152. loss: 2.979, 0.0970 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 15:34:25 visual_prompt]: 	Test 600/1152. loss: 2.878, 0.0964 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 15:34:41 visual_prompt]: 	Test 700/1152. loss: 2.961, 0.1212 s / batch. (data: 7.12e-03)max mem: 17.22454 GB 
[09/19 15:34:57 visual_prompt]: 	Test 800/1152. loss: 2.939, 0.0983 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 15:35:14 visual_prompt]: 	Test 900/1152. loss: 3.046, 0.0989 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 15:35:30 visual_prompt]: 	Test 1000/1152. loss: 3.023, 0.1368 s / batch. (data: 2.02e-02)max mem: 17.22454 GB 
[09/19 15:35:45 visual_prompt]: 	Test 1100/1152. loss: 2.884, 0.0962 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 15:35:58 visual_prompt]: Inference (test):avg data time: 2.17e-03, avg batch time: 0.1092, average loss: 2.9663
[09/19 15:35:58 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.57	top5: 27.49	
[09/19 15:35:58 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/19 15:36:08 visual_prompt]: Epoch 51 / 100: avg data time: 2.12e-01, avg batch time: 0.4407, average train loss: 2.9605
[09/19 15:36:14 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.0905, average loss: 2.9979
[09/19 15:36:14 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.00	top5: 38.50	
[09/19 15:36:34 visual_prompt]: 	Test 100/1152. loss: 3.028, 0.0982 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 15:36:50 visual_prompt]: 	Test 200/1152. loss: 3.095, 0.0978 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 15:37:07 visual_prompt]: 	Test 300/1152. loss: 3.295, 0.0992 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 15:37:23 visual_prompt]: 	Test 400/1152. loss: 3.127, 0.1358 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/19 15:37:39 visual_prompt]: 	Test 500/1152. loss: 3.076, 0.1079 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 15:37:55 visual_prompt]: 	Test 600/1152. loss: 3.243, 0.1078 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 15:38:11 visual_prompt]: 	Test 700/1152. loss: 3.141, 0.1199 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 15:38:28 visual_prompt]: 	Test 800/1152. loss: 3.160, 0.1306 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 15:38:44 visual_prompt]: 	Test 900/1152. loss: 2.947, 0.0988 s / batch. (data: 6.94e-05)max mem: 17.22454 GB 
[09/19 15:39:00 visual_prompt]: 	Test 1000/1152. loss: 2.905, 0.0966 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 15:39:17 visual_prompt]: 	Test 1100/1152. loss: 3.139, 0.0996 s / batch. (data: 9.30e-05)max mem: 17.22454 GB 
[09/19 15:39:29 visual_prompt]: Inference (test):avg data time: 1.91e-03, avg batch time: 0.1094, average loss: 3.0941
[09/19 15:39:29 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.44	top5: 34.65	
[09/19 15:39:29 visual_prompt]: Best epoch 51: best metric: 0.140
[09/19 15:39:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/19 15:39:39 visual_prompt]: Epoch 52 / 100: avg data time: 2.19e-01, avg batch time: 0.4412, average train loss: 2.9756
[09/19 15:39:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.0863, average loss: 2.8124
[09/19 15:39:46 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.00	top5: 42.50	
[09/19 15:40:05 visual_prompt]: 	Test 100/1152. loss: 2.921, 0.1322 s / batch. (data: 9.59e-03)max mem: 17.22454 GB 
[09/19 15:40:22 visual_prompt]: 	Test 200/1152. loss: 3.009, 0.1121 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 15:40:38 visual_prompt]: 	Test 300/1152. loss: 2.887, 0.1182 s / batch. (data: 2.19e-02)max mem: 17.22454 GB 
[09/19 15:40:54 visual_prompt]: 	Test 400/1152. loss: 2.947, 0.1437 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 15:41:10 visual_prompt]: 	Test 500/1152. loss: 2.864, 0.0963 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 15:41:27 visual_prompt]: 	Test 600/1152. loss: 2.915, 0.1046 s / batch. (data: 7.25e-03)max mem: 17.22454 GB 
[09/19 15:41:43 visual_prompt]: 	Test 700/1152. loss: 2.834, 0.0974 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 15:41:59 visual_prompt]: 	Test 800/1152. loss: 2.769, 0.1081 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 15:42:15 visual_prompt]: 	Test 900/1152. loss: 2.886, 0.1113 s / batch. (data: 1.09e-02)max mem: 17.22454 GB 
[09/19 15:42:32 visual_prompt]: 	Test 1000/1152. loss: 2.877, 0.1106 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 15:42:48 visual_prompt]: 	Test 1100/1152. loss: 2.881, 0.1131 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 15:43:00 visual_prompt]: Inference (test):avg data time: 1.76e-03, avg batch time: 0.1085, average loss: 2.8763
[09/19 15:43:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.64	top5: 36.20	
[09/19 15:43:00 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/19 15:43:10 visual_prompt]: Epoch 53 / 100: avg data time: 2.21e-01, avg batch time: 0.4400, average train loss: 2.9130
[09/19 15:43:17 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.0898, average loss: 2.8124
[09/19 15:43:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.50	top5: 43.50	
[09/19 15:43:36 visual_prompt]: 	Test 100/1152. loss: 2.939, 0.1018 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 15:43:52 visual_prompt]: 	Test 200/1152. loss: 2.892, 0.0996 s / batch. (data: 1.29e-05)max mem: 17.22454 GB 
[09/19 15:44:09 visual_prompt]: 	Test 300/1152. loss: 2.875, 0.1233 s / batch. (data: 1.58e-04)max mem: 17.22454 GB 
[09/19 15:44:25 visual_prompt]: 	Test 400/1152. loss: 2.920, 0.1039 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 15:44:41 visual_prompt]: 	Test 500/1152. loss: 3.008, 0.1238 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 15:44:58 visual_prompt]: 	Test 600/1152. loss: 2.869, 0.1036 s / batch. (data: 4.22e-05)max mem: 17.22454 GB 
[09/19 15:45:14 visual_prompt]: 	Test 700/1152. loss: 2.847, 0.1106 s / batch. (data: 3.55e-05)max mem: 17.22454 GB 
[09/19 15:45:30 visual_prompt]: 	Test 800/1152. loss: 2.972, 0.0964 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 15:45:46 visual_prompt]: 	Test 900/1152. loss: 2.812, 0.0985 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 15:46:01 visual_prompt]: 	Test 1000/1152. loss: 2.941, 0.1317 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 15:46:18 visual_prompt]: 	Test 1100/1152. loss: 2.976, 0.1281 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 15:46:30 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1090, average loss: 2.9366
[09/19 15:46:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 7.60	top5: 37.23	
[09/19 15:46:30 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/19 15:46:40 visual_prompt]: Epoch 54 / 100: avg data time: 2.25e-01, avg batch time: 0.4487, average train loss: 2.9123
[09/19 15:46:47 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.0958, average loss: 2.8381
[09/19 15:46:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 36.50	
[09/19 15:47:06 visual_prompt]: 	Test 100/1152. loss: 2.845, 0.1079 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 15:47:23 visual_prompt]: 	Test 200/1152. loss: 2.975, 0.1025 s / batch. (data: 5.34e-05)max mem: 17.22454 GB 
[09/19 15:47:39 visual_prompt]: 	Test 300/1152. loss: 2.872, 0.1181 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 15:47:55 visual_prompt]: 	Test 400/1152. loss: 2.907, 0.1192 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 15:48:11 visual_prompt]: 	Test 500/1152. loss: 2.842, 0.1248 s / batch. (data: 8.66e-03)max mem: 17.22454 GB 
[09/19 15:48:28 visual_prompt]: 	Test 600/1152. loss: 2.889, 0.1171 s / batch. (data: 8.53e-03)max mem: 17.22454 GB 
[09/19 15:48:44 visual_prompt]: 	Test 700/1152. loss: 2.819, 0.1142 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 15:48:59 visual_prompt]: 	Test 800/1152. loss: 2.746, 0.1024 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 15:49:16 visual_prompt]: 	Test 900/1152. loss: 2.808, 0.1155 s / batch. (data: 1.71e-04)max mem: 17.22454 GB 
[09/19 15:49:32 visual_prompt]: 	Test 1000/1152. loss: 2.740, 0.0977 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 15:49:48 visual_prompt]: 	Test 1100/1152. loss: 2.813, 0.1119 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 15:50:00 visual_prompt]: Inference (test):avg data time: 1.75e-03, avg batch time: 0.1082, average loss: 2.8665
[09/19 15:50:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.84	top5: 35.11	
[09/19 15:50:00 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/19 15:50:10 visual_prompt]: Epoch 55 / 100: avg data time: 2.13e-01, avg batch time: 0.4397, average train loss: 2.9094
[09/19 15:50:17 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.0888, average loss: 2.9072
[09/19 15:50:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.00	top5: 39.00	
[09/19 15:50:36 visual_prompt]: 	Test 100/1152. loss: 2.888, 0.0994 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 15:50:52 visual_prompt]: 	Test 200/1152. loss: 3.110, 0.1005 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 15:51:09 visual_prompt]: 	Test 300/1152. loss: 2.943, 0.1066 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 15:51:25 visual_prompt]: 	Test 400/1152. loss: 2.968, 0.1567 s / batch. (data: 3.97e-02)max mem: 17.22454 GB 
[09/19 15:51:41 visual_prompt]: 	Test 500/1152. loss: 2.841, 0.1453 s / batch. (data: 3.44e-03)max mem: 17.22454 GB 
[09/19 15:51:57 visual_prompt]: 	Test 600/1152. loss: 3.060, 0.1390 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 15:52:13 visual_prompt]: 	Test 700/1152. loss: 2.986, 0.0998 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 15:52:29 visual_prompt]: 	Test 800/1152. loss: 2.772, 0.1453 s / batch. (data: 2.30e-02)max mem: 17.22454 GB 
[09/19 15:52:45 visual_prompt]: 	Test 900/1152. loss: 3.086, 0.1071 s / batch. (data: 3.65e-05)max mem: 17.22454 GB 
[09/19 15:53:02 visual_prompt]: 	Test 1000/1152. loss: 2.950, 0.1141 s / batch. (data: 1.48e-02)max mem: 17.22454 GB 
[09/19 15:53:18 visual_prompt]: 	Test 1100/1152. loss: 2.854, 0.1158 s / batch. (data: 7.27e-03)max mem: 17.22454 GB 
[09/19 15:53:30 visual_prompt]: Inference (test):avg data time: 2.27e-03, avg batch time: 0.1096, average loss: 2.9414
[09/19 15:53:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.27	top5: 39.45	
[09/19 15:53:30 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/19 15:53:40 visual_prompt]: Epoch 56 / 100: avg data time: 2.23e-01, avg batch time: 0.4475, average train loss: 2.8209
[09/19 15:53:47 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.0950, average loss: 2.8861
[09/19 15:53:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.50	top5: 34.00	
[09/19 15:54:06 visual_prompt]: 	Test 100/1152. loss: 3.107, 0.1099 s / batch. (data: 9.32e-03)max mem: 17.22454 GB 
[09/19 15:54:23 visual_prompt]: 	Test 200/1152. loss: 2.921, 0.0942 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 15:54:39 visual_prompt]: 	Test 300/1152. loss: 2.722, 0.1011 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 15:54:55 visual_prompt]: 	Test 400/1152. loss: 2.835, 0.1174 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 15:55:11 visual_prompt]: 	Test 500/1152. loss: 2.950, 0.1071 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 15:55:27 visual_prompt]: 	Test 600/1152. loss: 2.960, 0.1247 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 15:55:43 visual_prompt]: 	Test 700/1152. loss: 2.677, 0.0954 s / batch. (data: 5.05e-05)max mem: 17.22454 GB 
[09/19 15:55:59 visual_prompt]: 	Test 800/1152. loss: 2.826, 0.1120 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 15:56:15 visual_prompt]: 	Test 900/1152. loss: 3.064, 0.1108 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 15:56:32 visual_prompt]: 	Test 1000/1152. loss: 2.991, 0.0983 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 15:56:48 visual_prompt]: 	Test 1100/1152. loss: 2.864, 0.1177 s / batch. (data: 5.22e-05)max mem: 17.22454 GB 
[09/19 15:57:00 visual_prompt]: Inference (test):avg data time: 2.18e-03, avg batch time: 0.1091, average loss: 2.8841
[09/19 15:57:00 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 8.15	top5: 37.07	
[09/19 15:57:00 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/19 15:57:10 visual_prompt]: Epoch 57 / 100: avg data time: 2.12e-01, avg batch time: 0.4353, average train loss: 2.9022
[09/19 15:57:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0925, average loss: 2.7443
[09/19 15:57:17 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 6.50	top5: 49.50	
[09/19 15:57:37 visual_prompt]: 	Test 100/1152. loss: 2.930, 0.1042 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 15:57:53 visual_prompt]: 	Test 200/1152. loss: 2.815, 0.1197 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 15:58:09 visual_prompt]: 	Test 300/1152. loss: 2.881, 0.1139 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 15:58:26 visual_prompt]: 	Test 400/1152. loss: 2.787, 0.1176 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 15:58:42 visual_prompt]: 	Test 500/1152. loss: 2.829, 0.1122 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 15:58:57 visual_prompt]: 	Test 600/1152. loss: 3.028, 0.0950 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 15:59:14 visual_prompt]: 	Test 700/1152. loss: 2.916, 0.0999 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 15:59:30 visual_prompt]: 	Test 800/1152. loss: 2.856, 0.1112 s / batch. (data: 1.79e-04)max mem: 17.22454 GB 
[09/19 15:59:46 visual_prompt]: 	Test 900/1152. loss: 2.970, 0.1027 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 16:00:02 visual_prompt]: 	Test 1000/1152. loss: 2.802, 0.1005 s / batch. (data: 3.27e-05)max mem: 17.22454 GB 
[09/19 16:00:18 visual_prompt]: 	Test 1100/1152. loss: 2.884, 0.1599 s / batch. (data: 1.93e-02)max mem: 17.22454 GB 
[09/19 16:00:30 visual_prompt]: Inference (test):avg data time: 2.12e-03, avg batch time: 0.1094, average loss: 2.8291
[09/19 16:00:30 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 9.14	top5: 42.37	
[09/19 16:00:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/19 16:00:40 visual_prompt]: Epoch 58 / 100: avg data time: 2.16e-01, avg batch time: 0.4470, average train loss: 2.7840
[09/19 16:00:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.0861, average loss: 3.0786
[09/19 16:00:47 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.50	top5: 34.00	
[09/19 16:01:06 visual_prompt]: 	Test 100/1152. loss: 3.211, 0.1081 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 16:01:23 visual_prompt]: 	Test 200/1152. loss: 2.999, 0.0976 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 16:01:39 visual_prompt]: 	Test 300/1152. loss: 3.036, 0.1094 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 16:01:56 visual_prompt]: 	Test 400/1152. loss: 2.967, 0.1122 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 16:02:12 visual_prompt]: 	Test 500/1152. loss: 3.066, 0.0984 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 16:02:29 visual_prompt]: 	Test 600/1152. loss: 2.880, 0.1226 s / batch. (data: 7.16e-03)max mem: 17.22454 GB 
[09/19 16:02:44 visual_prompt]: 	Test 700/1152. loss: 2.777, 0.1123 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 16:03:00 visual_prompt]: 	Test 800/1152. loss: 2.892, 0.1334 s / batch. (data: 8.83e-03)max mem: 17.22454 GB 
[09/19 16:03:17 visual_prompt]: 	Test 900/1152. loss: 3.071, 0.1000 s / batch. (data: 1.32e-04)max mem: 17.22454 GB 
[09/19 16:03:33 visual_prompt]: 	Test 1000/1152. loss: 3.104, 0.1278 s / batch. (data: 1.52e-02)max mem: 17.22454 GB 
[09/19 16:03:49 visual_prompt]: 	Test 1100/1152. loss: 3.003, 0.1000 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 16:04:01 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1093, average loss: 3.0387
[09/19 16:04:01 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 5.59	top5: 34.27	
[09/19 16:04:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/19 16:04:11 visual_prompt]: Epoch 59 / 100: avg data time: 2.13e-01, avg batch time: 0.4380, average train loss: 2.7789
[09/19 16:04:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.0927, average loss: 2.6484
[09/19 16:04:18 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.50	top5: 53.00	
[09/19 16:04:37 visual_prompt]: 	Test 100/1152. loss: 2.929, 0.0972 s / batch. (data: 4.32e-05)max mem: 17.22454 GB 
[09/19 16:04:54 visual_prompt]: 	Test 200/1152. loss: 2.721, 0.1159 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 16:05:10 visual_prompt]: 	Test 300/1152. loss: 2.808, 0.1106 s / batch. (data: 1.35e-02)max mem: 17.22454 GB 
[09/19 16:05:26 visual_prompt]: 	Test 400/1152. loss: 2.775, 0.1069 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 16:05:43 visual_prompt]: 	Test 500/1152. loss: 2.753, 0.1031 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 16:05:59 visual_prompt]: 	Test 600/1152. loss: 2.827, 0.1214 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 16:06:15 visual_prompt]: 	Test 700/1152. loss: 2.595, 0.1079 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 16:06:31 visual_prompt]: 	Test 800/1152. loss: 2.683, 0.1140 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 16:06:47 visual_prompt]: 	Test 900/1152. loss: 2.869, 0.0987 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 16:07:04 visual_prompt]: 	Test 1000/1152. loss: 2.800, 0.0977 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 16:07:20 visual_prompt]: 	Test 1100/1152. loss: 2.698, 0.1006 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 16:07:32 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1094, average loss: 2.7635
[09/19 16:07:32 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.21	top5: 45.60	
[09/19 16:07:32 visual_prompt]: Best epoch 59: best metric: 0.155
[09/19 16:07:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/19 16:07:42 visual_prompt]: Epoch 60 / 100: avg data time: 2.21e-01, avg batch time: 0.4498, average train loss: 2.7287
[09/19 16:07:49 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.0913, average loss: 2.6118
[09/19 16:07:49 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.50	top5: 51.00	
[09/19 16:08:08 visual_prompt]: 	Test 100/1152. loss: 2.746, 0.1060 s / batch. (data: 5.56e-05)max mem: 17.22454 GB 
[09/19 16:08:24 visual_prompt]: 	Test 200/1152. loss: 2.581, 0.1034 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 16:08:41 visual_prompt]: 	Test 300/1152. loss: 2.643, 0.0958 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 16:08:57 visual_prompt]: 	Test 400/1152. loss: 2.617, 0.1149 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 16:09:13 visual_prompt]: 	Test 500/1152. loss: 2.697, 0.1132 s / batch. (data: 5.79e-05)max mem: 17.22454 GB 
[09/19 16:09:29 visual_prompt]: 	Test 600/1152. loss: 2.733, 0.1077 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 16:09:45 visual_prompt]: 	Test 700/1152. loss: 2.587, 0.1004 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 16:10:02 visual_prompt]: 	Test 800/1152. loss: 2.630, 0.0998 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 16:10:18 visual_prompt]: 	Test 900/1152. loss: 2.777, 0.1059 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 16:10:33 visual_prompt]: 	Test 1000/1152. loss: 2.694, 0.1005 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 16:10:49 visual_prompt]: 	Test 1100/1152. loss: 2.686, 0.0995 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 16:11:02 visual_prompt]: Inference (test):avg data time: 1.38e-03, avg batch time: 0.1075, average loss: 2.7289
[09/19 16:11:02 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.86	top5: 44.82	
[09/19 16:11:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/19 16:11:12 visual_prompt]: Epoch 61 / 100: avg data time: 2.20e-01, avg batch time: 0.4470, average train loss: 2.7478
[09/19 16:11:19 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.0905, average loss: 2.7905
[09/19 16:11:19 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 11.00	top5: 50.50	
[09/19 16:11:38 visual_prompt]: 	Test 100/1152. loss: 2.866, 0.0962 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 16:11:54 visual_prompt]: 	Test 200/1152. loss: 2.983, 0.0989 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 16:12:11 visual_prompt]: 	Test 300/1152. loss: 2.775, 0.0977 s / batch. (data: 1.00e-04)max mem: 17.22454 GB 
[09/19 16:12:27 visual_prompt]: 	Test 400/1152. loss: 2.754, 0.1223 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 16:12:44 visual_prompt]: 	Test 500/1152. loss: 2.770, 0.1112 s / batch. (data: 7.71e-03)max mem: 17.22454 GB 
[09/19 16:13:00 visual_prompt]: 	Test 600/1152. loss: 2.879, 0.1274 s / batch. (data: 2.79e-03)max mem: 17.22454 GB 
[09/19 16:13:16 visual_prompt]: 	Test 700/1152. loss: 2.653, 0.1109 s / batch. (data: 1.00e-02)max mem: 17.22454 GB 
[09/19 16:13:33 visual_prompt]: 	Test 800/1152. loss: 2.716, 0.1078 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 16:13:49 visual_prompt]: 	Test 900/1152. loss: 2.909, 0.0971 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 16:14:06 visual_prompt]: 	Test 1000/1152. loss: 3.005, 0.1064 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 16:14:22 visual_prompt]: 	Test 1100/1152. loss: 2.899, 0.1075 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 16:14:34 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1090, average loss: 2.8577
[09/19 16:14:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.85	top5: 44.24	
[09/19 16:14:34 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/19 16:14:44 visual_prompt]: Epoch 62 / 100: avg data time: 2.20e-01, avg batch time: 0.4459, average train loss: 2.6657
[09/19 16:14:50 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.0869, average loss: 2.5649
[09/19 16:14:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 14.50	top5: 53.00	
[09/19 16:15:10 visual_prompt]: 	Test 100/1152. loss: 2.795, 0.1145 s / batch. (data: 6.51e-05)max mem: 17.22454 GB 
[09/19 16:15:26 visual_prompt]: 	Test 200/1152. loss: 2.658, 0.1064 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 16:15:43 visual_prompt]: 	Test 300/1152. loss: 2.613, 0.1366 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 16:15:59 visual_prompt]: 	Test 400/1152. loss: 2.664, 0.1097 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 16:16:15 visual_prompt]: 	Test 500/1152. loss: 2.681, 0.1025 s / batch. (data: 1.14e-04)max mem: 17.22454 GB 
[09/19 16:16:31 visual_prompt]: 	Test 600/1152. loss: 2.661, 0.1114 s / batch. (data: 6.65e-05)max mem: 17.22454 GB 
[09/19 16:16:47 visual_prompt]: 	Test 700/1152. loss: 2.599, 0.1074 s / batch. (data: 1.17e-04)max mem: 17.22454 GB 
[09/19 16:17:03 visual_prompt]: 	Test 800/1152. loss: 2.635, 0.1023 s / batch. (data: 7.03e-05)max mem: 17.22454 GB 
[09/19 16:17:19 visual_prompt]: 	Test 900/1152. loss: 2.692, 0.1188 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 16:17:35 visual_prompt]: 	Test 1000/1152. loss: 2.860, 0.1095 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/19 16:17:51 visual_prompt]: 	Test 1100/1152. loss: 2.731, 0.0972 s / batch. (data: 1.63e-04)max mem: 17.22454 GB 
[09/19 16:18:04 visual_prompt]: Inference (test):avg data time: 1.75e-03, avg batch time: 0.1087, average loss: 2.7317
[09/19 16:18:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 10.58	top5: 46.10	
[09/19 16:18:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/19 16:18:14 visual_prompt]: Epoch 63 / 100: avg data time: 2.13e-01, avg batch time: 0.4382, average train loss: 2.5998
[09/19 16:18:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0888, average loss: 2.3948
[09/19 16:18:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 27.50	top5: 66.50	
[09/19 16:18:40 visual_prompt]: 	Test 100/1152. loss: 2.706, 0.1025 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 16:18:56 visual_prompt]: 	Test 200/1152. loss: 2.409, 0.1008 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 16:19:13 visual_prompt]: 	Test 300/1152. loss: 2.577, 0.0979 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 16:19:29 visual_prompt]: 	Test 400/1152. loss: 2.607, 0.1266 s / batch. (data: 1.01e-02)max mem: 17.22454 GB 
[09/19 16:19:45 visual_prompt]: 	Test 500/1152. loss: 2.535, 0.1261 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 16:20:01 visual_prompt]: 	Test 600/1152. loss: 2.579, 0.0964 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 16:20:17 visual_prompt]: 	Test 700/1152. loss: 2.447, 0.1270 s / batch. (data: 1.05e-02)max mem: 17.22454 GB 
[09/19 16:20:33 visual_prompt]: 	Test 800/1152. loss: 2.546, 0.1078 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 16:20:49 visual_prompt]: 	Test 900/1152. loss: 2.653, 0.0981 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 16:21:05 visual_prompt]: 	Test 1000/1152. loss: 2.704, 0.1361 s / batch. (data: 7.34e-03)max mem: 17.22454 GB 
[09/19 16:21:21 visual_prompt]: 	Test 1100/1152. loss: 2.503, 0.0956 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 16:21:33 visual_prompt]: Inference (test):avg data time: 2.18e-03, avg batch time: 0.1089, average loss: 2.5902
[09/19 16:21:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.81	top5: 54.95	
[09/19 16:21:34 visual_prompt]: Best epoch 63: best metric: 0.275
[09/19 16:21:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/19 16:21:44 visual_prompt]: Epoch 64 / 100: avg data time: 2.11e-01, avg batch time: 0.4346, average train loss: 2.5085
[09/19 16:21:50 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.0876, average loss: 2.4275
[09/19 16:21:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 22.00	top5: 60.50	
[09/19 16:22:10 visual_prompt]: 	Test 100/1152. loss: 2.798, 0.1381 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 16:22:26 visual_prompt]: 	Test 200/1152. loss: 2.558, 0.0989 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 16:22:42 visual_prompt]: 	Test 300/1152. loss: 2.613, 0.1078 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 16:22:58 visual_prompt]: 	Test 400/1152. loss: 2.623, 0.1284 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 16:23:14 visual_prompt]: 	Test 500/1152. loss: 2.605, 0.0991 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 16:23:31 visual_prompt]: 	Test 600/1152. loss: 2.662, 0.1265 s / batch. (data: 3.11e-02)max mem: 17.22454 GB 
[09/19 16:23:47 visual_prompt]: 	Test 700/1152. loss: 2.321, 0.1107 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 16:24:03 visual_prompt]: 	Test 800/1152. loss: 2.526, 0.1443 s / batch. (data: 3.58e-02)max mem: 17.22454 GB 
[09/19 16:24:19 visual_prompt]: 	Test 900/1152. loss: 2.720, 0.1196 s / batch. (data: 2.31e-02)max mem: 17.22454 GB 
[09/19 16:24:35 visual_prompt]: 	Test 1000/1152. loss: 2.706, 0.0995 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 16:24:51 visual_prompt]: 	Test 1100/1152. loss: 2.566, 0.0981 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 16:25:03 visual_prompt]: Inference (test):avg data time: 2.16e-03, avg batch time: 0.1091, average loss: 2.6147
[09/19 16:25:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 15.66	top5: 54.67	
[09/19 16:25:04 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/19 16:25:13 visual_prompt]: Epoch 65 / 100: avg data time: 2.14e-01, avg batch time: 0.4390, average train loss: 2.4665
[09/19 16:25:20 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.0862, average loss: 2.3339
[09/19 16:25:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 30.00	top5: 67.50	
[09/19 16:25:40 visual_prompt]: 	Test 100/1152. loss: 2.774, 0.1473 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 16:25:56 visual_prompt]: 	Test 200/1152. loss: 2.554, 0.1079 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 16:26:12 visual_prompt]: 	Test 300/1152. loss: 2.636, 0.0954 s / batch. (data: 4.96e-05)max mem: 17.22454 GB 
[09/19 16:26:28 visual_prompt]: 	Test 400/1152. loss: 2.681, 0.0941 s / batch. (data: 5.53e-05)max mem: 17.22454 GB 
[09/19 16:26:44 visual_prompt]: 	Test 500/1152. loss: 2.523, 0.0949 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 16:27:00 visual_prompt]: 	Test 600/1152. loss: 2.622, 0.1007 s / batch. (data: 6.53e-05)max mem: 17.22454 GB 
[09/19 16:27:17 visual_prompt]: 	Test 700/1152. loss: 2.460, 0.0946 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 16:27:33 visual_prompt]: 	Test 800/1152. loss: 2.568, 0.0960 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 16:27:49 visual_prompt]: 	Test 900/1152. loss: 2.819, 0.0985 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 16:28:05 visual_prompt]: 	Test 1000/1152. loss: 2.951, 0.1439 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 16:28:21 visual_prompt]: 	Test 1100/1152. loss: 2.585, 0.1035 s / batch. (data: 1.80e-04)max mem: 17.22454 GB 
[09/19 16:28:33 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1094, average loss: 2.6923
[09/19 16:28:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 17.52	top5: 55.44	
[09/19 16:28:34 visual_prompt]: Best epoch 65: best metric: 0.300
[09/19 16:28:34 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/19 16:28:44 visual_prompt]: Epoch 66 / 100: avg data time: 2.21e-01, avg batch time: 0.4464, average train loss: 2.3556
[09/19 16:28:50 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.0914, average loss: 2.4143
[09/19 16:28:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 16.50	top5: 65.50	
[09/19 16:29:10 visual_prompt]: 	Test 100/1152. loss: 2.690, 0.1180 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 16:29:27 visual_prompt]: 	Test 200/1152. loss: 2.602, 0.0948 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/19 16:29:43 visual_prompt]: 	Test 300/1152. loss: 2.638, 0.0944 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 16:29:59 visual_prompt]: 	Test 400/1152. loss: 2.729, 0.1097 s / batch. (data: 5.89e-05)max mem: 17.22454 GB 
[09/19 16:30:15 visual_prompt]: 	Test 500/1152. loss: 2.541, 0.0955 s / batch. (data: 5.27e-05)max mem: 17.22454 GB 
[09/19 16:30:31 visual_prompt]: 	Test 600/1152. loss: 2.669, 0.1098 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 16:30:47 visual_prompt]: 	Test 700/1152. loss: 2.638, 0.0952 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 16:31:03 visual_prompt]: 	Test 800/1152. loss: 2.833, 0.0979 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 16:31:19 visual_prompt]: 	Test 900/1152. loss: 2.693, 0.0947 s / batch. (data: 5.29e-05)max mem: 17.22454 GB 
[09/19 16:31:35 visual_prompt]: 	Test 1000/1152. loss: 2.739, 0.0945 s / batch. (data: 5.17e-05)max mem: 17.22454 GB 
[09/19 16:31:52 visual_prompt]: 	Test 1100/1152. loss: 2.611, 0.0978 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 16:32:04 visual_prompt]: Inference (test):avg data time: 1.65e-03, avg batch time: 0.1082, average loss: 2.6914
[09/19 16:32:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 13.45	top5: 52.03	
[09/19 16:32:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/19 16:32:14 visual_prompt]: Epoch 67 / 100: avg data time: 2.22e-01, avg batch time: 0.4458, average train loss: 2.3285
[09/19 16:32:21 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.0864, average loss: 2.0291
[09/19 16:32:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 30.00	top5: 80.00	
[09/19 16:32:40 visual_prompt]: 	Test 100/1152. loss: 2.411, 0.1122 s / batch. (data: 1.62e-02)max mem: 17.22454 GB 
[09/19 16:32:56 visual_prompt]: 	Test 200/1152. loss: 2.434, 0.1079 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 16:33:12 visual_prompt]: 	Test 300/1152. loss: 2.517, 0.1180 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 16:33:28 visual_prompt]: 	Test 400/1152. loss: 2.602, 0.1326 s / batch. (data: 1.84e-04)max mem: 17.22454 GB 
[09/19 16:33:44 visual_prompt]: 	Test 500/1152. loss: 2.283, 0.1075 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 16:34:01 visual_prompt]: 	Test 600/1152. loss: 2.549, 0.1192 s / batch. (data: 7.13e-05)max mem: 17.22454 GB 
[09/19 16:34:17 visual_prompt]: 	Test 700/1152. loss: 2.398, 0.0998 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 16:34:33 visual_prompt]: 	Test 800/1152. loss: 2.496, 0.1492 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 16:34:49 visual_prompt]: 	Test 900/1152. loss: 2.596, 0.1097 s / batch. (data: 9.16e-05)max mem: 17.22454 GB 
[09/19 16:35:06 visual_prompt]: 	Test 1000/1152. loss: 2.661, 0.1057 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 16:35:22 visual_prompt]: 	Test 1100/1152. loss: 2.220, 0.1083 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 16:35:34 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1088, average loss: 2.4595
[09/19 16:35:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.02	top5: 63.24	
[09/19 16:35:35 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/19 16:35:45 visual_prompt]: Epoch 68 / 100: avg data time: 2.20e-01, avg batch time: 0.4484, average train loss: 2.2187
[09/19 16:35:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0953, average loss: 2.2179
[09/19 16:35:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 21.00	top5: 74.50	
[09/19 16:36:11 visual_prompt]: 	Test 100/1152. loss: 2.427, 0.1160 s / batch. (data: 1.12e-05)max mem: 17.22454 GB 
[09/19 16:36:27 visual_prompt]: 	Test 200/1152. loss: 2.528, 0.1040 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 16:36:43 visual_prompt]: 	Test 300/1152. loss: 2.395, 0.0990 s / batch. (data: 6.08e-05)max mem: 17.22454 GB 
[09/19 16:36:59 visual_prompt]: 	Test 400/1152. loss: 2.468, 0.0943 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/19 16:37:15 visual_prompt]: 	Test 500/1152. loss: 2.271, 0.0961 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 16:37:31 visual_prompt]: 	Test 600/1152. loss: 2.401, 0.1101 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 16:37:48 visual_prompt]: 	Test 700/1152. loss: 2.181, 0.0943 s / batch. (data: 5.87e-05)max mem: 17.22454 GB 
[09/19 16:38:04 visual_prompt]: 	Test 800/1152. loss: 2.422, 0.0992 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 16:38:19 visual_prompt]: 	Test 900/1152. loss: 2.473, 0.0981 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 16:38:35 visual_prompt]: 	Test 1000/1152. loss: 2.557, 0.0981 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 16:38:52 visual_prompt]: 	Test 1100/1152. loss: 2.426, 0.0943 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 16:39:04 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1089, average loss: 2.4716
[09/19 16:39:04 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 17.15	top5: 62.98	
[09/19 16:39:04 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/19 16:39:13 visual_prompt]: Epoch 69 / 100: avg data time: 2.08e-01, avg batch time: 0.4316, average train loss: 2.3871
[09/19 16:39:20 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.0922, average loss: 2.1486
[09/19 16:39:20 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.00	top5: 76.00	
[09/19 16:39:39 visual_prompt]: 	Test 100/1152. loss: 2.375, 0.0961 s / batch. (data: 3.55e-05)max mem: 17.22454 GB 
[09/19 16:39:55 visual_prompt]: 	Test 200/1152. loss: 2.467, 0.1038 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 16:40:12 visual_prompt]: 	Test 300/1152. loss: 2.340, 0.1003 s / batch. (data: 5.91e-05)max mem: 17.22454 GB 
[09/19 16:40:28 visual_prompt]: 	Test 400/1152. loss: 2.443, 0.1199 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 16:40:44 visual_prompt]: 	Test 500/1152. loss: 2.239, 0.1081 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 16:41:00 visual_prompt]: 	Test 600/1152. loss: 2.392, 0.0983 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 16:41:17 visual_prompt]: 	Test 700/1152. loss: 2.398, 0.0976 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 16:41:33 visual_prompt]: 	Test 800/1152. loss: 2.231, 0.1321 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 16:41:49 visual_prompt]: 	Test 900/1152. loss: 2.501, 0.1066 s / batch. (data: 8.60e-03)max mem: 17.22454 GB 
[09/19 16:42:05 visual_prompt]: 	Test 1000/1152. loss: 2.387, 0.1239 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 16:42:21 visual_prompt]: 	Test 1100/1152. loss: 2.385, 0.0969 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 16:42:34 visual_prompt]: Inference (test):avg data time: 2.45e-03, avg batch time: 0.1094, average loss: 2.4277
[09/19 16:42:34 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 20.42	top5: 65.44	
[09/19 16:42:34 visual_prompt]: Best epoch 69: best metric: 0.310
[09/19 16:42:34 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/19 16:42:44 visual_prompt]: Epoch 70 / 100: avg data time: 2.17e-01, avg batch time: 0.4378, average train loss: 2.1351
[09/19 16:42:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.0924, average loss: 2.1020
[09/19 16:42:50 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 27.50	top5: 80.50	
[09/19 16:43:10 visual_prompt]: 	Test 100/1152. loss: 2.471, 0.1260 s / batch. (data: 9.04e-03)max mem: 17.22454 GB 
[09/19 16:43:26 visual_prompt]: 	Test 200/1152. loss: 2.596, 0.1239 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 16:43:42 visual_prompt]: 	Test 300/1152. loss: 2.440, 0.1038 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 16:43:58 visual_prompt]: 	Test 400/1152. loss: 2.592, 0.1084 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 16:44:15 visual_prompt]: 	Test 500/1152. loss: 2.284, 0.1077 s / batch. (data: 6.34e-05)max mem: 17.22454 GB 
[09/19 16:44:31 visual_prompt]: 	Test 600/1152. loss: 2.402, 0.1004 s / batch. (data: 5.58e-05)max mem: 17.22454 GB 
[09/19 16:44:47 visual_prompt]: 	Test 700/1152. loss: 2.387, 0.1060 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 16:45:03 visual_prompt]: 	Test 800/1152. loss: 2.363, 0.1283 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 16:45:19 visual_prompt]: 	Test 900/1152. loss: 2.562, 0.1019 s / batch. (data: 5.84e-05)max mem: 17.22454 GB 
[09/19 16:45:36 visual_prompt]: 	Test 1000/1152. loss: 2.531, 0.1078 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 16:45:52 visual_prompt]: 	Test 1100/1152. loss: 2.488, 0.0962 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 16:46:04 visual_prompt]: Inference (test):avg data time: 2.06e-03, avg batch time: 0.1088, average loss: 2.5020
[09/19 16:46:05 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 19.75	top5: 65.94	
[09/19 16:46:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/19 16:46:14 visual_prompt]: Epoch 71 / 100: avg data time: 2.19e-01, avg batch time: 0.4424, average train loss: 1.9804
[09/19 16:46:21 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.0867, average loss: 1.7570
[09/19 16:46:21 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.50	top5: 85.50	
[09/19 16:46:41 visual_prompt]: 	Test 100/1152. loss: 2.233, 0.1157 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 16:46:57 visual_prompt]: 	Test 200/1152. loss: 2.287, 0.1266 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 16:47:14 visual_prompt]: 	Test 300/1152. loss: 2.242, 0.1077 s / batch. (data: 1.59e-04)max mem: 17.22454 GB 
[09/19 16:47:30 visual_prompt]: 	Test 400/1152. loss: 2.365, 0.1077 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 16:47:46 visual_prompt]: 	Test 500/1152. loss: 2.059, 0.0990 s / batch. (data: 1.68e-04)max mem: 17.22454 GB 
[09/19 16:48:03 visual_prompt]: 	Test 600/1152. loss: 2.169, 0.1156 s / batch. (data: 7.03e-03)max mem: 17.22454 GB 
[09/19 16:48:18 visual_prompt]: 	Test 700/1152. loss: 1.875, 0.0967 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 16:48:35 visual_prompt]: 	Test 800/1152. loss: 2.188, 0.0960 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 16:48:51 visual_prompt]: 	Test 900/1152. loss: 2.286, 0.0993 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 16:49:07 visual_prompt]: 	Test 1000/1152. loss: 2.243, 0.1038 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 16:49:23 visual_prompt]: 	Test 1100/1152. loss: 2.165, 0.1211 s / batch. (data: 2.05e-02)max mem: 17.22454 GB 
[09/19 16:49:35 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1087, average loss: 2.2513
[09/19 16:49:35 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.60	top5: 75.73	
[09/19 16:49:35 visual_prompt]: Best epoch 71: best metric: 0.405
[09/19 16:49:35 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/19 16:49:45 visual_prompt]: Epoch 72 / 100: avg data time: 2.09e-01, avg batch time: 0.4328, average train loss: 1.7723
[09/19 16:49:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.0907, average loss: 1.7847
[09/19 16:49:51 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 42.50	top5: 84.00	
[09/19 16:50:11 visual_prompt]: 	Test 100/1152. loss: 2.210, 0.1299 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 16:50:27 visual_prompt]: 	Test 200/1152. loss: 2.623, 0.0979 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 16:50:44 visual_prompt]: 	Test 300/1152. loss: 2.175, 0.0943 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 16:51:00 visual_prompt]: 	Test 400/1152. loss: 2.375, 0.1287 s / batch. (data: 6.77e-05)max mem: 17.22454 GB 
[09/19 16:51:16 visual_prompt]: 	Test 500/1152. loss: 2.167, 0.0950 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 16:51:33 visual_prompt]: 	Test 600/1152. loss: 2.203, 0.1031 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 16:51:49 visual_prompt]: 	Test 700/1152. loss: 1.928, 0.1029 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 16:52:05 visual_prompt]: 	Test 800/1152. loss: 2.239, 0.1057 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 16:52:21 visual_prompt]: 	Test 900/1152. loss: 2.342, 0.0948 s / batch. (data: 5.32e-05)max mem: 17.22454 GB 
[09/19 16:52:37 visual_prompt]: 	Test 1000/1152. loss: 2.429, 0.0950 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 16:52:53 visual_prompt]: 	Test 1100/1152. loss: 2.230, 0.0952 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 16:53:05 visual_prompt]: Inference (test):avg data time: 1.48e-03, avg batch time: 0.1079, average loss: 2.3200
[09/19 16:53:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 24.85	top5: 73.67	
[09/19 16:53:06 visual_prompt]: Best epoch 72: best metric: 0.425
[09/19 16:53:06 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/19 16:53:16 visual_prompt]: Epoch 73 / 100: avg data time: 2.21e-01, avg batch time: 0.4467, average train loss: 1.6577
[09/19 16:53:22 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.0878, average loss: 1.9351
[09/19 16:53:22 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 32.00	top5: 85.50	
[09/19 16:53:42 visual_prompt]: 	Test 100/1152. loss: 2.336, 0.1205 s / batch. (data: 1.19e-02)max mem: 17.22454 GB 
[09/19 16:53:58 visual_prompt]: 	Test 200/1152. loss: 2.630, 0.1320 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 16:54:15 visual_prompt]: 	Test 300/1152. loss: 2.185, 0.1054 s / batch. (data: 6.13e-05)max mem: 17.22454 GB 
[09/19 16:54:31 visual_prompt]: 	Test 400/1152. loss: 2.457, 0.1185 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 16:54:47 visual_prompt]: 	Test 500/1152. loss: 2.084, 0.1225 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 16:55:03 visual_prompt]: 	Test 600/1152. loss: 2.082, 0.1056 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 16:55:19 visual_prompt]: 	Test 700/1152. loss: 2.089, 0.1186 s / batch. (data: 6.01e-05)max mem: 17.22454 GB 
[09/19 16:55:35 visual_prompt]: 	Test 800/1152. loss: 2.199, 0.1081 s / batch. (data: 5.70e-05)max mem: 17.22454 GB 
[09/19 16:55:51 visual_prompt]: 	Test 900/1152. loss: 2.212, 0.1179 s / batch. (data: 4.96e-05)max mem: 17.22454 GB 
[09/19 16:56:07 visual_prompt]: 	Test 1000/1152. loss: 2.382, 0.1001 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 16:56:23 visual_prompt]: 	Test 1100/1152. loss: 2.384, 0.0955 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 16:56:36 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1092, average loss: 2.4013
[09/19 16:56:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 25.30	top5: 75.31	
[09/19 16:56:36 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/19 16:56:46 visual_prompt]: Epoch 74 / 100: avg data time: 2.10e-01, avg batch time: 0.4343, average train loss: 1.6455
[09/19 16:56:52 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.0891, average loss: 1.4384
[09/19 16:56:52 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 45.50	top5: 95.50	
[09/19 16:57:12 visual_prompt]: 	Test 100/1152. loss: 2.133, 0.1382 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 16:57:28 visual_prompt]: 	Test 200/1152. loss: 2.242, 0.1161 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 16:57:44 visual_prompt]: 	Test 300/1152. loss: 2.000, 0.0979 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 16:58:00 visual_prompt]: 	Test 400/1152. loss: 2.127, 0.0966 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 16:58:17 visual_prompt]: 	Test 500/1152. loss: 1.952, 0.0975 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 16:58:33 visual_prompt]: 	Test 600/1152. loss: 2.054, 0.1152 s / batch. (data: 6.03e-05)max mem: 17.22454 GB 
[09/19 16:58:49 visual_prompt]: 	Test 700/1152. loss: 1.564, 0.1069 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 16:59:06 visual_prompt]: 	Test 800/1152. loss: 1.982, 0.0966 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 16:59:22 visual_prompt]: 	Test 900/1152. loss: 1.818, 0.0964 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 16:59:38 visual_prompt]: 	Test 1000/1152. loss: 1.950, 0.1208 s / batch. (data: 5.51e-05)max mem: 17.22454 GB 
[09/19 16:59:54 visual_prompt]: 	Test 1100/1152. loss: 2.131, 0.1117 s / batch. (data: 5.72e-05)max mem: 17.22454 GB 
[09/19 17:00:06 visual_prompt]: Inference (test):avg data time: 1.77e-03, avg batch time: 0.1087, average loss: 2.0191
[09/19 17:00:06 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 30.48	top5: 83.90	
[09/19 17:00:06 visual_prompt]: Best epoch 74: best metric: 0.455
[09/19 17:00:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/19 17:00:16 visual_prompt]: Epoch 75 / 100: avg data time: 2.10e-01, avg batch time: 0.4375, average train loss: 1.4333
[09/19 17:00:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0892, average loss: 1.4612
[09/19 17:00:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 44.50	top5: 96.50	
[09/19 17:00:42 visual_prompt]: 	Test 100/1152. loss: 2.366, 0.1066 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 17:00:59 visual_prompt]: 	Test 200/1152. loss: 2.256, 0.1262 s / batch. (data: 1.37e-02)max mem: 17.22454 GB 
[09/19 17:01:15 visual_prompt]: 	Test 300/1152. loss: 1.849, 0.1081 s / batch. (data: 1.67e-04)max mem: 17.22454 GB 
[09/19 17:01:31 visual_prompt]: 	Test 400/1152. loss: 2.251, 0.1190 s / batch. (data: 9.34e-03)max mem: 17.22454 GB 
[09/19 17:01:47 visual_prompt]: 	Test 500/1152. loss: 1.944, 0.0989 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 17:02:03 visual_prompt]: 	Test 600/1152. loss: 1.997, 0.0962 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 17:02:19 visual_prompt]: 	Test 700/1152. loss: 1.760, 0.1190 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 17:02:35 visual_prompt]: 	Test 800/1152. loss: 1.918, 0.1021 s / batch. (data: 7.40e-03)max mem: 17.22454 GB 
[09/19 17:02:52 visual_prompt]: 	Test 900/1152. loss: 2.274, 0.1092 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 17:03:08 visual_prompt]: 	Test 1000/1152. loss: 1.912, 0.1322 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 17:03:24 visual_prompt]: 	Test 1100/1152. loss: 2.080, 0.0968 s / batch. (data: 1.73e-04)max mem: 17.22454 GB 
[09/19 17:03:36 visual_prompt]: Inference (test):avg data time: 1.88e-03, avg batch time: 0.1084, average loss: 2.0724
[09/19 17:03:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.45	top5: 87.53	
[09/19 17:03:37 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/19 17:03:47 visual_prompt]: Epoch 76 / 100: avg data time: 2.15e-01, avg batch time: 0.4422, average train loss: 1.3526
[09/19 17:03:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.0962, average loss: 1.2109
[09/19 17:03:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 54.00	top5: 97.00	
[09/19 17:04:12 visual_prompt]: 	Test 100/1152. loss: 2.033, 0.1628 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 17:04:29 visual_prompt]: 	Test 200/1152. loss: 2.214, 0.0969 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 17:04:45 visual_prompt]: 	Test 300/1152. loss: 1.825, 0.0993 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 17:05:01 visual_prompt]: 	Test 400/1152. loss: 2.100, 0.0986 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 17:05:17 visual_prompt]: 	Test 500/1152. loss: 1.753, 0.1119 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 17:05:33 visual_prompt]: 	Test 600/1152. loss: 1.815, 0.0989 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 17:05:50 visual_prompt]: 	Test 700/1152. loss: 1.593, 0.0982 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 17:06:06 visual_prompt]: 	Test 800/1152. loss: 1.518, 0.1308 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 17:06:23 visual_prompt]: 	Test 900/1152. loss: 1.968, 0.1019 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 17:06:38 visual_prompt]: 	Test 1000/1152. loss: 1.643, 0.1127 s / batch. (data: 8.13e-03)max mem: 17.22454 GB 
[09/19 17:06:54 visual_prompt]: 	Test 1100/1152. loss: 2.067, 0.0951 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 17:07:06 visual_prompt]: Inference (test):avg data time: 1.86e-03, avg batch time: 0.1083, average loss: 1.9097
[09/19 17:07:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 34.25	top5: 88.63	
[09/19 17:07:07 visual_prompt]: Best epoch 76: best metric: 0.540
[09/19 17:07:07 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/19 17:07:16 visual_prompt]: Epoch 77 / 100: avg data time: 2.07e-01, avg batch time: 0.4299, average train loss: 1.3678
[09/19 17:07:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.0913, average loss: 1.1735
[09/19 17:07:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 52.00	top5: 97.50	
[09/19 17:07:43 visual_prompt]: 	Test 100/1152. loss: 1.855, 0.1130 s / batch. (data: 7.33e-03)max mem: 17.22454 GB 
[09/19 17:07:59 visual_prompt]: 	Test 200/1152. loss: 1.933, 0.0962 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:08:15 visual_prompt]: 	Test 300/1152. loss: 1.991, 0.1238 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 17:08:31 visual_prompt]: 	Test 400/1152. loss: 1.989, 0.1326 s / batch. (data: 1.16e-04)max mem: 17.22454 GB 
[09/19 17:08:47 visual_prompt]: 	Test 500/1152. loss: 1.754, 0.1175 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 17:09:03 visual_prompt]: 	Test 600/1152. loss: 1.757, 0.0989 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 17:09:19 visual_prompt]: 	Test 700/1152. loss: 1.606, 0.0963 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 17:09:35 visual_prompt]: 	Test 800/1152. loss: 1.799, 0.0947 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 17:09:51 visual_prompt]: 	Test 900/1152. loss: 2.002, 0.1197 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 17:10:07 visual_prompt]: 	Test 1000/1152. loss: 1.878, 0.1132 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 17:10:24 visual_prompt]: 	Test 1100/1152. loss: 1.917, 0.1045 s / batch. (data: 6.70e-05)max mem: 17.22454 GB 
[09/19 17:10:36 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1089, average loss: 1.8876
[09/19 17:10:36 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.02	top5: 88.69	
[09/19 17:10:36 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/19 17:10:46 visual_prompt]: Epoch 78 / 100: avg data time: 2.09e-01, avg batch time: 0.4332, average train loss: 1.2392
[09/19 17:10:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.0958, average loss: 1.5052
[09/19 17:10:53 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 49.50	top5: 96.00	
[09/19 17:11:12 visual_prompt]: 	Test 100/1152. loss: 2.090, 0.1209 s / batch. (data: 8.26e-03)max mem: 17.22454 GB 
[09/19 17:11:28 visual_prompt]: 	Test 200/1152. loss: 2.669, 0.1142 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 17:11:45 visual_prompt]: 	Test 300/1152. loss: 2.028, 0.1025 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 17:12:01 visual_prompt]: 	Test 400/1152. loss: 2.300, 0.1085 s / batch. (data: 9.35e-03)max mem: 17.22454 GB 
[09/19 17:12:17 visual_prompt]: 	Test 500/1152. loss: 1.933, 0.0984 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 17:12:34 visual_prompt]: 	Test 600/1152. loss: 2.003, 0.1036 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 17:12:50 visual_prompt]: 	Test 700/1152. loss: 1.913, 0.1091 s / batch. (data: 5.36e-05)max mem: 17.22454 GB 
[09/19 17:13:06 visual_prompt]: 	Test 800/1152. loss: 2.078, 0.0992 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 17:13:22 visual_prompt]: 	Test 900/1152. loss: 2.347, 0.0985 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 17:13:38 visual_prompt]: 	Test 1000/1152. loss: 2.227, 0.1312 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 17:13:54 visual_prompt]: 	Test 1100/1152. loss: 2.097, 0.1270 s / batch. (data: 1.11e-02)max mem: 17.22454 GB 
[09/19 17:14:07 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1084, average loss: 2.1888
[09/19 17:14:07 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 31.83	top5: 87.99	
[09/19 17:14:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/19 17:14:17 visual_prompt]: Epoch 79 / 100: avg data time: 2.15e-01, avg batch time: 0.4424, average train loss: 1.2216
[09/19 17:14:23 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.0923, average loss: 1.1064
[09/19 17:14:23 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 56.50	top5: 99.00	
[09/19 17:14:43 visual_prompt]: 	Test 100/1152. loss: 1.967, 0.1157 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 17:14:59 visual_prompt]: 	Test 200/1152. loss: 2.215, 0.1149 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 17:15:15 visual_prompt]: 	Test 300/1152. loss: 1.792, 0.1003 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 17:15:32 visual_prompt]: 	Test 400/1152. loss: 2.176, 0.0988 s / batch. (data: 1.48e-04)max mem: 17.22454 GB 
[09/19 17:15:48 visual_prompt]: 	Test 500/1152. loss: 1.625, 0.1415 s / batch. (data: 1.03e-02)max mem: 17.22454 GB 
[09/19 17:16:04 visual_prompt]: 	Test 600/1152. loss: 1.690, 0.1119 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 17:16:20 visual_prompt]: 	Test 700/1152. loss: 1.608, 0.1251 s / batch. (data: 3.79e-05)max mem: 17.22454 GB 
[09/19 17:16:37 visual_prompt]: 	Test 800/1152. loss: 1.598, 0.1047 s / batch. (data: 1.66e-04)max mem: 17.22454 GB 
[09/19 17:16:52 visual_prompt]: 	Test 900/1152. loss: 2.118, 0.1003 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 17:17:09 visual_prompt]: 	Test 1000/1152. loss: 1.752, 0.1055 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 17:17:25 visual_prompt]: 	Test 1100/1152. loss: 2.055, 0.0996 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 17:17:37 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1084, average loss: 1.8902
[09/19 17:17:37 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 36.72	top5: 90.49	
[09/19 17:17:37 visual_prompt]: Best epoch 79: best metric: 0.565
[09/19 17:17:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/19 17:17:48 visual_prompt]: Epoch 80 / 100: avg data time: 2.26e-01, avg batch time: 0.4491, average train loss: 1.0945
[09/19 17:17:54 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.0877, average loss: 0.8634
[09/19 17:17:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 66.50	top5: 99.00	
[09/19 17:18:14 visual_prompt]: 	Test 100/1152. loss: 2.016, 0.1312 s / batch. (data: 2.15e-02)max mem: 17.22454 GB 
[09/19 17:18:30 visual_prompt]: 	Test 200/1152. loss: 2.118, 0.0997 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 17:18:46 visual_prompt]: 	Test 300/1152. loss: 1.726, 0.1146 s / batch. (data: 2.13e-04)max mem: 17.22454 GB 
[09/19 17:19:02 visual_prompt]: 	Test 400/1152. loss: 2.205, 0.0994 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 17:19:19 visual_prompt]: 	Test 500/1152. loss: 1.736, 0.0999 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 17:19:34 visual_prompt]: 	Test 600/1152. loss: 1.950, 0.1079 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 17:19:50 visual_prompt]: 	Test 700/1152. loss: 1.644, 0.0954 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:20:07 visual_prompt]: 	Test 800/1152. loss: 1.542, 0.1180 s / batch. (data: 6.06e-05)max mem: 17.22454 GB 
[09/19 17:20:23 visual_prompt]: 	Test 900/1152. loss: 2.097, 0.1035 s / batch. (data: 3.43e-05)max mem: 17.22454 GB 
[09/19 17:20:39 visual_prompt]: 	Test 1000/1152. loss: 1.811, 0.1093 s / batch. (data: 3.12e-04)max mem: 17.22454 GB 
[09/19 17:20:55 visual_prompt]: 	Test 1100/1152. loss: 2.060, 0.1079 s / batch. (data: 1.05e-04)max mem: 17.22454 GB 
[09/19 17:21:07 visual_prompt]: Inference (test):avg data time: 2.16e-03, avg batch time: 0.1085, average loss: 1.8699
[09/19 17:21:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 39.40	top5: 91.56	
[09/19 17:21:08 visual_prompt]: Best epoch 80: best metric: 0.665
[09/19 17:21:08 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/19 17:21:18 visual_prompt]: Epoch 81 / 100: avg data time: 2.15e-01, avg batch time: 0.4367, average train loss: 1.0514
[09/19 17:21:24 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.0944, average loss: 0.7460
[09/19 17:21:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 70.00	top5: 100.00	
[09/19 17:21:44 visual_prompt]: 	Test 100/1152. loss: 1.685, 0.1044 s / batch. (data: 6.58e-05)max mem: 17.22454 GB 
[09/19 17:22:00 visual_prompt]: 	Test 200/1152. loss: 2.101, 0.1079 s / batch. (data: 1.33e-04)max mem: 17.22454 GB 
[09/19 17:22:16 visual_prompt]: 	Test 300/1152. loss: 1.655, 0.0949 s / batch. (data: 6.37e-05)max mem: 17.22454 GB 
[09/19 17:22:32 visual_prompt]: 	Test 400/1152. loss: 1.808, 0.0959 s / batch. (data: 6.63e-05)max mem: 17.22454 GB 
[09/19 17:22:49 visual_prompt]: 	Test 500/1152. loss: 1.413, 0.1013 s / batch. (data: 5.44e-05)max mem: 17.22454 GB 
[09/19 17:23:05 visual_prompt]: 	Test 600/1152. loss: 1.876, 0.1173 s / batch. (data: 6.56e-05)max mem: 17.22454 GB 
[09/19 17:23:21 visual_prompt]: 	Test 700/1152. loss: 1.357, 0.0944 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 17:23:37 visual_prompt]: 	Test 800/1152. loss: 1.362, 0.1004 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 17:23:54 visual_prompt]: 	Test 900/1152. loss: 1.808, 0.0944 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 17:24:10 visual_prompt]: 	Test 1000/1152. loss: 1.656, 0.1137 s / batch. (data: 5.82e-05)max mem: 17.22454 GB 
[09/19 17:24:25 visual_prompt]: 	Test 1100/1152. loss: 1.968, 0.0974 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 17:24:38 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1078, average loss: 1.7266
[09/19 17:24:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 39.69	top5: 93.15	
[09/19 17:24:38 visual_prompt]: Best epoch 81: best metric: 0.700
[09/19 17:24:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/19 17:24:48 visual_prompt]: Epoch 82 / 100: avg data time: 2.14e-01, avg batch time: 0.4385, average train loss: 0.7809
[09/19 17:24:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.0898, average loss: 0.7566
[09/19 17:24:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 68.50	top5: 99.00	
[09/19 17:25:14 visual_prompt]: 	Test 100/1152. loss: 1.717, 0.1113 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 17:25:30 visual_prompt]: 	Test 200/1152. loss: 2.238, 0.0980 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 17:25:46 visual_prompt]: 	Test 300/1152. loss: 1.890, 0.1068 s / batch. (data: 6.15e-05)max mem: 17.22454 GB 
[09/19 17:26:03 visual_prompt]: 	Test 400/1152. loss: 2.097, 0.1320 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 17:26:19 visual_prompt]: 	Test 500/1152. loss: 1.697, 0.1042 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:26:35 visual_prompt]: 	Test 600/1152. loss: 1.492, 0.1178 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 17:26:51 visual_prompt]: 	Test 700/1152. loss: 1.475, 0.0948 s / batch. (data: 6.32e-05)max mem: 17.22454 GB 
[09/19 17:27:07 visual_prompt]: 	Test 800/1152. loss: 1.601, 0.1162 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 17:27:23 visual_prompt]: 	Test 900/1152. loss: 2.026, 0.1185 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 17:27:39 visual_prompt]: 	Test 1000/1152. loss: 1.526, 0.1092 s / batch. (data: 6.10e-05)max mem: 17.22454 GB 
[09/19 17:27:55 visual_prompt]: 	Test 1100/1152. loss: 1.715, 0.1250 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 17:28:08 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1083, average loss: 1.8771
[09/19 17:28:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 41.62	top5: 93.79	
[09/19 17:28:08 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/19 17:28:18 visual_prompt]: Epoch 83 / 100: avg data time: 2.15e-01, avg batch time: 0.4401, average train loss: 0.8036
[09/19 17:28:24 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.0886, average loss: 0.7450
[09/19 17:28:24 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 70.00	top5: 100.00	
[09/19 17:28:44 visual_prompt]: 	Test 100/1152. loss: 1.564, 0.1210 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 17:29:00 visual_prompt]: 	Test 200/1152. loss: 2.386, 0.1050 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/19 17:29:16 visual_prompt]: 	Test 300/1152. loss: 1.807, 0.1039 s / batch. (data: 7.23e-03)max mem: 17.22454 GB 
[09/19 17:29:33 visual_prompt]: 	Test 400/1152. loss: 1.966, 0.0991 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 17:29:49 visual_prompt]: 	Test 500/1152. loss: 1.519, 0.1082 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 17:30:05 visual_prompt]: 	Test 600/1152. loss: 1.501, 0.0952 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 17:30:22 visual_prompt]: 	Test 700/1152. loss: 1.618, 0.1290 s / batch. (data: 2.16e-02)max mem: 17.22454 GB 
[09/19 17:30:38 visual_prompt]: 	Test 800/1152. loss: 1.446, 0.1000 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 17:30:54 visual_prompt]: 	Test 900/1152. loss: 2.113, 0.1198 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 17:31:10 visual_prompt]: 	Test 1000/1152. loss: 1.733, 0.0986 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 17:31:26 visual_prompt]: 	Test 1100/1152. loss: 1.825, 0.1199 s / batch. (data: 3.24e-05)max mem: 17.22454 GB 
[09/19 17:31:38 visual_prompt]: Inference (test):avg data time: 1.80e-03, avg batch time: 0.1088, average loss: 1.8804
[09/19 17:31:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 39.81	top5: 92.36	
[09/19 17:31:39 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/19 17:31:48 visual_prompt]: Epoch 84 / 100: avg data time: 2.07e-01, avg batch time: 0.4348, average train loss: 0.7064
[09/19 17:31:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.0950, average loss: 0.7206
[09/19 17:31:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 72.50	top5: 99.00	
[09/19 17:32:14 visual_prompt]: 	Test 100/1152. loss: 2.040, 0.1664 s / batch. (data: 1.40e-02)max mem: 17.22454 GB 
[09/19 17:32:30 visual_prompt]: 	Test 200/1152. loss: 2.517, 0.1103 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 17:32:47 visual_prompt]: 	Test 300/1152. loss: 1.808, 0.1038 s / batch. (data: 1.03e-04)max mem: 17.22454 GB 
[09/19 17:33:03 visual_prompt]: 	Test 400/1152. loss: 1.961, 0.1083 s / batch. (data: 9.35e-05)max mem: 17.22454 GB 
[09/19 17:33:19 visual_prompt]: 	Test 500/1152. loss: 1.766, 0.1229 s / batch. (data: 1.50e-04)max mem: 17.22454 GB 
[09/19 17:33:36 visual_prompt]: 	Test 600/1152. loss: 1.762, 0.1324 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 17:33:52 visual_prompt]: 	Test 700/1152. loss: 1.716, 0.0980 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:34:08 visual_prompt]: 	Test 800/1152. loss: 1.503, 0.1123 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 17:34:24 visual_prompt]: 	Test 900/1152. loss: 2.284, 0.0973 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 17:34:40 visual_prompt]: 	Test 1000/1152. loss: 1.671, 0.1180 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 17:34:56 visual_prompt]: 	Test 1100/1152. loss: 2.066, 0.1135 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 17:35:08 visual_prompt]: Inference (test):avg data time: 1.74e-03, avg batch time: 0.1089, average loss: 2.0301
[09/19 17:35:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.24	top5: 92.01	
[09/19 17:35:08 visual_prompt]: Best epoch 84: best metric: 0.725
[09/19 17:35:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/19 17:35:18 visual_prompt]: Epoch 85 / 100: avg data time: 2.10e-01, avg batch time: 0.4366, average train loss: 0.6652
[09/19 17:35:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.0876, average loss: 0.8324
[09/19 17:35:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 68.50	top5: 100.00	
[09/19 17:35:44 visual_prompt]: 	Test 100/1152. loss: 2.049, 0.1108 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 17:36:00 visual_prompt]: 	Test 200/1152. loss: 2.946, 0.1199 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 17:36:16 visual_prompt]: 	Test 300/1152. loss: 2.204, 0.1084 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:36:33 visual_prompt]: 	Test 400/1152. loss: 2.235, 0.1197 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 17:36:49 visual_prompt]: 	Test 500/1152. loss: 1.746, 0.1496 s / batch. (data: 8.98e-03)max mem: 17.22454 GB 
[09/19 17:37:05 visual_prompt]: 	Test 600/1152. loss: 1.990, 0.0993 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 17:37:21 visual_prompt]: 	Test 700/1152. loss: 2.016, 0.1062 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 17:37:37 visual_prompt]: 	Test 800/1152. loss: 1.790, 0.0952 s / batch. (data: 1.10e-04)max mem: 17.22454 GB 
[09/19 17:37:53 visual_prompt]: 	Test 900/1152. loss: 2.462, 0.1238 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 17:38:09 visual_prompt]: 	Test 1000/1152. loss: 2.014, 0.1000 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 17:38:25 visual_prompt]: 	Test 1100/1152. loss: 2.272, 0.0974 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 17:38:38 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1087, average loss: 2.2352
[09/19 17:38:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 39.65	top5: 92.67	
[09/19 17:38:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/19 17:38:48 visual_prompt]: Epoch 86 / 100: avg data time: 2.15e-01, avg batch time: 0.4444, average train loss: 0.6323
[09/19 17:38:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.0879, average loss: 0.4728
[09/19 17:38:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 81.50	top5: 100.00	
[09/19 17:39:14 visual_prompt]: 	Test 100/1152. loss: 1.841, 0.1163 s / batch. (data: 1.30e-04)max mem: 17.22454 GB 
[09/19 17:39:30 visual_prompt]: 	Test 200/1152. loss: 2.728, 0.1029 s / batch. (data: 1.24e-04)max mem: 17.22454 GB 
[09/19 17:39:46 visual_prompt]: 	Test 300/1152. loss: 1.878, 0.1299 s / batch. (data: 3.32e-03)max mem: 17.22454 GB 
[09/19 17:40:03 visual_prompt]: 	Test 400/1152. loss: 1.854, 0.1199 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 17:40:19 visual_prompt]: 	Test 500/1152. loss: 1.514, 0.1270 s / batch. (data: 1.51e-04)max mem: 17.22454 GB 
[09/19 17:40:35 visual_prompt]: 	Test 600/1152. loss: 1.682, 0.1026 s / batch. (data: 1.11e-04)max mem: 17.22454 GB 
[09/19 17:40:51 visual_prompt]: 	Test 700/1152. loss: 1.694, 0.1197 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 17:41:07 visual_prompt]: 	Test 800/1152. loss: 1.220, 0.1004 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 17:41:23 visual_prompt]: 	Test 900/1152. loss: 2.082, 0.0948 s / batch. (data: 5.98e-05)max mem: 17.22454 GB 
[09/19 17:41:39 visual_prompt]: 	Test 1000/1152. loss: 1.463, 0.1066 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 17:41:55 visual_prompt]: 	Test 1100/1152. loss: 2.209, 0.0987 s / batch. (data: 6.48e-05)max mem: 17.22454 GB 
[09/19 17:42:08 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1087, average loss: 1.9238
[09/19 17:42:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.00	top5: 94.60	
[09/19 17:42:08 visual_prompt]: Best epoch 86: best metric: 0.815
[09/19 17:42:08 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/19 17:42:18 visual_prompt]: Epoch 87 / 100: avg data time: 2.16e-01, avg batch time: 0.4435, average train loss: 0.5203
[09/19 17:42:25 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.0883, average loss: 0.3218
[09/19 17:42:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 87.00	top5: 100.00	
[09/19 17:42:44 visual_prompt]: 	Test 100/1152. loss: 1.996, 0.1051 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 17:43:00 visual_prompt]: 	Test 200/1152. loss: 2.832, 0.0977 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 17:43:17 visual_prompt]: 	Test 300/1152. loss: 1.734, 0.1097 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 17:43:33 visual_prompt]: 	Test 400/1152. loss: 2.290, 0.0980 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 17:43:50 visual_prompt]: 	Test 500/1152. loss: 1.797, 0.1451 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 17:44:06 visual_prompt]: 	Test 600/1152. loss: 1.760, 0.1076 s / batch. (data: 1.10e-02)max mem: 17.22454 GB 
[09/19 17:44:22 visual_prompt]: 	Test 700/1152. loss: 1.808, 0.1042 s / batch. (data: 7.30e-03)max mem: 17.22454 GB 
[09/19 17:44:38 visual_prompt]: 	Test 800/1152. loss: 1.339, 0.1020 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 17:44:54 visual_prompt]: 	Test 900/1152. loss: 2.080, 0.1046 s / batch. (data: 7.29e-03)max mem: 17.22454 GB 
[09/19 17:45:10 visual_prompt]: 	Test 1000/1152. loss: 1.707, 0.1219 s / batch. (data: 1.25e-04)max mem: 17.22454 GB 
[09/19 17:45:26 visual_prompt]: 	Test 1100/1152. loss: 2.224, 0.1042 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 17:45:38 visual_prompt]: Inference (test):avg data time: 1.69e-03, avg batch time: 0.1082, average loss: 2.0631
[09/19 17:45:39 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.18	top5: 94.27	
[09/19 17:45:39 visual_prompt]: Best epoch 87: best metric: 0.870
[09/19 17:45:39 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/19 17:45:48 visual_prompt]: Epoch 88 / 100: avg data time: 2.08e-01, avg batch time: 0.4355, average train loss: 0.4604
[09/19 17:45:55 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.0913, average loss: 0.3698
[09/19 17:45:55 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 83.50	top5: 100.00	
[09/19 17:46:14 visual_prompt]: 	Test 100/1152. loss: 2.023, 0.1061 s / batch. (data: 5.50e-03)max mem: 17.22454 GB 
[09/19 17:46:31 visual_prompt]: 	Test 200/1152. loss: 3.462, 0.1101 s / batch. (data: 1.42e-02)max mem: 17.22454 GB 
[09/19 17:46:46 visual_prompt]: 	Test 300/1152. loss: 2.572, 0.0951 s / batch. (data: 5.25e-05)max mem: 17.22454 GB 
[09/19 17:47:03 visual_prompt]: 	Test 400/1152. loss: 2.465, 0.0999 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 17:47:19 visual_prompt]: 	Test 500/1152. loss: 1.806, 0.1454 s / batch. (data: 1.29e-05)max mem: 17.22454 GB 
[09/19 17:47:35 visual_prompt]: 	Test 600/1152. loss: 2.193, 0.1138 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:47:51 visual_prompt]: 	Test 700/1152. loss: 2.149, 0.0946 s / batch. (data: 6.18e-05)max mem: 17.22454 GB 
[09/19 17:48:07 visual_prompt]: 	Test 800/1152. loss: 1.566, 0.0945 s / batch. (data: 5.75e-05)max mem: 17.22454 GB 
[09/19 17:48:23 visual_prompt]: 	Test 900/1152. loss: 2.346, 0.0943 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 17:48:39 visual_prompt]: 	Test 1000/1152. loss: 2.360, 0.0989 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 17:48:55 visual_prompt]: 	Test 1100/1152. loss: 2.198, 0.1082 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 17:49:08 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1080, average loss: 2.4026
[09/19 17:49:08 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 42.06	top5: 93.86	
[09/19 17:49:08 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/19 17:49:18 visual_prompt]: Epoch 89 / 100: avg data time: 2.23e-01, avg batch time: 0.4486, average train loss: 0.4317
[09/19 17:49:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.0896, average loss: 0.5913
[09/19 17:49:25 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 80.00	top5: 99.50	
[09/19 17:49:44 visual_prompt]: 	Test 100/1152. loss: 2.220, 0.1092 s / batch. (data: 1.44e-04)max mem: 17.22454 GB 
[09/19 17:50:00 visual_prompt]: 	Test 200/1152. loss: 3.663, 0.1482 s / batch. (data: 4.70e-05)max mem: 17.22454 GB 
[09/19 17:50:16 visual_prompt]: 	Test 300/1152. loss: 2.565, 0.1090 s / batch. (data: 9.62e-03)max mem: 17.22454 GB 
[09/19 17:50:33 visual_prompt]: 	Test 400/1152. loss: 2.589, 0.1238 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 17:50:49 visual_prompt]: 	Test 500/1152. loss: 2.193, 0.1187 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 17:51:05 visual_prompt]: 	Test 600/1152. loss: 2.199, 0.0989 s / batch. (data: 1.20e-04)max mem: 17.22454 GB 
[09/19 17:51:21 visual_prompt]: 	Test 700/1152. loss: 2.398, 0.0978 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 17:51:37 visual_prompt]: 	Test 800/1152. loss: 2.039, 0.1011 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 17:51:53 visual_prompt]: 	Test 900/1152. loss: 2.770, 0.1099 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 17:52:09 visual_prompt]: 	Test 1000/1152. loss: 2.187, 0.1258 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 17:52:25 visual_prompt]: 	Test 1100/1152. loss: 2.262, 0.1269 s / batch. (data: 7.62e-03)max mem: 17.22454 GB 
[09/19 17:52:38 visual_prompt]: Inference (test):avg data time: 2.01e-03, avg batch time: 0.1091, average loss: 2.6436
[09/19 17:52:38 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.75	top5: 92.75	
[09/19 17:52:38 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/19 17:52:48 visual_prompt]: Epoch 90 / 100: avg data time: 2.09e-01, avg batch time: 0.4314, average train loss: 0.4066
[09/19 17:52:54 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.0957, average loss: 0.3774
[09/19 17:52:54 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 80.50	top5: 100.00	
[09/19 17:53:14 visual_prompt]: 	Test 100/1152. loss: 2.406, 0.1342 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 17:53:30 visual_prompt]: 	Test 200/1152. loss: 3.694, 0.1117 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 17:53:47 visual_prompt]: 	Test 300/1152. loss: 2.819, 0.0991 s / batch. (data: 1.46e-04)max mem: 17.22454 GB 
[09/19 17:54:03 visual_prompt]: 	Test 400/1152. loss: 2.734, 0.1201 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 17:54:20 visual_prompt]: 	Test 500/1152. loss: 2.165, 0.1077 s / batch. (data: 1.70e-04)max mem: 17.22454 GB 
[09/19 17:54:36 visual_prompt]: 	Test 600/1152. loss: 2.579, 0.1159 s / batch. (data: 1.53e-02)max mem: 17.22454 GB 
[09/19 17:54:52 visual_prompt]: 	Test 700/1152. loss: 2.239, 0.1084 s / batch. (data: 3.58e-05)max mem: 17.22454 GB 
[09/19 17:55:09 visual_prompt]: 	Test 800/1152. loss: 2.253, 0.1137 s / batch. (data: 1.01e-03)max mem: 17.22454 GB 
[09/19 17:55:25 visual_prompt]: 	Test 900/1152. loss: 2.801, 0.1017 s / batch. (data: 1.55e-04)max mem: 17.22454 GB 
[09/19 17:55:41 visual_prompt]: 	Test 1000/1152. loss: 2.126, 0.1000 s / batch. (data: 1.09e-04)max mem: 17.22454 GB 
[09/19 17:55:58 visual_prompt]: 	Test 1100/1152. loss: 2.351, 0.1186 s / batch. (data: 9.32e-05)max mem: 17.22454 GB 
[09/19 17:56:10 visual_prompt]: Inference (test):avg data time: 2.07e-03, avg batch time: 0.1096, average loss: 2.5958
[09/19 17:56:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 40.83	top5: 93.50	
[09/19 17:56:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/19 17:56:20 visual_prompt]: Epoch 91 / 100: avg data time: 2.25e-01, avg batch time: 0.4467, average train loss: 0.3591
[09/19 17:56:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.0893, average loss: 0.2615
[09/19 17:56:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 91.50	top5: 100.00	
[09/19 17:56:46 visual_prompt]: 	Test 100/1152. loss: 2.254, 0.1683 s / batch. (data: 2.15e-02)max mem: 17.22454 GB 
[09/19 17:57:02 visual_prompt]: 	Test 200/1152. loss: 3.244, 0.1561 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 17:57:18 visual_prompt]: 	Test 300/1152. loss: 2.369, 0.1159 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 17:57:35 visual_prompt]: 	Test 400/1152. loss: 2.618, 0.0949 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 17:57:51 visual_prompt]: 	Test 500/1152. loss: 2.260, 0.1264 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 17:58:07 visual_prompt]: 	Test 600/1152. loss: 1.907, 0.1475 s / batch. (data: 2.90e-02)max mem: 17.22454 GB 
[09/19 17:58:23 visual_prompt]: 	Test 700/1152. loss: 2.098, 0.1154 s / batch. (data: 6.29e-05)max mem: 17.22454 GB 
[09/19 17:58:39 visual_prompt]: 	Test 800/1152. loss: 1.962, 0.1079 s / batch. (data: 4.94e-05)max mem: 17.22454 GB 
[09/19 17:58:55 visual_prompt]: 	Test 900/1152. loss: 2.576, 0.1158 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 17:59:12 visual_prompt]: 	Test 1000/1152. loss: 2.071, 0.1161 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 17:59:28 visual_prompt]: 	Test 1100/1152. loss: 2.320, 0.1297 s / batch. (data: 3.40e-02)max mem: 17.22454 GB 
[09/19 17:59:40 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1093, average loss: 2.4306
[09/19 17:59:40 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.12	top5: 94.48	
[09/19 17:59:40 visual_prompt]: Best epoch 91: best metric: 0.915
[09/19 17:59:40 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/19 17:59:50 visual_prompt]: Epoch 92 / 100: avg data time: 2.21e-01, avg batch time: 0.4438, average train loss: 0.2670
[09/19 17:59:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.0919, average loss: 0.2497
[09/19 17:59:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 92.00	top5: 100.00	
[09/19 18:00:16 visual_prompt]: 	Test 100/1152. loss: 2.127, 0.0957 s / batch. (data: 1.29e-04)max mem: 17.22454 GB 
[09/19 18:00:32 visual_prompt]: 	Test 200/1152. loss: 3.590, 0.0962 s / batch. (data: 1.01e-04)max mem: 17.22454 GB 
[09/19 18:00:48 visual_prompt]: 	Test 300/1152. loss: 2.125, 0.1006 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 18:01:05 visual_prompt]: 	Test 400/1152. loss: 2.435, 0.1522 s / batch. (data: 1.52e-04)max mem: 17.22454 GB 
[09/19 18:01:21 visual_prompt]: 	Test 500/1152. loss: 2.092, 0.0955 s / batch. (data: 4.32e-05)max mem: 17.22454 GB 
[09/19 18:01:37 visual_prompt]: 	Test 600/1152. loss: 2.041, 0.1170 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 18:01:53 visual_prompt]: 	Test 700/1152. loss: 2.219, 0.1083 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 18:02:09 visual_prompt]: 	Test 800/1152. loss: 1.937, 0.1041 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 18:02:26 visual_prompt]: 	Test 900/1152. loss: 2.631, 0.1039 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 18:02:42 visual_prompt]: 	Test 1000/1152. loss: 2.070, 0.0987 s / batch. (data: 1.37e-04)max mem: 17.22454 GB 
[09/19 18:02:58 visual_prompt]: 	Test 1100/1152. loss: 2.358, 0.1038 s / batch. (data: 1.45e-04)max mem: 17.22454 GB 
[09/19 18:03:10 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1087, average loss: 2.4851
[09/19 18:03:10 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.74	top5: 94.65	
[09/19 18:03:10 visual_prompt]: Best epoch 92: best metric: 0.920
[09/19 18:03:10 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/19 18:03:20 visual_prompt]: Epoch 93 / 100: avg data time: 2.09e-01, avg batch time: 0.4338, average train loss: 0.2406
[09/19 18:03:27 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.0869, average loss: 0.2511
[09/19 18:03:27 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 89.50	top5: 100.00	
[09/19 18:03:47 visual_prompt]: 	Test 100/1152. loss: 2.159, 0.1286 s / batch. (data: 2.05e-02)max mem: 17.22454 GB 
[09/19 18:04:03 visual_prompt]: 	Test 200/1152. loss: 3.798, 0.0958 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 18:04:19 visual_prompt]: 	Test 300/1152. loss: 2.324, 0.1158 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 18:04:35 visual_prompt]: 	Test 400/1152. loss: 2.732, 0.1028 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 18:04:52 visual_prompt]: 	Test 500/1152. loss: 2.276, 0.1534 s / batch. (data: 4.53e-05)max mem: 17.22454 GB 
[09/19 18:05:07 visual_prompt]: 	Test 600/1152. loss: 2.190, 0.0980 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 18:05:24 visual_prompt]: 	Test 700/1152. loss: 2.356, 0.1133 s / batch. (data: 4.58e-05)max mem: 17.22454 GB 
[09/19 18:05:40 visual_prompt]: 	Test 800/1152. loss: 2.119, 0.1082 s / batch. (data: 4.32e-05)max mem: 17.22454 GB 
[09/19 18:05:56 visual_prompt]: 	Test 900/1152. loss: 2.798, 0.0976 s / batch. (data: 1.04e-04)max mem: 17.22454 GB 
[09/19 18:06:12 visual_prompt]: 	Test 1000/1152. loss: 2.288, 0.1279 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 18:06:28 visual_prompt]: 	Test 1100/1152. loss: 2.449, 0.0954 s / batch. (data: 3.41e-05)max mem: 17.22454 GB 
[09/19 18:06:40 visual_prompt]: Inference (test):avg data time: 2.00e-03, avg batch time: 0.1088, average loss: 2.6367
[09/19 18:06:41 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 42.66	top5: 94.01	
[09/19 18:06:41 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/19 18:06:51 visual_prompt]: Epoch 94 / 100: avg data time: 2.25e-01, avg batch time: 0.4499, average train loss: 0.1893
[09/19 18:06:57 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.0922, average loss: 0.2029
[09/19 18:06:57 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 92.50	top5: 100.00	
[09/19 18:07:17 visual_prompt]: 	Test 100/1152. loss: 2.151, 0.0973 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 18:07:33 visual_prompt]: 	Test 200/1152. loss: 3.888, 0.1088 s / batch. (data: 1.12e-02)max mem: 17.22454 GB 
[09/19 18:07:49 visual_prompt]: 	Test 300/1152. loss: 2.302, 0.1314 s / batch. (data: 1.49e-04)max mem: 17.22454 GB 
[09/19 18:08:05 visual_prompt]: 	Test 400/1152. loss: 2.798, 0.1237 s / batch. (data: 1.51e-02)max mem: 17.22454 GB 
[09/19 18:08:21 visual_prompt]: 	Test 500/1152. loss: 2.292, 0.1220 s / batch. (data: 1.74e-02)max mem: 17.22454 GB 
[09/19 18:08:38 visual_prompt]: 	Test 600/1152. loss: 2.148, 0.1307 s / batch. (data: 1.41e-02)max mem: 17.22454 GB 
[09/19 18:08:54 visual_prompt]: 	Test 700/1152. loss: 2.352, 0.1002 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 18:09:10 visual_prompt]: 	Test 800/1152. loss: 2.336, 0.1171 s / batch. (data: 2.09e-02)max mem: 17.22454 GB 
[09/19 18:09:26 visual_prompt]: 	Test 900/1152. loss: 2.902, 0.1069 s / batch. (data: 5.39e-05)max mem: 17.22454 GB 
[09/19 18:09:42 visual_prompt]: 	Test 1000/1152. loss: 2.037, 0.0990 s / batch. (data: 1.28e-04)max mem: 17.22454 GB 
[09/19 18:09:59 visual_prompt]: 	Test 1100/1152. loss: 2.403, 0.1233 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 18:10:11 visual_prompt]: Inference (test):avg data time: 2.11e-03, avg batch time: 0.1090, average loss: 2.6516
[09/19 18:10:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.47	top5: 94.45	
[09/19 18:10:11 visual_prompt]: Best epoch 94: best metric: 0.925
[09/19 18:10:11 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/19 18:10:21 visual_prompt]: Epoch 95 / 100: avg data time: 2.25e-01, avg batch time: 0.4506, average train loss: 0.1732
[09/19 18:10:28 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.0867, average loss: 0.1606
[09/19 18:10:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 95.00	top5: 100.00	
[09/19 18:10:47 visual_prompt]: 	Test 100/1152. loss: 2.225, 0.1111 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 18:11:04 visual_prompt]: 	Test 200/1152. loss: 3.685, 0.1200 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 18:11:20 visual_prompt]: 	Test 300/1152. loss: 2.298, 0.1120 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 18:11:37 visual_prompt]: 	Test 400/1152. loss: 2.891, 0.1178 s / batch. (data: 1.83e-04)max mem: 17.22454 GB 
[09/19 18:11:53 visual_prompt]: 	Test 500/1152. loss: 2.270, 0.1102 s / batch. (data: 1.35e-04)max mem: 17.22454 GB 
[09/19 18:12:09 visual_prompt]: 	Test 600/1152. loss: 2.238, 0.0964 s / batch. (data: 1.61e-04)max mem: 17.22454 GB 
[09/19 18:12:25 visual_prompt]: 	Test 700/1152. loss: 2.386, 0.0986 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 18:12:41 visual_prompt]: 	Test 800/1152. loss: 2.193, 0.1037 s / batch. (data: 1.12e-04)max mem: 17.22454 GB 
[09/19 18:12:57 visual_prompt]: 	Test 900/1152. loss: 2.608, 0.1290 s / batch. (data: 3.33e-02)max mem: 17.22454 GB 
[09/19 18:13:13 visual_prompt]: 	Test 1000/1152. loss: 2.231, 0.0998 s / batch. (data: 1.19e-04)max mem: 17.22454 GB 
[09/19 18:13:29 visual_prompt]: 	Test 1100/1152. loss: 2.433, 0.0969 s / batch. (data: 1.54e-04)max mem: 17.22454 GB 
[09/19 18:13:42 visual_prompt]: Inference (test):avg data time: 1.94e-03, avg batch time: 0.1086, average loss: 2.6553
[09/19 18:13:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.30	top5: 94.23	
[09/19 18:13:42 visual_prompt]: Best epoch 95: best metric: 0.950
[09/19 18:13:42 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/19 18:13:52 visual_prompt]: Epoch 96 / 100: avg data time: 2.18e-01, avg batch time: 0.4437, average train loss: 0.1529
[09/19 18:13:58 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.0946, average loss: 0.1663
[09/19 18:13:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 18:14:18 visual_prompt]: 	Test 100/1152. loss: 2.329, 0.1176 s / batch. (data: 1.08e-02)max mem: 17.22454 GB 
[09/19 18:14:34 visual_prompt]: 	Test 200/1152. loss: 3.864, 0.1248 s / batch. (data: 2.83e-02)max mem: 17.22454 GB 
[09/19 18:14:50 visual_prompt]: 	Test 300/1152. loss: 2.472, 0.0988 s / batch. (data: 1.07e-04)max mem: 17.22454 GB 
[09/19 18:15:06 visual_prompt]: 	Test 400/1152. loss: 2.980, 0.0953 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 18:15:22 visual_prompt]: 	Test 500/1152. loss: 2.329, 0.1158 s / batch. (data: 1.34e-04)max mem: 17.22454 GB 
[09/19 18:15:39 visual_prompt]: 	Test 600/1152. loss: 2.219, 0.1118 s / batch. (data: 1.40e-04)max mem: 17.22454 GB 
[09/19 18:15:55 visual_prompt]: 	Test 700/1152. loss: 2.439, 0.0985 s / batch. (data: 1.56e-04)max mem: 17.22454 GB 
[09/19 18:16:11 visual_prompt]: 	Test 800/1152. loss: 2.337, 0.1198 s / batch. (data: 7.24e-03)max mem: 17.22454 GB 
[09/19 18:16:27 visual_prompt]: 	Test 900/1152. loss: 2.833, 0.1103 s / batch. (data: 9.81e-03)max mem: 17.22454 GB 
[09/19 18:16:43 visual_prompt]: 	Test 1000/1152. loss: 2.166, 0.1211 s / batch. (data: 1.57e-04)max mem: 17.22454 GB 
[09/19 18:16:59 visual_prompt]: 	Test 1100/1152. loss: 2.386, 0.1517 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 18:17:11 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1090, average loss: 2.7232
[09/19 18:17:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.35	top5: 94.23	
[09/19 18:17:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/19 18:17:21 visual_prompt]: Epoch 97 / 100: avg data time: 2.20e-01, avg batch time: 0.4477, average train loss: 0.1479
[09/19 18:17:28 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.0967, average loss: 0.1577
[09/19 18:17:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 95.00	top5: 100.00	
[09/19 18:17:47 visual_prompt]: 	Test 100/1152. loss: 2.333, 0.1258 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 18:18:03 visual_prompt]: 	Test 200/1152. loss: 3.863, 0.1172 s / batch. (data: 1.17e-02)max mem: 17.22454 GB 
[09/19 18:18:20 visual_prompt]: 	Test 300/1152. loss: 2.357, 0.1075 s / batch. (data: 1.13e-02)max mem: 17.22454 GB 
[09/19 18:18:36 visual_prompt]: 	Test 400/1152. loss: 2.949, 0.1059 s / batch. (data: 1.75e-04)max mem: 17.22454 GB 
[09/19 18:18:53 visual_prompt]: 	Test 500/1152. loss: 2.312, 0.1160 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 18:19:09 visual_prompt]: 	Test 600/1152. loss: 2.149, 0.1293 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 18:19:25 visual_prompt]: 	Test 700/1152. loss: 2.479, 0.1104 s / batch. (data: 1.13e-04)max mem: 17.22454 GB 
[09/19 18:19:41 visual_prompt]: 	Test 800/1152. loss: 2.283, 0.0950 s / batch. (data: 5.60e-05)max mem: 17.22454 GB 
[09/19 18:19:57 visual_prompt]: 	Test 900/1152. loss: 2.778, 0.0960 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 18:20:13 visual_prompt]: 	Test 1000/1152. loss: 2.217, 0.1552 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 18:20:29 visual_prompt]: 	Test 1100/1152. loss: 2.500, 0.0990 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 18:20:41 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1088, average loss: 2.7168
[09/19 18:20:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.46	top5: 94.33	
[09/19 18:20:42 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/19 18:20:51 visual_prompt]: Epoch 98 / 100: avg data time: 2.08e-01, avg batch time: 0.4334, average train loss: 0.1448
[09/19 18:20:58 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.0923, average loss: 0.1625
[09/19 18:20:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 18:21:17 visual_prompt]: 	Test 100/1152. loss: 2.422, 0.0997 s / batch. (data: 1.47e-04)max mem: 17.22454 GB 
[09/19 18:21:33 visual_prompt]: 	Test 200/1152. loss: 3.964, 0.0979 s / batch. (data: 1.53e-04)max mem: 17.22454 GB 
[09/19 18:21:50 visual_prompt]: 	Test 300/1152. loss: 2.408, 0.1084 s / batch. (data: 1.18e-04)max mem: 17.22454 GB 
[09/19 18:22:06 visual_prompt]: 	Test 400/1152. loss: 2.982, 0.0985 s / batch. (data: 1.31e-04)max mem: 17.22454 GB 
[09/19 18:22:22 visual_prompt]: 	Test 500/1152. loss: 2.353, 0.1079 s / batch. (data: 1.22e-04)max mem: 17.22454 GB 
[09/19 18:22:38 visual_prompt]: 	Test 600/1152. loss: 2.202, 0.1107 s / batch. (data: 4.60e-05)max mem: 17.22454 GB 
[09/19 18:22:54 visual_prompt]: 	Test 700/1152. loss: 2.493, 0.1015 s / batch. (data: 1.15e-04)max mem: 17.22454 GB 
[09/19 18:23:10 visual_prompt]: 	Test 800/1152. loss: 2.324, 0.1156 s / batch. (data: 1.06e-04)max mem: 17.22454 GB 
[09/19 18:23:27 visual_prompt]: 	Test 900/1152. loss: 2.838, 0.1020 s / batch. (data: 5.41e-05)max mem: 17.22454 GB 
[09/19 18:23:43 visual_prompt]: 	Test 1000/1152. loss: 2.226, 0.0966 s / batch. (data: 5.96e-05)max mem: 17.22454 GB 
[09/19 18:23:59 visual_prompt]: 	Test 1100/1152. loss: 2.512, 0.1040 s / batch. (data: 1.42e-04)max mem: 17.22454 GB 
[09/19 18:24:11 visual_prompt]: Inference (test):avg data time: 1.78e-03, avg batch time: 0.1079, average loss: 2.7545
[09/19 18:24:11 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.29	top5: 94.16	
[09/19 18:24:11 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/19 18:24:21 visual_prompt]: Epoch 99 / 100: avg data time: 2.15e-01, avg batch time: 0.4413, average train loss: 0.1300
[09/19 18:24:28 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.0866, average loss: 0.1616
[09/19 18:24:28 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 93.00	top5: 100.00	
[09/19 18:24:47 visual_prompt]: 	Test 100/1152. loss: 2.385, 0.0965 s / batch. (data: 1.36e-04)max mem: 17.22454 GB 
[09/19 18:25:04 visual_prompt]: 	Test 200/1152. loss: 3.985, 0.1091 s / batch. (data: 1.23e-02)max mem: 17.22454 GB 
[09/19 18:25:20 visual_prompt]: 	Test 300/1152. loss: 2.389, 0.1107 s / batch. (data: 1.64e-04)max mem: 17.22454 GB 
[09/19 18:25:36 visual_prompt]: 	Test 400/1152. loss: 2.987, 0.0990 s / batch. (data: 1.43e-04)max mem: 17.22454 GB 
[09/19 18:25:52 visual_prompt]: 	Test 500/1152. loss: 2.337, 0.0980 s / batch. (data: 1.62e-04)max mem: 17.22454 GB 
[09/19 18:26:08 visual_prompt]: 	Test 600/1152. loss: 2.195, 0.1142 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 18:26:25 visual_prompt]: 	Test 700/1152. loss: 2.512, 0.1079 s / batch. (data: 1.65e-04)max mem: 17.22454 GB 
[09/19 18:26:41 visual_prompt]: 	Test 800/1152. loss: 2.322, 0.1293 s / batch. (data: 1.38e-04)max mem: 17.22454 GB 
[09/19 18:26:57 visual_prompt]: 	Test 900/1152. loss: 2.825, 0.1199 s / batch. (data: 1.14e-02)max mem: 17.22454 GB 
[09/19 18:27:13 visual_prompt]: 	Test 1000/1152. loss: 2.206, 0.0989 s / batch. (data: 2.10e-04)max mem: 17.22454 GB 
[09/19 18:27:29 visual_prompt]: 	Test 1100/1152. loss: 2.511, 0.1224 s / batch. (data: 1.41e-04)max mem: 17.22454 GB 
[09/19 18:27:42 visual_prompt]: Inference (test):avg data time: 1.89e-03, avg batch time: 0.1082, average loss: 2.7477
[09/19 18:27:42 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.40	top5: 94.20	
[09/19 18:27:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/19 18:27:52 visual_prompt]: Epoch 100 / 100: avg data time: 2.17e-01, avg batch time: 0.4458, average train loss: 0.1306
[09/19 18:27:58 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.0953, average loss: 0.1604
[09/19 18:27:58 visual_prompt]: Classification results with val_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 93.50	top5: 100.00	
[09/19 18:28:18 visual_prompt]: 	Test 100/1152. loss: 2.378, 0.1445 s / batch. (data: 2.46e-04)max mem: 17.22454 GB 
[09/19 18:28:34 visual_prompt]: 	Test 200/1152. loss: 3.976, 0.1358 s / batch. (data: 4.22e-05)max mem: 17.22454 GB 
[09/19 18:28:50 visual_prompt]: 	Test 300/1152. loss: 2.384, 0.1199 s / batch. (data: 1.23e-04)max mem: 17.22454 GB 
[09/19 18:29:06 visual_prompt]: 	Test 400/1152. loss: 2.986, 0.0973 s / batch. (data: 1.26e-04)max mem: 17.22454 GB 
[09/19 18:29:23 visual_prompt]: 	Test 500/1152. loss: 2.331, 0.1105 s / batch. (data: 1.27e-04)max mem: 17.22454 GB 
[09/19 18:29:39 visual_prompt]: 	Test 600/1152. loss: 2.191, 0.1198 s / batch. (data: 7.06e-03)max mem: 17.22454 GB 
[09/19 18:29:55 visual_prompt]: 	Test 700/1152. loss: 2.513, 0.0948 s / batch. (data: 1.21e-04)max mem: 17.22454 GB 
[09/19 18:30:11 visual_prompt]: 	Test 800/1152. loss: 2.316, 0.1020 s / batch. (data: 1.02e-04)max mem: 17.22454 GB 
[09/19 18:30:27 visual_prompt]: 	Test 900/1152. loss: 2.820, 0.0995 s / batch. (data: 1.08e-04)max mem: 17.22454 GB 
[09/19 18:30:44 visual_prompt]: 	Test 1000/1152. loss: 2.211, 0.0998 s / batch. (data: 1.39e-04)max mem: 17.22454 GB 
[09/19 18:31:00 visual_prompt]: 	Test 1100/1152. loss: 2.514, 0.0962 s / batch. (data: 1.60e-04)max mem: 17.22454 GB 
[09/19 18:31:12 visual_prompt]: Inference (test):avg data time: 2.17e-03, avg batch time: 0.1089, average loss: 2.7459
[09/19 18:31:13 visual_prompt]: Classification results with test_vtab-dsprites(predicted_attribute="label_orientation",num_classes=16): top1: 43.40	top5: 94.20	
