[09/16 02:42:46 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 02:42:47 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 02:42:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-oxford_flowers102', 'DATA.NUMBER_CLASSES', '102', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/16 02:42:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 02:42:47 visual_prompt]: Training with config:
[09/16 02:42:47 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-oxford_flowers102',
          'NO_TEST': False,
          'NUMBER_CLASSES': 102,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-oxford_flowers102/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 02:42:47 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 02:42:47.031332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 02:42:47.220410: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 02:42:48.235955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:42:48.236040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:42:48.236048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 02:42:50.543137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:42:50.543252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:42:50.543267: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 02:42:50 visual_prompt]: Constructing vtab-oxford_flowers102 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
2023-09-16 02:42:50.617568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 02:42:53 visual_prompt]: Number of images: 1000
[09/16 02:42:53 visual_prompt]: Number of classes: 102 / 102
[09/16 02:42:53 visual_prompt]: Loading validation data...
[09/16 02:42:53 visual_prompt]: Constructing vtab-oxford_flowers102 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 02:42:54 visual_prompt]: Number of images: 200
[09/16 02:42:54 visual_prompt]: Number of classes: 90 / 102
[09/16 02:42:54 visual_prompt]: Loading test data...
[09/16 02:42:54 visual_prompt]: Constructing vtab-oxford_flowers102 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split test, from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 02:43:08 visual_prompt]: Number of images: 6149
[09/16 02:43:08 visual_prompt]: Number of classes: 102 / 102
[09/16 02:43:08 visual_prompt]: Constructing models...
[09/16 02:43:11 visual_prompt]: Total Parameters: 86798694	 Gradient Parameters: 1000038
[09/16 02:43:11 visual_prompt]: tuned percent:1.152
[09/16 02:43:13 visual_prompt]: Device used for model: 0
[09/16 02:43:13 visual_prompt]: Setting up Evalutator...
[09/16 02:43:13 visual_prompt]: Setting up Trainer...
[09/16 02:43:13 visual_prompt]: 	Setting up the optimizer...
[09/16 02:43:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 02:43:23 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e-01, avg batch time: 0.5839, average train loss: 4.6667
[09/16 02:43:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1428, average loss: 4.6405
[09/16 02:43:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.00	top5: 4.50	
[09/16 02:43:46 visual_prompt]: Inference (test):avg data time: 5.73e-03, avg batch time: 0.1899, average loss: 4.6427
[09/16 02:43:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.27	top5: 7.25	
[09/16 02:43:46 visual_prompt]: Best epoch 1: best metric: 0.010
[09/16 02:43:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 02:43:55 visual_prompt]: Epoch 2 / 100: avg data time: 8.35e-02, avg batch time: 0.4868, average train loss: 4.5853
[09/16 02:43:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1429, average loss: 4.4297
[09/16 02:43:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 4.50	top5: 12.00	
[09/16 02:44:18 visual_prompt]: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1915, average loss: 4.5351
[09/16 02:44:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.42	top5: 10.78	
[09/16 02:44:18 visual_prompt]: Best epoch 2: best metric: 0.045
[09/16 02:44:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 02:44:27 visual_prompt]: Epoch 3 / 100: avg data time: 8.56e-02, avg batch time: 0.4948, average train loss: 4.3378
[09/16 02:44:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1432, average loss: 3.2770
[09/16 02:44:29 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 25.00	top5: 52.00	
[09/16 02:44:50 visual_prompt]: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1922, average loss: 3.7578
[09/16 02:44:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 13.38	top5: 35.10	
[09/16 02:44:50 visual_prompt]: Best epoch 3: best metric: 0.250
[09/16 02:44:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 02:44:59 visual_prompt]: Epoch 4 / 100: avg data time: 8.22e-02, avg batch time: 0.4880, average train loss: 2.9836
[09/16 02:45:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1435, average loss: 1.5672
[09/16 02:45:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 59.50	top5: 83.50	
[09/16 02:45:23 visual_prompt]: Inference (test):avg data time: 6.25e-03, avg batch time: 0.1971, average loss: 2.0057
[09/16 02:45:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 50.82	top5: 75.74	
[09/16 02:45:23 visual_prompt]: Best epoch 4: best metric: 0.595
[09/16 02:45:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 02:45:32 visual_prompt]: Epoch 5 / 100: avg data time: 9.29e-02, avg batch time: 0.4975, average train loss: 0.8739
[09/16 02:45:34 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1437, average loss: 0.2339
[09/16 02:45:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 94.00	top5: 100.00	
[09/16 02:45:55 visual_prompt]: Inference (test):avg data time: 7.06e-03, avg batch time: 0.1924, average loss: 0.7020
[09/16 02:45:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 81.14	top5: 94.86	
[09/16 02:45:55 visual_prompt]: Best epoch 5: best metric: 0.940
[09/16 02:45:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 02:46:04 visual_prompt]: Epoch 6 / 100: avg data time: 9.15e-02, avg batch time: 0.4943, average train loss: 0.2075
[09/16 02:46:06 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1439, average loss: 0.0802
[09/16 02:46:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 02:46:27 visual_prompt]: Inference (test):avg data time: 6.20e-03, avg batch time: 0.1919, average loss: 0.4666
[09/16 02:46:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.95	top5: 97.28	
[09/16 02:46:27 visual_prompt]: Best epoch 6: best metric: 0.980
[09/16 02:46:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 02:46:35 visual_prompt]: Epoch 7 / 100: avg data time: 7.86e-02, avg batch time: 0.4843, average train loss: 0.0622
[09/16 02:46:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1438, average loss: 0.0999
[09/16 02:46:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 02:46:59 visual_prompt]: Inference (test):avg data time: 6.30e-03, avg batch time: 0.1916, average loss: 0.2998
[09/16 02:46:59 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.41	top5: 98.42	
[09/16 02:46:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 02:47:08 visual_prompt]: Epoch 8 / 100: avg data time: 9.70e-02, avg batch time: 0.5015, average train loss: 0.0672
[09/16 02:47:10 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1438, average loss: 0.0381
[09/16 02:47:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 02:47:31 visual_prompt]: Inference (test):avg data time: 6.32e-03, avg batch time: 0.1918, average loss: 0.3902
[09/16 02:47:31 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.69	top5: 97.85	
[09/16 02:47:31 visual_prompt]: Best epoch 8: best metric: 0.990
[09/16 02:47:31 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 02:47:40 visual_prompt]: Epoch 9 / 100: avg data time: 8.30e-02, avg batch time: 0.4883, average train loss: 0.1283
[09/16 02:47:42 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1438, average loss: 0.0794
[09/16 02:47:42 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.50	top5: 99.50	
[09/16 02:48:03 visual_prompt]: Inference (test):avg data time: 6.28e-03, avg batch time: 0.1912, average loss: 0.4046
[09/16 02:48:03 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.66	top5: 97.89	
[09/16 02:48:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 02:48:11 visual_prompt]: Epoch 10 / 100: avg data time: 8.01e-02, avg batch time: 0.4856, average train loss: 0.0652
[09/16 02:48:14 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1438, average loss: 0.1040
[09/16 02:48:14 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.50	top5: 99.50	
[09/16 02:48:35 visual_prompt]: Inference (test):avg data time: 7.70e-03, avg batch time: 0.1932, average loss: 0.4378
[09/16 02:48:35 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.60	top5: 97.19	
[09/16 02:48:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 02:48:44 visual_prompt]: Epoch 11 / 100: avg data time: 9.41e-02, avg batch time: 0.5045, average train loss: 0.0722
[09/16 02:48:46 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1437, average loss: 0.2150
[09/16 02:48:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.00	top5: 100.00	
[09/16 02:49:07 visual_prompt]: Inference (test):avg data time: 5.97e-03, avg batch time: 0.1907, average loss: 0.6668
[09/16 02:49:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 84.29	top5: 96.28	
[09/16 02:49:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 02:49:16 visual_prompt]: Epoch 12 / 100: avg data time: 9.04e-02, avg batch time: 0.4927, average train loss: 0.0632
[09/16 02:49:18 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1438, average loss: 0.0898
[09/16 02:49:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 02:49:39 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1939, average loss: 0.4739
[09/16 02:49:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.61	top5: 97.82	
[09/16 02:49:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 02:49:48 visual_prompt]: Epoch 13 / 100: avg data time: 8.56e-02, avg batch time: 0.4895, average train loss: 0.0635
[09/16 02:49:50 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1439, average loss: 0.0642
[09/16 02:49:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.50	top5: 99.00	
[09/16 02:50:11 visual_prompt]: Inference (test):avg data time: 8.46e-03, avg batch time: 0.1929, average loss: 0.4555
[09/16 02:50:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.26	top5: 96.41	
[09/16 02:50:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 02:50:20 visual_prompt]: Epoch 14 / 100: avg data time: 9.36e-02, avg batch time: 0.4973, average train loss: 0.0798
[09/16 02:50:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1437, average loss: 0.0407
[09/16 02:50:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 02:50:44 visual_prompt]: Inference (test):avg data time: 6.59e-03, avg batch time: 0.1913, average loss: 0.4363
[09/16 02:50:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.74	top5: 96.93	
[09/16 02:50:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 02:50:52 visual_prompt]: Epoch 15 / 100: avg data time: 9.50e-02, avg batch time: 0.4994, average train loss: 0.0411
[09/16 02:50:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1438, average loss: 0.0101
[09/16 02:50:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:51:16 visual_prompt]: Inference (test):avg data time: 5.95e-03, avg batch time: 0.1933, average loss: 0.2714
[09/16 02:51:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.53	top5: 98.49	
[09/16 02:51:16 visual_prompt]: Best epoch 15: best metric: 1.000
[09/16 02:51:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 02:51:24 visual_prompt]: Epoch 16 / 100: avg data time: 8.85e-02, avg batch time: 0.4922, average train loss: 0.0101
[09/16 02:51:27 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1436, average loss: 0.0035
[09/16 02:51:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:51:48 visual_prompt]: Inference (test):avg data time: 6.74e-03, avg batch time: 0.1922, average loss: 0.1623
[09/16 02:51:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.06	top5: 99.24	
[09/16 02:51:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 02:51:56 visual_prompt]: Epoch 17 / 100: avg data time: 7.38e-02, avg batch time: 0.4798, average train loss: 0.0040
[09/16 02:51:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1437, average loss: 0.0034
[09/16 02:51:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:52:20 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1936, average loss: 0.1403
[09/16 02:52:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.76	top5: 99.25	
[09/16 02:52:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 02:52:29 visual_prompt]: Epoch 18 / 100: avg data time: 8.72e-02, avg batch time: 0.4928, average train loss: 0.0146
[09/16 02:52:31 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 02:52:31 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:52:52 visual_prompt]: Inference (test):avg data time: 6.73e-03, avg batch time: 0.1931, average loss: 0.1637
[09/16 02:52:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.29	top5: 99.11	
[09/16 02:52:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 02:53:01 visual_prompt]: Epoch 19 / 100: avg data time: 8.81e-02, avg batch time: 0.4917, average train loss: 0.0176
[09/16 02:53:03 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1439, average loss: 0.0061
[09/16 02:53:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:53:24 visual_prompt]: Inference (test):avg data time: 6.99e-03, avg batch time: 0.1925, average loss: 0.1638
[09/16 02:53:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.42	top5: 99.15	
[09/16 02:53:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 02:53:33 visual_prompt]: Epoch 20 / 100: avg data time: 9.21e-02, avg batch time: 0.4959, average train loss: 0.0182
[09/16 02:53:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1438, average loss: 0.0301
[09/16 02:53:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 02:53:57 visual_prompt]: Inference (test):avg data time: 6.53e-03, avg batch time: 0.1929, average loss: 0.2617
[09/16 02:53:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.08	top5: 98.52	
[09/16 02:53:57 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 02:54:05 visual_prompt]: Epoch 21 / 100: avg data time: 8.17e-02, avg batch time: 0.4882, average train loss: 0.0088
[09/16 02:54:08 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1438, average loss: 0.0034
[09/16 02:54:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:54:29 visual_prompt]: Inference (test):avg data time: 5.27e-03, avg batch time: 0.1913, average loss: 0.1458
[09/16 02:54:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.75	top5: 99.43	
[09/16 02:54:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 02:54:37 visual_prompt]: Epoch 22 / 100: avg data time: 9.99e-02, avg batch time: 0.5027, average train loss: 0.0046
[09/16 02:54:40 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1437, average loss: 0.0025
[09/16 02:54:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:55:01 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1931, average loss: 0.1190
[09/16 02:55:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.54	top5: 99.51	
[09/16 02:55:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 02:55:09 visual_prompt]: Epoch 23 / 100: avg data time: 7.18e-02, avg batch time: 0.4770, average train loss: 0.0032
[09/16 02:55:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1438, average loss: 0.0025
[09/16 02:55:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:55:33 visual_prompt]: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1926, average loss: 0.1202
[09/16 02:55:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.51	top5: 99.45	
[09/16 02:55:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 02:55:42 visual_prompt]: Epoch 24 / 100: avg data time: 9.62e-02, avg batch time: 0.5039, average train loss: 0.0034
[09/16 02:55:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1440, average loss: 0.0029
[09/16 02:55:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:56:05 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1927, average loss: 0.1211
[09/16 02:56:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.48	top5: 99.45	
[09/16 02:56:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 02:56:13 visual_prompt]: Epoch 25 / 100: avg data time: 8.70e-02, avg batch time: 0.4896, average train loss: 0.0039
[09/16 02:56:16 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 02:56:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:56:37 visual_prompt]: Inference (test):avg data time: 5.74e-03, avg batch time: 0.1914, average loss: 0.1206
[09/16 02:56:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.67	top5: 99.54	
[09/16 02:56:37 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 02:56:45 visual_prompt]: Epoch 26 / 100: avg data time: 8.84e-02, avg batch time: 0.4931, average train loss: 0.0043
[09/16 02:56:48 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1439, average loss: 0.0034
[09/16 02:56:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:57:09 visual_prompt]: Inference (test):avg data time: 7.01e-03, avg batch time: 0.1935, average loss: 0.1190
[09/16 02:57:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.53	
[09/16 02:57:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 02:57:17 visual_prompt]: Epoch 27 / 100: avg data time: 8.40e-02, avg batch time: 0.4870, average train loss: 0.0046
[09/16 02:57:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1439, average loss: 0.0034
[09/16 02:57:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:57:41 visual_prompt]: Inference (test):avg data time: 6.16e-03, avg batch time: 0.1950, average loss: 0.1222
[09/16 02:57:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.74	top5: 99.53	
[09/16 02:57:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 02:57:50 visual_prompt]: Epoch 28 / 100: avg data time: 8.86e-02, avg batch time: 0.4932, average train loss: 0.0047
[09/16 02:57:53 visual_prompt]: Inference (val):avg data time: 3.69e-04, avg batch time: 0.2858, average loss: 0.0040
[09/16 02:57:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:58:14 visual_prompt]: Inference (test):avg data time: 6.55e-03, avg batch time: 0.1929, average loss: 0.1240
[09/16 02:58:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.53	
[09/16 02:58:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 02:58:23 visual_prompt]: Epoch 29 / 100: avg data time: 8.40e-02, avg batch time: 0.4887, average train loss: 0.0050
[09/16 02:58:25 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1437, average loss: 0.0037
[09/16 02:58:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:58:46 visual_prompt]: Inference (test):avg data time: 5.68e-03, avg batch time: 0.1908, average loss: 0.1208
[09/16 02:58:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.61	
[09/16 02:58:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 02:58:55 visual_prompt]: Epoch 30 / 100: avg data time: 8.95e-02, avg batch time: 0.4944, average train loss: 0.0048
[09/16 02:58:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1438, average loss: 0.0035
[09/16 02:58:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:59:18 visual_prompt]: Inference (test):avg data time: 5.84e-03, avg batch time: 0.1967, average loss: 0.1159
[09/16 02:59:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.64	top5: 99.66	
[09/16 02:59:18 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 02:59:27 visual_prompt]: Epoch 31 / 100: avg data time: 9.89e-02, avg batch time: 0.5012, average train loss: 0.0045
[09/16 02:59:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 02:59:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 02:59:51 visual_prompt]: Inference (test):avg data time: 6.60e-03, avg batch time: 0.1919, average loss: 0.1224
[09/16 02:59:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.66	top5: 99.50	
[09/16 02:59:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 02:59:59 visual_prompt]: Epoch 32 / 100: avg data time: 8.50e-02, avg batch time: 0.4900, average train loss: 0.0044
[09/16 03:00:02 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 03:00:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:00:23 visual_prompt]: Inference (test):avg data time: 5.68e-03, avg batch time: 0.1923, average loss: 0.1129
[09/16 03:00:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.85	top5: 99.63	
[09/16 03:00:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 03:00:31 visual_prompt]: Epoch 33 / 100: avg data time: 8.52e-02, avg batch time: 0.4897, average train loss: 0.0043
[09/16 03:00:34 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 03:00:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:00:55 visual_prompt]: Inference (test):avg data time: 8.44e-03, avg batch time: 0.1928, average loss: 0.1141
[09/16 03:00:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.85	top5: 99.58	
[09/16 03:00:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 03:01:04 visual_prompt]: Epoch 34 / 100: avg data time: 8.58e-02, avg batch time: 0.4915, average train loss: 0.0043
[09/16 03:01:06 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1439, average loss: 0.0032
[09/16 03:01:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:01:27 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1927, average loss: 0.1161
[09/16 03:01:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.72	top5: 99.51	
[09/16 03:01:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 03:01:36 visual_prompt]: Epoch 35 / 100: avg data time: 8.33e-02, avg batch time: 0.4892, average train loss: 0.0044
[09/16 03:01:38 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1437, average loss: 0.0034
[09/16 03:01:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:01:59 visual_prompt]: Inference (test):avg data time: 7.10e-03, avg batch time: 0.1931, average loss: 0.1154
[09/16 03:01:59 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.74	top5: 99.58	
[09/16 03:01:59 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 03:02:08 visual_prompt]: Epoch 36 / 100: avg data time: 9.01e-02, avg batch time: 0.4951, average train loss: 0.0044
[09/16 03:02:10 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1436, average loss: 0.0031
[09/16 03:02:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:02:31 visual_prompt]: Inference (test):avg data time: 6.65e-03, avg batch time: 0.1927, average loss: 0.1117
[09/16 03:02:31 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.71	top5: 99.54	
[09/16 03:02:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 03:02:40 visual_prompt]: Epoch 37 / 100: avg data time: 9.54e-02, avg batch time: 0.4996, average train loss: 0.0042
[09/16 03:02:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1435, average loss: 0.0032
[09/16 03:02:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:03:04 visual_prompt]: Inference (test):avg data time: 7.46e-03, avg batch time: 0.1924, average loss: 0.1063
[09/16 03:03:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.97	top5: 99.58	
[09/16 03:03:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 03:03:12 visual_prompt]: Epoch 38 / 100: avg data time: 9.80e-02, avg batch time: 0.5005, average train loss: 0.0041
[09/16 03:03:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 03:03:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:03:35 visual_prompt]: Inference (test):avg data time: 6.43e-03, avg batch time: 0.1910, average loss: 0.1087
[09/16 03:03:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.00	top5: 99.54	
[09/16 03:03:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 03:03:44 visual_prompt]: Epoch 39 / 100: avg data time: 9.05e-02, avg batch time: 0.4955, average train loss: 0.0040
[09/16 03:03:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1435, average loss: 0.0030
[09/16 03:03:47 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:04:08 visual_prompt]: Inference (test):avg data time: 6.20e-03, avg batch time: 0.1916, average loss: 0.1110
[09/16 03:04:08 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.80	top5: 99.51	
[09/16 03:04:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 03:04:16 visual_prompt]: Epoch 40 / 100: avg data time: 9.33e-02, avg batch time: 0.4970, average train loss: 0.0039
[09/16 03:04:19 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1440, average loss: 0.0028
[09/16 03:04:19 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:04:40 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1958, average loss: 0.0997
[09/16 03:04:40 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.95	top5: 99.63	
[09/16 03:04:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 03:04:49 visual_prompt]: Epoch 41 / 100: avg data time: 9.46e-02, avg batch time: 0.4986, average train loss: 0.0039
[09/16 03:04:51 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1437, average loss: 0.0029
[09/16 03:04:51 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:05:12 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1936, average loss: 0.1008
[09/16 03:05:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.00	top5: 99.56	
[09/16 03:05:12 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 03:05:21 visual_prompt]: Epoch 42 / 100: avg data time: 9.25e-02, avg batch time: 0.4951, average train loss: 0.0039
[09/16 03:05:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 03:05:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:05:44 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1920, average loss: 0.1091
[09/16 03:05:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.48	
[09/16 03:05:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 03:05:53 visual_prompt]: Epoch 43 / 100: avg data time: 9.07e-02, avg batch time: 0.4949, average train loss: 0.0039
[09/16 03:05:56 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1439, average loss: 0.0032
[09/16 03:05:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:06:17 visual_prompt]: Inference (test):avg data time: 5.72e-03, avg batch time: 0.1944, average loss: 0.1019
[09/16 03:06:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.00	top5: 99.56	
[09/16 03:06:17 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 03:06:25 visual_prompt]: Epoch 44 / 100: avg data time: 9.26e-02, avg batch time: 0.4952, average train loss: 0.0040
[09/16 03:06:28 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1440, average loss: 0.0032
[09/16 03:06:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:06:49 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1977, average loss: 0.1104
[09/16 03:06:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.82	top5: 99.51	
[09/16 03:06:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 03:06:58 visual_prompt]: Epoch 45 / 100: avg data time: 8.13e-02, avg batch time: 0.4865, average train loss: 2.3691
[09/16 03:07:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1436, average loss: 4.6290
[09/16 03:07:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 3.00	top5: 16.50	
[09/16 03:07:22 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1922, average loss: 4.6299
[09/16 03:07:22 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 2.20	top5: 12.86	
[09/16 03:07:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 03:07:30 visual_prompt]: Epoch 46 / 100: avg data time: 9.94e-02, avg batch time: 0.5029, average train loss: 4.7362
[09/16 03:07:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1439, average loss: 5.0064
[09/16 03:07:33 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 5.50	top5: 13.00	
[09/16 03:07:55 visual_prompt]: Inference (test):avg data time: 7.09e-03, avg batch time: 0.2029, average loss: 4.7581
[09/16 03:07:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.87	top5: 12.16	
[09/16 03:07:55 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 03:08:04 visual_prompt]: Epoch 47 / 100: avg data time: 8.84e-02, avg batch time: 0.4938, average train loss: 4.2390
[09/16 03:08:06 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1450, average loss: 4.0098
[09/16 03:08:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 19.00	top5: 41.50	
[09/16 03:08:27 visual_prompt]: Inference (test):avg data time: 7.01e-03, avg batch time: 0.1917, average loss: 4.1993
[09/16 03:08:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 11.47	top5: 30.98	
[09/16 03:08:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 03:08:36 visual_prompt]: Epoch 48 / 100: avg data time: 7.82e-02, avg batch time: 0.4831, average train loss: 3.6877
[09/16 03:08:38 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1435, average loss: 4.4295
[09/16 03:08:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 20.50	top5: 46.50	
[09/16 03:08:59 visual_prompt]: Inference (test):avg data time: 6.46e-03, avg batch time: 0.1914, average loss: 4.0101
[09/16 03:08:59 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 14.98	top5: 39.65	
[09/16 03:08:59 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 03:09:07 visual_prompt]: Epoch 49 / 100: avg data time: 8.30e-02, avg batch time: 0.4865, average train loss: 3.7373
[09/16 03:09:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1440, average loss: 3.0188
[09/16 03:09:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 52.00	top5: 71.50	
[09/16 03:09:31 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1917, average loss: 3.1997
[09/16 03:09:31 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 35.86	top5: 58.58	
[09/16 03:09:31 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 03:09:39 visual_prompt]: Epoch 50 / 100: avg data time: 8.87e-02, avg batch time: 0.4927, average train loss: 2.4345
[09/16 03:09:42 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1436, average loss: 1.7089
[09/16 03:09:42 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 72.50	top5: 88.50	
[09/16 03:10:04 visual_prompt]: Inference (test):avg data time: 6.58e-03, avg batch time: 0.2023, average loss: 2.2402
[09/16 03:10:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 50.11	top5: 73.57	
[09/16 03:10:04 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 03:10:13 visual_prompt]: Epoch 51 / 100: avg data time: 9.29e-02, avg batch time: 0.4960, average train loss: 1.2490
[09/16 03:10:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1438, average loss: 0.7674
[09/16 03:10:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 80.00	top5: 96.00	
[09/16 03:10:36 visual_prompt]: Inference (test):avg data time: 4.37e-03, avg batch time: 0.1912, average loss: 1.4617
[09/16 03:10:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 61.23	top5: 86.60	
[09/16 03:10:36 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 03:10:45 visual_prompt]: Epoch 52 / 100: avg data time: 7.65e-02, avg batch time: 0.4826, average train loss: 0.5652
[09/16 03:10:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1439, average loss: 0.3148
[09/16 03:10:47 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 91.00	top5: 99.00	
[09/16 03:11:08 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1940, average loss: 0.9448
[09/16 03:11:08 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 75.67	top5: 92.18	
[09/16 03:11:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 03:11:17 visual_prompt]: Epoch 53 / 100: avg data time: 8.08e-02, avg batch time: 0.4847, average train loss: 0.2978
[09/16 03:11:19 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1438, average loss: 0.0983
[09/16 03:11:19 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.00	top5: 100.00	
[09/16 03:11:40 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1929, average loss: 0.6520
[09/16 03:11:40 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 82.79	top5: 95.20	
[09/16 03:11:40 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 03:11:49 visual_prompt]: Epoch 54 / 100: avg data time: 8.47e-02, avg batch time: 0.5010, average train loss: 0.1419
[09/16 03:11:52 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1437, average loss: 0.0926
[09/16 03:11:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 03:12:13 visual_prompt]: Inference (test):avg data time: 5.94e-03, avg batch time: 0.1926, average loss: 0.6037
[09/16 03:12:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 84.14	top5: 96.34	
[09/16 03:12:13 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 03:12:21 visual_prompt]: Epoch 55 / 100: avg data time: 8.95e-02, avg batch time: 0.4920, average train loss: 0.0776
[09/16 03:12:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1436, average loss: 0.0400
[09/16 03:12:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 03:12:45 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1930, average loss: 0.4946
[09/16 03:12:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 86.27	top5: 96.78	
[09/16 03:12:45 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 03:12:54 visual_prompt]: Epoch 56 / 100: avg data time: 9.51e-02, avg batch time: 0.4966, average train loss: 0.0369
[09/16 03:12:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1440, average loss: 0.0234
[09/16 03:12:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 03:13:17 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1926, average loss: 0.4844
[09/16 03:13:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.36	top5: 97.19	
[09/16 03:13:17 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 03:13:26 visual_prompt]: Epoch 57 / 100: avg data time: 7.83e-02, avg batch time: 0.4819, average train loss: 0.0201
[09/16 03:13:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1438, average loss: 0.0083
[09/16 03:13:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:13:49 visual_prompt]: Inference (test):avg data time: 7.74e-03, avg batch time: 0.1925, average loss: 0.3879
[09/16 03:13:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.69	top5: 97.71	
[09/16 03:13:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 03:13:57 visual_prompt]: Epoch 58 / 100: avg data time: 8.40e-02, avg batch time: 0.4890, average train loss: 0.0088
[09/16 03:14:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1436, average loss: 0.0047
[09/16 03:14:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:14:21 visual_prompt]: Inference (test):avg data time: 7.69e-03, avg batch time: 0.1931, average loss: 0.3652
[09/16 03:14:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.40	top5: 97.79	
[09/16 03:14:21 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 03:14:30 visual_prompt]: Epoch 59 / 100: avg data time: 9.16e-02, avg batch time: 0.4971, average train loss: 0.0069
[09/16 03:14:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1439, average loss: 0.0152
[09/16 03:14:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:14:53 visual_prompt]: Inference (test):avg data time: 6.27e-03, avg batch time: 0.1945, average loss: 0.4008
[09/16 03:14:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.93	top5: 97.41	
[09/16 03:14:53 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 03:15:02 visual_prompt]: Epoch 60 / 100: avg data time: 9.36e-02, avg batch time: 0.4963, average train loss: 0.0063
[09/16 03:15:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1437, average loss: 0.0054
[09/16 03:15:05 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:15:26 visual_prompt]: Inference (test):avg data time: 6.91e-03, avg batch time: 0.1923, average loss: 0.3693
[09/16 03:15:26 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.18	top5: 97.72	
[09/16 03:15:26 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 03:15:34 visual_prompt]: Epoch 61 / 100: avg data time: 8.84e-02, avg batch time: 0.4914, average train loss: 0.0050
[09/16 03:15:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.0039
[09/16 03:15:37 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:15:58 visual_prompt]: Inference (test):avg data time: 5.28e-03, avg batch time: 0.1915, average loss: 0.3308
[09/16 03:15:58 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.15	top5: 98.03	
[09/16 03:15:58 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 03:16:06 visual_prompt]: Epoch 62 / 100: avg data time: 8.63e-02, avg batch time: 0.4921, average train loss: 0.0045
[09/16 03:16:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1437, average loss: 0.0037
[09/16 03:16:09 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:16:30 visual_prompt]: Inference (test):avg data time: 6.88e-03, avg batch time: 0.1921, average loss: 0.3334
[09/16 03:16:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.15	top5: 97.93	
[09/16 03:16:30 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 03:16:38 visual_prompt]: Epoch 63 / 100: avg data time: 8.34e-02, avg batch time: 0.4877, average train loss: 0.0043
[09/16 03:16:41 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1436, average loss: 0.0037
[09/16 03:16:41 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:17:02 visual_prompt]: Inference (test):avg data time: 5.86e-03, avg batch time: 0.1914, average loss: 0.3353
[09/16 03:17:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.09	top5: 97.92	
[09/16 03:17:02 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 03:17:10 visual_prompt]: Epoch 64 / 100: avg data time: 8.61e-02, avg batch time: 0.4918, average train loss: 0.0042
[09/16 03:17:13 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1437, average loss: 0.0038
[09/16 03:17:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:17:34 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1923, average loss: 0.3278
[09/16 03:17:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.35	top5: 97.98	
[09/16 03:17:34 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 03:17:43 visual_prompt]: Epoch 65 / 100: avg data time: 8.87e-02, avg batch time: 0.4914, average train loss: 0.0041
[09/16 03:17:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1436, average loss: 0.0040
[09/16 03:17:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:18:06 visual_prompt]: Inference (test):avg data time: 6.92e-03, avg batch time: 0.1932, average loss: 0.3273
[09/16 03:18:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.28	top5: 97.93	
[09/16 03:18:06 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 03:18:15 visual_prompt]: Epoch 66 / 100: avg data time: 9.25e-02, avg batch time: 0.4954, average train loss: 0.0046
[09/16 03:18:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1438, average loss: 0.0042
[09/16 03:18:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:18:38 visual_prompt]: Inference (test):avg data time: 5.82e-03, avg batch time: 0.1920, average loss: 0.3283
[09/16 03:18:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.38	top5: 98.00	
[09/16 03:18:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 03:18:47 visual_prompt]: Epoch 67 / 100: avg data time: 9.83e-02, avg batch time: 0.5028, average train loss: 0.0046
[09/16 03:18:49 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1440, average loss: 0.0044
[09/16 03:18:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:19:10 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1924, average loss: 0.3239
[09/16 03:19:10 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.51	top5: 98.02	
[09/16 03:19:10 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 03:19:19 visual_prompt]: Epoch 68 / 100: avg data time: 8.43e-02, avg batch time: 0.4902, average train loss: 0.0049
[09/16 03:19:22 visual_prompt]: Inference (val):avg data time: 4.18e-04, avg batch time: 0.2224, average loss: 0.0046
[09/16 03:19:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:19:43 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1927, average loss: 0.3244
[09/16 03:19:43 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.56	top5: 98.00	
[09/16 03:19:43 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 03:19:52 visual_prompt]: Epoch 69 / 100: avg data time: 9.19e-02, avg batch time: 0.4971, average train loss: 0.0052
[09/16 03:19:54 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1440, average loss: 0.0047
[09/16 03:19:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:20:15 visual_prompt]: Inference (test):avg data time: 5.41e-03, avg batch time: 0.1928, average loss: 0.3220
[09/16 03:20:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.66	top5: 98.10	
[09/16 03:20:15 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 03:20:24 visual_prompt]: Epoch 70 / 100: avg data time: 9.14e-02, avg batch time: 0.4956, average train loss: 0.0056
[09/16 03:20:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1439, average loss: 0.0049
[09/16 03:20:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:20:47 visual_prompt]: Inference (test):avg data time: 6.73e-03, avg batch time: 0.1921, average loss: 0.3221
[09/16 03:20:47 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.66	top5: 98.08	
[09/16 03:20:47 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 03:20:56 visual_prompt]: Epoch 71 / 100: avg data time: 7.99e-02, avg batch time: 0.5160, average train loss: 0.0056
[09/16 03:20:59 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1439, average loss: 0.0053
[09/16 03:20:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:21:20 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1979, average loss: 0.3270
[09/16 03:21:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.38	top5: 98.08	
[09/16 03:21:21 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 03:21:29 visual_prompt]: Epoch 72 / 100: avg data time: 9.01e-02, avg batch time: 0.4937, average train loss: 0.0060
[09/16 03:21:32 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1437, average loss: 0.0053
[09/16 03:21:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:21:53 visual_prompt]: Inference (test):avg data time: 6.11e-03, avg batch time: 0.1910, average loss: 0.3233
[09/16 03:21:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.49	top5: 98.03	
[09/16 03:21:53 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 03:22:01 visual_prompt]: Epoch 73 / 100: avg data time: 9.58e-02, avg batch time: 0.4973, average train loss: 0.0062
[09/16 03:22:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1438, average loss: 0.0055
[09/16 03:22:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:22:25 visual_prompt]: Inference (test):avg data time: 6.49e-03, avg batch time: 0.1973, average loss: 0.3242
[09/16 03:22:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.69	top5: 97.98	
[09/16 03:22:25 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 03:22:34 visual_prompt]: Epoch 74 / 100: avg data time: 9.26e-02, avg batch time: 0.4951, average train loss: 0.0063
[09/16 03:22:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1440, average loss: 0.0055
[09/16 03:22:37 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:22:58 visual_prompt]: Inference (test):avg data time: 6.23e-03, avg batch time: 0.2016, average loss: 0.3244
[09/16 03:22:58 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.64	top5: 97.93	
[09/16 03:22:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 03:23:07 visual_prompt]: Epoch 75 / 100: avg data time: 8.54e-02, avg batch time: 0.4908, average train loss: 0.0063
[09/16 03:23:10 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1438, average loss: 0.0055
[09/16 03:23:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:23:30 visual_prompt]: Inference (test):avg data time: 6.88e-03, avg batch time: 0.1916, average loss: 0.3207
[09/16 03:23:31 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.75	top5: 98.02	
[09/16 03:23:31 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 03:23:39 visual_prompt]: Epoch 76 / 100: avg data time: 8.37e-02, avg batch time: 0.4883, average train loss: 0.0066
[09/16 03:23:42 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1439, average loss: 0.0056
[09/16 03:23:42 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:24:02 visual_prompt]: Inference (test):avg data time: 6.94e-03, avg batch time: 0.1916, average loss: 0.3246
[09/16 03:24:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.62	top5: 98.05	
[09/16 03:24:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 03:24:11 visual_prompt]: Epoch 77 / 100: avg data time: 7.36e-02, avg batch time: 0.4800, average train loss: 0.0065
[09/16 03:24:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1437, average loss: 0.0057
[09/16 03:24:14 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:24:34 visual_prompt]: Inference (test):avg data time: 7.10e-03, avg batch time: 0.1918, average loss: 0.3165
[09/16 03:24:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.88	top5: 98.10	
[09/16 03:24:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 03:24:43 visual_prompt]: Epoch 78 / 100: avg data time: 8.62e-02, avg batch time: 0.4897, average train loss: 0.0066
[09/16 03:24:46 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1439, average loss: 0.0059
[09/16 03:24:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:25:07 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1933, average loss: 0.3203
[09/16 03:25:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.80	top5: 98.18	
[09/16 03:25:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 03:25:15 visual_prompt]: Epoch 79 / 100: avg data time: 8.20e-02, avg batch time: 0.4893, average train loss: 0.0070
[09/16 03:25:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1444, average loss: 0.0060
[09/16 03:25:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:25:38 visual_prompt]: Inference (test):avg data time: 6.91e-03, avg batch time: 0.1932, average loss: 0.3177
[09/16 03:25:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.79	top5: 98.08	
[09/16 03:25:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 03:25:47 visual_prompt]: Epoch 80 / 100: avg data time: 9.66e-02, avg batch time: 0.5008, average train loss: 0.0069
[09/16 03:25:50 visual_prompt]: Inference (val):avg data time: 4.40e-05, avg batch time: 0.1438, average loss: 0.0059
[09/16 03:25:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:26:11 visual_prompt]: Inference (test):avg data time: 5.59e-03, avg batch time: 0.1907, average loss: 0.3108
[09/16 03:26:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.90	top5: 98.24	
[09/16 03:26:11 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 03:26:20 visual_prompt]: Epoch 81 / 100: avg data time: 9.48e-02, avg batch time: 0.4977, average train loss: 0.0067
[09/16 03:26:22 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1438, average loss: 0.0059
[09/16 03:26:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:26:43 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1939, average loss: 0.3124
[09/16 03:26:43 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.87	top5: 98.18	
[09/16 03:26:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 03:26:52 visual_prompt]: Epoch 82 / 100: avg data time: 8.21e-02, avg batch time: 0.4857, average train loss: 0.0067
[09/16 03:26:54 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1439, average loss: 0.0058
[09/16 03:26:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:27:15 visual_prompt]: Inference (test):avg data time: 5.80e-03, avg batch time: 0.1918, average loss: 0.3147
[09/16 03:27:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.71	top5: 98.19	
[09/16 03:27:15 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 03:27:24 visual_prompt]: Epoch 83 / 100: avg data time: 9.60e-02, avg batch time: 0.4992, average train loss: 0.0068
[09/16 03:27:26 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1437, average loss: 0.0058
[09/16 03:27:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:27:47 visual_prompt]: Inference (test):avg data time: 6.48e-03, avg batch time: 0.1915, average loss: 0.3109
[09/16 03:27:47 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.82	top5: 98.21	
[09/16 03:27:47 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 03:27:56 visual_prompt]: Epoch 84 / 100: avg data time: 8.44e-02, avg batch time: 0.4899, average train loss: 0.0067
[09/16 03:27:58 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1437, average loss: 0.0057
[09/16 03:27:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:28:19 visual_prompt]: Inference (test):avg data time: 5.53e-03, avg batch time: 0.1909, average loss: 0.3126
[09/16 03:28:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.97	top5: 98.15	
[09/16 03:28:19 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 03:28:28 visual_prompt]: Epoch 85 / 100: avg data time: 8.32e-02, avg batch time: 0.4900, average train loss: 0.0066
[09/16 03:28:30 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1439, average loss: 0.0056
[09/16 03:28:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:28:51 visual_prompt]: Inference (test):avg data time: 7.01e-03, avg batch time: 0.1922, average loss: 0.3132
[09/16 03:28:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.92	top5: 98.15	
[09/16 03:28:51 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 03:29:00 visual_prompt]: Epoch 86 / 100: avg data time: 7.21e-02, avg batch time: 0.5107, average train loss: 0.0065
[09/16 03:29:03 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1436, average loss: 0.0056
[09/16 03:29:03 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:29:23 visual_prompt]: Inference (test):avg data time: 5.64e-03, avg batch time: 0.1905, average loss: 0.3118
[09/16 03:29:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.98	top5: 98.11	
[09/16 03:29:23 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 03:29:32 visual_prompt]: Epoch 87 / 100: avg data time: 8.82e-02, avg batch time: 0.4898, average train loss: 0.0064
[09/16 03:29:34 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1438, average loss: 0.0055
[09/16 03:29:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:29:56 visual_prompt]: Inference (test):avg data time: 6.50e-03, avg batch time: 0.1946, average loss: 0.3111
[09/16 03:29:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.98	top5: 98.19	
[09/16 03:29:56 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 03:30:04 visual_prompt]: Epoch 88 / 100: avg data time: 8.84e-02, avg batch time: 0.4909, average train loss: 0.0065
[09/16 03:30:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1439, average loss: 0.0054
[09/16 03:30:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:30:28 visual_prompt]: Inference (test):avg data time: 6.19e-03, avg batch time: 0.1917, average loss: 0.3111
[09/16 03:30:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.03	top5: 98.15	
[09/16 03:30:28 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 03:30:36 visual_prompt]: Epoch 89 / 100: avg data time: 8.26e-02, avg batch time: 0.4868, average train loss: 0.0065
[09/16 03:30:39 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1441, average loss: 0.0054
[09/16 03:30:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:30:59 visual_prompt]: Inference (test):avg data time: 5.55e-03, avg batch time: 0.1912, average loss: 0.3112
[09/16 03:31:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.05	top5: 98.13	
[09/16 03:31:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 03:31:08 visual_prompt]: Epoch 90 / 100: avg data time: 8.46e-02, avg batch time: 0.4912, average train loss: 0.0065
[09/16 03:31:11 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1438, average loss: 0.0053
[09/16 03:31:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:31:32 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1918, average loss: 0.3123
[09/16 03:31:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.08	top5: 98.16	
[09/16 03:31:32 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 03:31:40 visual_prompt]: Epoch 91 / 100: avg data time: 9.37e-02, avg batch time: 0.4968, average train loss: 0.0065
[09/16 03:31:43 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1435, average loss: 0.0054
[09/16 03:31:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:32:04 visual_prompt]: Inference (test):avg data time: 8.05e-03, avg batch time: 0.1946, average loss: 0.3124
[09/16 03:32:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.08	top5: 98.11	
[09/16 03:32:04 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 03:32:13 visual_prompt]: Epoch 92 / 100: avg data time: 9.57e-02, avg batch time: 0.5017, average train loss: 0.0064
[09/16 03:32:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1436, average loss: 0.0054
[09/16 03:32:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:32:36 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1932, average loss: 0.3111
[09/16 03:32:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.10	top5: 98.10	
[09/16 03:32:36 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 03:32:45 visual_prompt]: Epoch 93 / 100: avg data time: 9.31e-02, avg batch time: 0.4979, average train loss: 0.0065
[09/16 03:32:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1438, average loss: 0.0054
[09/16 03:32:47 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:33:08 visual_prompt]: Inference (test):avg data time: 4.55e-03, avg batch time: 0.1906, average loss: 0.3128
[09/16 03:33:08 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.00	top5: 98.13	
[09/16 03:33:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 03:33:16 visual_prompt]: Epoch 94 / 100: avg data time: 9.38e-02, avg batch time: 0.4969, average train loss: 0.0062
[09/16 03:33:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1441, average loss: 0.0053
[09/16 03:33:19 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:33:40 visual_prompt]: Inference (test):avg data time: 8.92e-03, avg batch time: 0.1947, average loss: 0.3121
[09/16 03:33:40 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.11	top5: 98.10	
[09/16 03:33:40 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 03:33:49 visual_prompt]: Epoch 95 / 100: avg data time: 8.34e-02, avg batch time: 0.4990, average train loss: 0.0063
[09/16 03:33:51 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1439, average loss: 0.0053
[09/16 03:33:51 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:34:12 visual_prompt]: Inference (test):avg data time: 6.24e-03, avg batch time: 0.1907, average loss: 0.3116
[09/16 03:34:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.13	top5: 98.15	
[09/16 03:34:12 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 03:34:21 visual_prompt]: Epoch 96 / 100: avg data time: 9.23e-02, avg batch time: 0.4971, average train loss: 0.0063
[09/16 03:34:24 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1482, average loss: 0.0052
[09/16 03:34:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:34:45 visual_prompt]: Inference (test):avg data time: 6.91e-03, avg batch time: 0.1928, average loss: 0.3108
[09/16 03:34:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.15	top5: 98.13	
[09/16 03:34:45 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 03:34:54 visual_prompt]: Epoch 97 / 100: avg data time: 9.41e-02, avg batch time: 0.5087, average train loss: 0.0063
[09/16 03:34:56 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1439, average loss: 0.0053
[09/16 03:34:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:35:17 visual_prompt]: Inference (test):avg data time: 8.03e-03, avg batch time: 0.1942, average loss: 0.3112
[09/16 03:35:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.13	top5: 98.11	
[09/16 03:35:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 03:35:26 visual_prompt]: Epoch 98 / 100: avg data time: 9.57e-02, avg batch time: 0.4984, average train loss: 0.0064
[09/16 03:35:28 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1437, average loss: 0.0053
[09/16 03:35:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:35:49 visual_prompt]: Inference (test):avg data time: 7.16e-03, avg batch time: 0.1929, average loss: 0.3116
[09/16 03:35:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.06	top5: 98.11	
[09/16 03:35:49 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 03:35:58 visual_prompt]: Epoch 99 / 100: avg data time: 8.72e-02, avg batch time: 0.4917, average train loss: 0.0063
[09/16 03:36:01 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1442, average loss: 0.0053
[09/16 03:36:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:36:22 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1987, average loss: 0.3116
[09/16 03:36:22 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.05	top5: 98.10	
[09/16 03:36:22 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 03:36:31 visual_prompt]: Epoch 100 / 100: avg data time: 9.22e-02, avg batch time: 0.4951, average train loss: 0.0064
[09/16 03:36:33 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1437, average loss: 0.0053
[09/16 03:36:33 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:36:54 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1929, average loss: 0.3116
[09/16 03:36:54 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.05	top5: 98.10	
[09/16 03:37:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 03:37:27 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 03:37:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-oxford_flowers102', 'DATA.NUMBER_CLASSES', '102', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/16 03:37:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 03:37:27 visual_prompt]: Training with config:
[09/16 03:37:27 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-oxford_flowers102',
          'NO_TEST': False,
          'NUMBER_CLASSES': 102,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-oxford_flowers102/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 03:37:27 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 03:37:27.571886: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 03:37:27.765882: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 03:37:28.654648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:37:28.654741: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:37:28.654750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 03:37:30.662768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:37:30.662869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:37:30.662883: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 03:37:30 visual_prompt]: Constructing vtab-oxford_flowers102 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
2023-09-16 03:37:30.687677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 03:37:33 visual_prompt]: Number of images: 1000
[09/16 03:37:33 visual_prompt]: Number of classes: 102 / 102
[09/16 03:37:33 visual_prompt]: Loading validation data...
[09/16 03:37:33 visual_prompt]: Constructing vtab-oxford_flowers102 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 03:37:34 visual_prompt]: Number of images: 200
[09/16 03:37:34 visual_prompt]: Number of classes: 90 / 102
[09/16 03:37:34 visual_prompt]: Loading test data...
[09/16 03:37:34 visual_prompt]: Constructing vtab-oxford_flowers102 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split test, from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 03:37:48 visual_prompt]: Number of images: 6149
[09/16 03:37:48 visual_prompt]: Number of classes: 102 / 102
[09/16 03:37:48 visual_prompt]: Constructing models...
[09/16 03:37:51 visual_prompt]: Total Parameters: 86798694	 Gradient Parameters: 1000038
[09/16 03:37:51 visual_prompt]: tuned percent:1.152
[09/16 03:37:53 visual_prompt]: Device used for model: 0
[09/16 03:37:53 visual_prompt]: Setting up Evalutator...
[09/16 03:37:53 visual_prompt]: Setting up Trainer...
[09/16 03:37:53 visual_prompt]: 	Setting up the optimizer...
[09/16 03:37:53 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 03:38:03 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e-01, avg batch time: 0.5823, average train loss: 4.6675
[09/16 03:38:06 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1431, average loss: 4.6572
[09/16 03:38:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.00	top5: 5.50	
[09/16 03:38:26 visual_prompt]: Inference (test):avg data time: 7.29e-03, avg batch time: 0.1903, average loss: 4.6998
[09/16 03:38:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 1.11	top5: 3.87	
[09/16 03:38:27 visual_prompt]: Best epoch 1: best metric: 0.010
[09/16 03:38:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 03:38:35 visual_prompt]: Epoch 2 / 100: avg data time: 8.84e-02, avg batch time: 0.4909, average train loss: 4.6339
[09/16 03:38:38 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1464, average loss: 4.3224
[09/16 03:38:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 4.50	top5: 21.00	
[09/16 03:38:58 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1923, average loss: 4.4214
[09/16 03:38:59 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 2.03	top5: 12.54	
[09/16 03:38:59 visual_prompt]: Best epoch 2: best metric: 0.045
[09/16 03:38:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 03:39:08 visual_prompt]: Epoch 3 / 100: avg data time: 9.09e-02, avg batch time: 0.5243, average train loss: 4.6052
[09/16 03:39:10 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1435, average loss: 3.9699
[09/16 03:39:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 7.50	top5: 30.50	
[09/16 03:39:32 visual_prompt]: Inference (test):avg data time: 5.50e-03, avg batch time: 0.1970, average loss: 4.1692
[09/16 03:39:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.77	top5: 23.32	
[09/16 03:39:32 visual_prompt]: Best epoch 3: best metric: 0.075
[09/16 03:39:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 03:39:40 visual_prompt]: Epoch 4 / 100: avg data time: 8.67e-02, avg batch time: 0.4921, average train loss: 3.3944
[09/16 03:39:43 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1436, average loss: 1.8209
[09/16 03:39:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 55.50	top5: 80.00	
[09/16 03:40:04 visual_prompt]: Inference (test):avg data time: 5.55e-03, avg batch time: 0.1902, average loss: 2.4332
[09/16 03:40:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 43.83	top5: 66.61	
[09/16 03:40:04 visual_prompt]: Best epoch 4: best metric: 0.555
[09/16 03:40:04 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 03:40:12 visual_prompt]: Epoch 5 / 100: avg data time: 9.71e-02, avg batch time: 0.4999, average train loss: 0.9533
[09/16 03:40:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1437, average loss: 0.2900
[09/16 03:40:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 92.00	top5: 100.00	
[09/16 03:40:36 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1933, average loss: 0.6730
[09/16 03:40:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 81.40	top5: 96.28	
[09/16 03:40:36 visual_prompt]: Best epoch 5: best metric: 0.920
[09/16 03:40:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 03:40:45 visual_prompt]: Epoch 6 / 100: avg data time: 8.71e-02, avg batch time: 0.4931, average train loss: 0.1011
[09/16 03:40:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1439, average loss: 0.1481
[09/16 03:40:47 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 96.50	top5: 99.50	
[09/16 03:41:09 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1986, average loss: 0.6229
[09/16 03:41:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 85.43	top5: 95.76	
[09/16 03:41:09 visual_prompt]: Best epoch 6: best metric: 0.965
[09/16 03:41:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 03:41:17 visual_prompt]: Epoch 7 / 100: avg data time: 8.76e-02, avg batch time: 0.4909, average train loss: 0.0718
[09/16 03:41:20 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1436, average loss: 0.0773
[09/16 03:41:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.50	top5: 99.50	
[09/16 03:41:41 visual_prompt]: Inference (test):avg data time: 6.75e-03, avg batch time: 0.1922, average loss: 0.3127
[09/16 03:41:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.40	top5: 98.24	
[09/16 03:41:41 visual_prompt]: Best epoch 7: best metric: 0.975
[09/16 03:41:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 03:41:49 visual_prompt]: Epoch 8 / 100: avg data time: 8.45e-02, avg batch time: 0.4933, average train loss: 0.0264
[09/16 03:41:52 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1437, average loss: 0.0172
[09/16 03:41:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 03:42:13 visual_prompt]: Inference (test):avg data time: 6.01e-03, avg batch time: 0.1910, average loss: 0.2800
[09/16 03:42:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.67	top5: 98.81	
[09/16 03:42:13 visual_prompt]: Best epoch 8: best metric: 0.995
[09/16 03:42:13 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 03:42:21 visual_prompt]: Epoch 9 / 100: avg data time: 7.60e-02, avg batch time: 0.4827, average train loss: 0.0314
[09/16 03:42:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1437, average loss: 0.0141
[09/16 03:42:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 03:42:45 visual_prompt]: Inference (test):avg data time: 7.84e-03, avg batch time: 0.1926, average loss: 0.2494
[09/16 03:42:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.62	top5: 98.55	
[09/16 03:42:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 03:42:54 visual_prompt]: Epoch 10 / 100: avg data time: 9.06e-02, avg batch time: 0.4958, average train loss: 0.0044
[09/16 03:42:56 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1438, average loss: 0.0021
[09/16 03:42:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:43:17 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1914, average loss: 0.1597
[09/16 03:43:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.90	top5: 99.22	
[09/16 03:43:17 visual_prompt]: Best epoch 10: best metric: 1.000
[09/16 03:43:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 03:43:26 visual_prompt]: Epoch 11 / 100: avg data time: 8.44e-02, avg batch time: 0.4876, average train loss: 0.0024
[09/16 03:43:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1439, average loss: 0.0015
[09/16 03:43:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:43:49 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1981, average loss: 0.1365
[09/16 03:43:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.57	top5: 99.30	
[09/16 03:43:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 03:43:58 visual_prompt]: Epoch 12 / 100: avg data time: 8.13e-02, avg batch time: 0.4863, average train loss: 0.0018
[09/16 03:44:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1439, average loss: 0.0017
[09/16 03:44:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:44:21 visual_prompt]: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1927, average loss: 0.1301
[09/16 03:44:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.85	top5: 99.41	
[09/16 03:44:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 03:44:30 visual_prompt]: Epoch 13 / 100: avg data time: 7.45e-02, avg batch time: 0.4820, average train loss: 0.0022
[09/16 03:44:32 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1437, average loss: 0.0022
[09/16 03:44:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:44:54 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1956, average loss: 0.1267
[09/16 03:44:54 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.07	top5: 99.41	
[09/16 03:44:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 03:45:02 visual_prompt]: Epoch 14 / 100: avg data time: 8.31e-02, avg batch time: 0.4863, average train loss: 0.0030
[09/16 03:45:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1439, average loss: 0.0028
[09/16 03:45:05 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:45:26 visual_prompt]: Inference (test):avg data time: 6.22e-03, avg batch time: 0.1911, average loss: 0.1247
[09/16 03:45:26 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.22	top5: 99.43	
[09/16 03:45:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 03:45:35 visual_prompt]: Epoch 15 / 100: avg data time: 9.56e-02, avg batch time: 0.5043, average train loss: 0.0036
[09/16 03:45:37 visual_prompt]: Inference (val):avg data time: 4.62e-05, avg batch time: 0.1440, average loss: 0.0032
[09/16 03:45:37 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:45:58 visual_prompt]: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1923, average loss: 0.1235
[09/16 03:45:58 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.35	top5: 99.43	
[09/16 03:45:58 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 03:46:07 visual_prompt]: Epoch 16 / 100: avg data time: 8.14e-02, avg batch time: 0.4865, average train loss: 0.0042
[09/16 03:46:09 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1441, average loss: 0.0036
[09/16 03:46:09 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:46:30 visual_prompt]: Inference (test):avg data time: 5.29e-03, avg batch time: 0.1907, average loss: 0.1276
[09/16 03:46:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.40	top5: 99.45	
[09/16 03:46:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 03:46:38 visual_prompt]: Epoch 17 / 100: avg data time: 8.73e-02, avg batch time: 0.4930, average train loss: 0.0048
[09/16 03:46:41 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1442, average loss: 0.0038
[09/16 03:46:41 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:47:02 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1925, average loss: 0.1242
[09/16 03:47:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.54	top5: 99.48	
[09/16 03:47:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 03:47:11 visual_prompt]: Epoch 18 / 100: avg data time: 9.34e-02, avg batch time: 0.4988, average train loss: 0.0051
[09/16 03:47:13 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1437, average loss: 0.0041
[09/16 03:47:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:47:34 visual_prompt]: Inference (test):avg data time: 5.56e-03, avg batch time: 0.1921, average loss: 0.1262
[09/16 03:47:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.51	top5: 99.50	
[09/16 03:47:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 03:47:43 visual_prompt]: Epoch 19 / 100: avg data time: 9.44e-02, avg batch time: 0.5056, average train loss: 0.0053
[09/16 03:47:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1438, average loss: 0.0038
[09/16 03:47:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:48:07 visual_prompt]: Inference (test):avg data time: 6.04e-03, avg batch time: 0.1919, average loss: 0.1237
[09/16 03:48:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.58	top5: 99.48	
[09/16 03:48:07 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 03:48:15 visual_prompt]: Epoch 20 / 100: avg data time: 9.80e-02, avg batch time: 0.5016, average train loss: 0.0053
[09/16 03:48:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1437, average loss: 0.0039
[09/16 03:48:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:48:39 visual_prompt]: Inference (test):avg data time: 6.24e-03, avg batch time: 0.1926, average loss: 0.1277
[09/16 03:48:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.53	top5: 99.48	
[09/16 03:48:39 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 03:48:48 visual_prompt]: Epoch 21 / 100: avg data time: 9.18e-02, avg batch time: 0.4950, average train loss: 0.0053
[09/16 03:48:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1438, average loss: 0.0037
[09/16 03:48:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:49:11 visual_prompt]: Inference (test):avg data time: 7.31e-03, avg batch time: 0.1924, average loss: 0.1129
[09/16 03:49:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.85	top5: 99.63	
[09/16 03:49:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 03:49:20 visual_prompt]: Epoch 22 / 100: avg data time: 9.37e-02, avg batch time: 0.4988, average train loss: 0.0053
[09/16 03:49:23 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1436, average loss: 0.0036
[09/16 03:49:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:49:43 visual_prompt]: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1921, average loss: 0.1241
[09/16 03:49:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.51	top5: 99.50	
[09/16 03:49:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 03:49:52 visual_prompt]: Epoch 23 / 100: avg data time: 8.50e-02, avg batch time: 0.4903, average train loss: 0.0048
[09/16 03:49:55 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1439, average loss: 0.0034
[09/16 03:49:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:50:15 visual_prompt]: Inference (test):avg data time: 6.65e-03, avg batch time: 0.1907, average loss: 0.1172
[09/16 03:50:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.90	top5: 99.54	
[09/16 03:50:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 03:50:24 visual_prompt]: Epoch 24 / 100: avg data time: 9.49e-02, avg batch time: 0.4965, average train loss: 0.0047
[09/16 03:50:27 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1439, average loss: 0.0035
[09/16 03:50:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:50:47 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1922, average loss: 0.1241
[09/16 03:50:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.61	top5: 99.53	
[09/16 03:50:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 03:50:56 visual_prompt]: Epoch 25 / 100: avg data time: 9.49e-02, avg batch time: 0.4989, average train loss: 0.0049
[09/16 03:50:59 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1439, average loss: 0.0036
[09/16 03:50:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:51:20 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1926, average loss: 0.1196
[09/16 03:51:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.51	top5: 99.54	
[09/16 03:51:20 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 03:51:28 visual_prompt]: Epoch 26 / 100: avg data time: 8.88e-02, avg batch time: 0.4950, average train loss: 0.0046
[09/16 03:51:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1445, average loss: 0.0034
[09/16 03:51:31 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:51:52 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1915, average loss: 0.1044
[09/16 03:51:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.10	top5: 99.56	
[09/16 03:51:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 03:52:01 visual_prompt]: Epoch 27 / 100: avg data time: 9.20e-02, avg batch time: 0.4971, average train loss: 0.0045
[09/16 03:52:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 03:52:03 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:52:24 visual_prompt]: Inference (test):avg data time: 6.19e-03, avg batch time: 0.1915, average loss: 0.1196
[09/16 03:52:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.63	top5: 99.46	
[09/16 03:52:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 03:52:33 visual_prompt]: Epoch 28 / 100: avg data time: 8.55e-02, avg batch time: 0.4896, average train loss: 0.0044
[09/16 03:52:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1439, average loss: 0.0038
[09/16 03:52:35 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:52:56 visual_prompt]: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1918, average loss: 0.1335
[09/16 03:52:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.20	top5: 99.45	
[09/16 03:52:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 03:53:05 visual_prompt]: Epoch 29 / 100: avg data time: 9.52e-02, avg batch time: 0.4990, average train loss: 0.0047
[09/16 03:53:07 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1439, average loss: 0.0036
[09/16 03:53:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:53:28 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1922, average loss: 0.1220
[09/16 03:53:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.67	top5: 99.53	
[09/16 03:53:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 03:53:37 visual_prompt]: Epoch 30 / 100: avg data time: 9.53e-02, avg batch time: 0.4993, average train loss: 0.0048
[09/16 03:53:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1439, average loss: 0.0037
[09/16 03:53:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:54:01 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1927, average loss: 0.1359
[09/16 03:54:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.12	top5: 99.43	
[09/16 03:54:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 03:54:10 visual_prompt]: Epoch 31 / 100: avg data time: 9.66e-02, avg batch time: 0.5008, average train loss: 0.8027
[09/16 03:54:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1436, average loss: 4.6349
[09/16 03:54:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 3.00	top5: 14.50	
[09/16 03:54:33 visual_prompt]: Inference (test):avg data time: 5.67e-03, avg batch time: 0.1921, average loss: 4.7648
[09/16 03:54:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 1.38	top5: 10.70	
[09/16 03:54:33 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 03:54:42 visual_prompt]: Epoch 32 / 100: avg data time: 9.30e-02, avg batch time: 0.4957, average train loss: 4.8406
[09/16 03:54:44 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1437, average loss: 4.2543
[09/16 03:54:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 9.50	top5: 27.00	
[09/16 03:55:05 visual_prompt]: Inference (test):avg data time: 7.58e-03, avg batch time: 0.1921, average loss: 4.5434
[09/16 03:55:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 6.20	top5: 17.09	
[09/16 03:55:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 03:55:14 visual_prompt]: Epoch 33 / 100: avg data time: 7.90e-02, avg batch time: 0.4878, average train loss: 3.8800
[09/16 03:55:16 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1435, average loss: 2.0097
[09/16 03:55:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 52.00	top5: 78.00	
[09/16 03:55:37 visual_prompt]: Inference (test):avg data time: 8.71e-03, avg batch time: 0.1938, average loss: 2.8431
[09/16 03:55:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 34.41	top5: 62.29	
[09/16 03:55:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 03:55:46 visual_prompt]: Epoch 34 / 100: avg data time: 8.65e-02, avg batch time: 0.4909, average train loss: 1.6166
[09/16 03:55:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1436, average loss: 0.7003
[09/16 03:55:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 82.00	top5: 96.50	
[09/16 03:56:09 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1919, average loss: 1.3177
[09/16 03:56:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 66.32	top5: 89.04	
[09/16 03:56:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 03:56:18 visual_prompt]: Epoch 35 / 100: avg data time: 8.47e-02, avg batch time: 0.4912, average train loss: 0.4061
[09/16 03:56:20 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1437, average loss: 0.2254
[09/16 03:56:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 93.50	top5: 99.50	
[09/16 03:56:41 visual_prompt]: Inference (test):avg data time: 8.67e-03, avg batch time: 0.1942, average loss: 0.9794
[09/16 03:56:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 80.24	top5: 93.48	
[09/16 03:56:41 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 03:56:50 visual_prompt]: Epoch 36 / 100: avg data time: 8.63e-02, avg batch time: 0.4924, average train loss: 0.3772
[09/16 03:56:53 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1437, average loss: 0.0831
[09/16 03:56:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.00	top5: 100.00	
[09/16 03:57:14 visual_prompt]: Inference (test):avg data time: 6.67e-03, avg batch time: 0.1915, average loss: 0.6286
[09/16 03:57:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 84.16	top5: 96.03	
[09/16 03:57:14 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 03:57:22 visual_prompt]: Epoch 37 / 100: avg data time: 8.85e-02, avg batch time: 0.4953, average train loss: 0.1532
[09/16 03:57:25 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1439, average loss: 0.0120
[09/16 03:57:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 03:57:46 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1930, average loss: 0.4978
[09/16 03:57:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.97	top5: 96.93	
[09/16 03:57:46 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 03:57:55 visual_prompt]: Epoch 38 / 100: avg data time: 9.29e-02, avg batch time: 0.4968, average train loss: 0.0912
[09/16 03:57:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.2424
[09/16 03:57:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 92.50	top5: 98.50	
[09/16 03:58:18 visual_prompt]: Inference (test):avg data time: 8.02e-03, avg batch time: 0.1927, average loss: 1.0131
[09/16 03:58:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 76.48	top5: 93.27	
[09/16 03:58:18 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 03:58:26 visual_prompt]: Epoch 39 / 100: avg data time: 7.47e-02, avg batch time: 0.4831, average train loss: 0.1031
[09/16 03:58:29 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1439, average loss: 0.0362
[09/16 03:58:29 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 03:58:50 visual_prompt]: Inference (test):avg data time: 5.54e-03, avg batch time: 0.1913, average loss: 0.4882
[09/16 03:58:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.19	top5: 97.54	
[09/16 03:58:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 03:58:59 visual_prompt]: Epoch 40 / 100: avg data time: 9.70e-02, avg batch time: 0.4994, average train loss: 0.0482
[09/16 03:59:01 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1438, average loss: 0.0697
[09/16 03:59:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 03:59:22 visual_prompt]: Inference (test):avg data time: 7.01e-03, avg batch time: 0.1935, average loss: 0.4528
[09/16 03:59:22 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.71	top5: 98.05	
[09/16 03:59:22 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 03:59:31 visual_prompt]: Epoch 41 / 100: avg data time: 8.91e-02, avg batch time: 0.4933, average train loss: 0.0350
[09/16 03:59:33 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1438, average loss: 0.0300
[09/16 03:59:33 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 03:59:54 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1940, average loss: 0.4437
[09/16 03:59:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.31	top5: 97.63	
[09/16 03:59:55 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 04:00:03 visual_prompt]: Epoch 42 / 100: avg data time: 8.99e-02, avg batch time: 0.4956, average train loss: 0.0403
[09/16 04:00:06 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1439, average loss: 0.0424
[09/16 04:00:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.50	top5: 99.50	
[09/16 04:00:27 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1915, average loss: 0.4269
[09/16 04:00:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.62	top5: 97.58	
[09/16 04:00:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 04:00:35 visual_prompt]: Epoch 43 / 100: avg data time: 8.30e-02, avg batch time: 0.4884, average train loss: 0.0665
[09/16 04:00:38 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1438, average loss: 0.0231
[09/16 04:00:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:00:59 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1928, average loss: 0.4233
[09/16 04:00:59 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.61	top5: 97.80	
[09/16 04:00:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 04:01:07 visual_prompt]: Epoch 44 / 100: avg data time: 8.09e-02, avg batch time: 0.4867, average train loss: 0.0351
[09/16 04:01:10 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1437, average loss: 0.0021
[09/16 04:01:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:01:31 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1925, average loss: 0.2917
[09/16 04:01:31 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.96	top5: 98.65	
[09/16 04:01:31 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 04:01:39 visual_prompt]: Epoch 45 / 100: avg data time: 7.21e-02, avg batch time: 0.4775, average train loss: 0.0089
[09/16 04:01:42 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1440, average loss: 0.0138
[09/16 04:01:42 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 04:02:03 visual_prompt]: Inference (test):avg data time: 7.06e-03, avg batch time: 0.1932, average loss: 0.2711
[09/16 04:02:03 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.45	top5: 98.80	
[09/16 04:02:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 04:02:11 visual_prompt]: Epoch 46 / 100: avg data time: 7.89e-02, avg batch time: 0.4849, average train loss: 0.0238
[09/16 04:02:14 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1435, average loss: 0.0032
[09/16 04:02:14 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:02:35 visual_prompt]: Inference (test):avg data time: 5.00e-03, avg batch time: 0.1905, average loss: 0.3473
[09/16 04:02:35 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.16	top5: 97.85	
[09/16 04:02:35 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 04:02:43 visual_prompt]: Epoch 47 / 100: avg data time: 9.02e-02, avg batch time: 0.4935, average train loss: 0.0137
[09/16 04:02:46 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1445, average loss: 0.0180
[09/16 04:02:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 04:03:07 visual_prompt]: Inference (test):avg data time: 6.06e-03, avg batch time: 0.1914, average loss: 0.2496
[09/16 04:03:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.61	top5: 98.68	
[09/16 04:03:07 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 04:03:16 visual_prompt]: Epoch 48 / 100: avg data time: 9.37e-02, avg batch time: 0.4987, average train loss: 0.0043
[09/16 04:03:18 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1437, average loss: 0.0019
[09/16 04:03:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:03:39 visual_prompt]: Inference (test):avg data time: 6.40e-03, avg batch time: 0.1921, average loss: 0.2512
[09/16 04:03:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.00	top5: 98.55	
[09/16 04:03:39 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 04:03:48 visual_prompt]: Epoch 49 / 100: avg data time: 8.75e-02, avg batch time: 0.4942, average train loss: 0.0024
[09/16 04:03:51 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1441, average loss: 0.0014
[09/16 04:03:51 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:04:11 visual_prompt]: Inference (test):avg data time: 7.13e-03, avg batch time: 0.1920, average loss: 0.2256
[09/16 04:04:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.76	top5: 98.76	
[09/16 04:04:12 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 04:04:20 visual_prompt]: Epoch 50 / 100: avg data time: 9.15e-02, avg batch time: 0.4932, average train loss: 0.0020
[09/16 04:04:23 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1437, average loss: 0.0015
[09/16 04:04:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:04:44 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1925, average loss: 0.1919
[09/16 04:04:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.27	top5: 98.98	
[09/16 04:04:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 04:04:52 visual_prompt]: Epoch 51 / 100: avg data time: 7.44e-02, avg batch time: 0.4803, average train loss: 0.0020
[09/16 04:04:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1436, average loss: 0.0017
[09/16 04:04:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:05:16 visual_prompt]: Inference (test):avg data time: 8.13e-03, avg batch time: 0.1924, average loss: 0.1873
[09/16 04:05:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.46	top5: 98.99	
[09/16 04:05:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 04:05:24 visual_prompt]: Epoch 52 / 100: avg data time: 8.43e-02, avg batch time: 0.4900, average train loss: 0.0022
[09/16 04:05:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1437, average loss: 0.0018
[09/16 04:05:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:05:48 visual_prompt]: Inference (test):avg data time: 8.87e-03, avg batch time: 0.1940, average loss: 0.1863
[09/16 04:05:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.43	top5: 98.99	
[09/16 04:05:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 04:05:56 visual_prompt]: Epoch 53 / 100: avg data time: 8.45e-02, avg batch time: 0.4888, average train loss: 0.0026
[09/16 04:05:59 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1439, average loss: 0.0020
[09/16 04:05:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:06:20 visual_prompt]: Inference (test):avg data time: 6.06e-03, avg batch time: 0.1919, average loss: 0.1838
[09/16 04:06:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.43	top5: 99.01	
[09/16 04:06:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 04:06:28 visual_prompt]: Epoch 54 / 100: avg data time: 8.17e-02, avg batch time: 0.4861, average train loss: 0.0031
[09/16 04:06:31 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1439, average loss: 0.0023
[09/16 04:06:31 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:06:52 visual_prompt]: Inference (test):avg data time: 4.89e-03, avg batch time: 0.1921, average loss: 0.1867
[09/16 04:06:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.37	top5: 98.96	
[09/16 04:06:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 04:07:00 visual_prompt]: Epoch 55 / 100: avg data time: 8.82e-02, avg batch time: 0.4917, average train loss: 0.0031
[09/16 04:07:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1439, average loss: 0.0024
[09/16 04:07:03 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:07:24 visual_prompt]: Inference (test):avg data time: 3.92e-03, avg batch time: 0.1904, average loss: 0.1833
[09/16 04:07:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.48	top5: 98.99	
[09/16 04:07:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 04:07:32 visual_prompt]: Epoch 56 / 100: avg data time: 8.39e-02, avg batch time: 0.4918, average train loss: 0.0036
[09/16 04:07:35 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1437, average loss: 0.0026
[09/16 04:07:35 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:07:56 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1929, average loss: 0.1801
[09/16 04:07:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.51	top5: 99.07	
[09/16 04:07:56 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 04:08:05 visual_prompt]: Epoch 57 / 100: avg data time: 1.00e-01, avg batch time: 0.5033, average train loss: 0.0038
[09/16 04:08:07 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1435, average loss: 0.0028
[09/16 04:08:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:08:28 visual_prompt]: Inference (test):avg data time: 9.73e-03, avg batch time: 0.1949, average loss: 0.1717
[09/16 04:08:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.71	top5: 99.20	
[09/16 04:08:29 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 04:08:37 visual_prompt]: Epoch 58 / 100: avg data time: 9.10e-02, avg batch time: 0.4948, average train loss: 0.0041
[09/16 04:08:40 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1435, average loss: 0.0027
[09/16 04:08:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:09:01 visual_prompt]: Inference (test):avg data time: 6.21e-03, avg batch time: 0.1994, average loss: 0.1756
[09/16 04:09:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.67	top5: 99.15	
[09/16 04:09:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 04:09:10 visual_prompt]: Epoch 59 / 100: avg data time: 9.19e-02, avg batch time: 0.4942, average train loss: 0.0042
[09/16 04:09:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1436, average loss: 0.0030
[09/16 04:09:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:09:33 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1930, average loss: 0.1682
[09/16 04:09:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.89	top5: 99.19	
[09/16 04:09:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 04:09:42 visual_prompt]: Epoch 60 / 100: avg data time: 9.04e-02, avg batch time: 0.4930, average train loss: 0.0045
[09/16 04:09:45 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 04:09:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:10:06 visual_prompt]: Inference (test):avg data time: 6.89e-03, avg batch time: 0.1984, average loss: 0.1687
[09/16 04:10:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.84	top5: 99.22	
[09/16 04:10:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 04:10:15 visual_prompt]: Epoch 61 / 100: avg data time: 8.21e-02, avg batch time: 0.4890, average train loss: 0.0045
[09/16 04:10:17 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1435, average loss: 0.0030
[09/16 04:10:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:10:38 visual_prompt]: Inference (test):avg data time: 7.81e-03, avg batch time: 0.1920, average loss: 0.1669
[09/16 04:10:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.84	top5: 99.24	
[09/16 04:10:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 04:10:47 visual_prompt]: Epoch 62 / 100: avg data time: 9.09e-02, avg batch time: 0.4989, average train loss: 0.0048
[09/16 04:10:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1435, average loss: 0.0032
[09/16 04:10:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:11:11 visual_prompt]: Inference (test):avg data time: 6.25e-03, avg batch time: 0.1904, average loss: 0.1643
[09/16 04:11:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.02	top5: 99.30	
[09/16 04:11:11 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 04:11:19 visual_prompt]: Epoch 63 / 100: avg data time: 9.18e-02, avg batch time: 0.4966, average train loss: 0.0049
[09/16 04:11:22 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1439, average loss: 0.0033
[09/16 04:11:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:11:43 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1923, average loss: 0.1650
[09/16 04:11:43 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.95	top5: 99.27	
[09/16 04:11:43 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 04:11:51 visual_prompt]: Epoch 64 / 100: avg data time: 9.02e-02, avg batch time: 0.4953, average train loss: 0.0049
[09/16 04:11:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1437, average loss: 0.0034
[09/16 04:11:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:12:15 visual_prompt]: Inference (test):avg data time: 6.73e-03, avg batch time: 0.1943, average loss: 0.1637
[09/16 04:12:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.95	top5: 99.30	
[09/16 04:12:15 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 04:12:24 visual_prompt]: Epoch 65 / 100: avg data time: 8.51e-02, avg batch time: 0.4894, average train loss: 0.0052
[09/16 04:12:26 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1437, average loss: 0.0035
[09/16 04:12:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:12:47 visual_prompt]: Inference (test):avg data time: 5.78e-03, avg batch time: 0.1953, average loss: 0.1627
[09/16 04:12:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.11	top5: 99.38	
[09/16 04:12:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 04:12:56 visual_prompt]: Epoch 66 / 100: avg data time: 7.65e-02, avg batch time: 0.4814, average train loss: 0.0057
[09/16 04:12:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1440, average loss: 0.0036
[09/16 04:12:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:13:20 visual_prompt]: Inference (test):avg data time: 7.89e-03, avg batch time: 0.1936, average loss: 0.1557
[09/16 04:13:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.28	top5: 99.45	
[09/16 04:13:20 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 04:13:28 visual_prompt]: Epoch 67 / 100: avg data time: 8.24e-02, avg batch time: 0.4882, average train loss: 0.0055
[09/16 04:13:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1438, average loss: 0.0035
[09/16 04:13:31 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:13:51 visual_prompt]: Inference (test):avg data time: 5.75e-03, avg batch time: 0.1903, average loss: 0.1583
[09/16 04:13:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.31	top5: 99.41	
[09/16 04:13:51 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 04:14:00 visual_prompt]: Epoch 68 / 100: avg data time: 9.03e-02, avg batch time: 0.4976, average train loss: 0.0054
[09/16 04:14:03 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1437, average loss: 0.0035
[09/16 04:14:03 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:14:24 visual_prompt]: Inference (test):avg data time: 7.64e-03, avg batch time: 0.1923, average loss: 0.1529
[09/16 04:14:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.42	top5: 99.41	
[09/16 04:14:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 04:14:32 visual_prompt]: Epoch 69 / 100: avg data time: 9.96e-02, avg batch time: 0.5022, average train loss: 0.0053
[09/16 04:14:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1464, average loss: 0.0035
[09/16 04:14:35 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:14:56 visual_prompt]: Inference (test):avg data time: 5.56e-03, avg batch time: 0.1909, average loss: 0.1567
[09/16 04:14:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.32	top5: 99.41	
[09/16 04:14:56 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 04:15:04 visual_prompt]: Epoch 70 / 100: avg data time: 8.38e-02, avg batch time: 0.4883, average train loss: 0.0052
[09/16 04:15:07 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1436, average loss: 0.0035
[09/16 04:15:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:15:28 visual_prompt]: Inference (test):avg data time: 5.69e-03, avg batch time: 0.1907, average loss: 0.1531
[09/16 04:15:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.31	top5: 99.43	
[09/16 04:15:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 04:15:36 visual_prompt]: Epoch 71 / 100: avg data time: 8.74e-02, avg batch time: 0.4919, average train loss: 0.0054
[09/16 04:15:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1438, average loss: 0.0035
[09/16 04:15:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:16:00 visual_prompt]: Inference (test):avg data time: 5.54e-03, avg batch time: 0.1910, average loss: 0.1521
[09/16 04:16:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.50	top5: 99.43	
[09/16 04:16:00 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 04:16:08 visual_prompt]: Epoch 72 / 100: avg data time: 9.21e-02, avg batch time: 0.4966, average train loss: 0.0052
[09/16 04:16:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1436, average loss: 0.0035
[09/16 04:16:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:16:33 visual_prompt]: Inference (test):avg data time: 7.79e-03, avg batch time: 0.1985, average loss: 0.1521
[09/16 04:16:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.44	top5: 99.50	
[09/16 04:16:33 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 04:16:41 visual_prompt]: Epoch 73 / 100: avg data time: 7.59e-02, avg batch time: 0.4815, average train loss: 0.0053
[09/16 04:16:44 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1435, average loss: 0.0035
[09/16 04:16:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:17:04 visual_prompt]: Inference (test):avg data time: 6.11e-03, avg batch time: 0.1920, average loss: 0.1490
[09/16 04:17:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.58	top5: 99.50	
[09/16 04:17:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 04:17:13 visual_prompt]: Epoch 74 / 100: avg data time: 7.45e-02, avg batch time: 0.4796, average train loss: 0.0052
[09/16 04:17:15 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1439, average loss: 0.0035
[09/16 04:17:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:17:37 visual_prompt]: Inference (test):avg data time: 7.00e-03, avg batch time: 0.1958, average loss: 0.1513
[09/16 04:17:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.58	top5: 99.48	
[09/16 04:17:37 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 04:17:45 visual_prompt]: Epoch 75 / 100: avg data time: 8.99e-02, avg batch time: 0.4942, average train loss: 0.0051
[09/16 04:17:48 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1438, average loss: 0.0034
[09/16 04:17:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:18:09 visual_prompt]: Inference (test):avg data time: 7.31e-03, avg batch time: 0.1930, average loss: 0.1507
[09/16 04:18:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.57	top5: 99.50	
[09/16 04:18:09 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 04:18:17 visual_prompt]: Epoch 76 / 100: avg data time: 8.19e-02, avg batch time: 0.4872, average train loss: 0.0050
[09/16 04:18:20 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1436, average loss: 0.0033
[09/16 04:18:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:18:41 visual_prompt]: Inference (test):avg data time: 6.78e-03, avg batch time: 0.1937, average loss: 0.1482
[09/16 04:18:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.58	top5: 99.48	
[09/16 04:18:41 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 04:18:49 visual_prompt]: Epoch 77 / 100: avg data time: 7.40e-02, avg batch time: 0.4789, average train loss: 0.0049
[09/16 04:18:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 04:18:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:19:13 visual_prompt]: Inference (test):avg data time: 6.56e-03, avg batch time: 0.1915, average loss: 0.1479
[09/16 04:19:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.68	top5: 99.45	
[09/16 04:19:13 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 04:19:22 visual_prompt]: Epoch 78 / 100: avg data time: 9.85e-02, avg batch time: 0.5022, average train loss: 0.0051
[09/16 04:19:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1435, average loss: 0.0034
[09/16 04:19:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:19:45 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1926, average loss: 0.1504
[09/16 04:19:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.57	top5: 99.45	
[09/16 04:19:45 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 04:19:54 visual_prompt]: Epoch 79 / 100: avg data time: 7.25e-02, avg batch time: 0.4784, average train loss: 0.0049
[09/16 04:19:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 04:19:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:20:17 visual_prompt]: Inference (test):avg data time: 6.14e-03, avg batch time: 0.1910, average loss: 0.1461
[09/16 04:20:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.70	top5: 99.48	
[09/16 04:20:17 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 04:20:26 visual_prompt]: Epoch 80 / 100: avg data time: 9.21e-02, avg batch time: 0.4962, average train loss: 0.0050
[09/16 04:20:28 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1438, average loss: 0.0035
[09/16 04:20:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:20:49 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1932, average loss: 0.1499
[09/16 04:20:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.68	top5: 99.45	
[09/16 04:20:49 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 04:20:58 visual_prompt]: Epoch 81 / 100: avg data time: 8.35e-02, avg batch time: 0.4875, average train loss: 0.0049
[09/16 04:21:00 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 04:21:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:21:21 visual_prompt]: Inference (test):avg data time: 7.18e-03, avg batch time: 0.1917, average loss: 0.1481
[09/16 04:21:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.80	top5: 99.48	
[09/16 04:21:21 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 04:21:29 visual_prompt]: Epoch 82 / 100: avg data time: 7.95e-02, avg batch time: 0.4859, average train loss: 0.0049
[09/16 04:21:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1436, average loss: 0.0033
[09/16 04:21:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:21:53 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1918, average loss: 0.1479
[09/16 04:21:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.75	top5: 99.46	
[09/16 04:21:53 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 04:22:01 visual_prompt]: Epoch 83 / 100: avg data time: 8.09e-02, avg batch time: 0.4842, average train loss: 0.0048
[09/16 04:22:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1436, average loss: 0.0033
[09/16 04:22:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:22:25 visual_prompt]: Inference (test):avg data time: 7.03e-03, avg batch time: 0.1927, average loss: 0.1481
[09/16 04:22:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.75	top5: 99.50	
[09/16 04:22:25 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 04:22:34 visual_prompt]: Epoch 84 / 100: avg data time: 9.76e-02, avg batch time: 0.5007, average train loss: 0.0049
[09/16 04:22:36 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 04:22:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:22:57 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1921, average loss: 0.1482
[09/16 04:22:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.85	top5: 99.48	
[09/16 04:22:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 04:23:06 visual_prompt]: Epoch 85 / 100: avg data time: 8.41e-02, avg batch time: 0.4885, average train loss: 0.0049
[09/16 04:23:08 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 04:23:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:23:29 visual_prompt]: Inference (test):avg data time: 6.23e-03, avg batch time: 0.1907, average loss: 0.1478
[09/16 04:23:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.78	top5: 99.45	
[09/16 04:23:29 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 04:23:37 visual_prompt]: Epoch 86 / 100: avg data time: 7.39e-02, avg batch time: 0.4775, average train loss: 0.0047
[09/16 04:23:40 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 04:23:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:24:01 visual_prompt]: Inference (test):avg data time: 7.11e-03, avg batch time: 0.1923, average loss: 0.1475
[09/16 04:24:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.81	top5: 99.48	
[09/16 04:24:01 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 04:24:09 visual_prompt]: Epoch 87 / 100: avg data time: 9.24e-02, avg batch time: 0.4966, average train loss: 0.0048
[09/16 04:24:12 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1444, average loss: 0.0032
[09/16 04:24:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:24:33 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1918, average loss: 0.1463
[09/16 04:24:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.83	top5: 99.48	
[09/16 04:24:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 04:24:42 visual_prompt]: Epoch 88 / 100: avg data time: 8.81e-02, avg batch time: 0.4926, average train loss: 0.0048
[09/16 04:24:44 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1436, average loss: 0.0033
[09/16 04:24:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:25:05 visual_prompt]: Inference (test):avg data time: 6.94e-03, avg batch time: 0.1926, average loss: 0.1473
[09/16 04:25:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.81	top5: 99.48	
[09/16 04:25:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 04:25:14 visual_prompt]: Epoch 89 / 100: avg data time: 9.50e-02, avg batch time: 0.4974, average train loss: 0.0047
[09/16 04:25:16 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 04:25:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:25:37 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1932, average loss: 0.1467
[09/16 04:25:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.76	top5: 99.51	
[09/16 04:25:37 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 04:25:46 visual_prompt]: Epoch 90 / 100: avg data time: 8.53e-02, avg batch time: 0.4887, average train loss: 0.0047
[09/16 04:25:49 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 04:25:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:26:09 visual_prompt]: Inference (test):avg data time: 5.83e-03, avg batch time: 0.1915, average loss: 0.1455
[09/16 04:26:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.86	top5: 99.50	
[09/16 04:26:09 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 04:26:18 visual_prompt]: Epoch 91 / 100: avg data time: 7.90e-02, avg batch time: 0.4818, average train loss: 0.0048
[09/16 04:26:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 04:26:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:26:41 visual_prompt]: Inference (test):avg data time: 5.62e-03, avg batch time: 0.1923, average loss: 0.1448
[09/16 04:26:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.91	top5: 99.51	
[09/16 04:26:41 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 04:26:50 visual_prompt]: Epoch 92 / 100: avg data time: 9.19e-02, avg batch time: 0.4959, average train loss: 0.0048
[09/16 04:26:52 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1439, average loss: 0.0032
[09/16 04:26:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:27:13 visual_prompt]: Inference (test):avg data time: 6.79e-03, avg batch time: 0.1917, average loss: 0.1454
[09/16 04:27:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.88	top5: 99.51	
[09/16 04:27:13 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 04:27:22 visual_prompt]: Epoch 93 / 100: avg data time: 8.89e-02, avg batch time: 0.4957, average train loss: 0.0047
[09/16 04:27:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1440, average loss: 0.0032
[09/16 04:27:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:27:45 visual_prompt]: Inference (test):avg data time: 6.07e-03, avg batch time: 0.1916, average loss: 0.1460
[09/16 04:27:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.88	top5: 99.51	
[09/16 04:27:45 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 04:27:54 visual_prompt]: Epoch 94 / 100: avg data time: 9.09e-02, avg batch time: 0.4943, average train loss: 0.0048
[09/16 04:27:56 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 04:27:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:28:17 visual_prompt]: Inference (test):avg data time: 6.85e-03, avg batch time: 0.1924, average loss: 0.1457
[09/16 04:28:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.83	top5: 99.48	
[09/16 04:28:17 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 04:28:26 visual_prompt]: Epoch 95 / 100: avg data time: 7.95e-02, avg batch time: 0.4856, average train loss: 0.0046
[09/16 04:28:28 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1436, average loss: 0.0032
[09/16 04:28:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:28:49 visual_prompt]: Inference (test):avg data time: 5.92e-03, avg batch time: 0.1910, average loss: 0.1461
[09/16 04:28:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.83	top5: 99.48	
[09/16 04:28:49 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 04:28:58 visual_prompt]: Epoch 96 / 100: avg data time: 8.99e-02, avg batch time: 0.4919, average train loss: 0.0048
[09/16 04:29:00 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1436, average loss: 0.0032
[09/16 04:29:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:29:21 visual_prompt]: Inference (test):avg data time: 7.42e-03, avg batch time: 0.1929, average loss: 0.1458
[09/16 04:29:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.86	top5: 99.50	
[09/16 04:29:21 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 04:29:30 visual_prompt]: Epoch 97 / 100: avg data time: 8.34e-02, avg batch time: 0.4890, average train loss: 0.0047
[09/16 04:29:32 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 04:29:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:29:53 visual_prompt]: Inference (test):avg data time: 6.46e-03, avg batch time: 0.1925, average loss: 0.1459
[09/16 04:29:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.86	top5: 99.48	
[09/16 04:29:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 04:30:02 visual_prompt]: Epoch 98 / 100: avg data time: 8.80e-02, avg batch time: 0.4917, average train loss: 0.0047
[09/16 04:30:04 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1439, average loss: 0.0032
[09/16 04:30:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:30:25 visual_prompt]: Inference (test):avg data time: 5.68e-03, avg batch time: 0.1924, average loss: 0.1459
[09/16 04:30:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.85	top5: 99.48	
[09/16 04:30:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 04:30:34 visual_prompt]: Epoch 99 / 100: avg data time: 9.99e-02, avg batch time: 0.5023, average train loss: 0.0047
[09/16 04:30:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1436, average loss: 0.0032
[09/16 04:30:37 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:30:58 visual_prompt]: Inference (test):avg data time: 9.12e-03, avg batch time: 0.1933, average loss: 0.1459
[09/16 04:30:58 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.85	top5: 99.50	
[09/16 04:30:58 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 04:31:06 visual_prompt]: Epoch 100 / 100: avg data time: 8.78e-02, avg batch time: 0.4928, average train loss: 0.0047
[09/16 04:31:09 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 04:31:09 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:31:30 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1925, average loss: 0.1459
[09/16 04:31:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.85	top5: 99.50	
[09/16 04:32:03 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 04:32:03 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 04:32:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-oxford_flowers102', 'DATA.NUMBER_CLASSES', '102', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/16 04:32:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 04:32:03 visual_prompt]: Training with config:
[09/16 04:32:03 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-oxford_flowers102',
          'NO_TEST': False,
          'NUMBER_CLASSES': 102,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-oxford_flowers102/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 04:32:03 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 04:32:03.115731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 04:32:03.312528: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 04:32:04.226906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 04:32:04.226984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 04:32:04.226993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 04:32:06.258922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 04:32:06.259037: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 04:32:06.259055: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 04:32:06 visual_prompt]: Constructing vtab-oxford_flowers102 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
2023-09-16 04:32:06.284825: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 04:32:09 visual_prompt]: Number of images: 1000
[09/16 04:32:09 visual_prompt]: Number of classes: 102 / 102
[09/16 04:32:09 visual_prompt]: Loading validation data...
[09/16 04:32:09 visual_prompt]: Constructing vtab-oxford_flowers102 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 04:32:09 visual_prompt]: Number of images: 200
[09/16 04:32:09 visual_prompt]: Number of classes: 90 / 102
[09/16 04:32:09 visual_prompt]: Loading test data...
[09/16 04:32:09 visual_prompt]: Constructing vtab-oxford_flowers102 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split test, from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 04:32:23 visual_prompt]: Number of images: 6149
[09/16 04:32:23 visual_prompt]: Number of classes: 102 / 102
[09/16 04:32:23 visual_prompt]: Constructing models...
[09/16 04:32:26 visual_prompt]: Total Parameters: 86798694	 Gradient Parameters: 1000038
[09/16 04:32:26 visual_prompt]: tuned percent:1.152
[09/16 04:32:29 visual_prompt]: Device used for model: 0
[09/16 04:32:29 visual_prompt]: Setting up Evalutator...
[09/16 04:32:29 visual_prompt]: Setting up Trainer...
[09/16 04:32:29 visual_prompt]: 	Setting up the optimizer...
[09/16 04:32:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 04:32:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.02e-01, avg batch time: 0.5775, average train loss: 4.6610
[09/16 04:32:41 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1429, average loss: 4.6573
[09/16 04:32:41 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 2.50	top5: 6.50	
[09/16 04:33:02 visual_prompt]: Inference (test):avg data time: 6.24e-03, avg batch time: 0.1918, average loss: 4.6647
[09/16 04:33:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.52	top5: 4.41	
[09/16 04:33:02 visual_prompt]: Best epoch 1: best metric: 0.025
[09/16 04:33:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 04:33:11 visual_prompt]: Epoch 2 / 100: avg data time: 8.63e-02, avg batch time: 0.4885, average train loss: 4.6543
[09/16 04:33:13 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1431, average loss: 4.3841
[09/16 04:33:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 6.50	top5: 21.50	
[09/16 04:33:34 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1934, average loss: 4.5179
[09/16 04:33:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.58	top5: 10.31	
[09/16 04:33:34 visual_prompt]: Best epoch 2: best metric: 0.065
[09/16 04:33:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 04:33:43 visual_prompt]: Epoch 3 / 100: avg data time: 9.62e-02, avg batch time: 0.4981, average train loss: 4.1425
[09/16 04:33:45 visual_prompt]: Inference (val):avg data time: 1.14e-03, avg batch time: 0.1449, average loss: 3.5129
[09/16 04:33:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 15.50	top5: 44.00	
[09/16 04:34:06 visual_prompt]: Inference (test):avg data time: 7.07e-03, avg batch time: 0.1924, average loss: 4.0564
[09/16 04:34:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 11.73	top5: 30.10	
[09/16 04:34:06 visual_prompt]: Best epoch 3: best metric: 0.155
[09/16 04:34:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 04:34:15 visual_prompt]: Epoch 4 / 100: avg data time: 9.89e-02, avg batch time: 0.5024, average train loss: 3.0215
[09/16 04:34:18 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1436, average loss: 1.2068
[09/16 04:34:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 72.50	top5: 92.00	
[09/16 04:34:39 visual_prompt]: Inference (test):avg data time: 6.87e-03, avg batch time: 0.1942, average loss: 1.8599
[09/16 04:34:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 56.17	top5: 78.97	
[09/16 04:34:39 visual_prompt]: Best epoch 4: best metric: 0.725
[09/16 04:34:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 04:34:47 visual_prompt]: Epoch 5 / 100: avg data time: 8.64e-02, avg batch time: 0.4889, average train loss: 0.7292
[09/16 04:34:50 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1439, average loss: 0.3265
[09/16 04:34:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 92.50	top5: 97.00	
[09/16 04:35:11 visual_prompt]: Inference (test):avg data time: 6.86e-03, avg batch time: 0.1930, average loss: 0.6712
[09/16 04:35:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 82.73	top5: 95.56	
[09/16 04:35:11 visual_prompt]: Best epoch 5: best metric: 0.925
[09/16 04:35:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 04:35:19 visual_prompt]: Epoch 6 / 100: avg data time: 8.47e-02, avg batch time: 0.4883, average train loss: 0.1726
[09/16 04:35:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1439, average loss: 0.0958
[09/16 04:35:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 96.50	top5: 100.00	
[09/16 04:35:43 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1932, average loss: 0.4452
[09/16 04:35:43 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.69	top5: 97.43	
[09/16 04:35:43 visual_prompt]: Best epoch 6: best metric: 0.965
[09/16 04:35:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 04:35:51 visual_prompt]: Epoch 7 / 100: avg data time: 9.07e-02, avg batch time: 0.4952, average train loss: 0.0664
[09/16 04:35:54 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1435, average loss: 0.0212
[09/16 04:35:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 04:36:15 visual_prompt]: Inference (test):avg data time: 6.13e-03, avg batch time: 0.1916, average loss: 0.3302
[09/16 04:36:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.09	top5: 98.32	
[09/16 04:36:15 visual_prompt]: Best epoch 7: best metric: 0.995
[09/16 04:36:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 04:36:23 visual_prompt]: Epoch 8 / 100: avg data time: 8.96e-02, avg batch time: 0.4934, average train loss: 0.0245
[09/16 04:36:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1436, average loss: 0.0078
[09/16 04:36:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:36:47 visual_prompt]: Inference (test):avg data time: 5.63e-03, avg batch time: 0.1903, average loss: 0.3067
[09/16 04:36:47 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.05	top5: 98.28	
[09/16 04:36:47 visual_prompt]: Best epoch 8: best metric: 1.000
[09/16 04:36:47 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 04:36:55 visual_prompt]: Epoch 9 / 100: avg data time: 7.51e-02, avg batch time: 0.4805, average train loss: 0.0372
[09/16 04:36:58 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1436, average loss: 0.0915
[09/16 04:36:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.00	top5: 100.00	
[09/16 04:37:19 visual_prompt]: Inference (test):avg data time: 4.98e-03, avg batch time: 0.1909, average loss: 0.4275
[09/16 04:37:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.94	top5: 97.43	
[09/16 04:37:19 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 04:37:27 visual_prompt]: Epoch 10 / 100: avg data time: 8.45e-02, avg batch time: 0.4917, average train loss: 0.0331
[09/16 04:37:30 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1436, average loss: 0.0512
[09/16 04:37:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 04:37:51 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1926, average loss: 0.2839
[09/16 04:37:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.58	top5: 98.55	
[09/16 04:37:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 04:37:59 visual_prompt]: Epoch 11 / 100: avg data time: 8.92e-02, avg batch time: 0.4928, average train loss: 0.0334
[09/16 04:38:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1437, average loss: 0.0152
[09/16 04:38:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 04:38:23 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1923, average loss: 0.2665
[09/16 04:38:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.19	top5: 98.60	
[09/16 04:38:23 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 04:38:32 visual_prompt]: Epoch 12 / 100: avg data time: 8.67e-02, avg batch time: 0.4942, average train loss: 0.0523
[09/16 04:38:34 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1436, average loss: 0.0319
[09/16 04:38:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 04:38:56 visual_prompt]: Inference (test):avg data time: 6.21e-03, avg batch time: 0.1998, average loss: 0.2880
[09/16 04:38:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.81	top5: 98.32	
[09/16 04:38:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 04:39:04 visual_prompt]: Epoch 13 / 100: avg data time: 8.64e-02, avg batch time: 0.4919, average train loss: 0.0599
[09/16 04:39:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1434, average loss: 0.0141
[09/16 04:39:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:39:28 visual_prompt]: Inference (test):avg data time: 6.00e-03, avg batch time: 0.1909, average loss: 0.2649
[09/16 04:39:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.56	top5: 98.59	
[09/16 04:39:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 04:39:37 visual_prompt]: Epoch 14 / 100: avg data time: 9.44e-02, avg batch time: 0.5002, average train loss: 0.0249
[09/16 04:39:39 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1437, average loss: 0.0066
[09/16 04:39:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:40:00 visual_prompt]: Inference (test):avg data time: 6.07e-03, avg batch time: 0.1924, average loss: 0.1803
[09/16 04:40:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.28	top5: 99.33	
[09/16 04:40:00 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 04:40:09 visual_prompt]: Epoch 15 / 100: avg data time: 7.65e-02, avg batch time: 0.4834, average train loss: 0.0118
[09/16 04:40:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1439, average loss: 0.0183
[09/16 04:40:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 04:40:32 visual_prompt]: Inference (test):avg data time: 6.73e-03, avg batch time: 0.1927, average loss: 0.1978
[09/16 04:40:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.33	top5: 98.75	
[09/16 04:40:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 04:40:41 visual_prompt]: Epoch 16 / 100: avg data time: 8.25e-02, avg batch time: 0.4886, average train loss: 0.0051
[09/16 04:40:43 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1435, average loss: 0.0028
[09/16 04:40:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:41:04 visual_prompt]: Inference (test):avg data time: 7.72e-03, avg batch time: 0.1976, average loss: 0.1419
[09/16 04:41:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.57	top5: 99.41	
[09/16 04:41:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 04:41:13 visual_prompt]: Epoch 17 / 100: avg data time: 9.19e-02, avg batch time: 0.5183, average train loss: 0.0033
[09/16 04:41:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1437, average loss: 0.0037
[09/16 04:41:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:41:37 visual_prompt]: Inference (test):avg data time: 6.49e-03, avg batch time: 0.1921, average loss: 0.1479
[09/16 04:41:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.71	top5: 99.33	
[09/16 04:41:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 04:41:45 visual_prompt]: Epoch 18 / 100: avg data time: 9.67e-02, avg batch time: 0.5002, average train loss: 0.0047
[09/16 04:41:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1437, average loss: 0.0034
[09/16 04:41:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:42:09 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1942, average loss: 0.1466
[09/16 04:42:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.60	top5: 99.38	
[09/16 04:42:09 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 04:42:17 visual_prompt]: Epoch 19 / 100: avg data time: 8.49e-02, avg batch time: 0.4905, average train loss: 0.0039
[09/16 04:42:20 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 04:42:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:42:42 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1973, average loss: 0.1310
[09/16 04:42:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.25	top5: 99.50	
[09/16 04:42:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 04:42:50 visual_prompt]: Epoch 20 / 100: avg data time: 8.93e-02, avg batch time: 0.4935, average train loss: 0.0037
[09/16 04:42:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1436, average loss: 0.0029
[09/16 04:42:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:43:14 visual_prompt]: Inference (test):avg data time: 7.03e-03, avg batch time: 0.1926, average loss: 0.1261
[09/16 04:43:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.46	top5: 99.48	
[09/16 04:43:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 04:43:23 visual_prompt]: Epoch 21 / 100: avg data time: 9.77e-02, avg batch time: 0.5039, average train loss: 0.0040
[09/16 04:43:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1438, average loss: 0.0031
[09/16 04:43:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:43:46 visual_prompt]: Inference (test):avg data time: 5.28e-03, avg batch time: 0.1911, average loss: 0.1217
[09/16 04:43:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.50	top5: 99.51	
[09/16 04:43:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 04:43:55 visual_prompt]: Epoch 22 / 100: avg data time: 8.35e-02, avg batch time: 0.4933, average train loss: 0.0042
[09/16 04:43:58 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1435, average loss: 0.0034
[09/16 04:43:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:44:18 visual_prompt]: Inference (test):avg data time: 9.23e-03, avg batch time: 0.1929, average loss: 0.1225
[09/16 04:44:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.56	top5: 99.48	
[09/16 04:44:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 04:44:27 visual_prompt]: Epoch 23 / 100: avg data time: 8.56e-02, avg batch time: 0.4892, average train loss: 0.0046
[09/16 04:44:30 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1438, average loss: 0.0036
[09/16 04:44:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:44:50 visual_prompt]: Inference (test):avg data time: 5.52e-03, avg batch time: 0.1920, average loss: 0.1174
[09/16 04:44:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.59	
[09/16 04:44:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 04:44:59 visual_prompt]: Epoch 24 / 100: avg data time: 1.00e-01, avg batch time: 0.5026, average train loss: 0.0048
[09/16 04:45:02 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1435, average loss: 0.0036
[09/16 04:45:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:45:23 visual_prompt]: Inference (test):avg data time: 6.55e-03, avg batch time: 0.1931, average loss: 0.1189
[09/16 04:45:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.71	top5: 99.54	
[09/16 04:45:23 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 04:45:32 visual_prompt]: Epoch 25 / 100: avg data time: 8.73e-02, avg batch time: 0.4908, average train loss: 0.0048
[09/16 04:45:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1435, average loss: 0.0035
[09/16 04:45:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:45:55 visual_prompt]: Inference (test):avg data time: 6.65e-03, avg batch time: 0.1977, average loss: 0.1122
[09/16 04:45:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.00	top5: 99.58	
[09/16 04:45:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 04:46:04 visual_prompt]: Epoch 26 / 100: avg data time: 9.02e-02, avg batch time: 0.4917, average train loss: 0.0047
[09/16 04:46:07 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1436, average loss: 0.0033
[09/16 04:46:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:46:28 visual_prompt]: Inference (test):avg data time: 8.35e-03, avg batch time: 0.1933, average loss: 0.1142
[09/16 04:46:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.59	
[09/16 04:46:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 04:46:36 visual_prompt]: Epoch 27 / 100: avg data time: 8.70e-02, avg batch time: 0.4933, average train loss: 0.0046
[09/16 04:46:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1439, average loss: 0.0034
[09/16 04:46:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:47:00 visual_prompt]: Inference (test):avg data time: 6.34e-03, avg batch time: 0.1921, average loss: 0.1102
[09/16 04:47:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.97	top5: 99.63	
[09/16 04:47:00 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 04:47:08 visual_prompt]: Epoch 28 / 100: avg data time: 8.14e-02, avg batch time: 0.4846, average train loss: 0.0045
[09/16 04:47:11 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1438, average loss: 0.0034
[09/16 04:47:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:47:32 visual_prompt]: Inference (test):avg data time: 6.46e-03, avg batch time: 0.1924, average loss: 0.1121
[09/16 04:47:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.93	top5: 99.53	
[09/16 04:47:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 04:47:41 visual_prompt]: Epoch 29 / 100: avg data time: 8.63e-02, avg batch time: 0.4956, average train loss: 0.0045
[09/16 04:47:43 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1443, average loss: 0.0031
[09/16 04:47:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:48:04 visual_prompt]: Inference (test):avg data time: 6.57e-03, avg batch time: 0.1915, average loss: 0.1101
[09/16 04:48:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.84	top5: 99.56	
[09/16 04:48:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 04:48:13 visual_prompt]: Epoch 30 / 100: avg data time: 8.48e-02, avg batch time: 0.4921, average train loss: 0.0044
[09/16 04:48:15 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 04:48:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:48:36 visual_prompt]: Inference (test):avg data time: 5.59e-03, avg batch time: 0.1926, average loss: 0.1138
[09/16 04:48:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.80	top5: 99.53	
[09/16 04:48:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 04:48:45 visual_prompt]: Epoch 31 / 100: avg data time: 8.48e-02, avg batch time: 0.4973, average train loss: 0.0044
[09/16 04:48:47 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 04:48:47 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:49:09 visual_prompt]: Inference (test):avg data time: 7.76e-03, avg batch time: 0.1995, average loss: 0.1115
[09/16 04:49:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.67	top5: 99.58	
[09/16 04:49:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 04:49:18 visual_prompt]: Epoch 32 / 100: avg data time: 9.04e-02, avg batch time: 0.4939, average train loss: 0.0042
[09/16 04:49:20 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1439, average loss: 0.0032
[09/16 04:49:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:49:41 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1937, average loss: 0.1139
[09/16 04:49:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.72	top5: 99.54	
[09/16 04:49:41 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 04:49:50 visual_prompt]: Epoch 33 / 100: avg data time: 9.68e-02, avg batch time: 0.5024, average train loss: 0.0041
[09/16 04:49:53 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1440, average loss: 0.0030
[09/16 04:49:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:50:14 visual_prompt]: Inference (test):avg data time: 6.43e-03, avg batch time: 0.1922, average loss: 0.1089
[09/16 04:50:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.72	top5: 99.56	
[09/16 04:50:14 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 04:50:22 visual_prompt]: Epoch 34 / 100: avg data time: 8.78e-02, avg batch time: 0.4906, average train loss: 0.0040
[09/16 04:50:25 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1440, average loss: 0.0031
[09/16 04:50:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:50:46 visual_prompt]: Inference (test):avg data time: 5.27e-03, avg batch time: 0.1942, average loss: 0.1105
[09/16 04:50:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.84	top5: 99.53	
[09/16 04:50:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 04:50:55 visual_prompt]: Epoch 35 / 100: avg data time: 9.36e-02, avg batch time: 0.4976, average train loss: 0.0040
[09/16 04:50:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1438, average loss: 0.0029
[09/16 04:50:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:51:18 visual_prompt]: Inference (test):avg data time: 6.54e-03, avg batch time: 0.1916, average loss: 0.1070
[09/16 04:51:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.85	top5: 99.61	
[09/16 04:51:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 04:51:27 visual_prompt]: Epoch 36 / 100: avg data time: 9.59e-02, avg batch time: 0.4995, average train loss: 0.0041
[09/16 04:51:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1441, average loss: 0.0032
[09/16 04:51:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:51:50 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1928, average loss: 0.1072
[09/16 04:51:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.82	top5: 99.63	
[09/16 04:51:50 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 04:51:59 visual_prompt]: Epoch 37 / 100: avg data time: 8.25e-02, avg batch time: 0.4885, average train loss: 0.0044
[09/16 04:52:02 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1437, average loss: 0.0037
[09/16 04:52:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:52:23 visual_prompt]: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1927, average loss: 0.1240
[09/16 04:52:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.56	top5: 99.56	
[09/16 04:52:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 04:52:31 visual_prompt]: Epoch 38 / 100: avg data time: 8.86e-02, avg batch time: 0.4924, average train loss: 2.9708
[09/16 04:52:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1450, average loss: 5.0140
[09/16 04:52:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.50	top5: 8.50	
[09/16 04:52:55 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1935, average loss: 4.9057
[09/16 04:52:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.41	top5: 5.89	
[09/16 04:52:55 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 04:53:03 visual_prompt]: Epoch 39 / 100: avg data time: 8.77e-02, avg batch time: 0.4909, average train loss: 5.0844
[09/16 04:53:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1438, average loss: 4.8972
[09/16 04:53:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 0.50	top5: 6.00	
[09/16 04:53:27 visual_prompt]: Inference (test):avg data time: 9.65e-03, avg batch time: 0.1944, average loss: 4.9611
[09/16 04:53:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.40	top5: 6.36	
[09/16 04:53:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 04:53:35 visual_prompt]: Epoch 40 / 100: avg data time: 8.30e-02, avg batch time: 0.4854, average train loss: 5.0405
[09/16 04:53:38 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1440, average loss: 4.9421
[09/16 04:53:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.50	top5: 9.00	
[09/16 04:53:59 visual_prompt]: Inference (test):avg data time: 5.57e-03, avg batch time: 0.1933, average loss: 4.9603
[09/16 04:53:59 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 1.56	top5: 6.62	
[09/16 04:53:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 04:54:08 visual_prompt]: Epoch 41 / 100: avg data time: 8.34e-02, avg batch time: 0.4883, average train loss: 4.8684
[09/16 04:54:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1435, average loss: 4.6136
[09/16 04:54:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 4.00	top5: 15.50	
[09/16 04:54:31 visual_prompt]: Inference (test):avg data time: 8.20e-03, avg batch time: 0.1937, average loss: 4.8748
[09/16 04:54:31 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 1.37	top5: 8.51	
[09/16 04:54:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 04:54:40 visual_prompt]: Epoch 42 / 100: avg data time: 8.87e-02, avg batch time: 0.4926, average train loss: 4.6339
[09/16 04:54:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1437, average loss: 4.3320
[09/16 04:54:42 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 7.50	top5: 21.50	
[09/16 04:55:03 visual_prompt]: Inference (test):avg data time: 6.72e-03, avg batch time: 0.1910, average loss: 4.6112
[09/16 04:55:03 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.43	top5: 12.54	
[09/16 04:55:03 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 04:55:12 visual_prompt]: Epoch 43 / 100: avg data time: 8.77e-02, avg batch time: 0.4922, average train loss: 4.4567
[09/16 04:55:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1448, average loss: 4.4216
[09/16 04:55:14 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 9.50	top5: 34.50	
[09/16 04:55:35 visual_prompt]: Inference (test):avg data time: 6.21e-03, avg batch time: 0.1930, average loss: 4.3222
[09/16 04:55:35 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 9.94	top5: 27.65	
[09/16 04:55:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 04:55:43 visual_prompt]: Epoch 44 / 100: avg data time: 7.81e-02, avg batch time: 0.4840, average train loss: 3.8502
[09/16 04:55:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1438, average loss: 2.7935
[09/16 04:55:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 38.00	top5: 69.00	
[09/16 04:56:07 visual_prompt]: Inference (test):avg data time: 6.27e-03, avg batch time: 0.1918, average loss: 3.5388
[09/16 04:56:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 23.48	top5: 54.24	
[09/16 04:56:07 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 04:56:16 visual_prompt]: Epoch 45 / 100: avg data time: 7.49e-02, avg batch time: 0.5096, average train loss: 2.5403
[09/16 04:56:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1437, average loss: 1.5384
[09/16 04:56:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 66.50	top5: 88.50	
[09/16 04:56:39 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1924, average loss: 2.2692
[09/16 04:56:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 50.37	top5: 73.54	
[09/16 04:56:39 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 04:56:48 visual_prompt]: Epoch 46 / 100: avg data time: 8.91e-02, avg batch time: 0.5242, average train loss: 0.8138
[09/16 04:56:51 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1436, average loss: 0.7185
[09/16 04:56:51 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 85.50	top5: 97.00	
[09/16 04:57:12 visual_prompt]: Inference (test):avg data time: 5.28e-03, avg batch time: 0.1911, average loss: 1.2210
[09/16 04:57:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 72.42	top5: 90.73	
[09/16 04:57:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 04:57:21 visual_prompt]: Epoch 47 / 100: avg data time: 9.37e-02, avg batch time: 0.5058, average train loss: 0.2457
[09/16 04:57:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1438, average loss: 0.0725
[09/16 04:57:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.50	top5: 100.00	
[09/16 04:57:44 visual_prompt]: Inference (test):avg data time: 7.00e-03, avg batch time: 0.1926, average loss: 0.4988
[09/16 04:57:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.45	top5: 96.62	
[09/16 04:57:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 04:57:53 visual_prompt]: Epoch 48 / 100: avg data time: 9.75e-02, avg batch time: 0.5019, average train loss: 0.0529
[09/16 04:57:55 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1435, average loss: 0.0304
[09/16 04:57:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 04:58:16 visual_prompt]: Inference (test):avg data time: 6.74e-03, avg batch time: 0.1919, average loss: 0.5398
[09/16 04:58:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.04	top5: 96.75	
[09/16 04:58:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 04:58:25 visual_prompt]: Epoch 49 / 100: avg data time: 8.27e-02, avg batch time: 0.4880, average train loss: 0.0217
[09/16 04:58:28 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1435, average loss: 0.0072
[09/16 04:58:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:58:49 visual_prompt]: Inference (test):avg data time: 8.16e-03, avg batch time: 0.1923, average loss: 0.4758
[09/16 04:58:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.91	top5: 97.28	
[09/16 04:58:49 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 04:58:57 visual_prompt]: Epoch 50 / 100: avg data time: 8.98e-02, avg batch time: 0.4967, average train loss: 0.0087
[09/16 04:59:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1437, average loss: 0.0053
[09/16 04:59:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:59:21 visual_prompt]: Inference (test):avg data time: 7.60e-03, avg batch time: 0.1921, average loss: 0.3818
[09/16 04:59:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.80	top5: 97.54	
[09/16 04:59:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 04:59:29 visual_prompt]: Epoch 51 / 100: avg data time: 9.76e-02, avg batch time: 0.5011, average train loss: 0.0037
[09/16 04:59:32 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1437, average loss: 0.0057
[09/16 04:59:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 04:59:53 visual_prompt]: Inference (test):avg data time: 6.05e-03, avg batch time: 0.1918, average loss: 0.3210
[09/16 04:59:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.08	top5: 98.03	
[09/16 04:59:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 05:00:02 visual_prompt]: Epoch 52 / 100: avg data time: 9.98e-02, avg batch time: 0.5029, average train loss: 0.0045
[09/16 05:00:04 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1435, average loss: 0.0018
[09/16 05:00:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:00:25 visual_prompt]: Inference (test):avg data time: 6.59e-03, avg batch time: 0.1917, average loss: 0.3233
[09/16 05:00:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.90	top5: 98.06	
[09/16 05:00:25 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 05:00:34 visual_prompt]: Epoch 53 / 100: avg data time: 9.31e-02, avg batch time: 0.4947, average train loss: 0.0022
[09/16 05:00:36 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1438, average loss: 0.0053
[09/16 05:00:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 05:00:57 visual_prompt]: Inference (test):avg data time: 5.70e-03, avg batch time: 0.1919, average loss: 0.3180
[09/16 05:00:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.61	top5: 98.05	
[09/16 05:00:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 05:01:06 visual_prompt]: Epoch 54 / 100: avg data time: 9.43e-02, avg batch time: 0.4998, average train loss: 0.0031
[09/16 05:01:08 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1447, average loss: 0.0025
[09/16 05:01:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:01:30 visual_prompt]: Inference (test):avg data time: 5.97e-03, avg batch time: 0.1921, average loss: 0.3109
[09/16 05:01:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.85	top5: 98.03	
[09/16 05:01:30 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 05:01:38 visual_prompt]: Epoch 55 / 100: avg data time: 9.07e-02, avg batch time: 0.4946, average train loss: 0.0085
[09/16 05:01:41 visual_prompt]: Inference (val):avg data time: 3.02e-04, avg batch time: 0.2332, average loss: 0.0025
[09/16 05:01:41 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:02:02 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1930, average loss: 0.2944
[09/16 05:02:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.28	top5: 98.46	
[09/16 05:02:02 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 05:02:11 visual_prompt]: Epoch 56 / 100: avg data time: 7.19e-02, avg batch time: 0.4797, average train loss: 0.0029
[09/16 05:02:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1438, average loss: 0.0022
[09/16 05:02:14 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:02:35 visual_prompt]: Inference (test):avg data time: 6.75e-03, avg batch time: 0.1942, average loss: 0.2673
[09/16 05:02:35 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.97	top5: 98.46	
[09/16 05:02:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 05:02:43 visual_prompt]: Epoch 57 / 100: avg data time: 9.07e-02, avg batch time: 0.4955, average train loss: 0.0024
[09/16 05:02:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1439, average loss: 0.0025
[09/16 05:02:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:03:07 visual_prompt]: Inference (test):avg data time: 8.23e-03, avg batch time: 0.1928, average loss: 0.2649
[09/16 05:03:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.20	top5: 98.54	
[09/16 05:03:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 05:03:16 visual_prompt]: Epoch 58 / 100: avg data time: 9.26e-02, avg batch time: 0.4983, average train loss: 0.0026
[09/16 05:03:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1438, average loss: 0.0028
[09/16 05:03:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:03:39 visual_prompt]: Inference (test):avg data time: 5.32e-03, avg batch time: 0.1919, average loss: 0.2624
[09/16 05:03:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.20	top5: 98.60	
[09/16 05:03:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 05:03:48 visual_prompt]: Epoch 59 / 100: avg data time: 1.01e-01, avg batch time: 0.5032, average train loss: 0.0029
[09/16 05:03:51 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 05:03:51 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:04:12 visual_prompt]: Inference (test):avg data time: 7.07e-03, avg batch time: 0.1924, average loss: 0.2593
[09/16 05:04:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.22	top5: 98.63	
[09/16 05:04:12 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 05:04:20 visual_prompt]: Epoch 60 / 100: avg data time: 8.82e-02, avg batch time: 0.4933, average train loss: 0.0030
[09/16 05:04:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1437, average loss: 0.0031
[09/16 05:04:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:04:44 visual_prompt]: Inference (test):avg data time: 6.22e-03, avg batch time: 0.1924, average loss: 0.2598
[09/16 05:04:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.40	top5: 98.59	
[09/16 05:04:44 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 05:04:53 visual_prompt]: Epoch 61 / 100: avg data time: 8.87e-02, avg batch time: 0.4921, average train loss: 0.0032
[09/16 05:04:55 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1451, average loss: 0.0033
[09/16 05:04:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:05:16 visual_prompt]: Inference (test):avg data time: 6.16e-03, avg batch time: 0.1908, average loss: 0.2537
[09/16 05:05:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.58	top5: 98.62	
[09/16 05:05:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 05:05:24 visual_prompt]: Epoch 62 / 100: avg data time: 8.57e-02, avg batch time: 0.4889, average train loss: 0.0034
[09/16 05:05:27 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1438, average loss: 0.0036
[09/16 05:05:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:05:48 visual_prompt]: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1913, average loss: 0.2546
[09/16 05:05:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.72	top5: 98.60	
[09/16 05:05:48 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 05:05:57 visual_prompt]: Epoch 63 / 100: avg data time: 9.38e-02, avg batch time: 0.4978, average train loss: 0.0037
[09/16 05:05:59 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1438, average loss: 0.0037
[09/16 05:05:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:06:20 visual_prompt]: Inference (test):avg data time: 5.91e-03, avg batch time: 0.1918, average loss: 0.2504
[09/16 05:06:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.84	top5: 98.62	
[09/16 05:06:20 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 05:06:29 visual_prompt]: Epoch 64 / 100: avg data time: 9.27e-02, avg batch time: 0.5091, average train loss: 0.0041
[09/16 05:06:31 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1439, average loss: 0.0039
[09/16 05:06:31 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:06:52 visual_prompt]: Inference (test):avg data time: 6.56e-03, avg batch time: 0.1926, average loss: 0.2477
[09/16 05:06:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.93	top5: 98.63	
[09/16 05:06:52 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 05:07:01 visual_prompt]: Epoch 65 / 100: avg data time: 9.25e-02, avg batch time: 0.4992, average train loss: 0.0040
[09/16 05:07:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1439, average loss: 0.0039
[09/16 05:07:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:07:25 visual_prompt]: Inference (test):avg data time: 7.56e-03, avg batch time: 0.1930, average loss: 0.2406
[09/16 05:07:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.18	top5: 98.63	
[09/16 05:07:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 05:07:33 visual_prompt]: Epoch 66 / 100: avg data time: 9.09e-02, avg batch time: 0.4946, average train loss: 0.0042
[09/16 05:07:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1437, average loss: 0.0042
[09/16 05:07:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:07:57 visual_prompt]: Inference (test):avg data time: 6.25e-03, avg batch time: 0.1927, average loss: 0.2442
[09/16 05:07:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.15	top5: 98.62	
[09/16 05:07:57 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 05:08:06 visual_prompt]: Epoch 67 / 100: avg data time: 8.88e-02, avg batch time: 0.4916, average train loss: 0.0045
[09/16 05:08:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1438, average loss: 0.0044
[09/16 05:08:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:08:29 visual_prompt]: Inference (test):avg data time: 5.11e-03, avg batch time: 0.1924, average loss: 0.2420
[09/16 05:08:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.11	top5: 98.63	
[09/16 05:08:29 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 05:08:38 visual_prompt]: Epoch 68 / 100: avg data time: 7.65e-02, avg batch time: 0.4879, average train loss: 0.0045
[09/16 05:08:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1437, average loss: 0.0045
[09/16 05:08:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:09:01 visual_prompt]: Inference (test):avg data time: 6.57e-03, avg batch time: 0.1963, average loss: 0.2419
[09/16 05:09:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.98	top5: 98.68	
[09/16 05:09:01 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 05:09:10 visual_prompt]: Epoch 69 / 100: avg data time: 9.06e-02, avg batch time: 0.4926, average train loss: 0.0047
[09/16 05:09:12 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1438, average loss: 0.0046
[09/16 05:09:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:09:34 visual_prompt]: Inference (test):avg data time: 9.44e-03, avg batch time: 0.1970, average loss: 0.2461
[09/16 05:09:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.10	top5: 98.60	
[09/16 05:09:34 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 05:09:43 visual_prompt]: Epoch 70 / 100: avg data time: 8.94e-02, avg batch time: 0.4921, average train loss: 0.0048
[09/16 05:09:45 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1437, average loss: 0.0046
[09/16 05:09:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:10:06 visual_prompt]: Inference (test):avg data time: 6.19e-03, avg batch time: 0.1918, average loss: 0.2413
[09/16 05:10:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.19	top5: 98.65	
[09/16 05:10:06 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 05:10:15 visual_prompt]: Epoch 71 / 100: avg data time: 9.32e-02, avg batch time: 0.4973, average train loss: 0.0049
[09/16 05:10:17 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1440, average loss: 0.0047
[09/16 05:10:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:10:39 visual_prompt]: Inference (test):avg data time: 7.11e-03, avg batch time: 0.2015, average loss: 0.2419
[09/16 05:10:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.19	top5: 98.67	
[09/16 05:10:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 05:10:48 visual_prompt]: Epoch 72 / 100: avg data time: 8.78e-02, avg batch time: 0.4923, average train loss: 0.0049
[09/16 05:10:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.0048
[09/16 05:10:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:11:12 visual_prompt]: Inference (test):avg data time: 5.91e-03, avg batch time: 0.1924, average loss: 0.2432
[09/16 05:11:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.15	top5: 98.67	
[09/16 05:11:12 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 05:11:20 visual_prompt]: Epoch 73 / 100: avg data time: 8.25e-02, avg batch time: 0.4860, average train loss: 0.0051
[09/16 05:11:23 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1435, average loss: 0.0049
[09/16 05:11:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:11:44 visual_prompt]: Inference (test):avg data time: 7.62e-03, avg batch time: 0.1938, average loss: 0.2429
[09/16 05:11:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.13	top5: 98.63	
[09/16 05:11:44 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 05:11:53 visual_prompt]: Epoch 74 / 100: avg data time: 9.35e-02, avg batch time: 0.4970, average train loss: 0.0050
[09/16 05:11:55 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1436, average loss: 0.0046
[09/16 05:11:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:12:16 visual_prompt]: Inference (test):avg data time: 8.41e-03, avg batch time: 0.1928, average loss: 0.2369
[09/16 05:12:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.23	top5: 98.62	
[09/16 05:12:16 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 05:12:25 visual_prompt]: Epoch 75 / 100: avg data time: 8.72e-02, avg batch time: 0.4928, average train loss: 0.0050
[09/16 05:12:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1437, average loss: 0.0048
[09/16 05:12:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:12:48 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1919, average loss: 0.2378
[09/16 05:12:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.29	top5: 98.76	
[09/16 05:12:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 05:12:57 visual_prompt]: Epoch 76 / 100: avg data time: 8.10e-02, avg batch time: 0.4845, average train loss: 0.0050
[09/16 05:12:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1438, average loss: 0.0049
[09/16 05:12:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:13:20 visual_prompt]: Inference (test):avg data time: 6.72e-03, avg batch time: 0.1935, average loss: 0.2381
[09/16 05:13:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.23	top5: 98.63	
[09/16 05:13:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 05:13:29 visual_prompt]: Epoch 77 / 100: avg data time: 1.00e-01, avg batch time: 0.5028, average train loss: 0.0051
[09/16 05:13:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1439, average loss: 0.0046
[09/16 05:13:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:13:53 visual_prompt]: Inference (test):avg data time: 8.67e-03, avg batch time: 0.1938, average loss: 0.2345
[09/16 05:13:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.31	top5: 98.70	
[09/16 05:13:53 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 05:14:01 visual_prompt]: Epoch 78 / 100: avg data time: 8.28e-02, avg batch time: 0.4883, average train loss: 0.0049
[09/16 05:14:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1440, average loss: 0.0047
[09/16 05:14:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:14:25 visual_prompt]: Inference (test):avg data time: 6.85e-03, avg batch time: 0.1929, average loss: 0.2343
[09/16 05:14:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.36	top5: 98.75	
[09/16 05:14:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 05:14:34 visual_prompt]: Epoch 79 / 100: avg data time: 9.46e-02, avg batch time: 0.4971, average train loss: 0.0049
[09/16 05:14:36 visual_prompt]: Inference (val):avg data time: 5.27e-05, avg batch time: 0.1483, average loss: 0.0048
[09/16 05:14:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:14:57 visual_prompt]: Inference (test):avg data time: 6.40e-03, avg batch time: 0.1927, average loss: 0.2316
[09/16 05:14:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.37	top5: 98.83	
[09/16 05:14:57 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 05:15:06 visual_prompt]: Epoch 80 / 100: avg data time: 9.08e-02, avg batch time: 0.4937, average train loss: 0.0051
[09/16 05:15:08 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1435, average loss: 0.0047
[09/16 05:15:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:15:29 visual_prompt]: Inference (test):avg data time: 5.94e-03, avg batch time: 0.1922, average loss: 0.2340
[09/16 05:15:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.34	top5: 98.76	
[09/16 05:15:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 05:15:38 visual_prompt]: Epoch 81 / 100: avg data time: 8.67e-02, avg batch time: 0.4897, average train loss: 0.0051
[09/16 05:15:40 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1436, average loss: 0.0047
[09/16 05:15:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:16:01 visual_prompt]: Inference (test):avg data time: 6.79e-03, avg batch time: 0.1916, average loss: 0.2317
[09/16 05:16:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.37	top5: 98.80	
[09/16 05:16:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 05:16:10 visual_prompt]: Epoch 82 / 100: avg data time: 9.31e-02, avg batch time: 0.4954, average train loss: 0.0051
[09/16 05:16:12 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1439, average loss: 0.0045
[09/16 05:16:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:16:33 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1933, average loss: 0.2286
[09/16 05:16:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.41	top5: 98.75	
[09/16 05:16:33 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 05:16:42 visual_prompt]: Epoch 83 / 100: avg data time: 8.98e-02, avg batch time: 0.4944, average train loss: 0.0051
[09/16 05:16:45 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1486, average loss: 0.0047
[09/16 05:16:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:17:06 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1914, average loss: 0.2314
[09/16 05:17:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.36	top5: 98.76	
[09/16 05:17:06 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 05:17:15 visual_prompt]: Epoch 84 / 100: avg data time: 9.19e-02, avg batch time: 0.4964, average train loss: 0.0049
[09/16 05:17:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1438, average loss: 0.0046
[09/16 05:17:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:17:38 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1923, average loss: 0.2296
[09/16 05:17:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.44	top5: 98.83	
[09/16 05:17:38 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 05:17:47 visual_prompt]: Epoch 85 / 100: avg data time: 9.81e-02, avg batch time: 0.5001, average train loss: 0.0050
[09/16 05:17:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.0046
[09/16 05:17:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:18:11 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1912, average loss: 0.2288
[09/16 05:18:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.45	top5: 98.81	
[09/16 05:18:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 05:18:19 visual_prompt]: Epoch 86 / 100: avg data time: 8.62e-02, avg batch time: 0.4900, average train loss: 0.0050
[09/16 05:18:22 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1436, average loss: 0.0045
[09/16 05:18:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:18:43 visual_prompt]: Inference (test):avg data time: 7.96e-03, avg batch time: 0.1930, average loss: 0.2267
[09/16 05:18:43 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.50	top5: 98.85	
[09/16 05:18:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 05:18:51 visual_prompt]: Epoch 87 / 100: avg data time: 8.78e-02, avg batch time: 0.4920, average train loss: 0.0050
[09/16 05:18:54 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1441, average loss: 0.0046
[09/16 05:18:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:19:15 visual_prompt]: Inference (test):avg data time: 5.90e-03, avg batch time: 0.1978, average loss: 0.2274
[09/16 05:19:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.47	top5: 98.81	
[09/16 05:19:15 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 05:19:24 visual_prompt]: Epoch 88 / 100: avg data time: 9.91e-02, avg batch time: 0.5014, average train loss: 0.0049
[09/16 05:19:27 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1452, average loss: 0.0045
[09/16 05:19:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:19:48 visual_prompt]: Inference (test):avg data time: 6.02e-03, avg batch time: 0.1960, average loss: 0.2273
[09/16 05:19:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.44	top5: 98.78	
[09/16 05:19:48 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 05:19:57 visual_prompt]: Epoch 89 / 100: avg data time: 8.67e-02, avg batch time: 0.4928, average train loss: 0.0049
[09/16 05:20:00 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1442, average loss: 0.0045
[09/16 05:20:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:20:20 visual_prompt]: Inference (test):avg data time: 7.66e-03, avg batch time: 0.1921, average loss: 0.2267
[09/16 05:20:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.54	top5: 98.81	
[09/16 05:20:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 05:20:29 visual_prompt]: Epoch 90 / 100: avg data time: 8.72e-02, avg batch time: 0.4905, average train loss: 0.0049
[09/16 05:20:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1435, average loss: 0.0045
[09/16 05:20:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:20:53 visual_prompt]: Inference (test):avg data time: 5.74e-03, avg batch time: 0.1964, average loss: 0.2272
[09/16 05:20:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.52	top5: 98.78	
[09/16 05:20:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 05:21:01 visual_prompt]: Epoch 91 / 100: avg data time: 7.46e-02, avg batch time: 0.4816, average train loss: 0.0049
[09/16 05:21:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1437, average loss: 0.0045
[09/16 05:21:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:21:25 visual_prompt]: Inference (test):avg data time: 6.62e-03, avg batch time: 0.1937, average loss: 0.2262
[09/16 05:21:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.52	top5: 98.80	
[09/16 05:21:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 05:21:34 visual_prompt]: Epoch 92 / 100: avg data time: 8.71e-02, avg batch time: 0.4928, average train loss: 0.0049
[09/16 05:21:36 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1436, average loss: 0.0044
[09/16 05:21:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:21:57 visual_prompt]: Inference (test):avg data time: 5.55e-03, avg batch time: 0.1902, average loss: 0.2253
[09/16 05:21:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.58	top5: 98.83	
[09/16 05:21:57 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 05:22:06 visual_prompt]: Epoch 93 / 100: avg data time: 9.52e-02, avg batch time: 0.5048, average train loss: 0.0049
[09/16 05:22:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1438, average loss: 0.0045
[09/16 05:22:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:22:29 visual_prompt]: Inference (test):avg data time: 7.05e-03, avg batch time: 0.1944, average loss: 0.2266
[09/16 05:22:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.54	top5: 98.80	
[09/16 05:22:29 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 05:22:38 visual_prompt]: Epoch 94 / 100: avg data time: 9.14e-02, avg batch time: 0.4966, average train loss: 0.0048
[09/16 05:22:40 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1437, average loss: 0.0045
[09/16 05:22:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:23:01 visual_prompt]: Inference (test):avg data time: 6.34e-03, avg batch time: 0.1937, average loss: 0.2267
[09/16 05:23:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.55	top5: 98.80	
[09/16 05:23:02 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 05:23:10 visual_prompt]: Epoch 95 / 100: avg data time: 7.84e-02, avg batch time: 0.4838, average train loss: 0.0049
[09/16 05:23:12 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1437, average loss: 0.0045
[09/16 05:23:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:23:33 visual_prompt]: Inference (test):avg data time: 7.41e-03, avg batch time: 0.1933, average loss: 0.2263
[09/16 05:23:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.52	top5: 98.80	
[09/16 05:23:33 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 05:23:42 visual_prompt]: Epoch 96 / 100: avg data time: 9.51e-02, avg batch time: 0.5173, average train loss: 0.0049
[09/16 05:23:45 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1436, average loss: 0.0045
[09/16 05:23:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:24:06 visual_prompt]: Inference (test):avg data time: 9.03e-03, avg batch time: 0.1930, average loss: 0.2266
[09/16 05:24:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.54	top5: 98.81	
[09/16 05:24:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 05:24:15 visual_prompt]: Epoch 97 / 100: avg data time: 9.33e-02, avg batch time: 0.4984, average train loss: 0.0048
[09/16 05:24:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1437, average loss: 0.0045
[09/16 05:24:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:24:38 visual_prompt]: Inference (test):avg data time: 8.01e-03, avg batch time: 0.1932, average loss: 0.2263
[09/16 05:24:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.60	top5: 98.81	
[09/16 05:24:38 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 05:24:47 visual_prompt]: Epoch 98 / 100: avg data time: 7.44e-02, avg batch time: 0.4813, average train loss: 0.0049
[09/16 05:24:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1438, average loss: 0.0045
[09/16 05:24:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:25:10 visual_prompt]: Inference (test):avg data time: 7.98e-03, avg batch time: 0.1932, average loss: 0.2263
[09/16 05:25:10 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.60	top5: 98.81	
[09/16 05:25:10 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 05:25:19 visual_prompt]: Epoch 99 / 100: avg data time: 8.67e-02, avg batch time: 0.4897, average train loss: 0.0049
[09/16 05:25:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1436, average loss: 0.0045
[09/16 05:25:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:25:42 visual_prompt]: Inference (test):avg data time: 5.54e-03, avg batch time: 0.1911, average loss: 0.2263
[09/16 05:25:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.60	top5: 98.81	
[09/16 05:25:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 05:25:51 visual_prompt]: Epoch 100 / 100: avg data time: 9.20e-02, avg batch time: 0.5151, average train loss: 0.0048
[09/16 05:25:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1437, average loss: 0.0045
[09/16 05:25:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:26:15 visual_prompt]: Inference (test):avg data time: 6.96e-03, avg batch time: 0.1939, average loss: 0.2263
[09/16 05:26:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.60	top5: 98.81	
[09/16 05:26:38 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 05:26:38 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 05:26:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-oxford_flowers102', 'DATA.NUMBER_CLASSES', '102', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/16 05:26:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 05:26:38 visual_prompt]: Training with config:
[09/16 05:26:38 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-oxford_flowers102',
          'NO_TEST': False,
          'NUMBER_CLASSES': 102,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-oxford_flowers102/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 05:26:38 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 05:26:38.985075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 05:26:39.189300: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 05:26:40.089839: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 05:26:40.089924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 05:26:40.089940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 05:26:42.176896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 05:26:42.177003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 05:26:42.177017: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 05:26:42 visual_prompt]: Constructing vtab-oxford_flowers102 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
2023-09-16 05:26:42.208344: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 05:26:45 visual_prompt]: Number of images: 1000
[09/16 05:26:45 visual_prompt]: Number of classes: 102 / 102
[09/16 05:26:45 visual_prompt]: Loading validation data...
[09/16 05:26:45 visual_prompt]: Constructing vtab-oxford_flowers102 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 05:26:45 visual_prompt]: Number of images: 200
[09/16 05:26:45 visual_prompt]: Number of classes: 90 / 102
[09/16 05:26:45 visual_prompt]: Loading test data...
[09/16 05:26:45 visual_prompt]: Constructing vtab-oxford_flowers102 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split test, from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 05:26:59 visual_prompt]: Number of images: 6149
[09/16 05:26:59 visual_prompt]: Number of classes: 102 / 102
[09/16 05:26:59 visual_prompt]: Constructing models...
[09/16 05:27:02 visual_prompt]: Total Parameters: 86798694	 Gradient Parameters: 1000038
[09/16 05:27:02 visual_prompt]: tuned percent:1.152
[09/16 05:27:05 visual_prompt]: Device used for model: 0
[09/16 05:27:05 visual_prompt]: Setting up Evalutator...
[09/16 05:27:05 visual_prompt]: Setting up Trainer...
[09/16 05:27:05 visual_prompt]: 	Setting up the optimizer...
[09/16 05:27:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 05:27:15 visual_prompt]: Epoch 1 / 100: avg data time: 9.92e-02, avg batch time: 0.5805, average train loss: 4.6638
[09/16 05:27:17 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1432, average loss: 4.6613
[09/16 05:27:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.50	top5: 5.00	
[09/16 05:27:38 visual_prompt]: Inference (test):avg data time: 4.27e-03, avg batch time: 0.1895, average loss: 4.6742
[09/16 05:27:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.68	top5: 3.72	
[09/16 05:27:38 visual_prompt]: Best epoch 1: best metric: 0.015
[09/16 05:27:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 05:27:46 visual_prompt]: Epoch 2 / 100: avg data time: 7.43e-02, avg batch time: 0.4805, average train loss: 4.6009
[09/16 05:27:49 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1433, average loss: 4.2282
[09/16 05:27:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 6.00	top5: 19.50	
[09/16 05:28:10 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1918, average loss: 4.3990
[09/16 05:28:10 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 4.63	top5: 14.52	
[09/16 05:28:10 visual_prompt]: Best epoch 2: best metric: 0.060
[09/16 05:28:10 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 05:28:18 visual_prompt]: Epoch 3 / 100: avg data time: 8.94e-02, avg batch time: 0.4954, average train loss: 4.2080
[09/16 05:28:21 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1436, average loss: 3.8715
[09/16 05:28:21 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 11.00	top5: 29.00	
[09/16 05:28:42 visual_prompt]: Inference (test):avg data time: 6.69e-03, avg batch time: 0.1919, average loss: 4.1133
[09/16 05:28:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 8.13	top5: 24.48	
[09/16 05:28:42 visual_prompt]: Best epoch 3: best metric: 0.110
[09/16 05:28:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 05:28:51 visual_prompt]: Epoch 4 / 100: avg data time: 9.20e-02, avg batch time: 0.4955, average train loss: 3.7645
[09/16 05:28:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1438, average loss: 1.9673
[09/16 05:28:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 51.00	top5: 76.00	
[09/16 05:29:14 visual_prompt]: Inference (test):avg data time: 7.61e-03, avg batch time: 0.1917, average loss: 2.6021
[09/16 05:29:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 38.43	top5: 66.47	
[09/16 05:29:14 visual_prompt]: Best epoch 4: best metric: 0.510
[09/16 05:29:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 05:29:23 visual_prompt]: Epoch 5 / 100: avg data time: 8.71e-02, avg batch time: 0.4909, average train loss: 1.4274
[09/16 05:29:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1441, average loss: 0.1574
[09/16 05:29:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.50	top5: 100.00	
[09/16 05:29:46 visual_prompt]: Inference (test):avg data time: 6.42e-03, avg batch time: 0.1920, average loss: 0.5987
[09/16 05:29:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 84.97	top5: 96.15	
[09/16 05:29:46 visual_prompt]: Best epoch 5: best metric: 0.975
[09/16 05:29:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 05:29:55 visual_prompt]: Epoch 6 / 100: avg data time: 9.17e-02, avg batch time: 0.4948, average train loss: 0.1424
[09/16 05:29:58 visual_prompt]: Inference (val):avg data time: 3.75e-04, avg batch time: 0.2154, average loss: 0.0611
[09/16 05:29:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 05:30:19 visual_prompt]: Inference (test):avg data time: 6.72e-03, avg batch time: 0.1923, average loss: 0.4261
[09/16 05:30:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.13	top5: 97.46	
[09/16 05:30:19 visual_prompt]: Best epoch 6: best metric: 0.980
[09/16 05:30:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 05:30:27 visual_prompt]: Epoch 7 / 100: avg data time: 8.54e-02, avg batch time: 0.4880, average train loss: 0.0594
[09/16 05:30:30 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1440, average loss: 0.0288
[09/16 05:30:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 05:30:51 visual_prompt]: Inference (test):avg data time: 6.10e-03, avg batch time: 0.1920, average loss: 0.3023
[09/16 05:30:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 91.88	top5: 98.52	
[09/16 05:30:51 visual_prompt]: Best epoch 7: best metric: 0.995
[09/16 05:30:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 05:30:59 visual_prompt]: Epoch 8 / 100: avg data time: 8.35e-02, avg batch time: 0.4886, average train loss: 0.0191
[09/16 05:31:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1440, average loss: 0.0157
[09/16 05:31:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:31:23 visual_prompt]: Inference (test):avg data time: 7.05e-03, avg batch time: 0.1921, average loss: 0.3077
[09/16 05:31:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.06	top5: 98.10	
[09/16 05:31:23 visual_prompt]: Best epoch 8: best metric: 1.000
[09/16 05:31:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 05:31:31 visual_prompt]: Epoch 9 / 100: avg data time: 8.65e-02, avg batch time: 0.4927, average train loss: 0.0170
[09/16 05:31:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1441, average loss: 0.0109
[09/16 05:31:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:31:55 visual_prompt]: Inference (test):avg data time: 6.77e-03, avg batch time: 0.1923, average loss: 0.2790
[09/16 05:31:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.45	top5: 98.76	
[09/16 05:31:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 05:32:03 visual_prompt]: Epoch 10 / 100: avg data time: 8.25e-02, avg batch time: 0.4880, average train loss: 0.0383
[09/16 05:32:06 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1435, average loss: 0.0136
[09/16 05:32:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:32:27 visual_prompt]: Inference (test):avg data time: 7.02e-03, avg batch time: 0.1974, average loss: 0.2830
[09/16 05:32:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.71	top5: 98.44	
[09/16 05:32:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 05:32:36 visual_prompt]: Epoch 11 / 100: avg data time: 9.13e-02, avg batch time: 0.5180, average train loss: 0.0212
[09/16 05:32:39 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1437, average loss: 0.0207
[09/16 05:32:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:33:00 visual_prompt]: Inference (test):avg data time: 5.63e-03, avg batch time: 0.1976, average loss: 0.2185
[09/16 05:33:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.26	top5: 99.06	
[09/16 05:33:00 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 05:33:09 visual_prompt]: Epoch 12 / 100: avg data time: 9.61e-02, avg batch time: 0.4980, average train loss: 0.0329
[09/16 05:33:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1437, average loss: 0.0170
[09/16 05:33:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:33:33 visual_prompt]: Inference (test):avg data time: 6.94e-03, avg batch time: 0.1924, average loss: 0.3119
[09/16 05:33:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.39	top5: 98.19	
[09/16 05:33:33 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 05:33:41 visual_prompt]: Epoch 13 / 100: avg data time: 8.71e-02, avg batch time: 0.4918, average train loss: 0.0218
[09/16 05:33:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1438, average loss: 0.0053
[09/16 05:33:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:34:04 visual_prompt]: Inference (test):avg data time: 6.48e-03, avg batch time: 0.1917, average loss: 0.1967
[09/16 05:34:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.99	top5: 99.01	
[09/16 05:34:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 05:34:13 visual_prompt]: Epoch 14 / 100: avg data time: 9.63e-02, avg batch time: 0.4990, average train loss: 0.0124
[09/16 05:34:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1439, average loss: 0.0056
[09/16 05:34:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:34:36 visual_prompt]: Inference (test):avg data time: 5.11e-03, avg batch time: 0.1904, average loss: 0.2091
[09/16 05:34:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.52	top5: 98.75	
[09/16 05:34:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 05:34:45 visual_prompt]: Epoch 15 / 100: avg data time: 7.89e-02, avg batch time: 0.4850, average train loss: 0.0066
[09/16 05:34:47 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 05:34:47 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:35:08 visual_prompt]: Inference (test):avg data time: 6.33e-03, avg batch time: 0.1921, average loss: 0.1642
[09/16 05:35:08 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.02	top5: 99.20	
[09/16 05:35:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 05:35:17 visual_prompt]: Epoch 16 / 100: avg data time: 9.95e-02, avg batch time: 0.5031, average train loss: 0.0034
[09/16 05:35:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1437, average loss: 0.0022
[09/16 05:35:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:35:41 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1914, average loss: 0.1346
[09/16 05:35:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.91	top5: 99.37	
[09/16 05:35:41 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 05:35:49 visual_prompt]: Epoch 17 / 100: avg data time: 8.69e-02, avg batch time: 0.4890, average train loss: 0.0030
[09/16 05:35:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1439, average loss: 0.0024
[09/16 05:35:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:36:13 visual_prompt]: Inference (test):avg data time: 8.76e-03, avg batch time: 0.1941, average loss: 0.1316
[09/16 05:36:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.14	top5: 99.27	
[09/16 05:36:13 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 05:36:21 visual_prompt]: Epoch 18 / 100: avg data time: 9.24e-02, avg batch time: 0.4954, average train loss: 0.0033
[09/16 05:36:24 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1437, average loss: 0.0027
[09/16 05:36:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:36:45 visual_prompt]: Inference (test):avg data time: 5.34e-03, avg batch time: 0.1911, average loss: 0.1279
[09/16 05:36:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.33	top5: 99.37	
[09/16 05:36:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 05:36:53 visual_prompt]: Epoch 19 / 100: avg data time: 9.18e-02, avg batch time: 0.4966, average train loss: 0.0038
[09/16 05:36:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 05:36:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:37:17 visual_prompt]: Inference (test):avg data time: 6.99e-03, avg batch time: 0.1922, average loss: 0.1248
[09/16 05:37:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.61	top5: 99.45	
[09/16 05:37:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 05:37:25 visual_prompt]: Epoch 20 / 100: avg data time: 9.53e-02, avg batch time: 0.5009, average train loss: 0.0043
[09/16 05:37:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1436, average loss: 0.0034
[09/16 05:37:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:37:49 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1926, average loss: 0.1264
[09/16 05:37:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.58	top5: 99.51	
[09/16 05:37:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 05:37:57 visual_prompt]: Epoch 21 / 100: avg data time: 9.16e-02, avg batch time: 0.4955, average train loss: 0.0049
[09/16 05:38:00 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1436, average loss: 0.0037
[09/16 05:38:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:38:21 visual_prompt]: Inference (test):avg data time: 6.37e-03, avg batch time: 0.1923, average loss: 0.1295
[09/16 05:38:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.41	top5: 99.45	
[09/16 05:38:21 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 05:38:29 visual_prompt]: Epoch 22 / 100: avg data time: 8.45e-02, avg batch time: 0.4905, average train loss: 0.0052
[09/16 05:38:32 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1437, average loss: 0.0038
[09/16 05:38:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:38:53 visual_prompt]: Inference (test):avg data time: 7.83e-03, avg batch time: 0.1930, average loss: 0.1228
[09/16 05:38:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.72	top5: 99.61	
[09/16 05:38:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 05:39:02 visual_prompt]: Epoch 23 / 100: avg data time: 8.84e-02, avg batch time: 0.4936, average train loss: 0.0052
[09/16 05:39:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1436, average loss: 0.0038
[09/16 05:39:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:39:25 visual_prompt]: Inference (test):avg data time: 6.13e-03, avg batch time: 0.1914, average loss: 0.1129
[09/16 05:39:25 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.92	top5: 99.71	
[09/16 05:39:25 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 05:39:34 visual_prompt]: Epoch 24 / 100: avg data time: 8.44e-02, avg batch time: 0.4906, average train loss: 0.0048
[09/16 05:39:36 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1466, average loss: 0.0033
[09/16 05:39:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:39:57 visual_prompt]: Inference (test):avg data time: 6.55e-03, avg batch time: 0.1923, average loss: 0.1196
[09/16 05:39:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.67	top5: 99.64	
[09/16 05:39:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 05:40:05 visual_prompt]: Epoch 25 / 100: avg data time: 8.41e-02, avg batch time: 0.4883, average train loss: 0.0047
[09/16 05:40:08 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1438, average loss: 0.0035
[09/16 05:40:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:40:29 visual_prompt]: Inference (test):avg data time: 8.50e-03, avg batch time: 0.1923, average loss: 0.1125
[09/16 05:40:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.77	top5: 99.59	
[09/16 05:40:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 05:40:37 visual_prompt]: Epoch 26 / 100: avg data time: 7.82e-02, avg batch time: 0.4834, average train loss: 0.0049
[09/16 05:40:40 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1489, average loss: 0.0036
[09/16 05:40:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:41:01 visual_prompt]: Inference (test):avg data time: 6.56e-03, avg batch time: 0.1916, average loss: 0.1135
[09/16 05:41:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.89	top5: 99.63	
[09/16 05:41:01 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 05:41:10 visual_prompt]: Epoch 27 / 100: avg data time: 9.07e-02, avg batch time: 0.5133, average train loss: 0.0051
[09/16 05:41:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1437, average loss: 0.0043
[09/16 05:41:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:41:33 visual_prompt]: Inference (test):avg data time: 5.77e-03, avg batch time: 0.1909, average loss: 0.1219
[09/16 05:41:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.56	top5: 99.54	
[09/16 05:41:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 05:41:42 visual_prompt]: Epoch 28 / 100: avg data time: 8.41e-02, avg batch time: 0.4898, average train loss: 0.0051
[09/16 05:41:45 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1438, average loss: 0.0035
[09/16 05:41:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:42:05 visual_prompt]: Inference (test):avg data time: 5.28e-03, avg batch time: 0.1910, average loss: 0.1168
[09/16 05:42:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.74	top5: 99.61	
[09/16 05:42:05 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 05:42:14 visual_prompt]: Epoch 29 / 100: avg data time: 9.28e-02, avg batch time: 0.4990, average train loss: 0.0048
[09/16 05:42:17 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.1435, average loss: 0.0033
[09/16 05:42:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:42:38 visual_prompt]: Inference (test):avg data time: 5.58e-03, avg batch time: 0.1916, average loss: 0.1151
[09/16 05:42:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.63	top5: 99.63	
[09/16 05:42:38 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 05:42:46 visual_prompt]: Epoch 30 / 100: avg data time: 9.66e-02, avg batch time: 0.4999, average train loss: 0.0043
[09/16 05:42:49 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1442, average loss: 0.0031
[09/16 05:42:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:43:10 visual_prompt]: Inference (test):avg data time: 7.04e-03, avg batch time: 0.1913, average loss: 0.1165
[09/16 05:43:10 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.58	top5: 99.53	
[09/16 05:43:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 05:43:18 visual_prompt]: Epoch 31 / 100: avg data time: 8.24e-02, avg batch time: 0.4883, average train loss: 0.0042
[09/16 05:43:21 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 05:43:21 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:43:42 visual_prompt]: Inference (test):avg data time: 6.33e-03, avg batch time: 0.1911, average loss: 0.1163
[09/16 05:43:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.56	top5: 99.54	
[09/16 05:43:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 05:43:50 visual_prompt]: Epoch 32 / 100: avg data time: 8.03e-02, avg batch time: 0.4870, average train loss: 0.0042
[09/16 05:43:53 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1439, average loss: 0.0031
[09/16 05:43:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:44:14 visual_prompt]: Inference (test):avg data time: 7.03e-03, avg batch time: 0.1922, average loss: 0.1155
[09/16 05:44:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.69	top5: 99.50	
[09/16 05:44:14 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 05:44:23 visual_prompt]: Epoch 33 / 100: avg data time: 9.45e-02, avg batch time: 0.4974, average train loss: 0.0042
[09/16 05:44:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 05:44:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:44:46 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1927, average loss: 0.1160
[09/16 05:44:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.45	top5: 99.48	
[09/16 05:44:46 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 05:44:55 visual_prompt]: Epoch 34 / 100: avg data time: 8.49e-02, avg batch time: 0.4889, average train loss: 0.0040
[09/16 05:44:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1439, average loss: 0.0029
[09/16 05:44:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:45:18 visual_prompt]: Inference (test):avg data time: 5.14e-03, avg batch time: 0.1907, average loss: 0.1129
[09/16 05:45:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.67	top5: 99.50	
[09/16 05:45:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 05:45:27 visual_prompt]: Epoch 35 / 100: avg data time: 9.95e-02, avg batch time: 0.5037, average train loss: 0.0040
[09/16 05:45:29 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1437, average loss: 0.0031
[09/16 05:45:29 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:45:50 visual_prompt]: Inference (test):avg data time: 5.76e-03, avg batch time: 0.1917, average loss: 0.1164
[09/16 05:45:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.63	top5: 99.53	
[09/16 05:45:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 05:45:59 visual_prompt]: Epoch 36 / 100: avg data time: 9.38e-02, avg batch time: 0.5233, average train loss: 0.0042
[09/16 05:46:02 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1439, average loss: 0.0031
[09/16 05:46:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:46:23 visual_prompt]: Inference (test):avg data time: 6.19e-03, avg batch time: 0.1927, average loss: 0.1067
[09/16 05:46:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.58	top5: 99.64	
[09/16 05:46:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 05:46:31 visual_prompt]: Epoch 37 / 100: avg data time: 7.35e-02, avg batch time: 0.4837, average train loss: 0.0041
[09/16 05:46:34 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1439, average loss: 0.0032
[09/16 05:46:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:46:55 visual_prompt]: Inference (test):avg data time: 6.42e-03, avg batch time: 0.1910, average loss: 0.1101
[09/16 05:46:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.84	top5: 99.61	
[09/16 05:46:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 05:47:03 visual_prompt]: Epoch 38 / 100: avg data time: 9.47e-02, avg batch time: 0.4994, average train loss: 0.0040
[09/16 05:47:06 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 05:47:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:47:27 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1920, average loss: 0.1150
[09/16 05:47:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.69	top5: 99.58	
[09/16 05:47:27 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 05:47:36 visual_prompt]: Epoch 39 / 100: avg data time: 9.34e-02, avg batch time: 0.5069, average train loss: 0.0039
[09/16 05:47:38 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 05:47:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:48:00 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1968, average loss: 0.1183
[09/16 05:48:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.53	top5: 99.51	
[09/16 05:48:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 05:48:08 visual_prompt]: Epoch 40 / 100: avg data time: 8.55e-02, avg batch time: 0.4899, average train loss: 0.0038
[09/16 05:48:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1437, average loss: 0.0029
[09/16 05:48:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:48:32 visual_prompt]: Inference (test):avg data time: 6.66e-03, avg batch time: 0.1923, average loss: 0.1042
[09/16 05:48:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.58	
[09/16 05:48:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 05:48:41 visual_prompt]: Epoch 41 / 100: avg data time: 8.32e-02, avg batch time: 0.5447, average train loss: 0.0037
[09/16 05:48:44 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1438, average loss: 0.0028
[09/16 05:48:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:49:05 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1918, average loss: 0.1021
[09/16 05:49:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.90	top5: 99.71	
[09/16 05:49:05 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 05:49:13 visual_prompt]: Epoch 42 / 100: avg data time: 7.73e-02, avg batch time: 0.4826, average train loss: 0.0038
[09/16 05:49:16 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1439, average loss: 0.0029
[09/16 05:49:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:49:37 visual_prompt]: Inference (test):avg data time: 5.86e-03, avg batch time: 0.1923, average loss: 0.1211
[09/16 05:49:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.33	top5: 99.51	
[09/16 05:49:37 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 05:49:45 visual_prompt]: Epoch 43 / 100: avg data time: 9.28e-02, avg batch time: 0.4950, average train loss: 0.0039
[09/16 05:49:48 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 05:49:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:50:09 visual_prompt]: Inference (test):avg data time: 8.15e-03, avg batch time: 0.1934, average loss: 0.1115
[09/16 05:50:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.63	top5: 99.59	
[09/16 05:50:09 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 05:50:18 visual_prompt]: Epoch 44 / 100: avg data time: 8.48e-02, avg batch time: 0.4881, average train loss: 0.0061
[09/16 05:50:20 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1438, average loss: 4.8485
[09/16 05:50:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.00	top5: 10.00	
[09/16 05:50:41 visual_prompt]: Inference (test):avg data time: 6.88e-03, avg batch time: 0.1921, average loss: 4.8184
[09/16 05:50:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.33	top5: 10.33	
[09/16 05:50:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 05:50:49 visual_prompt]: Epoch 45 / 100: avg data time: 7.09e-02, avg batch time: 0.4770, average train loss: 4.8123
[09/16 05:50:52 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1436, average loss: 4.7841
[09/16 05:50:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 1.00	top5: 8.50	
[09/16 05:51:13 visual_prompt]: Inference (test):avg data time: 4.86e-03, avg batch time: 0.1908, average loss: 4.9795
[09/16 05:51:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.39	top5: 3.69	
[09/16 05:51:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 05:51:21 visual_prompt]: Epoch 46 / 100: avg data time: 9.58e-02, avg batch time: 0.4998, average train loss: 4.7803
[09/16 05:51:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1437, average loss: 4.9957
[09/16 05:51:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 6.50	top5: 24.00	
[09/16 05:51:45 visual_prompt]: Inference (test):avg data time: 8.98e-03, avg batch time: 0.1951, average loss: 5.6985
[09/16 05:51:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 4.36	top5: 14.83	
[09/16 05:51:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 05:51:54 visual_prompt]: Epoch 47 / 100: avg data time: 8.46e-02, avg batch time: 0.4923, average train loss: 3.7344
[09/16 05:51:56 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1438, average loss: 2.4663
[09/16 05:51:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 33.00	top5: 69.50	
[09/16 05:52:17 visual_prompt]: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1932, average loss: 2.9411
[09/16 05:52:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 26.61	top5: 56.63	
[09/16 05:52:17 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 05:52:26 visual_prompt]: Epoch 48 / 100: avg data time: 8.80e-02, avg batch time: 0.4911, average train loss: 2.0323
[09/16 05:52:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1436, average loss: 1.0352
[09/16 05:52:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 73.00	top5: 90.50	
[09/16 05:52:49 visual_prompt]: Inference (test):avg data time: 6.45e-03, avg batch time: 0.1926, average loss: 1.8389
[09/16 05:52:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 56.06	top5: 80.81	
[09/16 05:52:49 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 05:52:58 visual_prompt]: Epoch 49 / 100: avg data time: 9.33e-02, avg batch time: 0.4987, average train loss: 0.7098
[09/16 05:53:01 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1437, average loss: 0.3291
[09/16 05:53:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 90.50	top5: 99.00	
[09/16 05:53:22 visual_prompt]: Inference (test):avg data time: 6.74e-03, avg batch time: 0.1984, average loss: 1.0345
[09/16 05:53:22 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 74.74	top5: 91.80	
[09/16 05:53:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 05:53:31 visual_prompt]: Epoch 50 / 100: avg data time: 9.23e-02, avg batch time: 0.4962, average train loss: 0.3031
[09/16 05:53:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1436, average loss: 0.1400
[09/16 05:53:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 96.50	top5: 99.50	
[09/16 05:53:55 visual_prompt]: Inference (test):avg data time: 5.66e-03, avg batch time: 0.1919, average loss: 0.6262
[09/16 05:53:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 83.28	top5: 95.98	
[09/16 05:53:55 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 05:54:04 visual_prompt]: Epoch 51 / 100: avg data time: 1.05e-01, avg batch time: 0.5069, average train loss: 0.0935
[09/16 05:54:06 visual_prompt]: Inference (val):avg data time: 7.75e-05, avg batch time: 0.1482, average loss: 0.1023
[09/16 05:54:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 96.00	top5: 100.00	
[09/16 05:54:28 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1939, average loss: 0.6197
[09/16 05:54:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 83.83	top5: 96.98	
[09/16 05:54:28 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 05:54:36 visual_prompt]: Epoch 52 / 100: avg data time: 9.43e-02, avg batch time: 0.4985, average train loss: 0.0606
[09/16 05:54:39 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1438, average loss: 0.0241
[09/16 05:54:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.50	top5: 100.00	
[09/16 05:55:00 visual_prompt]: Inference (test):avg data time: 5.96e-03, avg batch time: 0.1912, average loss: 0.5257
[09/16 05:55:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 86.99	top5: 97.28	
[09/16 05:55:00 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 05:55:08 visual_prompt]: Epoch 53 / 100: avg data time: 8.77e-02, avg batch time: 0.4928, average train loss: 0.0300
[09/16 05:55:11 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1436, average loss: 0.0113
[09/16 05:55:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:55:32 visual_prompt]: Inference (test):avg data time: 6.54e-03, avg batch time: 0.1929, average loss: 0.5168
[09/16 05:55:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 88.29	top5: 96.67	
[09/16 05:55:32 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 05:55:40 visual_prompt]: Epoch 54 / 100: avg data time: 8.04e-02, avg batch time: 0.4843, average train loss: 0.0582
[09/16 05:55:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1434, average loss: 0.0190
[09/16 05:55:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 05:56:04 visual_prompt]: Inference (test):avg data time: 6.63e-03, avg batch time: 0.1949, average loss: 0.6915
[09/16 05:56:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 84.26	top5: 96.19	
[09/16 05:56:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 05:56:13 visual_prompt]: Epoch 55 / 100: avg data time: 9.18e-02, avg batch time: 0.4958, average train loss: 0.0337
[09/16 05:56:15 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1436, average loss: 0.0107
[09/16 05:56:15 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 05:56:36 visual_prompt]: Inference (test):avg data time: 6.11e-03, avg batch time: 0.1921, average loss: 0.3675
[09/16 05:56:36 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.75	top5: 97.69	
[09/16 05:56:36 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 05:56:45 visual_prompt]: Epoch 56 / 100: avg data time: 9.41e-02, avg batch time: 0.4994, average train loss: 0.0154
[09/16 05:56:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1436, average loss: 0.0097
[09/16 05:56:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 05:57:09 visual_prompt]: Inference (test):avg data time: 8.51e-03, avg batch time: 0.1931, average loss: 0.3625
[09/16 05:57:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.91	top5: 97.80	
[09/16 05:57:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 05:57:18 visual_prompt]: Epoch 57 / 100: avg data time: 8.80e-02, avg batch time: 0.4926, average train loss: 0.0056
[09/16 05:57:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1435, average loss: 0.0019
[09/16 05:57:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:57:41 visual_prompt]: Inference (test):avg data time: 7.47e-03, avg batch time: 0.1945, average loss: 0.3112
[09/16 05:57:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.31	top5: 98.11	
[09/16 05:57:41 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 05:57:50 visual_prompt]: Epoch 58 / 100: avg data time: 8.71e-02, avg batch time: 0.4909, average train loss: 0.0025
[09/16 05:57:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1437, average loss: 0.0012
[09/16 05:57:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:58:13 visual_prompt]: Inference (test):avg data time: 6.35e-03, avg batch time: 0.1914, average loss: 0.3001
[09/16 05:58:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.67	top5: 98.10	
[09/16 05:58:13 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 05:58:22 visual_prompt]: Epoch 59 / 100: avg data time: 9.11e-02, avg batch time: 0.4949, average train loss: 0.0017
[09/16 05:58:25 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1438, average loss: 0.0009
[09/16 05:58:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:58:46 visual_prompt]: Inference (test):avg data time: 7.39e-03, avg batch time: 0.1939, average loss: 0.2774
[09/16 05:58:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.17	top5: 98.24	
[09/16 05:58:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 05:58:54 visual_prompt]: Epoch 60 / 100: avg data time: 8.63e-02, avg batch time: 0.4895, average train loss: 0.0016
[09/16 05:58:57 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1439, average loss: 0.0009
[09/16 05:58:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:59:17 visual_prompt]: Inference (test):avg data time: 7.51e-03, avg batch time: 0.1925, average loss: 0.2631
[09/16 05:59:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.38	top5: 98.31	
[09/16 05:59:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 05:59:26 visual_prompt]: Epoch 61 / 100: avg data time: 8.92e-02, avg batch time: 0.4938, average train loss: 0.0019
[09/16 05:59:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1434, average loss: 0.0010
[09/16 05:59:29 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 05:59:49 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1922, average loss: 0.2574
[09/16 05:59:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.51	top5: 98.36	
[09/16 05:59:49 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 05:59:58 visual_prompt]: Epoch 62 / 100: avg data time: 8.63e-02, avg batch time: 0.4886, average train loss: 0.0019
[09/16 06:00:01 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1443, average loss: 0.0012
[09/16 06:00:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:00:21 visual_prompt]: Inference (test):avg data time: 6.54e-03, avg batch time: 0.1924, average loss: 0.2554
[09/16 06:00:22 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.61	top5: 98.32	
[09/16 06:00:22 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 06:00:30 visual_prompt]: Epoch 63 / 100: avg data time: 9.11e-02, avg batch time: 0.4961, average train loss: 0.0021
[09/16 06:00:33 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1442, average loss: 0.0014
[09/16 06:00:33 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:00:54 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1944, average loss: 0.2538
[09/16 06:00:54 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.71	top5: 98.36	
[09/16 06:00:54 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 06:01:02 visual_prompt]: Epoch 64 / 100: avg data time: 9.01e-02, avg batch time: 0.4941, average train loss: 0.0024
[09/16 06:01:05 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1435, average loss: 0.0016
[09/16 06:01:05 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:01:26 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1966, average loss: 0.2505
[09/16 06:01:26 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.69	top5: 98.41	
[09/16 06:01:26 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 06:01:35 visual_prompt]: Epoch 65 / 100: avg data time: 8.94e-02, avg batch time: 0.4937, average train loss: 0.0026
[09/16 06:01:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.0018
[09/16 06:01:37 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:01:58 visual_prompt]: Inference (test):avg data time: 6.43e-03, avg batch time: 0.1919, average loss: 0.2441
[09/16 06:01:58 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.87	top5: 98.49	
[09/16 06:01:58 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 06:02:07 visual_prompt]: Epoch 66 / 100: avg data time: 7.47e-02, avg batch time: 0.4819, average train loss: 0.0030
[09/16 06:02:10 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1439, average loss: 0.0019
[09/16 06:02:10 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:02:30 visual_prompt]: Inference (test):avg data time: 6.02e-03, avg batch time: 0.1929, average loss: 0.2419
[09/16 06:02:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.87	top5: 98.50	
[09/16 06:02:30 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 06:02:39 visual_prompt]: Epoch 67 / 100: avg data time: 8.48e-02, avg batch time: 0.4883, average train loss: 0.0029
[09/16 06:02:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1439, average loss: 0.0021
[09/16 06:02:42 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:03:02 visual_prompt]: Inference (test):avg data time: 4.65e-03, avg batch time: 0.1906, average loss: 0.2377
[09/16 06:03:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.05	top5: 98.57	
[09/16 06:03:02 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 06:03:11 visual_prompt]: Epoch 68 / 100: avg data time: 9.31e-02, avg batch time: 0.4955, average train loss: 0.0031
[09/16 06:03:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1439, average loss: 0.0022
[09/16 06:03:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:03:34 visual_prompt]: Inference (test):avg data time: 5.90e-03, avg batch time: 0.1911, average loss: 0.2397
[09/16 06:03:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.10	top5: 98.54	
[09/16 06:03:34 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 06:03:43 visual_prompt]: Epoch 69 / 100: avg data time: 8.21e-02, avg batch time: 0.4873, average train loss: 0.0033
[09/16 06:03:45 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1435, average loss: 0.0024
[09/16 06:03:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:04:06 visual_prompt]: Inference (test):avg data time: 6.80e-03, avg batch time: 0.1921, average loss: 0.2382
[09/16 06:04:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.10	top5: 98.55	
[09/16 06:04:06 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 06:04:15 visual_prompt]: Epoch 70 / 100: avg data time: 8.27e-02, avg batch time: 0.4913, average train loss: 0.0034
[09/16 06:04:17 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1438, average loss: 0.0025
[09/16 06:04:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:04:38 visual_prompt]: Inference (test):avg data time: 5.65e-03, avg batch time: 0.1935, average loss: 0.2358
[09/16 06:04:38 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.23	top5: 98.55	
[09/16 06:04:38 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 06:04:47 visual_prompt]: Epoch 71 / 100: avg data time: 9.78e-02, avg batch time: 0.5012, average train loss: 0.0037
[09/16 06:04:50 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1436, average loss: 0.0026
[09/16 06:04:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:05:10 visual_prompt]: Inference (test):avg data time: 6.99e-03, avg batch time: 0.1917, average loss: 0.2320
[09/16 06:05:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.29	top5: 98.60	
[09/16 06:05:11 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 06:05:19 visual_prompt]: Epoch 72 / 100: avg data time: 7.91e-02, avg batch time: 0.4865, average train loss: 0.0038
[09/16 06:05:22 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1437, average loss: 0.0027
[09/16 06:05:22 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:05:43 visual_prompt]: Inference (test):avg data time: 7.12e-03, avg batch time: 0.1925, average loss: 0.2294
[09/16 06:05:43 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.49	top5: 98.59	
[09/16 06:05:43 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 06:05:51 visual_prompt]: Epoch 73 / 100: avg data time: 8.06e-02, avg batch time: 0.4862, average train loss: 0.0040
[09/16 06:05:54 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1438, average loss: 0.0027
[09/16 06:05:54 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:06:15 visual_prompt]: Inference (test):avg data time: 6.30e-03, avg batch time: 0.1924, average loss: 0.2237
[09/16 06:06:15 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.60	top5: 98.65	
[09/16 06:06:15 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 06:06:23 visual_prompt]: Epoch 74 / 100: avg data time: 7.47e-02, avg batch time: 0.4810, average train loss: 0.0039
[09/16 06:06:26 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1441, average loss: 0.0028
[09/16 06:06:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:06:47 visual_prompt]: Inference (test):avg data time: 9.47e-03, avg batch time: 0.1944, average loss: 0.2253
[09/16 06:06:47 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.57	top5: 98.63	
[09/16 06:06:47 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 06:06:56 visual_prompt]: Epoch 75 / 100: avg data time: 9.23e-02, avg batch time: 0.4978, average train loss: 0.0041
[09/16 06:06:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1441, average loss: 0.0029
[09/16 06:06:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:07:19 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1917, average loss: 0.2237
[09/16 06:07:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.63	top5: 98.70	
[09/16 06:07:19 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 06:07:28 visual_prompt]: Epoch 76 / 100: avg data time: 8.02e-02, avg batch time: 0.4861, average train loss: 0.0042
[09/16 06:07:30 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1438, average loss: 0.0029
[09/16 06:07:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:07:52 visual_prompt]: Inference (test):avg data time: 8.28e-03, avg batch time: 0.1985, average loss: 0.2215
[09/16 06:07:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.80	top5: 98.68	
[09/16 06:07:52 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 06:08:00 visual_prompt]: Epoch 77 / 100: avg data time: 8.27e-02, avg batch time: 0.4870, average train loss: 0.0043
[09/16 06:08:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1437, average loss: 0.0028
[09/16 06:08:03 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:08:23 visual_prompt]: Inference (test):avg data time: 6.64e-03, avg batch time: 0.1922, average loss: 0.2256
[09/16 06:08:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.55	top5: 98.63	
[09/16 06:08:24 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 06:08:32 visual_prompt]: Epoch 78 / 100: avg data time: 9.68e-02, avg batch time: 0.5023, average train loss: 0.0043
[09/16 06:08:35 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 06:08:35 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:08:56 visual_prompt]: Inference (test):avg data time: 5.72e-03, avg batch time: 0.1913, average loss: 0.2245
[09/16 06:08:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.71	top5: 98.63	
[09/16 06:08:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 06:09:04 visual_prompt]: Epoch 79 / 100: avg data time: 8.69e-02, avg batch time: 0.4909, average train loss: 0.0043
[09/16 06:09:07 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 06:09:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:09:28 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1925, average loss: 0.2166
[09/16 06:09:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.89	top5: 98.73	
[09/16 06:09:28 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 06:09:37 visual_prompt]: Epoch 80 / 100: avg data time: 8.24e-02, avg batch time: 0.5198, average train loss: 0.0045
[09/16 06:09:39 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 06:09:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:10:00 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1927, average loss: 0.2195
[09/16 06:10:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.88	top5: 98.65	
[09/16 06:10:00 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 06:10:09 visual_prompt]: Epoch 81 / 100: avg data time: 8.81e-02, avg batch time: 0.4923, average train loss: 0.0045
[09/16 06:10:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1439, average loss: 0.0029
[09/16 06:10:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:10:33 visual_prompt]: Inference (test):avg data time: 6.29e-03, avg batch time: 0.1914, average loss: 0.2127
[09/16 06:10:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.94	top5: 98.76	
[09/16 06:10:33 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 06:10:41 visual_prompt]: Epoch 82 / 100: avg data time: 8.83e-02, avg batch time: 0.4921, average train loss: 0.0046
[09/16 06:10:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1438, average loss: 0.0029
[09/16 06:10:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:11:05 visual_prompt]: Inference (test):avg data time: 7.14e-03, avg batch time: 0.1921, average loss: 0.2175
[09/16 06:11:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.86	top5: 98.70	
[09/16 06:11:05 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 06:11:13 visual_prompt]: Epoch 83 / 100: avg data time: 9.07e-02, avg batch time: 0.4984, average train loss: 0.0045
[09/16 06:11:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1438, average loss: 0.0029
[09/16 06:11:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:11:37 visual_prompt]: Inference (test):avg data time: 5.94e-03, avg batch time: 0.1929, average loss: 0.2145
[09/16 06:11:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.99	top5: 98.72	
[09/16 06:11:37 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 06:11:46 visual_prompt]: Epoch 84 / 100: avg data time: 8.81e-02, avg batch time: 0.4910, average train loss: 0.0044
[09/16 06:11:48 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 06:11:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:12:09 visual_prompt]: Inference (test):avg data time: 6.61e-03, avg batch time: 0.1920, average loss: 0.2192
[09/16 06:12:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.67	top5: 98.70	
[09/16 06:12:09 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 06:12:18 visual_prompt]: Epoch 85 / 100: avg data time: 8.24e-02, avg batch time: 0.4874, average train loss: 0.0045
[09/16 06:12:21 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 06:12:21 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:12:42 visual_prompt]: Inference (test):avg data time: 5.64e-03, avg batch time: 0.1949, average loss: 0.2171
[09/16 06:12:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.86	top5: 98.72	
[09/16 06:12:42 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 06:12:51 visual_prompt]: Epoch 86 / 100: avg data time: 8.03e-02, avg batch time: 0.4870, average train loss: 0.0045
[09/16 06:12:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 06:12:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:13:14 visual_prompt]: Inference (test):avg data time: 6.81e-03, avg batch time: 0.1925, average loss: 0.2135
[09/16 06:13:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.91	top5: 98.78	
[09/16 06:13:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 06:13:23 visual_prompt]: Epoch 87 / 100: avg data time: 8.77e-02, avg batch time: 0.4962, average train loss: 0.0044
[09/16 06:13:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1442, average loss: 0.0029
[09/16 06:13:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:13:46 visual_prompt]: Inference (test):avg data time: 6.74e-03, avg batch time: 0.1928, average loss: 0.2133
[09/16 06:13:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.99	top5: 98.75	
[09/16 06:13:46 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 06:13:55 visual_prompt]: Epoch 88 / 100: avg data time: 9.75e-02, avg batch time: 0.5003, average train loss: 0.0046
[09/16 06:13:58 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1439, average loss: 0.0031
[09/16 06:13:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:14:19 visual_prompt]: Inference (test):avg data time: 6.09e-03, avg batch time: 0.1920, average loss: 0.2141
[09/16 06:14:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.91	top5: 98.73	
[09/16 06:14:19 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 06:14:27 visual_prompt]: Epoch 89 / 100: avg data time: 9.22e-02, avg batch time: 0.4960, average train loss: 0.0046
[09/16 06:14:30 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 06:14:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:14:51 visual_prompt]: Inference (test):avg data time: 6.56e-03, avg batch time: 0.1928, average loss: 0.2151
[09/16 06:14:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.91	top5: 98.73	
[09/16 06:14:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 06:15:00 visual_prompt]: Epoch 90 / 100: avg data time: 9.64e-02, avg batch time: 0.5012, average train loss: 0.0045
[09/16 06:15:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1436, average loss: 0.0030
[09/16 06:15:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:15:23 visual_prompt]: Inference (test):avg data time: 6.34e-03, avg batch time: 0.1919, average loss: 0.2151
[09/16 06:15:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.84	top5: 98.70	
[09/16 06:15:23 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 06:15:32 visual_prompt]: Epoch 91 / 100: avg data time: 9.17e-02, avg batch time: 0.4963, average train loss: 0.0045
[09/16 06:15:34 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1436, average loss: 0.0030
[09/16 06:15:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:15:55 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1940, average loss: 0.2154
[09/16 06:15:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.84	top5: 98.72	
[09/16 06:15:55 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 06:16:04 visual_prompt]: Epoch 92 / 100: avg data time: 8.18e-02, avg batch time: 0.4864, average train loss: 0.0045
[09/16 06:16:06 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 06:16:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:16:27 visual_prompt]: Inference (test):avg data time: 5.33e-03, avg batch time: 0.1914, average loss: 0.2153
[09/16 06:16:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.81	top5: 98.73	
[09/16 06:16:27 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 06:16:36 visual_prompt]: Epoch 93 / 100: avg data time: 9.63e-02, avg batch time: 0.5008, average train loss: 0.0044
[09/16 06:16:39 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1435, average loss: 0.0030
[09/16 06:16:39 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:17:00 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1949, average loss: 0.2131
[09/16 06:17:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.91	top5: 98.75	
[09/16 06:17:00 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 06:17:08 visual_prompt]: Epoch 94 / 100: avg data time: 8.87e-02, avg batch time: 0.4927, average train loss: 0.0044
[09/16 06:17:11 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 06:17:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:17:32 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1930, average loss: 0.2137
[09/16 06:17:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.89	top5: 98.70	
[09/16 06:17:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 06:17:41 visual_prompt]: Epoch 95 / 100: avg data time: 9.57e-02, avg batch time: 0.4998, average train loss: 0.0047
[09/16 06:17:43 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1436, average loss: 0.0030
[09/16 06:17:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:18:04 visual_prompt]: Inference (test):avg data time: 7.87e-03, avg batch time: 0.1926, average loss: 0.2132
[09/16 06:18:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.93	top5: 98.73	
[09/16 06:18:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 06:18:13 visual_prompt]: Epoch 96 / 100: avg data time: 8.93e-02, avg batch time: 0.4943, average train loss: 0.0046
[09/16 06:18:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1443, average loss: 0.0030
[09/16 06:18:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:18:37 visual_prompt]: Inference (test):avg data time: 5.80e-03, avg batch time: 0.1934, average loss: 0.2126
[09/16 06:18:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.94	top5: 98.72	
[09/16 06:18:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 06:18:45 visual_prompt]: Epoch 97 / 100: avg data time: 8.10e-02, avg batch time: 0.4856, average train loss: 0.0045
[09/16 06:18:48 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 06:18:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:19:09 visual_prompt]: Inference (test):avg data time: 4.75e-03, avg batch time: 0.1966, average loss: 0.2131
[09/16 06:19:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.96	top5: 98.72	
[09/16 06:19:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 06:19:18 visual_prompt]: Epoch 98 / 100: avg data time: 8.88e-02, avg batch time: 0.4921, average train loss: 0.0045
[09/16 06:19:20 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1438, average loss: 0.0030
[09/16 06:19:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:19:42 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1998, average loss: 0.2130
[09/16 06:19:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.97	top5: 98.72	
[09/16 06:19:42 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 06:19:51 visual_prompt]: Epoch 99 / 100: avg data time: 9.45e-02, avg batch time: 0.4967, average train loss: 0.0044
[09/16 06:19:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 06:19:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:20:14 visual_prompt]: Inference (test):avg data time: 7.19e-03, avg batch time: 0.1918, average loss: 0.2130
[09/16 06:20:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.97	top5: 98.72	
[09/16 06:20:14 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 06:20:23 visual_prompt]: Epoch 100 / 100: avg data time: 9.20e-02, avg batch time: 0.4960, average train loss: 0.0045
[09/16 06:20:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1439, average loss: 0.0030
[09/16 06:20:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:20:46 visual_prompt]: Inference (test):avg data time: 6.07e-03, avg batch time: 0.1919, average loss: 0.2129
[09/16 06:20:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.97	top5: 98.72	
[09/16 06:20:57 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 06:20:57 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 06:20:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-oxford_flowers102', 'DATA.NUMBER_CLASSES', '102', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/16 06:20:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 06:20:57 visual_prompt]: Training with config:
[09/16 06:20:57 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-oxford_flowers102',
          'NO_TEST': False,
          'NUMBER_CLASSES': 102,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-oxford_flowers102/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 06:20:57 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 06:20:57.435442: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 06:20:57.639064: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 06:20:58.540410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 06:20:58.540491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 06:20:58.540500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 06:21:00.608076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 06:21:00.608192: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 06:21:00.608207: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 06:21:00 visual_prompt]: Constructing vtab-oxford_flowers102 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
2023-09-16 06:21:00.632428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 06:21:03 visual_prompt]: Number of images: 1000
[09/16 06:21:03 visual_prompt]: Number of classes: 102 / 102
[09/16 06:21:03 visual_prompt]: Loading validation data...
[09/16 06:21:03 visual_prompt]: Constructing vtab-oxford_flowers102 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split validation[:200], from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 06:21:04 visual_prompt]: Number of images: 200
[09/16 06:21:04 visual_prompt]: Number of classes: 90 / 102
[09/16 06:21:04 visual_prompt]: Loading test data...
[09/16 06:21:04 visual_prompt]: Constructing vtab-oxford_flowers102 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[INFO: dataset_builder.py:  510]: Reusing dataset oxford_flowers102 (visual_prompt_tuning/data_path/oxford_flowers102/2.1.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset oxford_flowers102 for split test, from visual_prompt_tuning/data_path/oxford_flowers102/2.1.1
[09/16 06:21:18 visual_prompt]: Number of images: 6149
[09/16 06:21:18 visual_prompt]: Number of classes: 102 / 102
[09/16 06:21:18 visual_prompt]: Constructing models...
[09/16 06:21:20 visual_prompt]: Total Parameters: 86798694	 Gradient Parameters: 1000038
[09/16 06:21:20 visual_prompt]: tuned percent:1.152
[09/16 06:21:23 visual_prompt]: Device used for model: 0
[09/16 06:21:23 visual_prompt]: Setting up Evalutator...
[09/16 06:21:23 visual_prompt]: Setting up Trainer...
[09/16 06:21:23 visual_prompt]: 	Setting up the optimizer...
[09/16 06:21:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 06:21:33 visual_prompt]: Epoch 1 / 100: avg data time: 9.61e-02, avg batch time: 0.5802, average train loss: 4.6736
[09/16 06:21:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1429, average loss: 4.7018
[09/16 06:21:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 0.50	top5: 3.00	
[09/16 06:21:56 visual_prompt]: Inference (test):avg data time: 6.23e-03, avg batch time: 0.1916, average loss: 4.6564
[09/16 06:21:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.50	top5: 3.53	
[09/16 06:21:56 visual_prompt]: Best epoch 1: best metric: 0.005
[09/16 06:21:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 06:22:05 visual_prompt]: Epoch 2 / 100: avg data time: 8.82e-02, avg batch time: 0.4932, average train loss: 4.6538
[09/16 06:22:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1434, average loss: 4.4634
[09/16 06:22:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 3.00	top5: 16.50	
[09/16 06:22:29 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1937, average loss: 4.5965
[09/16 06:22:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 3.02	top5: 9.25	
[09/16 06:22:29 visual_prompt]: Best epoch 2: best metric: 0.030
[09/16 06:22:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 06:22:37 visual_prompt]: Epoch 3 / 100: avg data time: 8.63e-02, avg batch time: 0.4912, average train loss: 4.3376
[09/16 06:22:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1433, average loss: 3.3737
[09/16 06:22:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 19.50	top5: 47.50	
[09/16 06:23:01 visual_prompt]: Inference (test):avg data time: 8.48e-03, avg batch time: 0.1996, average loss: 3.9055
[09/16 06:23:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 11.82	top5: 30.10	
[09/16 06:23:01 visual_prompt]: Best epoch 3: best metric: 0.195
[09/16 06:23:01 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 06:23:10 visual_prompt]: Epoch 4 / 100: avg data time: 9.87e-02, avg batch time: 0.5026, average train loss: 3.0373
[09/16 06:23:13 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1447, average loss: 1.3689
[09/16 06:23:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 70.00	top5: 87.00	
[09/16 06:23:33 visual_prompt]: Inference (test):avg data time: 6.07e-03, avg batch time: 0.1914, average loss: 1.8957
[09/16 06:23:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 55.13	top5: 77.12	
[09/16 06:23:33 visual_prompt]: Best epoch 4: best metric: 0.700
[09/16 06:23:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 06:23:42 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e-01, avg batch time: 0.5066, average train loss: 0.6297
[09/16 06:23:45 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1436, average loss: 0.0848
[09/16 06:23:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.00	top5: 100.00	
[09/16 06:24:06 visual_prompt]: Inference (test):avg data time: 6.25e-03, avg batch time: 0.1914, average loss: 0.4447
[09/16 06:24:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.36	top5: 97.74	
[09/16 06:24:06 visual_prompt]: Best epoch 5: best metric: 0.970
[09/16 06:24:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 06:24:14 visual_prompt]: Epoch 6 / 100: avg data time: 7.57e-02, avg batch time: 0.4808, average train loss: 0.1005
[09/16 06:24:17 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1435, average loss: 0.0628
[09/16 06:24:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 06:24:37 visual_prompt]: Inference (test):avg data time: 6.11e-03, avg batch time: 0.1914, average loss: 0.4558
[09/16 06:24:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 87.51	top5: 97.38	
[09/16 06:24:37 visual_prompt]: Best epoch 6: best metric: 0.980
[09/16 06:24:37 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 06:24:46 visual_prompt]: Epoch 7 / 100: avg data time: 9.50e-02, avg batch time: 0.4979, average train loss: 0.0788
[09/16 06:24:49 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1438, average loss: 0.0126
[09/16 06:24:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:25:10 visual_prompt]: Inference (test):avg data time: 6.60e-03, avg batch time: 0.1914, average loss: 0.2486
[09/16 06:25:10 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.45	top5: 99.02	
[09/16 06:25:10 visual_prompt]: Best epoch 7: best metric: 1.000
[09/16 06:25:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 06:25:18 visual_prompt]: Epoch 8 / 100: avg data time: 8.96e-02, avg batch time: 0.4934, average train loss: 0.0264
[09/16 06:25:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1436, average loss: 0.0113
[09/16 06:25:21 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 06:25:42 visual_prompt]: Inference (test):avg data time: 7.30e-03, avg batch time: 0.1925, average loss: 0.3090
[09/16 06:25:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.21	top5: 98.28	
[09/16 06:25:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 06:25:51 visual_prompt]: Epoch 9 / 100: avg data time: 8.57e-02, avg batch time: 0.4910, average train loss: 0.0167
[09/16 06:25:53 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1444, average loss: 0.0087
[09/16 06:25:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:26:14 visual_prompt]: Inference (test):avg data time: 6.64e-03, avg batch time: 0.1910, average loss: 0.2079
[09/16 06:26:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.58	top5: 98.91	
[09/16 06:26:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 06:26:22 visual_prompt]: Epoch 10 / 100: avg data time: 8.35e-02, avg batch time: 0.4879, average train loss: 0.0121
[09/16 06:26:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1437, average loss: 0.0317
[09/16 06:26:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 06:26:46 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1931, average loss: 0.1828
[09/16 06:26:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.20	top5: 99.06	
[09/16 06:26:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 06:26:55 visual_prompt]: Epoch 11 / 100: avg data time: 9.49e-02, avg batch time: 0.4987, average train loss: 0.0039
[09/16 06:26:57 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1440, average loss: 0.0038
[09/16 06:26:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:27:18 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1930, average loss: 0.1529
[09/16 06:27:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.85	top5: 99.40	
[09/16 06:27:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 06:27:27 visual_prompt]: Epoch 12 / 100: avg data time: 9.25e-02, avg batch time: 0.4949, average train loss: 0.0029
[09/16 06:27:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1440, average loss: 0.0021
[09/16 06:27:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:27:50 visual_prompt]: Inference (test):avg data time: 6.75e-03, avg batch time: 0.1939, average loss: 0.1343
[09/16 06:27:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.63	top5: 99.43	
[09/16 06:27:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 06:27:59 visual_prompt]: Epoch 13 / 100: avg data time: 9.07e-02, avg batch time: 0.4952, average train loss: 0.0024
[09/16 06:28:02 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1435, average loss: 0.0023
[09/16 06:28:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:28:23 visual_prompt]: Inference (test):avg data time: 8.70e-03, avg batch time: 0.1935, average loss: 0.1232
[09/16 06:28:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.01	top5: 99.51	
[09/16 06:28:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 06:28:31 visual_prompt]: Epoch 14 / 100: avg data time: 8.66e-02, avg batch time: 0.4949, average train loss: 0.0027
[09/16 06:28:34 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1471, average loss: 0.0027
[09/16 06:28:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:28:55 visual_prompt]: Inference (test):avg data time: 6.33e-03, avg batch time: 0.1922, average loss: 0.1238
[09/16 06:28:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.07	top5: 99.53	
[09/16 06:28:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 06:29:03 visual_prompt]: Epoch 15 / 100: avg data time: 8.21e-02, avg batch time: 0.4878, average train loss: 0.0034
[09/16 06:29:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 06:29:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:29:27 visual_prompt]: Inference (test):avg data time: 5.87e-03, avg batch time: 0.1941, average loss: 0.1204
[09/16 06:29:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.32	top5: 99.58	
[09/16 06:29:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 06:29:35 visual_prompt]: Epoch 16 / 100: avg data time: 8.71e-02, avg batch time: 0.4915, average train loss: 0.0041
[09/16 06:29:38 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1437, average loss: 0.0036
[09/16 06:29:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:30:00 visual_prompt]: Inference (test):avg data time: 6.03e-03, avg batch time: 0.2005, average loss: 0.1161
[09/16 06:30:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.69	top5: 99.59	
[09/16 06:30:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 06:30:08 visual_prompt]: Epoch 17 / 100: avg data time: 9.23e-02, avg batch time: 0.4953, average train loss: 0.0047
[09/16 06:30:11 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1437, average loss: 0.0036
[09/16 06:30:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:30:32 visual_prompt]: Inference (test):avg data time: 7.43e-03, avg batch time: 0.1936, average loss: 0.1227
[09/16 06:30:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.46	top5: 99.48	
[09/16 06:30:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 06:30:41 visual_prompt]: Epoch 18 / 100: avg data time: 9.25e-02, avg batch time: 0.4966, average train loss: 0.0049
[09/16 06:30:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1435, average loss: 0.0038
[09/16 06:30:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:31:04 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1913, average loss: 0.1213
[09/16 06:31:04 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.66	top5: 99.63	
[09/16 06:31:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 06:31:13 visual_prompt]: Epoch 19 / 100: avg data time: 9.56e-02, avg batch time: 0.4997, average train loss: 0.0050
[09/16 06:31:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1436, average loss: 0.0035
[09/16 06:31:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:31:37 visual_prompt]: Inference (test):avg data time: 6.48e-03, avg batch time: 0.1917, average loss: 0.1212
[09/16 06:31:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.74	top5: 99.51	
[09/16 06:31:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 06:31:45 visual_prompt]: Epoch 20 / 100: avg data time: 9.23e-02, avg batch time: 0.4966, average train loss: 0.0048
[09/16 06:31:48 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1434, average loss: 0.0037
[09/16 06:31:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:32:09 visual_prompt]: Inference (test):avg data time: 5.72e-03, avg batch time: 0.1931, average loss: 0.1146
[09/16 06:32:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.77	top5: 99.59	
[09/16 06:32:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 06:32:18 visual_prompt]: Epoch 21 / 100: avg data time: 9.44e-02, avg batch time: 0.4968, average train loss: 0.0049
[09/16 06:32:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1436, average loss: 0.0036
[09/16 06:32:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:32:41 visual_prompt]: Inference (test):avg data time: 5.93e-03, avg batch time: 0.1950, average loss: 0.1125
[09/16 06:32:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.84	top5: 99.66	
[09/16 06:32:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 06:32:50 visual_prompt]: Epoch 22 / 100: avg data time: 7.18e-02, avg batch time: 0.4790, average train loss: 0.0049
[09/16 06:32:52 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1437, average loss: 0.0036
[09/16 06:32:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:33:13 visual_prompt]: Inference (test):avg data time: 6.65e-03, avg batch time: 0.1924, average loss: 0.1204
[09/16 06:33:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.72	top5: 99.53	
[09/16 06:33:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 06:33:22 visual_prompt]: Epoch 23 / 100: avg data time: 9.34e-02, avg batch time: 0.4973, average train loss: 0.0048
[09/16 06:33:25 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1445, average loss: 0.0035
[09/16 06:33:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:33:46 visual_prompt]: Inference (test):avg data time: 7.27e-03, avg batch time: 0.1936, average loss: 0.1223
[09/16 06:33:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.69	top5: 99.50	
[09/16 06:33:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 06:33:54 visual_prompt]: Epoch 24 / 100: avg data time: 8.78e-02, avg batch time: 0.4918, average train loss: 0.0047
[09/16 06:33:57 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1435, average loss: 0.0033
[09/16 06:33:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:34:18 visual_prompt]: Inference (test):avg data time: 7.88e-03, avg batch time: 0.1980, average loss: 0.1089
[09/16 06:34:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.89	top5: 99.61	
[09/16 06:34:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 06:34:27 visual_prompt]: Epoch 25 / 100: avg data time: 7.94e-02, avg batch time: 0.4856, average train loss: 0.0053
[09/16 06:34:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1437, average loss: 0.0040
[09/16 06:34:29 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:34:50 visual_prompt]: Inference (test):avg data time: 7.07e-03, avg batch time: 0.1920, average loss: 0.1194
[09/16 06:34:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.76	top5: 99.61	
[09/16 06:34:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 06:34:59 visual_prompt]: Epoch 26 / 100: avg data time: 9.31e-02, avg batch time: 0.4971, average train loss: 0.0057
[09/16 06:35:02 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1436, average loss: 0.0038
[09/16 06:35:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:35:23 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1928, average loss: 0.1062
[09/16 06:35:23 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.95	top5: 99.69	
[09/16 06:35:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 06:35:32 visual_prompt]: Epoch 27 / 100: avg data time: 9.63e-02, avg batch time: 0.5015, average train loss: 0.0050
[09/16 06:35:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1437, average loss: 0.0035
[09/16 06:35:34 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:35:55 visual_prompt]: Inference (test):avg data time: 6.54e-03, avg batch time: 0.1960, average loss: 0.1101
[09/16 06:35:55 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.82	top5: 99.66	
[09/16 06:35:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 06:36:04 visual_prompt]: Epoch 28 / 100: avg data time: 8.24e-02, avg batch time: 0.4891, average train loss: 0.0044
[09/16 06:36:06 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1436, average loss: 0.0031
[09/16 06:36:06 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:36:27 visual_prompt]: Inference (test):avg data time: 6.48e-03, avg batch time: 0.1911, average loss: 0.1034
[09/16 06:36:27 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.00	top5: 99.71	
[09/16 06:36:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 06:36:36 visual_prompt]: Epoch 29 / 100: avg data time: 8.90e-02, avg batch time: 0.4923, average train loss: 0.0040
[09/16 06:36:38 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1438, average loss: 0.0029
[09/16 06:36:38 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:36:59 visual_prompt]: Inference (test):avg data time: 7.99e-03, avg batch time: 0.1931, average loss: 0.1097
[09/16 06:37:00 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.79	top5: 99.64	
[09/16 06:37:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 06:37:08 visual_prompt]: Epoch 30 / 100: avg data time: 9.18e-02, avg batch time: 0.4951, average train loss: 0.0039
[09/16 06:37:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1438, average loss: 0.0029
[09/16 06:37:11 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:37:32 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1925, average loss: 0.0991
[09/16 06:37:32 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 98.13	top5: 99.58	
[09/16 06:37:32 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 06:37:41 visual_prompt]: Epoch 31 / 100: avg data time: 9.95e-02, avg batch time: 0.5213, average train loss: 0.0038
[09/16 06:37:43 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1437, average loss: 0.0030
[09/16 06:37:43 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:38:05 visual_prompt]: Inference (test):avg data time: 6.94e-03, avg batch time: 0.1964, average loss: 0.1110
[09/16 06:38:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.90	top5: 99.56	
[09/16 06:38:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 06:38:13 visual_prompt]: Epoch 32 / 100: avg data time: 8.56e-02, avg batch time: 0.4889, average train loss: 0.0042
[09/16 06:38:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1438, average loss: 0.0038
[09/16 06:38:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:38:37 visual_prompt]: Inference (test):avg data time: 6.76e-03, avg batch time: 0.1913, average loss: 0.1144
[09/16 06:38:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 97.74	top5: 99.61	
[09/16 06:38:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 06:38:45 visual_prompt]: Epoch 33 / 100: avg data time: 9.13e-02, avg batch time: 0.4945, average train loss: 0.0050
[09/16 06:38:48 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1435, average loss: 0.0043
[09/16 06:38:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:39:09 visual_prompt]: Inference (test):avg data time: 5.21e-03, avg batch time: 0.1925, average loss: 0.1541
[09/16 06:39:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.75	top5: 99.40	
[09/16 06:39:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 06:39:18 visual_prompt]: Epoch 34 / 100: avg data time: 8.92e-02, avg batch time: 0.4923, average train loss: 0.9719
[09/16 06:39:20 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1437, average loss: 5.1513
[09/16 06:39:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 2.00	top5: 9.00	
[09/16 06:39:41 visual_prompt]: Inference (test):avg data time: 6.69e-03, avg batch time: 0.1918, average loss: 5.1882
[09/16 06:39:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 0.75	top5: 6.60	
[09/16 06:39:41 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 06:39:50 visual_prompt]: Epoch 35 / 100: avg data time: 8.62e-02, avg batch time: 0.4900, average train loss: 5.4700
[09/16 06:39:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1437, average loss: 6.2742
[09/16 06:39:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 0.50	top5: 9.50	
[09/16 06:40:13 visual_prompt]: Inference (test):avg data time: 8.62e-03, avg batch time: 0.1937, average loss: 5.6097
[09/16 06:40:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 1.17	top5: 7.33	
[09/16 06:40:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 06:40:22 visual_prompt]: Epoch 36 / 100: avg data time: 9.48e-02, avg batch time: 0.4977, average train loss: 5.1683
[09/16 06:40:25 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1438, average loss: 5.9329
[09/16 06:40:25 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 9.50	top5: 23.00	
[09/16 06:40:46 visual_prompt]: Inference (test):avg data time: 6.06e-03, avg batch time: 0.1927, average loss: 5.6061
[09/16 06:40:46 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 6.52	top5: 19.08	
[09/16 06:40:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 06:40:54 visual_prompt]: Epoch 37 / 100: avg data time: 9.46e-02, avg batch time: 0.4980, average train loss: 4.9324
[09/16 06:40:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1436, average loss: 4.5757
[09/16 06:40:57 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 20.00	top5: 42.00	
[09/16 06:41:18 visual_prompt]: Inference (test):avg data time: 3.77e-03, avg batch time: 0.1903, average loss: 5.2227
[09/16 06:41:18 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 12.72	top5: 30.59	
[09/16 06:41:18 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 06:41:26 visual_prompt]: Epoch 38 / 100: avg data time: 8.47e-02, avg batch time: 0.4895, average train loss: 3.4924
[09/16 06:41:29 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1436, average loss: 2.0956
[09/16 06:41:29 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 54.50	top5: 80.00	
[09/16 06:41:50 visual_prompt]: Inference (test):avg data time: 6.60e-03, avg batch time: 0.1920, average loss: 2.6508
[09/16 06:41:50 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 40.77	top5: 68.58	
[09/16 06:41:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 06:41:58 visual_prompt]: Epoch 39 / 100: avg data time: 7.03e-02, avg batch time: 0.4768, average train loss: 1.4611
[09/16 06:42:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1436, average loss: 1.0794
[09/16 06:42:01 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 72.50	top5: 92.50	
[09/16 06:42:22 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1922, average loss: 1.7712
[09/16 06:42:22 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 56.94	top5: 82.39	
[09/16 06:42:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 06:42:31 visual_prompt]: Epoch 40 / 100: avg data time: 8.73e-02, avg batch time: 0.4905, average train loss: 0.6373
[09/16 06:42:33 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1438, average loss: 0.2276
[09/16 06:42:33 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 93.50	top5: 100.00	
[09/16 06:42:54 visual_prompt]: Inference (test):avg data time: 6.01e-03, avg batch time: 0.1921, average loss: 1.0824
[09/16 06:42:54 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 73.51	top5: 92.60	
[09/16 06:42:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 06:43:02 visual_prompt]: Epoch 41 / 100: avg data time: 7.93e-02, avg batch time: 0.4856, average train loss: 0.2132
[09/16 06:43:05 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1438, average loss: 0.1249
[09/16 06:43:05 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 95.50	top5: 99.50	
[09/16 06:43:26 visual_prompt]: Inference (test):avg data time: 7.97e-03, avg batch time: 0.1959, average loss: 0.8013
[09/16 06:43:26 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 80.01	top5: 95.58	
[09/16 06:43:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 06:43:35 visual_prompt]: Epoch 42 / 100: avg data time: 7.70e-02, avg batch time: 0.4822, average train loss: 0.1202
[09/16 06:43:37 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1438, average loss: 0.1155
[09/16 06:43:37 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 97.00	top5: 100.00	
[09/16 06:43:58 visual_prompt]: Inference (test):avg data time: 7.25e-03, avg batch time: 0.1933, average loss: 0.6134
[09/16 06:43:58 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 84.62	top5: 96.57	
[09/16 06:43:58 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 06:44:07 visual_prompt]: Epoch 43 / 100: avg data time: 9.00e-02, avg batch time: 0.4939, average train loss: 0.1288
[09/16 06:44:09 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1456, average loss: 0.0348
[09/16 06:44:09 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.50	top5: 100.00	
[09/16 06:44:30 visual_prompt]: Inference (test):avg data time: 6.63e-03, avg batch time: 0.1915, average loss: 0.5649
[09/16 06:44:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 85.69	top5: 96.89	
[09/16 06:44:30 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 06:44:39 visual_prompt]: Epoch 44 / 100: avg data time: 8.51e-02, avg batch time: 0.4900, average train loss: 0.1096
[09/16 06:44:41 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1436, average loss: 0.0333
[09/16 06:44:41 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 06:45:03 visual_prompt]: Inference (test):avg data time: 6.68e-03, avg batch time: 0.1970, average loss: 0.5541
[09/16 06:45:03 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 85.14	top5: 96.89	
[09/16 06:45:03 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 06:45:11 visual_prompt]: Epoch 45 / 100: avg data time: 8.65e-02, avg batch time: 0.4899, average train loss: 0.0845
[09/16 06:45:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1437, average loss: 0.0608
[09/16 06:45:14 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 98.00	top5: 100.00	
[09/16 06:45:35 visual_prompt]: Inference (test):avg data time: 7.26e-03, avg batch time: 0.1928, average loss: 0.3937
[09/16 06:45:35 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 89.28	top5: 98.05	
[09/16 06:45:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 06:45:44 visual_prompt]: Epoch 46 / 100: avg data time: 8.94e-02, avg batch time: 0.4928, average train loss: 0.0331
[09/16 06:45:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1437, average loss: 0.0327
[09/16 06:45:46 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 99.00	top5: 100.00	
[09/16 06:46:07 visual_prompt]: Inference (test):avg data time: 7.37e-03, avg batch time: 0.1922, average loss: 0.5530
[09/16 06:46:07 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 86.79	top5: 97.32	
[09/16 06:46:07 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 06:46:16 visual_prompt]: Epoch 47 / 100: avg data time: 9.09e-02, avg batch time: 0.4953, average train loss: 0.0304
[09/16 06:46:18 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1438, average loss: 0.0137
[09/16 06:46:18 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:46:39 visual_prompt]: Inference (test):avg data time: 5.80e-03, avg batch time: 0.1927, average loss: 0.3715
[09/16 06:46:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 90.11	top5: 98.47	
[09/16 06:46:39 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 06:46:48 visual_prompt]: Epoch 48 / 100: avg data time: 9.16e-02, avg batch time: 0.4952, average train loss: 0.0070
[09/16 06:46:51 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1439, average loss: 0.0019
[09/16 06:46:51 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:47:12 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1922, average loss: 0.2607
[09/16 06:47:12 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 92.83	top5: 98.76	
[09/16 06:47:12 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 06:47:20 visual_prompt]: Epoch 49 / 100: avg data time: 8.08e-02, avg batch time: 0.4871, average train loss: 0.0027
[09/16 06:47:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1435, average loss: 0.0014
[09/16 06:47:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:47:44 visual_prompt]: Inference (test):avg data time: 6.45e-03, avg batch time: 0.1925, average loss: 0.2490
[09/16 06:47:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.28	top5: 98.91	
[09/16 06:47:44 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 06:47:52 visual_prompt]: Epoch 50 / 100: avg data time: 9.54e-02, avg batch time: 0.5016, average train loss: 0.0027
[09/16 06:47:55 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1436, average loss: 0.0013
[09/16 06:47:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:48:16 visual_prompt]: Inference (test):avg data time: 7.04e-03, avg batch time: 0.1924, average loss: 0.2393
[09/16 06:48:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 93.76	top5: 98.81	
[09/16 06:48:16 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 06:48:24 visual_prompt]: Epoch 51 / 100: avg data time: 7.31e-02, avg batch time: 0.4811, average train loss: 0.0025
[09/16 06:48:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1436, average loss: 0.0014
[09/16 06:48:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:48:48 visual_prompt]: Inference (test):avg data time: 7.23e-03, avg batch time: 0.1919, average loss: 0.2148
[09/16 06:48:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.44	top5: 98.93	
[09/16 06:48:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 06:48:56 visual_prompt]: Epoch 52 / 100: avg data time: 8.70e-02, avg batch time: 0.4925, average train loss: 0.0021
[09/16 06:48:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1440, average loss: 0.0015
[09/16 06:48:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:49:20 visual_prompt]: Inference (test):avg data time: 7.75e-03, avg batch time: 0.1926, average loss: 0.2029
[09/16 06:49:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.67	top5: 98.94	
[09/16 06:49:20 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 06:49:29 visual_prompt]: Epoch 53 / 100: avg data time: 8.66e-02, avg batch time: 0.4901, average train loss: 0.0020
[09/16 06:49:31 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1439, average loss: 0.0018
[09/16 06:49:31 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:49:52 visual_prompt]: Inference (test):avg data time: 7.35e-03, avg batch time: 0.1924, average loss: 0.1976
[09/16 06:49:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.89	top5: 98.98	
[09/16 06:49:52 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 06:50:01 visual_prompt]: Epoch 54 / 100: avg data time: 8.61e-02, avg batch time: 0.4903, average train loss: 0.0025
[09/16 06:50:03 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1441, average loss: 0.0021
[09/16 06:50:03 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:50:24 visual_prompt]: Inference (test):avg data time: 7.59e-03, avg batch time: 0.1933, average loss: 0.1966
[09/16 06:50:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.02	top5: 99.04	
[09/16 06:50:24 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 06:50:33 visual_prompt]: Epoch 55 / 100: avg data time: 8.83e-02, avg batch time: 0.4928, average train loss: 0.0028
[09/16 06:50:36 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1435, average loss: 0.0025
[09/16 06:50:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:50:56 visual_prompt]: Inference (test):avg data time: 8.14e-03, avg batch time: 0.1922, average loss: 0.1961
[09/16 06:50:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.09	top5: 99.04	
[09/16 06:50:57 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 06:51:05 visual_prompt]: Epoch 56 / 100: avg data time: 9.23e-02, avg batch time: 0.4951, average train loss: 0.0031
[09/16 06:51:08 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1436, average loss: 0.0029
[09/16 06:51:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:51:29 visual_prompt]: Inference (test):avg data time: 4.87e-03, avg batch time: 0.1913, average loss: 0.1964
[09/16 06:51:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 94.94	top5: 99.12	
[09/16 06:51:29 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 06:51:37 visual_prompt]: Epoch 57 / 100: avg data time: 9.44e-02, avg batch time: 0.4980, average train loss: 0.0032
[09/16 06:51:40 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1434, average loss: 0.0031
[09/16 06:51:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:52:01 visual_prompt]: Inference (test):avg data time: 7.78e-03, avg batch time: 0.1926, average loss: 0.1958
[09/16 06:52:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.06	top5: 99.11	
[09/16 06:52:01 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 06:52:09 visual_prompt]: Epoch 58 / 100: avg data time: 8.24e-02, avg batch time: 0.4893, average train loss: 0.0039
[09/16 06:52:12 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.1435, average loss: 0.0034
[09/16 06:52:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:52:33 visual_prompt]: Inference (test):avg data time: 7.28e-03, avg batch time: 0.1936, average loss: 0.1953
[09/16 06:52:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.19	top5: 99.17	
[09/16 06:52:33 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 06:52:42 visual_prompt]: Epoch 59 / 100: avg data time: 8.45e-02, avg batch time: 0.4885, average train loss: 0.0042
[09/16 06:52:44 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1437, average loss: 0.0036
[09/16 06:52:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:53:05 visual_prompt]: Inference (test):avg data time: 7.52e-03, avg batch time: 0.1923, average loss: 0.1902
[09/16 06:53:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.43	top5: 99.19	
[09/16 06:53:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 06:53:14 visual_prompt]: Epoch 60 / 100: avg data time: 8.37e-02, avg batch time: 0.4872, average train loss: 0.0046
[09/16 06:53:16 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1437, average loss: 0.0037
[09/16 06:53:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:53:37 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1929, average loss: 0.1890
[09/16 06:53:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.43	top5: 99.25	
[09/16 06:53:37 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 06:53:46 visual_prompt]: Epoch 61 / 100: avg data time: 9.75e-02, avg batch time: 0.5002, average train loss: 0.0048
[09/16 06:53:49 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1438, average loss: 0.0039
[09/16 06:53:49 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:54:10 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1953, average loss: 0.1878
[09/16 06:54:10 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.61	top5: 99.22	
[09/16 06:54:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 06:54:18 visual_prompt]: Epoch 62 / 100: avg data time: 8.33e-02, avg batch time: 0.4894, average train loss: 0.0049
[09/16 06:54:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1436, average loss: 0.0039
[09/16 06:54:21 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:54:42 visual_prompt]: Inference (test):avg data time: 8.58e-03, avg batch time: 0.1935, average loss: 0.1855
[09/16 06:54:42 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.56	top5: 99.20	
[09/16 06:54:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 06:54:51 visual_prompt]: Epoch 63 / 100: avg data time: 9.32e-02, avg batch time: 0.4984, average train loss: 0.0050
[09/16 06:54:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1437, average loss: 0.0039
[09/16 06:54:53 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:55:14 visual_prompt]: Inference (test):avg data time: 6.03e-03, avg batch time: 0.1919, average loss: 0.1829
[09/16 06:55:14 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.82	top5: 99.35	
[09/16 06:55:14 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 06:55:23 visual_prompt]: Epoch 64 / 100: avg data time: 7.87e-02, avg batch time: 0.4839, average train loss: 0.0053
[09/16 06:55:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1437, average loss: 0.0042
[09/16 06:55:26 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:55:47 visual_prompt]: Inference (test):avg data time: 5.17e-03, avg batch time: 0.1914, average loss: 0.1839
[09/16 06:55:47 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.71	top5: 99.35	
[09/16 06:55:47 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 06:55:55 visual_prompt]: Epoch 65 / 100: avg data time: 7.68e-02, avg batch time: 0.4847, average train loss: 0.0055
[09/16 06:55:58 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1438, average loss: 0.0043
[09/16 06:55:58 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:56:19 visual_prompt]: Inference (test):avg data time: 6.39e-03, avg batch time: 0.1923, average loss: 0.1823
[09/16 06:56:19 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.93	top5: 99.30	
[09/16 06:56:19 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 06:56:27 visual_prompt]: Epoch 66 / 100: avg data time: 6.76e-02, avg batch time: 0.4744, average train loss: 0.0052
[09/16 06:56:30 visual_prompt]: Inference (val):avg data time: 2.93e-04, avg batch time: 0.2385, average loss: 0.0042
[09/16 06:56:30 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:56:51 visual_prompt]: Inference (test):avg data time: 7.57e-03, avg batch time: 0.1931, average loss: 0.1811
[09/16 06:56:51 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.82	top5: 99.33	
[09/16 06:56:51 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 06:57:00 visual_prompt]: Epoch 67 / 100: avg data time: 8.86e-02, avg batch time: 0.4939, average train loss: 0.0053
[09/16 06:57:02 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1438, average loss: 0.0042
[09/16 06:57:02 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:57:24 visual_prompt]: Inference (test):avg data time: 6.31e-03, avg batch time: 0.1956, average loss: 0.1801
[09/16 06:57:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.92	top5: 99.38	
[09/16 06:57:24 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 06:57:32 visual_prompt]: Epoch 68 / 100: avg data time: 7.60e-02, avg batch time: 0.4829, average train loss: 0.0051
[09/16 06:57:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1440, average loss: 0.0040
[09/16 06:57:35 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:57:56 visual_prompt]: Inference (test):avg data time: 7.48e-03, avg batch time: 0.1932, average loss: 0.1785
[09/16 06:57:56 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.93	top5: 99.38	
[09/16 06:57:56 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 06:58:05 visual_prompt]: Epoch 69 / 100: avg data time: 7.87e-02, avg batch time: 0.4920, average train loss: 0.0052
[09/16 06:58:07 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1438, average loss: 0.0039
[09/16 06:58:07 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:58:28 visual_prompt]: Inference (test):avg data time: 6.46e-03, avg batch time: 0.1922, average loss: 0.1781
[09/16 06:58:28 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.02	top5: 99.33	
[09/16 06:58:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 06:58:37 visual_prompt]: Epoch 70 / 100: avg data time: 9.01e-02, avg batch time: 0.4938, average train loss: 0.0054
[09/16 06:58:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1439, average loss: 0.0040
[09/16 06:58:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:59:01 visual_prompt]: Inference (test):avg data time: 6.44e-03, avg batch time: 0.1927, average loss: 0.1755
[09/16 06:59:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.05	top5: 99.35	
[09/16 06:59:01 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 06:59:09 visual_prompt]: Epoch 71 / 100: avg data time: 9.01e-02, avg batch time: 0.4942, average train loss: 0.0054
[09/16 06:59:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1437, average loss: 0.0039
[09/16 06:59:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 06:59:33 visual_prompt]: Inference (test):avg data time: 6.69e-03, avg batch time: 0.1924, average loss: 0.1760
[09/16 06:59:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.13	top5: 99.38	
[09/16 06:59:33 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 06:59:41 visual_prompt]: Epoch 72 / 100: avg data time: 8.60e-02, avg batch time: 0.4903, average train loss: 0.0053
[09/16 06:59:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1437, average loss: 0.0038
[09/16 06:59:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:00:05 visual_prompt]: Inference (test):avg data time: 6.53e-03, avg batch time: 0.1923, average loss: 0.1773
[09/16 07:00:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.92	top5: 99.37	
[09/16 07:00:05 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 07:00:13 visual_prompt]: Epoch 73 / 100: avg data time: 7.38e-02, avg batch time: 0.4804, average train loss: 0.0050
[09/16 07:00:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1436, average loss: 0.0037
[09/16 07:00:16 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:00:37 visual_prompt]: Inference (test):avg data time: 5.42e-03, avg batch time: 0.1928, average loss: 0.1759
[09/16 07:00:37 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.98	top5: 99.40	
[09/16 07:00:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 07:00:46 visual_prompt]: Epoch 74 / 100: avg data time: 9.54e-02, avg batch time: 0.4989, average train loss: 0.0050
[09/16 07:00:48 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1438, average loss: 0.0036
[09/16 07:00:48 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:01:09 visual_prompt]: Inference (test):avg data time: 6.82e-03, avg batch time: 0.1916, average loss: 0.1747
[09/16 07:01:09 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.05	top5: 99.37	
[09/16 07:01:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 07:01:17 visual_prompt]: Epoch 75 / 100: avg data time: 8.05e-02, avg batch time: 0.4844, average train loss: 0.0051
[09/16 07:01:20 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1439, average loss: 0.0038
[09/16 07:01:20 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:01:41 visual_prompt]: Inference (test):avg data time: 7.85e-03, avg batch time: 0.1933, average loss: 0.1734
[09/16 07:01:41 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.06	top5: 99.41	
[09/16 07:01:41 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 07:01:50 visual_prompt]: Epoch 76 / 100: avg data time: 9.64e-02, avg batch time: 0.5004, average train loss: 0.0050
[09/16 07:01:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1437, average loss: 0.0036
[09/16 07:01:52 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:02:13 visual_prompt]: Inference (test):avg data time: 5.90e-03, avg batch time: 0.1915, average loss: 0.1733
[09/16 07:02:13 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.03	top5: 99.37	
[09/16 07:02:13 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 07:02:22 visual_prompt]: Epoch 77 / 100: avg data time: 8.04e-02, avg batch time: 0.4846, average train loss: 0.0050
[09/16 07:02:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1439, average loss: 0.0036
[09/16 07:02:24 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:02:45 visual_prompt]: Inference (test):avg data time: 6.24e-03, avg batch time: 0.1917, average loss: 0.1696
[09/16 07:02:45 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.11	top5: 99.40	
[09/16 07:02:45 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 07:02:54 visual_prompt]: Epoch 78 / 100: avg data time: 8.33e-02, avg batch time: 0.4900, average train loss: 0.0051
[09/16 07:02:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1438, average loss: 0.0036
[09/16 07:02:56 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:03:17 visual_prompt]: Inference (test):avg data time: 4.69e-03, avg batch time: 0.1909, average loss: 0.1758
[09/16 07:03:17 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 95.93	top5: 99.38	
[09/16 07:03:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 07:03:26 visual_prompt]: Epoch 79 / 100: avg data time: 9.92e-02, avg batch time: 0.5027, average train loss: 0.0050
[09/16 07:03:28 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1437, average loss: 0.0036
[09/16 07:03:28 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:03:49 visual_prompt]: Inference (test):avg data time: 6.70e-03, avg batch time: 0.1927, average loss: 0.1710
[09/16 07:03:49 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.11	top5: 99.41	
[09/16 07:03:49 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 07:03:58 visual_prompt]: Epoch 80 / 100: avg data time: 7.73e-02, avg batch time: 0.4837, average train loss: 0.0051
[09/16 07:04:00 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1439, average loss: 0.0035
[09/16 07:04:00 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:04:21 visual_prompt]: Inference (test):avg data time: 7.40e-03, avg batch time: 0.1926, average loss: 0.1701
[09/16 07:04:21 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.05	top5: 99.41	
[09/16 07:04:21 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 07:04:30 visual_prompt]: Epoch 81 / 100: avg data time: 1.05e-01, avg batch time: 0.5088, average train loss: 0.0050
[09/16 07:04:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1438, average loss: 0.0037
[09/16 07:04:33 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:04:53 visual_prompt]: Inference (test):avg data time: 5.50e-03, avg batch time: 0.1912, average loss: 0.1720
[09/16 07:04:53 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.08	top5: 99.43	
[09/16 07:04:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 07:05:02 visual_prompt]: Epoch 82 / 100: avg data time: 7.88e-02, avg batch time: 0.4823, average train loss: 0.0048
[09/16 07:05:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1438, average loss: 0.0036
[09/16 07:05:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:05:25 visual_prompt]: Inference (test):avg data time: 7.82e-03, avg batch time: 0.1930, average loss: 0.1697
[09/16 07:05:26 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.03	top5: 99.43	
[09/16 07:05:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 07:05:34 visual_prompt]: Epoch 83 / 100: avg data time: 7.22e-02, avg batch time: 0.4774, average train loss: 0.0048
[09/16 07:05:36 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1436, average loss: 0.0035
[09/16 07:05:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:05:57 visual_prompt]: Inference (test):avg data time: 6.08e-03, avg batch time: 0.1922, average loss: 0.1720
[09/16 07:05:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.13	top5: 99.41	
[09/16 07:05:57 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 07:06:06 visual_prompt]: Epoch 84 / 100: avg data time: 7.52e-02, avg batch time: 0.4792, average train loss: 0.0049
[09/16 07:06:08 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1438, average loss: 0.0034
[09/16 07:06:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:06:29 visual_prompt]: Inference (test):avg data time: 6.29e-03, avg batch time: 0.1918, average loss: 0.1699
[09/16 07:06:30 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.08	top5: 99.41	
[09/16 07:06:30 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 07:06:38 visual_prompt]: Epoch 85 / 100: avg data time: 8.39e-02, avg batch time: 0.4895, average train loss: 0.0048
[09/16 07:06:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1440, average loss: 0.0034
[09/16 07:06:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:07:02 visual_prompt]: Inference (test):avg data time: 8.38e-03, avg batch time: 0.1936, average loss: 0.1706
[09/16 07:07:02 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.05	top5: 99.40	
[09/16 07:07:02 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 07:07:10 visual_prompt]: Epoch 86 / 100: avg data time: 9.06e-02, avg batch time: 0.4936, average train loss: 0.0051
[09/16 07:07:13 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1439, average loss: 0.0033
[09/16 07:07:13 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:07:34 visual_prompt]: Inference (test):avg data time: 5.95e-03, avg batch time: 0.1915, average loss: 0.1680
[09/16 07:07:34 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.16	top5: 99.41	
[09/16 07:07:34 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 07:07:43 visual_prompt]: Epoch 87 / 100: avg data time: 7.29e-02, avg batch time: 0.4939, average train loss: 0.0049
[09/16 07:07:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 07:07:45 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:08:06 visual_prompt]: Inference (test):avg data time: 4.59e-03, avg batch time: 0.1904, average loss: 0.1691
[09/16 07:08:06 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.21	top5: 99.41	
[09/16 07:08:06 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 07:08:15 visual_prompt]: Epoch 88 / 100: avg data time: 9.50e-02, avg batch time: 0.4990, average train loss: 0.0049
[09/16 07:08:17 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1439, average loss: 0.0033
[09/16 07:08:17 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:08:39 visual_prompt]: Inference (test):avg data time: 7.32e-03, avg batch time: 0.1992, average loss: 0.1690
[09/16 07:08:39 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.16	top5: 99.41	
[09/16 07:08:39 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 07:08:48 visual_prompt]: Epoch 89 / 100: avg data time: 9.29e-02, avg batch time: 0.4975, average train loss: 0.0049
[09/16 07:08:50 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 07:08:50 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:09:11 visual_prompt]: Inference (test):avg data time: 6.32e-03, avg batch time: 0.1954, average loss: 0.1699
[09/16 07:09:11 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.21	top5: 99.40	
[09/16 07:09:11 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 07:09:20 visual_prompt]: Epoch 90 / 100: avg data time: 9.06e-02, avg batch time: 0.4931, average train loss: 0.0048
[09/16 07:09:23 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 07:09:23 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:09:44 visual_prompt]: Inference (test):avg data time: 8.04e-03, avg batch time: 0.1928, average loss: 0.1706
[09/16 07:09:44 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.21	top5: 99.40	
[09/16 07:09:44 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 07:09:52 visual_prompt]: Epoch 91 / 100: avg data time: 9.13e-02, avg batch time: 0.4951, average train loss: 0.0047
[09/16 07:09:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 07:09:55 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:10:16 visual_prompt]: Inference (test):avg data time: 6.26e-03, avg batch time: 0.1925, average loss: 0.1683
[09/16 07:10:16 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.28	top5: 99.43	
[09/16 07:10:16 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 07:10:25 visual_prompt]: Epoch 92 / 100: avg data time: 9.61e-02, avg batch time: 0.4993, average train loss: 0.0048
[09/16 07:10:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1440, average loss: 0.0033
[09/16 07:10:27 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:10:48 visual_prompt]: Inference (test):avg data time: 7.93e-03, avg batch time: 0.1921, average loss: 0.1679
[09/16 07:10:48 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.24	top5: 99.40	
[09/16 07:10:48 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 07:10:57 visual_prompt]: Epoch 93 / 100: avg data time: 7.83e-02, avg batch time: 0.4844, average train loss: 0.0048
[09/16 07:10:59 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1440, average loss: 0.0033
[09/16 07:10:59 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:11:20 visual_prompt]: Inference (test):avg data time: 6.62e-03, avg batch time: 0.1925, average loss: 0.1687
[09/16 07:11:20 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.24	top5: 99.40	
[09/16 07:11:20 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 07:11:29 visual_prompt]: Epoch 94 / 100: avg data time: 8.84e-02, avg batch time: 0.4914, average train loss: 0.0048
[09/16 07:11:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 07:11:32 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:11:52 visual_prompt]: Inference (test):avg data time: 6.41e-03, avg batch time: 0.1916, average loss: 0.1679
[09/16 07:11:52 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.26	top5: 99.40	
[09/16 07:11:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 07:12:01 visual_prompt]: Epoch 95 / 100: avg data time: 9.59e-02, avg batch time: 0.5015, average train loss: 0.0047
[09/16 07:12:04 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1435, average loss: 0.0033
[09/16 07:12:04 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:12:24 visual_prompt]: Inference (test):avg data time: 7.49e-03, avg batch time: 0.1923, average loss: 0.1680
[09/16 07:12:24 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.28	top5: 99.40	
[09/16 07:12:24 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 07:12:33 visual_prompt]: Epoch 96 / 100: avg data time: 8.30e-02, avg batch time: 0.4882, average train loss: 0.0047
[09/16 07:12:36 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 07:12:36 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:12:57 visual_prompt]: Inference (test):avg data time: 5.84e-03, avg batch time: 0.1913, average loss: 0.1684
[09/16 07:12:57 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.28	top5: 99.40	
[09/16 07:12:57 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 07:13:05 visual_prompt]: Epoch 97 / 100: avg data time: 8.90e-02, avg batch time: 0.4950, average train loss: 0.0047
[09/16 07:13:08 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 07:13:08 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:13:29 visual_prompt]: Inference (test):avg data time: 6.95e-03, avg batch time: 0.1926, average loss: 0.1684
[09/16 07:13:29 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.29	top5: 99.40	
[09/16 07:13:29 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 07:13:37 visual_prompt]: Epoch 98 / 100: avg data time: 9.00e-02, avg batch time: 0.4942, average train loss: 0.0048
[09/16 07:13:40 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 07:13:40 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:14:01 visual_prompt]: Inference (test):avg data time: 7.63e-03, avg batch time: 0.1944, average loss: 0.1682
[09/16 07:14:01 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.29	top5: 99.40	
[09/16 07:14:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 07:14:10 visual_prompt]: Epoch 99 / 100: avg data time: 7.65e-02, avg batch time: 0.4829, average train loss: 0.0047
[09/16 07:14:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1438, average loss: 0.0033
[09/16 07:14:12 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:14:33 visual_prompt]: Inference (test):avg data time: 8.25e-03, avg batch time: 0.1930, average loss: 0.1681
[09/16 07:14:33 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.29	top5: 99.40	
[09/16 07:14:33 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 07:14:42 visual_prompt]: Epoch 100 / 100: avg data time: 8.87e-02, avg batch time: 0.4928, average train loss: 0.0047
[09/16 07:14:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 07:14:44 visual_prompt]: Classification results with val_vtab-oxford_flowers102: top1: 100.00	top5: 100.00	
[09/16 07:15:05 visual_prompt]: Inference (test):avg data time: 7.65e-03, avg batch time: 0.1921, average loss: 0.1681
[09/16 07:15:05 visual_prompt]: Classification results with test_vtab-oxford_flowers102: top1: 96.29	top5: 99.40	
