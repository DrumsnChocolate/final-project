/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/02 16:30:40 visual_prompt]: Rank of current process: 0. World size: 1
[10/02 16:30:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/02 16:30:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/02 16:30:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/02 16:30:41 visual_prompt]: Training with config:
[10/02 16:30:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/02 16:30:41 visual_prompt]: Loading training data...
[10/02 16:30:41 visual_prompt]: Constructing mammo-cbis dataset train...
[10/02 16:30:41 visual_prompt]: Loading validation data...
[10/02 16:30:41 visual_prompt]: Constructing mammo-cbis dataset val...
[10/02 16:30:41 visual_prompt]: Constructing models...
[10/02 16:30:44 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/02 16:30:44 visual_prompt]: tuned percent:0.536
[10/02 16:30:46 visual_prompt]: Device used for model: 0
[10/02 16:30:46 visual_prompt]: Setting up Evaluator...
[10/02 16:30:46 visual_prompt]: Setting up Trainer...
[10/02 16:30:46 visual_prompt]: 	Setting up the optimizer...
[10/02 16:30:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/02 16:37:25 visual_prompt]: Epoch 1 / 100: avg data time: 1.01e+01, avg batch time: 11.4013, average train loss: 1.4432
[10/02 16:38:10 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.7205, average loss: 1.4399
[10/02 16:38:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/02 16:38:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[10/02 16:44:36 visual_prompt]: Epoch 2 / 100: avg data time: 9.83e+00, avg batch time: 11.0007, average train loss: 28.1912
[10/02 16:45:21 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.7268, average loss: 7.7681
[10/02 16:45:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.13	
[10/02 16:45:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[10/02 16:51:48 visual_prompt]: Epoch 3 / 100: avg data time: 9.87e+00, avg batch time: 11.0475, average train loss: 23.9297
[10/02 16:52:33 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.7309, average loss: 0.7483
[10/02 16:52:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 55.70	
[10/02 16:52:33 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[10/02 16:58:59 visual_prompt]: Epoch 4 / 100: avg data time: 9.85e+00, avg batch time: 11.0262, average train loss: 28.8345
[10/02 16:59:45 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.7198, average loss: 27.9435
[10/02 16:59:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 47.22	
[10/02 16:59:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[10/02 17:06:11 visual_prompt]: Epoch 5 / 100: avg data time: 9.86e+00, avg batch time: 11.0287, average train loss: 53.9718
[10/02 17:06:57 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7291, average loss: 19.8861
[10/02 17:06:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[10/02 17:06:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[10/02 17:13:29 visual_prompt]: Epoch 6 / 100: avg data time: 1.00e+01, avg batch time: 11.2145, average train loss: 80.2819
[10/02 17:14:16 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.7213, average loss: 81.5236
[10/02 17:14:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.44	
[10/02 17:14:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[10/02 17:20:46 visual_prompt]: Epoch 7 / 100: avg data time: 9.96e+00, avg batch time: 11.1292, average train loss: 74.9050
[10/02 17:21:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.7281, average loss: 151.1909
[10/02 17:21:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.67	
[10/02 17:21:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[10/02 17:28:02 visual_prompt]: Epoch 8 / 100: avg data time: 9.98e+00, avg batch time: 11.1399, average train loss: 104.7947
[10/02 17:28:48 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.7275, average loss: 124.2073
[10/02 17:28:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.99	
[10/02 17:28:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[10/02 17:35:20 visual_prompt]: Epoch 9 / 100: avg data time: 1.00e+01, avg batch time: 11.1778, average train loss: 114.4858
[10/02 17:36:06 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7209, average loss: 31.6457
[10/02 17:36:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.11	
[10/02 17:36:06 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[10/02 17:42:36 visual_prompt]: Epoch 10 / 100: avg data time: 9.97e+00, avg batch time: 11.1311, average train loss: 141.7878
[10/02 17:43:22 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.7202, average loss: 212.2128
[10/02 17:43:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.10	
[10/02 17:43:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[10/02 17:49:50 visual_prompt]: Epoch 11 / 100: avg data time: 9.92e+00, avg batch time: 11.0771, average train loss: 107.1301
[10/02 17:50:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.7236, average loss: 87.4884
[10/02 17:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.69	
[10/02 17:50:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[10/02 17:57:05 visual_prompt]: Epoch 12 / 100: avg data time: 9.95e+00, avg batch time: 11.1200, average train loss: 127.5114
[10/02 17:57:51 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.7228, average loss: 156.0284
[10/02 17:57:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.59	
[10/02 17:57:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[10/02 18:04:22 visual_prompt]: Epoch 13 / 100: avg data time: 1.00e+01, avg batch time: 11.1673, average train loss: 123.3632
[10/02 18:05:09 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.7264, average loss: 132.9319
[10/02 18:05:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.70	
[10/02 18:05:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[10/02 18:11:47 visual_prompt]: Epoch 14 / 100: avg data time: 1.02e+01, avg batch time: 11.3698, average train loss: 118.4506
[10/02 18:12:34 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.7251, average loss: 413.5839
[10/02 18:12:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.96	
[10/02 18:12:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[10/02 18:19:10 visual_prompt]: Epoch 15 / 100: avg data time: 1.02e+01, avg batch time: 11.3297, average train loss: 168.0777
[10/02 18:19:58 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.7261, average loss: 177.3540
[10/02 18:19:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.56	
[10/02 18:19:58 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[10/02 18:26:32 visual_prompt]: Epoch 16 / 100: avg data time: 1.01e+01, avg batch time: 11.2662, average train loss: 153.6443
[10/02 18:27:19 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.7242, average loss: 213.1648
[10/02 18:27:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.78	
[10/02 18:27:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[10/02 18:33:56 visual_prompt]: Epoch 17 / 100: avg data time: 1.02e+01, avg batch time: 11.3433, average train loss: 161.0038
[10/02 18:34:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.7187, average loss: 63.9858
[10/02 18:34:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.09	
[10/02 18:34:43 visual_prompt]: Best epoch 17: best metric: -63.986
[10/02 18:34:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[10/02 18:41:14 visual_prompt]: Epoch 18 / 100: avg data time: 9.99e+00, avg batch time: 11.1602, average train loss: 121.6138
[10/02 18:41:59 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.7214, average loss: 132.7883
[10/02 18:41:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.31	
[10/02 18:41:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[10/02 18:48:29 visual_prompt]: Epoch 19 / 100: avg data time: 9.97e+00, avg batch time: 11.1324, average train loss: 115.6560
[10/02 18:49:15 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.7244, average loss: 12.5098
[10/02 18:49:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.65	
[10/02 18:49:15 visual_prompt]: Best epoch 19: best metric: -12.510
[10/02 18:49:15 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[10/02 18:55:43 visual_prompt]: Epoch 20 / 100: avg data time: 9.90e+00, avg batch time: 11.0691, average train loss: 127.3774
[10/02 18:56:28 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.7340, average loss: 102.8995
[10/02 18:56:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.82	
[10/02 18:56:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[10/02 19:02:57 visual_prompt]: Epoch 21 / 100: avg data time: 9.94e+00, avg batch time: 11.1049, average train loss: 128.3010
[10/02 19:03:43 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.7300, average loss: 47.2012
[10/02 19:03:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.52	
[10/02 19:03:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[10/02 19:10:13 visual_prompt]: Epoch 22 / 100: avg data time: 9.95e+00, avg batch time: 11.1157, average train loss: 164.0197
[10/02 19:10:58 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.7255, average loss: 145.9279
[10/02 19:10:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.02	
[10/02 19:10:58 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[10/02 19:17:24 visual_prompt]: Epoch 23 / 100: avg data time: 9.87e+00, avg batch time: 11.0343, average train loss: 91.4616
[10/02 19:18:10 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.7253, average loss: 345.0354
[10/02 19:18:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.49	
[10/02 19:18:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[10/02 19:24:38 visual_prompt]: Epoch 24 / 100: avg data time: 9.93e+00, avg batch time: 11.0905, average train loss: 140.0738
[10/02 19:25:24 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.7314, average loss: 76.2726
[10/02 19:25:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.75	
[10/02 19:25:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[10/02 19:31:52 visual_prompt]: Epoch 25 / 100: avg data time: 9.92e+00, avg batch time: 11.0819, average train loss: 158.0046
[10/02 19:32:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.7249, average loss: 403.3833
[10/02 19:32:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.62	
[10/02 19:32:37 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[10/02 19:39:07 visual_prompt]: Epoch 26 / 100: avg data time: 9.97e+00, avg batch time: 11.1419, average train loss: 138.2520
[10/02 19:39:53 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.7232, average loss: 98.8286
[10/02 19:39:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.61	
[10/02 19:39:53 visual_prompt]: Stopping early.
[10/02 19:39:53 visual_prompt]: Rank of current process: 0. World size: 1
[10/02 19:39:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/02 19:39:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/02 19:39:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/02 19:39:53 visual_prompt]: Training with config:
[10/02 19:39:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/02 19:39:53 visual_prompt]: Loading training data...
[10/02 19:39:53 visual_prompt]: Constructing mammo-cbis dataset train...
[10/02 19:39:53 visual_prompt]: Loading validation data...
[10/02 19:39:53 visual_prompt]: Constructing mammo-cbis dataset val...
[10/02 19:39:53 visual_prompt]: Constructing models...
[10/02 19:39:56 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/02 19:39:56 visual_prompt]: tuned percent:0.536
[10/02 19:39:56 visual_prompt]: Device used for model: 0
[10/02 19:39:56 visual_prompt]: Setting up Evaluator...
[10/02 19:39:56 visual_prompt]: Setting up Trainer...
[10/02 19:39:56 visual_prompt]: 	Setting up the optimizer...
[10/02 19:39:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/02 19:46:28 visual_prompt]: Epoch 1 / 100: avg data time: 1.00e+01, avg batch time: 11.1725, average train loss: 1.4432
[10/02 19:47:14 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.7093, average loss: 1.4399
[10/02 19:47:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/02 19:47:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[10/02 19:53:44 visual_prompt]: Epoch 2 / 100: avg data time: 9.99e+00, avg batch time: 11.1460, average train loss: 20.0904
[10/02 19:54:30 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.7131, average loss: 6.7086
[10/02 19:54:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.26	
[10/02 19:54:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[10/02 20:01:01 visual_prompt]: Epoch 3 / 100: avg data time: 1.00e+01, avg batch time: 11.1611, average train loss: 37.2076
[10/02 20:01:47 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.7083, average loss: 22.6134
[10/02 20:01:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[10/02 20:01:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[10/02 20:08:18 visual_prompt]: Epoch 4 / 100: avg data time: 9.99e+00, avg batch time: 11.1494, average train loss: 22.5176
[10/02 20:09:03 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7025, average loss: 4.9006
[10/02 20:09:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.89	
[10/02 20:09:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[10/02 20:15:32 visual_prompt]: Epoch 5 / 100: avg data time: 9.95e+00, avg batch time: 11.1122, average train loss: 36.5615
[10/02 20:16:19 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.7123, average loss: 14.4196
[10/02 20:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.06	
[10/02 20:16:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[10/02 20:22:50 visual_prompt]: Epoch 6 / 100: avg data time: 9.99e+00, avg batch time: 11.1594, average train loss: 36.3270
[10/02 20:23:36 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7078, average loss: 11.1084
[10/02 20:23:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.49	
[10/02 20:23:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[10/02 20:30:07 visual_prompt]: Epoch 7 / 100: avg data time: 1.00e+01, avg batch time: 11.1828, average train loss: 73.7841
[10/02 20:30:54 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7115, average loss: 44.3981
[10/02 20:30:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.63	
[10/02 20:30:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[10/02 20:37:25 visual_prompt]: Epoch 8 / 100: avg data time: 1.00e+01, avg batch time: 11.1699, average train loss: 83.5152
[10/02 20:38:11 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7225, average loss: 70.7745
[10/02 20:38:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.85	
[10/02 20:38:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[10/02 20:44:46 visual_prompt]: Epoch 9 / 100: avg data time: 1.01e+01, avg batch time: 11.2847, average train loss: 74.7561
[10/02 20:45:33 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7127, average loss: 96.4574
[10/02 20:45:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.27	
[10/02 20:45:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[10/02 20:52:06 visual_prompt]: Epoch 10 / 100: avg data time: 1.01e+01, avg batch time: 11.2294, average train loss: 74.1861
[10/02 20:52:52 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.7066, average loss: 77.6613
[10/02 20:52:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.14	
[10/02 20:52:52 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[10/02 20:59:26 visual_prompt]: Epoch 11 / 100: avg data time: 1.01e+01, avg batch time: 11.2449, average train loss: 113.6030
[10/02 21:00:12 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.7156, average loss: 341.1895
[10/02 21:00:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[10/02 21:00:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[10/02 21:06:44 visual_prompt]: Epoch 12 / 100: avg data time: 1.00e+01, avg batch time: 11.1752, average train loss: 138.3560
[10/02 21:07:30 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.7150, average loss: 165.6288
[10/02 21:07:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.88	
[10/02 21:07:30 visual_prompt]: Best epoch 12: best metric: -165.629
[10/02 21:07:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[10/02 21:14:00 visual_prompt]: Epoch 13 / 100: avg data time: 1.00e+01, avg batch time: 11.1561, average train loss: 138.0021
[10/02 21:14:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.7112, average loss: 21.3471
[10/02 21:14:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.85	
[10/02 21:14:48 visual_prompt]: Best epoch 13: best metric: -21.347
[10/02 21:14:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[10/02 21:21:19 visual_prompt]: Epoch 14 / 100: avg data time: 1.00e+01, avg batch time: 11.1793, average train loss: 151.8206
[10/02 21:22:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7132, average loss: 125.4801
[10/02 21:22:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[10/02 21:22:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[10/02 21:28:35 visual_prompt]: Epoch 15 / 100: avg data time: 9.99e+00, avg batch time: 11.1495, average train loss: 82.1610
[10/02 21:29:21 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.7164, average loss: 52.0464
[10/02 21:29:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.98	
[10/02 21:29:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[10/02 21:35:51 visual_prompt]: Epoch 16 / 100: avg data time: 9.98e+00, avg batch time: 11.1357, average train loss: 100.7854
[10/02 21:36:37 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.7134, average loss: 222.6594
[10/02 21:36:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.54	
[10/02 21:36:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[10/02 21:43:04 visual_prompt]: Epoch 17 / 100: avg data time: 9.90e+00, avg batch time: 11.0620, average train loss: 119.6415
[10/02 21:43:50 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7097, average loss: 557.8604
[10/02 21:43:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.31	
[10/02 21:43:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[10/02 21:50:20 visual_prompt]: Epoch 18 / 100: avg data time: 9.98e+00, avg batch time: 11.1447, average train loss: 139.9472
[10/02 21:51:06 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.7122, average loss: 373.1405
[10/02 21:51:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.49	
[10/02 21:51:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[10/02 21:57:36 visual_prompt]: Epoch 19 / 100: avg data time: 9.99e+00, avg batch time: 11.1444, average train loss: 106.1542
[10/02 21:58:22 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7115, average loss: 46.9442
[10/02 21:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.61	
[10/02 21:58:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[10/02 22:04:51 visual_prompt]: Epoch 20 / 100: avg data time: 9.96e+00, avg batch time: 11.1185, average train loss: 88.7551
[10/02 22:05:37 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.7078, average loss: 201.3966
[10/02 22:05:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.07	
[10/02 22:05:37 visual_prompt]: Stopping early.
[10/02 22:05:37 visual_prompt]: Rank of current process: 0. World size: 1
[10/02 22:05:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/02 22:05:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/02 22:05:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/02 22:05:37 visual_prompt]: Training with config:
[10/02 22:05:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/02 22:05:37 visual_prompt]: Loading training data...
[10/02 22:05:37 visual_prompt]: Constructing mammo-cbis dataset train...
[10/02 22:05:37 visual_prompt]: Loading validation data...
[10/02 22:05:37 visual_prompt]: Constructing mammo-cbis dataset val...
[10/02 22:05:37 visual_prompt]: Constructing models...
[10/02 22:05:40 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/02 22:05:40 visual_prompt]: tuned percent:0.536
[10/02 22:05:40 visual_prompt]: Device used for model: 0
[10/02 22:05:40 visual_prompt]: Setting up Evaluator...
[10/02 22:05:40 visual_prompt]: Setting up Trainer...
[10/02 22:05:40 visual_prompt]: 	Setting up the optimizer...
[10/02 22:05:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/02 22:12:07 visual_prompt]: Epoch 1 / 100: avg data time: 9.88e+00, avg batch time: 11.0463, average train loss: 1.4432
[10/02 22:12:52 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.7126, average loss: 1.4399
[10/02 22:12:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/02 22:12:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[10/02 22:19:19 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 11.0441, average train loss: 20.1477
[10/02 22:20:05 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.7091, average loss: 21.3977
[10/02 22:20:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.74	
[10/02 22:20:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[10/02 22:26:31 visual_prompt]: Epoch 3 / 100: avg data time: 9.86e+00, avg batch time: 11.0256, average train loss: 23.2273
[10/02 22:27:16 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7123, average loss: 10.0396
[10/02 22:27:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.76	
[10/02 22:27:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[10/02 22:33:42 visual_prompt]: Epoch 4 / 100: avg data time: 9.85e+00, avg batch time: 11.0075, average train loss: 20.6705
[10/02 22:34:27 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.7053, average loss: 60.2509
[10/02 22:34:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.75	
[10/02 22:34:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[10/02 22:40:51 visual_prompt]: Epoch 5 / 100: avg data time: 9.79e+00, avg batch time: 10.9528, average train loss: 54.2520
[10/02 22:41:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.7112, average loss: 58.5102
[10/02 22:41:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.45	
[10/02 22:41:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[10/02 22:48:00 visual_prompt]: Epoch 6 / 100: avg data time: 9.79e+00, avg batch time: 10.9569, average train loss: 49.8613
[10/02 22:48:45 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7094, average loss: 123.0924
[10/02 22:48:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.28	
[10/02 22:48:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[10/02 22:55:09 visual_prompt]: Epoch 7 / 100: avg data time: 9.81e+00, avg batch time: 10.9694, average train loss: 91.0644
[10/02 22:55:54 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.7104, average loss: 108.4804
[10/02 22:55:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.35	
[10/02 22:55:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[10/02 23:02:17 visual_prompt]: Epoch 8 / 100: avg data time: 9.76e+00, avg batch time: 10.9152, average train loss: 80.7255
[10/02 23:03:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7063, average loss: 132.6052
[10/02 23:03:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.43	
[10/02 23:03:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[10/02 23:09:25 visual_prompt]: Epoch 9 / 100: avg data time: 9.79e+00, avg batch time: 10.9503, average train loss: 52.0097
[10/02 23:10:10 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7082, average loss: 39.0298
[10/02 23:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.27	
[10/02 23:10:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[10/02 23:16:33 visual_prompt]: Epoch 10 / 100: avg data time: 9.77e+00, avg batch time: 10.9285, average train loss: 62.5956
[10/02 23:17:18 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.7072, average loss: 60.1182
[10/02 23:17:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.02	
[10/02 23:17:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[10/02 23:23:40 visual_prompt]: Epoch 11 / 100: avg data time: 9.76e+00, avg batch time: 10.9121, average train loss: 104.2936
[10/02 23:24:25 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.7048, average loss: 152.2292
[10/02 23:24:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.53	
[10/02 23:24:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[10/02 23:30:46 visual_prompt]: Epoch 12 / 100: avg data time: 9.73e+00, avg batch time: 10.8802, average train loss: 111.1297
[10/02 23:31:31 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7076, average loss: 42.5438
[10/02 23:31:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.87	
[10/02 23:31:31 visual_prompt]: Best epoch 12: best metric: -42.544
[10/02 23:31:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[10/02 23:37:53 visual_prompt]: Epoch 13 / 100: avg data time: 9.75e+00, avg batch time: 10.9075, average train loss: 71.6803
[10/02 23:38:38 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.7054, average loss: 85.0036
[10/02 23:38:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.55	
[10/02 23:38:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[10/02 23:44:59 visual_prompt]: Epoch 14 / 100: avg data time: 9.74e+00, avg batch time: 10.8914, average train loss: 69.1299
[10/02 23:45:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7066, average loss: 55.3690
[10/02 23:45:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.82	
[10/02 23:45:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[10/02 23:52:07 visual_prompt]: Epoch 15 / 100: avg data time: 9.76e+00, avg batch time: 10.9215, average train loss: 87.9787
[10/02 23:52:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7040, average loss: 43.6740
[10/02 23:52:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.23	
[10/02 23:52:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[10/02 23:59:14 visual_prompt]: Epoch 16 / 100: avg data time: 9.75e+00, avg batch time: 10.9064, average train loss: 69.0210
[10/02 23:59:59 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.7132, average loss: 152.5282
[10/02 23:59:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.88	
[10/02 23:59:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[10/03 00:06:21 visual_prompt]: Epoch 17 / 100: avg data time: 9.76e+00, avg batch time: 10.9123, average train loss: 118.9749
[10/03 00:07:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7066, average loss: 68.4973
[10/03 00:07:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.17	
[10/03 00:07:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[10/03 00:13:28 visual_prompt]: Epoch 18 / 100: avg data time: 9.75e+00, avg batch time: 10.9062, average train loss: 61.1423
[10/03 00:14:13 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.7110, average loss: 345.0061
[10/03 00:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.21	
[10/03 00:14:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[10/03 00:20:34 visual_prompt]: Epoch 19 / 100: avg data time: 9.73e+00, avg batch time: 10.8861, average train loss: 109.2406
[10/03 00:21:19 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.7087, average loss: 103.0431
[10/03 00:21:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.35	
[10/03 00:21:19 visual_prompt]: Stopping early.
[10/03 00:21:19 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 00:21:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 00:21:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 00:21:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 00:21:19 visual_prompt]: Training with config:
[10/03 00:21:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 00:21:19 visual_prompt]: Loading training data...
[10/03 00:21:19 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 00:21:19 visual_prompt]: Loading validation data...
[10/03 00:21:19 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 00:21:19 visual_prompt]: Constructing models...
[10/03 00:21:22 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 00:21:22 visual_prompt]: tuned percent:0.536
[10/03 00:21:22 visual_prompt]: Device used for model: 0
[10/03 00:21:22 visual_prompt]: Setting up Evaluator...
[10/03 00:21:22 visual_prompt]: Setting up Trainer...
[10/03 00:21:22 visual_prompt]: 	Setting up the optimizer...
[10/03 00:21:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 00:27:46 visual_prompt]: Epoch 1 / 100: avg data time: 9.82e+00, avg batch time: 10.9802, average train loss: 1.4432
[10/03 00:28:31 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7059, average loss: 1.4399
[10/03 00:28:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 00:28:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[10/03 00:34:54 visual_prompt]: Epoch 2 / 100: avg data time: 9.77e+00, avg batch time: 10.9355, average train loss: 21.7838
[10/03 00:35:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.7077, average loss: 20.8583
[10/03 00:35:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.70	
[10/03 00:35:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[10/03 00:42:02 visual_prompt]: Epoch 3 / 100: avg data time: 9.77e+00, avg batch time: 10.9344, average train loss: 20.0278
[10/03 00:42:47 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7072, average loss: 17.3450
[10/03 00:42:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.85	
[10/03 00:42:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[10/03 00:49:10 visual_prompt]: Epoch 4 / 100: avg data time: 9.76e+00, avg batch time: 10.9231, average train loss: 27.0385
[10/03 00:49:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7135, average loss: 54.9024
[10/03 00:49:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.44	
[10/03 00:49:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[10/03 00:56:18 visual_prompt]: Epoch 5 / 100: avg data time: 9.77e+00, avg batch time: 10.9249, average train loss: 69.8981
[10/03 00:57:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7147, average loss: 4.2949
[10/03 00:57:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[10/03 00:57:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[10/03 01:03:27 visual_prompt]: Epoch 6 / 100: avg data time: 9.80e+00, avg batch time: 10.9636, average train loss: 54.0075
[10/03 01:04:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.7087, average loss: 88.1390
[10/03 01:04:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.43	
[10/03 01:04:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[10/03 01:10:36 visual_prompt]: Epoch 7 / 100: avg data time: 9.78e+00, avg batch time: 10.9409, average train loss: 74.4518
[10/03 01:11:21 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7108, average loss: 78.3696
[10/03 01:11:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[10/03 01:11:21 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[10/03 01:17:43 visual_prompt]: Epoch 8 / 100: avg data time: 9.75e+00, avg batch time: 10.9110, average train loss: 68.6966
[10/03 01:18:28 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.7138, average loss: 64.1244
[10/03 01:18:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.66	
[10/03 01:18:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[10/03 01:24:51 visual_prompt]: Epoch 9 / 100: avg data time: 9.78e+00, avg batch time: 10.9430, average train loss: 47.7369
[10/03 01:25:36 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.7148, average loss: 24.1710
[10/03 01:25:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.19	
[10/03 01:25:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[10/03 01:31:59 visual_prompt]: Epoch 10 / 100: avg data time: 9.76e+00, avg batch time: 10.9235, average train loss: 35.2725
[10/03 01:32:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7082, average loss: 36.8046
[10/03 01:32:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[10/03 01:32:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[10/03 01:39:07 visual_prompt]: Epoch 11 / 100: avg data time: 9.78e+00, avg batch time: 10.9456, average train loss: 53.9576
[10/03 01:39:52 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.7115, average loss: 149.4351
[10/03 01:39:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[10/03 01:39:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[10/03 01:46:16 visual_prompt]: Epoch 12 / 100: avg data time: 9.78e+00, avg batch time: 10.9393, average train loss: 94.6870
[10/03 01:47:01 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.7060, average loss: 182.3330
[10/03 01:47:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.58	
[10/03 01:47:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[10/03 01:53:23 visual_prompt]: Epoch 13 / 100: avg data time: 9.77e+00, avg batch time: 10.9313, average train loss: 115.6970
[10/03 01:54:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7093, average loss: 124.8109
[10/03 01:54:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.72	
[10/03 01:54:09 visual_prompt]: Best epoch 13: best metric: -124.811
[10/03 01:54:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[10/03 02:00:31 visual_prompt]: Epoch 14 / 100: avg data time: 9.77e+00, avg batch time: 10.9287, average train loss: 73.4744
[10/03 02:01:17 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.7077, average loss: 4.2066
[10/03 02:01:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.60	
[10/03 02:01:17 visual_prompt]: Best epoch 14: best metric: -4.207
[10/03 02:01:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[10/03 02:07:41 visual_prompt]: Epoch 15 / 100: avg data time: 9.80e+00, avg batch time: 10.9646, average train loss: 72.9943
[10/03 02:08:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.7135, average loss: 3.9043
[10/03 02:08:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.45	
[10/03 02:08:26 visual_prompt]: Best epoch 15: best metric: -3.904
[10/03 02:08:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[10/03 02:14:49 visual_prompt]: Epoch 16 / 100: avg data time: 9.77e+00, avg batch time: 10.9374, average train loss: 61.2347
[10/03 02:15:34 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7083, average loss: 69.8820
[10/03 02:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.14	
[10/03 02:15:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[10/03 02:21:56 visual_prompt]: Epoch 17 / 100: avg data time: 9.76e+00, avg batch time: 10.9184, average train loss: 64.8947
[10/03 02:22:42 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7162, average loss: 18.1887
[10/03 02:22:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[10/03 02:22:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[10/03 02:29:04 visual_prompt]: Epoch 18 / 100: avg data time: 9.77e+00, avg batch time: 10.9254, average train loss: 72.9098
[10/03 02:29:49 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.7142, average loss: 25.5401
[10/03 02:29:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.80	
[10/03 02:29:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[10/03 02:36:13 visual_prompt]: Epoch 19 / 100: avg data time: 9.79e+00, avg batch time: 10.9457, average train loss: 83.3088
[10/03 02:36:58 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.7097, average loss: 113.6465
[10/03 02:36:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.86	
[10/03 02:36:58 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[10/03 02:43:21 visual_prompt]: Epoch 20 / 100: avg data time: 9.78e+00, avg batch time: 10.9350, average train loss: 51.2556
[10/03 02:44:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.7089, average loss: 8.7162
[10/03 02:44:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.32	
[10/03 02:44:06 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[10/03 02:50:29 visual_prompt]: Epoch 21 / 100: avg data time: 9.77e+00, avg batch time: 10.9340, average train loss: 48.3686
[10/03 02:51:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.7133, average loss: 54.9170
[10/03 02:51:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.35	
[10/03 02:51:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[10/03 02:57:36 visual_prompt]: Epoch 22 / 100: avg data time: 9.76e+00, avg batch time: 10.9211, average train loss: 34.9452
[10/03 02:58:21 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7082, average loss: 34.2833
[10/03 02:58:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.54	
[10/03 02:58:21 visual_prompt]: Stopping early.
[10/03 02:58:22 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 02:58:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 02:58:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 02:58:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 02:58:22 visual_prompt]: Training with config:
[10/03 02:58:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 02:58:22 visual_prompt]: Loading training data...
[10/03 02:58:22 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 02:58:22 visual_prompt]: Loading validation data...
[10/03 02:58:22 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 02:58:22 visual_prompt]: Constructing models...
[10/03 02:58:24 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 02:58:24 visual_prompt]: tuned percent:0.536
[10/03 02:58:24 visual_prompt]: Device used for model: 0
[10/03 02:58:24 visual_prompt]: Setting up Evaluator...
[10/03 02:58:24 visual_prompt]: Setting up Trainer...
[10/03 02:58:24 visual_prompt]: 	Setting up the optimizer...
[10/03 02:58:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 03:04:49 visual_prompt]: Epoch 1 / 100: avg data time: 9.82e+00, avg batch time: 10.9906, average train loss: 1.4432
[10/03 03:05:34 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7165, average loss: 1.4399
[10/03 03:05:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 03:05:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[10/03 03:11:57 visual_prompt]: Epoch 2 / 100: avg data time: 9.77e+00, avg batch time: 10.9376, average train loss: 11.4790
[10/03 03:12:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.7137, average loss: 0.9195
[10/03 03:12:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.59	
[10/03 03:12:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[10/03 03:19:06 visual_prompt]: Epoch 3 / 100: avg data time: 9.77e+00, avg batch time: 10.9419, average train loss: 16.4615
[10/03 03:19:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.7060, average loss: 3.0586
[10/03 03:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.79	
[10/03 03:19:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[10/03 03:26:14 visual_prompt]: Epoch 4 / 100: avg data time: 9.77e+00, avg batch time: 10.9376, average train loss: 20.2806
[10/03 03:26:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7085, average loss: 8.5779
[10/03 03:26:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.98	
[10/03 03:26:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[10/03 03:33:21 visual_prompt]: Epoch 5 / 100: avg data time: 9.74e+00, avg batch time: 10.9070, average train loss: 20.8844
[10/03 03:34:06 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.7044, average loss: 36.0676
[10/03 03:34:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[10/03 03:34:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[10/03 03:40:31 visual_prompt]: Epoch 6 / 100: avg data time: 9.83e+00, avg batch time: 11.0027, average train loss: 27.0465
[10/03 03:41:16 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7052, average loss: 9.9494
[10/03 03:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.36	
[10/03 03:41:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[10/03 03:47:42 visual_prompt]: Epoch 7 / 100: avg data time: 9.84e+00, avg batch time: 11.0017, average train loss: 30.2808
[10/03 03:48:27 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.7123, average loss: 66.2610
[10/03 03:48:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.72	
[10/03 03:48:27 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[10/03 03:54:50 visual_prompt]: Epoch 8 / 100: avg data time: 9.78e+00, avg batch time: 10.9449, average train loss: 46.6164
[10/03 03:55:35 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.7050, average loss: 146.8339
[10/03 03:55:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.71	
[10/03 03:55:35 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[10/03 04:02:00 visual_prompt]: Epoch 9 / 100: avg data time: 9.83e+00, avg batch time: 10.9987, average train loss: 58.6268
[10/03 04:02:46 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.7103, average loss: 27.6498
[10/03 04:02:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.95	
[10/03 04:02:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[10/03 04:09:10 visual_prompt]: Epoch 10 / 100: avg data time: 9.81e+00, avg batch time: 10.9736, average train loss: 63.0868
[10/03 04:09:55 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7104, average loss: 16.3126
[10/03 04:09:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.74	
[10/03 04:09:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[10/03 04:16:19 visual_prompt]: Epoch 11 / 100: avg data time: 9.81e+00, avg batch time: 10.9708, average train loss: 63.1420
[10/03 04:17:05 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7115, average loss: 128.5638
[10/03 04:17:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.40	
[10/03 04:17:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[10/03 04:23:28 visual_prompt]: Epoch 12 / 100: avg data time: 9.80e+00, avg batch time: 10.9607, average train loss: 65.6813
[10/03 04:24:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.7087, average loss: 76.7402
[10/03 04:24:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.57	
[10/03 04:24:14 visual_prompt]: Best epoch 12: best metric: -76.740
[10/03 04:24:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[10/03 04:30:38 visual_prompt]: Epoch 13 / 100: avg data time: 9.81e+00, avg batch time: 10.9737, average train loss: 65.2741
[10/03 04:31:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.7187, average loss: 29.1432
[10/03 04:31:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.80	
[10/03 04:31:23 visual_prompt]: Best epoch 13: best metric: -29.143
[10/03 04:31:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[10/03 04:37:46 visual_prompt]: Epoch 14 / 100: avg data time: 9.77e+00, avg batch time: 10.9300, average train loss: 79.9115
[10/03 04:38:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.7158, average loss: 21.7552
[10/03 04:38:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.37	
[10/03 04:38:31 visual_prompt]: Best epoch 14: best metric: -21.755
[10/03 04:38:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[10/03 04:44:55 visual_prompt]: Epoch 15 / 100: avg data time: 9.79e+00, avg batch time: 10.9535, average train loss: 68.7788
[10/03 04:45:40 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7154, average loss: 64.6262
[10/03 04:45:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.40	
[10/03 04:45:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[10/03 04:52:03 visual_prompt]: Epoch 16 / 100: avg data time: 9.78e+00, avg batch time: 10.9425, average train loss: 53.5748
[10/03 04:52:48 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7115, average loss: 24.1470
[10/03 04:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.33	
[10/03 04:52:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[10/03 04:59:11 visual_prompt]: Epoch 17 / 100: avg data time: 9.76e+00, avg batch time: 10.9208, average train loss: 70.6547
[10/03 04:59:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7188, average loss: 126.3950
[10/03 04:59:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.47	
[10/03 04:59:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[10/03 05:06:20 visual_prompt]: Epoch 18 / 100: avg data time: 9.80e+00, avg batch time: 10.9642, average train loss: 64.3183
[10/03 05:07:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.7140, average loss: 59.1207
[10/03 05:07:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.78	
[10/03 05:07:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[10/03 05:13:29 visual_prompt]: Epoch 19 / 100: avg data time: 9.78e+00, avg batch time: 10.9472, average train loss: 49.6896
[10/03 05:14:14 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7089, average loss: 51.1168
[10/03 05:14:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.10	
[10/03 05:14:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[10/03 05:20:39 visual_prompt]: Epoch 20 / 100: avg data time: 9.84e+00, avg batch time: 11.0037, average train loss: 81.5709
[10/03 05:21:25 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7146, average loss: 8.4628
[10/03 05:21:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 56.30	
[10/03 05:21:25 visual_prompt]: Best epoch 20: best metric: -8.463
[10/03 05:21:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[10/03 05:27:50 visual_prompt]: Epoch 21 / 100: avg data time: 9.84e+00, avg batch time: 11.0035, average train loss: 77.0259
[10/03 05:28:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7116, average loss: 165.5222
[10/03 05:28:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.28	
[10/03 05:28:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[10/03 05:35:00 visual_prompt]: Epoch 22 / 100: avg data time: 9.83e+00, avg batch time: 10.9911, average train loss: 73.5009
[10/03 05:35:46 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.7090, average loss: 56.8181
[10/03 05:35:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.11	
[10/03 05:35:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[10/03 05:42:11 visual_prompt]: Epoch 23 / 100: avg data time: 9.83e+00, avg batch time: 10.9945, average train loss: 69.2510
[10/03 05:42:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7084, average loss: 26.6646
[10/03 05:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.98	
[10/03 05:42:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[10/03 05:49:20 visual_prompt]: Epoch 24 / 100: avg data time: 9.80e+00, avg batch time: 10.9580, average train loss: 102.5986
[10/03 05:50:05 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7172, average loss: 85.0633
[10/03 05:50:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.52	
[10/03 05:50:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[10/03 05:56:28 visual_prompt]: Epoch 25 / 100: avg data time: 9.77e+00, avg batch time: 10.9291, average train loss: 52.1895
[10/03 05:57:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7120, average loss: 2.5795
[10/03 05:57:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.11	
[10/03 05:57:13 visual_prompt]: Best epoch 25: best metric: -2.579
[10/03 05:57:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[10/03 06:03:35 visual_prompt]: Epoch 26 / 100: avg data time: 9.77e+00, avg batch time: 10.9302, average train loss: 64.8037
[10/03 06:04:21 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.7059, average loss: 49.9525
[10/03 06:04:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.62	
[10/03 06:04:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[10/03 06:10:43 visual_prompt]: Epoch 27 / 100: avg data time: 9.77e+00, avg batch time: 10.9321, average train loss: 64.8416
[10/03 06:11:29 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.7087, average loss: 297.9398
[10/03 06:11:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.21	
[10/03 06:11:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[10/03 06:17:51 visual_prompt]: Epoch 28 / 100: avg data time: 9.75e+00, avg batch time: 10.9164, average train loss: 61.1749
[10/03 06:18:36 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.7089, average loss: 26.5288
[10/03 06:18:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.25	
[10/03 06:18:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[10/03 06:24:59 visual_prompt]: Epoch 29 / 100: avg data time: 9.79e+00, avg batch time: 10.9533, average train loss: 57.5874
[10/03 06:25:45 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.7093, average loss: 35.5740
[10/03 06:25:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.53	
[10/03 06:25:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[10/03 06:32:08 visual_prompt]: Epoch 30 / 100: avg data time: 9.76e+00, avg batch time: 10.9315, average train loss: 50.1374
[10/03 06:32:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7142, average loss: 14.9220
[10/03 06:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.01	
[10/03 06:32:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[10/03 06:39:15 visual_prompt]: Epoch 31 / 100: avg data time: 9.76e+00, avg batch time: 10.9193, average train loss: 57.5563
[10/03 06:40:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7184, average loss: 36.5282
[10/03 06:40:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.00	
[10/03 06:40:00 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[10/03 06:46:23 visual_prompt]: Epoch 32 / 100: avg data time: 9.78e+00, avg batch time: 10.9483, average train loss: 39.8827
[10/03 06:47:09 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7190, average loss: 33.4746
[10/03 06:47:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.13	
[10/03 06:47:09 visual_prompt]: Stopping early.
[10/03 06:47:09 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 06:47:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 06:47:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 06:47:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 06:47:09 visual_prompt]: Training with config:
[10/03 06:47:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 06:47:09 visual_prompt]: Loading training data...
[10/03 06:47:09 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 06:47:09 visual_prompt]: Loading validation data...
[10/03 06:47:09 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 06:47:09 visual_prompt]: Constructing models...
[10/03 06:47:11 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 06:47:11 visual_prompt]: tuned percent:0.536
[10/03 06:47:12 visual_prompt]: Device used for model: 0
[10/03 06:47:12 visual_prompt]: Setting up Evaluator...
[10/03 06:47:12 visual_prompt]: Setting up Trainer...
[10/03 06:47:12 visual_prompt]: 	Setting up the optimizer...
[10/03 06:47:12 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 06:53:36 visual_prompt]: Epoch 1 / 100: avg data time: 9.81e+00, avg batch time: 10.9788, average train loss: 1.4432
[10/03 06:54:22 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.7116, average loss: 1.4399
[10/03 06:54:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 06:54:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[10/03 07:00:49 visual_prompt]: Epoch 2 / 100: avg data time: 9.90e+00, avg batch time: 11.0616, average train loss: 10.3433
[10/03 07:01:35 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.7085, average loss: 0.7852
[10/03 07:01:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 52.80	
[10/03 07:01:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[10/03 07:08:03 visual_prompt]: Epoch 3 / 100: avg data time: 9.92e+00, avg batch time: 11.0803, average train loss: 6.2659
[10/03 07:08:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.7073, average loss: 2.6012
[10/03 07:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.34	
[10/03 07:08:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[10/03 07:15:18 visual_prompt]: Epoch 4 / 100: avg data time: 9.94e+00, avg batch time: 11.0987, average train loss: 18.8022
[10/03 07:16:03 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7114, average loss: 9.2399
[10/03 07:16:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.40	
[10/03 07:16:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[10/03 07:22:29 visual_prompt]: Epoch 5 / 100: avg data time: 9.85e+00, avg batch time: 11.0129, average train loss: 18.0771
[10/03 07:23:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.7133, average loss: 8.7323
[10/03 07:23:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.34	
[10/03 07:23:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[10/03 07:29:38 visual_prompt]: Epoch 6 / 100: avg data time: 9.82e+00, avg batch time: 10.9778, average train loss: 16.4192
[10/03 07:30:24 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.7158, average loss: 46.6622
[10/03 07:30:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.72	
[10/03 07:30:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[10/03 07:36:48 visual_prompt]: Epoch 7 / 100: avg data time: 9.81e+00, avg batch time: 10.9751, average train loss: 34.1675
[10/03 07:37:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7064, average loss: 34.0785
[10/03 07:37:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[10/03 07:37:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[10/03 07:43:57 visual_prompt]: Epoch 8 / 100: avg data time: 9.78e+00, avg batch time: 10.9439, average train loss: 31.2149
[10/03 07:44:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.7088, average loss: 39.7565
[10/03 07:44:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.75	
[10/03 07:44:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[10/03 07:51:06 visual_prompt]: Epoch 9 / 100: avg data time: 9.81e+00, avg batch time: 10.9770, average train loss: 22.2712
[10/03 07:51:51 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7103, average loss: 37.2180
[10/03 07:51:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.88	
[10/03 07:51:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[10/03 07:58:15 visual_prompt]: Epoch 10 / 100: avg data time: 9.79e+00, avg batch time: 10.9466, average train loss: 61.1578
[10/03 07:59:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7115, average loss: 100.6937
[10/03 07:59:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.85	
[10/03 07:59:00 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[10/03 08:05:23 visual_prompt]: Epoch 11 / 100: avg data time: 9.80e+00, avg batch time: 10.9556, average train loss: 65.0167
[10/03 08:06:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.7081, average loss: 46.2057
[10/03 08:06:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.66	
[10/03 08:06:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[10/03 08:12:32 visual_prompt]: Epoch 12 / 100: avg data time: 9.78e+00, avg batch time: 10.9436, average train loss: 53.9913
[10/03 08:13:17 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.7138, average loss: 18.9756
[10/03 08:13:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.21	
[10/03 08:13:17 visual_prompt]: Best epoch 12: best metric: -18.976
[10/03 08:13:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[10/03 08:19:40 visual_prompt]: Epoch 13 / 100: avg data time: 9.78e+00, avg batch time: 10.9444, average train loss: 52.0180
[10/03 08:20:25 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.7102, average loss: 29.8829
[10/03 08:20:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.53	
[10/03 08:20:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[10/03 08:26:47 visual_prompt]: Epoch 14 / 100: avg data time: 9.76e+00, avg batch time: 10.9161, average train loss: 67.4417
[10/03 08:27:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7046, average loss: 44.1597
[10/03 08:27:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.86	
[10/03 08:27:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[10/03 08:33:56 visual_prompt]: Epoch 15 / 100: avg data time: 9.78e+00, avg batch time: 10.9380, average train loss: 62.1023
[10/03 08:34:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.7045, average loss: 94.0601
[10/03 08:34:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.11	
[10/03 08:34:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[10/03 08:41:03 visual_prompt]: Epoch 16 / 100: avg data time: 9.76e+00, avg batch time: 10.9224, average train loss: 46.7664
[10/03 08:41:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7142, average loss: 126.1739
[10/03 08:41:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.16	
[10/03 08:41:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[10/03 08:48:11 visual_prompt]: Epoch 17 / 100: avg data time: 9.75e+00, avg batch time: 10.9127, average train loss: 62.7172
[10/03 08:48:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7173, average loss: 26.8040
[10/03 08:48:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.31	
[10/03 08:48:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[10/03 08:55:18 visual_prompt]: Epoch 18 / 100: avg data time: 9.76e+00, avg batch time: 10.9225, average train loss: 49.0542
[10/03 08:56:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.7078, average loss: 38.1358
[10/03 08:56:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.85	
[10/03 08:56:03 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[10/03 09:02:26 visual_prompt]: Epoch 19 / 100: avg data time: 9.77e+00, avg batch time: 10.9353, average train loss: 51.6560
[10/03 09:03:11 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.7093, average loss: 14.0625
[10/03 09:03:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[10/03 09:03:11 visual_prompt]: Best epoch 19: best metric: -14.062
[10/03 09:03:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[10/03 09:09:34 visual_prompt]: Epoch 20 / 100: avg data time: 9.78e+00, avg batch time: 10.9425, average train loss: 48.2921
[10/03 09:10:19 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.7069, average loss: 21.2129
[10/03 09:10:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.11	
[10/03 09:10:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[10/03 09:16:42 visual_prompt]: Epoch 21 / 100: avg data time: 9.77e+00, avg batch time: 10.9257, average train loss: 58.3894
[10/03 09:17:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.7085, average loss: 85.3619
[10/03 09:17:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.87	
[10/03 09:17:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[10/03 09:23:51 visual_prompt]: Epoch 22 / 100: avg data time: 9.81e+00, avg batch time: 10.9699, average train loss: 74.6160
[10/03 09:24:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7123, average loss: 43.7689
[10/03 09:24:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.93	
[10/03 09:24:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[10/03 09:31:13 visual_prompt]: Epoch 23 / 100: avg data time: 1.02e+01, avg batch time: 11.3097, average train loss: 48.1773
[10/03 09:32:00 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7043, average loss: 35.7975
[10/03 09:32:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.04	
[10/03 09:32:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[10/03 09:38:32 visual_prompt]: Epoch 24 / 100: avg data time: 1.00e+01, avg batch time: 11.2078, average train loss: 51.8639
[10/03 09:39:18 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.7040, average loss: 39.0344
[10/03 09:39:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.40	
[10/03 09:39:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[10/03 09:45:48 visual_prompt]: Epoch 25 / 100: avg data time: 9.97e+00, avg batch time: 11.1271, average train loss: 76.3601
[10/03 09:46:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.7084, average loss: 31.6017
[10/03 09:46:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.46	
[10/03 09:46:34 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[10/03 09:53:02 visual_prompt]: Epoch 26 / 100: avg data time: 9.90e+00, avg batch time: 11.0662, average train loss: 54.2820
[10/03 09:53:48 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7131, average loss: 27.4978
[10/03 09:53:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.54	
[10/03 09:53:48 visual_prompt]: Stopping early.
[10/03 09:53:48 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 09:53:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 09:53:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 09:53:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 09:53:48 visual_prompt]: Training with config:
[10/03 09:53:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 09:53:48 visual_prompt]: Loading training data...
[10/03 09:53:48 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 09:53:48 visual_prompt]: Loading validation data...
[10/03 09:53:48 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 09:53:48 visual_prompt]: Constructing models...
[10/03 09:53:51 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 09:53:51 visual_prompt]: tuned percent:0.536
[10/03 09:53:51 visual_prompt]: Device used for model: 0
[10/03 09:53:51 visual_prompt]: Setting up Evaluator...
[10/03 09:53:51 visual_prompt]: Setting up Trainer...
[10/03 09:53:51 visual_prompt]: 	Setting up the optimizer...
[10/03 09:53:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 10:00:19 visual_prompt]: Epoch 1 / 100: avg data time: 9.93e+00, avg batch time: 11.0974, average train loss: 1.4432
[10/03 10:01:05 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.7084, average loss: 1.4399
[10/03 10:01:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 10:01:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[10/03 10:07:39 visual_prompt]: Epoch 2 / 100: avg data time: 1.01e+01, avg batch time: 11.2585, average train loss: 23.3059
[10/03 10:08:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.7129, average loss: 8.8453
[10/03 10:08:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.91	
[10/03 10:08:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[10/03 10:15:15 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 11.6297, average train loss: 13.1739
[10/03 10:16:02 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7168, average loss: 14.1774
[10/03 10:16:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.80	
[10/03 10:16:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[10/03 10:22:43 visual_prompt]: Epoch 4 / 100: avg data time: 1.03e+01, avg batch time: 11.4351, average train loss: 15.2536
[10/03 10:23:30 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.7162, average loss: 4.2887
[10/03 10:23:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.22	
[10/03 10:23:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[10/03 10:30:08 visual_prompt]: Epoch 5 / 100: avg data time: 1.02e+01, avg batch time: 11.3757, average train loss: 12.0970
[10/03 10:30:54 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.7138, average loss: 14.5222
[10/03 10:30:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.57	
[10/03 10:30:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[10/03 10:37:28 visual_prompt]: Epoch 6 / 100: avg data time: 1.01e+01, avg batch time: 11.2326, average train loss: 14.1685
[10/03 10:38:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7115, average loss: 14.8755
[10/03 10:38:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.48	
[10/03 10:38:14 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[10/03 10:44:47 visual_prompt]: Epoch 7 / 100: avg data time: 1.01e+01, avg batch time: 11.2259, average train loss: 9.8749
[10/03 10:45:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7196, average loss: 69.8386
[10/03 10:45:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.28	
[10/03 10:45:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[10/03 10:52:03 visual_prompt]: Epoch 8 / 100: avg data time: 9.97e+00, avg batch time: 11.1363, average train loss: 35.6665
[10/03 10:52:48 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7126, average loss: 0.6849
[10/03 10:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 56.01	
[10/03 10:52:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[10/03 10:59:14 visual_prompt]: Epoch 9 / 100: avg data time: 9.84e+00, avg batch time: 11.0020, average train loss: 22.7956
[10/03 10:59:59 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7102, average loss: 23.2213
[10/03 10:59:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.71	
[10/03 10:59:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[10/03 11:06:24 visual_prompt]: Epoch 10 / 100: avg data time: 9.83e+00, avg batch time: 11.0026, average train loss: 13.6272
[10/03 11:07:10 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7106, average loss: 42.3707
[10/03 11:07:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.08	
[10/03 11:07:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[10/03 11:13:45 visual_prompt]: Epoch 11 / 100: avg data time: 1.01e+01, avg batch time: 11.2769, average train loss: 60.4955
[10/03 11:14:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7055, average loss: 91.1158
[10/03 11:14:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.78	
[10/03 11:14:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[10/03 11:21:16 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 11.5678, average train loss: 30.3508
[10/03 11:22:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7044, average loss: 52.0136
[10/03 11:22:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.85	
[10/03 11:22:02 visual_prompt]: Best epoch 12: best metric: -52.014
[10/03 11:22:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[10/03 11:28:38 visual_prompt]: Epoch 13 / 100: avg data time: 1.01e+01, avg batch time: 11.2875, average train loss: 46.3164
[10/03 11:29:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7143, average loss: 37.2626
[10/03 11:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.91	
[10/03 11:29:24 visual_prompt]: Best epoch 13: best metric: -37.263
[10/03 11:29:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[10/03 11:35:59 visual_prompt]: Epoch 14 / 100: avg data time: 1.01e+01, avg batch time: 11.2917, average train loss: 36.0580
[10/03 11:36:46 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7104, average loss: 32.2358
[10/03 11:36:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.91	
[10/03 11:36:46 visual_prompt]: Best epoch 14: best metric: -32.236
[10/03 11:36:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[10/03 11:43:22 visual_prompt]: Epoch 15 / 100: avg data time: 1.01e+01, avg batch time: 11.3114, average train loss: 43.3242
[10/03 11:44:09 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.7144, average loss: 16.1969
[10/03 11:44:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.34	
[10/03 11:44:09 visual_prompt]: Best epoch 15: best metric: -16.197
[10/03 11:44:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[10/03 11:51:03 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 11.8039, average train loss: 23.8807
[10/03 11:51:52 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.7110, average loss: 11.9175
[10/03 11:51:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 43.80	
[10/03 11:51:52 visual_prompt]: Best epoch 16: best metric: -11.918
[10/03 11:51:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[10/03 11:58:39 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 11.6332, average train loss: 31.0473
[10/03 11:59:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7111, average loss: 78.6212
[10/03 11:59:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[10/03 11:59:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[10/03 12:05:59 visual_prompt]: Epoch 18 / 100: avg data time: 1.01e+01, avg batch time: 11.2491, average train loss: 47.2819
[10/03 12:06:46 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.7174, average loss: 3.7568
[10/03 12:06:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.34	
[10/03 12:06:46 visual_prompt]: Best epoch 18: best metric: -3.757
[10/03 12:06:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[10/03 12:13:21 visual_prompt]: Epoch 19 / 100: avg data time: 1.01e+01, avg batch time: 11.2912, average train loss: 27.8316
[10/03 12:14:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.7107, average loss: 37.1191
[10/03 12:14:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.28	
[10/03 12:14:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[10/03 12:20:44 visual_prompt]: Epoch 20 / 100: avg data time: 1.02e+01, avg batch time: 11.3303, average train loss: 26.2649
[10/03 12:21:31 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7153, average loss: 10.2520
[10/03 12:21:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.63	
[10/03 12:21:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[10/03 12:28:21 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.7239, average train loss: 24.1919
[10/03 12:29:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7156, average loss: 28.2498
[10/03 12:29:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.39	
[10/03 12:29:10 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[10/03 12:36:03 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 11.7959, average train loss: 39.1432
[10/03 12:36:51 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7119, average loss: 91.6308
[10/03 12:36:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.86	
[10/03 12:36:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[10/03 12:43:32 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 11.4630, average train loss: 34.1969
[10/03 12:44:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.7186, average loss: 31.0454
[10/03 12:44:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.16	
[10/03 12:44:19 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[10/03 12:50:59 visual_prompt]: Epoch 24 / 100: avg data time: 1.03e+01, avg batch time: 11.4218, average train loss: 64.6989
[10/03 12:51:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7146, average loss: 111.8331
[10/03 12:51:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.55	
[10/03 12:51:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[10/03 12:58:21 visual_prompt]: Epoch 25 / 100: avg data time: 1.01e+01, avg batch time: 11.2679, average train loss: 36.7877
[10/03 12:59:07 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.7073, average loss: 31.2371
[10/03 12:59:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.40	
[10/03 12:59:07 visual_prompt]: Stopping early.
[10/03 12:59:07 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 12:59:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 12:59:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 12:59:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 12:59:07 visual_prompt]: Training with config:
[10/03 12:59:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 12:59:07 visual_prompt]: Loading training data...
[10/03 12:59:07 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 12:59:07 visual_prompt]: Loading validation data...
[10/03 12:59:07 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 12:59:07 visual_prompt]: Constructing models...
[10/03 12:59:10 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 12:59:10 visual_prompt]: tuned percent:0.536
[10/03 12:59:10 visual_prompt]: Device used for model: 0
[10/03 12:59:10 visual_prompt]: Setting up Evaluator...
[10/03 12:59:10 visual_prompt]: Setting up Trainer...
[10/03 12:59:10 visual_prompt]: 	Setting up the optimizer...
[10/03 12:59:10 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 13:05:54 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 11.5545, average train loss: 1.4432
[10/03 13:06:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.7065, average loss: 1.4399
[10/03 13:06:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 13:06:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[10/03 13:13:40 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.8965, average train loss: 22.8654
[10/03 13:14:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.7040, average loss: 2.1768
[10/03 13:14:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.16	
[10/03 13:14:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[10/03 13:21:03 visual_prompt]: Epoch 3 / 100: avg data time: 1.01e+01, avg batch time: 11.3016, average train loss: 10.2310
[10/03 13:21:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.7081, average loss: 4.4416
[10/03 13:21:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[10/03 13:21:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[10/03 13:28:17 visual_prompt]: Epoch 4 / 100: avg data time: 9.92e+00, avg batch time: 11.0855, average train loss: 12.5841
[10/03 13:29:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7152, average loss: 3.7683
[10/03 13:29:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.25	
[10/03 13:29:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[10/03 13:35:32 visual_prompt]: Epoch 5 / 100: avg data time: 9.94e+00, avg batch time: 11.1076, average train loss: 16.9831
[10/03 13:36:19 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.7085, average loss: 4.0548
[10/03 13:36:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.93	
[10/03 13:36:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[10/03 13:42:59 visual_prompt]: Epoch 6 / 100: avg data time: 1.02e+01, avg batch time: 11.4080, average train loss: 14.1939
[10/03 13:43:47 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.7070, average loss: 28.4640
[10/03 13:43:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.82	
[10/03 13:43:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[10/03 13:50:45 visual_prompt]: Epoch 7 / 100: avg data time: 1.08e+01, avg batch time: 11.9340, average train loss: 15.7390
[10/03 13:51:35 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.7045, average loss: 1.7573
[10/03 13:51:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.28	
[10/03 13:51:35 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[10/03 13:58:13 visual_prompt]: Epoch 8 / 100: avg data time: 1.02e+01, avg batch time: 11.3876, average train loss: 25.4060
[10/03 13:59:00 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.7076, average loss: 46.0501
[10/03 13:59:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.29	
[10/03 13:59:00 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[10/03 14:05:39 visual_prompt]: Epoch 9 / 100: avg data time: 1.02e+01, avg batch time: 11.3715, average train loss: 32.3422
[10/03 14:06:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7104, average loss: 33.3962
[10/03 14:06:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[10/03 14:06:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[10/03 14:13:03 visual_prompt]: Epoch 10 / 100: avg data time: 1.02e+01, avg batch time: 11.3591, average train loss: 32.3070
[10/03 14:13:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7127, average loss: 16.7560
[10/03 14:13:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.99	
[10/03 14:13:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[10/03 14:20:29 visual_prompt]: Epoch 11 / 100: avg data time: 1.02e+01, avg batch time: 11.3855, average train loss: 26.8079
[10/03 14:21:16 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7134, average loss: 13.8130
[10/03 14:21:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.07	
[10/03 14:21:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[10/03 14:28:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 12.0330, average train loss: 37.1260
[10/03 14:29:09 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.7052, average loss: 7.6542
[10/03 14:29:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.91	
[10/03 14:29:09 visual_prompt]: Best epoch 12: best metric: -7.654
[10/03 14:29:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[10/03 14:36:09 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.9948, average train loss: 30.7710
[10/03 14:36:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.7045, average loss: 20.2509
[10/03 14:36:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.76	
[10/03 14:36:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[10/03 14:43:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.00e+01, avg batch time: 11.1628, average train loss: 26.0024
[10/03 14:44:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7103, average loss: 7.7522
[10/03 14:44:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.38	
[10/03 14:44:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[10/03 14:50:48 visual_prompt]: Epoch 15 / 100: avg data time: 1.01e+01, avg batch time: 11.2636, average train loss: 17.1599
[10/03 14:51:34 visual_prompt]: Inference (val):avg data time: 4.48e-05, avg batch time: 0.7078, average loss: 8.3548
[10/03 14:51:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.95	
[10/03 14:51:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[10/03 14:58:07 visual_prompt]: Epoch 16 / 100: avg data time: 1.01e+01, avg batch time: 11.2396, average train loss: 12.9468
[10/03 14:58:54 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.7123, average loss: 33.5613
[10/03 14:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.27	
[10/03 14:58:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[10/03 15:05:26 visual_prompt]: Epoch 17 / 100: avg data time: 1.00e+01, avg batch time: 11.2057, average train loss: 23.6514
[10/03 15:06:12 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.7092, average loss: 26.2987
[10/03 15:06:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.53	
[10/03 15:06:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[10/03 15:12:39 visual_prompt]: Epoch 18 / 100: avg data time: 9.89e+00, avg batch time: 11.0616, average train loss: 18.0545
[10/03 15:13:25 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7073, average loss: 72.2691
[10/03 15:13:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.00	
[10/03 15:13:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[10/03 15:19:52 visual_prompt]: Epoch 19 / 100: avg data time: 9.90e+00, avg batch time: 11.0624, average train loss: 22.4134
[10/03 15:20:38 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.7160, average loss: 12.7482
[10/03 15:20:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.83	
[10/03 15:20:38 visual_prompt]: Stopping early.
[10/03 15:20:38 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 15:20:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 15:20:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 15:20:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 15:20:38 visual_prompt]: Training with config:
[10/03 15:20:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 15:20:38 visual_prompt]: Loading training data...
[10/03 15:20:38 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 15:20:38 visual_prompt]: Loading validation data...
[10/03 15:20:38 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 15:20:38 visual_prompt]: Constructing models...
[10/03 15:20:41 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 15:20:41 visual_prompt]: tuned percent:0.536
[10/03 15:20:41 visual_prompt]: Device used for model: 0
[10/03 15:20:41 visual_prompt]: Setting up Evaluator...
[10/03 15:20:41 visual_prompt]: Setting up Trainer...
[10/03 15:20:41 visual_prompt]: 	Setting up the optimizer...
[10/03 15:20:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 15:27:10 visual_prompt]: Epoch 1 / 100: avg data time: 9.93e+00, avg batch time: 11.0978, average train loss: 1.4432
[10/03 15:27:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.7049, average loss: 1.4399
[10/03 15:27:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 15:27:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[10/03 15:34:23 visual_prompt]: Epoch 2 / 100: avg data time: 9.91e+00, avg batch time: 11.0711, average train loss: 9.2562
[10/03 15:35:09 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.7092, average loss: 0.9879
[10/03 15:35:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.20	
[10/03 15:35:09 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[10/03 15:41:37 visual_prompt]: Epoch 3 / 100: avg data time: 9.91e+00, avg batch time: 11.0771, average train loss: 2.4942
[10/03 15:42:22 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.7006, average loss: 6.8142
[10/03 15:42:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.76	
[10/03 15:42:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[10/03 15:48:50 visual_prompt]: Epoch 4 / 100: avg data time: 9.90e+00, avg batch time: 11.0682, average train loss: 5.6242
[10/03 15:49:36 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7132, average loss: 6.9050
[10/03 15:49:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.89	
[10/03 15:49:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[10/03 15:56:04 visual_prompt]: Epoch 5 / 100: avg data time: 9.92e+00, avg batch time: 11.0829, average train loss: 7.6706
[10/03 15:56:51 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.7140, average loss: 5.2614
[10/03 15:56:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.99	
[10/03 15:56:51 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[10/03 16:03:23 visual_prompt]: Epoch 6 / 100: avg data time: 1.01e+01, avg batch time: 11.2123, average train loss: 19.0181
[10/03 16:04:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7085, average loss: 0.7194
[10/03 16:04:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 57.52	
[10/03 16:04:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[10/03 16:10:40 visual_prompt]: Epoch 7 / 100: avg data time: 9.94e+00, avg batch time: 11.1027, average train loss: 17.8882
[10/03 16:11:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.7167, average loss: 6.5757
[10/03 16:11:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.57	
[10/03 16:11:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[10/03 16:17:52 visual_prompt]: Epoch 8 / 100: avg data time: 9.87e+00, avg batch time: 11.0395, average train loss: 12.8227
[10/03 16:18:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.7039, average loss: 4.7389
[10/03 16:18:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 39.13	
[10/03 16:18:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[10/03 16:25:04 visual_prompt]: Epoch 9 / 100: avg data time: 9.88e+00, avg batch time: 11.0350, average train loss: 20.9709
[10/03 16:25:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7096, average loss: 7.2642
[10/03 16:25:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.39	
[10/03 16:25:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[10/03 16:32:16 visual_prompt]: Epoch 10 / 100: avg data time: 9.86e+00, avg batch time: 11.0282, average train loss: 22.7366
[10/03 16:33:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7039, average loss: 1.5493
[10/03 16:33:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 45.70	
[10/03 16:33:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[10/03 16:39:27 visual_prompt]: Epoch 11 / 100: avg data time: 9.85e+00, avg batch time: 11.0142, average train loss: 33.4817
[10/03 16:40:13 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.7103, average loss: 77.6934
[10/03 16:40:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.96	
[10/03 16:40:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[10/03 16:46:39 visual_prompt]: Epoch 12 / 100: avg data time: 9.86e+00, avg batch time: 11.0237, average train loss: 17.5302
[10/03 16:47:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.7101, average loss: 26.9904
[10/03 16:47:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.43	
[10/03 16:47:24 visual_prompt]: Best epoch 12: best metric: -26.990
[10/03 16:47:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[10/03 16:53:50 visual_prompt]: Epoch 13 / 100: avg data time: 9.85e+00, avg batch time: 11.0165, average train loss: 20.1795
[10/03 16:54:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.7134, average loss: 21.5882
[10/03 16:54:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.11	
[10/03 16:54:35 visual_prompt]: Best epoch 13: best metric: -21.588
[10/03 16:54:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[10/03 17:00:59 visual_prompt]: Epoch 14 / 100: avg data time: 9.78e+00, avg batch time: 10.9458, average train loss: 25.6916
[10/03 17:01:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.7125, average loss: 4.7068
[10/03 17:01:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.73	
[10/03 17:01:44 visual_prompt]: Best epoch 14: best metric: -4.707
[10/03 17:01:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[10/03 17:08:08 visual_prompt]: Epoch 15 / 100: avg data time: 9.80e+00, avg batch time: 10.9616, average train loss: 23.4192
[10/03 17:08:53 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7060, average loss: 16.3164
[10/03 17:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.41	
[10/03 17:08:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[10/03 17:15:17 visual_prompt]: Epoch 16 / 100: avg data time: 9.79e+00, avg batch time: 10.9559, average train loss: 19.6790
[10/03 17:16:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7059, average loss: 18.2637
[10/03 17:16:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.18	
[10/03 17:16:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[10/03 17:22:26 visual_prompt]: Epoch 17 / 100: avg data time: 9.79e+00, avg batch time: 10.9516, average train loss: 24.6416
[10/03 17:23:11 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7088, average loss: 7.9506
[10/03 17:23:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 48.31	
[10/03 17:23:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[10/03 17:29:35 visual_prompt]: Epoch 18 / 100: avg data time: 9.79e+00, avg batch time: 10.9598, average train loss: 20.7228
[10/03 17:30:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7112, average loss: 49.8067
[10/03 17:30:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.53	
[10/03 17:30:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[10/03 17:36:42 visual_prompt]: Epoch 19 / 100: avg data time: 9.75e+00, avg batch time: 10.9188, average train loss: 19.0518
[10/03 17:37:27 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.7116, average loss: 48.1431
[10/03 17:37:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.26	
[10/03 17:37:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[10/03 17:43:52 visual_prompt]: Epoch 20 / 100: avg data time: 9.81e+00, avg batch time: 10.9738, average train loss: 31.3458
[10/03 17:44:37 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7104, average loss: 52.8666
[10/03 17:44:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.50	
[10/03 17:44:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[10/03 17:51:01 visual_prompt]: Epoch 21 / 100: avg data time: 9.79e+00, avg batch time: 10.9563, average train loss: 30.6290
[10/03 17:51:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7051, average loss: 1.5925
[10/03 17:51:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.07	
[10/03 17:51:46 visual_prompt]: Best epoch 21: best metric: -1.592
[10/03 17:51:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[10/03 17:58:09 visual_prompt]: Epoch 22 / 100: avg data time: 9.79e+00, avg batch time: 10.9482, average train loss: 22.4767
[10/03 17:58:55 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.7064, average loss: 10.3613
[10/03 17:58:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.59	
[10/03 17:58:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[10/03 18:05:19 visual_prompt]: Epoch 23 / 100: avg data time: 9.81e+00, avg batch time: 10.9749, average train loss: 15.4515
[10/03 18:06:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7197, average loss: 9.0750
[10/03 18:06:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.57	
[10/03 18:06:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[10/03 18:12:26 visual_prompt]: Epoch 24 / 100: avg data time: 9.74e+00, avg batch time: 10.9025, average train loss: 14.5855
[10/03 18:13:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.7096, average loss: 26.1873
[10/03 18:13:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.94	
[10/03 18:13:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[10/03 18:19:32 visual_prompt]: Epoch 25 / 100: avg data time: 9.71e+00, avg batch time: 10.8756, average train loss: 18.3749
[10/03 18:20:17 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.7152, average loss: 26.6809
[10/03 18:20:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.25	
[10/03 18:20:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[10/03 18:26:38 visual_prompt]: Epoch 26 / 100: avg data time: 9.71e+00, avg batch time: 10.8711, average train loss: 25.4017
[10/03 18:27:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.7049, average loss: 36.8443
[10/03 18:27:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.73	
[10/03 18:27:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[10/03 18:33:43 visual_prompt]: Epoch 27 / 100: avg data time: 9.71e+00, avg batch time: 10.8736, average train loss: 23.8162
[10/03 18:34:28 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.7153, average loss: 7.3207
[10/03 18:34:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 55.21	
[10/03 18:34:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[10/03 18:40:49 visual_prompt]: Epoch 28 / 100: avg data time: 9.70e+00, avg batch time: 10.8648, average train loss: 20.6091
[10/03 18:41:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7067, average loss: 16.8622
[10/03 18:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.42	
[10/03 18:41:34 visual_prompt]: Stopping early.
[10/03 18:41:34 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 18:41:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 18:41:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 18:41:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 18:41:34 visual_prompt]: Training with config:
[10/03 18:41:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 18:41:34 visual_prompt]: Loading training data...
[10/03 18:41:34 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 18:41:34 visual_prompt]: Loading validation data...
[10/03 18:41:34 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 18:41:34 visual_prompt]: Constructing models...
[10/03 18:41:37 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 18:41:37 visual_prompt]: tuned percent:0.536
[10/03 18:41:37 visual_prompt]: Device used for model: 0
[10/03 18:41:37 visual_prompt]: Setting up Evaluator...
[10/03 18:41:37 visual_prompt]: Setting up Trainer...
[10/03 18:41:37 visual_prompt]: 	Setting up the optimizer...
[10/03 18:41:37 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 18:47:59 visual_prompt]: Epoch 1 / 100: avg data time: 9.73e+00, avg batch time: 10.9027, average train loss: 1.4432
[10/03 18:48:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7167, average loss: 1.4399
[10/03 18:48:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 18:48:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[10/03 18:55:05 visual_prompt]: Epoch 2 / 100: avg data time: 9.73e+00, avg batch time: 10.8929, average train loss: 9.6677
[10/03 18:55:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.7082, average loss: 4.9732
[10/03 18:55:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.15	
[10/03 18:55:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[10/03 19:02:12 visual_prompt]: Epoch 3 / 100: avg data time: 9.74e+00, avg batch time: 10.9070, average train loss: 2.4882
[10/03 19:02:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.7101, average loss: 7.4281
[10/03 19:02:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.53	
[10/03 19:02:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[10/03 19:09:18 visual_prompt]: Epoch 4 / 100: avg data time: 9.72e+00, avg batch time: 10.8870, average train loss: 1.7303
[10/03 19:10:03 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.7079, average loss: 0.6894
[10/03 19:10:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.72	
[10/03 19:10:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[10/03 19:16:24 visual_prompt]: Epoch 5 / 100: avg data time: 9.71e+00, avg batch time: 10.8761, average train loss: 5.7066
[10/03 19:17:10 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.7120, average loss: 7.0995
[10/03 19:17:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[10/03 19:17:10 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[10/03 19:23:32 visual_prompt]: Epoch 6 / 100: avg data time: 9.75e+00, avg batch time: 10.9190, average train loss: 17.8190
[10/03 19:24:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.7091, average loss: 2.3499
[10/03 19:24:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 50.13	
[10/03 19:24:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[10/03 19:30:39 visual_prompt]: Epoch 7 / 100: avg data time: 9.75e+00, avg batch time: 10.9107, average train loss: 8.3594
[10/03 19:31:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7165, average loss: 13.2243
[10/03 19:31:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.95	
[10/03 19:31:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[10/03 19:37:45 visual_prompt]: Epoch 8 / 100: avg data time: 9.72e+00, avg batch time: 10.8842, average train loss: 15.1063
[10/03 19:38:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7066, average loss: 34.4613
[10/03 19:38:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.98	
[10/03 19:38:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[10/03 19:44:52 visual_prompt]: Epoch 9 / 100: avg data time: 9.75e+00, avg batch time: 10.9103, average train loss: 18.9363
[10/03 19:45:37 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.7098, average loss: 20.6348
[10/03 19:45:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[10/03 19:45:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[10/03 19:51:59 visual_prompt]: Epoch 10 / 100: avg data time: 9.73e+00, avg batch time: 10.8928, average train loss: 19.2340
[10/03 19:52:44 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.7106, average loss: 51.7530
[10/03 19:52:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.35	
[10/03 19:52:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[10/03 19:59:05 visual_prompt]: Epoch 11 / 100: avg data time: 9.72e+00, avg batch time: 10.8881, average train loss: 28.7346
[10/03 19:59:50 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7086, average loss: 54.1221
[10/03 19:59:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.17	
[10/03 19:59:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[10/03 20:06:11 visual_prompt]: Epoch 12 / 100: avg data time: 9.72e+00, avg batch time: 10.8836, average train loss: 17.2500
[10/03 20:06:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.7125, average loss: 34.5076
[10/03 20:06:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.53	
[10/03 20:06:56 visual_prompt]: Best epoch 12: best metric: -34.508
[10/03 20:06:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[10/03 20:13:18 visual_prompt]: Epoch 13 / 100: avg data time: 9.73e+00, avg batch time: 10.8943, average train loss: 19.7771
[10/03 20:14:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7056, average loss: 2.9311
[10/03 20:14:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.43	
[10/03 20:14:03 visual_prompt]: Best epoch 13: best metric: -2.931
[10/03 20:14:03 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[10/03 20:20:23 visual_prompt]: Epoch 14 / 100: avg data time: 9.71e+00, avg batch time: 10.8692, average train loss: 29.0508
[10/03 20:21:08 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7143, average loss: 2.0324
[10/03 20:21:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.08	
[10/03 20:21:08 visual_prompt]: Best epoch 14: best metric: -2.032
[10/03 20:21:08 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[10/03 20:27:30 visual_prompt]: Epoch 15 / 100: avg data time: 9.73e+00, avg batch time: 10.8972, average train loss: 22.0962
[10/03 20:28:15 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.7118, average loss: 8.2871
[10/03 20:28:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.00	
[10/03 20:28:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[10/03 20:34:36 visual_prompt]: Epoch 16 / 100: avg data time: 9.71e+00, avg batch time: 10.8757, average train loss: 13.7697
[10/03 20:35:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7077, average loss: 8.4502
[10/03 20:35:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.18	
[10/03 20:35:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[10/03 20:41:41 visual_prompt]: Epoch 17 / 100: avg data time: 9.70e+00, avg batch time: 10.8639, average train loss: 11.2027
[10/03 20:42:26 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.7163, average loss: 5.0257
[10/03 20:42:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.31	
[10/03 20:42:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[10/03 20:48:47 visual_prompt]: Epoch 18 / 100: avg data time: 9.71e+00, avg batch time: 10.8705, average train loss: 16.5939
[10/03 20:49:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7151, average loss: 8.1210
[10/03 20:49:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.86	
[10/03 20:49:32 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[10/03 20:55:53 visual_prompt]: Epoch 19 / 100: avg data time: 9.72e+00, avg batch time: 10.8788, average train loss: 18.0008
[10/03 20:56:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.7198, average loss: 11.1219
[10/03 20:56:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.23	
[10/03 20:56:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[10/03 21:02:59 visual_prompt]: Epoch 20 / 100: avg data time: 9.72e+00, avg batch time: 10.8807, average train loss: 20.6965
[10/03 21:03:44 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.7140, average loss: 24.7778
[10/03 21:03:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.97	
[10/03 21:03:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[10/03 21:10:05 visual_prompt]: Epoch 21 / 100: avg data time: 9.70e+00, avg batch time: 10.8642, average train loss: 11.0656
[10/03 21:10:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.7075, average loss: 1.4052
[10/03 21:10:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.87	
[10/03 21:10:50 visual_prompt]: Best epoch 21: best metric: -1.405
[10/03 21:10:50 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[10/03 21:17:11 visual_prompt]: Epoch 22 / 100: avg data time: 9.71e+00, avg batch time: 10.8768, average train loss: 14.1753
[10/03 21:17:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.7125, average loss: 3.4826
[10/03 21:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.02	
[10/03 21:17:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[10/03 21:24:17 visual_prompt]: Epoch 23 / 100: avg data time: 9.72e+00, avg batch time: 10.8857, average train loss: 28.1918
[10/03 21:25:02 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.7109, average loss: 14.0717
[10/03 21:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.67	
[10/03 21:25:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[10/03 21:31:23 visual_prompt]: Epoch 24 / 100: avg data time: 9.72e+00, avg batch time: 10.8858, average train loss: 26.3734
[10/03 21:32:08 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.7048, average loss: 23.6252
[10/03 21:32:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.24	
[10/03 21:32:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[10/03 21:38:29 visual_prompt]: Epoch 25 / 100: avg data time: 9.72e+00, avg batch time: 10.8801, average train loss: 28.4121
[10/03 21:39:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7178, average loss: 4.3463
[10/03 21:39:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.13	
[10/03 21:39:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[10/03 21:45:35 visual_prompt]: Epoch 26 / 100: avg data time: 9.72e+00, avg batch time: 10.8845, average train loss: 14.5191
[10/03 21:46:20 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.7105, average loss: 38.6980
[10/03 21:46:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.34	
[10/03 21:46:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[10/03 21:52:41 visual_prompt]: Epoch 27 / 100: avg data time: 9.72e+00, avg batch time: 10.8837, average train loss: 19.8404
[10/03 21:53:26 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7141, average loss: 34.7308
[10/03 21:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.30	
[10/03 21:53:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[10/03 21:59:47 visual_prompt]: Epoch 28 / 100: avg data time: 9.70e+00, avg batch time: 10.8624, average train loss: 16.0658
[10/03 22:00:32 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.7140, average loss: 26.2042
[10/03 22:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.71	
[10/03 22:00:32 visual_prompt]: Stopping early.
[10/03 22:00:32 visual_prompt]: Rank of current process: 0. World size: 1
[10/03 22:00:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/03 22:00:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/03 22:00:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/03 22:00:32 visual_prompt]: Training with config:
[10/03 22:00:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/03 22:00:32 visual_prompt]: Loading training data...
[10/03 22:00:32 visual_prompt]: Constructing mammo-cbis dataset train...
[10/03 22:00:32 visual_prompt]: Loading validation data...
[10/03 22:00:32 visual_prompt]: Constructing mammo-cbis dataset val...
[10/03 22:00:32 visual_prompt]: Constructing models...
[10/03 22:00:35 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/03 22:00:35 visual_prompt]: tuned percent:0.536
[10/03 22:00:35 visual_prompt]: Device used for model: 0
[10/03 22:00:35 visual_prompt]: Setting up Evaluator...
[10/03 22:00:35 visual_prompt]: Setting up Trainer...
[10/03 22:00:35 visual_prompt]: 	Setting up the optimizer...
[10/03 22:00:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/03 22:06:57 visual_prompt]: Epoch 1 / 100: avg data time: 9.75e+00, avg batch time: 10.9083, average train loss: 1.4432
[10/03 22:07:42 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7138, average loss: 1.4399
[10/03 22:07:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/03 22:07:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[10/03 22:14:03 visual_prompt]: Epoch 2 / 100: avg data time: 9.72e+00, avg batch time: 10.8912, average train loss: 9.0441
[10/03 22:14:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.7170, average loss: 0.9360
[10/03 22:14:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.92	
[10/03 22:14:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[10/03 22:21:10 visual_prompt]: Epoch 3 / 100: avg data time: 9.72e+00, avg batch time: 10.8914, average train loss: 1.0445
[10/03 22:21:55 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7160, average loss: 1.9347
[10/03 22:21:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.66	
[10/03 22:21:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[10/03 22:28:16 visual_prompt]: Epoch 4 / 100: avg data time: 9.72e+00, avg batch time: 10.8831, average train loss: 3.6043
[10/03 22:29:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7114, average loss: 8.9295
[10/03 22:29:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.71	
[10/03 22:29:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[10/03 22:35:21 visual_prompt]: Epoch 5 / 100: avg data time: 9.69e+00, avg batch time: 10.8644, average train loss: 8.9083
[10/03 22:36:06 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.7122, average loss: 10.0134
[10/03 22:36:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.78	
[10/03 22:36:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[10/03 22:42:29 visual_prompt]: Epoch 6 / 100: avg data time: 9.75e+00, avg batch time: 10.9167, average train loss: 13.0730
[10/03 22:43:14 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7053, average loss: 4.2438
[10/03 22:43:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.18	
[10/03 22:43:14 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[10/03 22:49:35 visual_prompt]: Epoch 7 / 100: avg data time: 9.74e+00, avg batch time: 10.9017, average train loss: 6.0095
[10/03 22:50:20 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7180, average loss: 3.6710
[10/03 22:50:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.05	
[10/03 22:50:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[10/03 22:56:41 visual_prompt]: Epoch 8 / 100: avg data time: 9.70e+00, avg batch time: 10.8676, average train loss: 9.5570
[10/03 22:57:26 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.7131, average loss: 10.2672
[10/03 22:57:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.79	
[10/03 22:57:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[10/03 23:03:48 visual_prompt]: Epoch 9 / 100: avg data time: 9.73e+00, avg batch time: 10.8966, average train loss: 18.1117
[10/03 23:04:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.7134, average loss: 3.1503
[10/03 23:04:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.39	
[10/03 23:04:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[10/03 23:10:54 visual_prompt]: Epoch 10 / 100: avg data time: 9.72e+00, avg batch time: 10.8965, average train loss: 9.7942
[10/03 23:11:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7102, average loss: 14.7436
[10/03 23:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.73	
[10/03 23:11:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[10/03 23:18:01 visual_prompt]: Epoch 11 / 100: avg data time: 9.73e+00, avg batch time: 10.8940, average train loss: 10.8210
[10/03 23:18:46 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.7106, average loss: 10.0464
[10/03 23:18:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.34	
[10/03 23:18:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[10/03 23:25:06 visual_prompt]: Epoch 12 / 100: avg data time: 9.71e+00, avg batch time: 10.8773, average train loss: 9.2027
[10/03 23:25:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7108, average loss: 20.1761
[10/03 23:25:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.99	
[10/03 23:25:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[10/03 23:32:13 visual_prompt]: Epoch 13 / 100: avg data time: 9.73e+00, avg batch time: 10.9013, average train loss: 8.9209
[10/03 23:32:58 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.7055, average loss: 5.2801
[10/03 23:32:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.70	
[10/03 23:32:58 visual_prompt]: Best epoch 13: best metric: -5.280
[10/03 23:32:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[10/03 23:39:19 visual_prompt]: Epoch 14 / 100: avg data time: 9.70e+00, avg batch time: 10.8709, average train loss: 13.7929
[10/03 23:40:04 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.7184, average loss: 14.0152
[10/03 23:40:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.17	
[10/03 23:40:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[10/03 23:46:25 visual_prompt]: Epoch 15 / 100: avg data time: 9.72e+00, avg batch time: 10.8876, average train loss: 5.6168
[10/03 23:47:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.7171, average loss: 15.0701
[10/03 23:47:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.86	
[10/03 23:47:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[10/03 23:53:32 visual_prompt]: Epoch 16 / 100: avg data time: 9.73e+00, avg batch time: 10.8915, average train loss: 13.8660
[10/03 23:54:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.7119, average loss: 44.8438
[10/03 23:54:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.47	
[10/03 23:54:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[10/04 00:00:37 visual_prompt]: Epoch 17 / 100: avg data time: 9.70e+00, avg batch time: 10.8647, average train loss: 21.3088
[10/04 00:01:22 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7151, average loss: 18.9820
[10/04 00:01:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.40	
[10/04 00:01:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[10/04 00:07:43 visual_prompt]: Epoch 18 / 100: avg data time: 9.71e+00, avg batch time: 10.8793, average train loss: 19.7951
[10/04 00:08:28 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.7124, average loss: 43.6749
[10/04 00:08:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.85	
[10/04 00:08:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[10/04 00:14:49 visual_prompt]: Epoch 19 / 100: avg data time: 9.70e+00, avg batch time: 10.8654, average train loss: 12.8931
[10/04 00:15:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7157, average loss: 0.7768
[10/04 00:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.24	
[10/04 00:15:34 visual_prompt]: Best epoch 19: best metric: -0.777
[10/04 00:15:34 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[10/04 00:21:55 visual_prompt]: Epoch 20 / 100: avg data time: 9.72e+00, avg batch time: 10.8841, average train loss: 5.9698
[10/04 00:22:40 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7129, average loss: 11.3266
[10/04 00:22:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.41	
[10/04 00:22:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[10/04 00:29:01 visual_prompt]: Epoch 21 / 100: avg data time: 9.71e+00, avg batch time: 10.8805, average train loss: 16.1827
[10/04 00:29:46 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.7090, average loss: 21.6334
[10/04 00:29:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.07	
[10/04 00:29:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[10/04 00:36:07 visual_prompt]: Epoch 22 / 100: avg data time: 9.70e+00, avg batch time: 10.8702, average train loss: 15.7095
[10/04 00:36:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.7121, average loss: 13.9571
[10/04 00:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.71	
[10/04 00:36:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[10/04 00:43:13 visual_prompt]: Epoch 23 / 100: avg data time: 9.73e+00, avg batch time: 10.8883, average train loss: 23.6315
[10/04 00:43:58 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.7170, average loss: 29.8744
[10/04 00:43:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.64	
[10/04 00:43:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[10/04 00:50:20 visual_prompt]: Epoch 24 / 100: avg data time: 9.73e+00, avg batch time: 10.8922, average train loss: 12.8623
[10/04 00:51:05 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.7115, average loss: 8.1316
[10/04 00:51:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.88	
[10/04 00:51:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[10/04 00:57:26 visual_prompt]: Epoch 25 / 100: avg data time: 9.71e+00, avg batch time: 10.8775, average train loss: 9.8170
[10/04 00:58:11 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.7117, average loss: 9.4115
[10/04 00:58:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.27	
[10/04 00:58:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[10/04 01:04:31 visual_prompt]: Epoch 26 / 100: avg data time: 9.70e+00, avg batch time: 10.8721, average train loss: 5.1545
[10/04 01:05:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.7198, average loss: 9.8931
[10/04 01:05:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.59	
[10/04 01:05:16 visual_prompt]: Stopping early.
[10/04 01:05:17 visual_prompt]: Rank of current process: 0. World size: 1
[10/04 01:05:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/04 01:05:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/04 01:05:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/04 01:05:17 visual_prompt]: Training with config:
[10/04 01:05:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/04 01:05:17 visual_prompt]: Loading training data...
[10/04 01:05:17 visual_prompt]: Constructing mammo-cbis dataset train...
[10/04 01:05:17 visual_prompt]: Loading validation data...
[10/04 01:05:17 visual_prompt]: Constructing mammo-cbis dataset val...
[10/04 01:05:17 visual_prompt]: Constructing models...
[10/04 01:05:19 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/04 01:05:19 visual_prompt]: tuned percent:0.536
[10/04 01:05:19 visual_prompt]: Device used for model: 0
[10/04 01:05:19 visual_prompt]: Setting up Evaluator...
[10/04 01:05:19 visual_prompt]: Setting up Trainer...
[10/04 01:05:19 visual_prompt]: 	Setting up the optimizer...
[10/04 01:05:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/04 01:11:41 visual_prompt]: Epoch 1 / 100: avg data time: 9.75e+00, avg batch time: 10.9164, average train loss: 1.4432
[10/04 01:12:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7116, average loss: 1.4399
[10/04 01:12:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/04 01:12:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[10/04 01:18:48 visual_prompt]: Epoch 2 / 100: avg data time: 9.74e+00, avg batch time: 10.9031, average train loss: 9.2018
[10/04 01:19:33 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.7156, average loss: 1.5829
[10/04 01:19:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.36	
[10/04 01:19:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[10/04 01:25:55 visual_prompt]: Epoch 3 / 100: avg data time: 9.72e+00, avg batch time: 10.8895, average train loss: 2.5722
[10/04 01:26:40 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.7157, average loss: 8.0551
[10/04 01:26:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.68	
[10/04 01:26:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[10/04 01:33:01 visual_prompt]: Epoch 4 / 100: avg data time: 9.72e+00, avg batch time: 10.8887, average train loss: 5.0648
[10/04 01:33:46 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.7134, average loss: 2.7494
[10/04 01:33:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.32	
[10/04 01:33:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[10/04 01:40:07 visual_prompt]: Epoch 5 / 100: avg data time: 9.72e+00, avg batch time: 10.8889, average train loss: 5.9388
[10/04 01:40:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7120, average loss: 0.7020
[10/04 01:40:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 51.99	
[10/04 01:40:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[10/04 01:47:15 visual_prompt]: Epoch 6 / 100: avg data time: 9.75e+00, avg batch time: 10.9197, average train loss: 7.3723
[10/04 01:48:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7117, average loss: 11.8842
[10/04 01:48:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.00	
[10/04 01:48:00 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[10/04 01:54:22 visual_prompt]: Epoch 7 / 100: avg data time: 9.73e+00, avg batch time: 10.9032, average train loss: 10.6462
[10/04 01:55:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7146, average loss: 14.5550
[10/04 01:55:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.72	
[10/04 01:55:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[10/04 02:01:27 visual_prompt]: Epoch 8 / 100: avg data time: 9.70e+00, avg batch time: 10.8723, average train loss: 8.9280
[10/04 02:02:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7163, average loss: 9.1698
[10/04 02:02:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.57	
[10/04 02:02:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[10/04 02:08:35 visual_prompt]: Epoch 9 / 100: avg data time: 9.76e+00, avg batch time: 10.9228, average train loss: 5.9214
[10/04 02:09:20 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7174, average loss: 3.8356
[10/04 02:09:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.12	
[10/04 02:09:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[10/04 02:15:42 visual_prompt]: Epoch 10 / 100: avg data time: 9.73e+00, avg batch time: 10.8992, average train loss: 7.8584
[10/04 02:16:27 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.7129, average loss: 3.7298
[10/04 02:16:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.75	
[10/04 02:16:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[10/04 02:22:49 visual_prompt]: Epoch 11 / 100: avg data time: 9.74e+00, avg batch time: 10.9081, average train loss: 8.1157
[10/04 02:23:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.7201, average loss: 1.6773
[10/04 02:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.83	
[10/04 02:23:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[10/04 02:29:55 visual_prompt]: Epoch 12 / 100: avg data time: 9.72e+00, avg batch time: 10.8888, average train loss: 4.4833
[10/04 02:30:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.7138, average loss: 1.4647
[10/04 02:30:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.32	
[10/04 02:30:40 visual_prompt]: Best epoch 12: best metric: -1.465
[10/04 02:30:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[10/04 02:37:02 visual_prompt]: Epoch 13 / 100: avg data time: 9.73e+00, avg batch time: 10.9037, average train loss: 8.5253
[10/04 02:37:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.7106, average loss: 17.3172
[10/04 02:37:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.29	
[10/04 02:37:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[10/04 02:44:08 visual_prompt]: Epoch 14 / 100: avg data time: 9.71e+00, avg batch time: 10.8813, average train loss: 19.2262
[10/04 02:44:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.7199, average loss: 79.2466
[10/04 02:44:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.96	
[10/04 02:44:53 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[10/04 02:51:15 visual_prompt]: Epoch 15 / 100: avg data time: 9.75e+00, avg batch time: 10.9127, average train loss: 26.3857
[10/04 02:52:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7201, average loss: 55.8470
[10/04 02:52:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.26	
[10/04 02:52:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[10/04 02:58:22 visual_prompt]: Epoch 16 / 100: avg data time: 9.74e+00, avg batch time: 10.9018, average train loss: 20.6188
[10/04 02:59:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.7137, average loss: 1.1186
[10/04 02:59:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.18	
[10/04 02:59:07 visual_prompt]: Best epoch 16: best metric: -1.119
[10/04 02:59:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[10/04 03:05:29 visual_prompt]: Epoch 17 / 100: avg data time: 9.73e+00, avg batch time: 10.8930, average train loss: 9.0387
[10/04 03:06:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.7123, average loss: 12.3150
[10/04 03:06:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.02	
[10/04 03:06:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[10/04 03:12:35 visual_prompt]: Epoch 18 / 100: avg data time: 9.71e+00, avg batch time: 10.8868, average train loss: 11.3680
[10/04 03:13:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7185, average loss: 16.7676
[10/04 03:13:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.74	
[10/04 03:13:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[10/04 03:19:42 visual_prompt]: Epoch 19 / 100: avg data time: 9.74e+00, avg batch time: 10.9081, average train loss: 11.6831
[10/04 03:20:27 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.7216, average loss: 3.7828
[10/04 03:20:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.68	
[10/04 03:20:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[10/04 03:26:49 visual_prompt]: Epoch 20 / 100: avg data time: 9.73e+00, avg batch time: 10.8935, average train loss: 10.7619
[10/04 03:27:34 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.7126, average loss: 7.9773
[10/04 03:27:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.86	
[10/04 03:27:34 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[10/04 03:33:56 visual_prompt]: Epoch 21 / 100: avg data time: 9.73e+00, avg batch time: 10.9004, average train loss: 5.0341
[10/04 03:34:41 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.7150, average loss: 7.1729
[10/04 03:34:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.08	
[10/04 03:34:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[10/04 03:41:02 visual_prompt]: Epoch 22 / 100: avg data time: 9.71e+00, avg batch time: 10.8791, average train loss: 4.7154
[10/04 03:41:47 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.7117, average loss: 1.0866
[10/04 03:41:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.25	
[10/04 03:41:47 visual_prompt]: Best epoch 22: best metric: -1.087
[10/04 03:41:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[10/04 03:48:09 visual_prompt]: Epoch 23 / 100: avg data time: 9.74e+00, avg batch time: 10.9093, average train loss: 6.5585
[10/04 03:48:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.7153, average loss: 10.5957
[10/04 03:48:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.66	
[10/04 03:48:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[10/04 03:55:16 visual_prompt]: Epoch 24 / 100: avg data time: 9.73e+00, avg batch time: 10.8963, average train loss: 6.5338
[10/04 03:56:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7081, average loss: 1.9253
[10/04 03:56:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.62	
[10/04 03:56:01 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[10/04 04:02:22 visual_prompt]: Epoch 25 / 100: avg data time: 9.72e+00, avg batch time: 10.8923, average train loss: 5.6481
[10/04 04:03:07 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.7214, average loss: 0.7693
[10/04 04:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.21	
[10/04 04:03:07 visual_prompt]: Best epoch 25: best metric: -0.769
[10/04 04:03:07 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[10/04 04:09:28 visual_prompt]: Epoch 26 / 100: avg data time: 9.71e+00, avg batch time: 10.8840, average train loss: 9.3473
[10/04 04:10:13 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.7158, average loss: 0.7305
[10/04 04:10:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.20	
[10/04 04:10:13 visual_prompt]: Best epoch 26: best metric: -0.730
[10/04 04:10:13 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[10/04 04:16:35 visual_prompt]: Epoch 27 / 100: avg data time: 9.72e+00, avg batch time: 10.8901, average train loss: 6.2570
[10/04 04:17:20 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.7133, average loss: 1.6741
[10/04 04:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.52	
[10/04 04:17:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[10/04 04:23:41 visual_prompt]: Epoch 28 / 100: avg data time: 9.71e+00, avg batch time: 10.8789, average train loss: 4.0619
[10/04 04:24:26 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.7185, average loss: 7.3128
[10/04 04:24:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.83	
[10/04 04:24:26 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[10/04 04:30:48 visual_prompt]: Epoch 29 / 100: avg data time: 9.75e+00, avg batch time: 10.9132, average train loss: 2.6570
[10/04 04:31:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7072, average loss: 1.4253
[10/04 04:31:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.24	
[10/04 04:31:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[10/04 04:37:55 visual_prompt]: Epoch 30 / 100: avg data time: 9.72e+00, avg batch time: 10.8967, average train loss: 6.8175
[10/04 04:38:40 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.7107, average loss: 5.8767
[10/04 04:38:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.60	
[10/04 04:38:40 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[10/04 04:45:01 visual_prompt]: Epoch 31 / 100: avg data time: 9.72e+00, avg batch time: 10.8833, average train loss: 4.2146
[10/04 04:45:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.7231, average loss: 6.3998
[10/04 04:45:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.62	
[10/04 04:45:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[10/04 04:52:08 visual_prompt]: Epoch 32 / 100: avg data time: 9.74e+00, avg batch time: 10.9118, average train loss: 5.6568
[10/04 04:52:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.7106, average loss: 8.8228
[10/04 04:52:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.58	
[10/04 04:52:53 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[10/04 04:59:15 visual_prompt]: Epoch 33 / 100: avg data time: 9.73e+00, avg batch time: 10.9002, average train loss: 8.4704
[10/04 05:00:00 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.7113, average loss: 5.5750
[10/04 05:00:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.16	
[10/04 05:00:00 visual_prompt]: Stopping early.
[10/04 05:00:00 visual_prompt]: Rank of current process: 0. World size: 1
[10/04 05:00:00 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/04 05:00:00 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/04 05:00:00 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/04 05:00:00 visual_prompt]: Training with config:
[10/04 05:00:00 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/04 05:00:00 visual_prompt]: Loading training data...
[10/04 05:00:00 visual_prompt]: Constructing mammo-cbis dataset train...
[10/04 05:00:00 visual_prompt]: Loading validation data...
[10/04 05:00:00 visual_prompt]: Constructing mammo-cbis dataset val...
[10/04 05:00:00 visual_prompt]: Constructing models...
[10/04 05:00:03 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/04 05:00:03 visual_prompt]: tuned percent:0.536
[10/04 05:00:03 visual_prompt]: Device used for model: 0
[10/04 05:00:03 visual_prompt]: Setting up Evaluator...
[10/04 05:00:03 visual_prompt]: Setting up Trainer...
[10/04 05:00:03 visual_prompt]: 	Setting up the optimizer...
[10/04 05:00:03 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/04 05:06:26 visual_prompt]: Epoch 1 / 100: avg data time: 9.76e+00, avg batch time: 10.9274, average train loss: 1.4432
[10/04 05:07:11 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.7097, average loss: 1.4399
[10/04 05:07:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/04 05:07:11 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[10/04 05:13:32 visual_prompt]: Epoch 2 / 100: avg data time: 9.71e+00, avg batch time: 10.8806, average train loss: 4.8791
[10/04 05:14:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7156, average loss: 0.8683
[10/04 05:14:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.11	
[10/04 05:14:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[10/04 05:20:38 visual_prompt]: Epoch 3 / 100: avg data time: 9.72e+00, avg batch time: 10.8874, average train loss: 0.8329
[10/04 05:21:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7127, average loss: 0.6888
[10/04 05:21:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.13	
[10/04 05:21:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[10/04 05:27:44 visual_prompt]: Epoch 4 / 100: avg data time: 9.70e+00, avg batch time: 10.8723, average train loss: 1.0373
[10/04 05:28:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.7166, average loss: 2.7001
[10/04 05:28:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.44	
[10/04 05:28:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[10/04 05:34:49 visual_prompt]: Epoch 5 / 100: avg data time: 9.69e+00, avg batch time: 10.8617, average train loss: 2.1786
[10/04 05:35:34 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.7153, average loss: 0.9527
[10/04 05:35:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.39	
[10/04 05:35:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[10/04 05:41:55 visual_prompt]: Epoch 6 / 100: avg data time: 9.73e+00, avg batch time: 10.8931, average train loss: 4.6976
[10/04 05:42:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.7082, average loss: 4.2991
[10/04 05:42:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.29	
[10/04 05:42:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[10/04 05:49:02 visual_prompt]: Epoch 7 / 100: avg data time: 9.73e+00, avg batch time: 10.8973, average train loss: 5.6412
[10/04 05:49:47 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.7148, average loss: 9.2488
[10/04 05:49:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.49	
[10/04 05:49:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[10/04 05:56:08 visual_prompt]: Epoch 8 / 100: avg data time: 9.70e+00, avg batch time: 10.8712, average train loss: 7.6165
[10/04 05:56:53 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.7124, average loss: 8.5723
[10/04 05:56:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.97	
[10/04 05:56:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[10/04 06:03:15 visual_prompt]: Epoch 9 / 100: avg data time: 9.74e+00, avg batch time: 10.9132, average train loss: 10.4988
[10/04 06:04:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.7147, average loss: 4.1433
[10/04 06:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.38	
[10/04 06:04:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[10/04 06:10:21 visual_prompt]: Epoch 10 / 100: avg data time: 9.71e+00, avg batch time: 10.8838, average train loss: 15.8001
[10/04 06:11:06 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.7085, average loss: 19.3510
[10/04 06:11:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.40	
[10/04 06:11:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[10/04 06:17:27 visual_prompt]: Epoch 11 / 100: avg data time: 9.71e+00, avg batch time: 10.8855, average train loss: 9.7341
[10/04 06:18:12 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.7118, average loss: 17.0008
[10/04 06:18:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 37.84	
[10/04 06:18:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[10/04 06:24:34 visual_prompt]: Epoch 12 / 100: avg data time: 9.71e+00, avg batch time: 10.8907, average train loss: 11.0285
[10/04 06:25:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.7174, average loss: 10.6402
[10/04 06:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.79	
[10/04 06:25:19 visual_prompt]: Best epoch 12: best metric: -10.640
[10/04 06:25:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[10/04 06:31:40 visual_prompt]: Epoch 13 / 100: avg data time: 9.71e+00, avg batch time: 10.8856, average train loss: 13.5713
[10/04 06:32:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.7209, average loss: 8.3168
[10/04 06:32:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.88	
[10/04 06:32:25 visual_prompt]: Best epoch 13: best metric: -8.317
[10/04 06:32:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[10/04 06:38:45 visual_prompt]: Epoch 14 / 100: avg data time: 9.69e+00, avg batch time: 10.8574, average train loss: 9.5686
[10/04 06:39:30 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.7164, average loss: 2.0555
[10/04 06:39:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.93	
[10/04 06:39:30 visual_prompt]: Best epoch 14: best metric: -2.056
[10/04 06:39:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[10/04 06:45:52 visual_prompt]: Epoch 15 / 100: avg data time: 9.73e+00, avg batch time: 10.8965, average train loss: 10.8868
[10/04 06:46:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.7179, average loss: 0.7823
[10/04 06:46:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.67	
[10/04 06:46:37 visual_prompt]: Best epoch 15: best metric: -0.782
[10/04 06:46:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[10/04 06:52:58 visual_prompt]: Epoch 16 / 100: avg data time: 9.70e+00, avg batch time: 10.8763, average train loss: 11.4118
[10/04 06:53:43 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.7118, average loss: 6.8281
[10/04 06:53:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.32	
[10/04 06:53:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[10/04 07:00:03 visual_prompt]: Epoch 17 / 100: avg data time: 9.70e+00, avg batch time: 10.8676, average train loss: 14.4604
[10/04 07:00:48 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.7101, average loss: 16.6704
[10/04 07:00:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[10/04 07:00:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[10/04 07:07:09 visual_prompt]: Epoch 18 / 100: avg data time: 9.70e+00, avg batch time: 10.8749, average train loss: 11.6631
[10/04 07:07:54 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.7099, average loss: 4.6379
[10/04 07:07:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.75	
[10/04 07:07:54 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[10/04 07:14:15 visual_prompt]: Epoch 19 / 100: avg data time: 9.71e+00, avg batch time: 10.8803, average train loss: 13.7285
[10/04 07:15:00 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.7234, average loss: 29.2378
[10/04 07:15:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.53	
[10/04 07:15:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[10/04 07:21:21 visual_prompt]: Epoch 20 / 100: avg data time: 9.70e+00, avg batch time: 10.8720, average train loss: 10.5978
[10/04 07:22:06 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.7167, average loss: 7.2658
[10/04 07:22:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.70	
[10/04 07:22:06 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[10/04 07:28:27 visual_prompt]: Epoch 21 / 100: avg data time: 9.71e+00, avg batch time: 10.8760, average train loss: 8.7806
[10/04 07:29:12 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.7101, average loss: 3.6524
[10/04 07:29:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.48	
[10/04 07:29:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[10/04 07:35:32 visual_prompt]: Epoch 22 / 100: avg data time: 9.69e+00, avg batch time: 10.8625, average train loss: 9.3095
[10/04 07:36:17 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.7135, average loss: 8.0129
[10/04 07:36:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[10/04 07:36:17 visual_prompt]: Stopping early.
[10/04 07:36:17 visual_prompt]: Rank of current process: 0. World size: 1
[10/04 07:36:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/04 07:36:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss'])
[10/04 07:36:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/04 07:36:17 visual_prompt]: Training with config:
[10/04 07:36:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/04 07:36:17 visual_prompt]: Loading training data...
[10/04 07:36:17 visual_prompt]: Constructing mammo-cbis dataset train...
[10/04 07:36:17 visual_prompt]: Loading validation data...
[10/04 07:36:17 visual_prompt]: Constructing mammo-cbis dataset val...
[10/04 07:36:17 visual_prompt]: Constructing models...
[10/04 07:36:20 visual_prompt]: Total Parameters: 86260994	 Gradient Parameters: 462338
[10/04 07:36:20 visual_prompt]: tuned percent:0.536
[10/04 07:36:20 visual_prompt]: Device used for model: 0
[10/04 07:36:20 visual_prompt]: Setting up Evaluator...
[10/04 07:36:20 visual_prompt]: Setting up Trainer...
[10/04 07:36:20 visual_prompt]: 	Setting up the optimizer...
[10/04 07:36:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/04 07:42:42 visual_prompt]: Epoch 1 / 100: avg data time: 9.73e+00, avg batch time: 10.9042, average train loss: 1.4432
[10/04 07:43:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.7129, average loss: 1.4399
[10/04 07:43:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.07	
[10/04 07:43:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[10/04 07:49:48 visual_prompt]: Epoch 2 / 100: avg data time: 9.72e+00, avg batch time: 10.8884, average train loss: 4.6415
[10/04 07:50:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.7171, average loss: 1.0394
[10/04 07:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.68	
[10/04 07:50:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[10/04 07:56:55 visual_prompt]: Epoch 3 / 100: avg data time: 9.72e+00, avg batch time: 10.8856, average train loss: 1.4480
[10/04 07:57:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.7105, average loss: 0.8389
[10/04 07:57:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.85	
[10/04 07:57:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
slurmstepd-ctit088: error: *** JOB 238642 ON ctit088 CANCELLED AT 2023-10-04T08:02:19 ***
